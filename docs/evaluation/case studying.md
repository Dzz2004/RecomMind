# case studying

### **核心功能对比矩阵**

| **功能维度** | **本操作系统智能体系统 (OS Agent)** | **GPT-4o / ChatGPT (OpenAI)** | **Claude 3.5 Sonnet (Anthropic)** | **Gemini 2.5 Pro (Google)** | **DeepSeek V3 / R1 (深度求索)** | **Cursor / GitHub Copilot** |
| --- | --- | --- | --- | --- | --- | --- |
| **基础模型与部署** | **Qwen-8B + 4-bit 量化 (本地/私有部署)** | 闭源 API / 云端订阅 | 闭源 API / 云端 Artifacts | 闭源 API / 高延迟大规模推理 | **开源权重 (MoE 架构, 671B)** | 混合云架构 (集成 GPT-4/Claude) |
| **知识检索深度** | **双向 RAG：教材 PDF + 内核源码级索引** | 单层 File Search (RAG)：支持文件上传，深度有限 | 200k 长上下文：可处理多文件，但易丢失细节 | **1M - 10M 极大上下文：支持全量代码扫描** | 128k 上下文：支持代码搜索，缺乏教材元数据 | **仓库级索引：使用 Merkle 树同步代码索引** |
| **源码处理策略** | **两阶段检索 (文件摘要 + 块级语义重排)** | 线性检索：在大规模代码库中效率较低 | Agentic Coding：通过工具调用读写文件 | 原生 Context：直接暴力读取海量代码 | MLA 架构优化：减少推理时的 KV 缓存占用 | **实时同步：按需增量更新本地代码索引** |
| **教学判题能力** | **教材增强判题：支持置信度评分与分级反馈** | 通用评测：逻辑性强但无法对齐特定教学大纲 | 强逻辑纠错：适合代码审阅，缺乏教学分级 | 闭口题判题：处理长试卷表现优异 | **推理判题：R1 提供 Step-by-step 深度思考链** | 代码评审：侧重 Bug 检测，非教学性判分 |
| **交互体验** | **SSE 流式展示中间检索片段与思考过程** | 文本流式生成：不公开检索中间路径 | Artifacts：侧重静态展示，过程黑盒 | 文本生成：侧重多模态结果，检索过程不可见 | 文本生成：支持 DeepThink 思考过程展示 | **IDE 集成：原地生成/修改，支持浮窗解释** |
| **元数据溯源** | **精准溯源：包含教材章节、页码及函数行号** | 文件名引用：无法精确定位教材物理位置 | 上下文引用：展示引用来源，非结构化 | Vertex AI 溯源：展示参考文档链接 | 搜索模式：集成网页链接，缺乏教材元数据 | **代码跳转：支持从 AI 建议直接跳转至代码行** |
| **针对性优化** | **专注于 kernel/ 和 mm/ 模块的专项描述索引** | 通用能力：针对全行业通用知识 | 创意与文案：更偏向文学与高层逻辑 | 视频/长文档：侧重处理跨媒体海量数据 | 极高性价比：大幅降低了推理成本 | **补全与重构：针对生产环境的高效开发** |

### **对比分析与深度洞察**

通过上述对比可见，本项目在操作系统的垂直领域具有显著的差异化优势。商业模型如 GPT-4o 虽然拥有更强的通用推理能力，但在面对特定的高校操作系统教材（可能包含特定年份、特定教授编写的实验指南）时，往往无法提供精准的页码级溯源，且存在训练数据泄露导致的旧版知识误用 。与之相比，本系统通过本地 RAG 机制强制将知识源锁定在指定的 PDF 文档中，确保了教学内容的权威性与实时性 。

在源码检索方面，Gemini 1.5 Pro 的 1000 万 token 上下文窗口虽然理论上可以容纳整个 Linux 内核，但研究表明，长上下文模型在面对复杂查询时，召回率往往随内容增长而剧烈衰减（Lost in the Middle 现象），且推理成本极高 。本系统采用的两阶段检索策略，通过“先粗筛文件，后精排语义块”的方式，模拟了人类架构师阅读源码的逻辑，不仅检索响应速度更快（秒级），且能通过代码块描述索引精确锁定函数级逻辑，有效规避了暴力扫描的低效问题 。

此外，在教学判题维度，传统的 AI 辅助判题往往仅给出最终得分，缺乏对过程的“分数置信度”评估 。本系统引入的 `confidence` 字段能够提示教师该判分结果是否可能存在争议，从而辅助教师进行人工复核，这种“人机协同”的设计思路在目前的商业工具中尚属前沿 。

# **case studying**

## **案例一：教材理论溯源——“分段与分页的深度辨析”**

### **1. Case 内容**

学生提问：“操作系统中，分段机制相比分页机制有哪些本质区别？请根据我们的课程教材给出具体页码和原理对比。”

### **2. 本系统（OS Agent）表现**

- **多轮检索增强**：系统通过 `RetrievalSuggester` 识别意图，将口语化提问改写为“分段分页内存碎片对比”、“分段机制逻辑地址空间”等 5 个专业检索词 [1, 1]。
- **级联过滤与 sufficiency 判断**：执行第一轮向量召回后，`_judge_chunk_relevance()` 剔除无关噪音。若发现资料未覆盖“外部碎片”细节，自动触发第二轮补充检索 [1, 1]。
- **精准页码溯源**：基于 SSE 流式推送，学生能即时看到“正在检索《操作系统导论》第 18 章...”的思考过程 。最终回答不仅详述原理，且在每段结论后精确标注：“参考来源：教材 PDF 第 182 页、195 页图 8.4” 。

![image.png](image.png)

![image.png](image%201.png)

![image.png](image%202.png)

![image.png](image%203.png)

### **3. GPT-4o（商用模型典范）表现**

[https://www.notion.so](https://www.notion.so)

- **幻觉与知识漂移**：GPT-4o 能够生成一段逻辑通顺的通用解释，但由于缺乏对“特定版本”教材的感知，其给出的术语可能与课堂教授不一致 。
- **无法物理溯源**：GPT-4o 无法提供物理教材的页码。当被强制要求提供页码时，极易产生“虚假页码”幻觉 。
- **检索深度受限**：其内置的 File Search 往往采用单层检索，在面对长达数百页的教材 PDF 时，容易在生成过程中丢失中间章节的微小细节 。

![image.png](image%204.png)

![image.png](image%205.png)

---

## **案例二：大规模源码剖析——“Linux 内核进程记账实现”**

### **1. Case 内容**

学生提问：“在 Linux 4.x 内核中，进程退出时的记账信息（struct acct）是如何写入文件的？具体的函数调用链路是什么？”

### **2. 本系统（OS Agent）预期表现**

- **两阶段检索（2-stage Retrieval）效率**：
    - **第一阶段**：在 `kernel_file_summaries` 摘要库中通过向量匹配，秒级从上千个文件中锁定核心文件 `kernel/acct.c` [1, 1]。
    - **第二阶段**：利用 `rank_chunks_by_semantic` 模块，对比问题与该文件内每个函数的自然语言描述。即便代码中没有“记账”中文，BGE-M3 模型也能通过语义理解锁定关键函数 `do_acct_process` [1, 1]。
- **结构化讲解**：SSE 实时推送 `code_description_chunk` 事件，在前端“相关源代码”栏位高亮展示 `encode_comp_t` 函数的起止行号，并解析其对时间信息的压缩逻辑 [1, 1]。

![image.png](image%206.png)

![image.png](image%207.png)

### **3. Gemini 2.5 Pro（极大上下文模型）预期表现**

- **“大海捞针”性能衰减**：Gemini 虽然支持 1000 万 token 上下文，理论上可塞入全量内核源码，但研究显示长上下文模型在面对大规模代码库检索时，召回率随内容增加呈指数级下降（Lost in the Middle 现象），且推理成本极高 。
- **高感知延迟**：处理全量源码的 Prompt 注入需要数十秒甚至分钟级的预处理时间，无法实现本项目 `CodeRAGWorkflow` 的秒级流式响应 。
- **缺乏块级元数据**：Gemini 往往仅能指出文件名，无法像本项目一样精准提取函数级的“起止行号”并关联其离线生成的语义描述索引 。

![image.png](image%208.png)

![image.png](image%209.png)

---

## 案例三：习题智能评测——“地址重定位概念判题”

### 1. Case 内容

**题目**：“什么是地址重定位？它分为哪两种？各是依据什么实现的？试比较它们的优缺点。”

**学生答案**：“地址重定位是把逻辑地址转成物理地址。分为静态和动态。静态是装入时完成的，动态是执行时完成的。优点是方便，缺点是静态重定位后程序不能在内存里移动。”

### 2. 本系统（OS Agent）预期表现

- **教材增强判分**：判题引擎首先检索教材中关于“重定位寄存器”和“软件修改”的具体描述作为裁判依据 。
- **多维度深度反馈（JSON 结构化）**：
    - **分析理由（reasoning）**：指出学生准确回答了类型和时间点，但在“依据什么实现”部分描述空洞，未提及硬件寄存器或软件地址修改逻辑 [1, 1]。
    - **改进建议（ImprovementSuggestions）**：明确提示：“请重点复习教材第 X 节，补充关于‘重定位寄存器（Relocation Register）’在动态重定位中的硬件支撑作用” 。
    - **质量分级**：输出 `answerQuality: "正确"` 及 `confidence: 0.85` 。

![image.png](image%2010.png)

### 3. DeepSeek R1（开源推理模型）预期表现

- **通用逻辑偏移**：DeepSeek R1 虽然有极强的推理链（CoT），但其判分依据是“模型常识”。如果该校教材对“静态重定位”的实现细节有特定要求（如必须提及加载器的具体动作），R1 往往无法识别出学生答案与“课程大纲”的偏离 。
- **反馈闭环缺失**：通用模型通常仅给出“正确/错误”或简单的改写建议，缺乏本系统内置的结构化 `ImprovementSuggestions` 和与特定教材章节绑定的针对性知识点指引 。
- **无法输出确定性置信度**：通用对话模型无法输出针对判题准确性的 `confidence` 字段，教师难以在批改大量习题时筛选出低置信度的争议样本进行人工复核 。

![image.png](image%2011.png)

---

![image.png](image%2012.png)