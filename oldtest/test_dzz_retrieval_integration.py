#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• dzz æ£€ç´¢ç³»ç»Ÿé›†æˆåˆ° CodeRAGWorkflow
éªŒè¯ä¸¤é˜¶æ®µæ£€ç´¢é€»è¾‘æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
from simple_rag_workflow import CodeRAGWorkflow

def test_dzz_retrieval_integration():
    """æµ‹è¯• dzz æ£€ç´¢ç³»ç»Ÿé›†æˆ"""
    
    print("="*60)
    print("ğŸ§ª æµ‹è¯• dzz æ£€ç´¢ç³»ç»Ÿé›†æˆ")
    print("="*60)
    
    # é…ç½®å‚æ•°
    config = {
        "llm_path": "../models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5",
        "embedding_model_path": "/home/ubuntu/.cache/huggingface/hub/models--BAAI--bge-m3/snapshots/5617a9f61b028005a4858fdac845db406aefb181/",
        "db_path": "./vector_db",
        "similarity_threshold": 0.3,
        "chroma_md_path": "./dzz_retrieval/chroma_md",
        "top_files": 3,
        "top_chunks": 5
    }
    
    print("\nğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - LLMè·¯å¾„: {config['llm_path']}")
    print(f"  - åµŒå…¥æ¨¡å‹è·¯å¾„: {config['embedding_model_path']}")
    print(f"  - å‘é‡æ•°æ®åº“è·¯å¾„: {config['db_path']}")
    print(f"  - dzz ChromaDBè·¯å¾„: {config['chroma_md_path']}")
    print(f"  - æ–‡ä»¶çº§æ£€ç´¢æ•°é‡: {config['top_files']}")
    print(f"  - ä»£ç å—çº§æ£€ç´¢æ•°é‡: {config['top_chunks']}")
    
    try:
        # åˆå§‹åŒ–æºç æ£€ç´¢å·¥ä½œæµ
        print("\n" + "="*60)
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æºç æ£€ç´¢å·¥ä½œæµ...")
        print("="*60)
        
        workflow = CodeRAGWorkflow(**config)
        
        print("\n" + "="*60)
        print("âœ… åˆå§‹åŒ–æˆåŠŸ!")
        print("="*60)
        
        # æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
        test_queries = [
            "Linux å¦‚ä½•å®ç°è¿›ç¨‹è®°è´¦",
            "æ–‡ä»¶ç³»ç»Ÿç›¸å…³çš„ä»£ç ",
            "å†…å­˜ç®¡ç†å‡½æ•°çš„å®ç°",
            "è¿›ç¨‹è°ƒåº¦ç›¸å…³çš„ä»£ç "
        ]
        
        print("\n" + "="*60)
        print("ğŸ“ å¼€å§‹æµ‹è¯•æŸ¥è¯¢...")
        print("="*60)
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n{'='*60}")
            print(f"æµ‹è¯• {i}/{len(test_queries)}: {query}")
            print(f"{'='*60}")
            
            try:
                # å¤„ç†æºç æŸ¥è¯¢
                response = workflow.process_code_query(query)
                
                # æ˜¾ç¤ºç»“æœæ‘˜è¦
                print(f"\nğŸ“Š ç»“æœæ‘˜è¦:")
                print(f"  - æ£€ç´¢å»ºè®®æ•°é‡: {len(response.retrieval_suggestion.suggested_queries) if response.retrieval_suggestion else 0}")
                print(f"  - æ£€ç´¢åˆ°çš„ä»£ç ç‰‡æ®µæ•°: {len(response.retrieved_chunks)}")
                print(f"  - ä»£ç æè¿°é•¿åº¦: {len(response.llm_response)} å­—ç¬¦")
                
                # æ˜¾ç¤ºæ£€ç´¢å»ºè®®è¯¦æƒ…
                if response.retrieval_suggestion:
                    print(f"\nğŸ” æ£€ç´¢å»ºè®®è¯¦æƒ…:")
                    print(f"  - æ„å›¾: {response.retrieval_suggestion.intent}")
                    print(f"  - ç½®ä¿¡åº¦: {response.retrieval_suggestion.confidence:.2f}")
                    print(f"  - å…³é”®è¯: {', '.join(response.retrieval_suggestion.search_keywords[:5])}")
                    print(f"  - å»ºè®®æŸ¥è¯¢: {response.retrieval_suggestion.suggested_queries[:3]}")
                
                # æ˜¾ç¤ºæ£€ç´¢åˆ°çš„ä»£ç ç‰‡æ®µè¯¦æƒ…
                if response.retrieved_chunks:
                    print(f"\nğŸ’» æ£€ç´¢åˆ°çš„ä»£ç ç‰‡æ®µè¯¦æƒ…:")
                    for j, chunk in enumerate(response.retrieved_chunks[:5], 1):
                        print(f"\n  ç‰‡æ®µ {j}:")
                        print(f"    - æ–‡ä»¶å: {chunk.filename}")
                        print(f"    - æ–‡ä»¶è·¯å¾„: {chunk.metadata.get('file_path', 'N/A')}")
                        print(f"    - è¡Œå·èŒƒå›´: {chunk.metadata.get('line_range', 'N/A')}")
                        print(f"    - å‡½æ•°å: {chunk.metadata.get('function_name', 'N/A')}")
                        print(f"    - ç›¸ä¼¼åº¦: {chunk.score:.4f}")
                        print(f"    - æè¿°: {chunk.metadata.get('description', 'N/A')[:100]}...")
                        print(f"    - å†…å®¹é¢„è§ˆ: {chunk.content[:150] if chunk.content else 'N/A'}...")
                else:
                    print("\nâš ï¸  æœªæ£€ç´¢åˆ°ç›¸å…³ä»£ç ç‰‡æ®µ")
                
                # æ˜¾ç¤ºLLMç”Ÿæˆçš„æè¿°ï¼ˆå‰300å­—ç¬¦ï¼‰
                if response.llm_response:
                    print(f"\nğŸ¤– LLMç”Ÿæˆçš„ä»£ç æè¿°ï¼ˆé¢„è§ˆï¼‰:")
                    print(f"  {response.llm_response[:300]}...")
                
                print(f"\nâœ… æµ‹è¯• {i} å®Œæˆ")
                
            except Exception as e:
                print(f"\nâŒ æµ‹è¯• {i} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("="*60)
        
        # æµ‹è¯•å¯¹è¯å†å²
        print("\nğŸ“ æµ‹è¯•å¯¹è¯å†å²åŠŸèƒ½...")
        history = workflow.conversation_manager.get_history()
        print(f"  - å¯¹è¯æ¶ˆæ¯æ•°: {len(history)}")
        if history:
            print(f"  - æœ€åä¸€æ¡æ¶ˆæ¯: {history[-1].role} - {history[-1].content[:50]}...")
        
        # æ¸…ç©ºå¯¹è¯å†å²
        print("\nğŸ§¹ æ¸…ç©ºå¯¹è¯å†å²...")
        workflow.clear_conversation()
        print("  âœ… å¯¹è¯å†å²å·²æ¸…ç©º")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_single_query():
    """æµ‹è¯•å•ä¸ªæŸ¥è¯¢ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰"""
    
    print("="*60)
    print("ğŸ§ª å¿«é€Ÿæµ‹è¯• - å•ä¸ªæŸ¥è¯¢")
    print("="*60)
    
    config = {
        "llm_path": "../models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5",
        "embedding_model_path": "/home/ubuntu/.cache/huggingface/hub/models--BAAI--bge-m3/snapshots/5617a9f61b028005a4858fdac845db406aefb181/",
        "db_path": "./vector_db",
        "similarity_threshold": 0.3,
        "chroma_md_path": "./dzz_retrieval/chroma_md",
        "top_files": 3,
        "top_chunks": 5
    }
    
    try:
        print("\nğŸ”§ æ­£åœ¨åˆå§‹åŒ–...")
        workflow = CodeRAGWorkflow(**config)
        print("âœ… åˆå§‹åŒ–æˆåŠŸ!\n")
        
        # æµ‹è¯•ä¸€ä¸ªæŸ¥è¯¢
        test_query = "Linux å¦‚ä½•å®ç°è¿›ç¨‹è®°è´¦"
        print(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: {test_query}\n")
        
        response = workflow.process_code_query(test_query)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\n{'='*60}")
        print("ğŸ“Š æ£€ç´¢ç»“æœ:")
        print(f"{'='*60}")
        print(f"æ£€ç´¢åˆ°çš„ä»£ç ç‰‡æ®µæ•°: {len(response.retrieved_chunks)}")
        
        if response.retrieved_chunks:
            print(f"\nå‰3ä¸ªä»£ç ç‰‡æ®µ:")
            for i, chunk in enumerate(response.retrieved_chunks[:3], 1):
                print(f"\n  [{i}] {chunk.filename}")
                print(f"      è·¯å¾„: {chunk.metadata.get('file_path', 'N/A')}")
                print(f"      è¡Œå·: {chunk.metadata.get('line_range', 'N/A')}")
                print(f"      å‡½æ•°: {chunk.metadata.get('function_name', 'N/A')}")
                print(f"      ç›¸ä¼¼åº¦: {chunk.score:.4f}")
                print(f"      æè¿°: {chunk.metadata.get('description', 'N/A')[:80]}...")
        
        print(f"\n{'='*60}")
        print("âœ… æµ‹è¯•å®Œæˆ!")
        print(f"{'='*60}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æµ‹è¯• dzz æ£€ç´¢ç³»ç»Ÿé›†æˆ")
    parser.add_argument(
        "--mode",
        choices=["full", "quick"],
        default="quick",
        help="æµ‹è¯•æ¨¡å¼: full(å®Œæ•´æµ‹è¯•) æˆ– quick(å¿«é€Ÿæµ‹è¯•)"
    )
    
    args = parser.parse_args()
    
    if args.mode == "full":
        success = test_dzz_retrieval_integration()
    else:
        success = test_single_query()
    
    sys.exit(0 if success else 1)

