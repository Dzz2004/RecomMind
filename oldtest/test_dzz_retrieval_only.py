#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• dzz æ£€ç´¢ç³»ç»Ÿé›†æˆï¼ˆä»…æµ‹è¯•æ£€ç´¢éƒ¨åˆ†ï¼Œä¸åŠ è½½LLMï¼‰
"""

import sys
import os

# æµ‹è¯•æ£€ç´¢é€»è¾‘ï¼ˆä¸åŠ è½½LLMï¼‰
def test_retrieval_only():
    """ä»…æµ‹è¯•æ£€ç´¢é€»è¾‘ï¼Œä¸åŠ è½½LLM"""
    
    print("="*60)
    print("ğŸ§ª æµ‹è¯• dzz æ£€ç´¢ç³»ç»Ÿï¼ˆä»…æ£€ç´¢éƒ¨åˆ†ï¼‰")
    print("="*60)
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from simple_rag_workflow import CodeRetrievalSuggester, RetrievalSuggestion, ConversationMessage
        from datetime import datetime
        import chromadb
        from chromadb.utils import embedding_functions
        import torch
        
        # æµ‹è¯• dzz æ£€ç´¢ç³»ç»Ÿåˆå§‹åŒ–
        print("\n1. æµ‹è¯• dzz æ£€ç´¢ç³»ç»Ÿåˆå§‹åŒ–...")
        chroma_md_path = "./dzz_retrieval/chroma_md"
        embedding_model_path = "/home/ubuntu/.cache/huggingface/hub/models--BAAI--bge-m3/snapshots/5617a9f61b028005a4858fdac845db406aefb181/"
        
        client = chromadb.PersistentClient(path=chroma_md_path)
        embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name=embedding_model_path,
            device="cuda" if torch.cuda.is_available() else "cpu",
            normalize_embeddings=True
        )
        
        collection = client.get_collection(
            name="kernel_file_summaries",
            embedding_function=embedding_fn
        )
        
        file_count = collection.count()
        print(f"   âœ… dzz æ–‡ä»¶æ‘˜è¦é›†åˆåˆå§‹åŒ–æˆåŠŸï¼Œæ€»æ–‡ä»¶æ•°: {file_count}")
        
        # æµ‹è¯•æ–‡ä»¶çº§æ£€ç´¢
        print("\n2. æµ‹è¯•æ–‡ä»¶çº§æ£€ç´¢...")
        test_query = "Linux å¦‚ä½•å®ç°è¿›ç¨‹è®°è´¦"
        
        md_results = collection.query(
            query_texts=[test_query],
            n_results=3,
            include=["documents", "metadatas", "distances"]
        )
        
        candidate_source_files = []
        for doc, meta, dist in zip(
            md_results['documents'][0],
            md_results['metadatas'][0],
            md_results['distances'][0]
        ):
            source_file = meta.get('source_file', '')
            if source_file:
                source_file = os.path.join("kernel", source_file) if not source_file.startswith("kernel/") else source_file
                candidate_source_files.append(source_file)
                similarity = 1 - dist
                print(f"   âœ… æ–‡ä»¶: {os.path.basename(source_file)} (ç›¸ä¼¼åº¦: {similarity:.4f})")
        
        if not candidate_source_files:
            print("   âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡ä»¶")
            return False
        
        # æµ‹è¯•ä»£ç å—çº§æ£€ç´¢
        print(f"\n3. æµ‹è¯•ä»£ç å—çº§è¯­ä¹‰æ’åº...")
        sys.path.insert(0, './dzz_retrieval')
        from rank_chunks_by_semantic import rank_chunks_by_description
        
        all_top_chunks = rank_chunks_by_description(test_query, candidate_source_files, top_k=5)
        
        if not all_top_chunks:
            print("   âŒ æœªæ‰¾åˆ°ç›¸å…³ä»£ç å—")
            return False
        
        print(f"   âœ… æ‰¾åˆ° {len(all_top_chunks)} ä¸ªç›¸å…³ä»£ç å—")
        
        # æ˜¾ç¤ºå‰3ä¸ªä»£ç å—
        print(f"\n4. æ˜¾ç¤ºå‰3ä¸ªä»£ç å—è¯¦æƒ…:")
        for i, chunk in enumerate(all_top_chunks[:3], 1):
            print(f"\n   [{i}] ç›¸ä¼¼åº¦: {chunk.get('_score', 0):.4f}")
            file_path = chunk.get('file_path', 'unknown').replace('\\', '/')
            print(f"       æ–‡ä»¶: {file_path}")
            print(f"       è¡Œå·: {chunk.get('start_line', 'N/A')} - {chunk.get('end_line', 'N/A')}")
            print(f"       å‡½æ•°: {chunk.get('function_name', 'N/A')}")
            print(f"       æè¿°: {chunk.get('description', 'N/A')[:100]}...")
        
        print("\n" + "="*60)
        print("âœ… æ£€ç´¢æµ‹è¯•å®Œæˆï¼")
        print("="*60)
        print("\nğŸ’¡ è¯´æ˜:")
        print("  - æ–‡ä»¶çº§æ£€ç´¢ï¼šâœ… æ­£å¸¸å·¥ä½œ")
        print("  - ä»£ç å—çº§æ£€ç´¢ï¼šâœ… æ­£å¸¸å·¥ä½œ")
        print("  - ä¸¤é˜¶æ®µæ£€ç´¢é€»è¾‘ï¼šâœ… é›†æˆæˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_retrieval_only()
    sys.exit(0 if success else 1)

