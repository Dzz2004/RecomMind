#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGå·¥ä½œæµåç«¯APIæœåŠ¡å™¨
åŸºäºFlaskå®ç°ï¼Œé›†æˆSimpleRAGWorkflow
"""

import os
import json
import logging
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from flask import Flask, request, jsonify, Response, stream_with_context
from flask_cors import CORS
from dataclasses import dataclass, asdict
import traceback
from queue import Queue
from threading import Thread

# å¯¼å…¥RAGå·¥ä½œæµ
from simple_rag_workflow import (
    SimpleRAGWorkflow, 
    CodeRAGWorkflow,
    WorkflowResponse, 
    RetrievedChunk
)

# ==================== é…ç½® ====================

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åº”ç”¨é…ç½®
app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# å…¨å±€RAGå·¥ä½œæµå®ä¾‹
rag_workflow: Optional[SimpleRAGWorkflow] = None
code_rag_workflow: Optional[CodeRAGWorkflow] = None

# ==================== æ•°æ®æ¨¡å‹ ====================

@dataclass
class ChatRequest:
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    userInput: str
    useRag: bool
    useCodeRetrieval: bool = False

@dataclass
class RetrievedDocument:
    """æ£€ç´¢åˆ°çš„æ–‡æ¡£æ¨¡å‹"""
    source: str
    page: int
    content: str
    chapter: Optional[int] = None
    finalPage: Optional[int] = None
    pageRange: Optional[str] = None

@dataclass
class CodeReference:
    """ä»£ç å¼•ç”¨æ¨¡å‹"""
    path: str
    startLine: int
    endLine: int
    description: Optional[str] = None

@dataclass
class ChatResponse:
    """èŠå¤©å“åº”æ¨¡å‹"""
    thought: str
    answer: str
    documents: List[RetrievedDocument]
    codes: List[CodeReference] = None

@dataclass
class ApiResponse:
    """APIå“åº”æ¨¡å‹"""
    code: int
    message: str
    data: Any
    timestamp: str

# ==================== å·¥å…·å‡½æ•° ====================

def init_rag_workflow():
    """åˆå§‹åŒ–RAGå·¥ä½œæµ"""
    global rag_workflow, code_rag_workflow
    
    try:
        logger.info("æ­£åœ¨åˆå§‹åŒ–RAGå·¥ä½œæµ...")
        
        # é…ç½®å‚æ•°
        # use_quantization: True=ä½¿ç”¨4ä½é‡åŒ–ï¼ˆèŠ‚çœæ˜¾å­˜ï¼Œæ¨èï¼‰ï¼ŒFalse=å…¨ç²¾åº¦ï¼ˆæ›´é«˜ç²¾åº¦ï¼Œéœ€è¦æ›´å¤šæ˜¾å­˜ï¼‰
        config = {
            "llm_path": "../models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5",
            "embedding_model_path": "/home/ubuntu/.cache/huggingface/hub/models--BAAI--bge-m3/snapshots/5617a9f61b028005a4858fdac845db406aefb181/",
            "db_path": "./vector_db",
            "similarity_threshold": 0.0,  # æ•™ææ£€ç´¢ä½¿ç”¨0.0é˜ˆå€¼
            "use_quantization": True  # æ˜¯å¦ä½¿ç”¨4ä½é‡åŒ–ï¼ŒTrue=å¼€å¯ï¼ˆé»˜è®¤ï¼‰ï¼ŒFalse=å…³é—­
        }
        
        # ä»£ç æ£€ç´¢é…ç½®ï¼ˆä½¿ç”¨ dzz æ£€ç´¢ç³»ç»Ÿï¼‰
        code_config = {
            "llm_path": config["llm_path"],
            "embedding_model_path": config["embedding_model_path"],
            "db_path": config["db_path"],
            "similarity_threshold": 0.0,  # ä»£ç æ£€ç´¢ä½¿ç”¨0.0é˜ˆå€¼ï¼Œç¡®ä¿èƒ½æ£€ç´¢åˆ°ç»“æœ
            "chroma_md_path": "./dzz_retrieval/chroma_md",  # dzz æ£€ç´¢ç³»ç»Ÿçš„ ChromaDB è·¯å¾„
            "top_files": 3,  # æ–‡ä»¶çº§æ£€ç´¢æ•°é‡
            "top_chunks": 5,  # ä»£ç å—çº§æ£€ç´¢æ•°é‡
            "use_quantization": config["use_quantization"]  # ä½¿ç”¨ç›¸åŒçš„é‡åŒ–é…ç½®
        }
        
        rag_workflow = SimpleRAGWorkflow(**config)
        logger.info("âœ… RAGå·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–æºç æ£€ç´¢å·¥ä½œæµ
        logger.info("æ­£åœ¨åˆå§‹åŒ–æºç æ£€ç´¢å·¥ä½œæµ...")
        code_rag_workflow = CodeRAGWorkflow(**code_config)
        logger.info("âœ… æºç æ£€ç´¢å·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
        
    except Exception as e:
        logger.error(f"âŒ RAGå·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        raise

def convert_retrieved_chunks_to_documents(chunks: List[RetrievedChunk]) -> List[RetrievedDocument]:
    """å°†RetrievedChunkè½¬æ¢ä¸ºRetrievedDocument"""
    documents = []
    
    for chunk in chunks:
        # ä»æ–‡ä»¶åä¸­æå–ç« èŠ‚å·
        chapter = None
        if chunk.filename:
            import re
            match = re.search(r'ch(\d+)\.pdf', chunk.filename)
            if match:
                chapter = int(match.group(1))
        
        # è®¡ç®—æœ€ç»ˆé¡µç ï¼špage_rangeçš„èµ·ç‚¹ + 10
        final_page = None
        page_range = chunk.metadata.get('page_range', '')
        if page_range:
            # è§£æpageRangeï¼Œä¾‹å¦‚ "79-84" æˆ– "79"
            import re
            page_range_match = re.match(r'(\d+)(?:-(\d+))?', page_range)
            if page_range_match:
                start_page = int(page_range_match.group(1))
                final_page = start_page + 10
        
        doc = RetrievedDocument(
            source=chunk.filename or "unknown.pdf",
            page=chunk.metadata.get('page', 1),
            content=chunk.content,
            chapter=chapter,
            finalPage=final_page,
            pageRange=chunk.metadata.get('page_range', '')
        )
        documents.append(doc)
    
    return documents

def convert_code_chunks_to_references(chunks: List[RetrievedChunk]) -> List[CodeReference]:
    """å°†ä»£ç RetrievedChunkè½¬æ¢ä¸ºCodeReference"""
    code_refs = []
    
    for chunk in chunks:
        # è§£æè¡Œå·èŒƒå›´ï¼ˆä¼˜å…ˆä½¿ç”¨ start_line å’Œ end_lineï¼‰
        start_line = chunk.metadata.get('start_line', 1)
        end_line = chunk.metadata.get('end_line', 1)
        
        # å¦‚æœæ²¡æœ‰ start_line/end_lineï¼Œå°è¯•ä» line_range è§£æ
        if start_line == 1 and end_line == 1:
            line_range = chunk.metadata.get('line_range', '')
            if line_range:
                import re
                # è§£æ "10-25" æˆ– "10" æ ¼å¼
                line_match = re.match(r'(\d+)(?:-(\d+))?', line_range)
                if line_match:
                    start_line = int(line_match.group(1))
                    end_line = int(line_match.group(2)) if line_match.group(2) else start_line
        
        # è·å–æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨file_pathï¼Œå¦åˆ™ä½¿ç”¨relative_pathæˆ–filenameï¼‰
        file_path = (
            chunk.metadata.get('file_path') or 
            chunk.relative_path or 
            chunk.filename or 
            'unknown'
        )
        
        # ç”Ÿæˆæè¿°ï¼ˆä¼˜å…ˆä½¿ç”¨ metadata ä¸­çš„ descriptionï¼Œå¦åˆ™ä½¿ç”¨å‡½æ•°åæˆ–ä»£ç ç¬¬ä¸€è¡Œï¼‰
        description = chunk.metadata.get('description', '')
        
        # å¦‚æœ description ä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨å‡½æ•°å
        if not description:
            function_name = chunk.metadata.get('function_name', 'N/A')
            if function_name and function_name != 'N/A':
                description = f"å‡½æ•°: {function_name}"
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æè¿°ï¼Œä½¿ç”¨ä»£ç çš„ç¬¬ä¸€è¡Œ
        if not description and chunk.content:
            first_line = chunk.content.split('\n')[0].strip()
            if first_line and len(first_line) < 100:
                description = first_line
        
        code_ref = CodeReference(
            path=file_path,
            startLine=start_line,
            endLine=end_line,
            description=description
        )
        code_refs.append(code_ref)
    
    return code_refs

def create_api_response(code: int, message: str, data: Any = None) -> Dict[str, Any]:
    """åˆ›å»ºæ ‡å‡†APIå“åº”"""
    return {
        "code": code,
        "message": message,
        "data": data,
        "timestamp": datetime.now().isoformat()
    }

# ==================== APIè·¯ç”± ====================

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    try:
        rag_status = "healthy" if rag_workflow is not None else "unhealthy"
        code_status = "healthy" if code_rag_workflow is not None else "unhealthy"
        
        status = {
            "rag_workflow": rag_status,
            "code_rag_workflow": code_status,
            "overall": "healthy" if (rag_workflow is not None or code_rag_workflow is not None) else "unhealthy"
        }
        
        return jsonify(create_api_response(200, "æœåŠ¡æ­£å¸¸", status))
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return jsonify(create_api_response(500, "æœåŠ¡å¼‚å¸¸", {"error": str(e)}))

@app.route('/api/chat', methods=['POST'])
def chat():
    """èŠå¤©æ¥å£"""
    try:
        # æ£€æŸ¥RAGå·¥ä½œæµæ˜¯å¦å·²åˆå§‹åŒ–
        if rag_workflow is None:
            return jsonify(create_api_response(500, "RAGå·¥ä½œæµæœªåˆå§‹åŒ–"))

        # è§£æè¯·æ±‚æ•°æ®
        request_data = request.get_json()
        if not request_data:
            return jsonify(create_api_response(400, "è¯·æ±‚æ•°æ®ä¸ºç©º"))

        # éªŒè¯è¯·æ±‚å­—æ®µ
        user_input = request_data.get('userInput', '').strip()
        use_rag = request_data.get('useRag', True)
        use_code_retrieval = request_data.get('useCodeRetrieval', False)

        if not user_input:
            return jsonify(create_api_response(400, "ç”¨æˆ·è¾“å…¥ä¸èƒ½ä¸ºç©º"))

        logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚: userInput='{user_input}', useRag={use_rag}, useCodeRetrieval={use_code_retrieval}")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥ä½œæµ
        if not use_rag and not use_code_retrieval:
            # æœªå¯ç”¨RAGå’Œä»£ç æ£€ç´¢æ—¶ä»é€šè¿‡SSEè¿”å›é™æ€å“åº”ï¼Œä¿æŒå‰ç«¯é€»è¾‘ä¸€è‡´
            def non_rag_stream():
                chat_response = ChatResponse(
                    thought=f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚ç”±äºæœªå¯ç”¨RAGå’Œä»£ç æ£€ç´¢ï¼Œæˆ‘å°†åŸºäºæ¨¡å‹çŸ¥è¯†ç›´æ¥å›ç­”ã€‚",
                    answer=f"è¿™æ˜¯å¯¹'{user_input}'çš„å›ç­”ã€‚ç”±äºæœªå¯ç”¨RAGæ£€ç´¢å’Œä»£ç æ£€ç´¢ï¼Œæˆ‘æ— æ³•æä¾›åŸºäºæ–‡æ¡£æˆ–ä»£ç çš„è¯¦ç»†ä¿¡æ¯ã€‚",
                    documents=[],
                    codes=[]
                )
                payload = json.dumps(asdict(chat_response), ensure_ascii=False)
                yield f"data: {payload}\n\n"
                yield "data: [DONE]\n\n"

            return Response(stream_with_context(non_rag_stream()), mimetype='text/event-stream')
        
        # ç¡®å®šä½¿ç”¨å“ªä¸ªå·¥ä½œæµ
        # å¦‚æœåŒæ—¶å¯ç”¨RAGå’Œä»£ç æ£€ç´¢ï¼Œå…ˆæ‰§è¡ŒRAGï¼Œç„¶åæ‰§è¡Œä»£ç æ£€ç´¢å¹¶è¿½åŠ ç»“æœ
        use_code_workflow = use_code_retrieval
        use_textbook_workflow = use_rag
        
        if use_code_workflow and code_rag_workflow is None:
            return jsonify(create_api_response(500, "æºç æ£€ç´¢å·¥ä½œæµæœªåˆå§‹åŒ–"))
        if use_textbook_workflow and rag_workflow is None:
            return jsonify(create_api_response(500, "RAGå·¥ä½œæµæœªåˆå§‹åŒ–"))

        # ä½¿ç”¨é˜Ÿåˆ—æ¡¥æ¥å·¥ä½œæµäº‹ä»¶ä¸SSEè¾“å‡º
        event_queue: "Queue[Dict[str, Any]]" = Queue()
        code_event_queue: "Queue[Dict[str, Any]]" = Queue() if use_code_workflow else None

        def enqueue_event(event: Dict[str, Any]) -> None:
            event_queue.put(event)

        def enqueue_code_event(event: Dict[str, Any]) -> None:
            if code_event_queue:
                code_event_queue.put(event)

        def run_textbook_workflow() -> None:
            """è¿è¡Œæ•™ææ£€ç´¢å·¥ä½œæµ"""
            try:
                response = rag_workflow.process_user_query(
                    user_input,
                    stream_callback=enqueue_event,
                )
                # å·¥ä½œæµå®Œæˆåï¼Œè®°å½•å®Œæ•´ç»“æœåˆ°æ—¥å¿—
                logger.info("="*60)
                logger.info("ğŸ“Š æ•™ææ£€ç´¢å¤„ç†ç»“æœæ‘˜è¦")
                logger.info("="*60)
                logger.info(f"ç”¨æˆ·æŸ¥è¯¢: {response.user_query}")
                logger.info(f"æ£€ç´¢å»ºè®®æ•°é‡: {len(response.retrieval_suggestion.suggested_queries) if response.retrieval_suggestion else 0}")
                logger.info(f"æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µæ•°: {len(response.retrieved_chunks)}")
                logger.info(f"å›ç­”é•¿åº¦: {len(response.llm_response)} å­—ç¬¦")
                
                if response.retrieved_chunks:
                    logger.info("æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µè¯¦æƒ…:")
                    for i, chunk in enumerate(response.retrieved_chunks[:5], 1):
                        logger.info(f"  [{i}] {chunk.filename}")
                        logger.info(f"      ç« èŠ‚: {chunk.metadata.get('section', 'N/A')}")
                        logger.info(f"      é¡µç èŒƒå›´: {chunk.metadata.get('page_range', 'N/A')}")
                        logger.info(f"      ç›¸ä¼¼åº¦: {chunk.score:.4f}")
                        content_preview = chunk.content[:100] + "..." if len(chunk.content) > 100 else chunk.content
                        logger.info(f"      å†…å®¹é¢„è§ˆ: {content_preview}")
                
                logger.info(f"å›ç­”é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
                logger.info(f"{response.llm_response[:500]}...")
                logger.info("="*60)
            except Exception as workflow_error:
                logger.error(f"æ•™ææ£€ç´¢å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {workflow_error}")
                event_queue.put({"type": "error", "message": str(workflow_error)})
            finally:
                event_queue.put({"type": "textbook_done"})

        def run_code_workflow() -> None:
            """è¿è¡Œæºç æ£€ç´¢å·¥ä½œæµï¼ˆåœ¨RAGå®Œæˆåæ‰§è¡Œï¼‰"""
            try:
                response = code_rag_workflow.process_code_query(
                    user_input,
                    stream_callback=enqueue_code_event,
                )
                # å·¥ä½œæµå®Œæˆåï¼Œè®°å½•å®Œæ•´ç»“æœåˆ°æ—¥å¿—
                logger.info("="*60)
                logger.info("ğŸ“Š æºç æŸ¥è¯¢å¤„ç†ç»“æœæ‘˜è¦")
                logger.info("="*60)
                logger.info(f"ç”¨æˆ·æŸ¥è¯¢: {response.user_query}")
                logger.info(f"æ£€ç´¢å»ºè®®æ•°é‡: {len(response.retrieval_suggestion.suggested_queries) if response.retrieval_suggestion else 0}")
                logger.info(f"æ£€ç´¢åˆ°çš„ä»£ç ç‰‡æ®µæ•°: {len(response.retrieved_chunks)}")
                logger.info(f"ç”Ÿæˆå›å¤é•¿åº¦: {len(response.llm_response)} å­—ç¬¦")
                
                if response.retrieved_chunks:
                    logger.info("æ£€ç´¢åˆ°çš„ä»£ç ç‰‡æ®µè¯¦æƒ…:")
                    for i, chunk in enumerate(response.retrieved_chunks[:5], 1):
                        logger.info(f"  [{i}] {chunk.filename}")
                        logger.info(f"      è·¯å¾„: {chunk.metadata.get('file_path', 'N/A')}")
                        logger.info(f"      è¡Œå·: {chunk.metadata.get('line_range', 'N/A')}")
                        logger.info(f"      å‡½æ•°: {chunk.metadata.get('function_name', 'N/A')}")
                        logger.info(f"      ç›¸ä¼¼åº¦: {chunk.score:.4f}")
                
                logger.info(f"ç”Ÿæˆå›å¤é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
                logger.info(f"{response.llm_response[:500]}...")
                logger.info("="*60)
            except Exception as workflow_error:
                logger.error(f"æºç æ£€ç´¢å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {workflow_error}")
                if code_event_queue:
                    code_event_queue.put({"type": "error", "message": str(workflow_error)})
            finally:
                if code_event_queue:
                    code_event_queue.put({"type": "code_done"})

        # å¯åŠ¨å·¥ä½œæµçº¿ç¨‹
        # å¦‚æœåŒæ—¶å¯ç”¨ï¼Œå…ˆå¯åŠ¨RAGå·¥ä½œæµ
        if use_textbook_workflow:
            Thread(target=run_textbook_workflow, daemon=True).start()
        
        # å¦‚æœåªå¯ç”¨ä»£ç æ£€ç´¢ï¼ˆæ²¡æœ‰RAGï¼‰ï¼Œç›´æ¥å¯åŠ¨ä»£ç æ£€ç´¢
        if use_code_workflow and not use_textbook_workflow:
            Thread(target=run_code_workflow, daemon=True).start()
        
        # å¦‚æœä¸¤ä¸ªéƒ½æœªå¯ç”¨ï¼Œç›´æ¥è¿”å›
        if not use_textbook_workflow and not use_code_workflow:
            event_queue.put({"type": "done"})

        @stream_with_context
        def event_stream():
            try:
                textbook_done = False
                code_done = False
                code_chunks_received = False
                documents_received = []
                code_references_received = []
                thought_sent = False
                code_workflow_started = False
                answer_started = False  # è·Ÿè¸ªæ˜¯å¦å·²å¼€å§‹ç”Ÿæˆå›ç­”
                code_answer_started = False  # è·Ÿè¸ªæ˜¯å¦å·²å¼€å§‹ç”Ÿæˆä»£ç å›ç­”
                last_heartbeat = time.time()
                heartbeat_interval = 15  # æ¯15ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
                
                while True:
                    # å¿ƒè·³æœºåˆ¶ï¼šå®šæœŸå‘é€ç©ºæ•°æ®ä¿æŒè¿æ¥
                    current_time = time.time()
                    if current_time - last_heartbeat > heartbeat_interval:
                        try:
                            # å‘é€å¿ƒè·³ï¼ˆç©ºæ³¨é‡Šï¼ŒSSEè§„èŒƒå…è®¸ï¼‰
                            yield ": heartbeat\n\n"
                            last_heartbeat = current_time
                        except (BrokenPipeError, ConnectionError, OSError, GeneratorExit):
                            logger.info("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼ˆå¿ƒè·³æ£€æµ‹ï¼‰")
                            return
                    # å¤„ç†æ•™ææ£€ç´¢äº‹ä»¶ï¼ˆä¼˜å…ˆå¤„ç†ï¼‰
                    if use_textbook_workflow and not textbook_done:
                        try:
                            event = event_queue.get(timeout=0.1)
                            event_type = event.get("type")

                            if event_type == "retrieval":
                                chunks: List[RetrievedChunk] = event.get("retrieved_chunks", []) or []
                                round_num = event.get("round", 1)  # è·å–æ£€ç´¢è½®æ¬¡
                                documents = convert_retrieved_chunks_to_documents(chunks)
                                
                                # ç´¯ç§¯å¤šè½®æ£€ç´¢çš„ç»“æœï¼ˆå»é‡ï¼‰
                                seen_content = {doc.content for doc in documents_received}
                                new_documents = [doc for doc in documents if doc.content not in seen_content]
                                
                                # åœ¨extendä¹‹å‰è®°å½•ç¬¬ä¸€è½®çš„æ–‡æ¡£æ•°é‡ï¼ˆç”¨äºç¬¬äºŒè½®æ˜¾ç¤ºï¼‰
                                round1_count = len(documents_received) if round_num == 2 else 0
                                
                                documents_received.extend(new_documents)
                                
                                # æ„å»ºthoughtæ–‡æœ¬
                                if round_num == 1:
                                    thought_text = f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚æˆ‘é€šè¿‡ç¬¬ä¸€è½®RAGæ£€ç´¢åˆ°äº†{len(chunks)}ä¸ªæ–‡æ¡£ç‰‡æ®µï¼Œæ­£åœ¨åˆ¤æ–­å®ƒä»¬æ˜¯å¦ä¸é—®é¢˜ç›¸å…³..."
                                else:
                                    # ç¬¬äºŒè½®æ£€ç´¢æ—¶ï¼Œæ›´æ–°thoughtä¿¡æ¯ï¼ŒåŒ…å«ç¬¬ä¸€è½®çš„ç»“æœ
                                    thought_text = f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚ç¬¬ä¸€è½®æ£€ç´¢åˆ°{round1_count}ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µï¼Œä½†å†…å®¹ä¸è¶³ã€‚æˆ‘é€šè¿‡ç¬¬äºŒè½®RAGæ£€ç´¢åˆ°äº†{len(new_documents)}ä¸ªæ–°çš„æ–‡æ¡£ç‰‡æ®µï¼Œæ­£åœ¨åˆ¤æ–­å®ƒä»¬æ˜¯å¦ä¸é—®é¢˜ç›¸å…³..."
                                
                                payload = {
                                    "documents": [asdict(doc) for doc in documents_received],  # å‘é€ç´¯ç§¯çš„æ‰€æœ‰æ–‡æ¡£
                                    "thought": thought_text  # å§‹ç»ˆå‘é€thoughtå­—æ®µï¼Œå‰ç«¯ä¼šæ›´æ–°æ˜¾ç¤º
                                }
                                thought_sent = True  # æ ‡è®°å·²å‘é€thought
                                yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"

                            elif event_type == "answer_chunk":
                                chunk_text = event.get("chunk", "")
                                if chunk_text:
                                    try:
                                        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªanswer_chunkï¼Œæ›´æ–°thoughtä¿¡æ¯
                                        if not answer_started:
                                            answer_started = True
                                            total_relevant = len(documents_received)
                                            thought_update = f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚å·²ç­›é€‰å‡º{total_relevant}ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µï¼Œæ­£åœ¨åŸºäºè¿™äº›å†…å®¹ç”Ÿæˆå›ç­”..."
                                            payload = {"thought": thought_update, "answer_chunk": chunk_text}
                                        else:
                                            payload = {"answer_chunk": chunk_text}
                                        yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                                    except (BrokenPipeError, ConnectionError, OSError):
                                        # å®¢æˆ·ç«¯æ–­å¼€ï¼Œåœæ­¢å‘é€
                                        logger.info("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œåœæ­¢å‘é€å›ç­”ç‰‡æ®µ")
                                        return

                            elif event_type == "error":
                                error_payload = {"error": event.get("message", "å‘ç”ŸæœªçŸ¥é”™è¯¯")}
                                yield f"data: {json.dumps(error_payload, ensure_ascii=False)}\n\n"

                            elif event_type == "textbook_done":
                                textbook_done = True
                                # RAGå®Œæˆåï¼Œå¦‚æœå¯ç”¨äº†ä»£ç æ£€ç´¢ï¼Œç°åœ¨å¯åŠ¨ä»£ç æ£€ç´¢å·¥ä½œæµ
                                if use_code_workflow and not code_workflow_started:
                                    logger.info("RAGå·¥ä½œæµå®Œæˆï¼Œå¼€å§‹å¯åŠ¨ä»£ç æ£€ç´¢å·¥ä½œæµ...")
                                    Thread(target=run_code_workflow, daemon=True).start()
                                    code_workflow_started = True

                        except:
                            pass  # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­
                    
                    # å¤„ç†ä»£ç æ£€ç´¢äº‹ä»¶ï¼ˆåœ¨RAGå®Œæˆåæˆ–å•ç‹¬æ‰§è¡Œï¼‰
                    if use_code_workflow and code_event_queue and not code_done:
                        try:
                            code_event = code_event_queue.get(timeout=0.1)
                            code_event_type = code_event.get("type")

                            if code_event_type == "code_retrieval":
                                code_chunks: List[RetrievedChunk] = code_event.get("retrieved_chunks", []) or []
                                round_num = code_event.get("round", 1)  # è·å–æ£€ç´¢è½®æ¬¡
                                code_refs = convert_code_chunks_to_references(code_chunks)
                                
                                # ç´¯ç§¯å¤šè½®æ£€ç´¢çš„ç»“æœï¼ˆå»é‡ï¼‰
                                seen_paths = {(ref.path, ref.startLine, ref.endLine) for ref in code_references_received}
                                new_code_refs = [
                                    ref for ref in code_refs 
                                    if (ref.path, ref.startLine, ref.endLine) not in seen_paths
                                ]
                                code_references_received.extend(new_code_refs)
                                code_chunks_received = True
                                
                                # æ„å»ºthoughtæ–‡æœ¬
                                if round_num == 1:
                                    thought_text = f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚æˆ‘é€šè¿‡ç¬¬ä¸€è½®æºç æ£€ç´¢æ‰¾åˆ°äº†{len(code_chunks)}ä¸ªä»£ç ç‰‡æ®µï¼Œæ­£åœ¨åˆ¤æ–­è¿™äº›å†…å®¹æ˜¯å¦è¶³ä»¥å›ç­”é—®é¢˜..."
                                else:
                                    # ç¬¬äºŒè½®æ£€ç´¢æ—¶ï¼Œæ›´æ–°thoughtä¿¡æ¯
                                    round1_count = len(code_references_received) - len(new_code_refs)
                                    thought_text = f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚ç¬¬ä¸€è½®æ£€ç´¢åˆ°{round1_count}ä¸ªä»£ç ç‰‡æ®µï¼Œä½†å†…å®¹ä¸è¶³ã€‚æˆ‘é€šè¿‡ç¬¬äºŒè½®æºç æ£€ç´¢æ‰¾åˆ°äº†{len(new_code_refs)}ä¸ªæ–°çš„ä»£ç ç‰‡æ®µï¼Œæ­£åœ¨åŸºäºè¿™äº›ä»£ç å†…å®¹ç”Ÿæˆæ™ºèƒ½å›å¤..."
                                
                                # å‘é€ä»£ç å¼•ç”¨
                                payload = {
                                    "codes": [asdict(ref) for ref in code_references_received],  # å‘é€ç´¯ç§¯çš„æ‰€æœ‰ä»£ç å¼•ç”¨
                                    "thought": thought_text  # å§‹ç»ˆå‘é€thoughtå­—æ®µï¼Œå‰ç«¯ä¼šæ›´æ–°æ˜¾ç¤º
                                }
                                
                                # å¦‚æœåŒæ—¶å¯ç”¨äº†RAGï¼Œè¿½åŠ åˆ†éš”æ–‡æœ¬
                                if use_textbook_workflow:
                                    separator = "\n\n---\n\n### ç›¸å…³æºä»£ç \n\n"
                                    payload_separator = {"answer_chunk": separator}
                                    yield f"data: {json.dumps(payload_separator, ensure_ascii=False)}\n\n"
                                
                                yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                                thought_sent = True  # æ ‡è®°å·²å‘é€thought

                            elif code_event_type == "code_description_chunk":
                                chunk_text = code_event.get("chunk", "")
                                if chunk_text:
                                    try:
                                        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªcode_description_chunkï¼Œæ›´æ–°thoughtä¿¡æ¯
                                        if not code_answer_started:
                                            code_answer_started = True
                                            total_code_refs = len(code_references_received)
                                            thought_update = f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚å·²æ£€ç´¢åˆ°{total_code_refs}ä¸ªç›¸å…³ä»£ç ç‰‡æ®µï¼Œæ­£åœ¨åŸºäºè¿™äº›ä»£ç å†…å®¹ç”Ÿæˆæ™ºèƒ½å›å¤..."
                                            payload = {"thought": thought_update, "answer_chunk": chunk_text}
                                        else:
                                            payload = {"answer_chunk": chunk_text}
                                        yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                                    except (BrokenPipeError, ConnectionError, OSError):
                                        # å®¢æˆ·ç«¯æ–­å¼€ï¼Œåœæ­¢å‘é€
                                        logger.info("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œåœæ­¢å‘é€ä»£ç æè¿°")
                                        return

                            elif code_event_type == "error":
                                error_payload = {"error": code_event.get("message", "å‘ç”ŸæœªçŸ¥é”™è¯¯")}
                                yield f"data: {json.dumps(error_payload, ensure_ascii=False)}\n\n"

                            elif code_event_type == "code_done":
                                code_done = True

                        except:
                            pass  # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­
                    
                    # æ£€æŸ¥æ˜¯å¦éƒ½å®Œæˆäº†
                    textbook_finished = not use_textbook_workflow or textbook_done
                    code_finished = not use_code_workflow or code_done
                    
                    if textbook_finished and code_finished:
                        # å‘é€æœ€ç»ˆçš„ä»£ç å¼•ç”¨ï¼ˆå¦‚æœä¹‹å‰æ²¡æœ‰å‘é€ï¼‰
                        if use_code_workflow and code_references_received and not code_chunks_received:
                            payload = {
                                "codes": [asdict(ref) for ref in code_references_received],
                            }
                            yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                        
                        yield "data: [DONE]\n\n"
                        break

            except GeneratorExit:
                # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£å¸¸é€€å‡º
                logger.info("å®¢æˆ·ç«¯å…³é—­äº†SSEè¿æ¥")
                return
            except BrokenPipeError:
                # ç®¡é“æ–­å¼€ï¼Œæ­£å¸¸é€€å‡º
                logger.info("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼ˆBrokenPipeï¼‰")
                return
            except Exception as stream_error:
                logger.error(f"SSEæµå¤„ç†å¤±è´¥: {stream_error}")
                try:
                    error_payload = {"error": str(stream_error)}
                    yield f"data: {json.dumps(error_payload, ensure_ascii=False)}\n\n"
                    yield "data: [DONE]\n\n"
                except (GeneratorExit, BrokenPipeError):
                    # å¦‚æœå®¢æˆ·ç«¯å·²æ–­å¼€ï¼Œç›´æ¥è¿”å›
                    return

        return Response(event_stream(), mimetype='text/event-stream')

    except Exception as e:
        logger.error(f"èŠå¤©å¤„ç†å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify(create_api_response(500, "èŠå¤©å¤„ç†å¤±è´¥", {"error": str(e)}))

@app.route('/api/conversation/clear', methods=['POST'])
def clear_conversation():
    """æ¸…ç©ºå¯¹è¯å†å²ï¼ˆåŒæ—¶æ¸…ç©ºæ•™æå’Œæºç æ£€ç´¢çš„å¯¹è¯å†å²ï¼‰"""
    try:
        cleared = []
        
        if rag_workflow is not None:
            rag_workflow.clear_conversation()
            cleared.append("æ•™ææ£€ç´¢")
        
        if code_rag_workflow is not None:
            code_rag_workflow.clear_conversation()
            cleared.append("æºç æ£€ç´¢")
        
        if not cleared:
            return jsonify(create_api_response(500, "æ²¡æœ‰å¯æ¸…ç©ºçš„å¯¹è¯å†å²"))
        
        logger.info(f"å¯¹è¯å†å²å·²æ¸…ç©º: {', '.join(cleared)}")
        
        return jsonify(create_api_response(200, "å¯¹è¯å†å²æ¸…ç©ºæˆåŠŸ", {"cleared": cleared}))
        
    except Exception as e:
        logger.error(f"æ¸…ç©ºå¯¹è¯å†å²å¤±è´¥: {e}")
        return jsonify(create_api_response(500, "æ¸…ç©ºå¯¹è¯å†å²å¤±è´¥", {"error": str(e)}))

@app.route('/api/conversation/summary', methods=['GET'])
def get_conversation_summary():
    """è·å–å¯¹è¯æ‘˜è¦"""
    try:
        if rag_workflow is None:
            return jsonify(create_api_response(500, "RAGå·¥ä½œæµæœªåˆå§‹åŒ–"))
        
        summary = rag_workflow.get_conversation_summary()
        
        return jsonify(create_api_response(200, "è·å–å¯¹è¯æ‘˜è¦æˆåŠŸ", {"summary": summary}))
        
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯æ‘˜è¦å¤±è´¥: {e}")
        return jsonify(create_api_response(500, "è·å–å¯¹è¯æ‘˜è¦å¤±è´¥", {"error": str(e)}))

@app.route('/api/config/similarity-threshold', methods=['POST'])
def update_similarity_threshold():
    """æ›´æ–°ç›¸ä¼¼åº¦é˜ˆå€¼"""
    try:
        if rag_workflow is None:
            return jsonify(create_api_response(500, "RAGå·¥ä½œæµæœªåˆå§‹åŒ–"))
        
        request_data = request.get_json()
        if not request_data or 'threshold' not in request_data:
            return jsonify(create_api_response(400, "ç¼ºå°‘thresholdå‚æ•°"))
        
        threshold = float(request_data['threshold'])
        if not (0.0 <= threshold <= 1.0):
            return jsonify(create_api_response(400, "é˜ˆå€¼å¿…é¡»åœ¨0.0åˆ°1.0ä¹‹é—´"))
        
        # æ›´æ–°é˜ˆå€¼
        rag_workflow.similarity_threshold = threshold
        rag_workflow.rag_engine.similarity_threshold = threshold
        
        logger.info(f"ç›¸ä¼¼åº¦é˜ˆå€¼å·²æ›´æ–°ä¸º: {threshold}")
        
        return jsonify(create_api_response(200, "ç›¸ä¼¼åº¦é˜ˆå€¼æ›´æ–°æˆåŠŸ", {"threshold": threshold}))
        
    except Exception as e:
        logger.error(f"æ›´æ–°ç›¸ä¼¼åº¦é˜ˆå€¼å¤±è´¥: {e}")
        return jsonify(create_api_response(500, "æ›´æ–°ç›¸ä¼¼åº¦é˜ˆå€¼å¤±è´¥", {"error": str(e)}))

@app.route('/api/rag/info', methods=['GET'])
def get_rag_info():
    """è·å–RAGç³»ç»Ÿä¿¡æ¯"""
    try:
        if rag_workflow is None:
            return jsonify(create_api_response(500, "RAGå·¥ä½œæµæœªåˆå§‹åŒ–"))
        
        # è·å–é›†åˆä¿¡æ¯
        collection_info = rag_workflow.rag_engine.get_collection_info()
        
        info = {
            "collection_info": collection_info,
            "similarity_threshold": rag_workflow.similarity_threshold,
            "conversation_count": len(rag_workflow.conversation_manager.conversations),
            "llm_path": rag_workflow.llm_path,
            "embedding_model_path": rag_workflow.rag_engine.embedding_model_path
        }
        
        return jsonify(create_api_response(200, "è·å–RAGä¿¡æ¯æˆåŠŸ", info))
        
    except Exception as e:
        logger.error(f"è·å–RAGä¿¡æ¯å¤±è´¥: {e}")
        return jsonify(create_api_response(500, "è·å–RAGä¿¡æ¯å¤±è´¥", {"error": str(e)}))

@app.route('/api/code/info', methods=['GET'])
def get_code_rag_info():
    """è·å–æºç æ£€ç´¢ç³»ç»Ÿä¿¡æ¯"""
    try:
        if code_rag_workflow is None:
            return jsonify(create_api_response(500, "æºç æ£€ç´¢å·¥ä½œæµæœªåˆå§‹åŒ–"))
        
        # è·å– dzz é›†åˆä¿¡æ¯
        dzz_collection_info = code_rag_workflow.dzz_collections_info if hasattr(code_rag_workflow, 'dzz_collections_info') else {'info': 'æœªçŸ¥'}
        
        # è·å–æºç RAGå¼•æ“ä¿¡æ¯
        code_rag_engine_info = code_rag_workflow.code_rag_engine.get_collection_info()
        
        info = {
            "code_rag_engine": code_rag_engine_info,
            "dzz_collection": dzz_collection_info,
            "similarity_threshold": code_rag_workflow.similarity_threshold,
            "conversation_count": len(code_rag_workflow.conversation_manager.conversations),
            "llm_path": code_rag_workflow.llm_path,
            "chroma_md_path": code_rag_workflow.chroma_md_path,
            "top_files": code_rag_workflow.top_files,
            "top_chunks": code_rag_workflow.top_chunks
        }
        
        return jsonify(create_api_response(200, "è·å–æºç æ£€ç´¢ä¿¡æ¯æˆåŠŸ", info))
        
    except Exception as e:
        logger.error(f"è·å–æºç æ£€ç´¢ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify(create_api_response(500, "è·å–æºç æ£€ç´¢ä¿¡æ¯å¤±è´¥", {"error": str(e)}))

@app.route('/api/code/query', methods=['POST'])
def code_query():
    """æºç æ£€ç´¢ä¸“ç”¨æ¥å£ï¼ˆä»…æºç æ£€ç´¢ï¼Œä¸åŒ…å«æ•™ææ£€ç´¢ï¼‰"""
    try:
        if code_rag_workflow is None:
            return jsonify(create_api_response(500, "æºç æ£€ç´¢å·¥ä½œæµæœªåˆå§‹åŒ–"))
        
        # è§£æè¯·æ±‚æ•°æ®
        request_data = request.get_json()
        if not request_data:
            return jsonify(create_api_response(400, "è¯·æ±‚æ•°æ®ä¸ºç©º"))
        
        # éªŒè¯è¯·æ±‚å­—æ®µ
        user_input = request_data.get('userInput', '').strip()
        if not user_input:
            return jsonify(create_api_response(400, "ç”¨æˆ·è¾“å…¥ä¸èƒ½ä¸ºç©º"))
        
        logger.info(f"æ”¶åˆ°æºç æ£€ç´¢è¯·æ±‚: userInput='{user_input}'")
        
        # ä½¿ç”¨é˜Ÿåˆ—æ¡¥æ¥å·¥ä½œæµäº‹ä»¶ä¸SSEè¾“å‡º
        event_queue: "Queue[Dict[str, Any]]" = Queue()
        
        def enqueue_event(event: Dict[str, Any]) -> None:
            event_queue.put(event)
        
        def run_code_workflow() -> None:
            """è¿è¡Œæºç æ£€ç´¢å·¥ä½œæµ"""
            try:
                response = code_rag_workflow.process_code_query(
                    user_input,
                    stream_callback=enqueue_event,
                )
                # å·¥ä½œæµå®Œæˆåï¼Œè®°å½•å®Œæ•´ç»“æœåˆ°æ—¥å¿—
                logger.info("="*60)
                logger.info("ğŸ“Š æºç æŸ¥è¯¢å¤„ç†ç»“æœæ‘˜è¦")
                logger.info("="*60)
                logger.info(f"ç”¨æˆ·æŸ¥è¯¢: {response.user_query}")
                logger.info(f"æ£€ç´¢å»ºè®®æ•°é‡: {len(response.retrieval_suggestion.suggested_queries) if response.retrieval_suggestion else 0}")
                logger.info(f"æ£€ç´¢åˆ°çš„ä»£ç ç‰‡æ®µæ•°: {len(response.retrieved_chunks)}")
                logger.info(f"ç”Ÿæˆå›å¤é•¿åº¦: {len(response.llm_response)} å­—ç¬¦")
                
                if response.retrieved_chunks:
                    logger.info("æ£€ç´¢åˆ°çš„ä»£ç ç‰‡æ®µè¯¦æƒ…:")
                    for i, chunk in enumerate(response.retrieved_chunks[:5], 1):
                        logger.info(f"  [{i}] {chunk.filename}")
                        logger.info(f"      è·¯å¾„: {chunk.metadata.get('file_path', 'N/A')}")
                        logger.info(f"      è¡Œå·: {chunk.metadata.get('line_range', 'N/A')}")
                        logger.info(f"      å‡½æ•°: {chunk.metadata.get('function_name', 'N/A')}")
                        logger.info(f"      ç›¸ä¼¼åº¦: {chunk.score:.4f}")
                
                logger.info(f"ç”Ÿæˆå›å¤é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
                logger.info(f"{response.llm_response[:500]}...")
                logger.info("="*60)
            except Exception as workflow_error:
                logger.error(f"æºç æ£€ç´¢å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {workflow_error}")
                event_queue.put({"type": "error", "message": str(workflow_error)})
            finally:
                event_queue.put({"type": "done"})
        
        # å¯åŠ¨å·¥ä½œæµçº¿ç¨‹
        Thread(target=run_code_workflow, daemon=True).start()
        
        @stream_with_context
        def event_stream():
            try:
                code_references_received = []
                thought_sent = False
                code_answer_started = False
                
                while True:
                    try:
                        event = event_queue.get(timeout=0.1)
                        event_type = event.get("type")
                        
                        if event_type == "code_retrieval":
                            code_chunks: List[RetrievedChunk] = event.get("retrieved_chunks", []) or []
                            round_num = event.get("round", 1)  # è·å–æ£€ç´¢è½®æ¬¡
                            code_refs = convert_code_chunks_to_references(code_chunks)
                            
                            # ç´¯ç§¯å¤šè½®æ£€ç´¢çš„ç»“æœï¼ˆå»é‡ï¼‰
                            seen_paths = {(ref.path, ref.startLine, ref.endLine) for ref in code_references_received}
                            new_code_refs = [
                                ref for ref in code_refs 
                                if (ref.path, ref.startLine, ref.endLine) not in seen_paths
                            ]
                            code_references_received.extend(new_code_refs)
                            
                            # æ„å»ºthoughtæ–‡æœ¬
                            if round_num == 1:
                                thought_text = f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚æˆ‘é€šè¿‡ç¬¬ä¸€è½®æºç æ£€ç´¢æ‰¾åˆ°äº†{len(code_chunks)}ä¸ªä»£ç ç‰‡æ®µï¼Œæ­£åœ¨åˆ¤æ–­è¿™äº›å†…å®¹æ˜¯å¦è¶³ä»¥å›ç­”é—®é¢˜..."
                            else:
                                # ç¬¬äºŒè½®æ£€ç´¢æ—¶ï¼Œæ›´æ–°thoughtä¿¡æ¯
                                round1_count = len(code_references_received) - len(new_code_refs)
                                thought_text = f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚ç¬¬ä¸€è½®æ£€ç´¢åˆ°{round1_count}ä¸ªä»£ç ç‰‡æ®µï¼Œä½†å†…å®¹ä¸è¶³ã€‚æˆ‘é€šè¿‡ç¬¬äºŒè½®æºç æ£€ç´¢æ‰¾åˆ°äº†{len(new_code_refs)}ä¸ªæ–°çš„ä»£ç ç‰‡æ®µï¼Œæ­£åœ¨åŸºäºè¿™äº›ä»£ç å†…å®¹ç”Ÿæˆæ™ºèƒ½å›å¤..."
                            
                            # å‘é€ä»£ç å¼•ç”¨
                            payload = {
                                "codes": [asdict(ref) for ref in code_references_received],  # å‘é€ç´¯ç§¯çš„æ‰€æœ‰ä»£ç å¼•ç”¨
                                "thought": thought_text  # å§‹ç»ˆå‘é€thoughtå­—æ®µï¼Œå‰ç«¯ä¼šæ›´æ–°æ˜¾ç¤º
                            }
                            thought_sent = True  # æ ‡è®°å·²å‘é€thought
                            yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                        
                        elif event_type == "code_description_chunk":
                            chunk_text = event.get("chunk", "")
                            if chunk_text:
                                try:
                                    # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªcode_description_chunkï¼Œæ›´æ–°thoughtä¿¡æ¯
                                    if not code_answer_started:
                                        code_answer_started = True
                                        total_code_refs = len(code_references_received)
                                        thought_update = f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚å·²æ£€ç´¢åˆ°{total_code_refs}ä¸ªç›¸å…³ä»£ç ç‰‡æ®µï¼Œæ­£åœ¨åŸºäºè¿™äº›ä»£ç å†…å®¹ç”Ÿæˆæ™ºèƒ½å›å¤..."
                                        payload = {"thought": thought_update, "answer_chunk": chunk_text}
                                    else:
                                        payload = {"answer_chunk": chunk_text}
                                    yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                                except (BrokenPipeError, ConnectionError, OSError):
                                    # å®¢æˆ·ç«¯æ–­å¼€ï¼Œåœæ­¢å‘é€
                                    logger.info("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œåœæ­¢å‘é€ä»£ç æè¿°")
                                    return
                        
                        elif event_type == "error":
                            error_payload = {"error": event.get("message", "å‘ç”ŸæœªçŸ¥é”™è¯¯")}
                            yield f"data: {json.dumps(error_payload, ensure_ascii=False)}\n\n"
                        
                        elif event_type == "done":
                            # å‘é€æœ€ç»ˆçš„ä»£ç å¼•ç”¨ï¼ˆå¦‚æœä¹‹å‰æ²¡æœ‰å‘é€ï¼‰
                            if code_references_received and not thought_sent:
                                payload = {
                                    "thought": f"ç”¨æˆ·è¯¢é—®: {user_input}ã€‚æˆ‘é€šè¿‡æºç æ£€ç´¢æ‰¾åˆ°äº†{len(code_references_received)}ä¸ªç›¸å…³ä»£ç ç‰‡æ®µï¼Œå·²åŸºäºè¿™äº›ä»£ç å†…å®¹ç”Ÿæˆæ™ºèƒ½å›å¤ã€‚",
                                    "codes": [asdict(ref) for ref in code_references_received],
                                }
                                yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                            
                            yield "data: [DONE]\n\n"
                            break
                    
                    except:
                        pass  # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­
                        
            except GeneratorExit:
                # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£å¸¸é€€å‡º
                logger.info("å®¢æˆ·ç«¯å…³é—­äº†SSEè¿æ¥")
                return
            except BrokenPipeError:
                # ç®¡é“æ–­å¼€ï¼Œæ­£å¸¸é€€å‡º
                logger.info("å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼ˆBrokenPipeï¼‰")
                return
            except Exception as stream_error:
                logger.error(f"SSEæµå¤„ç†å¤±è´¥: {stream_error}")
                try:
                    error_payload = {"error": str(stream_error)}
                    yield f"data: {json.dumps(error_payload, ensure_ascii=False)}\n\n"
                    yield "data: [DONE]\n\n"
                except (GeneratorExit, BrokenPipeError):
                    # å¦‚æœå®¢æˆ·ç«¯å·²æ–­å¼€ï¼Œç›´æ¥è¿”å›
                    return
        
        return Response(event_stream(), mimetype='text/event-stream')
        
    except Exception as e:
        logger.error(f"æºç æ£€ç´¢å¤„ç†å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify(create_api_response(500, "æºç æ£€ç´¢å¤„ç†å¤±è´¥", {"error": str(e)}))

@app.route('/api/code/conversation/clear', methods=['POST'])
def clear_code_conversation():
    """æ¸…ç©ºæºç æ£€ç´¢å¯¹è¯å†å²"""
    try:
        if code_rag_workflow is None:
            return jsonify(create_api_response(500, "æºç æ£€ç´¢å·¥ä½œæµæœªåˆå§‹åŒ–"))
        
        code_rag_workflow.clear_conversation()
        logger.info("æºç æ£€ç´¢å¯¹è¯å†å²å·²æ¸…ç©º")
        
        return jsonify(create_api_response(200, "æºç æ£€ç´¢å¯¹è¯å†å²æ¸…ç©ºæˆåŠŸ"))
        
    except Exception as e:
        logger.error(f"æ¸…ç©ºæºç æ£€ç´¢å¯¹è¯å†å²å¤±è´¥: {e}")
        return jsonify(create_api_response(500, "æ¸…ç©ºæºç æ£€ç´¢å¯¹è¯å†å²å¤±è´¥", {"error": str(e)}))

@app.route('/api/question/judge', methods=['POST'])
def judge_answer():
    """å¤§æ¨¡å‹æ™ºèƒ½åˆ¤é¢˜æ¥å£ï¼ˆé€‰æ‹©é¢˜/å¡«ç©ºé¢˜/é—®ç­”é¢˜é€šç”¨ï¼‰"""
    try:
        if rag_workflow is None:
            return jsonify(create_api_response(500, "RAGå·¥ä½œæµæœªåˆå§‹åŒ–"))
        
        # è§£æè¯·æ±‚æ•°æ®
        request_data = request.get_json()
        if not request_data:
            return jsonify(create_api_response(400, "è¯·æ±‚æ•°æ®ä¸ºç©º"))
        
        # éªŒè¯è¯·æ±‚å­—æ®µ
        question_content = request_data.get('questionContent', '').strip()
        student_answer = request_data.get('studentAnswer', '').strip()
        question_options = request_data.get('questionOptions', [])
        question_type = request_data.get('questionType', 'é€‰æ‹©é¢˜').strip()
        correct_answer = request_data.get('correctAnswer', '').strip()
        knowledge_point = request_data.get('knowledgePoint', '').strip()
        
        if not question_content or not student_answer:
            return jsonify(create_api_response(400, "é¢˜ç›®å†…å®¹å’Œå­¦ç”Ÿç­”æ¡ˆä¸èƒ½ä¸ºç©º"))
        
        logger.info(f"æ”¶åˆ°æ™ºèƒ½åˆ¤é¢˜è¯·æ±‚: question='{question_content[:50]}...', answer='{student_answer[:30]}...', type='{question_type}'")
        
        # æ ¹æ®é¢˜ç›®ç±»å‹é€‰æ‹©åˆ¤é¢˜æ–¹æ³•
        if question_type in ['å¡«ç©ºé¢˜', 'é—®ç­”é¢˜']:
            # ä½¿ç”¨æ–‡æœ¬åˆ¤é¢˜
            judge_result = rag_workflow.judge_text_answer(
                question_content=question_content,
                student_answer=student_answer,
                question_type=question_type,
                knowledge_point=knowledge_point
            )
        else:
            # ä½¿ç”¨é€‰æ‹©é¢˜åˆ¤é¢˜
            judge_result = rag_workflow.judge_answer(
                question_content=question_content,
                question_options=question_options,
                selected_answer=student_answer,
                correct_answer=correct_answer,
                knowledge_point=knowledge_point
            )
        
        logger.info(f"æ™ºèƒ½åˆ¤é¢˜å®Œæˆ: isCorrect={judge_result['isCorrect']}")
        
        return jsonify(create_api_response(200, "æ™ºèƒ½åˆ¤é¢˜æˆåŠŸ", judge_result))
        
    except Exception as e:
        logger.error(f"æ™ºèƒ½åˆ¤é¢˜å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify(create_api_response(500, "æ™ºèƒ½åˆ¤é¢˜å¤±è´¥", {"error": str(e)}))

@app.route('/api/question/explanation', methods=['POST'])
def generate_explanation():
    """å¤§æ¨¡å‹ç”Ÿæˆé¢˜ç›®è§£ææ¥å£"""
    try:
        if rag_workflow is None:
            return jsonify(create_api_response(500, "RAGå·¥ä½œæµæœªåˆå§‹åŒ–"))
        
        # è§£æè¯·æ±‚æ•°æ®
        request_data = request.get_json()
        if not request_data:
            return jsonify(create_api_response(400, "è¯·æ±‚æ•°æ®ä¸ºç©º"))
        
        # éªŒè¯è¯·æ±‚å­—æ®µ
        question_content = request_data.get('questionContent', '').strip()
        question_options = request_data.get('questionOptions', [])
        selected_answer = request_data.get('selectedAnswer', '').strip()
        correct_answer = request_data.get('correctAnswer', '').strip()
        knowledge_point = request_data.get('knowledgePoint', '').strip()
        is_correct = request_data.get('isCorrect', False)
        
        if not question_content:
            return jsonify(create_api_response(400, "é¢˜ç›®å†…å®¹ä¸èƒ½ä¸ºç©º"))
        
        logger.info(f"æ”¶åˆ°è§£æç”Ÿæˆè¯·æ±‚: question='{question_content[:50]}...', isCorrect={is_correct}")
        
        # ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆè§£æ
        explanation = rag_workflow.generate_explanation(
            question_content=question_content,
            question_options=question_options,
            selected_answer=selected_answer,
            correct_answer=correct_answer,
            knowledge_point=knowledge_point,
            is_correct=is_correct
        )
        
        logger.info(f"è§£æç”Ÿæˆå®Œæˆ: length={len(explanation)}")
        
        return jsonify(create_api_response(200, "è§£æç”ŸæˆæˆåŠŸ", {"explanation": explanation}))
        
    except Exception as e:
        logger.error(f"è§£æç”Ÿæˆå¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return jsonify(create_api_response(500, "è§£æç”Ÿæˆå¤±è´¥", {"error": str(e)}))

# ==================== é”™è¯¯å¤„ç† ====================

@app.errorhandler(404)
def not_found(error):
    """404é”™è¯¯å¤„ç†"""
    return jsonify(create_api_response(404, "æ¥å£ä¸å­˜åœ¨"))

@app.errorhandler(405)
def method_not_allowed(error):
    """405é”™è¯¯å¤„ç†"""
    return jsonify(create_api_response(405, "è¯·æ±‚æ–¹æ³•ä¸å…è®¸"))

@app.errorhandler(500)
def internal_error(error):
    """500é”™è¯¯å¤„ç†"""
    logger.error(f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {error}")
    return jsonify(create_api_response(500, "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯"))

# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆå§‹åŒ–RAGå·¥ä½œæµ
        init_rag_workflow()
        
        # å¯åŠ¨Flaskåº”ç”¨
        logger.info("ğŸš€ å¯åŠ¨RAGå·¥ä½œæµåç«¯APIæœåŠ¡å™¨...")
        logger.info("ğŸ“¡ APIæ¥å£:")
        logger.info("  POST /api/chat - èŠå¤©æ¥å£ï¼ˆæ”¯æŒæ•™æå’Œæºç æ£€ç´¢ï¼‰")
        logger.info("  POST /api/code/query - æºç æ£€ç´¢ä¸“ç”¨æ¥å£")
        logger.info("  POST /api/conversation/clear - æ¸…ç©ºå¯¹è¯å†å²ï¼ˆæ•™æ+æºç ï¼‰")
        logger.info("  POST /api/code/conversation/clear - æ¸…ç©ºæºç æ£€ç´¢å¯¹è¯å†å²")
        logger.info("  GET  /api/conversation/summary - è·å–å¯¹è¯æ‘˜è¦")
        logger.info("  POST /api/config/similarity-threshold - æ›´æ–°ç›¸ä¼¼åº¦é˜ˆå€¼")
        logger.info("  GET  /api/rag/info - è·å–æ•™æRAGç³»ç»Ÿä¿¡æ¯")
        logger.info("  GET  /api/code/info - è·å–æºç æ£€ç´¢ç³»ç»Ÿä¿¡æ¯")
        logger.info("  GET  /api/health - å¥åº·æ£€æŸ¥")
        
        # å¯åŠ¨æœåŠ¡å™¨
        app.run(
            host='0.0.0.0',
            port=5000,
            debug=False,  # ç”Ÿäº§ç¯å¢ƒå»ºè®®è®¾ä¸ºFalse
            threaded=True
        )
        
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()
