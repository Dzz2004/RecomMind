{
  "query": "Linux内存管理数据结构设计",
  "timestamp": "2025-12-20 17:28:46",
  "retrieved_files": [
    {
      "source_file": "mm/list_lru.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:35:23\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `list_lru.c`\n\n---\n\n# list_lru.c 技术文档\n\n## 1. 文件概述\n\n`list_lru.c` 实现了 Linux 内核中通用的 **List-based LRU（Least Recently Used）基础设施**，用于管理可回收对象的双向链表。该机制支持按 NUMA 节点（node）和内存控制组（memcg）进行细粒度组织，便于内存压力下的高效回收。主要服务于 slab 分配器等子系统，作为 shrinker 框架的一部分，在内存紧张时协助释放非活跃对象。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct list_lru`：顶层 LRU 管理结构，包含 per-node 的 `list_lru_node`\n- `struct list_lru_node`：每个 NUMA 节点对应的 LRU 节点，含自旋锁和总项数\n- `struct list_lru_one`：实际存储对象链表和计数的单元（per-memcg per-node）\n- `struct list_lru_memcg`：当启用 `CONFIG_MEMCG` 时，为每个 memcg 存储 per-node 的 `list_lru_one`\n\n### 主要导出函数\n- `list_lru_add()` / `list_lru_add_obj()`：向 LRU 添加对象\n- `list_lru_del()` / `list_lru_del_obj()`：从 LRU 删除对象\n- `list_lru_isolate()` / `list_lru_isolate_move()`：在回收过程中隔离对象\n- `list_lru_count_one()` / `list_lru_count_node()`：查询 LRU 中对象数量\n- `list_lru_walk_one()` / `list_lru_walk_node()`：遍历并处理 LRU 中的对象（用于 shrinker 回调）\n\n### 内部辅助函数\n- `list_lru_from_memcg_idx()`：根据 memcg ID 获取对应的 `list_lru_one`\n- `__list_lru_walk_one()`：带锁的 LRU 遍历核心逻辑\n- `list_lru_register()` / `list_lru_unregister()`：注册/注销 memcg-aware 的 LRU（用于全局追踪）\n\n## 3. 关键实现\n\n### 内存控制组（memcg）支持\n- 通过 `CONFIG_MEMCG` 条件编译控制 memcg 相关逻辑\n- 使用 XArray (`lru->xa`) 动态存储每个 memcg 对应的 `list_lru_memcg` 结构\n- 每个 memcg 在每个 NUMA 节点上拥有独立的 `list_lru_one`，实现资源隔离\n- 全局 `memcg_list_lrus` 链表和 `list_lrus_mutex` 用于跟踪所有 memcg-aware 的 LRU 实例\n\n### 并发控制\n- 每个 NUMA 节点 (`list_lru_node`) 拥有独立的自旋锁 (`nlru->lock`)\n- 所有对 LRU 链表的操作（增、删、遍历）均在对应节点锁保护下进行\n- 提供 `_irq` 版本的遍历函数（`list_lru_walk_one_irq`）用于中断上下文\n\n### 回收遍历机制\n- `list_lru_walk_*` 函数接受回调函数 `isolate`，由调用者定义回收策略\n- 回调返回值控制遍历行为：\n  - `LRU_REMOVED`：成功移除\n  - `LRU_REMOVED_RETRY`：移除后需重新开始遍历（锁曾被释放）\n  - `LRU_RETRY`：未移除但需重新开始遍历\n  - `LRU_ROTATE`：将对象移到链表尾部（标记为最近使用）\n  - `LRU_SKIP`：跳过当前对象\n  - `LRU_STOP`：立即停止遍历\n- 通过 `nr_to_walk` 限制单次遍历的最大对象数，防止长时间持锁\n\n### Shrinker 集成\n- 当向空的 `list_lru_one` 添加首个对象时，调用 `set_shrinker_bit()` 标记该 memcg/node 需要被 shrinker 处理\n- `lru_shrinker_id()` 返回关联的 shrinker ID，用于通知内存回收子系统\n\n### 对象归属识别\n- `list_lru_add_obj()` / `list_lru_del_obj()` 通过 `mem_cgroup_from_slab_obj()` 自动获取对象所属的 memcg\n- 使用 `page_to_nid(virt_to_page(item))` 确定对象所在的 NUMA 节点\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/list_lru.h>`：定义核心数据结构和 API\n  - `<linux/memcontrol.h>`：memcg 相关接口（如 `memcg_kmem_id`）\n  - `\"slab.h\"` 和 `\"internal.h\"`：slab 分配器内部接口（如 `mem_cgroup_from_slab_obj`）\n- **配置依赖**：\n  - `CONFIG_MEMCG`：决定是否编译 memcg 相关代码\n  - `CONFIG_NUMA`：影响 per-node 数据结构的大小（通过 `nr_node_ids`）\n- **子系统依赖**：\n  - Slab 分配器：作为主要使用者，管理可回收 slab 对象\n  - Memory Control Group (memcg)：提供内存隔离和记账\n  - Shrinker 框架：通过 shrinker 回调触发 LRU 遍历回收\n\n## 5. 使用场景\n\n- **Slab 对象回收**：当系统内存压力大时，shrinker 通过 `list_lru_walk_*` 遍历 inactive slab 对象链表，释放可回收对象\n- **Per-memcg 内存限制**：在 cgroup 内存超限时，仅遍历该 memcg 对应的 LRU 部分，实现精确回收\n- **NUMA 感知管理**：按 NUMA 节点分离 LRU 链表，减少远程内存访问，提升性能\n- **通用 LRU 容器**：任何需要按 LRU 策略管理可回收对象的内核子系统均可使用此基础设施（如 dentry、inode 缓存等）",
      "similarity": 0.6527343392372131,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "mm/list_lru.c",
          "start_line": 425,
          "end_line": 551,
          "content": [
            "static void memcg_reparent_list_lru(struct list_lru *lru,",
            "\t\t\t\t    int src_idx, struct mem_cgroup *dst_memcg)",
            "{",
            "\tint i;",
            "",
            "\tfor_each_node(i)",
            "\t\tmemcg_reparent_list_lru_node(lru, i, src_idx, dst_memcg);",
            "",
            "\tmemcg_list_lru_free(lru, src_idx);",
            "}",
            "void memcg_reparent_list_lrus(struct mem_cgroup *memcg, struct mem_cgroup *parent)",
            "{",
            "\tstruct cgroup_subsys_state *css;",
            "\tstruct list_lru *lru;",
            "\tint src_idx = memcg->kmemcg_id;",
            "",
            "\t/*",
            "\t * Change kmemcg_id of this cgroup and all its descendants to the",
            "\t * parent's id, and then move all entries from this cgroup's list_lrus",
            "\t * to ones of the parent.",
            "\t *",
            "\t * After we have finished, all list_lrus corresponding to this cgroup",
            "\t * are guaranteed to remain empty. So we can safely free this cgroup's",
            "\t * list lrus in memcg_list_lru_free().",
            "\t *",
            "\t * Changing ->kmemcg_id to the parent can prevent memcg_list_lru_alloc()",
            "\t * from allocating list lrus for this cgroup after memcg_list_lru_free()",
            "\t * call.",
            "\t */",
            "\trcu_read_lock();",
            "\tcss_for_each_descendant_pre(css, &memcg->css) {",
            "\t\tstruct mem_cgroup *child;",
            "",
            "\t\tchild = mem_cgroup_from_css(css);",
            "\t\tWRITE_ONCE(child->kmemcg_id, parent->kmemcg_id);",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\tmutex_lock(&list_lrus_mutex);",
            "\tlist_for_each_entry(lru, &memcg_list_lrus, list)",
            "\t\tmemcg_reparent_list_lru(lru, src_idx, parent);",
            "\tmutex_unlock(&list_lrus_mutex);",
            "}",
            "static inline bool memcg_list_lru_allocated(struct mem_cgroup *memcg,",
            "\t\t\t\t\t    struct list_lru *lru)",
            "{",
            "\tint idx = memcg->kmemcg_id;",
            "",
            "\treturn idx < 0 || xa_load(&lru->xa, idx);",
            "}",
            "int memcg_list_lru_alloc(struct mem_cgroup *memcg, struct list_lru *lru,",
            "\t\t\t gfp_t gfp)",
            "{",
            "\tint i;",
            "\tunsigned long flags;",
            "\tstruct list_lru_memcg_table {",
            "\t\tstruct list_lru_memcg *mlru;",
            "\t\tstruct mem_cgroup *memcg;",
            "\t} *table;",
            "\tXA_STATE(xas, &lru->xa, 0);",
            "",
            "\tif (!list_lru_memcg_aware(lru) || memcg_list_lru_allocated(memcg, lru))",
            "\t\treturn 0;",
            "",
            "\tgfp &= GFP_RECLAIM_MASK;",
            "\ttable = kmalloc_array(memcg->css.cgroup->level, sizeof(*table), gfp);",
            "\tif (!table)",
            "\t\treturn -ENOMEM;",
            "",
            "\t/*",
            "\t * Because the list_lru can be reparented to the parent cgroup's",
            "\t * list_lru, we should make sure that this cgroup and all its",
            "\t * ancestors have allocated list_lru_memcg.",
            "\t */",
            "\tfor (i = 0; memcg; memcg = parent_mem_cgroup(memcg), i++) {",
            "\t\tif (memcg_list_lru_allocated(memcg, lru))",
            "\t\t\tbreak;",
            "",
            "\t\ttable[i].memcg = memcg;",
            "\t\ttable[i].mlru = memcg_init_list_lru_one(gfp);",
            "\t\tif (!table[i].mlru) {",
            "\t\t\twhile (i--)",
            "\t\t\t\tkfree(table[i].mlru);",
            "\t\t\tkfree(table);",
            "\t\t\treturn -ENOMEM;",
            "\t\t}",
            "\t}",
            "",
            "\txas_lock_irqsave(&xas, flags);",
            "\twhile (i--) {",
            "\t\tint index = READ_ONCE(table[i].memcg->kmemcg_id);",
            "\t\tstruct list_lru_memcg *mlru = table[i].mlru;",
            "",
            "\t\txas_set(&xas, index);",
            "retry:",
            "\t\tif (unlikely(index < 0 || xas_error(&xas) || xas_load(&xas))) {",
            "\t\t\tkfree(mlru);",
            "\t\t} else {",
            "\t\t\txas_store(&xas, mlru);",
            "\t\t\tif (xas_error(&xas) == -ENOMEM) {",
            "\t\t\t\txas_unlock_irqrestore(&xas, flags);",
            "\t\t\t\tif (xas_nomem(&xas, gfp))",
            "\t\t\t\t\txas_set_err(&xas, 0);",
            "\t\t\t\txas_lock_irqsave(&xas, flags);",
            "\t\t\t\t/*",
            "\t\t\t\t * The xas lock has been released, this memcg",
            "\t\t\t\t * can be reparented before us. So reload",
            "\t\t\t\t * memcg id. More details see the comments",
            "\t\t\t\t * in memcg_reparent_list_lrus().",
            "\t\t\t\t */",
            "\t\t\t\tindex = READ_ONCE(table[i].memcg->kmemcg_id);",
            "\t\t\t\tif (index < 0)",
            "\t\t\t\t\txas_set_err(&xas, 0);",
            "\t\t\t\telse if (!xas_error(&xas) && index != xas.xa_index)",
            "\t\t\t\t\txas_set(&xas, index);",
            "\t\t\t\tgoto retry;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "\t/* xas_nomem() is used to free memory instead of memory allocation. */",
            "\tif (xas.xa_alloc)",
            "\t\txas_nomem(&xas, gfp);",
            "\txas_unlock_irqrestore(&xas, flags);",
            "\tkfree(table);",
            "",
            "\treturn xas_error(&xas);",
            "}"
          ],
          "function_name": "memcg_reparent_list_lru, memcg_reparent_list_lrus, memcg_list_lru_allocated, memcg_list_lru_alloc",
          "description": "实现内存组层级间的LRU列表迁移与分配机制，包含递归子组处理、动态分配/释放LRU结构体及冲突解决逻辑。",
          "similarity": 0.6415719985961914
        },
        {
          "chunk_id": 5,
          "file_path": "mm/list_lru.c",
          "start_line": 556,
          "end_line": 605,
          "content": [
            "static inline void memcg_init_list_lru(struct list_lru *lru, bool memcg_aware)",
            "{",
            "}",
            "static void memcg_destroy_list_lru(struct list_lru *lru)",
            "{",
            "}",
            "int __list_lru_init(struct list_lru *lru, bool memcg_aware,",
            "\t\t    struct lock_class_key *key, struct shrinker *shrinker)",
            "{",
            "\tint i;",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tif (shrinker)",
            "\t\tlru->shrinker_id = shrinker->id;",
            "\telse",
            "\t\tlru->shrinker_id = -1;",
            "#endif",
            "",
            "\tlru->node = kcalloc(nr_node_ids, sizeof(*lru->node), GFP_KERNEL);",
            "\tif (!lru->node)",
            "\t\treturn -ENOMEM;",
            "",
            "\tfor_each_node(i) {",
            "\t\tspin_lock_init(&lru->node[i].lock);",
            "\t\tif (key)",
            "\t\t\tlockdep_set_class(&lru->node[i].lock, key);",
            "\t\tinit_one_lru(&lru->node[i].lru);",
            "\t}",
            "",
            "\tmemcg_init_list_lru(lru, memcg_aware);",
            "\tlist_lru_register(lru);",
            "",
            "\treturn 0;",
            "}",
            "void list_lru_destroy(struct list_lru *lru)",
            "{",
            "\t/* Already destroyed or not yet initialized? */",
            "\tif (!lru->node)",
            "\t\treturn;",
            "",
            "\tlist_lru_unregister(lru);",
            "",
            "\tmemcg_destroy_list_lru(lru);",
            "\tkfree(lru->node);",
            "\tlru->node = NULL;",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tlru->shrinker_id = -1;",
            "#endif",
            "}"
          ],
          "function_name": "memcg_init_list_lru, memcg_destroy_list_lru, __list_lru_init, list_lru_destroy",
          "description": "该代码段实现了基于内存控制组（MEMCG）的LRU列表管理功能。  \n`__list_lru_init` 初始化 `list_lru` 结构体并注册到系统，其中包含 MEMCG 相关的 shrinker ID 设置及节点锁初始化；`list_lru_destroy` 反向清理资源，但 `memcg_init_list_lru` 和 `memcg_destroy_list_lru` 的具体实现缺失，上下文不完整。",
          "similarity": 0.6019122004508972
        },
        {
          "chunk_id": 1,
          "file_path": "mm/list_lru.c",
          "start_line": 22,
          "end_line": 129,
          "content": [
            "static inline bool list_lru_memcg_aware(struct list_lru *lru)",
            "{",
            "\treturn lru->memcg_aware;",
            "}",
            "static void list_lru_register(struct list_lru *lru)",
            "{",
            "\tif (!list_lru_memcg_aware(lru))",
            "\t\treturn;",
            "",
            "\tmutex_lock(&list_lrus_mutex);",
            "\tlist_add(&lru->list, &memcg_list_lrus);",
            "\tmutex_unlock(&list_lrus_mutex);",
            "}",
            "static void list_lru_unregister(struct list_lru *lru)",
            "{",
            "\tif (!list_lru_memcg_aware(lru))",
            "\t\treturn;",
            "",
            "\tmutex_lock(&list_lrus_mutex);",
            "\tlist_del(&lru->list);",
            "\tmutex_unlock(&list_lrus_mutex);",
            "}",
            "static int lru_shrinker_id(struct list_lru *lru)",
            "{",
            "\treturn lru->shrinker_id;",
            "}",
            "static void list_lru_register(struct list_lru *lru)",
            "{",
            "}",
            "static void list_lru_unregister(struct list_lru *lru)",
            "{",
            "}",
            "static int lru_shrinker_id(struct list_lru *lru)",
            "{",
            "\treturn -1;",
            "}",
            "static inline bool list_lru_memcg_aware(struct list_lru *lru)",
            "{",
            "\treturn false;",
            "}",
            "bool list_lru_add(struct list_lru *lru, struct list_head *item, int nid,",
            "\t\t    struct mem_cgroup *memcg)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tstruct list_lru_one *l;",
            "",
            "\tspin_lock(&nlru->lock);",
            "\tif (list_empty(item)) {",
            "\t\tl = list_lru_from_memcg_idx(lru, nid, memcg_kmem_id(memcg));",
            "\t\tlist_add_tail(item, &l->list);",
            "\t\t/* Set shrinker bit if the first element was added */",
            "\t\tif (!l->nr_items++)",
            "\t\t\tset_shrinker_bit(memcg, nid, lru_shrinker_id(lru));",
            "\t\tnlru->nr_items++;",
            "\t\tspin_unlock(&nlru->lock);",
            "\t\treturn true;",
            "\t}",
            "\tspin_unlock(&nlru->lock);",
            "\treturn false;",
            "}",
            "bool list_lru_add_obj(struct list_lru *lru, struct list_head *item)",
            "{",
            "\tbool ret;",
            "\tint nid = page_to_nid(virt_to_page(item));",
            "",
            "\tif (list_lru_memcg_aware(lru)) {",
            "\t\trcu_read_lock();",
            "\t\tret = list_lru_add(lru, item, nid, mem_cgroup_from_slab_obj(item));",
            "\t\trcu_read_unlock();",
            "\t} else {",
            "\t\tret = list_lru_add(lru, item, nid, NULL);",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "bool list_lru_del(struct list_lru *lru, struct list_head *item, int nid,",
            "\t\t    struct mem_cgroup *memcg)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tstruct list_lru_one *l;",
            "",
            "\tspin_lock(&nlru->lock);",
            "\tif (!list_empty(item)) {",
            "\t\tl = list_lru_from_memcg_idx(lru, nid, memcg_kmem_id(memcg));",
            "\t\tlist_del_init(item);",
            "\t\tl->nr_items--;",
            "\t\tnlru->nr_items--;",
            "\t\tspin_unlock(&nlru->lock);",
            "\t\treturn true;",
            "\t}",
            "\tspin_unlock(&nlru->lock);",
            "\treturn false;",
            "}",
            "bool list_lru_del_obj(struct list_lru *lru, struct list_head *item)",
            "{",
            "\tbool ret;",
            "\tint nid = page_to_nid(virt_to_page(item));",
            "",
            "\tif (list_lru_memcg_aware(lru)) {",
            "\t\trcu_read_lock();",
            "\t\tret = list_lru_del(lru, item, nid, mem_cgroup_from_slab_obj(item));",
            "\t\trcu_read_unlock();",
            "\t} else {",
            "\t\tret = list_lru_del(lru, item, nid, NULL);",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "list_lru_memcg_aware, list_lru_register, list_lru_unregister, lru_shrinker_id, list_lru_register, list_lru_unregister, lru_shrinker_id, list_lru_memcg_aware, list_lru_add, list_lru_add_obj, list_lru_del, list_lru_del_obj",
          "description": "实现了LRU列表的添加/删除操作，支持MemCG感知的节点和内存组粒度管理，包含处理多核、内存组切换及RCU安全访问的逻辑。",
          "similarity": 0.600623607635498
        },
        {
          "chunk_id": 0,
          "file_path": "mm/list_lru.c",
          "start_line": 1,
          "end_line": 21,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Copyright (c) 2013 Red Hat, Inc. and Parallels Inc. All rights reserved.",
            " * Authors: David Chinner and Glauber Costa",
            " *",
            " * Generic LRU infrastructure",
            " */",
            "#include <linux/kernel.h>",
            "#include <linux/module.h>",
            "#include <linux/mm.h>",
            "#include <linux/list_lru.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/memcontrol.h>",
            "#include \"slab.h\"",
            "#include \"internal.h\"",
            "",
            "#ifdef CONFIG_MEMCG",
            "static LIST_HEAD(memcg_list_lrus);",
            "static DEFINE_MUTEX(list_lrus_mutex);",
            ""
          ],
          "function_name": null,
          "description": "定义了支持内存控制组（MemCG）的LRU基础设施，声明了全局链表头memcg_list_lrus和互斥锁list_lrus_mutex，用于管理MemCG环境下的LRU列表注册与注销操作。",
          "similarity": 0.5863087177276611
        },
        {
          "chunk_id": 3,
          "file_path": "mm/list_lru.c",
          "start_line": 289,
          "end_line": 400,
          "content": [
            "unsigned long",
            "list_lru_walk_one_irq(struct list_lru *lru, int nid, struct mem_cgroup *memcg,",
            "\t\t      list_lru_walk_cb isolate, void *cb_arg,",
            "\t\t      unsigned long *nr_to_walk)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tunsigned long ret;",
            "",
            "\tspin_lock_irq(&nlru->lock);",
            "\tret = __list_lru_walk_one(lru, nid, memcg_kmem_id(memcg), isolate,",
            "\t\t\t\t  cb_arg, nr_to_walk);",
            "\tspin_unlock_irq(&nlru->lock);",
            "\treturn ret;",
            "}",
            "unsigned long list_lru_walk_node(struct list_lru *lru, int nid,",
            "\t\t\t\t list_lru_walk_cb isolate, void *cb_arg,",
            "\t\t\t\t unsigned long *nr_to_walk)",
            "{",
            "\tlong isolated = 0;",
            "",
            "\tisolated += list_lru_walk_one(lru, nid, NULL, isolate, cb_arg,",
            "\t\t\t\t      nr_to_walk);",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tif (*nr_to_walk > 0 && list_lru_memcg_aware(lru)) {",
            "\t\tstruct list_lru_memcg *mlru;",
            "\t\tunsigned long index;",
            "",
            "\t\txa_for_each(&lru->xa, index, mlru) {",
            "\t\t\tstruct list_lru_node *nlru = &lru->node[nid];",
            "",
            "\t\t\tspin_lock(&nlru->lock);",
            "\t\t\tisolated += __list_lru_walk_one(lru, nid, index,",
            "\t\t\t\t\t\t\tisolate, cb_arg,",
            "\t\t\t\t\t\t\tnr_to_walk);",
            "\t\t\tspin_unlock(&nlru->lock);",
            "",
            "\t\t\tif (*nr_to_walk <= 0)",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "#endif",
            "",
            "\treturn isolated;",
            "}",
            "static void init_one_lru(struct list_lru_one *l)",
            "{",
            "\tINIT_LIST_HEAD(&l->list);",
            "\tl->nr_items = 0;",
            "}",
            "static void memcg_list_lru_free(struct list_lru *lru, int src_idx)",
            "{",
            "\tstruct list_lru_memcg *mlru = xa_erase_irq(&lru->xa, src_idx);",
            "",
            "\t/*",
            "\t * The __list_lru_walk_one() can walk the list of this node.",
            "\t * We need kvfree_rcu() here. And the walking of the list",
            "\t * is under lru->node[nid]->lock, which can serve as a RCU",
            "\t * read-side critical section.",
            "\t */",
            "\tif (mlru)",
            "\t\tkvfree_rcu(mlru, rcu);",
            "}",
            "static inline void memcg_init_list_lru(struct list_lru *lru, bool memcg_aware)",
            "{",
            "\tif (memcg_aware)",
            "\t\txa_init_flags(&lru->xa, XA_FLAGS_LOCK_IRQ);",
            "\tlru->memcg_aware = memcg_aware;",
            "}",
            "static void memcg_destroy_list_lru(struct list_lru *lru)",
            "{",
            "\tXA_STATE(xas, &lru->xa, 0);",
            "\tstruct list_lru_memcg *mlru;",
            "",
            "\tif (!list_lru_memcg_aware(lru))",
            "\t\treturn;",
            "",
            "\txas_lock_irq(&xas);",
            "\txas_for_each(&xas, mlru, ULONG_MAX) {",
            "\t\tkfree(mlru);",
            "\t\txas_store(&xas, NULL);",
            "\t}",
            "\txas_unlock_irq(&xas);",
            "}",
            "static void memcg_reparent_list_lru_node(struct list_lru *lru, int nid,",
            "\t\t\t\t\t int src_idx, struct mem_cgroup *dst_memcg)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tint dst_idx = dst_memcg->kmemcg_id;",
            "\tstruct list_lru_one *src, *dst;",
            "",
            "\t/*",
            "\t * Since list_lru_{add,del} may be called under an IRQ-safe lock,",
            "\t * we have to use IRQ-safe primitives here to avoid deadlock.",
            "\t */",
            "\tspin_lock_irq(&nlru->lock);",
            "",
            "\tsrc = list_lru_from_memcg_idx(lru, nid, src_idx);",
            "\tif (!src)",
            "\t\tgoto out;",
            "\tdst = list_lru_from_memcg_idx(lru, nid, dst_idx);",
            "",
            "\tlist_splice_init(&src->list, &dst->list);",
            "",
            "\tif (src->nr_items) {",
            "\t\tdst->nr_items += src->nr_items;",
            "\t\tset_shrinker_bit(dst_memcg, nid, lru_shrinker_id(lru));",
            "\t\tsrc->nr_items = 0;",
            "\t}",
            "out:",
            "\tspin_unlock_irq(&nlru->lock);",
            "}"
          ],
          "function_name": "list_lru_walk_one_irq, list_lru_walk_node, init_one_lru, memcg_list_lru_free, memcg_init_list_lru, memcg_destroy_list_lru, memcg_reparent_list_lru_node",
          "description": "包含LRU节点初始化、内存组间列表迁移、资源释放等高级操作，涉及XA表管理、中断安全锁操作及内存组重新归属处理。",
          "similarity": 0.5818251967430115
        }
      ]
    },
    {
      "source_file": "mm/memblock.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:38:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memblock.c`\n\n---\n\n# memblock.c 技术文档\n\n## 1. 文件概述\n\n`memblock.c` 实现了 Linux 内核早期启动阶段的内存管理机制——**memblock**。该机制用于在常规内存分配器（如 buddy allocator）尚未初始化之前，对物理内存进行粗粒度的区域管理。它将系统内存抽象为若干连续的内存区域（regions），支持“可用内存”（memory）、“保留内存”（reserved）和“物理内存”（physmem，部分架构支持）三种类型，为内核早期初始化提供内存添加、查询和分配能力。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct memblock_region`：表示一个连续的物理内存区域，包含基地址（base）、大小（size）、NUMA 节点 ID 和属性标志。\n- `struct memblock_type`：管理一类内存区域的集合，包含区域数组、当前数量（cnt）、最大容量（max）和名称。\n- `struct memblock`：全局 memblock 管理结构，包含 `memory` 和 `reserved` 两种类型的 `memblock_type`，以及分配方向（bottom_up）和当前分配上限（current_limit）。\n- `physmem`（条件编译）：描述不受 `mem=` 参数限制的实际物理内存布局。\n\n### 主要函数与变量\n- `memblock_add()` / `memblock_add_node()`：向 memblock 添加可用内存区域。\n- `memblock_reserve()`：标记内存区域为保留（不可用于动态分配）。\n- `memblock_phys_alloc*()` / `memblock_alloc*()`：分配物理或虚拟地址的内存。\n- `memblock_overlaps_region()`：判断指定区域是否与某类 memblock 区域重叠。\n- `__memblock_find_range_bottom_up()`：从低地址向高地址查找满足条件的空闲内存范围。\n- 全局变量 `memblock`：静态初始化的主 memblock 结构体。\n- `max_low_pfn`, `min_low_pfn`, `max_pfn`, `max_possible_pfn`：记录 PFN（页帧号）边界信息。\n\n### 配置宏\n- `INIT_MEMBLOCK_REGIONS`：初始内存/保留区域数组大小（默认 128）。\n- `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 类型支持。\n- `CONFIG_MEMBLOCK_KHO_SCRATCH`：支持仅从特定标记（KHO_SCRATCH）区域分配内存。\n- `CONFIG_ARCH_KEEP_MEMBLOCK`：决定是否在初始化完成后保留 memblock 数据结构。\n\n## 3. 关键实现\n\n### 初始化与存储\n- `memblock` 结构体在编译时静态初始化，其 `memory` 和 `reserved` 的区域数组分别使用 `memblock_memory_init_regions` 和 `memblock_reserved_init_regions`，初始容量由 `INIT_MEMBLOCK_*_REGIONS` 定义。\n- 每个 `memblock_type` 的 `cnt` 初始设为 1，但实际第一个条目为空的占位符，有效区域从索引 1 开始（后续代码处理）。\n- 支持通过 `memblock_allow_resize()` 动态扩容区域数组，但需谨慎避免与 initrd 等关键区域冲突。\n\n### 内存区域管理\n- 使用 `for_each_memblock_type` 宏遍历指定类型的区域。\n- `memblock_addrs_overlap()` 通过比较区间端点判断两个物理内存区域是否重叠。\n- `memblock_overlaps_region()` 封装了对某类所有区域的重叠检测。\n\n### 分配策略\n- 默认采用 **top-down**（从高地址向低地址）分配策略，可通过 `memblock_set_bottom_up(true)` 切换为 **bottom-up**。\n- 分配时受 `current_limit` 限制（默认 `MEMBLOCK_ALLOC_ANYWHERE` 表示无限制）。\n- 支持基于 NUMA 节点、对齐要求、内存属性（如 `MEMBLOCK_MIRROR`、`MEMBLOCK_KHO_SCRATCH`）的精细控制。\n- `choose_memblock_flags()` 根据 `kho_scratch_only` 和镜像内存存在性动态选择分配标志。\n\n### 安全与调试\n- `memblock_cap_size()` 防止地址计算溢出（确保 `base + size <= PHYS_ADDR_MAX`）。\n- 条件编译的 `memblock_dbg()` 宏用于调试输出（需开启 `memblock_debug`）。\n- 使用 `__initdata_memblock` 属性标记仅在初始化阶段使用的数据，便于后续释放。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memblock.h>`：定义 memblock API 和数据结构。\n  - `<linux/kernel.h>`, `<linux/init.h>`：提供基础内核功能和初始化宏。\n  - `<linux/pfn.h>`：PFN 相关操作。\n  - `<asm/sections.h>`：访问内核链接段信息。\n  - 架构相关头文件（如 `internal.h`）。\n- **配置依赖**：\n  - `CONFIG_NUMA`：影响 `contig_page_data` 的定义。\n  - `CONFIG_KEXEC_HANDOVER`：引入 kexec 相关头文件。\n  - `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 支持。\n- **后续移交**：在 `mem_init()` 中，memblock 管理的内存会被释放给 buddy allocator，完成内存管理权移交。\n\n## 5. 使用场景\n\n- **内核早期初始化**：在 `start_kernel()` 初期，架构代码（如 `setup_arch()`）调用 `memblock_add()` 注册可用物理内存，调用 `memblock_reserve()` 保留内核镜像、设备树、initrd 等关键区域。\n- **早期内存分配**：在 slab/buddy 分配器就绪前，使用 `memblock_alloc()` 分配大块连续内存（如页表、中断向量表、ACPI 表解析缓冲区）。\n- **内存布局查询**：通过 `for_each_memblock()` 等宏遍历内存区域，用于构建 e820 表、EFI 内存映射或 NUMA 拓扑。\n- **特殊分配需求**：支持从镜像内存（`MEMBLOCK_MIRROR`）或 KHO scratch 区域分配，满足安全启动或崩溃转储等场景。\n- **调试与分析**：通过 debugfs 接口（未在片段中体现）导出 memblock 布局，辅助内存问题诊断。",
      "similarity": 0.6487938761711121,
      "chunks": [
        {
          "chunk_id": 10,
          "file_path": "mm/memblock.c",
          "start_line": 1954,
          "end_line": 2057,
          "content": [
            "void __init memblock_mem_limit_remove_map(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr;",
            "",
            "\tif (!limit)",
            "\t\treturn;",
            "",
            "\tmax_addr = __find_max_addr(limit);",
            "",
            "\t/* @limit exceeds the total size of the memory, do nothing */",
            "\tif (max_addr == PHYS_ADDR_MAX)",
            "\t\treturn;",
            "",
            "\tmemblock_cap_memory_range(0, max_addr);",
            "}",
            "static int __init_memblock memblock_search(struct memblock_type *type, phys_addr_t addr)",
            "{",
            "\tunsigned int left = 0, right = type->cnt;",
            "",
            "\tdo {",
            "\t\tunsigned int mid = (right + left) / 2;",
            "",
            "\t\tif (addr < type->regions[mid].base)",
            "\t\t\tright = mid;",
            "\t\telse if (addr >= (type->regions[mid].base +",
            "\t\t\t\t  type->regions[mid].size))",
            "\t\t\tleft = mid + 1;",
            "\t\telse",
            "\t\t\treturn mid;",
            "\t} while (left < right);",
            "\treturn -1;",
            "}",
            "bool __init_memblock memblock_is_reserved(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.reserved, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_memory(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.memory, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_map_memory(phys_addr_t addr)",
            "{",
            "\tint i = memblock_search(&memblock.memory, addr);",
            "",
            "\tif (i == -1)",
            "\t\treturn false;",
            "\treturn !memblock_is_nomap(&memblock.memory.regions[i]);",
            "}",
            "int __init_memblock memblock_search_pfn_nid(unsigned long pfn,",
            "\t\t\t unsigned long *start_pfn, unsigned long *end_pfn)",
            "{",
            "\tstruct memblock_type *type = &memblock.memory;",
            "\tint mid = memblock_search(type, PFN_PHYS(pfn));",
            "",
            "\tif (mid == -1)",
            "\t\treturn -1;",
            "",
            "\t*start_pfn = PFN_DOWN(type->regions[mid].base);",
            "\t*end_pfn = PFN_DOWN(type->regions[mid].base + type->regions[mid].size);",
            "",
            "\treturn memblock_get_region_node(&type->regions[mid]);",
            "}",
            "bool __init_memblock memblock_is_region_memory(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tint idx = memblock_search(&memblock.memory, base);",
            "\tphys_addr_t end = base + memblock_cap_size(base, &size);",
            "",
            "\tif (idx == -1)",
            "\t\treturn false;",
            "\treturn (memblock.memory.regions[idx].base +",
            "\t\t memblock.memory.regions[idx].size) >= end;",
            "}",
            "bool __init_memblock memblock_is_region_reserved(phys_addr_t base, phys_addr_t size)",
            "{",
            "\treturn memblock_overlaps_region(&memblock.reserved, base, size);",
            "}",
            "void __init_memblock memblock_trim_memory(phys_addr_t align)",
            "{",
            "\tphys_addr_t start, end, orig_start, orig_end;",
            "\tstruct memblock_region *r;",
            "",
            "\tfor_each_mem_region(r) {",
            "\t\torig_start = r->base;",
            "\t\torig_end = r->base + r->size;",
            "\t\tstart = round_up(orig_start, align);",
            "\t\tend = round_down(orig_end, align);",
            "",
            "\t\tif (start == orig_start && end == orig_end)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (start < end) {",
            "\t\t\tr->base = start;",
            "\t\t\tr->size = end - start;",
            "\t\t} else {",
            "\t\t\tmemblock_remove_region(&memblock.memory,",
            "\t\t\t\t\t       r - memblock.memory.regions);",
            "\t\t\tr--;",
            "\t\t}",
            "\t}",
            "}",
            "void __init_memblock memblock_set_current_limit(phys_addr_t limit)",
            "{",
            "\tmemblock.current_limit = limit;",
            "}"
          ],
          "function_name": "memblock_mem_limit_remove_map, memblock_search, memblock_is_reserved, memblock_is_memory, memblock_is_map_memory, memblock_search_pfn_nid, memblock_is_region_memory, memblock_is_region_reserved, memblock_trim_memory, memblock_set_current_limit",
          "description": "实现内存块限制移除、搜索和区域判断逻辑，用于管理内存和保留区域的地址范围查询及修剪操作",
          "similarity": 0.6272539496421814
        },
        {
          "chunk_id": 11,
          "file_path": "mm/memblock.c",
          "start_line": 2094,
          "end_line": 2203,
          "content": [
            "static void __init_memblock memblock_dump(struct memblock_type *type)",
            "{",
            "\tphys_addr_t base, end, size;",
            "\tenum memblock_flags flags;",
            "\tint idx;",
            "\tstruct memblock_region *rgn;",
            "",
            "\tpr_info(\" %s.cnt  = 0x%lx\\n\", type->name, type->cnt);",
            "",
            "\tfor_each_memblock_type(idx, type, rgn) {",
            "\t\tchar nid_buf[32] = \"\";",
            "",
            "\t\tbase = rgn->base;",
            "\t\tsize = rgn->size;",
            "\t\tend = base + size - 1;",
            "\t\tflags = rgn->flags;",
            "#ifdef CONFIG_NUMA",
            "\t\tif (numa_valid_node(memblock_get_region_node(rgn)))",
            "\t\t\tsnprintf(nid_buf, sizeof(nid_buf), \" on node %d\",",
            "\t\t\t\t memblock_get_region_node(rgn));",
            "#endif",
            "\t\tpr_info(\" %s[%#x]\\t[%pa-%pa], %pa bytes%s flags: %#x\\n\",",
            "\t\t\ttype->name, idx, &base, &end, &size, nid_buf, flags);",
            "\t}",
            "}",
            "void __init memblock_allow_resize(void)",
            "{",
            "\tmemblock_can_resize = 1;",
            "}",
            "static int __init early_memblock(char *p)",
            "{",
            "\tif (p && strstr(p, \"debug\"))",
            "\t\tmemblock_debug = 1;",
            "\treturn 0;",
            "}",
            "static void __init free_memmap(unsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tstruct page *start_pg, *end_pg;",
            "\tphys_addr_t pg, pgend;",
            "",
            "\t/*",
            "\t * Convert start_pfn/end_pfn to a struct page pointer.",
            "\t */",
            "\tstart_pg = pfn_to_page(start_pfn - 1) + 1;",
            "\tend_pg = pfn_to_page(end_pfn - 1) + 1;",
            "",
            "\t/*",
            "\t * Convert to physical addresses, and round start upwards and end",
            "\t * downwards.",
            "\t */",
            "\tpg = PAGE_ALIGN(__pa(start_pg));",
            "\tpgend = __pa(end_pg) & PAGE_MASK;",
            "",
            "\t/*",
            "\t * If there are free pages between these, free the section of the",
            "\t * memmap array.",
            "\t */",
            "\tif (pg < pgend)",
            "\t\tmemblock_phys_free(pg, pgend - pg);",
            "}",
            "static void __init free_unused_memmap(void)",
            "{",
            "\tunsigned long start, end, prev_end = 0;",
            "\tint i;",
            "",
            "\tif (!IS_ENABLED(CONFIG_HAVE_ARCH_PFN_VALID) ||",
            "\t    IS_ENABLED(CONFIG_SPARSEMEM_VMEMMAP))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * This relies on each bank being in address order.",
            "\t * The banks are sorted previously in bootmem_init().",
            "\t */",
            "\tfor_each_mem_pfn_range(i, MAX_NUMNODES, &start, &end, NULL) {",
            "#ifdef CONFIG_SPARSEMEM",
            "\t\t/*",
            "\t\t * Take care not to free memmap entries that don't exist",
            "\t\t * due to SPARSEMEM sections which aren't present.",
            "\t\t */",
            "\t\tstart = min(start, ALIGN(prev_end, PAGES_PER_SECTION));",
            "#endif",
            "\t\t/*",
            "\t\t * Align down here since many operations in VM subsystem",
            "\t\t * presume that there are no holes in the memory map inside",
            "\t\t * a pageblock",
            "\t\t */",
            "\t\tstart = pageblock_start_pfn(start);",
            "",
            "\t\t/*",
            "\t\t * If we had a previous bank, and there is a space",
            "\t\t * between the current bank and the previous, free it.",
            "\t\t */",
            "\t\tif (prev_end && prev_end < start)",
            "\t\t\tfree_memmap(prev_end, start);",
            "",
            "\t\t/*",
            "\t\t * Align up here since many operations in VM subsystem",
            "\t\t * presume that there are no holes in the memory map inside",
            "\t\t * a pageblock",
            "\t\t */",
            "\t\tprev_end = pageblock_align(end);",
            "\t}",
            "",
            "#ifdef CONFIG_SPARSEMEM",
            "\tif (!IS_ALIGNED(prev_end, PAGES_PER_SECTION)) {",
            "\t\tprev_end = pageblock_align(end);",
            "\t\tfree_memmap(prev_end, ALIGN(prev_end, PAGES_PER_SECTION));",
            "\t}",
            "#endif",
            "}"
          ],
          "function_name": "memblock_dump, memblock_allow_resize, early_memblock, free_memmap, free_unused_memmap",
          "description": "提供内存块状态调试、调整支持、早期内存处理及未使用memmap释放功能，用于优化内存映射管理",
          "similarity": 0.6129294037818909
        },
        {
          "chunk_id": 9,
          "file_path": "mm/memblock.c",
          "start_line": 1607,
          "end_line": 1734,
          "content": [
            "phys_addr_t __init memblock_phys_alloc_range(phys_addr_t size,",
            "\t\t\t\t\t     phys_addr_t align,",
            "\t\t\t\t\t     phys_addr_t start,",
            "\t\t\t\t\t     phys_addr_t end)",
            "{",
            "\tmemblock_dbg(\"%s: %llu bytes align=0x%llx from=%pa max_addr=%pa %pS\\n\",",
            "\t\t     __func__, (u64)size, (u64)align, &start, &end,",
            "\t\t     (void *)_RET_IP_);",
            "\treturn memblock_alloc_range_nid(size, align, start, end, NUMA_NO_NODE,",
            "\t\t\t\t\tfalse);",
            "}",
            "phys_addr_t __init memblock_phys_alloc_try_nid(phys_addr_t size, phys_addr_t align, int nid)",
            "{",
            "\treturn memblock_alloc_range_nid(size, align, 0,",
            "\t\t\t\t\tMEMBLOCK_ALLOC_ACCESSIBLE, nid, false);",
            "}",
            "void __init memblock_free_late(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t cursor, end;",
            "",
            "\tend = base + size - 1;",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\",",
            "\t\t     __func__, &base, &end, (void *)_RET_IP_);",
            "\tkmemleak_free_part_phys(base, size);",
            "\tcursor = PFN_UP(base);",
            "\tend = PFN_DOWN(base + size);",
            "",
            "\tfor (; cursor < end; cursor++) {",
            "\t\tmemblock_free_pages(pfn_to_page(cursor), cursor, 0);",
            "\t\ttotalram_pages_inc();",
            "\t}",
            "}",
            "phys_addr_t __init_memblock memblock_reserved_kern_size(phys_addr_t limit, int nid)",
            "{",
            "\tstruct memblock_region *r;",
            "\tphys_addr_t total = 0;",
            "",
            "\tfor_each_reserved_mem_region(r) {",
            "\t\tphys_addr_t size = r->size;",
            "",
            "\t\tif (r->base > limit)",
            "\t\t\tbreak;",
            "",
            "\t\tif (r->base + r->size > limit)",
            "\t\t\tsize = limit - r->base;",
            "",
            "\t\tif (nid == memblock_get_region_node(r) || !numa_valid_node(nid))",
            "\t\t\tif (r->flags & MEMBLOCK_RSRV_KERN)",
            "\t\t\t\ttotal += size;",
            "\t}",
            "",
            "\treturn total;",
            "}",
            "unsigned long __init memblock_estimated_nr_free_pages(void)",
            "{",
            "\treturn PHYS_PFN(memblock_phys_mem_size() - memblock_reserved_size());",
            "}",
            "static phys_addr_t __init_memblock __find_max_addr(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr = PHYS_ADDR_MAX;",
            "\tstruct memblock_region *r;",
            "",
            "\t/*",
            "\t * translate the memory @limit size into the max address within one of",
            "\t * the memory memblock regions, if the @limit exceeds the total size",
            "\t * of those regions, max_addr will keep original value PHYS_ADDR_MAX",
            "\t */",
            "\tfor_each_mem_region(r) {",
            "\t\tif (limit <= r->size) {",
            "\t\t\tmax_addr = r->base + limit;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tlimit -= r->size;",
            "\t}",
            "",
            "\treturn max_addr;",
            "}",
            "void __init memblock_enforce_memory_limit(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr;",
            "",
            "\tif (!limit)",
            "\t\treturn;",
            "",
            "\tmax_addr = __find_max_addr(limit);",
            "",
            "\t/* @limit exceeds the total size of the memory, do nothing */",
            "\tif (max_addr == PHYS_ADDR_MAX)",
            "\t\treturn;",
            "",
            "\t/* truncate both memory and reserved regions */",
            "\tmemblock_remove_range(&memblock.memory, max_addr,",
            "\t\t\t      PHYS_ADDR_MAX);",
            "\tmemblock_remove_range(&memblock.reserved, max_addr,",
            "\t\t\t      PHYS_ADDR_MAX);",
            "}",
            "void __init memblock_cap_memory_range(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tint start_rgn, end_rgn;",
            "\tint i, ret;",
            "",
            "\tif (!size)",
            "\t\treturn;",
            "",
            "\tif (!memblock_memory->total_size) {",
            "\t\tpr_warn(\"%s: No memory registered yet\\n\", __func__);",
            "\t\treturn;",
            "\t}",
            "",
            "\tret = memblock_isolate_range(&memblock.memory, base, size,",
            "\t\t\t\t\t\t&start_rgn, &end_rgn);",
            "\tif (ret)",
            "\t\treturn;",
            "",
            "\t/* remove all the MAP regions */",
            "\tfor (i = memblock.memory.cnt - 1; i >= end_rgn; i--)",
            "\t\tif (!memblock_is_nomap(&memblock.memory.regions[i]))",
            "\t\t\tmemblock_remove_region(&memblock.memory, i);",
            "",
            "\tfor (i = start_rgn - 1; i >= 0; i--)",
            "\t\tif (!memblock_is_nomap(&memblock.memory.regions[i]))",
            "\t\t\tmemblock_remove_region(&memblock.memory, i);",
            "",
            "\t/* truncate the reserved regions */",
            "\tmemblock_remove_range(&memblock.reserved, 0, base);",
            "\tmemblock_remove_range(&memblock.reserved,",
            "\t\t\tbase + size, PHYS_ADDR_MAX);",
            "}"
          ],
          "function_name": "memblock_phys_alloc_range, memblock_phys_alloc_try_nid, memblock_free_late, memblock_reserved_kern_size, memblock_estimated_nr_free_pages, __find_max_addr, memblock_enforce_memory_limit, memblock_cap_memory_range",
          "description": "实现物理内存分配/释放控制，包含内存上限强制限制、空闲页面估算、内存区域截断等管理功能，支持对保留内存的容量统计",
          "similarity": 0.6085851192474365
        },
        {
          "chunk_id": 12,
          "file_path": "mm/memblock.c",
          "start_line": 2233,
          "end_line": 2340,
          "content": [
            "static void __init __free_pages_memory(unsigned long start, unsigned long end)",
            "{",
            "\tint order;",
            "",
            "\twhile (start < end) {",
            "\t\t/*",
            "\t\t * Free the pages in the largest chunks alignment allows.",
            "\t\t *",
            "\t\t * __ffs() behaviour is undefined for 0. start == 0 is",
            "\t\t * MAX_PAGE_ORDER-aligned, set order to MAX_PAGE_ORDER for",
            "\t\t * the case.",
            "\t\t */",
            "\t\tif (start)",
            "\t\t\torder = min_t(int, MAX_PAGE_ORDER, __ffs(start));",
            "\t\telse",
            "\t\t\torder = MAX_PAGE_ORDER;",
            "",
            "\t\twhile (start + (1UL << order) > end)",
            "\t\t\torder--;",
            "",
            "\t\tmemblock_free_pages(pfn_to_page(start), start, order);",
            "",
            "\t\tstart += (1UL << order);",
            "\t}",
            "}",
            "static unsigned long __init __free_memory_core(phys_addr_t start,",
            "\t\t\t\t phys_addr_t end)",
            "{",
            "\tunsigned long start_pfn = PFN_UP(start);",
            "\tunsigned long end_pfn = min_t(unsigned long,",
            "\t\t\t\t      PFN_DOWN(end), max_low_pfn);",
            "",
            "\tif (start_pfn >= end_pfn)",
            "\t\treturn 0;",
            "",
            "\t__free_pages_memory(start_pfn, end_pfn);",
            "",
            "\treturn end_pfn - start_pfn;",
            "}",
            "static void __init memmap_init_reserved_pages(void)",
            "{",
            "\tstruct memblock_region *region;",
            "\tphys_addr_t start, end;",
            "\tint nid;",
            "\tunsigned long max_reserved;",
            "",
            "\t/*",
            "\t * set nid on all reserved pages and also treat struct",
            "\t * pages for the NOMAP regions as PageReserved",
            "\t */",
            "repeat:",
            "\tmax_reserved = memblock.reserved.max;",
            "\tfor_each_mem_region(region) {",
            "\t\tnid = memblock_get_region_node(region);",
            "\t\tstart = region->base;",
            "\t\tend = start + region->size;",
            "",
            "\t\tif (memblock_is_nomap(region))",
            "\t\t\treserve_bootmem_region(start, end, nid);",
            "",
            "\t\tmemblock_set_node(start, region->size, &memblock.reserved, nid);",
            "\t}",
            "\t/*",
            "\t * 'max' is changed means memblock.reserved has been doubled its",
            "\t * array, which may result a new reserved region before current",
            "\t * 'start'. Now we should repeat the procedure to set its node id.",
            "\t */",
            "\tif (max_reserved != memblock.reserved.max)",
            "\t\tgoto repeat;",
            "",
            "\t/*",
            "\t * initialize struct pages for reserved regions that don't have",
            "\t * the MEMBLOCK_RSRV_NOINIT flag set",
            "\t */",
            "\tfor_each_reserved_mem_region(region) {",
            "\t\tif (!memblock_is_reserved_noinit(region)) {",
            "\t\t\tnid = memblock_get_region_node(region);",
            "\t\t\tstart = region->base;",
            "\t\t\tend = start + region->size;",
            "",
            "\t\t\tif (!numa_valid_node(nid))",
            "\t\t\t\tnid = early_pfn_to_nid(PFN_DOWN(start));",
            "",
            "\t\t\treserve_bootmem_region(start, end, nid);",
            "\t\t}",
            "\t}",
            "}",
            "static unsigned long __init free_low_memory_core_early(void)",
            "{",
            "\tunsigned long count = 0;",
            "\tphys_addr_t start, end;",
            "\tu64 i;",
            "",
            "\tmemblock_clear_hotplug(0, -1);",
            "",
            "\tmemmap_init_reserved_pages();",
            "",
            "\t/*",
            "\t * We need to use NUMA_NO_NODE instead of NODE_DATA(0)->node_id",
            "\t *  because in some case like Node0 doesn't have RAM installed",
            "\t *  low ram will be on Node1",
            "\t */",
            "\tfor_each_free_mem_range(i, NUMA_NO_NODE, MEMBLOCK_NONE, &start, &end,",
            "\t\t\t\tNULL)",
            "\t\tcount += __free_memory_core(start, end);",
            "",
            "\treturn count;",
            "}"
          ],
          "function_name": "__free_pages_memory, __free_memory_core, memmap_init_reserved_pages, free_low_memory_core_early",
          "description": "核心实现内存页面释放逻辑，初始化保留区域页结构并处理低内存核心区域的提前释放操作",
          "similarity": 0.6032471060752869
        },
        {
          "chunk_id": 2,
          "file_path": "mm/memblock.c",
          "start_line": 366,
          "end_line": 506,
          "content": [
            "static void __init_memblock memblock_remove_region(struct memblock_type *type, unsigned long r)",
            "{",
            "\ttype->total_size -= type->regions[r].size;",
            "\tmemmove(&type->regions[r], &type->regions[r + 1],",
            "\t\t(type->cnt - (r + 1)) * sizeof(type->regions[r]));",
            "\ttype->cnt--;",
            "",
            "\t/* Special case for empty arrays */",
            "\tif (type->cnt == 0) {",
            "\t\tWARN_ON(type->total_size != 0);",
            "\t\ttype->cnt = 1;",
            "\t\ttype->regions[0].base = 0;",
            "\t\ttype->regions[0].size = 0;",
            "\t\ttype->regions[0].flags = 0;",
            "\t\tmemblock_set_region_node(&type->regions[0], MAX_NUMNODES);",
            "\t}",
            "}",
            "void __init memblock_discard(void)",
            "{",
            "\tphys_addr_t addr, size;",
            "",
            "\tif (memblock.reserved.regions != memblock_reserved_init_regions) {",
            "\t\taddr = __pa(memblock.reserved.regions);",
            "\t\tsize = PAGE_ALIGN(sizeof(struct memblock_region) *",
            "\t\t\t\t  memblock.reserved.max);",
            "\t\tif (memblock_reserved_in_slab)",
            "\t\t\tkfree(memblock.reserved.regions);",
            "\t\telse",
            "\t\t\tmemblock_free_late(addr, size);",
            "\t}",
            "",
            "\tif (memblock.memory.regions != memblock_memory_init_regions) {",
            "\t\taddr = __pa(memblock.memory.regions);",
            "\t\tsize = PAGE_ALIGN(sizeof(struct memblock_region) *",
            "\t\t\t\t  memblock.memory.max);",
            "\t\tif (memblock_memory_in_slab)",
            "\t\t\tkfree(memblock.memory.regions);",
            "\t\telse",
            "\t\t\tmemblock_free_late(addr, size);",
            "\t}",
            "",
            "\tmemblock_memory = NULL;",
            "}",
            "static int __init_memblock memblock_double_array(struct memblock_type *type,",
            "\t\t\t\t\t\tphys_addr_t new_area_start,",
            "\t\t\t\t\t\tphys_addr_t new_area_size)",
            "{",
            "\tstruct memblock_region *new_array, *old_array;",
            "\tphys_addr_t old_alloc_size, new_alloc_size;",
            "\tphys_addr_t old_size, new_size, addr, new_end;",
            "\tint use_slab = slab_is_available();",
            "\tint *in_slab;",
            "",
            "\t/* We don't allow resizing until we know about the reserved regions",
            "\t * of memory that aren't suitable for allocation",
            "\t */",
            "\tif (!memblock_can_resize)",
            "\t\treturn -1;",
            "",
            "\t/* Calculate new doubled size */",
            "\told_size = type->max * sizeof(struct memblock_region);",
            "\tnew_size = old_size << 1;",
            "\t/*",
            "\t * We need to allocated new one align to PAGE_SIZE,",
            "\t *   so we can free them completely later.",
            "\t */",
            "\told_alloc_size = PAGE_ALIGN(old_size);",
            "\tnew_alloc_size = PAGE_ALIGN(new_size);",
            "",
            "\t/* Retrieve the slab flag */",
            "\tif (type == &memblock.memory)",
            "\t\tin_slab = &memblock_memory_in_slab;",
            "\telse",
            "\t\tin_slab = &memblock_reserved_in_slab;",
            "",
            "\t/* Try to find some space for it */",
            "\tif (use_slab) {",
            "\t\tnew_array = kmalloc(new_size, GFP_KERNEL);",
            "\t\taddr = new_array ? __pa(new_array) : 0;",
            "\t} else {",
            "\t\t/* only exclude range when trying to double reserved.regions */",
            "\t\tif (type != &memblock.reserved)",
            "\t\t\tnew_area_start = new_area_size = 0;",
            "",
            "\t\taddr = memblock_find_in_range(new_area_start + new_area_size,",
            "\t\t\t\t\t\tmemblock.current_limit,",
            "\t\t\t\t\t\tnew_alloc_size, PAGE_SIZE);",
            "\t\tif (!addr && new_area_size)",
            "\t\t\taddr = memblock_find_in_range(0,",
            "\t\t\t\tmin(new_area_start, memblock.current_limit),",
            "\t\t\t\tnew_alloc_size, PAGE_SIZE);",
            "",
            "\t\tif (addr) {",
            "\t\t\t/* The memory may not have been accepted, yet. */",
            "\t\t\taccept_memory(addr, new_alloc_size);",
            "",
            "\t\t\tnew_array = __va(addr);",
            "\t\t} else {",
            "\t\t\tnew_array = NULL;",
            "\t\t}",
            "\t}",
            "\tif (!addr) {",
            "\t\tpr_err(\"memblock: Failed to double %s array from %ld to %ld entries !\\n\",",
            "\t\t       type->name, type->max, type->max * 2);",
            "\t\treturn -1;",
            "\t}",
            "",
            "\tnew_end = addr + new_size - 1;",
            "\tmemblock_dbg(\"memblock: %s is doubled to %ld at [%pa-%pa]\",",
            "\t\t\ttype->name, type->max * 2, &addr, &new_end);",
            "",
            "\t/*",
            "\t * Found space, we now need to move the array over before we add the",
            "\t * reserved region since it may be our reserved array itself that is",
            "\t * full.",
            "\t */",
            "\tmemcpy(new_array, type->regions, old_size);",
            "\tmemset(new_array + type->max, 0, old_size);",
            "\told_array = type->regions;",
            "\ttype->regions = new_array;",
            "\ttype->max <<= 1;",
            "",
            "\t/* Free old array. We needn't free it if the array is the static one */",
            "\tif (*in_slab)",
            "\t\tkfree(old_array);",
            "\telse if (old_array != memblock_memory_init_regions &&",
            "\t\t old_array != memblock_reserved_init_regions)",
            "\t\tmemblock_free(old_array, old_alloc_size);",
            "",
            "\t/*",
            "\t * Reserve the new array if that comes from the memblock.  Otherwise, we",
            "\t * needn't do it",
            "\t */",
            "\tif (!use_slab)",
            "\t\tBUG_ON(memblock_reserve_kern(addr, new_alloc_size));",
            "",
            "\t/* Update slab flag */",
            "\t*in_slab = use_slab;",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "memblock_remove_region, memblock_discard, memblock_double_array",
          "description": "实现内存区域数组的动态扩容（double_array）、旧区域释放（discard）及区域移除操作，维护内存类型总大小统计。",
          "similarity": 0.602973222732544
        }
      ]
    },
    {
      "source_file": "mm/sparse.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:25:01\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sparse.c`\n\n---\n\n# sparse.c 技术文档\n\n## 1. 文件概述\n\n`sparse.c` 是 Linux 内核中实现 **SPARSEMEM（稀疏内存模型）** 的核心文件，用于管理物理内存的稀疏映射。该模型将整个物理地址空间划分为固定大小的“内存段”（memory sections），仅对实际存在的内存段分配 `mem_map`（页描述符数组），从而在支持大物理地址空间的同时节省内存开销。此文件负责内存段的初始化、节点关联、存在性标记以及与内存热插拔和 vmemmap 相关的功能。\n\n## 2. 核心功能\n\n### 主要数据结构\n- **`mem_section`**: 全局内存段数组，每个元素代表一个内存段，存储该段的 `mem_map` 指针及其他元数据。\n  - 在 `CONFIG_SPARSEMEM_EXTREME` 下为二级指针（动态分配根数组）\n  - 否则为静态二维数组 `[NR_SECTION_ROOTS][SECTIONS_PER_ROOT]`\n- **`section_to_node_table`**: （仅当 `NODE_NOT_IN_PAGE_FLAGS` 时）用于通过内存段号查找所属 NUMA 节点的查找表。\n- **`__highest_present_section_nr`**: 记录当前系统中编号最大的已存在内存段，用于优化遍历。\n\n### 主要函数\n- **`memory_present()`**: 标记指定 PFN 范围内的内存段为“存在”，并关联到指定 NUMA 节点。\n- **`memblocks_present()`**: 遍历所有 memblock 内存区域，调用 `memory_present()` 标记所有系统内存。\n- **`sparse_index_init()`**: （仅 `CONFIG_SPARSEMEM_EXTREME`）为指定内存段分配其所在的根数组项。\n- **`sparse_encode_mem_map()` / `sparse_decode_mem_map()`**: 编码/解码 `mem_map` 指针，使其能通过段内偏移计算出实际 PFN。\n- **`subsection_map_init()`**: （仅 `CONFIG_SPARSEMEM_VMEMMAP`）初始化子段（subsection）位图，用于更细粒度的内存管理。\n- **`page_to_nid()`**: （仅 `NODE_NOT_IN_PAGE_FLAGS`）通过页结构获取其所属 NUMA 节点。\n- **`mminit_validate_memmodel_limits()`**: 验证传入的 PFN 范围是否超出 SPARSEMEM 模型支持的最大地址。\n\n### 辅助宏与内联函数\n- **`for_each_present_section_nr()`**: 高效遍历所有已存在的内存段。\n- **`first_present_section_nr()`**: 获取第一个存在的内存段编号。\n- **`sparse_encode_early_nid()` / `sparse_early_nid()`**: 在早期启动阶段利用 `section_mem_map` 字段临时存储 NUMA 节点 ID。\n\n## 3. 关键实现\n\n### 内存段管理\n- 物理内存被划分为 `PAGES_PER_SECTION` 大小的段（通常 128MB）。\n- `mem_section` 数组索引即为段号（section number），通过 `__nr_to_section()` 宏访问。\n- 段的存在性通过 `SECTION_MARKED_PRESENT` 位标记，并维护 `__highest_present_section_nr` 以加速遍历。\n\n### NUMA 节点关联\n- 若页结构体（`struct page`）中未直接存储节点 ID（`NODE_NOT_IN_PAGE_FLAGS`），则使用 `section_to_node_table` 查找。\n- 在 `memory_present()` 中通过 `set_section_nid()` 建立段到节点的映射。\n\n### 动态内存段分配（SPARSEMEM_EXTREME）\n- 为减少静态内存占用，`mem_section` 采用二级结构：\n  - 一级：`mem_section[]` 指向多个二级数组\n  - 二级：每个 `mem_section[root]` 指向 `SECTIONS_PER_ROOT` 个 `struct mem_section`\n- `sparse_index_init()` 在需要时动态分配二级数组（使用 `kzalloc_node` 或 `memblock_alloc_node`）。\n\n### 早期启动阶段的优化\n- 在 `mem_map` 分配前，复用 `section_mem_map` 字段的高位存储 NUMA 节点 ID（`sparse_encode_early_nid()`）。\n- 此信息在分配真实 `mem_map` 前被清除。\n\n### vmemmap 子段支持\n- 当启用 `CONFIG_SPARSEMEM_VMEMMAP` 时，每个内存段进一步划分为子段（subsections）。\n- `subsection_map_init()` 初始化位图，标记哪些子段包含有效内存，支持更灵活的内存热插拔。\n\n### 地址空间验证\n- `mminit_validate_memmodel_limits()` 确保传入的 PFN 范围不超过 `PHYSMEM_END`（SPARSEMEM 模型最大支持地址），防止越界。\n\n## 4. 依赖关系\n\n- **头文件依赖**:\n  - `<linux/mm.h>`, `<linux/mmzone.h>`: 内存管理核心定义\n  - `<linux/memblock.h>`: 早期内存分配器\n  - `<linux/vmalloc.h>`: 用于 vmemmap 映射\n  - `<asm/dma.h>`: 架构相关 DMA 定义\n  - `\"internal.h\"`: MM 子系统内部头文件\n- **配置选项依赖**:\n  - `CONFIG_SPARSEMEM`: 基础稀疏内存模型\n  - `CONFIG_SPARSEMEM_EXTREME`: 动态内存段分配\n  - `CONFIG_SPARSEMEM_VMEMMAP`: 使用虚拟映射的 mem_map\n  - `CONFIG_MEMORY_HOTPLUG`: 内存热插拔支持\n  - `NODE_NOT_IN_PAGE_FLAGS`: 页结构体不包含节点 ID\n- **与其他模块交互**:\n  - **Memory Block (memblock)**: 通过 `for_each_mem_pfn_range()` 获取初始内存布局\n  - **Page Allocator**: 提供 `struct page` 数组（mem_map）\n  - **NUMA Subsystem**: 通过节点 ID 关联内存与 CPU 拓扑\n  - **Memory Hotplug**: 依赖本文件提供的段管理接口进行内存增删\n\n## 5. 使用场景\n\n- **系统启动初始化**:\n  - `memblocks_present()` 在 `mm_init()` 阶段被调用，标记所有固件报告的内存区域为“存在”。\n- **内存热插拔**:\n  - 热添加内存时，调用 `memory_present()` 标记新段；热移除时清理对应段。\n  - `sparse_index_init()` 支持动态扩展 `mem_section` 数组。\n- **页到节点转换**:\n  - 当 `page_to_nid()` 被调用时（如页面迁移、NUMA 调度），通过段查找节点。\n- **vmemmap 优化**:\n  - 在支持 `SPARSEMEM_VMEMMAP` 的架构（如 x86_64, ARM64）上，`subsection_map_init()` 使内核能按子段粒度映射 `struct page`，减少虚拟地址空间占用。\n- **调试与验证**:\n  - `mminit_validate_memmodel_limits()` 在开发阶段捕获内存模型配置错误。",
      "similarity": 0.6404956579208374,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/sparse.c",
          "start_line": 219,
          "end_line": 339,
          "content": [
            "void __init subsection_map_init(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "}",
            "static void __init memory_present(int nid, unsigned long start, unsigned long end)",
            "{",
            "\tunsigned long pfn;",
            "",
            "#ifdef CONFIG_SPARSEMEM_EXTREME",
            "\tif (unlikely(!mem_section)) {",
            "\t\tunsigned long size, align;",
            "",
            "\t\tsize = sizeof(struct mem_section *) * NR_SECTION_ROOTS;",
            "\t\talign = 1 << (INTERNODE_CACHE_SHIFT);",
            "\t\tmem_section = memblock_alloc(size, align);",
            "\t\tif (!mem_section)",
            "\t\t\tpanic(\"%s: Failed to allocate %lu bytes align=0x%lx\\n\",",
            "\t\t\t      __func__, size, align);",
            "\t}",
            "#endif",
            "",
            "\tstart &= PAGE_SECTION_MASK;",
            "\tmminit_validate_memmodel_limits(&start, &end);",
            "\tfor (pfn = start; pfn < end; pfn += PAGES_PER_SECTION) {",
            "\t\tunsigned long section = pfn_to_section_nr(pfn);",
            "\t\tstruct mem_section *ms;",
            "",
            "\t\tsparse_index_init(section, nid);",
            "\t\tset_section_nid(section, nid);",
            "",
            "\t\tms = __nr_to_section(section);",
            "\t\tif (!ms->section_mem_map) {",
            "\t\t\tms->section_mem_map = sparse_encode_early_nid(nid) |",
            "\t\t\t\t\t\t\tSECTION_IS_ONLINE;",
            "\t\t\t__section_mark_present(ms, section);",
            "\t\t}",
            "\t}",
            "}",
            "static void __init memblocks_present(void)",
            "{",
            "\tunsigned long start, end;",
            "\tint i, nid;",
            "",
            "\tfor_each_mem_pfn_range(i, MAX_NUMNODES, &start, &end, &nid)",
            "\t\tmemory_present(nid, start, end);",
            "}",
            "static unsigned long sparse_encode_mem_map(struct page *mem_map, unsigned long pnum)",
            "{",
            "\tunsigned long coded_mem_map =",
            "\t\t(unsigned long)(mem_map - (section_nr_to_pfn(pnum)));",
            "\tBUILD_BUG_ON(SECTION_MAP_LAST_BIT > PFN_SECTION_SHIFT);",
            "\tBUG_ON(coded_mem_map & ~SECTION_MAP_MASK);",
            "\treturn coded_mem_map;",
            "}",
            "static void __meminit sparse_init_one_section(struct mem_section *ms,",
            "\t\tunsigned long pnum, struct page *mem_map,",
            "\t\tstruct mem_section_usage *usage, unsigned long flags)",
            "{",
            "\tms->section_mem_map &= ~SECTION_MAP_MASK;",
            "\tms->section_mem_map |= sparse_encode_mem_map(mem_map, pnum)",
            "\t\t| SECTION_HAS_MEM_MAP | flags;",
            "\tms->usage = usage;",
            "}",
            "static unsigned long usemap_size(void)",
            "{",
            "\treturn BITS_TO_LONGS(SECTION_BLOCKFLAGS_BITS) * sizeof(unsigned long);",
            "}",
            "size_t mem_section_usage_size(void)",
            "{",
            "\treturn sizeof(struct mem_section_usage) + usemap_size();",
            "}",
            "static inline phys_addr_t pgdat_to_phys(struct pglist_data *pgdat)",
            "{",
            "#ifndef CONFIG_NUMA",
            "\tVM_BUG_ON(pgdat != &contig_page_data);",
            "\treturn __pa_symbol(&contig_page_data);",
            "#else",
            "\treturn __pa(pgdat);",
            "#endif",
            "}",
            "static void __init check_usemap_section_nr(int nid,",
            "\t\tstruct mem_section_usage *usage)",
            "{",
            "\tunsigned long usemap_snr, pgdat_snr;",
            "\tstatic unsigned long old_usemap_snr;",
            "\tstatic unsigned long old_pgdat_snr;",
            "\tstruct pglist_data *pgdat = NODE_DATA(nid);",
            "\tint usemap_nid;",
            "",
            "\t/* First call */",
            "\tif (!old_usemap_snr) {",
            "\t\told_usemap_snr = NR_MEM_SECTIONS;",
            "\t\told_pgdat_snr = NR_MEM_SECTIONS;",
            "\t}",
            "",
            "\tusemap_snr = pfn_to_section_nr(__pa(usage) >> PAGE_SHIFT);",
            "\tpgdat_snr = pfn_to_section_nr(pgdat_to_phys(pgdat) >> PAGE_SHIFT);",
            "\tif (usemap_snr == pgdat_snr)",
            "\t\treturn;",
            "",
            "\tif (old_usemap_snr == usemap_snr && old_pgdat_snr == pgdat_snr)",
            "\t\t/* skip redundant message */",
            "\t\treturn;",
            "",
            "\told_usemap_snr = usemap_snr;",
            "\told_pgdat_snr = pgdat_snr;",
            "",
            "\tusemap_nid = sparse_early_nid(__nr_to_section(usemap_snr));",
            "\tif (usemap_nid != nid) {",
            "\t\tpr_info(\"node %d must be removed before remove section %ld\\n\",",
            "\t\t\tnid, usemap_snr);",
            "\t\treturn;",
            "\t}",
            "\t/*",
            "\t * There is a circular dependency.",
            "\t * Some platforms allow un-removable section because they will just",
            "\t * gather other removable sections for dynamic partitioning.",
            "\t * Just notify un-removable section's number here.",
            "\t */",
            "\tpr_info(\"Section %ld and %ld (node %d) have a circular dependency on usemap and pgdat allocations\\n\",",
            "\t\tusemap_snr, pgdat_snr, nid);",
            "}"
          ],
          "function_name": "subsection_map_init, memory_present, memblocks_present, sparse_encode_mem_map, sparse_init_one_section, usemap_size, mem_section_usage_size, pgdat_to_phys, check_usemap_section_nr",
          "description": "实现memory_present标记内存区段为有效，memblocks_present遍历所有内存块执行此操作。提供sparse_encode_mem_map编码内存图，sparse_init_one_section初始化区段结构体。包含使用图大小计算、PGDAT物理地址转换及使用图与PGDAT的依赖检查功能。",
          "similarity": 0.5576674342155457
        },
        {
          "chunk_id": 3,
          "file_path": "mm/sparse.c",
          "start_line": 410,
          "end_line": 527,
          "content": [
            "static void __init check_usemap_section_nr(int nid,",
            "\t\tstruct mem_section_usage *usage)",
            "{",
            "}",
            "static unsigned long __init section_map_size(void)",
            "{",
            "\treturn ALIGN(sizeof(struct page) * PAGES_PER_SECTION, PMD_SIZE);",
            "}",
            "static unsigned long __init section_map_size(void)",
            "{",
            "\treturn PAGE_ALIGN(sizeof(struct page) * PAGES_PER_SECTION);",
            "}",
            "static inline void __meminit sparse_buffer_free(unsigned long size)",
            "{",
            "\tWARN_ON(!sparsemap_buf || size == 0);",
            "\tmemblock_free(sparsemap_buf, size);",
            "}",
            "static void __init sparse_buffer_init(unsigned long size, int nid)",
            "{",
            "\tphys_addr_t addr = __pa(MAX_DMA_ADDRESS);",
            "\tWARN_ON(sparsemap_buf);\t/* forgot to call sparse_buffer_fini()? */",
            "\t/*",
            "\t * Pre-allocated buffer is mainly used by __populate_section_memmap",
            "\t * and we want it to be properly aligned to the section size - this is",
            "\t * especially the case for VMEMMAP which maps memmap to PMDs",
            "\t */",
            "\tsparsemap_buf = memmap_alloc(size, section_map_size(), addr, nid, true);",
            "\tsparsemap_buf_end = sparsemap_buf + size;",
            "}",
            "static void __init sparse_buffer_fini(void)",
            "{",
            "\tunsigned long size = sparsemap_buf_end - sparsemap_buf;",
            "",
            "\tif (sparsemap_buf && size > 0)",
            "\t\tsparse_buffer_free(size);",
            "\tsparsemap_buf = NULL;",
            "}",
            "void __weak __meminit vmemmap_populate_print_last(void)",
            "{",
            "}",
            "static void __init sparse_init_nid(int nid, unsigned long pnum_begin,",
            "\t\t\t\t   unsigned long pnum_end,",
            "\t\t\t\t   unsigned long map_count)",
            "{",
            "\tstruct mem_section_usage *usage;",
            "\tunsigned long pnum;",
            "\tstruct page *map;",
            "",
            "\tusage = sparse_early_usemaps_alloc_pgdat_section(NODE_DATA(nid),",
            "\t\t\tmem_section_usage_size() * map_count);",
            "\tif (!usage) {",
            "\t\tpr_err(\"%s: node[%d] usemap allocation failed\", __func__, nid);",
            "\t\tgoto failed;",
            "\t}",
            "\tsparse_buffer_init(map_count * section_map_size(), nid);",
            "\tfor_each_present_section_nr(pnum_begin, pnum) {",
            "\t\tunsigned long pfn = section_nr_to_pfn(pnum);",
            "",
            "\t\tif (pnum >= pnum_end)",
            "\t\t\tbreak;",
            "",
            "\t\tmap = __populate_section_memmap(pfn, PAGES_PER_SECTION,",
            "\t\t\t\tnid, NULL, NULL);",
            "\t\tif (!map) {",
            "\t\t\tpr_err(\"%s: node[%d] memory map backing failed. Some memory will not be available.\",",
            "\t\t\t       __func__, nid);",
            "\t\t\tpnum_begin = pnum;",
            "\t\t\tsparse_buffer_fini();",
            "\t\t\tgoto failed;",
            "\t\t}",
            "\t\tcheck_usemap_section_nr(nid, usage);",
            "\t\tsparse_init_one_section(__nr_to_section(pnum), pnum, map, usage,",
            "\t\t\t\tSECTION_IS_EARLY);",
            "\t\tusage = (void *) usage + mem_section_usage_size();",
            "\t}",
            "\tsparse_buffer_fini();",
            "\treturn;",
            "failed:",
            "\t/* We failed to allocate, mark all the following pnums as not present */",
            "\tfor_each_present_section_nr(pnum_begin, pnum) {",
            "\t\tstruct mem_section *ms;",
            "",
            "\t\tif (pnum >= pnum_end)",
            "\t\t\tbreak;",
            "\t\tms = __nr_to_section(pnum);",
            "\t\tms->section_mem_map = 0;",
            "\t}",
            "}",
            "void __init sparse_init(void)",
            "{",
            "\tunsigned long pnum_end, pnum_begin, map_count = 1;",
            "\tint nid_begin;",
            "",
            "\tmemblocks_present();",
            "",
            "\tpnum_begin = first_present_section_nr();",
            "\tnid_begin = sparse_early_nid(__nr_to_section(pnum_begin));",
            "",
            "\t/* Setup pageblock_order for HUGETLB_PAGE_SIZE_VARIABLE */",
            "\tset_pageblock_order();",
            "",
            "\tfor_each_present_section_nr(pnum_begin + 1, pnum_end) {",
            "\t\tint nid = sparse_early_nid(__nr_to_section(pnum_end));",
            "",
            "\t\tif (nid == nid_begin) {",
            "\t\t\tmap_count++;",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\t/* Init node with sections in range [pnum_begin, pnum_end) */",
            "\t\tsparse_init_nid(nid_begin, pnum_begin, pnum_end, map_count);",
            "\t\tnid_begin = nid;",
            "\t\tpnum_begin = pnum_end;",
            "\t\tmap_count = 1;",
            "\t}",
            "\t/* cover the last node */",
            "\tsparse_init_nid(nid_begin, pnum_begin, pnum_end, map_count);",
            "\tvmemmap_populate_print_last();",
            "}"
          ],
          "function_name": "check_usemap_section_nr, section_map_size, section_map_size, sparse_buffer_free, sparse_buffer_init, sparse_buffer_fini, vmemmap_populate_print_last, sparse_init_nid, sparse_init",
          "description": "定义section_map_size计算区段映射大小，管理sparse_buffer缓冲区的分配释放。实现sparse_init_nid初始化节点区段，通过__populate_section_memmap填充内存图。包含错误处理逻辑，失败时清除已分配区段标识。",
          "similarity": 0.5413860082626343
        },
        {
          "chunk_id": 1,
          "file_path": "mm/sparse.c",
          "start_line": 46,
          "end_line": 160,
          "content": [
            "int page_to_nid(const struct page *page)",
            "{",
            "\treturn section_to_node_table[page_to_section(page)];",
            "}",
            "static void set_section_nid(unsigned long section_nr, int nid)",
            "{",
            "\tsection_to_node_table[section_nr] = nid;",
            "}",
            "static inline void set_section_nid(unsigned long section_nr, int nid)",
            "{",
            "}",
            "static int __meminit sparse_index_init(unsigned long section_nr, int nid)",
            "{",
            "\tunsigned long root = SECTION_NR_TO_ROOT(section_nr);",
            "\tstruct mem_section *section;",
            "",
            "\t/*",
            "\t * An existing section is possible in the sub-section hotplug",
            "\t * case. First hot-add instantiates, follow-on hot-add reuses",
            "\t * the existing section.",
            "\t *",
            "\t * The mem_hotplug_lock resolves the apparent race below.",
            "\t */",
            "\tif (mem_section[root])",
            "\t\treturn 0;",
            "",
            "\tsection = sparse_index_alloc(nid);",
            "\tif (!section)",
            "\t\treturn -ENOMEM;",
            "",
            "\tmem_section[root] = section;",
            "",
            "\treturn 0;",
            "}",
            "static inline int sparse_index_init(unsigned long section_nr, int nid)",
            "{",
            "\treturn 0;",
            "}",
            "static inline unsigned long sparse_encode_early_nid(int nid)",
            "{",
            "\treturn ((unsigned long)nid << SECTION_NID_SHIFT);",
            "}",
            "static inline int sparse_early_nid(struct mem_section *section)",
            "{",
            "\treturn (section->section_mem_map >> SECTION_NID_SHIFT);",
            "}",
            "static void __meminit mminit_validate_memmodel_limits(unsigned long *start_pfn,",
            "\t\t\t\t\t\tunsigned long *end_pfn)",
            "{",
            "\tunsigned long max_sparsemem_pfn = (PHYSMEM_END + 1) >> PAGE_SHIFT;",
            "",
            "\t/*",
            "\t * Sanity checks - do not allow an architecture to pass",
            "\t * in larger pfns than the maximum scope of sparsemem:",
            "\t */",
            "\tif (*start_pfn > max_sparsemem_pfn) {",
            "\t\tmminit_dprintk(MMINIT_WARNING, \"pfnvalidation\",",
            "\t\t\t\"Start of range %lu -> %lu exceeds SPARSEMEM max %lu\\n\",",
            "\t\t\t*start_pfn, *end_pfn, max_sparsemem_pfn);",
            "\t\tWARN_ON_ONCE(1);",
            "\t\t*start_pfn = max_sparsemem_pfn;",
            "\t\t*end_pfn = max_sparsemem_pfn;",
            "\t} else if (*end_pfn > max_sparsemem_pfn) {",
            "\t\tmminit_dprintk(MMINIT_WARNING, \"pfnvalidation\",",
            "\t\t\t\"End of range %lu -> %lu exceeds SPARSEMEM max %lu\\n\",",
            "\t\t\t*start_pfn, *end_pfn, max_sparsemem_pfn);",
            "\t\tWARN_ON_ONCE(1);",
            "\t\t*end_pfn = max_sparsemem_pfn;",
            "\t}",
            "}",
            "static void __section_mark_present(struct mem_section *ms,",
            "\t\tunsigned long section_nr)",
            "{",
            "\tif (section_nr > __highest_present_section_nr)",
            "\t\t__highest_present_section_nr = section_nr;",
            "",
            "\tms->section_mem_map |= SECTION_MARKED_PRESENT;",
            "}",
            "static inline unsigned long first_present_section_nr(void)",
            "{",
            "\treturn next_present_section_nr(-1);",
            "}",
            "static void subsection_mask_set(unsigned long *map, unsigned long pfn,",
            "\t\tunsigned long nr_pages)",
            "{",
            "\tint idx = subsection_map_index(pfn);",
            "\tint end = subsection_map_index(pfn + nr_pages - 1);",
            "",
            "\tbitmap_set(map, idx, end - idx + 1);",
            "}",
            "void __init subsection_map_init(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "\tint end_sec = pfn_to_section_nr(pfn + nr_pages - 1);",
            "\tunsigned long nr, start_sec = pfn_to_section_nr(pfn);",
            "",
            "\tif (!nr_pages)",
            "\t\treturn;",
            "",
            "\tfor (nr = start_sec; nr <= end_sec; nr++) {",
            "\t\tstruct mem_section *ms;",
            "\t\tunsigned long pfns;",
            "",
            "\t\tpfns = min(nr_pages, PAGES_PER_SECTION",
            "\t\t\t\t- (pfn & ~PAGE_SECTION_MASK));",
            "\t\tms = __nr_to_section(nr);",
            "\t\tsubsection_mask_set(ms->usage->subsection_map, pfn, pfns);",
            "",
            "\t\tpr_debug(\"%s: sec: %lu pfns: %lu set(%d, %d)\\n\", __func__, nr,",
            "\t\t\t\tpfns, subsection_map_index(pfn),",
            "\t\t\t\tsubsection_map_index(pfn + pfns - 1));",
            "",
            "\t\tpfn += pfns;",
            "\t\tnr_pages -= pfns;",
            "\t}",
            "}"
          ],
          "function_name": "page_to_nid, set_section_nid, set_section_nid, sparse_index_init, sparse_index_init, sparse_encode_early_nid, sparse_early_nid, mminit_validate_memmodel_limits, __section_mark_present, first_present_section_nr, subsection_mask_set, subsection_map_init",
          "description": "提供区段与节点号转换接口，包括page_to_nid获取节点号，set_section_nid设置区段节点号。实现sparse_index_init初始化区段结构，包含内存分配和有效性检查。定义sparse_encode_early_nid/nid转换函数，以及内存模型验证和子部分掩码操作函数。",
          "similarity": 0.5351110696792603
        },
        {
          "chunk_id": 4,
          "file_path": "mm/sparse.c",
          "start_line": 592,
          "end_line": 692,
          "content": [
            "void online_mem_sections(unsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tunsigned long pfn;",
            "",
            "\tfor (pfn = start_pfn; pfn < end_pfn; pfn += PAGES_PER_SECTION) {",
            "\t\tunsigned long section_nr = pfn_to_section_nr(pfn);",
            "\t\tstruct mem_section *ms;",
            "",
            "\t\t/* onlining code should never touch invalid ranges */",
            "\t\tif (WARN_ON(!valid_section_nr(section_nr)))",
            "\t\t\tcontinue;",
            "",
            "\t\tms = __nr_to_section(section_nr);",
            "\t\tms->section_mem_map |= SECTION_IS_ONLINE;",
            "\t}",
            "}",
            "void offline_mem_sections(unsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tunsigned long pfn;",
            "",
            "\tfor (pfn = start_pfn; pfn < end_pfn; pfn += PAGES_PER_SECTION) {",
            "\t\tunsigned long section_nr = pfn_to_section_nr(pfn);",
            "\t\tstruct mem_section *ms;",
            "",
            "\t\t/*",
            "\t\t * TODO this needs some double checking. Offlining code makes",
            "\t\t * sure to check pfn_valid but those checks might be just bogus",
            "\t\t */",
            "\t\tif (WARN_ON(!valid_section_nr(section_nr)))",
            "\t\t\tcontinue;",
            "",
            "\t\tms = __nr_to_section(section_nr);",
            "\t\tms->section_mem_map &= ~SECTION_IS_ONLINE;",
            "\t}",
            "}",
            "static void depopulate_section_memmap(unsigned long pfn, unsigned long nr_pages,",
            "\t\tstruct vmem_altmap *altmap)",
            "{",
            "\tunsigned long start = (unsigned long) pfn_to_page(pfn);",
            "\tunsigned long end = start + nr_pages * sizeof(struct page);",
            "",
            "\tvmemmap_free(start, end, altmap);",
            "}",
            "static void free_map_bootmem(struct page *memmap)",
            "{",
            "\tunsigned long start = (unsigned long)memmap;",
            "\tunsigned long end = (unsigned long)(memmap + PAGES_PER_SECTION);",
            "",
            "\tvmemmap_free(start, end, NULL);",
            "}",
            "static int clear_subsection_map(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "\tDECLARE_BITMAP(map, SUBSECTIONS_PER_SECTION) = { 0 };",
            "\tDECLARE_BITMAP(tmp, SUBSECTIONS_PER_SECTION) = { 0 };",
            "\tstruct mem_section *ms = __pfn_to_section(pfn);",
            "\tunsigned long *subsection_map = ms->usage",
            "\t\t? &ms->usage->subsection_map[0] : NULL;",
            "",
            "\tsubsection_mask_set(map, pfn, nr_pages);",
            "\tif (subsection_map)",
            "\t\tbitmap_and(tmp, map, subsection_map, SUBSECTIONS_PER_SECTION);",
            "",
            "\tif (WARN(!subsection_map || !bitmap_equal(tmp, map, SUBSECTIONS_PER_SECTION),",
            "\t\t\t\t\"section already deactivated (%#lx + %ld)\\n\",",
            "\t\t\t\tpfn, nr_pages))",
            "\t\treturn -EINVAL;",
            "",
            "\tbitmap_xor(subsection_map, map, subsection_map, SUBSECTIONS_PER_SECTION);",
            "\treturn 0;",
            "}",
            "static bool is_subsection_map_empty(struct mem_section *ms)",
            "{",
            "\treturn bitmap_empty(&ms->usage->subsection_map[0],",
            "\t\t\t    SUBSECTIONS_PER_SECTION);",
            "}",
            "static int fill_subsection_map(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "\tstruct mem_section *ms = __pfn_to_section(pfn);",
            "\tDECLARE_BITMAP(map, SUBSECTIONS_PER_SECTION) = { 0 };",
            "\tunsigned long *subsection_map;",
            "\tint rc = 0;",
            "",
            "\tsubsection_mask_set(map, pfn, nr_pages);",
            "",
            "\tsubsection_map = &ms->usage->subsection_map[0];",
            "",
            "\tif (bitmap_empty(map, SUBSECTIONS_PER_SECTION))",
            "\t\trc = -EINVAL;",
            "\telse if (bitmap_intersects(map, subsection_map, SUBSECTIONS_PER_SECTION))",
            "\t\trc = -EEXIST;",
            "\telse",
            "\t\tbitmap_or(subsection_map, map, subsection_map,",
            "\t\t\t\tSUBSECTIONS_PER_SECTION);",
            "",
            "\treturn rc;",
            "}",
            "static void depopulate_section_memmap(unsigned long pfn, unsigned long nr_pages,",
            "\t\tstruct vmem_altmap *altmap)",
            "{",
            "\tkvfree(pfn_to_page(pfn));",
            "}"
          ],
          "function_name": "online_mem_sections, offline_mem_sections, depopulate_section_memmap, free_map_bootmem, clear_subsection_map, is_subsection_map_empty, fill_subsection_map, depopulate_section_memmap",
          "description": "提供区段在线/离线操作接口，修改区段在线状态标志。实现depopulate_section_memmap释放内存映射，free_map_bootmem释放启动内存。包含子部分掩码操作函数，用于跟踪和验证内存区域的有效性。",
          "similarity": 0.5271785259246826
        },
        {
          "chunk_id": 0,
          "file_path": "mm/sparse.c",
          "start_line": 1,
          "end_line": 45,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * sparse memory mappings.",
            " */",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/memblock.h>",
            "#include <linux/compiler.h>",
            "#include <linux/highmem.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/swap.h>",
            "#include <linux/swapops.h>",
            "#include <linux/bootmem_info.h>",
            "",
            "#include \"internal.h\"",
            "#include <asm/dma.h>",
            "",
            "/*",
            " * Permanent SPARSEMEM data:",
            " *",
            " * 1) mem_section\t- memory sections, mem_map's for valid memory",
            " */",
            "#ifdef CONFIG_SPARSEMEM_EXTREME",
            "struct mem_section **mem_section;",
            "#else",
            "struct mem_section mem_section[NR_SECTION_ROOTS][SECTIONS_PER_ROOT]",
            "\t____cacheline_internodealigned_in_smp;",
            "#endif",
            "EXPORT_SYMBOL(mem_section);",
            "",
            "#ifdef NODE_NOT_IN_PAGE_FLAGS",
            "/*",
            " * If we did not store the node number in the page then we have to",
            " * do a lookup in the section_to_node_table in order to find which",
            " * node the page belongs to.",
            " */",
            "#if MAX_NUMNODES <= 256",
            "static u8 section_to_node_table[NR_MEM_SECTIONS] __cacheline_aligned;",
            "#else",
            "static u16 section_to_node_table[NR_MEM_SECTIONS] __cacheline_aligned;",
            "#endif",
            ""
          ],
          "function_name": null,
          "description": "定义SPARSEMEM永久数据结构mem_section，用于存储内存区段信息。根据CONFIG_SPARSEMEM_EXTREME配置选择数组形式或指针数组。声明section_to_node_table用于节点号查询，当未在页结构中存储节点号时使用。",
          "similarity": 0.5252794623374939
        }
      ]
    }
  ]
}