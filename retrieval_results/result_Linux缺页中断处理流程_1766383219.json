{
  "query": "Linux缺页中断处理流程",
  "timestamp": "2025-12-22 14:00:19",
  "retrieved_files": [
    {
      "source_file": "mm/memory-failure.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:40:57\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memory-failure.c`\n\n---\n\n# memory-failure.c 技术文档\n\n## 1. 文件概述\n\n`memory-failure.c` 是 Linux 内核中用于处理硬件报告的内存故障（如多比特 ECC 错误）的核心模块。该文件实现了对已损坏物理页的检测、隔离和恢复机制，支持两种主要操作模式：\n- **硬离线（Hard Offline）**：处理已被硬件标记为损坏的页面，通常会导致使用该页的进程被终止\n- **软离线（Soft Offline）**：主动隔离可疑但尚未损坏的页面，避免潜在故障而不杀死进程\n\n该模块需要在不违反虚拟内存子系统正常锁定规则的前提下，异步安全地处理内存错误，确保系统稳定性。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `sysctl_memory_failure_early_kill`：控制是否立即杀死使用损坏页面的进程（0=延迟处理，1=立即杀死）\n- `sysctl_memory_failure_recovery`：启用/禁用内存故障恢复功能（默认启用）\n- `num_poisoned_pages`：原子计数器，记录已标记为有毒（poisoned）的页面数量\n- `hw_memory_failure`：标识是否由硬件直接报告的内存故障\n- `mf_mutex`：保护内存故障处理操作的互斥锁\n\n### 主要函数\n- `num_poisoned_pages_inc()` / `num_poisoned_pages_sub()`：管理有毒页面计数\n- `__page_handle_poison()`：处理大页或空闲页的溶解和从伙伴系统移除\n- `page_handle_poison()`：通用页面毒化处理函数，设置 HWPoison 标志并更新计数\n- `hwpoison_filter_dev()`：基于设备号过滤硬件毒化页面（用于测试）\n- `hwpoison_filter_flags()`：基于页面标志过滤硬件毒化页面（用于测试）\n\n### Sysfs 接口\n通过 `MF_ATTR_RO` 宏定义的只读属性，提供每个 NUMA 节点的内存故障统计信息：\n- `total`：总处理的内存故障数\n- `ignored`：被忽略的故障数\n- `failed`：处理失败的故障数  \n- `delayed`：延迟处理的故障数\n- `recovered`：成功恢复的故障数\n\n## 3. 关键实现\n\n### 页面毒化处理流程\n1. **页面状态识别**：区分大页（hugepage）、空闲页（freepage）和其他类型页面\n2. **大页处理**：调用 `dissolve_free_huge_page()` 溶解大页，然后通过 `drain_all_pages()` 和 `take_page_off_buddy()` 确保页面从伙伴系统移除\n3. **标志设置**：使用 `SetPageHWPoison()` 标记页面为硬件毒化状态\n4. **引用计数管理**：增加页面引用计数并更新全局有毒页面计数器\n\n### 锁定策略\n- 避免使用 `zone_pcp_disable()` 以防止与 CPU 热插拔锁产生死锁\n- 采用标准 VM 锁定规则，即使这意味着错误处理可能耗时较长\n- 使用 `mf_mutex` 保护关键的内存故障处理路径\n\n### 复杂度考量\n- 由于 VM 数据结构的限制，某些操作（如通过 RMAP 反向映射查找进程）具有非线性时间复杂度\n- 基于内存故障的稀有性，接受这种性能开销以避免影响核心 VM 性能\n\n### 开发约束\n新增处理逻辑必须满足：\n- 具备可测试性\n- 能够集成到 mce-test 测试套件\n- 在真实工作负载中属于常见页面状态（page-types 工具 top 10）\n\n## 4. 依赖关系\n\n### 内核头文件依赖\n- **内存管理**：`<linux/mm.h>`, `<linux/page-flags.h>`, `<linux/pagemap.h>`, `<linux/swap.h>`\n- **进程管理**：`<linux/sched/signal.h>`, `<linux/sched/task.h>`\n- **特殊内存类型**：`<linux/hugetlb.h>`, `<linux/dax.h>`, `<linux/ksm.h>`, `<linux/shmem_fs.h>`\n- **系统架构**：`<linux/ras/ras_event.h>`, `<linux/memremap.h>`\n- **内核内部**：`\"swap.h\"`, `\"internal.h\"`\n\n### 功能依赖\n- **RAS（Reliability, Availability, Serviceability）**：通过 ras_event 提供事件通知\n- **内存热插拔**：`memblk_nr_poison_inc/sub` 用于内存块级统计\n- **cgroup 内存控制**：CONFIG_MEMCG 支持基于 memcg 的故障页面过滤\n- **硬件毒化注入**：CONFIG_HWPOISON_INJECT 提供测试框架\n\n## 5. 使用场景\n\n### 硬件内存故障处理\n- 当硬件检测到多比特 ECC 内存错误时，通过 Machine Check Exception (MCE) 机制调用此模块\n- 自动隔离损坏页面，防止数据损坏扩散\n\n### 主动内存维护\n- 系统管理员可通过 `/sys` 接口触发软离线操作，主动替换可疑内存页\n- 用于内存压力测试和预防性维护\n\n### 故障注入测试\n- 通过 `hwpoison_inject` 模块模拟硬件内存故障\n- 支持基于设备号、页面标志和 memcg 的精细过滤，用于针对性测试\n\n### 系统监控和诊断\n- 通过 sysfs 接口提供详细的内存故障统计信息\n- 便于系统管理员监控内存健康状况和故障恢复效果\n\n### 企业级可靠性保障\n- 在高可用服务器环境中，确保单个内存故障不会导致整个系统崩溃\n- 通过可配置的策略（early_kill, recovery）平衡服务连续性和数据完整性",
      "similarity": 0.6386547088623047,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "mm/memory-failure.c",
          "start_line": 919,
          "end_line": 1050,
          "content": [
            "static int delete_from_lru_cache(struct page *p)",
            "{",
            "\tif (isolate_lru_page(p)) {",
            "\t\t/*",
            "\t\t * Clear sensible page flags, so that the buddy system won't",
            "\t\t * complain when the page is unpoison-and-freed.",
            "\t\t */",
            "\t\tClearPageActive(p);",
            "\t\tClearPageUnevictable(p);",
            "",
            "\t\t/*",
            "\t\t * Poisoned page might never drop its ref count to 0 so we have",
            "\t\t * to uncharge it manually from its memcg.",
            "\t\t */",
            "\t\tmem_cgroup_uncharge(page_folio(p));",
            "",
            "\t\t/*",
            "\t\t * drop the page count elevated by isolate_lru_page()",
            "\t\t */",
            "\t\tput_page(p);",
            "\t\treturn 0;",
            "\t}",
            "\treturn -EIO;",
            "}",
            "static int truncate_error_page(struct page *p, unsigned long pfn,",
            "\t\t\t\tstruct address_space *mapping)",
            "{",
            "\tstruct folio *folio = page_folio(p);",
            "\tint ret = MF_FAILED;",
            "",
            "\tif (mapping->a_ops->error_remove_page) {",
            "\t\tint err = mapping->a_ops->error_remove_page(mapping, p);",
            "",
            "\t\tif (err != 0)",
            "\t\t\tpr_info(\"%#lx: Failed to punch page: %d\\n\", pfn, err);",
            "\t\telse if (!filemap_release_folio(folio, GFP_NOIO))",
            "\t\t\tpr_info(\"%#lx: failed to release buffers\\n\", pfn);",
            "\t\telse",
            "\t\t\tret = MF_RECOVERED;",
            "\t} else {",
            "\t\t/*",
            "\t\t * If the file system doesn't support it just invalidate",
            "\t\t * This fails on dirty or anything with private pages",
            "\t\t */",
            "\t\tif (mapping_evict_folio(mapping, folio))",
            "\t\t\tret = MF_RECOVERED;",
            "\t\telse",
            "\t\t\tpr_info(\"%#lx: Failed to invalidate\\n\",\tpfn);",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "static bool has_extra_refcount(struct page_state *ps, struct page *p,",
            "\t\t\t       bool extra_pins)",
            "{",
            "\tint count = page_count(p) - 1;",
            "",
            "\tif (extra_pins)",
            "\t\tcount -= folio_nr_pages(page_folio(p));",
            "",
            "\tif (count > 0) {",
            "\t\tpr_err(\"%#lx: %s still referenced by %d users\\n\",",
            "\t\t       page_to_pfn(p), action_page_types[ps->type], count);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static int me_kernel(struct page_state *ps, struct page *p)",
            "{",
            "\tunlock_page(p);",
            "\treturn MF_IGNORED;",
            "}",
            "static int me_unknown(struct page_state *ps, struct page *p)",
            "{",
            "\tpr_err(\"%#lx: Unknown page state\\n\", page_to_pfn(p));",
            "\tunlock_page(p);",
            "\treturn MF_FAILED;",
            "}",
            "static int me_pagecache_clean(struct page_state *ps, struct page *p)",
            "{",
            "\tint ret;",
            "\tstruct address_space *mapping;",
            "\tbool extra_pins;",
            "",
            "\tdelete_from_lru_cache(p);",
            "",
            "\t/*",
            "\t * For anonymous pages we're done the only reference left",
            "\t * should be the one m_f() holds.",
            "\t */",
            "\tif (PageAnon(p)) {",
            "\t\tret = MF_RECOVERED;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * Now truncate the page in the page cache. This is really",
            "\t * more like a \"temporary hole punch\"",
            "\t * Don't do this for block devices when someone else",
            "\t * has a reference, because it could be file system metadata",
            "\t * and that's not safe to truncate.",
            "\t */",
            "\tmapping = page_mapping(p);",
            "\tif (!mapping) {",
            "\t\t/*",
            "\t\t * Page has been teared down in the meanwhile",
            "\t\t */",
            "\t\tret = MF_FAILED;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * The shmem page is kept in page cache instead of truncating",
            "\t * so is expected to have an extra refcount after error-handling.",
            "\t */",
            "\textra_pins = shmem_mapping(mapping);",
            "",
            "\t/*",
            "\t * Truncation is a bit tricky. Enable it per file system for now.",
            "\t *",
            "\t * Open: to take i_rwsem or not for this? Right now we don't.",
            "\t */",
            "\tret = truncate_error_page(p, page_to_pfn(p), mapping);",
            "\tif (has_extra_refcount(ps, p, extra_pins))",
            "\t\tret = MF_FAILED;",
            "",
            "out:",
            "\tunlock_page(p);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "delete_from_lru_cache, truncate_error_page, has_extra_refcount, me_kernel, me_unknown, me_pagecache_clean",
          "description": "提供内存故障页面清理流程，包括从LRU列表移除、截断页面缓存及检查引用计数的辅助函数",
          "similarity": 0.6833969354629517
        },
        {
          "chunk_id": 7,
          "file_path": "mm/memory-failure.c",
          "start_line": 1088,
          "end_line": 1202,
          "content": [
            "static int me_pagecache_dirty(struct page_state *ps, struct page *p)",
            "{",
            "\tstruct address_space *mapping = page_mapping(p);",
            "",
            "\tSetPageError(p);",
            "\t/* TBD: print more information about the file. */",
            "\tif (mapping) {",
            "\t\t/*",
            "\t\t * IO error will be reported by write(), fsync(), etc.",
            "\t\t * who check the mapping.",
            "\t\t * This way the application knows that something went",
            "\t\t * wrong with its dirty file data.",
            "\t\t *",
            "\t\t * There's one open issue:",
            "\t\t *",
            "\t\t * The EIO will be only reported on the next IO",
            "\t\t * operation and then cleared through the IO map.",
            "\t\t * Normally Linux has two mechanisms to pass IO error",
            "\t\t * first through the AS_EIO flag in the address space",
            "\t\t * and then through the PageError flag in the page.",
            "\t\t * Since we drop pages on memory failure handling the",
            "\t\t * only mechanism open to use is through AS_AIO.",
            "\t\t *",
            "\t\t * This has the disadvantage that it gets cleared on",
            "\t\t * the first operation that returns an error, while",
            "\t\t * the PageError bit is more sticky and only cleared",
            "\t\t * when the page is reread or dropped.  If an",
            "\t\t * application assumes it will always get error on",
            "\t\t * fsync, but does other operations on the fd before",
            "\t\t * and the page is dropped between then the error",
            "\t\t * will not be properly reported.",
            "\t\t *",
            "\t\t * This can already happen even without hwpoisoned",
            "\t\t * pages: first on metadata IO errors (which only",
            "\t\t * report through AS_EIO) or when the page is dropped",
            "\t\t * at the wrong time.",
            "\t\t *",
            "\t\t * So right now we assume that the application DTRT on",
            "\t\t * the first EIO, but we're not worse than other parts",
            "\t\t * of the kernel.",
            "\t\t */",
            "\t\tmapping_set_error(mapping, -EIO);",
            "\t}",
            "",
            "\treturn me_pagecache_clean(ps, p);",
            "}",
            "static int me_swapcache_dirty(struct page_state *ps, struct page *p)",
            "{",
            "\tint ret;",
            "\tbool extra_pins = false;",
            "",
            "\tClearPageDirty(p);",
            "\t/* Trigger EIO in shmem: */",
            "\tClearPageUptodate(p);",
            "",
            "\tret = delete_from_lru_cache(p) ? MF_FAILED : MF_DELAYED;",
            "\tunlock_page(p);",
            "",
            "\tif (ret == MF_DELAYED)",
            "\t\textra_pins = true;",
            "",
            "\tif (has_extra_refcount(ps, p, extra_pins))",
            "\t\tret = MF_FAILED;",
            "",
            "\treturn ret;",
            "}",
            "static int me_swapcache_clean(struct page_state *ps, struct page *p)",
            "{",
            "\tstruct folio *folio = page_folio(p);",
            "\tint ret;",
            "",
            "\tdelete_from_swap_cache(folio);",
            "",
            "\tret = delete_from_lru_cache(p) ? MF_FAILED : MF_RECOVERED;",
            "\tfolio_unlock(folio);",
            "",
            "\tif (has_extra_refcount(ps, p, false))",
            "\t\tret = MF_FAILED;",
            "",
            "\treturn ret;",
            "}",
            "static int me_huge_page(struct page_state *ps, struct page *p)",
            "{",
            "\tstruct folio *folio = page_folio(p);",
            "\tint res;",
            "\tstruct address_space *mapping;",
            "\tbool extra_pins = false;",
            "",
            "\tmapping = folio_mapping(folio);",
            "\tif (mapping) {",
            "\t\tres = truncate_error_page(&folio->page, page_to_pfn(p), mapping);",
            "\t\t/* The page is kept in page cache. */",
            "\t\textra_pins = true;",
            "\t\tfolio_unlock(folio);",
            "\t} else {",
            "\t\tfolio_unlock(folio);",
            "\t\t/*",
            "\t\t * migration entry prevents later access on error hugepage,",
            "\t\t * so we can free and dissolve it into buddy to save healthy",
            "\t\t * subpages.",
            "\t\t */",
            "\t\tfolio_put(folio);",
            "\t\tif (__page_handle_poison(p) > 0) {",
            "\t\t\tpage_ref_inc(p);",
            "\t\t\tres = MF_RECOVERED;",
            "\t\t} else {",
            "\t\t\tres = MF_FAILED;",
            "\t\t}",
            "\t}",
            "",
            "\tif (has_extra_refcount(ps, p, extra_pins))",
            "\t\tres = MF_FAILED;",
            "",
            "\treturn res;",
            "}"
          ],
          "function_name": "me_pagecache_dirty, me_swapcache_dirty, me_swapcache_clean, me_huge_page",
          "description": "针对不同页面状态（脏页/交换缓存/大页）实施差异化处理，设置错误标志并触发生效I/O错误",
          "similarity": 0.658517062664032
        },
        {
          "chunk_id": 14,
          "file_path": "mm/memory-failure.c",
          "start_line": 2186,
          "end_line": 2390,
          "content": [
            "int memory_failure(unsigned long pfn, int flags)",
            "{",
            "\tstruct page *p;",
            "\tstruct folio *folio;",
            "\tstruct dev_pagemap *pgmap;",
            "\tint res = 0;",
            "\tunsigned long page_flags;",
            "\tbool retry = true;",
            "\tint hugetlb = 0;",
            "",
            "\tif (!sysctl_memory_failure_recovery)",
            "\t\tpanic(\"Memory failure on page %lx\", pfn);",
            "",
            "\tmutex_lock(&mf_mutex);",
            "",
            "\tif (!(flags & MF_SW_SIMULATED))",
            "\t\thw_memory_failure = true;",
            "",
            "\tp = pfn_to_online_page(pfn);",
            "\tif (!p) {",
            "\t\tres = arch_memory_failure(pfn, flags);",
            "\t\tif (res == 0)",
            "\t\t\tgoto unlock_mutex;",
            "",
            "\t\tif (pfn_valid(pfn)) {",
            "\t\t\tpgmap = get_dev_pagemap(pfn, NULL);",
            "\t\t\tput_ref_page(pfn, flags);",
            "\t\t\tif (pgmap) {",
            "\t\t\t\tres = memory_failure_dev_pagemap(pfn, flags,",
            "\t\t\t\t\t\t\t\t pgmap);",
            "\t\t\t\tgoto unlock_mutex;",
            "\t\t\t}",
            "\t\t}",
            "\t\tpr_err(\"%#lx: memory outside kernel control\\n\", pfn);",
            "\t\tres = -ENXIO;",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "try_again:",
            "\tres = try_memory_failure_hugetlb(pfn, flags, &hugetlb);",
            "\tif (hugetlb)",
            "\t\tgoto unlock_mutex;",
            "",
            "\tif (TestSetPageHWPoison(p)) {",
            "\t\tpr_err(\"%#lx: already hardware poisoned\\n\", pfn);",
            "\t\tres = -EHWPOISON;",
            "\t\tif (flags & MF_ACTION_REQUIRED)",
            "\t\t\tres = kill_accessing_process(current, pfn, flags);",
            "\t\tif (flags & MF_COUNT_INCREASED)",
            "\t\t\tput_page(p);",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\t/*",
            "\t * We need/can do nothing about count=0 pages.",
            "\t * 1) it's a free page, and therefore in safe hand:",
            "\t *    check_new_page() will be the gate keeper.",
            "\t * 2) it's part of a non-compound high order page.",
            "\t *    Implies some kernel user: cannot stop them from",
            "\t *    R/W the page; let's pray that the page has been",
            "\t *    used and will be freed some time later.",
            "\t * In fact it's dangerous to directly bump up page count from 0,",
            "\t * that may make page_ref_freeze()/page_ref_unfreeze() mismatch.",
            "\t */",
            "\tif (!(flags & MF_COUNT_INCREASED)) {",
            "\t\tres = get_hwpoison_page(p, flags);",
            "\t\tif (!res) {",
            "\t\t\tif (is_free_buddy_page(p)) {",
            "\t\t\t\tif (take_page_off_buddy(p)) {",
            "\t\t\t\t\tpage_ref_inc(p);",
            "\t\t\t\t\tres = MF_RECOVERED;",
            "\t\t\t\t} else {",
            "\t\t\t\t\t/* We lost the race, try again */",
            "\t\t\t\t\tif (retry) {",
            "\t\t\t\t\t\tClearPageHWPoison(p);",
            "\t\t\t\t\t\tretry = false;",
            "\t\t\t\t\t\tgoto try_again;",
            "\t\t\t\t\t}",
            "\t\t\t\t\tres = MF_FAILED;",
            "\t\t\t\t}",
            "\t\t\t\tres = action_result(pfn, MF_MSG_BUDDY, res);",
            "\t\t\t} else {",
            "\t\t\t\tres = action_result(pfn, MF_MSG_KERNEL_HIGH_ORDER, MF_IGNORED);",
            "\t\t\t}",
            "\t\t\tgoto unlock_mutex;",
            "\t\t} else if (res < 0) {",
            "\t\t\tres = action_result(pfn, MF_MSG_UNKNOWN, MF_IGNORED);",
            "\t\t\tgoto unlock_mutex;",
            "\t\t}",
            "\t}",
            "",
            "\tfolio = page_folio(p);",
            "\tif (folio_test_large(folio)) {",
            "\t\t/*",
            "\t\t * The flag must be set after the refcount is bumped",
            "\t\t * otherwise it may race with THP split.",
            "\t\t * And the flag can't be set in get_hwpoison_page() since",
            "\t\t * it is called by soft offline too and it is just called",
            "\t\t * for !MF_COUNT_INCREASED.  So here seems to be the best",
            "\t\t * place.",
            "\t\t *",
            "\t\t * Don't need care about the above error handling paths for",
            "\t\t * get_hwpoison_page() since they handle either free page",
            "\t\t * or unhandlable page.  The refcount is bumped iff the",
            "\t\t * page is a valid handlable page.",
            "\t\t */",
            "\t\tfolio_set_has_hwpoisoned(folio);",
            "\t\tif (try_to_split_thp_page(p) < 0) {",
            "\t\t\tres = action_result(pfn, MF_MSG_UNSPLIT_THP, MF_IGNORED);",
            "\t\t\tgoto unlock_mutex;",
            "\t\t}",
            "\t\tVM_BUG_ON_PAGE(!page_count(p), p);",
            "\t\tfolio = page_folio(p);",
            "\t}",
            "",
            "\t/*",
            "\t * We ignore non-LRU pages for good reasons.",
            "\t * - PG_locked is only well defined for LRU pages and a few others",
            "\t * - to avoid races with __SetPageLocked()",
            "\t * - to avoid races with __SetPageSlab*() (and more non-atomic ops)",
            "\t * The check (unnecessarily) ignores LRU pages being isolated and",
            "\t * walked by the page reclaim code, however that's not a big loss.",
            "\t */",
            "\tshake_folio(folio);",
            "",
            "\tfolio_lock(folio);",
            "",
            "\t/*",
            "\t * We're only intended to deal with the non-Compound page here.",
            "\t * However, the page could have changed compound pages due to",
            "\t * race window. If this happens, we could try again to hopefully",
            "\t * handle the page next round.",
            "\t */",
            "\tif (folio_test_large(folio)) {",
            "\t\tif (retry) {",
            "\t\t\tClearPageHWPoison(p);",
            "\t\t\tfolio_unlock(folio);",
            "\t\t\tfolio_put(folio);",
            "\t\t\tflags &= ~MF_COUNT_INCREASED;",
            "\t\t\tretry = false;",
            "\t\t\tgoto try_again;",
            "\t\t}",
            "\t\tres = action_result(pfn, MF_MSG_DIFFERENT_COMPOUND, MF_IGNORED);",
            "\t\tgoto unlock_page;",
            "\t}",
            "",
            "\t/*",
            "\t * We use page flags to determine what action should be taken, but",
            "\t * the flags can be modified by the error containment action.  One",
            "\t * example is an mlocked page, where PG_mlocked is cleared by",
            "\t * folio_remove_rmap_*() in try_to_unmap_one(). So to determine page",
            "\t * status correctly, we save a copy of the page flags at this time.",
            "\t */",
            "\tpage_flags = folio->flags;",
            "",
            "\tif (hwpoison_filter(p)) {",
            "\t\tClearPageHWPoison(p);",
            "\t\tfolio_unlock(folio);",
            "\t\tfolio_put(folio);",
            "\t\tres = -EOPNOTSUPP;",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\t/*",
            "\t * __munlock_folio() may clear a writeback folio's LRU flag without",
            "\t * the folio lock. We need to wait for writeback completion for this",
            "\t * folio or it may trigger a vfs BUG while evicting inode.",
            "\t */",
            "\tif (!folio_test_lru(folio) && !folio_test_writeback(folio))",
            "\t\tgoto identify_page_state;",
            "",
            "\t/*",
            "\t * It's very difficult to mess with pages currently under IO",
            "\t * and in many cases impossible, so we just avoid it here.",
            "\t */",
            "\tfolio_wait_writeback(folio);",
            "",
            "\t/*",
            "\t * Now take care of user space mappings.",
            "\t * Abort on fail: __filemap_remove_folio() assumes unmapped page.",
            "\t */",
            "\tif (!hwpoison_user_mappings(folio, p, pfn, flags)) {",
            "\t\tres = action_result(pfn, MF_MSG_UNMAP_FAILED, MF_IGNORED);",
            "\t\tgoto unlock_page;",
            "\t}",
            "",
            "\t/*",
            "\t * Torn down by someone else?",
            "\t */",
            "\tif (folio_test_lru(folio) && !folio_test_swapcache(folio) &&",
            "\t    folio->mapping == NULL) {",
            "\t\tres = action_result(pfn, MF_MSG_TRUNCATED_LRU, MF_IGNORED);",
            "\t\tgoto unlock_page;",
            "\t}",
            "",
            "identify_page_state:",
            "\tres = identify_page_state(pfn, p, page_flags);",
            "\tmutex_unlock(&mf_mutex);",
            "\treturn res;",
            "unlock_page:",
            "\tfolio_unlock(folio);",
            "unlock_mutex:",
            "\tmutex_unlock(&mf_mutex);",
            "\treturn res;",
            "}"
          ],
          "function_name": "memory_failure",
          "description": "memory_failure主函数处理内存故障，检查页面有效性，通过不同路径处理普通页、大页和设备页，调用相应处理函数并返回结果",
          "similarity": 0.6179856657981873
        },
        {
          "chunk_id": 5,
          "file_path": "mm/memory-failure.c",
          "start_line": 736,
          "end_line": 851,
          "content": [
            "static void set_to_kill(struct to_kill *tk, unsigned long addr, short shift)",
            "{",
            "\ttk->addr = addr;",
            "\ttk->size_shift = shift;",
            "}",
            "static int check_hwpoisoned_entry(pte_t pte, unsigned long addr, short shift,",
            "\t\t\t\tunsigned long poisoned_pfn, struct to_kill *tk)",
            "{",
            "\tunsigned long pfn = 0;",
            "",
            "\tif (pte_present(pte)) {",
            "\t\tpfn = pte_pfn(pte);",
            "\t} else {",
            "\t\tswp_entry_t swp = pte_to_swp_entry(pte);",
            "",
            "\t\tif (is_hwpoison_entry(swp))",
            "\t\t\tpfn = swp_offset_pfn(swp);",
            "\t}",
            "",
            "\tif (!pfn || pfn != poisoned_pfn)",
            "\t\treturn 0;",
            "",
            "\tset_to_kill(tk, addr, shift);",
            "\treturn 1;",
            "}",
            "static int check_hwpoisoned_pmd_entry(pmd_t *pmdp, unsigned long addr,",
            "\t\t\t\t      struct hwpoison_walk *hwp)",
            "{",
            "\tpmd_t pmd = *pmdp;",
            "\tunsigned long pfn;",
            "\tunsigned long hwpoison_vaddr;",
            "",
            "\tif (!pmd_present(pmd))",
            "\t\treturn 0;",
            "\tpfn = pmd_pfn(pmd);",
            "\tif (pfn <= hwp->pfn && hwp->pfn < pfn + HPAGE_PMD_NR) {",
            "\t\thwpoison_vaddr = addr + ((hwp->pfn - pfn) << PAGE_SHIFT);",
            "\t\tset_to_kill(&hwp->tk, hwpoison_vaddr, PAGE_SHIFT);",
            "\t\treturn 1;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int check_hwpoisoned_pmd_entry(pmd_t *pmdp, unsigned long addr,",
            "\t\t\t\t      struct hwpoison_walk *hwp)",
            "{",
            "\treturn 0;",
            "}",
            "static int hwpoison_pte_range(pmd_t *pmdp, unsigned long addr,",
            "\t\t\t      unsigned long end, struct mm_walk *walk)",
            "{",
            "\tstruct hwpoison_walk *hwp = walk->private;",
            "\tint ret = 0;",
            "\tpte_t *ptep, *mapped_pte;",
            "\tspinlock_t *ptl;",
            "",
            "\tptl = pmd_trans_huge_lock(pmdp, walk->vma);",
            "\tif (ptl) {",
            "\t\tret = check_hwpoisoned_pmd_entry(pmdp, addr, hwp);",
            "\t\tspin_unlock(ptl);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tmapped_pte = ptep = pte_offset_map_lock(walk->vma->vm_mm, pmdp,",
            "\t\t\t\t\t\taddr, &ptl);",
            "\tif (!ptep)",
            "\t\tgoto out;",
            "",
            "\tfor (; addr != end; ptep++, addr += PAGE_SIZE) {",
            "\t\tret = check_hwpoisoned_entry(ptep_get(ptep), addr, PAGE_SHIFT,",
            "\t\t\t\t\t     hwp->pfn, &hwp->tk);",
            "\t\tif (ret == 1)",
            "\t\t\tbreak;",
            "\t}",
            "\tpte_unmap_unlock(mapped_pte, ptl);",
            "out:",
            "\tcond_resched();",
            "\treturn ret;",
            "}",
            "static int hwpoison_hugetlb_range(pte_t *ptep, unsigned long hmask,",
            "\t\t\t    unsigned long addr, unsigned long end,",
            "\t\t\t    struct mm_walk *walk)",
            "{",
            "\tstruct hwpoison_walk *hwp = walk->private;",
            "\tpte_t pte = huge_ptep_get(ptep);",
            "\tstruct hstate *h = hstate_vma(walk->vma);",
            "",
            "\treturn check_hwpoisoned_entry(pte, addr, huge_page_shift(h),",
            "\t\t\t\t      hwp->pfn, &hwp->tk);",
            "}",
            "static int kill_accessing_process(struct task_struct *p, unsigned long pfn,",
            "\t\t\t\t  int flags)",
            "{",
            "\tint ret;",
            "\tstruct hwpoison_walk priv = {",
            "\t\t.pfn = pfn,",
            "\t};",
            "\tpriv.tk.tsk = p;",
            "",
            "\tif (!p->mm)",
            "\t\treturn -EFAULT;",
            "",
            "\tmmap_read_lock(p->mm);",
            "\tret = walk_page_range(p->mm, 0, TASK_SIZE, &hwpoison_walk_ops,",
            "\t\t\t      (void *)&priv);",
            "\t/*",
            "\t * ret = 1 when CMCI wins, regardless of whether try_to_unmap()",
            "\t * succeeds or fails, then kill the process with SIGBUS.",
            "\t * ret = 0 when poison page is a clean page and it's dropped, no",
            "\t * SIGBUS is needed.",
            "\t */",
            "\tif (ret == 1 && priv.tk.addr)",
            "\t\tkill_proc(&priv.tk, pfn, flags);",
            "\tmmap_read_unlock(p->mm);",
            "",
            "\treturn ret > 0 ? -EHWPOISON : 0;",
            "}"
          ],
          "function_name": "set_to_kill, check_hwpoisoned_entry, check_hwpoisoned_pmd_entry, check_hwpoisoned_pmd_entry, hwpoison_pte_range, hwpoison_hugetlb_range, kill_accessing_process",
          "description": "实现硬件中毒页表项检测与进程终止逻辑，通过遍历页表查找中毒页并标记待杀进程",
          "similarity": 0.6153676509857178
        },
        {
          "chunk_id": 13,
          "file_path": "mm/memory-failure.c",
          "start_line": 2042,
          "end_line": 2153,
          "content": [
            "static int try_memory_failure_hugetlb(unsigned long pfn, int flags, int *hugetlb)",
            "{",
            "\tint res;",
            "\tstruct page *p = pfn_to_page(pfn);",
            "\tstruct folio *folio;",
            "\tunsigned long page_flags;",
            "\tbool migratable_cleared = false;",
            "",
            "\t*hugetlb = 1;",
            "retry:",
            "\tres = get_huge_page_for_hwpoison(pfn, flags, &migratable_cleared);",
            "\tif (res == 2) { /* fallback to normal page handling */",
            "\t\t*hugetlb = 0;",
            "\t\treturn 0;",
            "\t} else if (res == -EHWPOISON) {",
            "\t\tpr_err(\"%#lx: already hardware poisoned\\n\", pfn);",
            "\t\tif (flags & MF_ACTION_REQUIRED) {",
            "\t\t\tfolio = page_folio(p);",
            "\t\t\tres = kill_accessing_process(current, folio_pfn(folio), flags);",
            "\t\t}",
            "\t\treturn res;",
            "\t} else if (res == -EBUSY) {",
            "\t\tif (!(flags & MF_NO_RETRY)) {",
            "\t\t\tflags |= MF_NO_RETRY;",
            "\t\t\tgoto retry;",
            "\t\t}",
            "\t\treturn action_result(pfn, MF_MSG_UNKNOWN, MF_IGNORED);",
            "\t}",
            "",
            "\tfolio = page_folio(p);",
            "\tfolio_lock(folio);",
            "",
            "\tif (hwpoison_filter(p)) {",
            "\t\tfolio_clear_hugetlb_hwpoison(folio);",
            "\t\tif (migratable_cleared)",
            "\t\t\tfolio_set_hugetlb_migratable(folio);",
            "\t\tfolio_unlock(folio);",
            "\t\tif (res == 1)",
            "\t\t\tfolio_put(folio);",
            "\t\treturn -EOPNOTSUPP;",
            "\t}",
            "",
            "\t/*",
            "\t * Handling free hugepage.  The possible race with hugepage allocation",
            "\t * or demotion can be prevented by PageHWPoison flag.",
            "\t */",
            "\tif (res == 0) {",
            "\t\tfolio_unlock(folio);",
            "\t\tif (__page_handle_poison(p) > 0) {",
            "\t\t\tpage_ref_inc(p);",
            "\t\t\tres = MF_RECOVERED;",
            "\t\t} else {",
            "\t\t\tres = MF_FAILED;",
            "\t\t}",
            "\t\treturn action_result(pfn, MF_MSG_FREE_HUGE, res);",
            "\t}",
            "",
            "\tpage_flags = folio->flags;",
            "",
            "\tif (!hwpoison_user_mappings(folio, p, pfn, flags)) {",
            "\t\tfolio_unlock(folio);",
            "\t\treturn action_result(pfn, MF_MSG_UNMAP_FAILED, MF_IGNORED);",
            "\t}",
            "",
            "\treturn identify_page_state(pfn, p, page_flags);",
            "}",
            "static inline int try_memory_failure_hugetlb(unsigned long pfn, int flags, int *hugetlb)",
            "{",
            "\treturn 0;",
            "}",
            "static inline unsigned long folio_free_raw_hwp(struct folio *folio, bool flag)",
            "{",
            "\treturn 0;",
            "}",
            "static void put_ref_page(unsigned long pfn, int flags)",
            "{",
            "\tif (!(flags & MF_COUNT_INCREASED))",
            "\t\treturn;",
            "",
            "\tput_page(pfn_to_page(pfn));",
            "}",
            "static int memory_failure_dev_pagemap(unsigned long pfn, int flags,",
            "\t\tstruct dev_pagemap *pgmap)",
            "{",
            "\tint rc = -ENXIO;",
            "",
            "\t/* device metadata space is not recoverable */",
            "\tif (!pgmap_pfn_valid(pgmap, pfn))",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * Call driver's implementation to handle the memory failure, otherwise",
            "\t * fall back to generic handler.",
            "\t */",
            "\tif (pgmap_has_memory_failure(pgmap)) {",
            "\t\trc = pgmap->ops->memory_failure(pgmap, pfn, 1, flags);",
            "\t\t/*",
            "\t\t * Fall back to generic handler too if operation is not",
            "\t\t * supported inside the driver/device/filesystem.",
            "\t\t */",
            "\t\tif (rc != -EOPNOTSUPP)",
            "\t\t\tgoto out;",
            "\t}",
            "",
            "\trc = mf_generic_kill_procs(pfn, flags, pgmap);",
            "out:",
            "\t/* drop pgmap ref acquired in caller */",
            "\tput_dev_pagemap(pgmap);",
            "\tif (rc != -EOPNOTSUPP)",
            "\t\taction_result(pfn, MF_MSG_DAX, rc ? MF_FAILED : MF_RECOVERED);",
            "\treturn rc;",
            "}"
          ],
          "function_name": "try_memory_failure_hugetlb, try_memory_failure_hugetlb, folio_free_raw_hwp, put_ref_page, memory_failure_dev_pagemap",
          "description": "try_memory_failure_hugetlb尝试处理大页HWPOISON，跳转至通用处理；folio_free_raw_hwp空实现；put_ref_page释放引用计数；memory_failure_dev_pagemap调用设备驱动处理HWPOISON页，失败则回退至通用处理",
          "similarity": 0.6128062009811401
        }
      ]
    },
    {
      "source_file": "kernel/irq/spurious.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:09:47\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\spurious.c`\n\n---\n\n# `irq/spurious.c` 技术文档\n\n## 1. 文件概述\n\n`irq/spurious.c` 是 Linux 内核中断子系统中的一个关键组件，负责处理**伪中断**（spurious interrupts）和**错误路由中断**（misrouted interrupts）。当硬件中断未被任何中断处理程序正确处理（返回 `IRQ_NONE`）时，内核会怀疑该中断是伪中断或被错误路由到当前 IRQ 线。该文件实现了检测、诊断和恢复机制，包括：\n\n- 统计未处理中断次数并判断是否为“卡住”的 IRQ\n- 在启用 `irqfixup` 选项时尝试在其他 IRQ 线上查找真正的中断源（中断错位恢复）\n- 定期轮询被禁用的伪中断线以尝试恢复共享中断设备\n- 提供诊断信息（如调用栈和注册的处理函数列表）\n\n该机制对于提高系统在硬件或固件存在缺陷时的鲁棒性至关重要。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `irqfixup`：模块参数，控制伪中断修复行为（0=禁用，1=仅对未处理中断尝试修复，2=对标记为 `IRQF_IRQPOLL` 的中断也尝试修复）\n- `poll_spurious_irq_timer`：定时器，用于定期轮询被标记为 `IRQS_SPURIOUS_DISABLED` 的中断线\n- `irq_poll_cpu`：记录当前正在执行轮询任务的 CPU ID\n- `irq_poll_active`：原子变量，防止多个 CPU 同时执行轮询\n\n### 主要函数\n- `irq_wait_for_poll(struct irq_desc *desc)`  \n  等待轮询操作完成，避免与轮询线程竞争。在 SMP 系统中自旋等待 `IRQS_POLL_INPROGRESS` 标志清除。\n  \n- `try_one_irq(struct irq_desc *desc, bool force)`  \n  尝试在指定中断描述符上执行中断处理。跳过 PER_CPU、嵌套线程和显式标记为轮询的中断。若中断被禁用，则仅在 `force=true` 时处理。支持共享中断的 `IRQS_PENDING` 重试机制。\n\n- `misrouted_irq(int irq)`  \n  遍历所有 IRQ（除 0 和当前 IRQ），调用 `try_one_irq()` 尝试在其他线上找到真正的中断源。用于中断错位恢复。\n\n- `poll_spurious_irqs(struct timer_list *unused)`  \n  定时器回调函数，轮询所有被标记为 `IRQS_SPURIOUS_DISABLED` 的中断线，强制尝试处理（`force=true`）。\n\n- `__report_bad_irq()` / `report_bad_irq()`  \n  打印伪中断诊断信息，包括中断号、错误返回值、调用栈及所有注册的处理函数。\n\n- `try_misrouted_irq()`  \n  根据 `irqfixup` 级别判断是否应尝试中断错位恢复。\n\n- `note_interrupt(struct irq_desc *desc, irqreturn_t action_ret)`  \n  中断处理结果分析入口。统计未处理中断，触发伪中断检测、诊断和恢复逻辑。\n\n## 3. 关键实现\n\n### 伪中断检测机制\n- 当 `note_interrupt()` 收到 `IRQ_NONE` 时，会递增中断描述符的未处理计数。\n- 若在 100,000 次中断中有 99,900 次未处理，则判定该 IRQ “卡住”，打印诊断信息并建议使用 `irqpoll` 启动参数。\n- 诊断信息包含所有注册的处理函数地址及符号名，便于调试。\n\n### 中断错位恢复（Misrouted IRQ Recovery）\n- 通过 `irqfixup` 内核参数启用（启动时传入 `irqfixup=1` 或 `2`）。\n- 当当前 IRQ 未被处理时，遍历其他所有 IRQ 线，尝试调用其处理函数（`try_one_irq()`）。\n- 仅适用于共享中断（`IRQF_SHARED`）且非 PER_CPU/嵌套线程类型。\n- 使用 `IRQS_POLL_INPROGRESS` 标志防止与正常中断处理冲突。\n\n### 轮询恢复机制\n- 被判定为伪中断的 IRQ 会被标记 `IRQS_SPURIOUS_DISABLED` 并禁用。\n- 启用 `irqfixup` 时，启动定时器 `poll_spurious_irq_timer`（间隔 100ms）。\n- 定时器回调 `poll_spurious_irqs()` 遍历所有 `IRQS_SPURIOUS_DISABLED` 的 IRQ，强制尝试处理（即使已禁用）。\n- 通过 `local_irq_disable/enable()` 保证轮询期间本地中断关闭，避免嵌套。\n\n### SMP 安全性\n- 使用 `irq_poll_active` 原子变量确保同一时间仅一个 CPU 执行轮询。\n- `irq_wait_for_poll()` 在 SMP 下自旋等待轮询完成，防止死锁。\n- 所有关键操作均在 `desc->lock` 保护下进行。\n\n### 线程化中断处理支持\n- 若主处理函数返回 `IRQ_WAKE_THREAD`，则延迟伪中断判断至下一次硬件中断，以等待线程处理结果。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/irq.h>`、`<linux/interrupt.h>`：中断核心数据结构和 API\n  - `<linux/timer.h>`：定时器支持（用于轮询）\n  - `\"internals.h\"`：中断子系统内部接口\n\n- **内核配置依赖**：\n  - `CONFIG_SMP`：影响 `irq_wait_for_poll()` 的实现\n  - `irqfixup` 模块参数：控制恢复行为\n\n- **与其他模块交互**：\n  - 被通用中断处理流程（如 `handle_irq_event()`）调用\n  - 与中断描述符管理（`irq_desc`）紧密集成\n  - 依赖内核打印和栈回溯机制（`dump_stack()`）\n\n## 5. 使用场景\n\n1. **硬件/固件缺陷处理**：  \n   当 BIOS 或硬件错误地将设备中断路由到错误的 IRQ 线时，通过 `irqfixup` 机制尝试在其他线上找到真正的处理函数。\n\n2. **共享中断线故障恢复**：  \n   在多个设备共享同一 IRQ 线时，若其中一个设备故障产生持续中断但无处理函数响应，内核可禁用该线并定期轮询，避免系统被中断风暴拖垮。\n\n3. **系统调试与诊断**：  \n   当出现“nobody cared”中断错误时，自动打印详细的处理函数列表和调用栈，帮助开发者定位问题设备或驱动。\n\n4. **高可用性系统**：  \n   在无法立即修复硬件问题的生产环境中，通过 `irqpoll` 启动参数启用轮询机制，维持系统基本运行。\n\n5. **传统 PC 兼容性**：  \n   特别处理 IRQ 0（系统定时器），因其在传统 PC 架构中的特殊地位，即使在 `irqfixup=2` 模式下也始终尝试恢复。",
      "similarity": 0.6361583471298218,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/irq/spurious.c",
          "start_line": 272,
          "end_line": 432,
          "content": [
            "void note_interrupt(struct irq_desc *desc, irqreturn_t action_ret)",
            "{",
            "\tunsigned int irq;",
            "",
            "\tif (desc->istate & IRQS_POLL_INPROGRESS ||",
            "\t    irq_settings_is_polled(desc))",
            "\t\treturn;",
            "",
            "\tif (bad_action_ret(action_ret)) {",
            "\t\treport_bad_irq(desc, action_ret);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/*",
            "\t * We cannot call note_interrupt from the threaded handler",
            "\t * because we need to look at the compound of all handlers",
            "\t * (primary and threaded). Aside of that in the threaded",
            "\t * shared case we have no serialization against an incoming",
            "\t * hardware interrupt while we are dealing with a threaded",
            "\t * result.",
            "\t *",
            "\t * So in case a thread is woken, we just note the fact and",
            "\t * defer the analysis to the next hardware interrupt.",
            "\t *",
            "\t * The threaded handlers store whether they successfully",
            "\t * handled an interrupt and we check whether that number",
            "\t * changed versus the last invocation.",
            "\t *",
            "\t * We could handle all interrupts with the delayed by one",
            "\t * mechanism, but for the non forced threaded case we'd just",
            "\t * add pointless overhead to the straight hardirq interrupts",
            "\t * for the sake of a few lines less code.",
            "\t */",
            "\tif (action_ret & IRQ_WAKE_THREAD) {",
            "\t\t/*",
            "\t\t * There is a thread woken. Check whether one of the",
            "\t\t * shared primary handlers returned IRQ_HANDLED. If",
            "\t\t * not we defer the spurious detection to the next",
            "\t\t * interrupt.",
            "\t\t */",
            "\t\tif (action_ret == IRQ_WAKE_THREAD) {",
            "\t\t\tint handled;",
            "\t\t\t/*",
            "\t\t\t * We use bit 31 of thread_handled_last to",
            "\t\t\t * denote the deferred spurious detection",
            "\t\t\t * active. No locking necessary as",
            "\t\t\t * thread_handled_last is only accessed here",
            "\t\t\t * and we have the guarantee that hard",
            "\t\t\t * interrupts are not reentrant.",
            "\t\t\t */",
            "\t\t\tif (!(desc->threads_handled_last & SPURIOUS_DEFERRED)) {",
            "\t\t\t\tdesc->threads_handled_last |= SPURIOUS_DEFERRED;",
            "\t\t\t\treturn;",
            "\t\t\t}",
            "\t\t\t/*",
            "\t\t\t * Check whether one of the threaded handlers",
            "\t\t\t * returned IRQ_HANDLED since the last",
            "\t\t\t * interrupt happened.",
            "\t\t\t *",
            "\t\t\t * For simplicity we just set bit 31, as it is",
            "\t\t\t * set in threads_handled_last as well. So we",
            "\t\t\t * avoid extra masking. And we really do not",
            "\t\t\t * care about the high bits of the handled",
            "\t\t\t * count. We just care about the count being",
            "\t\t\t * different than the one we saw before.",
            "\t\t\t */",
            "\t\t\thandled = atomic_read(&desc->threads_handled);",
            "\t\t\thandled |= SPURIOUS_DEFERRED;",
            "\t\t\tif (handled != desc->threads_handled_last) {",
            "\t\t\t\taction_ret = IRQ_HANDLED;",
            "\t\t\t\t/*",
            "\t\t\t\t * Note: We keep the SPURIOUS_DEFERRED",
            "\t\t\t\t * bit set. We are handling the",
            "\t\t\t\t * previous invocation right now.",
            "\t\t\t\t * Keep it for the current one, so the",
            "\t\t\t\t * next hardware interrupt will",
            "\t\t\t\t * account for it.",
            "\t\t\t\t */",
            "\t\t\t\tdesc->threads_handled_last = handled;",
            "\t\t\t} else {",
            "\t\t\t\t/*",
            "\t\t\t\t * None of the threaded handlers felt",
            "\t\t\t\t * responsible for the last interrupt",
            "\t\t\t\t *",
            "\t\t\t\t * We keep the SPURIOUS_DEFERRED bit",
            "\t\t\t\t * set in threads_handled_last as we",
            "\t\t\t\t * need to account for the current",
            "\t\t\t\t * interrupt as well.",
            "\t\t\t\t */",
            "\t\t\t\taction_ret = IRQ_NONE;",
            "\t\t\t}",
            "\t\t} else {",
            "\t\t\t/*",
            "\t\t\t * One of the primary handlers returned",
            "\t\t\t * IRQ_HANDLED. So we don't care about the",
            "\t\t\t * threaded handlers on the same line. Clear",
            "\t\t\t * the deferred detection bit.",
            "\t\t\t *",
            "\t\t\t * In theory we could/should check whether the",
            "\t\t\t * deferred bit is set and take the result of",
            "\t\t\t * the previous run into account here as",
            "\t\t\t * well. But it's really not worth the",
            "\t\t\t * trouble. If every other interrupt is",
            "\t\t\t * handled we never trigger the spurious",
            "\t\t\t * detector. And if this is just the one out",
            "\t\t\t * of 100k unhandled ones which is handled",
            "\t\t\t * then we merily delay the spurious detection",
            "\t\t\t * by one hard interrupt. Not a real problem.",
            "\t\t\t */",
            "\t\t\tdesc->threads_handled_last &= ~SPURIOUS_DEFERRED;",
            "\t\t}",
            "\t}",
            "",
            "\tif (unlikely(action_ret == IRQ_NONE)) {",
            "\t\t/*",
            "\t\t * If we are seeing only the odd spurious IRQ caused by",
            "\t\t * bus asynchronicity then don't eventually trigger an error,",
            "\t\t * otherwise the counter becomes a doomsday timer for otherwise",
            "\t\t * working systems",
            "\t\t */",
            "\t\tif (time_after(jiffies, desc->last_unhandled + HZ/10))",
            "\t\t\tdesc->irqs_unhandled = 1;",
            "\t\telse",
            "\t\t\tdesc->irqs_unhandled++;",
            "\t\tdesc->last_unhandled = jiffies;",
            "\t}",
            "",
            "\tirq = irq_desc_get_irq(desc);",
            "\tif (unlikely(try_misrouted_irq(irq, desc, action_ret))) {",
            "\t\tint ok = misrouted_irq(irq);",
            "\t\tif (action_ret == IRQ_NONE)",
            "\t\t\tdesc->irqs_unhandled -= ok;",
            "\t}",
            "",
            "\tif (likely(!desc->irqs_unhandled))",
            "\t\treturn;",
            "",
            "\t/* Now getting into unhandled irq detection */",
            "\tdesc->irq_count++;",
            "\tif (likely(desc->irq_count < 100000))",
            "\t\treturn;",
            "",
            "\tdesc->irq_count = 0;",
            "\tif (unlikely(desc->irqs_unhandled > 99900)) {",
            "\t\t/*",
            "\t\t * The interrupt is stuck",
            "\t\t */",
            "\t\t__report_bad_irq(desc, action_ret);",
            "\t\t/*",
            "\t\t * Now kill the IRQ",
            "\t\t */",
            "\t\tprintk(KERN_EMERG \"Disabling IRQ #%d\\n\", irq);",
            "\t\tdesc->istate |= IRQS_SPURIOUS_DISABLED;",
            "\t\tdesc->depth++;",
            "\t\tirq_disable(desc);",
            "",
            "\t\tmod_timer(&poll_spurious_irq_timer,",
            "\t\t\t  jiffies + POLL_SPURIOUS_IRQ_INTERVAL);",
            "\t}",
            "\tdesc->irqs_unhandled = 0;",
            "}"
          ],
          "function_name": "note_interrupt",
          "description": "note_interrupt记录中断事件，检测未处理中断并触发报告，处理线程唤醒场景下的特殊逻辑。",
          "similarity": 0.5908317565917969
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/spurious.c",
          "start_line": 36,
          "end_line": 136,
          "content": [
            "bool irq_wait_for_poll(struct irq_desc *desc)",
            "\t__must_hold(&desc->lock)",
            "{",
            "\tif (WARN_ONCE(irq_poll_cpu == smp_processor_id(),",
            "\t\t      \"irq poll in progress on cpu %d for irq %d\\n\",",
            "\t\t      smp_processor_id(), desc->irq_data.irq))",
            "\t\treturn false;",
            "",
            "#ifdef CONFIG_SMP",
            "\tdo {",
            "\t\traw_spin_unlock(&desc->lock);",
            "\t\twhile (irqd_irq_inprogress(&desc->irq_data))",
            "\t\t\tcpu_relax();",
            "\t\traw_spin_lock(&desc->lock);",
            "\t} while (irqd_irq_inprogress(&desc->irq_data));",
            "\t/* Might have been disabled in meantime */",
            "\treturn !irqd_irq_disabled(&desc->irq_data) && desc->action;",
            "#else",
            "\treturn false;",
            "#endif",
            "}",
            "static int try_one_irq(struct irq_desc *desc, bool force)",
            "{",
            "\tirqreturn_t ret = IRQ_NONE;",
            "\tstruct irqaction *action;",
            "",
            "\traw_spin_lock(&desc->lock);",
            "",
            "\t/*",
            "\t * PER_CPU, nested thread interrupts and interrupts explicitly",
            "\t * marked polled are excluded from polling.",
            "\t */",
            "\tif (irq_settings_is_per_cpu(desc) ||",
            "\t    irq_settings_is_nested_thread(desc) ||",
            "\t    irq_settings_is_polled(desc))",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * Do not poll disabled interrupts unless the spurious",
            "\t * disabled poller asks explicitly.",
            "\t */",
            "\tif (irqd_irq_disabled(&desc->irq_data) && !force)",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * All handlers must agree on IRQF_SHARED, so we test just the",
            "\t * first.",
            "\t */",
            "\taction = desc->action;",
            "\tif (!action || !(action->flags & IRQF_SHARED) ||",
            "\t    (action->flags & __IRQF_TIMER))",
            "\t\tgoto out;",
            "",
            "\t/* Already running on another processor */",
            "\tif (irqd_irq_inprogress(&desc->irq_data)) {",
            "\t\t/*",
            "\t\t * Already running: If it is shared get the other",
            "\t\t * CPU to go looking for our mystery interrupt too",
            "\t\t */",
            "\t\tdesc->istate |= IRQS_PENDING;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/* Mark it poll in progress */",
            "\tdesc->istate |= IRQS_POLL_INPROGRESS;",
            "\tdo {",
            "\t\tif (handle_irq_event(desc) == IRQ_HANDLED)",
            "\t\t\tret = IRQ_HANDLED;",
            "\t\t/* Make sure that there is still a valid action */",
            "\t\taction = desc->action;",
            "\t} while ((desc->istate & IRQS_PENDING) && action);",
            "\tdesc->istate &= ~IRQS_POLL_INPROGRESS;",
            "out:",
            "\traw_spin_unlock(&desc->lock);",
            "\treturn ret == IRQ_HANDLED;",
            "}",
            "static int misrouted_irq(int irq)",
            "{",
            "\tstruct irq_desc *desc;",
            "\tint i, ok = 0;",
            "",
            "\tif (atomic_inc_return(&irq_poll_active) != 1)",
            "\t\tgoto out;",
            "",
            "\tirq_poll_cpu = smp_processor_id();",
            "",
            "\tfor_each_irq_desc(i, desc) {",
            "\t\tif (!i)",
            "\t\t\t continue;",
            "",
            "\t\tif (i == irq)\t/* Already tried */",
            "\t\t\tcontinue;",
            "",
            "\t\tif (try_one_irq(desc, false))",
            "\t\t\tok = 1;",
            "\t}",
            "out:",
            "\tatomic_dec(&irq_poll_active);",
            "\t/* So the caller can adjust the irq error counts */",
            "\treturn ok;",
            "}"
          ],
          "function_name": "irq_wait_for_poll, try_one_irq, misrouted_irq",
          "description": "实现了irq_wait_for_poll用于等待轮询完成，try_one_irq尝试处理单个中断，misrouted_irq尝试修复误路由中断。",
          "similarity": 0.5663576126098633
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/irq/spurious.c",
          "start_line": 144,
          "end_line": 256,
          "content": [
            "static void poll_spurious_irqs(struct timer_list *unused)",
            "{",
            "\tstruct irq_desc *desc;",
            "\tint i;",
            "",
            "\tif (atomic_inc_return(&irq_poll_active) != 1)",
            "\t\tgoto out;",
            "\tirq_poll_cpu = smp_processor_id();",
            "",
            "\tfor_each_irq_desc(i, desc) {",
            "\t\tunsigned int state;",
            "",
            "\t\tif (!i)",
            "\t\t\t continue;",
            "",
            "\t\t/* Racy but it doesn't matter */",
            "\t\tstate = desc->istate;",
            "\t\tbarrier();",
            "\t\tif (!(state & IRQS_SPURIOUS_DISABLED))",
            "\t\t\tcontinue;",
            "",
            "\t\tlocal_irq_disable();",
            "\t\ttry_one_irq(desc, true);",
            "\t\tlocal_irq_enable();",
            "\t}",
            "out:",
            "\tatomic_dec(&irq_poll_active);",
            "\tmod_timer(&poll_spurious_irq_timer,",
            "\t\t  jiffies + POLL_SPURIOUS_IRQ_INTERVAL);",
            "}",
            "static inline int bad_action_ret(irqreturn_t action_ret)",
            "{",
            "\tunsigned int r = action_ret;",
            "",
            "\tif (likely(r <= (IRQ_HANDLED | IRQ_WAKE_THREAD)))",
            "\t\treturn 0;",
            "\treturn 1;",
            "}",
            "static void __report_bad_irq(struct irq_desc *desc, irqreturn_t action_ret)",
            "{",
            "\tunsigned int irq = irq_desc_get_irq(desc);",
            "\tstruct irqaction *action;",
            "\tunsigned long flags;",
            "",
            "\tif (bad_action_ret(action_ret)) {",
            "\t\tprintk(KERN_ERR \"irq event %d: bogus return value %x\\n\",",
            "\t\t\t\tirq, action_ret);",
            "\t} else {",
            "\t\tprintk(KERN_ERR \"irq %d: nobody cared (try booting with \"",
            "\t\t\t\t\"the \\\"irqpoll\\\" option)\\n\", irq);",
            "\t}",
            "\tdump_stack();",
            "\tprintk(KERN_ERR \"handlers:\\n\");",
            "",
            "\t/*",
            "\t * We need to take desc->lock here. note_interrupt() is called",
            "\t * w/o desc->lock held, but IRQ_PROGRESS set. We might race",
            "\t * with something else removing an action. It's ok to take",
            "\t * desc->lock here. See synchronize_irq().",
            "\t */",
            "\traw_spin_lock_irqsave(&desc->lock, flags);",
            "\tfor_each_action_of_desc(desc, action) {",
            "\t\tprintk(KERN_ERR \"[<%p>] %ps\", action->handler, action->handler);",
            "\t\tif (action->thread_fn)",
            "\t\t\tprintk(KERN_CONT \" threaded [<%p>] %ps\",",
            "\t\t\t\t\taction->thread_fn, action->thread_fn);",
            "\t\tprintk(KERN_CONT \"\\n\");",
            "\t}",
            "\traw_spin_unlock_irqrestore(&desc->lock, flags);",
            "}",
            "static void report_bad_irq(struct irq_desc *desc, irqreturn_t action_ret)",
            "{",
            "\tstatic int count = 100;",
            "",
            "\tif (count > 0) {",
            "\t\tcount--;",
            "\t\t__report_bad_irq(desc, action_ret);",
            "\t}",
            "}",
            "static inline int",
            "try_misrouted_irq(unsigned int irq, struct irq_desc *desc,",
            "\t\t  irqreturn_t action_ret)",
            "{",
            "\tstruct irqaction *action;",
            "",
            "\tif (!irqfixup)",
            "\t\treturn 0;",
            "",
            "\t/* We didn't actually handle the IRQ - see if it was misrouted? */",
            "\tif (action_ret == IRQ_NONE)",
            "\t\treturn 1;",
            "",
            "\t/*",
            "\t * But for 'irqfixup == 2' we also do it for handled interrupts if",
            "\t * they are marked as IRQF_IRQPOLL (or for irq zero, which is the",
            "\t * traditional PC timer interrupt.. Legacy)",
            "\t */",
            "\tif (irqfixup < 2)",
            "\t\treturn 0;",
            "",
            "\tif (!irq)",
            "\t\treturn 1;",
            "",
            "\t/*",
            "\t * Since we don't get the descriptor lock, \"action\" can",
            "\t * change under us.  We don't really care, but we don't",
            "\t * want to follow a NULL pointer. So tell the compiler to",
            "\t * just load it once by using a barrier.",
            "\t */",
            "\taction = desc->action;",
            "\tbarrier();",
            "\treturn action && (action->flags & IRQF_IRQPOLL);",
            "}"
          ],
          "function_name": "poll_spurious_irqs, bad_action_ret, __report_bad_irq, report_bad_irq, try_misrouted_irq",
          "description": "poll_spurious_irqs定时扫描中断描述符并处理疑似虚假中断，包含错误报告辅助函数和误路由检测逻辑。",
          "similarity": 0.5506864786148071
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/irq/spurious.c",
          "start_line": 436,
          "end_line": 467,
          "content": [
            "int noirqdebug_setup(char *str)",
            "{",
            "\tnoirqdebug = 1;",
            "\tprintk(KERN_INFO \"IRQ lockup detection disabled\\n\");",
            "",
            "\treturn 1;",
            "}",
            "static int __init irqfixup_setup(char *str)",
            "{",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT)) {",
            "\t\tpr_warn(\"irqfixup boot option not supported with PREEMPT_RT\\n\");",
            "\t\treturn 1;",
            "\t}",
            "\tirqfixup = 1;",
            "\tprintk(KERN_WARNING \"Misrouted IRQ fixup support enabled.\\n\");",
            "\tprintk(KERN_WARNING \"This may impact system performance.\\n\");",
            "",
            "\treturn 1;",
            "}",
            "static int __init irqpoll_setup(char *str)",
            "{",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT)) {",
            "\t\tpr_warn(\"irqpoll boot option not supported with PREEMPT_RT\\n\");",
            "\t\treturn 1;",
            "\t}",
            "\tirqfixup = 2;",
            "\tprintk(KERN_WARNING \"Misrouted IRQ fixup and polling support \"",
            "\t\t\t\t\"enabled\\n\");",
            "\tprintk(KERN_WARNING \"This may significantly impact system \"",
            "\t\t\t\t\"performance\\n\");",
            "\treturn 1;",
            "}"
          ],
          "function_name": "noirqdebug_setup, irqfixup_setup, irqpoll_setup",
          "description": "提供启动参数配置接口，用于启用或禁用irqfixup和irqpoll功能，并输出相应警告信息。",
          "similarity": 0.502685546875
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/spurious.c",
          "start_line": 1,
          "end_line": 35,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 1992, 1998-2004 Linus Torvalds, Ingo Molnar",
            " *",
            " * This file contains spurious interrupt handling.",
            " */",
            "",
            "#include <linux/jiffies.h>",
            "#include <linux/irq.h>",
            "#include <linux/module.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/timer.h>",
            "",
            "#include \"internals.h\"",
            "",
            "static int irqfixup __read_mostly;",
            "",
            "#define POLL_SPURIOUS_IRQ_INTERVAL (HZ/10)",
            "static void poll_spurious_irqs(struct timer_list *unused);",
            "static DEFINE_TIMER(poll_spurious_irq_timer, poll_spurious_irqs);",
            "static int irq_poll_cpu;",
            "static atomic_t irq_poll_active;",
            "",
            "/*",
            " * We wait here for a poller to finish.",
            " *",
            " * If the poll runs on this CPU, then we yell loudly and return",
            " * false. That will leave the interrupt line disabled in the worst",
            " * case, but it should never happen.",
            " *",
            " * We wait until the poller is done and then recheck disabled and",
            " * action (about to be disabled). Only if it's still active, we return",
            " * true and let the handler run.",
            " */"
          ],
          "function_name": null,
          "description": "定义了处理虚假中断的相关变量和定时器，用于周期性地扫描和处理可能存在的虚假中断。",
          "similarity": 0.4879503846168518
        }
      ]
    },
    {
      "source_file": "mm/userfaultfd.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:30:55\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `userfaultfd.c`\n\n---\n\n# userfaultfd.c 技术文档\n\n## 1. 文件概述\n\n`userfaultfd.c` 是 Linux 内核中实现 **用户态缺页处理（UserfaultFD）** 机制的核心文件之一，位于 `mm/` 子系统目录下。该文件主要负责在发生用户注册的缺页事件（如缺页、写保护等）时，通过原子操作安全地填充目标虚拟内存区域（VMA）的页表项（PTE），从而支持用户空间对缺页事件进行延迟处理或自定义处理。典型应用场景包括内存迁移、检查点/恢复（CRIU）、虚拟机热迁移等。\n\n本文件重点实现了 **原子性内存填充（mfill_atomic）** 相关逻辑，确保在并发环境下对目标 VMA 的 PTE 安装操作是线程安全且语义正确的。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `validate_dst_vma()`  \n  验证目标 VMA 是否有效：检查目标地址范围是否完全包含在 VMA 内，且该 VMA 已注册 userfaultfd 上下文。\n\n- `find_vma_and_prepare_anon()`  \n  在持有 `mmap_lock` 的前提下，查找包含指定地址的 VMA，并为匿名映射预分配 `anon_vma` 结构。\n\n- `uffd_lock_vma()`（仅当 `CONFIG_PER_VMA_LOCK` 启用时）  \n  在不持有 `mmap_lock` 的情况下，通过 RCU 或读写锁安全地查找并锁定目标 VMA。\n\n- `uffd_mfill_lock()` / `uffd_mfill_unlock()`  \n  封装了获取和释放目标 VMA 锁的逻辑，根据是否启用 per-VMA 锁采用不同策略（RCU + VMA 锁 或 全局 mmap_read_lock）。\n\n- `mfill_file_over_size()`  \n  检查目标地址是否超出底层文件的实际大小（用于文件映射场景）。\n\n- `mfill_atomic_install_pte()`  \n  **核心函数**：将指定物理页安装到目标 VMA 的 PTE 中，处理权限（可写、共享）、userfaultfd 写保护标志（`MFILL_ATOMIC_WP`）、反向映射（rmap）和 LRU 管理。\n\n- `mfill_atomic_pte_copy()`  \n  从用户空间源地址拷贝一页数据到新分配的内核页，并调用 `mfill_atomic_install_pte()` 安装该页。\n\n- `mfill_atomic_pte_zeroed_folio()`（未完整展示）  \n  用于安装已清零的页（如处理 `MCOPY_ATOMIC_CONTINUE` 或零页填充）。\n\n### 关键数据结构\n\n- `struct vm_area_struct`：虚拟内存区域描述符，包含 userfaultfd 上下文指针 `vm_userfaultfd_ctx.ctx`。\n- `uffd_flags_t`：传递 userfaultfd 特定标志（如 `MFILL_ATOMIC_WP` 表示需设置 UFFD 写保护位）。\n- `pmd_t *dst_pmd`：指向目标页中间目录项，用于定位 PTE。\n\n## 3. 关键实现\n\n### 原子性与并发控制\n- 支持两种锁模型：\n  - **传统模型**：使用全局 `mmap_read_lock` 保护整个 VMA 查找和操作过程。\n  - **细粒度模型（`CONFIG_PER_VMA_LOCK`）**：优先尝试 RCU 无锁查找 VMA，失败后回退到 `mmap_read_lock`，并在成功路径上使用 per-VMA 读锁（`vm_lock`），提升并发性能。\n- 在拷贝用户数据时临时禁用页错误（`pagefault_disable()`），避免因嵌套 `mmap_lock` 导致死锁。\n\n### PTE 安装逻辑\n- **权限处理**：\n  - 若 VMA 可写且非共享文件映射，则 PTE 不设写权限（防止 COW 问题）。\n  - 若请求写保护（`MFILL_ATOMIC_WP`），则设置 `pte_mkuffd_wp()` 标志位。\n- **反向映射（rmap）**：\n  - 匿名页：调用 `folio_add_new_anon_rmap()` 建立匿名反向映射。\n  - 文件页：调用 `folio_add_file_rmap_pte()` 建立文件反向映射。\n- **内存统计**：通过 `inc_mm_counter()` 更新进程的 RSS 计数器。\n- **安全检查**：\n  - 拒绝覆盖非空 PTE（`!pte_none_mostly()`），但允许覆盖 PTE 标记（如 userfaultfd 缺失标记）。\n  - 对文件映射检查是否越界（`mfill_file_over_size()`）。\n\n### 内存管理\n- 使用 `vma_alloc_folio()` 分配高优先级可移动页。\n- 通过 `mem_cgroup_charge()` 进行内存控制组记账。\n- 正确管理 folio 的 LRU 链表（`folio_add_lru()` / `folio_add_lru_vma()`）和引用计数。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/userfaultfd_k.h>`：提供 userfaultfd 内核接口和标志定义。\n  - `<linux/mmu_notifier.h>`：用于内存管理通知机制。\n  - `<linux/rmap.h>`、`<linux/swap.h>`：反向映射和交换相关操作。\n  - `<asm/tlbflush.h>`：TLB 刷新支持（虽未直接调用，但 `update_mmu_cache()` 可能触发）。\n- **内核子系统**：\n  - **MM 子系统**：深度集成 VMA 管理、页表操作、内存分配、LRU 和 rmap。\n  - **Filesystem**：通过 `shmem_fs.h` 和 `i_size_read()` 支持 tmpfs/shmem 映射。\n  - **HugeTLB**：包含 hugetlb 头文件，为未来扩展预留支持。\n- **配置选项**：\n  - 依赖 `CONFIG_USERFAULTFD`。\n  - 可选支持 `CONFIG_PER_VMA_LOCK`（Linux 6.3+ 引入的细粒度 VMA 锁）。\n\n## 5. 使用场景\n\n- **用户态缺页处理（UserfaultFD）**：\n  - 当进程访问未映射或写保护的内存区域时，内核暂停线程并通知用户态守护进程。\n  - 用户态通过 `UFFDIO_COPY` 或 `UFFDIO_ZEROPAGE` ioctl 请求内核填充页面，触发 `mfill_atomic_*` 系列函数。\n- **检查点/恢复（CRIU）**：\n  - 在恢复过程中，延迟加载内存页，由用户态按需提供内容。\n- **虚拟机/容器热迁移**：\n  - 目标机预先注册 userfaultfd，迁移过程中缺页由源机数据填充。\n- **高性能内存池/垃圾回收**：\n  - 应用程序可拦截缺页以实现自定义内存分配策略。\n\n> 注：本文档基于提供的代码片段生成，`mfill_atomic_pte_zeroed_folio()` 函数体未完整给出，其功能推测为安装预清零页。",
      "similarity": 0.63474440574646,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "mm/userfaultfd.c",
          "start_line": 349,
          "end_line": 459,
          "content": [
            "static int mfill_atomic_pte_zeropage(pmd_t *dst_pmd,",
            "\t\t\t\t     struct vm_area_struct *dst_vma,",
            "\t\t\t\t     unsigned long dst_addr)",
            "{",
            "\tpte_t _dst_pte, *dst_pte;",
            "\tspinlock_t *ptl;",
            "\tint ret;",
            "",
            "\tif (mm_forbids_zeropage(dst_vma->vm_mm))",
            "\t\treturn mfill_atomic_pte_zeroed_folio(dst_pmd, dst_vma, dst_addr);",
            "",
            "\t_dst_pte = pte_mkspecial(pfn_pte(my_zero_pfn(dst_addr),",
            "\t\t\t\t\t dst_vma->vm_page_prot));",
            "\tret = -EAGAIN;",
            "\tdst_pte = pte_offset_map_lock(dst_vma->vm_mm, dst_pmd, dst_addr, &ptl);",
            "\tif (!dst_pte)",
            "\t\tgoto out;",
            "\tif (mfill_file_over_size(dst_vma, dst_addr)) {",
            "\t\tret = -EFAULT;",
            "\t\tgoto out_unlock;",
            "\t}",
            "\tret = -EEXIST;",
            "\tif (!pte_none(ptep_get(dst_pte)))",
            "\t\tgoto out_unlock;",
            "\tset_pte_at(dst_vma->vm_mm, dst_addr, dst_pte, _dst_pte);",
            "\t/* No need to invalidate - it was non-present before */",
            "\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);",
            "\tret = 0;",
            "out_unlock:",
            "\tpte_unmap_unlock(dst_pte, ptl);",
            "out:",
            "\treturn ret;",
            "}",
            "static int mfill_atomic_pte_continue(pmd_t *dst_pmd,",
            "\t\t\t\t     struct vm_area_struct *dst_vma,",
            "\t\t\t\t     unsigned long dst_addr,",
            "\t\t\t\t     uffd_flags_t flags)",
            "{",
            "\tstruct inode *inode = file_inode(dst_vma->vm_file);",
            "\tpgoff_t pgoff = linear_page_index(dst_vma, dst_addr);",
            "\tstruct folio *folio;",
            "\tstruct page *page;",
            "\tint ret;",
            "",
            "\tret = shmem_get_folio(inode, pgoff, 0, &folio, SGP_NOALLOC);",
            "\t/* Our caller expects us to return -EFAULT if we failed to find folio */",
            "\tif (ret == -ENOENT)",
            "\t\tret = -EFAULT;",
            "\tif (ret)",
            "\t\tgoto out;",
            "\tif (!folio) {",
            "\t\tret = -EFAULT;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tpage = folio_file_page(folio, pgoff);",
            "\tif (PageHWPoison(page)) {",
            "\t\tret = -EIO;",
            "\t\tgoto out_release;",
            "\t}",
            "",
            "\tret = mfill_atomic_install_pte(dst_pmd, dst_vma, dst_addr,",
            "\t\t\t\t       page, false, flags);",
            "\tif (ret)",
            "\t\tgoto out_release;",
            "",
            "\tfolio_unlock(folio);",
            "\tret = 0;",
            "out:",
            "\treturn ret;",
            "out_release:",
            "\tfolio_unlock(folio);",
            "\tfolio_put(folio);",
            "\tgoto out;",
            "}",
            "static int mfill_atomic_pte_poison(pmd_t *dst_pmd,",
            "\t\t\t\t   struct vm_area_struct *dst_vma,",
            "\t\t\t\t   unsigned long dst_addr,",
            "\t\t\t\t   uffd_flags_t flags)",
            "{",
            "\tint ret;",
            "\tstruct mm_struct *dst_mm = dst_vma->vm_mm;",
            "\tpte_t _dst_pte, *dst_pte;",
            "\tspinlock_t *ptl;",
            "",
            "\t_dst_pte = make_pte_marker(PTE_MARKER_POISONED);",
            "\tret = -EAGAIN;",
            "\tdst_pte = pte_offset_map_lock(dst_mm, dst_pmd, dst_addr, &ptl);",
            "\tif (!dst_pte)",
            "\t\tgoto out;",
            "",
            "\tif (mfill_file_over_size(dst_vma, dst_addr)) {",
            "\t\tret = -EFAULT;",
            "\t\tgoto out_unlock;",
            "\t}",
            "",
            "\tret = -EEXIST;",
            "\t/* Refuse to overwrite any PTE, even a PTE marker (e.g. UFFD WP). */",
            "\tif (!pte_none(ptep_get(dst_pte)))",
            "\t\tgoto out_unlock;",
            "",
            "\tset_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);",
            "",
            "\t/* No need to invalidate - it was non-present before */",
            "\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);",
            "\tret = 0;",
            "out_unlock:",
            "\tpte_unmap_unlock(dst_pte, ptl);",
            "out:",
            "\treturn ret;",
            "}"
          ],
          "function_name": "mfill_atomic_pte_zeropage, mfill_atomic_pte_continue, mfill_atomic_pte_poison",
          "description": "mfill_atomic_pte_zeropage使用专用零页标记，mfill_atomic_pte_continue从文件系统获取页面，mfill_atomic_pte_poison标记中毒页，三者通过不同策略实现原子化页面填充。",
          "similarity": 0.5770531892776489
        },
        {
          "chunk_id": 8,
          "file_path": "mm/userfaultfd.c",
          "start_line": 1124,
          "end_line": 1333,
          "content": [
            "static int move_pages_pte(struct mm_struct *mm, pmd_t *dst_pmd, pmd_t *src_pmd,",
            "\t\t\t  struct vm_area_struct *dst_vma,",
            "\t\t\t  struct vm_area_struct *src_vma,",
            "\t\t\t  unsigned long dst_addr, unsigned long src_addr,",
            "\t\t\t  __u64 mode)",
            "{",
            "\tswp_entry_t entry;",
            "\tpte_t orig_src_pte, orig_dst_pte;",
            "\tpte_t src_folio_pte;",
            "\tspinlock_t *src_ptl, *dst_ptl;",
            "\tpte_t *src_pte = NULL;",
            "\tpte_t *dst_pte = NULL;",
            "",
            "\tstruct folio *src_folio = NULL;",
            "\tstruct anon_vma *src_anon_vma = NULL;",
            "\tstruct mmu_notifier_range range;",
            "\tint err = 0;",
            "",
            "\tflush_cache_range(src_vma, src_addr, src_addr + PAGE_SIZE);",
            "\tmmu_notifier_range_init(&range, MMU_NOTIFY_CLEAR, 0, mm,",
            "\t\t\t\tsrc_addr, src_addr + PAGE_SIZE);",
            "\tmmu_notifier_invalidate_range_start(&range);",
            "retry:",
            "\tdst_pte = pte_offset_map_nolock(mm, dst_pmd, dst_addr, &dst_ptl);",
            "",
            "\t/* Retry if a huge pmd materialized from under us */",
            "\tif (unlikely(!dst_pte)) {",
            "\t\terr = -EAGAIN;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tsrc_pte = pte_offset_map_nolock(mm, src_pmd, src_addr, &src_ptl);",
            "",
            "\t/*",
            "\t * We held the mmap_lock for reading so MADV_DONTNEED",
            "\t * can zap transparent huge pages under us, or the",
            "\t * transparent huge page fault can establish new",
            "\t * transparent huge pages under us.",
            "\t */",
            "\tif (unlikely(!src_pte)) {",
            "\t\terr = -EAGAIN;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/* Sanity checks before the operation */",
            "\tif (WARN_ON_ONCE(pmd_none(*dst_pmd)) ||\tWARN_ON_ONCE(pmd_none(*src_pmd)) ||",
            "\t    WARN_ON_ONCE(pmd_trans_huge(*dst_pmd)) || WARN_ON_ONCE(pmd_trans_huge(*src_pmd))) {",
            "\t\terr = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tspin_lock(dst_ptl);",
            "\torig_dst_pte = ptep_get(dst_pte);",
            "\tspin_unlock(dst_ptl);",
            "\tif (!pte_none(orig_dst_pte)) {",
            "\t\terr = -EEXIST;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tspin_lock(src_ptl);",
            "\torig_src_pte = ptep_get(src_pte);",
            "\tspin_unlock(src_ptl);",
            "\tif (pte_none(orig_src_pte)) {",
            "\t\tif (!(mode & UFFDIO_MOVE_MODE_ALLOW_SRC_HOLES))",
            "\t\t\terr = -ENOENT;",
            "\t\telse /* nothing to do to move a hole */",
            "\t\t\terr = 0;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/* If PTE changed after we locked the folio them start over */",
            "\tif (src_folio && unlikely(!pte_same(src_folio_pte, orig_src_pte))) {",
            "\t\terr = -EAGAIN;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (pte_present(orig_src_pte)) {",
            "\t\tif (is_zero_pfn(pte_pfn(orig_src_pte))) {",
            "\t\t\terr = move_zeropage_pte(mm, dst_vma, src_vma,",
            "\t\t\t\t\t       dst_addr, src_addr, dst_pte, src_pte,",
            "\t\t\t\t\t       orig_dst_pte, orig_src_pte,",
            "\t\t\t\t\t       dst_ptl, src_ptl);",
            "\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Pin and lock both source folio and anon_vma. Since we are in",
            "\t\t * RCU read section, we can't block, so on contention have to",
            "\t\t * unmap the ptes, obtain the lock and retry.",
            "\t\t */",
            "\t\tif (!src_folio) {",
            "\t\t\tstruct folio *folio;",
            "",
            "\t\t\t/*",
            "\t\t\t * Pin the page while holding the lock to be sure the",
            "\t\t\t * page isn't freed under us",
            "\t\t\t */",
            "\t\t\tspin_lock(src_ptl);",
            "\t\t\tif (!pte_same(orig_src_pte, ptep_get(src_pte))) {",
            "\t\t\t\tspin_unlock(src_ptl);",
            "\t\t\t\terr = -EAGAIN;",
            "\t\t\t\tgoto out;",
            "\t\t\t}",
            "",
            "\t\t\tfolio = vm_normal_folio(src_vma, src_addr, orig_src_pte);",
            "\t\t\tif (!folio || !PageAnonExclusive(&folio->page)) {",
            "\t\t\t\tspin_unlock(src_ptl);",
            "\t\t\t\terr = -EBUSY;",
            "\t\t\t\tgoto out;",
            "\t\t\t}",
            "",
            "\t\t\tfolio_get(folio);",
            "\t\t\tsrc_folio = folio;",
            "\t\t\tsrc_folio_pte = orig_src_pte;",
            "\t\t\tspin_unlock(src_ptl);",
            "",
            "\t\t\tif (!folio_trylock(src_folio)) {",
            "\t\t\t\tpte_unmap(&orig_src_pte);",
            "\t\t\t\tpte_unmap(&orig_dst_pte);",
            "\t\t\t\tsrc_pte = dst_pte = NULL;",
            "\t\t\t\t/* now we can block and wait */",
            "\t\t\t\tfolio_lock(src_folio);",
            "\t\t\t\tgoto retry;",
            "\t\t\t}",
            "",
            "\t\t\tif (WARN_ON_ONCE(!folio_test_anon(src_folio))) {",
            "\t\t\t\terr = -EBUSY;",
            "\t\t\t\tgoto out;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\t/* at this point we have src_folio locked */",
            "\t\tif (folio_test_large(src_folio)) {",
            "\t\t\t/* split_folio() can block */",
            "\t\t\tpte_unmap(&orig_src_pte);",
            "\t\t\tpte_unmap(&orig_dst_pte);",
            "\t\t\tsrc_pte = dst_pte = NULL;",
            "\t\t\terr = split_folio(src_folio);",
            "\t\t\tif (err)",
            "\t\t\t\tgoto out;",
            "\t\t\t/* have to reacquire the folio after it got split */",
            "\t\t\tfolio_unlock(src_folio);",
            "\t\t\tfolio_put(src_folio);",
            "\t\t\tsrc_folio = NULL;",
            "\t\t\tgoto retry;",
            "\t\t}",
            "",
            "\t\tif (!src_anon_vma) {",
            "\t\t\t/*",
            "\t\t\t * folio_referenced walks the anon_vma chain",
            "\t\t\t * without the folio lock. Serialize against it with",
            "\t\t\t * the anon_vma lock, the folio lock is not enough.",
            "\t\t\t */",
            "\t\t\tsrc_anon_vma = folio_get_anon_vma(src_folio);",
            "\t\t\tif (!src_anon_vma) {",
            "\t\t\t\t/* page was unmapped from under us */",
            "\t\t\t\terr = -EAGAIN;",
            "\t\t\t\tgoto out;",
            "\t\t\t}",
            "\t\t\tif (!anon_vma_trylock_write(src_anon_vma)) {",
            "\t\t\t\tpte_unmap(&orig_src_pte);",
            "\t\t\t\tpte_unmap(&orig_dst_pte);",
            "\t\t\t\tsrc_pte = dst_pte = NULL;",
            "\t\t\t\t/* now we can block and wait */",
            "\t\t\t\tanon_vma_lock_write(src_anon_vma);",
            "\t\t\t\tgoto retry;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\terr = move_present_pte(mm,  dst_vma, src_vma,",
            "\t\t\t\t       dst_addr, src_addr, dst_pte, src_pte,",
            "\t\t\t\t       orig_dst_pte, orig_src_pte,",
            "\t\t\t\t       dst_ptl, src_ptl, src_folio);",
            "\t} else {",
            "\t\tentry = pte_to_swp_entry(orig_src_pte);",
            "\t\tif (non_swap_entry(entry)) {",
            "\t\t\tif (is_migration_entry(entry)) {",
            "\t\t\t\tpte_unmap(&orig_src_pte);",
            "\t\t\t\tpte_unmap(&orig_dst_pte);",
            "\t\t\t\tsrc_pte = dst_pte = NULL;",
            "\t\t\t\tmigration_entry_wait(mm, src_pmd, src_addr);",
            "\t\t\t\terr = -EAGAIN;",
            "\t\t\t} else",
            "\t\t\t\terr = -EFAULT;",
            "\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\terr = move_swap_pte(mm, dst_addr, src_addr,",
            "\t\t\t\t    dst_pte, src_pte,",
            "\t\t\t\t    orig_dst_pte, orig_src_pte,",
            "\t\t\t\t    dst_ptl, src_ptl);",
            "\t}",
            "",
            "out:",
            "\tif (src_anon_vma) {",
            "\t\tanon_vma_unlock_write(src_anon_vma);",
            "\t\tput_anon_vma(src_anon_vma);",
            "\t}",
            "\tif (src_folio) {",
            "\t\tfolio_unlock(src_folio);",
            "\t\tfolio_put(src_folio);",
            "\t}",
            "\tif (dst_pte)",
            "\t\tpte_unmap(dst_pte);",
            "\tif (src_pte)",
            "\t\tpte_unmap(src_pte);",
            "\tmmu_notifier_invalidate_range_end(&range);",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "move_pages_pte",
          "description": "move_pages_pte 处理页面迁移核心逻辑，校验页表项有效性，处理大页拆分、交换页迁移、零页填充等场景，协调页表修改与内存管理。",
          "similarity": 0.5664893388748169
        },
        {
          "chunk_id": 0,
          "file_path": "mm/userfaultfd.c",
          "start_line": 1,
          "end_line": 21,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " *  mm/userfaultfd.c",
            " *",
            " *  Copyright (C) 2015  Red Hat, Inc.",
            " */",
            "",
            "#include <linux/mm.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/rmap.h>",
            "#include <linux/swap.h>",
            "#include <linux/swapops.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/shmem_fs.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/tlb.h>",
            "#include \"internal.h\"",
            ""
          ],
          "function_name": null,
          "description": "包含userfaultfd模块所需的头文件和许可证声明，定义了核心结构体及依赖的内核接口，为后续用户空间故障处理功能提供基础支持。",
          "similarity": 0.5549817681312561
        },
        {
          "chunk_id": 2,
          "file_path": "mm/userfaultfd.c",
          "start_line": 241,
          "end_line": 346,
          "content": [
            "static int mfill_atomic_pte_copy(pmd_t *dst_pmd,",
            "\t\t\t\t struct vm_area_struct *dst_vma,",
            "\t\t\t\t unsigned long dst_addr,",
            "\t\t\t\t unsigned long src_addr,",
            "\t\t\t\t uffd_flags_t flags,",
            "\t\t\t\t struct folio **foliop)",
            "{",
            "\tvoid *kaddr;",
            "\tint ret;",
            "\tstruct folio *folio;",
            "",
            "\tif (!*foliop) {",
            "\t\tret = -ENOMEM;",
            "\t\tfolio = vma_alloc_folio(GFP_HIGHUSER_MOVABLE, 0, dst_vma,",
            "\t\t\t\t\tdst_addr, false);",
            "\t\tif (!folio)",
            "\t\t\tgoto out;",
            "",
            "\t\tkaddr = kmap_local_folio(folio, 0);",
            "\t\t/*",
            "\t\t * The read mmap_lock is held here.  Despite the",
            "\t\t * mmap_lock being read recursive a deadlock is still",
            "\t\t * possible if a writer has taken a lock.  For example:",
            "\t\t *",
            "\t\t * process A thread 1 takes read lock on own mmap_lock",
            "\t\t * process A thread 2 calls mmap, blocks taking write lock",
            "\t\t * process B thread 1 takes page fault, read lock on own mmap lock",
            "\t\t * process B thread 2 calls mmap, blocks taking write lock",
            "\t\t * process A thread 1 blocks taking read lock on process B",
            "\t\t * process B thread 1 blocks taking read lock on process A",
            "\t\t *",
            "\t\t * Disable page faults to prevent potential deadlock",
            "\t\t * and retry the copy outside the mmap_lock.",
            "\t\t */",
            "\t\tpagefault_disable();",
            "\t\tret = copy_from_user(kaddr, (const void __user *) src_addr,",
            "\t\t\t\t     PAGE_SIZE);",
            "\t\tpagefault_enable();",
            "\t\tkunmap_local(kaddr);",
            "",
            "\t\t/* fallback to copy_from_user outside mmap_lock */",
            "\t\tif (unlikely(ret)) {",
            "\t\t\tret = -ENOENT;",
            "\t\t\t*foliop = folio;",
            "\t\t\t/* don't free the page */",
            "\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\tflush_dcache_folio(folio);",
            "\t} else {",
            "\t\tfolio = *foliop;",
            "\t\t*foliop = NULL;",
            "\t}",
            "",
            "\t/*",
            "\t * The memory barrier inside __folio_mark_uptodate makes sure that",
            "\t * preceding stores to the page contents become visible before",
            "\t * the set_pte_at() write.",
            "\t */",
            "\t__folio_mark_uptodate(folio);",
            "",
            "\tret = -ENOMEM;",
            "\tif (mem_cgroup_charge(folio, dst_vma->vm_mm, GFP_KERNEL))",
            "\t\tgoto out_release;",
            "",
            "\tret = mfill_atomic_install_pte(dst_pmd, dst_vma, dst_addr,",
            "\t\t\t\t       &folio->page, true, flags);",
            "\tif (ret)",
            "\t\tgoto out_release;",
            "out:",
            "\treturn ret;",
            "out_release:",
            "\tfolio_put(folio);",
            "\tgoto out;",
            "}",
            "static int mfill_atomic_pte_zeroed_folio(pmd_t *dst_pmd,",
            "\t\t\t\t\t struct vm_area_struct *dst_vma,",
            "\t\t\t\t\t unsigned long dst_addr)",
            "{",
            "\tstruct folio *folio;",
            "\tint ret = -ENOMEM;",
            "",
            "\tfolio = vma_alloc_zeroed_movable_folio(dst_vma, dst_addr);",
            "\tif (!folio)",
            "\t\treturn ret;",
            "",
            "\tif (mem_cgroup_charge(folio, dst_vma->vm_mm, GFP_KERNEL))",
            "\t\tgoto out_put;",
            "",
            "\t/*",
            "\t * The memory barrier inside __folio_mark_uptodate makes sure that",
            "\t * zeroing out the folio become visible before mapping the page",
            "\t * using set_pte_at(). See do_anonymous_page().",
            "\t */",
            "\t__folio_mark_uptodate(folio);",
            "",
            "\tret = mfill_atomic_install_pte(dst_pmd, dst_vma, dst_addr,",
            "\t\t\t\t       &folio->page, true, 0);",
            "\tif (ret)",
            "\t\tgoto out_put;",
            "",
            "\treturn 0;",
            "out_put:",
            "\tfolio_put(folio);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "mfill_atomic_pte_copy, mfill_atomic_pte_zeroed_folio",
          "description": "mfill_atomic_pte_copy通过folio分配和用户态拷贝实现页面填充，mfill_atomic_pte_zeroed_folio创建零初始化folio并完成页表映射，均通过原子操作保证内存一致性。",
          "similarity": 0.5403615832328796
        },
        {
          "chunk_id": 6,
          "file_path": "mm/userfaultfd.c",
          "start_line": 865,
          "end_line": 980,
          "content": [
            "ssize_t mfill_atomic_copy(struct userfaultfd_ctx *ctx, unsigned long dst_start,",
            "\t\t\t  unsigned long src_start, unsigned long len,",
            "\t\t\t  uffd_flags_t flags)",
            "{",
            "\treturn mfill_atomic(ctx, dst_start, src_start, len,",
            "\t\t\t    uffd_flags_set_mode(flags, MFILL_ATOMIC_COPY));",
            "}",
            "ssize_t mfill_atomic_zeropage(struct userfaultfd_ctx *ctx,",
            "\t\t\t      unsigned long start,",
            "\t\t\t      unsigned long len)",
            "{",
            "\treturn mfill_atomic(ctx, start, 0, len,",
            "\t\t\t    uffd_flags_set_mode(0, MFILL_ATOMIC_ZEROPAGE));",
            "}",
            "ssize_t mfill_atomic_continue(struct userfaultfd_ctx *ctx, unsigned long start,",
            "\t\t\t      unsigned long len, uffd_flags_t flags)",
            "{",
            "\treturn mfill_atomic(ctx, start, 0, len,",
            "\t\t\t    uffd_flags_set_mode(flags, MFILL_ATOMIC_CONTINUE));",
            "}",
            "ssize_t mfill_atomic_poison(struct userfaultfd_ctx *ctx, unsigned long start,",
            "\t\t\t    unsigned long len, uffd_flags_t flags)",
            "{",
            "\treturn mfill_atomic(ctx, start, 0, len,",
            "\t\t\t    uffd_flags_set_mode(flags, MFILL_ATOMIC_POISON));",
            "}",
            "long uffd_wp_range(struct vm_area_struct *dst_vma,",
            "\t\t   unsigned long start, unsigned long len, bool enable_wp)",
            "{",
            "\tunsigned int mm_cp_flags;",
            "\tstruct mmu_gather tlb;",
            "\tlong ret;",
            "",
            "\tVM_WARN_ONCE(start < dst_vma->vm_start || start + len > dst_vma->vm_end,",
            "\t\t\t\"The address range exceeds VMA boundary.\\n\");",
            "\tif (enable_wp)",
            "\t\tmm_cp_flags = MM_CP_UFFD_WP;",
            "\telse",
            "\t\tmm_cp_flags = MM_CP_UFFD_WP_RESOLVE;",
            "",
            "\t/*",
            "\t * vma->vm_page_prot already reflects that uffd-wp is enabled for this",
            "\t * VMA (see userfaultfd_set_vm_flags()) and that all PTEs are supposed",
            "\t * to be write-protected as default whenever protection changes.",
            "\t * Try upgrading write permissions manually.",
            "\t */",
            "\tif (!enable_wp && vma_wants_manual_pte_write_upgrade(dst_vma))",
            "\t\tmm_cp_flags |= MM_CP_TRY_CHANGE_WRITABLE;",
            "\ttlb_gather_mmu(&tlb, dst_vma->vm_mm);",
            "\tret = change_protection(&tlb, dst_vma, start, start + len, mm_cp_flags);",
            "\ttlb_finish_mmu(&tlb);",
            "",
            "\treturn ret;",
            "}",
            "int mwriteprotect_range(struct userfaultfd_ctx *ctx, unsigned long start,",
            "\t\t\tunsigned long len, bool enable_wp)",
            "{",
            "\tstruct mm_struct *dst_mm = ctx->mm;",
            "\tunsigned long end = start + len;",
            "\tunsigned long _start, _end;",
            "\tstruct vm_area_struct *dst_vma;",
            "\tunsigned long page_mask;",
            "\tlong err;",
            "\tVMA_ITERATOR(vmi, dst_mm, start);",
            "",
            "\t/*",
            "\t * Sanitize the command parameters:",
            "\t */",
            "\tBUG_ON(start & ~PAGE_MASK);",
            "\tBUG_ON(len & ~PAGE_MASK);",
            "",
            "\t/* Does the address range wrap, or is the span zero-sized? */",
            "\tBUG_ON(start + len <= start);",
            "",
            "\tmmap_read_lock(dst_mm);",
            "",
            "\t/*",
            "\t * If memory mappings are changing because of non-cooperative",
            "\t * operation (e.g. mremap) running in parallel, bail out and",
            "\t * request the user to retry later",
            "\t */",
            "\tdown_read(&ctx->map_changing_lock);",
            "\terr = -EAGAIN;",
            "\tif (atomic_read(&ctx->mmap_changing))",
            "\t\tgoto out_unlock;",
            "",
            "\terr = -ENOENT;",
            "\tfor_each_vma_range(vmi, dst_vma, end) {",
            "",
            "\t\tif (!userfaultfd_wp(dst_vma)) {",
            "\t\t\terr = -ENOENT;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tif (is_vm_hugetlb_page(dst_vma)) {",
            "\t\t\terr = -EINVAL;",
            "\t\t\tpage_mask = vma_kernel_pagesize(dst_vma) - 1;",
            "\t\t\tif ((start & page_mask) || (len & page_mask))",
            "\t\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\t_start = max(dst_vma->vm_start, start);",
            "\t\t_end = min(dst_vma->vm_end, end);",
            "",
            "\t\terr = uffd_wp_range(dst_vma, _start, _end - _start, enable_wp);",
            "",
            "\t\t/* Return 0 on success, <0 on failures */",
            "\t\tif (err < 0)",
            "\t\t\tbreak;",
            "\t\terr = 0;",
            "\t}",
            "out_unlock:",
            "\tup_read(&ctx->map_changing_lock);",
            "\tmmap_read_unlock(dst_mm);",
            "\treturn err;",
            "}"
          ],
          "function_name": "mfill_atomic_copy, mfill_atomic_zeropage, mfill_atomic_continue, mfill_atomic_poison, uffd_wp_range, mwriteprotect_range",
          "description": "mfill_atomic 系列函数封装不同填充模式（copy/zeropage/continue/poison），uffd_wp_range/mwriteprotect_range 实现用户faultfd 写保护范围的设置与验证，处理页表保护状态变更。",
          "similarity": 0.535949170589447
        }
      ]
    }
  ]
}