{
  "query": "OOM killer触发条件与内存回收",
  "timestamp": "2025-12-20 19:37:16",
  "retrieved_files": [
    {
      "source_file": "mm/oom_kill.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:58:11\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `oom_kill.c`\n\n---\n\n# oom_kill.c 技术文档\n\n## 1. 文件概述\n\n`oom_kill.c` 是 Linux 内核内存管理子系统中的关键组件，负责在系统严重内存不足（Out-Of-Memory, OOM）时选择并终止一个或多个进程，以释放内存资源、防止系统崩溃。该文件实现了 OOM Killer 的核心逻辑，包括候选进程的选择策略、内存压力评估、以及与内存控制组（memcg）、NUMA 策略、cpuset 等子系统的集成。OOM Killer 通常由 `__alloc_pages()` 在无法满足内存分配请求时触发。\n\n## 2. 核心功能\n\n### 主要函数\n- **`out_of_memory()`**：OOM Killer 的主入口函数（虽未在片段中完整显示，但为本文件核心）\n- **`oom_badness()`**：计算进程“坏度”（badness）分数的核心启发式函数，用于决定哪个进程最应被杀死\n- **`find_lock_task_mm()`**：在进程及其线程组中查找具有有效内存描述符（`mm_struct`）的可杀任务，并加锁\n- **`oom_unkillable_task()`**：判断某任务是否不可被 OOM Killer 杀死（如 init 进程、内核线程）\n- **`constrained_alloc()`**：确定当前内存分配所受的约束类型（如 memcg、cpuset、mempolicy）\n- **`oom_cpuset_eligible()`**（仅 CONFIG_NUMA）：在 NUMA 系统中检查任务是否符合 cpuset 或 mempolicy 的 OOM 杀死条件\n- **`should_dump_unreclaim_slab()`**：判断是否因不可回收 slab 内存过多而触发 OOM，用于辅助诊断\n\n### 关键数据结构\n- **`struct oom_control`**：封装 OOM 事件上下文，包括分配标志（`gfp_mask`）、节点掩码（`nodemask`）、内存控制组（`memcg`）、分配阶数（`order`）等\n- **`enum oom_constraint`**：表示内存分配受限的类型（`CONSTRAINT_NONE`、`CONSTRAINT_CPUSET`、`CONSTRAINT_MEMORY_POLICY`、`CONSTRAINT_MEMCG`）\n\n### 全局变量\n- **`sysctl_panic_on_oom`**：控制 OOM 时是否直接 panic\n- **`sysctl_oom_kill_allocating_task`**：若置位，则优先杀死触发 OOM 的进程\n- **`sysctl_oom_dump_tasks`**：控制 OOM 时是否打印所有任务的内存使用信息\n- **`oom_lock`**：互斥锁，序列化 OOM Killer 调用，防止并发过度杀进程\n- **`oom_adj_mutex`**：互斥锁，保护 `oom_score_adj` 和 `oom_score_adj_min` 的更新\n\n## 3. 关键实现\n\n### OOM 坏度评分算法 (`oom_badness`)\n- **基础分值**：基于进程的 RSS（Resident Set Size）、交换页数量（`MM_SWAPENTS`）和页表占用内存（`mm_pgtables_bytes`），单位为页数。\n- **调整因子**：通过 `oom_score_adj`（范围 [-1000, 1000]）进行线性调整。调整量 = `oom_score_adj * totalpages / 1000`，其中 `totalpages` 为当前 OOM 上下文允许的最大内存页数（全局或 memcg 限制）。\n- **排除规则**：\n  - 全局 init 进程（PID 1）和内核线程（`PF_KTHREAD`）不可杀。\n  - 显式设置 `oom_score_adj = OOM_SCORE_ADJ_MIN (-1000)` 的进程不可杀。\n  - 已被标记跳过（`MMF_OOM_SKIP`）或处于 `vfork` 中间状态的进程不可杀。\n- **返回值**：`LONG_MIN` 表示不可杀；否则返回综合评分，值越大越优先被杀。\n\n### 内存分配约束识别 (`constrained_alloc`)\n- **Memcg OOM**：若 `oc->memcg` 非空，则 `totalpages` 设为 memcg 的内存上限，约束类型为 `CONSTRAINT_MEMCG`。\n- **全局 OOM**：默认 `totalpages = totalram_pages + total_swap_pages`。\n- **NUMA 约束**：\n  - 若分配请求指定 `__GFP_THISNODE`，视为无特殊约束（避免杀死当前进程）。\n  - 若存在非全集的 `nodemask`（来自 mempolicy），则 `totalpages` 仅统计该 nodemask 覆盖节点的内存，约束类型为 `CONSTRAINT_MEMORY_POLICY`。\n  - Cpuset 约束由页面分配器处理，此处不直接计算。\n\n### 多线程与内存描述符处理 (`find_lock_task_mm`)\n- 遍历目标进程的整个线程组（`for_each_thread`），寻找任一仍持有有效 `mm_struct` 的线程。\n- 对找到的线程加 `task_lock` 并返回，确保在检查其内存状态时不会被释放。\n- 适用于主线程已退出但子线程仍在运行的场景。\n\n### NUMA 可杀性检查 (`oom_cpuset_eligible`)\n- 在 NUMA 系统中，仅当候选任务与触发 OOM 的当前任务在内存策略（mempolicy）或 cpuset 允许的节点集上有交集时，才视为可杀。\n- 若 OOM 由 mempolicy 触发（`oc->nodemask` 非空），则仅检查 mempolicy 交集。\n- 否则，检查 cpuset 的 `mems_allowed` 交集。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm.h>`、`<linux/gfp.h>`、`<linux/swap.h>` 获取内存状态、分配标志和交换信息。\n- **进程调度与管理**：依赖 `<linux/sched.h>` 及相关头文件访问任务结构、线程组、cpuset 和内存策略。\n- **内存控制组 (cgroup v2)**：通过 `<linux/memcontrol.h>` 集成 memcg，支持容器级 OOM。\n- **安全模块**：通过 `<linux/security.h>` 调用 LSM 钩子（如 `security_oom_kill()`）。\n- **调试与追踪**：使用 ftrace (`<linux/ftrace.h>`) 和自定义 tracepoint (`trace/events/oom.h`) 记录 OOM 事件。\n- **体系结构相关**：包含 `<asm/tlb.h>` 处理 TLB 刷新。\n- **内部 MM 实现**：包含 `\"internal.h\"` 和 `\"slab.h\"` 访问内核私有内存管理接口。\n\n## 5. 使用场景\n\n- **全局内存耗尽**：当系统整体可用内存（含 swap）低于临界阈值，且无法通过页面回收释放足够内存时，由页面分配器调用 `out_of_memory()`。\n- **Memcg 内存超限**：当某个 memory cgroup 的内存使用超过其配额时，触发该 cgroup 内的 OOM Killer。\n- **SysRq 触发**：通过 Magic SysRq 键（`Alt+SysRq+f`）手动触发 OOM Killer，此时 `oc->order = -1`。\n- **诊断辅助**：当不可回收 slab 内存（如内核对象缓存）异常增长导致 OOM 时，`should_dump_unreclaim_slab()` 可触发 slab 信息转储以辅助调试。\n- **策略约束下的 OOM**：在 NUMA 系统中，受 cpuset 或 mempolicy 限制的进程在局部节点内存耗尽时触发针对性 OOM。",
      "similarity": 0.6930886507034302,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "mm/oom_kill.c",
          "start_line": 496,
          "end_line": 624,
          "content": [
            "bool process_shares_mm(struct task_struct *p, struct mm_struct *mm)",
            "{",
            "\tstruct task_struct *t;",
            "",
            "\tfor_each_thread(p, t) {",
            "\t\tstruct mm_struct *t_mm = READ_ONCE(t->mm);",
            "\t\tif (t_mm)",
            "\t\t\treturn t_mm == mm;",
            "\t}",
            "\treturn false;",
            "}",
            "static bool __oom_reap_task_mm(struct mm_struct *mm)",
            "{",
            "\tstruct vm_area_struct *vma;",
            "\tbool ret = true;",
            "\tVMA_ITERATOR(vmi, mm, 0);",
            "",
            "\t/*",
            "\t * Tell all users of get_user/copy_from_user etc... that the content",
            "\t * is no longer stable. No barriers really needed because unmapping",
            "\t * should imply barriers already and the reader would hit a page fault",
            "\t * if it stumbled over a reaped memory.",
            "\t */",
            "\tset_bit(MMF_UNSTABLE, &mm->flags);",
            "",
            "\tfor_each_vma(vmi, vma) {",
            "\t\tif (vma->vm_flags & (VM_HUGETLB|VM_PFNMAP))",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * Only anonymous pages have a good chance to be dropped",
            "\t\t * without additional steps which we cannot afford as we",
            "\t\t * are OOM already.",
            "\t\t *",
            "\t\t * We do not even care about fs backed pages because all",
            "\t\t * which are reclaimable have already been reclaimed and",
            "\t\t * we do not want to block exit_mmap by keeping mm ref",
            "\t\t * count elevated without a good reason.",
            "\t\t */",
            "\t\tif (vma_is_anonymous(vma) || !(vma->vm_flags & VM_SHARED)) {",
            "\t\t\tstruct mmu_notifier_range range;",
            "\t\t\tstruct mmu_gather tlb;",
            "",
            "\t\t\tmmu_notifier_range_init(&range, MMU_NOTIFY_UNMAP, 0,",
            "\t\t\t\t\t\tmm, vma->vm_start,",
            "\t\t\t\t\t\tvma->vm_end);",
            "\t\t\ttlb_gather_mmu(&tlb, mm);",
            "\t\t\tif (mmu_notifier_invalidate_range_start_nonblock(&range)) {",
            "\t\t\t\ttlb_finish_mmu(&tlb);",
            "\t\t\t\tret = false;",
            "\t\t\t\tcontinue;",
            "\t\t\t}",
            "\t\t\tunmap_page_range(&tlb, vma, range.start, range.end, NULL);",
            "\t\t\tmmu_notifier_invalidate_range_end(&range);",
            "\t\t\ttlb_finish_mmu(&tlb);",
            "\t\t}",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "static bool oom_reap_task_mm(struct task_struct *tsk, struct mm_struct *mm)",
            "{",
            "\tbool ret = true;",
            "",
            "\tif (!mmap_read_trylock(mm)) {",
            "\t\ttrace_skip_task_reaping(tsk->pid);",
            "\t\treturn false;",
            "\t}",
            "",
            "\t/*",
            "\t * MMF_OOM_SKIP is set by exit_mmap when the OOM reaper can't",
            "\t * work on the mm anymore. The check for MMF_OOM_SKIP must run",
            "\t * under mmap_lock for reading because it serializes against the",
            "\t * mmap_write_lock();mmap_write_unlock() cycle in exit_mmap().",
            "\t */",
            "\tif (test_bit(MMF_OOM_SKIP, &mm->flags)) {",
            "\t\ttrace_skip_task_reaping(tsk->pid);",
            "\t\tgoto out_unlock;",
            "\t}",
            "",
            "\ttrace_start_task_reaping(tsk->pid);",
            "",
            "\t/* failed to reap part of the address space. Try again later */",
            "\tret = __oom_reap_task_mm(mm);",
            "\tif (!ret)",
            "\t\tgoto out_finish;",
            "",
            "\tpr_info(\"oom_reaper: reaped process %d (%s), now anon-rss:%lukB, file-rss:%lukB, shmem-rss:%lukB\\n\",",
            "\t\t\ttask_pid_nr(tsk), tsk->comm,",
            "\t\t\tK(get_mm_counter(mm, MM_ANONPAGES)),",
            "\t\t\tK(get_mm_counter(mm, MM_FILEPAGES)),",
            "\t\t\tK(get_mm_counter(mm, MM_SHMEMPAGES)));",
            "out_finish:",
            "\ttrace_finish_task_reaping(tsk->pid);",
            "out_unlock:",
            "\tmmap_read_unlock(mm);",
            "",
            "\treturn ret;",
            "}",
            "static void oom_reap_task(struct task_struct *tsk)",
            "{",
            "\tint attempts = 0;",
            "\tstruct mm_struct *mm = tsk->signal->oom_mm;",
            "",
            "\t/* Retry the mmap_read_trylock(mm) a few times */",
            "\twhile (attempts++ < MAX_OOM_REAP_RETRIES && !oom_reap_task_mm(tsk, mm))",
            "\t\tschedule_timeout_idle(HZ/10);",
            "",
            "\tif (attempts <= MAX_OOM_REAP_RETRIES ||",
            "\t    test_bit(MMF_OOM_SKIP, &mm->flags))",
            "\t\tgoto done;",
            "",
            "\tpr_info(\"oom_reaper: unable to reap pid:%d (%s)\\n\",",
            "\t\ttask_pid_nr(tsk), tsk->comm);",
            "\tsched_show_task(tsk);",
            "\tdebug_show_all_locks();",
            "",
            "done:",
            "\ttsk->oom_reaper_list = NULL;",
            "",
            "\t/*",
            "\t * Hide this mm from OOM killer because it has been either reaped or",
            "\t * somebody can't call mmap_write_unlock(mm).",
            "\t */",
            "\tset_bit(MMF_OOM_SKIP, &mm->flags);",
            "",
            "\t/* Drop a reference taken by queue_oom_reaper */",
            "\tput_task_struct(tsk);",
            "}"
          ],
          "function_name": "process_shares_mm, __oom_reap_task_mm, oom_reap_task_mm, oom_reap_task",
          "description": "通过强制解除地址空间映射、清除MMF_OOM_SKIP标志等方式尝试回收选定进程的内存资源，最终标记该进程为不可再次被OOM杀手处理。",
          "similarity": 0.7184946537017822
        },
        {
          "chunk_id": 2,
          "file_path": "mm/oom_kill.c",
          "start_line": 253,
          "end_line": 359,
          "content": [
            "static enum oom_constraint constrained_alloc(struct oom_control *oc)",
            "{",
            "\tstruct zone *zone;",
            "\tstruct zoneref *z;",
            "\tenum zone_type highest_zoneidx = gfp_zone(oc->gfp_mask);",
            "\tbool cpuset_limited = false;",
            "\tint nid;",
            "",
            "\tif (is_memcg_oom(oc)) {",
            "\t\toc->totalpages = mem_cgroup_get_max(oc->memcg) ?: 1;",
            "\t\treturn CONSTRAINT_MEMCG;",
            "\t}",
            "",
            "\t/* Default to all available memory */",
            "\toc->totalpages = totalram_pages() + total_swap_pages;",
            "",
            "\tif (!IS_ENABLED(CONFIG_NUMA))",
            "\t\treturn CONSTRAINT_NONE;",
            "",
            "\tif (!oc->zonelist)",
            "\t\treturn CONSTRAINT_NONE;",
            "\t/*",
            "\t * Reach here only when __GFP_NOFAIL is used. So, we should avoid",
            "\t * to kill current.We have to random task kill in this case.",
            "\t * Hopefully, CONSTRAINT_THISNODE...but no way to handle it, now.",
            "\t */",
            "\tif (oc->gfp_mask & __GFP_THISNODE)",
            "\t\treturn CONSTRAINT_NONE;",
            "",
            "\t/*",
            "\t * This is not a __GFP_THISNODE allocation, so a truncated nodemask in",
            "\t * the page allocator means a mempolicy is in effect.  Cpuset policy",
            "\t * is enforced in get_page_from_freelist().",
            "\t */",
            "\tif (oc->nodemask &&",
            "\t    !nodes_subset(node_states[N_MEMORY], *oc->nodemask)) {",
            "\t\toc->totalpages = total_swap_pages;",
            "\t\tfor_each_node_mask(nid, *oc->nodemask)",
            "\t\t\toc->totalpages += node_present_pages(nid);",
            "\t\treturn CONSTRAINT_MEMORY_POLICY;",
            "\t}",
            "",
            "\t/* Check this allocation failure is caused by cpuset's wall function */",
            "\tfor_each_zone_zonelist_nodemask(zone, z, oc->zonelist,",
            "\t\t\thighest_zoneidx, oc->nodemask)",
            "\t\tif (!cpuset_zone_allowed(zone, oc->gfp_mask))",
            "\t\t\tcpuset_limited = true;",
            "",
            "\tif (cpuset_limited) {",
            "\t\toc->totalpages = total_swap_pages;",
            "\t\tfor_each_node_mask(nid, cpuset_current_mems_allowed)",
            "\t\t\toc->totalpages += node_present_pages(nid);",
            "\t\treturn CONSTRAINT_CPUSET;",
            "\t}",
            "\treturn CONSTRAINT_NONE;",
            "}",
            "static int oom_evaluate_task(struct task_struct *task, void *arg)",
            "{",
            "\tstruct oom_control *oc = arg;",
            "\tlong points;",
            "",
            "\tif (oom_unkillable_task(task))",
            "\t\tgoto next;",
            "",
            "\t/* p may not have freeable memory in nodemask */",
            "\tif (!is_memcg_oom(oc) && !oom_cpuset_eligible(task, oc))",
            "\t\tgoto next;",
            "",
            "\t/*",
            "\t * This task already has access to memory reserves and is being killed.",
            "\t * Don't allow any other task to have access to the reserves unless",
            "\t * the task has MMF_OOM_SKIP because chances that it would release",
            "\t * any memory is quite low.",
            "\t */",
            "\tif (!is_sysrq_oom(oc) && tsk_is_oom_victim(task)) {",
            "\t\tif (test_bit(MMF_OOM_SKIP, &task->signal->oom_mm->flags))",
            "\t\t\tgoto next;",
            "\t\tgoto abort;",
            "\t}",
            "",
            "\t/*",
            "\t * If task is allocating a lot of memory and has been marked to be",
            "\t * killed first if it triggers an oom, then select it.",
            "\t */",
            "\tif (oom_task_origin(task)) {",
            "\t\tpoints = LONG_MAX;",
            "\t\tgoto select;",
            "\t}",
            "",
            "\tpoints = oom_badness(task, oc->totalpages);",
            "\tif (points == LONG_MIN || points < oc->chosen_points)",
            "\t\tgoto next;",
            "",
            "select:",
            "\tif (oc->chosen)",
            "\t\tput_task_struct(oc->chosen);",
            "\tget_task_struct(task);",
            "\toc->chosen = task;",
            "\toc->chosen_points = points;",
            "next:",
            "\treturn 0;",
            "abort:",
            "\tif (oc->chosen)",
            "\t\tput_task_struct(oc->chosen);",
            "\toc->chosen = (void *)-1UL;",
            "\treturn 1;",
            "}"
          ],
          "function_name": "constrained_alloc, oom_evaluate_task",
          "description": "根据内存分配约束条件（如NUMA节点、内存组）动态调整可回收内存总量，并通过评估函数筛选出具有最高OOM不良值的任务作为潜在受害者。",
          "similarity": 0.6955966949462891
        },
        {
          "chunk_id": 6,
          "file_path": "mm/oom_kill.c",
          "start_line": 826,
          "end_line": 995,
          "content": [
            "bool oom_killer_disable(signed long timeout)",
            "{",
            "\tsigned long ret;",
            "",
            "\t/*",
            "\t * Make sure to not race with an ongoing OOM killer. Check that the",
            "\t * current is not killed (possibly due to sharing the victim's memory).",
            "\t */",
            "\tif (mutex_lock_killable(&oom_lock))",
            "\t\treturn false;",
            "\toom_killer_disabled = true;",
            "\tmutex_unlock(&oom_lock);",
            "",
            "\tret = wait_event_interruptible_timeout(oom_victims_wait,",
            "\t\t\t!atomic_read(&oom_victims), timeout);",
            "\tif (ret <= 0) {",
            "\t\toom_killer_enable();",
            "\t\treturn false;",
            "\t}",
            "\tpr_info(\"OOM killer disabled.\\n\");",
            "",
            "\treturn true;",
            "}",
            "static inline bool __task_will_free_mem(struct task_struct *task)",
            "{",
            "\tstruct signal_struct *sig = task->signal;",
            "",
            "\t/*",
            "\t * A coredumping process may sleep for an extended period in",
            "\t * coredump_task_exit(), so the oom killer cannot assume that",
            "\t * the process will promptly exit and release memory.",
            "\t */",
            "\tif (sig->core_state)",
            "\t\treturn false;",
            "",
            "\tif (sig->flags & SIGNAL_GROUP_EXIT)",
            "\t\treturn true;",
            "",
            "\tif (thread_group_empty(task) && (task->flags & PF_EXITING))",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "static bool task_will_free_mem(struct task_struct *task)",
            "{",
            "\tstruct mm_struct *mm = task->mm;",
            "\tstruct task_struct *p;",
            "\tbool ret = true;",
            "",
            "\t/*",
            "\t * Skip tasks without mm because it might have passed its exit_mm and",
            "\t * exit_oom_victim. oom_reaper could have rescued that but do not rely",
            "\t * on that for now. We can consider find_lock_task_mm in future.",
            "\t */",
            "\tif (!mm)",
            "\t\treturn false;",
            "",
            "\tif (!__task_will_free_mem(task))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * This task has already been drained by the oom reaper so there are",
            "\t * only small chances it will free some more",
            "\t */",
            "\tif (test_bit(MMF_OOM_SKIP, &mm->flags))",
            "\t\treturn false;",
            "",
            "\tif (atomic_read(&mm->mm_users) <= 1)",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * Make sure that all tasks which share the mm with the given tasks",
            "\t * are dying as well to make sure that a) nobody pins its mm and",
            "\t * b) the task is also reapable by the oom reaper.",
            "\t */",
            "\trcu_read_lock();",
            "\tfor_each_process(p) {",
            "\t\tif (!process_shares_mm(p, mm))",
            "\t\t\tcontinue;",
            "\t\tif (same_thread_group(task, p))",
            "\t\t\tcontinue;",
            "\t\tret = __task_will_free_mem(p);",
            "\t\tif (!ret)",
            "\t\t\tbreak;",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\treturn ret;",
            "}",
            "static void __oom_kill_process(struct task_struct *victim, const char *message)",
            "{",
            "\tstruct task_struct *p;",
            "\tstruct mm_struct *mm;",
            "\tbool can_oom_reap = true;",
            "",
            "\tp = find_lock_task_mm(victim);",
            "\tif (!p) {",
            "\t\tpr_info(\"%s: OOM victim %d (%s) is already exiting. Skip killing the task\\n\",",
            "\t\t\tmessage, task_pid_nr(victim), victim->comm);",
            "\t\tput_task_struct(victim);",
            "\t\treturn;",
            "\t} else if (victim != p) {",
            "\t\tget_task_struct(p);",
            "\t\tput_task_struct(victim);",
            "\t\tvictim = p;",
            "\t}",
            "",
            "\t/* Get a reference to safely compare mm after task_unlock(victim) */",
            "\tmm = victim->mm;",
            "\tmmgrab(mm);",
            "",
            "\t/* Raise event before sending signal: task reaper must see this */",
            "\tcount_vm_event(OOM_KILL);",
            "\tmemcg_memory_event_mm(mm, MEMCG_OOM_KILL);",
            "",
            "\t/*",
            "\t * We should send SIGKILL before granting access to memory reserves",
            "\t * in order to prevent the OOM victim from depleting the memory",
            "\t * reserves from the user space under its control.",
            "\t */",
            "\tdo_send_sig_info(SIGKILL, SEND_SIG_PRIV, victim, PIDTYPE_TGID);",
            "\tmark_oom_victim(victim);",
            "\tpr_err(\"%s: Killed process %d (%s) total-vm:%lukB, anon-rss:%lukB, file-rss:%lukB, shmem-rss:%lukB, UID:%u pgtables:%lukB oom_score_adj:%hd\\n\",",
            "\t\tmessage, task_pid_nr(victim), victim->comm, K(mm->total_vm),",
            "\t\tK(get_mm_counter(mm, MM_ANONPAGES)),",
            "\t\tK(get_mm_counter(mm, MM_FILEPAGES)),",
            "\t\tK(get_mm_counter(mm, MM_SHMEMPAGES)),",
            "\t\tfrom_kuid(&init_user_ns, task_uid(victim)),",
            "\t\tmm_pgtables_bytes(mm) >> 10, victim->signal->oom_score_adj);",
            "\ttask_unlock(victim);",
            "",
            "\t/*",
            "\t * Kill all user processes sharing victim->mm in other thread groups, if",
            "\t * any.  They don't get access to memory reserves, though, to avoid",
            "\t * depletion of all memory.  This prevents mm->mmap_lock livelock when an",
            "\t * oom killed thread cannot exit because it requires the semaphore and",
            "\t * its contended by another thread trying to allocate memory itself.",
            "\t * That thread will now get access to memory reserves since it has a",
            "\t * pending fatal signal.",
            "\t */",
            "\trcu_read_lock();",
            "\tfor_each_process(p) {",
            "\t\tif (!process_shares_mm(p, mm))",
            "\t\t\tcontinue;",
            "\t\tif (same_thread_group(p, victim))",
            "\t\t\tcontinue;",
            "\t\tif (is_global_init(p)) {",
            "\t\t\tcan_oom_reap = false;",
            "\t\t\tset_bit(MMF_OOM_SKIP, &mm->flags);",
            "\t\t\tpr_info(\"oom killer %d (%s) has mm pinned by %d (%s)\\n\",",
            "\t\t\t\t\ttask_pid_nr(victim), victim->comm,",
            "\t\t\t\t\ttask_pid_nr(p), p->comm);",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\t/*",
            "\t\t * No kthread_use_mm() user needs to read from the userspace so",
            "\t\t * we are ok to reap it.",
            "\t\t */",
            "\t\tif (unlikely(p->flags & PF_KTHREAD))",
            "\t\t\tcontinue;",
            "\t\tdo_send_sig_info(SIGKILL, SEND_SIG_PRIV, p, PIDTYPE_TGID);",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\tif (can_oom_reap)",
            "\t\tqueue_oom_reaper(victim);",
            "",
            "\tmmdrop(mm);",
            "\tput_task_struct(victim);",
            "}"
          ],
          "function_name": "oom_killer_disable, __task_will_free_mem, task_will_free_mem, __oom_kill_process",
          "description": "提供OOM杀手禁用逻辑及进程可回收性判断，实现OOM触发时的进程强制终止流程，包含共享MM处理、信号发送、内存统计等核心操作",
          "similarity": 0.6938363313674927
        },
        {
          "chunk_id": 7,
          "file_path": "mm/oom_kill.c",
          "start_line": 1011,
          "end_line": 1162,
          "content": [
            "static int oom_kill_memcg_member(struct task_struct *task, void *message)",
            "{",
            "\tif (task->signal->oom_score_adj != OOM_SCORE_ADJ_MIN &&",
            "\t    !is_global_init(task)) {",
            "\t\tget_task_struct(task);",
            "\t\t__oom_kill_process(task, message);",
            "\t}",
            "\treturn 0;",
            "}",
            "static void oom_kill_process(struct oom_control *oc, const char *message)",
            "{",
            "\tstruct task_struct *victim = oc->chosen;",
            "\tstruct mem_cgroup *oom_group;",
            "\tstatic DEFINE_RATELIMIT_STATE(oom_rs, DEFAULT_RATELIMIT_INTERVAL,",
            "\t\t\t\t\t      DEFAULT_RATELIMIT_BURST);",
            "",
            "\t/*",
            "\t * If the task is already exiting, don't alarm the sysadmin or kill",
            "\t * its children or threads, just give it access to memory reserves",
            "\t * so it can die quickly",
            "\t */",
            "\ttask_lock(victim);",
            "\tif (task_will_free_mem(victim)) {",
            "\t\tmark_oom_victim(victim);",
            "\t\tqueue_oom_reaper(victim);",
            "\t\ttask_unlock(victim);",
            "\t\tput_task_struct(victim);",
            "\t\treturn;",
            "\t}",
            "\ttask_unlock(victim);",
            "",
            "\tif (__ratelimit(&oom_rs))",
            "\t\tdump_header(oc, victim);",
            "",
            "\t/*",
            "\t * Do we need to kill the entire memory cgroup?",
            "\t * Or even one of the ancestor memory cgroups?",
            "\t * Check this out before killing the victim task.",
            "\t */",
            "\toom_group = mem_cgroup_get_oom_group(victim, oc->memcg);",
            "",
            "\t__oom_kill_process(victim, message);",
            "",
            "\t/*",
            "\t * If necessary, kill all tasks in the selected memory cgroup.",
            "\t */",
            "\tif (oom_group) {",
            "\t\tmemcg_memory_event(oom_group, MEMCG_OOM_GROUP_KILL);",
            "\t\tmem_cgroup_print_oom_group(oom_group);",
            "\t\tmem_cgroup_scan_tasks(oom_group, oom_kill_memcg_member,",
            "\t\t\t\t      (void *)message);",
            "\t\tmem_cgroup_put(oom_group);",
            "\t}",
            "}",
            "static void check_panic_on_oom(struct oom_control *oc)",
            "{",
            "\tif (likely(!sysctl_panic_on_oom))",
            "\t\treturn;",
            "\tif (sysctl_panic_on_oom != 2) {",
            "\t\t/*",
            "\t\t * panic_on_oom == 1 only affects CONSTRAINT_NONE, the kernel",
            "\t\t * does not panic for cpuset, mempolicy, or memcg allocation",
            "\t\t * failures.",
            "\t\t */",
            "\t\tif (oc->constraint != CONSTRAINT_NONE)",
            "\t\t\treturn;",
            "\t}",
            "\t/* Do not panic for oom kills triggered by sysrq */",
            "\tif (is_sysrq_oom(oc))",
            "\t\treturn;",
            "\tdump_header(oc, NULL);",
            "\tpanic(\"Out of memory: %s panic_on_oom is enabled\\n\",",
            "\t\tsysctl_panic_on_oom == 2 ? \"compulsory\" : \"system-wide\");",
            "}",
            "int register_oom_notifier(struct notifier_block *nb)",
            "{",
            "\treturn blocking_notifier_chain_register(&oom_notify_list, nb);",
            "}",
            "int unregister_oom_notifier(struct notifier_block *nb)",
            "{",
            "\treturn blocking_notifier_chain_unregister(&oom_notify_list, nb);",
            "}",
            "bool out_of_memory(struct oom_control *oc)",
            "{",
            "\tunsigned long freed = 0;",
            "",
            "\tif (oom_killer_disabled)",
            "\t\treturn false;",
            "",
            "\tif (!is_memcg_oom(oc)) {",
            "\t\tblocking_notifier_call_chain(&oom_notify_list, 0, &freed);",
            "\t\tif (freed > 0 && !is_sysrq_oom(oc))",
            "\t\t\t/* Got some memory back in the last second. */",
            "\t\t\treturn true;",
            "\t}",
            "",
            "\t/*",
            "\t * If current has a pending SIGKILL or is exiting, then automatically",
            "\t * select it.  The goal is to allow it to allocate so that it may",
            "\t * quickly exit and free its memory.",
            "\t */",
            "\tif (task_will_free_mem(current)) {",
            "\t\tmark_oom_victim(current);",
            "\t\tqueue_oom_reaper(current);",
            "\t\treturn true;",
            "\t}",
            "",
            "\t/*",
            "\t * The OOM killer does not compensate for IO-less reclaim.",
            "\t * But mem_cgroup_oom() has to invoke the OOM killer even",
            "\t * if it is a GFP_NOFS allocation.",
            "\t */",
            "\tif (!(oc->gfp_mask & __GFP_FS) && !is_memcg_oom(oc))",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * Check if there were limitations on the allocation (only relevant for",
            "\t * NUMA and memcg) that may require different handling.",
            "\t */",
            "\toc->constraint = constrained_alloc(oc);",
            "\tif (oc->constraint != CONSTRAINT_MEMORY_POLICY)",
            "\t\toc->nodemask = NULL;",
            "\tcheck_panic_on_oom(oc);",
            "",
            "\tif (!is_memcg_oom(oc) && sysctl_oom_kill_allocating_task &&",
            "\t    current->mm && !oom_unkillable_task(current) &&",
            "\t    oom_cpuset_eligible(current, oc) &&",
            "\t    current->signal->oom_score_adj != OOM_SCORE_ADJ_MIN) {",
            "\t\tget_task_struct(current);",
            "\t\toc->chosen = current;",
            "\t\toom_kill_process(oc, \"Out of memory (oom_kill_allocating_task)\");",
            "\t\treturn true;",
            "\t}",
            "",
            "\tselect_bad_process(oc);",
            "\t/* Found nothing?!?! */",
            "\tif (!oc->chosen) {",
            "\t\tdump_header(oc, NULL);",
            "\t\tpr_warn(\"Out of memory and no killable processes...\\n\");",
            "\t\t/*",
            "\t\t * If we got here due to an actual allocation at the",
            "\t\t * system level, we cannot survive this and will enter",
            "\t\t * an endless loop in the allocator. Bail out now.",
            "\t\t */",
            "\t\tif (!is_sysrq_oom(oc) && !is_memcg_oom(oc))",
            "\t\t\tpanic(\"System is deadlocked on memory\\n\");",
            "\t}",
            "\tif (oc->chosen && oc->chosen != (void *)-1UL)",
            "\t\toom_kill_process(oc, !is_memcg_oom(oc) ? \"Out of memory\" :",
            "\t\t\t\t \"Memory cgroup out of memory\");",
            "\treturn !!oc->chosen;",
            "}"
          ],
          "function_name": "oom_kill_memcg_member, oom_kill_process, check_panic_on_oom, register_oom_notifier, unregister_oom_notifier, out_of_memory",
          "description": "实现基于内存控制组的OOM处理逻辑，集成OOM通知机制，包含OOM触发判定、进程选择算法、内存组遍历杀进程等功能，支持系统级OOM恐慌检测",
          "similarity": 0.6778132915496826
        },
        {
          "chunk_id": 5,
          "file_path": "mm/oom_kill.c",
          "start_line": 646,
          "end_line": 746,
          "content": [
            "static int oom_reaper(void *unused)",
            "{",
            "\tset_freezable();",
            "",
            "\twhile (true) {",
            "\t\tstruct task_struct *tsk = NULL;",
            "",
            "\t\twait_event_freezable(oom_reaper_wait, oom_reaper_list != NULL);",
            "\t\tspin_lock_irq(&oom_reaper_lock);",
            "\t\tif (oom_reaper_list != NULL) {",
            "\t\t\ttsk = oom_reaper_list;",
            "\t\t\toom_reaper_list = tsk->oom_reaper_list;",
            "\t\t}",
            "\t\tspin_unlock_irq(&oom_reaper_lock);",
            "",
            "\t\tif (tsk)",
            "\t\t\toom_reap_task(tsk);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static void wake_oom_reaper(struct timer_list *timer)",
            "{",
            "\tstruct task_struct *tsk = container_of(timer, struct task_struct,",
            "\t\t\toom_reaper_timer);",
            "\tstruct mm_struct *mm = tsk->signal->oom_mm;",
            "\tunsigned long flags;",
            "",
            "\t/* The victim managed to terminate on its own - see exit_mmap */",
            "\tif (test_bit(MMF_OOM_SKIP, &mm->flags)) {",
            "\t\tput_task_struct(tsk);",
            "\t\treturn;",
            "\t}",
            "",
            "\tspin_lock_irqsave(&oom_reaper_lock, flags);",
            "\ttsk->oom_reaper_list = oom_reaper_list;",
            "\toom_reaper_list = tsk;",
            "\tspin_unlock_irqrestore(&oom_reaper_lock, flags);",
            "\ttrace_wake_reaper(tsk->pid);",
            "\twake_up(&oom_reaper_wait);",
            "}",
            "static void queue_oom_reaper(struct task_struct *tsk)",
            "{",
            "\t/* mm is already queued? */",
            "\tif (test_and_set_bit(MMF_OOM_REAP_QUEUED, &tsk->signal->oom_mm->flags))",
            "\t\treturn;",
            "",
            "\tget_task_struct(tsk);",
            "\ttimer_setup(&tsk->oom_reaper_timer, wake_oom_reaper, 0);",
            "\ttsk->oom_reaper_timer.expires = jiffies + OOM_REAPER_DELAY;",
            "\tadd_timer(&tsk->oom_reaper_timer);",
            "}",
            "static int __init oom_init(void)",
            "{",
            "\toom_reaper_th = kthread_run(oom_reaper, NULL, \"oom_reaper\");",
            "#ifdef CONFIG_SYSCTL",
            "\tregister_sysctl_init(\"vm\", vm_oom_kill_table);",
            "#endif",
            "\treturn 0;",
            "}",
            "static inline void queue_oom_reaper(struct task_struct *tsk)",
            "{",
            "}",
            "static void mark_oom_victim(struct task_struct *tsk)",
            "{",
            "\tconst struct cred *cred;",
            "\tstruct mm_struct *mm = tsk->mm;",
            "",
            "\tWARN_ON(oom_killer_disabled);",
            "\t/* OOM killer might race with memcg OOM */",
            "\tif (test_and_set_tsk_thread_flag(tsk, TIF_MEMDIE))",
            "\t\treturn;",
            "",
            "\t/* oom_mm is bound to the signal struct life time. */",
            "\tif (!cmpxchg(&tsk->signal->oom_mm, NULL, mm))",
            "\t\tmmgrab(tsk->signal->oom_mm);",
            "",
            "\t/*",
            "\t * Make sure that the task is woken up from uninterruptible sleep",
            "\t * if it is frozen because OOM killer wouldn't be able to free",
            "\t * any memory and livelock. freezing_slow_path will tell the freezer",
            "\t * that TIF_MEMDIE tasks should be ignored.",
            "\t */",
            "\t__thaw_task(tsk);",
            "\tatomic_inc(&oom_victims);",
            "\tcred = get_task_cred(tsk);",
            "\ttrace_mark_victim(tsk, cred->uid.val);",
            "\tput_cred(cred);",
            "}",
            "void exit_oom_victim(void)",
            "{",
            "\tclear_thread_flag(TIF_MEMDIE);",
            "",
            "\tif (!atomic_dec_return(&oom_victims))",
            "\t\twake_up_all(&oom_victims_wait);",
            "}",
            "void oom_killer_enable(void)",
            "{",
            "\toom_killer_disabled = false;",
            "\tpr_info(\"OOM killer enabled.\\n\");",
            "}"
          ],
          "function_name": "oom_reaper, wake_oom_reaper, queue_oom_reaper, oom_init, queue_oom_reaper, mark_oom_victim, exit_oom_victim, oom_killer_enable",
          "description": "定义OOM杀手线程及其管理逻辑，通过等待队列和自旋锁协调进程回收，支持定时唤醒和任务标记机制，初始化OOM杀手线程并注册sysctl接口，部分函数存在重复定义导致上下文不完整",
          "similarity": 0.6485987901687622
        }
      ]
    },
    {
      "source_file": "kernel/iomem.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:45:49\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `iomem.c`\n\n---\n\n# iomem.c 技术文档\n\n## 1. 文件概述\n\n`iomem.c` 实现了通用的内存重映射（`memremap`）接口，用于将物理地址空间（特别是 I/O 内存资源）映射为可直接访问的内核虚拟地址。与传统的 `ioremap` 不同，`memremap` 专为**无 I/O 副作用**的内存区域设计（如持久内存 PMEM、设备内存等），并支持多种缓存策略（如写回 WB、写通 WT、写合并 WC）。该文件还提供了资源管理版本（`devm_memremap`），可自动在设备卸载时释放映射。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`memremap()`**  \n  核心映射函数，根据指定的缓存策略（`MEMREMAP_WB`/`WT`/`WC`）将物理地址映射为内核虚拟地址。若映射区域为系统 RAM 且请求 `MEMREMAP_WB`，则直接返回线性映射地址。\n\n- **`memunmap()`**  \n  释放由 `memremap()` 创建的映射。若地址来自 `ioremap` 系列函数，则调用 `iounmap()`；若为直接映射地址则无需操作。\n\n- **`devm_memremap()`**  \n  设备资源管理版本的 `memremap()`，将映射资源与设备生命周期绑定，设备卸载时自动释放。\n\n- **`devm_memunmap()`**  \n  显式释放由 `devm_memremap()` 分配的资源（通常无需手动调用）。\n\n### 辅助函数\n\n- **`try_ram_remap()`**  \n  尝试对系统 RAM 区域使用内核直接映射（`__va()`），避免创建新页表。\n\n- **`arch_memremap_wb()`**（弱符号）  \n  架构特定的写回（WB）映射实现，默认回退到 `ioremap_cache()` 或 `ioremap()`。\n\n- **`arch_memremap_can_ram_remap()`**（弱符号）  \n  架构特定的 RAM 重映射能力检查，默认返回 `true`。\n\n### 标志位（Flags）\n\n- `MEMREMAP_WB`：写回缓存（默认系统 RAM 策略）\n- `MEMREMAP_WT`：写通缓存（禁止用于系统 RAM）\n- `MEMREMAP_WC`：写合并（禁止用于系统 RAM）\n- `MEMREMAP_ENC`/`DEC`：加密/解密映射（代码中未直接处理，由底层 `ioremap` 实现）\n\n## 3. 关键实现\n\n### 内存区域类型检测\n- 使用 `region_intersects()` 检查物理地址范围是否与 `IORESOURCE_SYSTEM_RAM` 重叠，返回：\n  - `REGION_INTERSECTS`：完全或部分在系统 RAM 内\n  - `REGION_MIXED`：跨越 RAM 与非 RAM 区域（视为错误）\n  - `REGION_DISJOINT`：完全在非 RAM 区域\n\n### RAM 直接映射优化\n- 当请求 `MEMREMAP_WB` 且区域为系统 RAM 时：\n  1. 调用 `try_ram_remap()` 检查是否满足直接映射条件：\n     - 物理页帧有效（`pfn_valid()`）\n     - 非高端内存（`!PageHighMem()`）\n     - 架构允许 RAM 重映射（`arch_memremap_can_ram_remap()`）\n  2. 若满足，直接返回 `__va(offset)`（内核线性映射地址），避免页表开销。\n\n### 非 RAM 区域映射\n- 对于非 RAM 区域或非 WB 请求：\n  - `MEMREMAP_WT` → `ioremap_wt()`\n  - `MEMREMAP_WC` → `ioremap_wc()`\n  - `MEMREMAP_WB` → `arch_memremap_wb()`（最终调用 `ioremap_cache()` 或 `ioremap()`）\n\n### 安全限制\n- 禁止对系统 RAM 使用 `WT`/`WC` 映射（会触发 `WARN_ONCE` 并返回 `NULL`）\n- 禁止映射混合 RAM/非 RAM 区域（视为编程错误）\n\n### 资源管理\n- `devm_memremap()` 使用设备资源管理框架（`devres`）：\n  - 分配资源描述符（`devres_alloc_node`）\n  - 注册释放回调（`devm_memremap_release`）\n  - 设备卸载时自动调用 `memunmap()`\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/io.h>`：提供 `ioremap_*()` 系列函数\n  - `<linux/mm.h>`：提供 `pfn_valid()`、`PageHighMem()` 等内存管理接口\n  - `<linux/ioremap.h>`：定义 `ioremap` 相关类型和函数\n  - `<linux/device.h>`：提供设备资源管理（`devres`）接口\n\n- **架构依赖**：\n  - 依赖架构实现的 `ioremap_cache()`、`ioremap_wt()`、`ioremap_wc()`\n  - 可选覆盖 `arch_memremap_wb()` 和 `arch_memremap_can_ram_remap()`\n\n- **内核子系统**：\n  - 内存管理子系统（MM）：页表管理、直接映射\n  - 设备驱动模型：设备资源生命周期管理\n\n## 5. 使用场景\n\n- **持久内存（PMEM）驱动**：  \n  将持久内存设备的物理地址映射为可直接读写的内核虚拟地址（通常使用 `MEMREMAP_WB`）。\n\n- **设备内存（Device Memory）访问**：  \n  访问无 I/O 副作用的设备内存区域（如 GPU 显存、FPGA 内存），根据性能需求选择缓存策略。\n\n- **EFI 运行时服务内存**：  \n  映射 EFI 固件提供的内存区域（需确保无副作用）。\n\n- **设备驱动资源管理**：  \n  使用 `devm_memremap()` 简化驱动代码，避免手动释放映射（尤其适用于 probe/remove 场景）。\n\n- **内核子系统通用映射**：  \n  为需要高性能内存访问的子系统（如 DAX、HMM）提供统一映射接口。",
      "similarity": 0.5889074206352234,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/iomem.c",
          "start_line": 20,
          "end_line": 42,
          "content": [
            "static bool arch_memremap_can_ram_remap(resource_size_t offset, size_t size,",
            "\t\t\t\t\tunsigned long flags)",
            "{",
            "\treturn true;",
            "}",
            "void memunmap(void *addr)",
            "{",
            "\tif (is_ioremap_addr(addr))",
            "\t\tiounmap((void __iomem *) addr);",
            "}",
            "static void devm_memremap_release(struct device *dev, void *res)",
            "{",
            "\tmemunmap(*(void **)res);",
            "}",
            "static int devm_memremap_match(struct device *dev, void *res, void *match_data)",
            "{",
            "\treturn *(void **)res == match_data;",
            "}",
            "void devm_memunmap(struct device *dev, void *addr)",
            "{",
            "\tWARN_ON(devres_release(dev, devm_memremap_release,",
            "\t\t\t\tdevm_memremap_match, addr));",
            "}"
          ],
          "function_name": "arch_memremap_can_ram_remap, memunmap, devm_memremap_release, devm_memremap_match, devm_memunmap",
          "description": "实现内存映射释放相关函数，包含判断能否进行RAM重映射的钩子函数、解除ioremap地址映射的memunmap函数，以及设备资源管理中的动态内存映射释放匹配逻辑",
          "similarity": 0.5815714597702026
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/iomem.c",
          "start_line": 1,
          "end_line": 19,
          "content": [
            "/* SPDX-License-Identifier: GPL-2.0 */",
            "#include <linux/device.h>",
            "#include <linux/types.h>",
            "#include <linux/io.h>",
            "#include <linux/mm.h>",
            "#include <linux/ioremap.h>",
            "",
            "#ifndef arch_memremap_wb",
            "static void *arch_memremap_wb(resource_size_t offset, unsigned long size)",
            "{",
            "#ifdef ioremap_cache",
            "\treturn (__force void *)ioremap_cache(offset, size);",
            "#else",
            "\treturn (__force void *)ioremap(offset, size);",
            "#endif",
            "}",
            "#endif",
            "",
            "#ifndef arch_memremap_can_ram_remap"
          ],
          "function_name": null,
          "description": "定义arch_memremap_wb函数，根据ioremap_cache是否存在选择使用ioremap_cache或ioremap实现，用于创建带写回缓存策略的内存映射区域，上下文不完整",
          "similarity": 0.5297254323959351
        }
      ]
    },
    {
      "source_file": "mm/memcontrol-v1.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:38:55\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memcontrol-v1.c`\n\n---\n\n# memcontrol-v1.c 技术文档\n\n## 1. 文件概述\n\n`memcontrol-v1.c` 是 Linux 内核内存控制组（Memory Cgroup）v1 接口的核心实现文件之一，主要负责基于软限制（soft limit）的内存回收机制、OOM 事件通知以及与 cgroup v1 兼容的资源统计和管理功能。该文件维护了一个独立于 cgroup 层级结构的红黑树（RB-Tree），用于高效地追踪和选择超出软限制最多的内存控制组进行内存回收。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct mem_cgroup_tree_per_node`**  \n  每个 NUMA 节点对应的红黑树结构，用于存储超出软限制的 `mem_cgroup_per_node` 实例。\n  - `rb_root`: 红黑树根节点\n  - `rb_rightmost`: 指向使用量超出软限制最多的节点（树中最右侧节点）\n  - `lock`: 保护该树的自旋锁\n\n- **`struct mem_cgroup_tree`**  \n  全局软限制树结构，包含每个 NUMA 节点对应的 `mem_cgroup_tree_per_node`。\n\n- **`struct mem_cgroup_eventfd_list`**  \n  用于 OOM 事件通知的 eventfd 列表项。\n\n- **`struct mem_cgroup_event`**  \n  表示用户空间注册的内存事件（如 OOM、阈值触发等），支持通过 eventfd 通知用户空间。\n\n- **枚举常量 `RES_*`**  \n  定义了 cgroup v1 接口中可读写的资源属性类型（如使用量、限制、最大使用量、失败计数、软限制等）。\n\n### 主要函数\n\n- **`__mem_cgroup_insert_exceeded()` / `__mem_cgroup_remove_exceeded()`**  \n  在指定节点的软限制红黑树中插入或移除一个 `mem_cgroup_per_node` 节点。\n\n- **`memcg1_update_tree()`**  \n  根据当前内存使用量与软限制的差值，更新指定 memcg 及其所有祖先在软限制树中的位置。\n\n- **`memcg1_remove_from_trees()`**  \n  在 memcg 销毁时，将其从所有 NUMA 节点的软限制树中移除。\n\n- **`mem_cgroup_largest_soft_limit_node()`**  \n  从指定节点的软限制树中找出超出软限制最多的 memcg 节点，用于优先回收。\n\n- **`mem_cgroup_soft_reclaim()`**  \n  对指定 memcg 层级结构执行软限制驱动的内存回收。\n\n- **`memcg1_soft_limit_reclaim()`**（未完整显示）  \n  全局软限制回收入口函数，由内存短缺路径调用，尝试从超出软限制的 memcg 中回收内存。\n\n## 3. 关键实现\n\n### 软限制红黑树机制\n\n- 所有超出软限制（`memory.usage > soft_limit`）的 `mem_cgroup_per_node` 实例被组织到 per-NUMA-node 的红黑树中。\n- 树按 `usage_in_excess = usage - soft_limit` 升序排列，最右侧节点即为超出最多的 memcg。\n- 当 memcg 的内存使用量变化或软限制被修改时，调用 `memcg1_update_tree()` 更新其在树中的位置（先删除再重新插入）。\n- 回收时优先选择 `rb_rightmost` 节点，确保优先回收“最违规”的 memcg。\n\n### 层级遍历与祖先更新\n\n- 在启用 cgroup 层级模式时，子 memcg 的内存使用会影响父 memcg 的统计。\n- 因此，当子 memcg 的使用量变化时，需向上遍历所有祖先，更新它们在软限制树中的状态。\n\n### 防止无限循环的回收控制\n\n- `MEM_CGROUP_MAX_RECLAIM_LOOPS`（100）和 `MEM_CGROUP_MAX_SOFT_LIMIT_RECLAIM_LOOPS`（2）用于限制回收循环次数。\n- 若一轮遍历未回收足够内存（`total < excess >> 2`），最多再尝试一次。\n\n### 与 LRU_GEN 的集成\n\n- 若启用了多代 LRU（`lru_gen_enabled()`），则绕过红黑树机制，直接调用 `lru_gen_soft_reclaim()` 进行软限制回收。\n\n### 事件通知机制\n\n- 支持通过 `eventfd` 向用户空间发送 OOM 或其他内存事件通知。\n- 使用 `poll_table` 和 `wait_queue` 实现 eventfd 的自动注销（当 fd 关闭时）。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memcontrol.h>`：内存控制组核心接口\n  - `<linux/swap.h>`, `\"swap.h\"`：交换子系统支持\n  - `<linux/eventfd.h>`, `<linux/poll.h>`：事件通知机制\n  - `\"internal.h\"`：内核内存管理内部接口\n\n- **功能依赖**：\n  - 依赖 `page_counter` 子系统进行内存使用量统计\n  - 依赖 `mem_cgroup_iter()` 实现层级遍历\n  - 依赖 `mem_cgroup_shrink_node()` 执行实际页面回收\n  - 可选依赖 `lru_gen` 多代 LRU 回收器\n\n- **配置依赖**：\n  - `CONFIG_MEMCG`：必须启用内存 cgroup\n  - `CONFIG_LOCKDEP`：仅在调试时定义锁依赖映射\n\n## 5. 使用场景\n\n- **内存压力下的软限制回收**：当系统内存紧张时，`kswapd` 或直接回收路径会调用 `memcg1_soft_limit_reclaim()`，优先从超出软限制的 memcg 中回收内存，以维持服务质量（QoS）。\n- **cgroup v1 接口兼容**：为 `/sys/fs/cgroup/memory/` 下的 `memory.soft_limit_in_bytes` 等文件提供后端支持。\n- **OOM 事件通知**：当 memcg 触发 OOM 时，通过预先注册的 eventfd 向用户空间守护进程（如容器运行时）发送通知。\n- **动态资源调整**：当用户通过写入 `memory.soft_limit_in_bytes` 修改软限制时，触发 `memcg1_update_tree()` 更新红黑树结构。\n- **memcg 销毁清理**：在 cgroup 被删除时，确保其从所有软限制树中正确移除，防止悬挂指针。",
      "similarity": 0.5673251748085022,
      "chunks": [
        {
          "chunk_id": 8,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 1222,
          "end_line": 1369,
          "content": [
            "void memcg1_oom_recover(struct mem_cgroup *memcg)",
            "{",
            "\t/*",
            "\t * For the following lockless ->under_oom test, the only required",
            "\t * guarantee is that it must see the state asserted by an OOM when",
            "\t * this function is called as a result of userland actions",
            "\t * triggered by the notification of the OOM.  This is trivially",
            "\t * achieved by invoking mem_cgroup_mark_under_oom() before",
            "\t * triggering notification.",
            "\t */",
            "\tif (memcg && memcg->under_oom)",
            "\t\t__wake_up(&memcg_oom_waitq, TASK_NORMAL, 0, memcg);",
            "}",
            "bool mem_cgroup_oom_synchronize(bool handle)",
            "{",
            "\tstruct mem_cgroup *memcg = current->memcg_in_oom;",
            "\tstruct oom_wait_info owait;",
            "\tbool locked;",
            "",
            "\t/* OOM is global, do not handle */",
            "\tif (!memcg)",
            "\t\treturn false;",
            "",
            "\tif (!handle)",
            "\t\tgoto cleanup;",
            "",
            "\towait.memcg = memcg;",
            "\towait.wait.flags = 0;",
            "\towait.wait.func = memcg_oom_wake_function;",
            "\towait.wait.private = current;",
            "\tINIT_LIST_HEAD(&owait.wait.entry);",
            "",
            "\tprepare_to_wait(&memcg_oom_waitq, &owait.wait, TASK_KILLABLE);",
            "\tmem_cgroup_mark_under_oom(memcg);",
            "",
            "\tlocked = mem_cgroup_oom_trylock(memcg);",
            "",
            "\tif (locked)",
            "\t\tmem_cgroup_oom_notify(memcg);",
            "",
            "\tschedule();",
            "\tmem_cgroup_unmark_under_oom(memcg);",
            "\tfinish_wait(&memcg_oom_waitq, &owait.wait);",
            "",
            "\tif (locked)",
            "\t\tmem_cgroup_oom_unlock(memcg);",
            "cleanup:",
            "\tcurrent->memcg_in_oom = NULL;",
            "\tcss_put(&memcg->css);",
            "\treturn true;",
            "}",
            "bool memcg1_oom_prepare(struct mem_cgroup *memcg, bool *locked)",
            "{",
            "\t/*",
            "\t * We are in the middle of the charge context here, so we",
            "\t * don't want to block when potentially sitting on a callstack",
            "\t * that holds all kinds of filesystem and mm locks.",
            "\t *",
            "\t * cgroup1 allows disabling the OOM killer and waiting for outside",
            "\t * handling until the charge can succeed; remember the context and put",
            "\t * the task to sleep at the end of the page fault when all locks are",
            "\t * released.",
            "\t *",
            "\t * On the other hand, in-kernel OOM killer allows for an async victim",
            "\t * memory reclaim (oom_reaper) and that means that we are not solely",
            "\t * relying on the oom victim to make a forward progress and we can",
            "\t * invoke the oom killer here.",
            "\t *",
            "\t * Please note that mem_cgroup_out_of_memory might fail to find a",
            "\t * victim and then we have to bail out from the charge path.",
            "\t */",
            "\tif (READ_ONCE(memcg->oom_kill_disable)) {",
            "\t\tif (current->in_user_fault) {",
            "\t\t\tcss_get(&memcg->css);",
            "\t\t\tcurrent->memcg_in_oom = memcg;",
            "\t\t}",
            "\t\treturn false;",
            "\t}",
            "",
            "\tmem_cgroup_mark_under_oom(memcg);",
            "",
            "\t*locked = mem_cgroup_oom_trylock(memcg);",
            "",
            "\tif (*locked)",
            "\t\tmem_cgroup_oom_notify(memcg);",
            "",
            "\tmem_cgroup_unmark_under_oom(memcg);",
            "",
            "\treturn true;",
            "}",
            "void memcg1_oom_finish(struct mem_cgroup *memcg, bool locked)",
            "{",
            "\tif (locked)",
            "\t\tmem_cgroup_oom_unlock(memcg);",
            "}",
            "static int mem_cgroup_resize_max(struct mem_cgroup *memcg,",
            "\t\t\t\t unsigned long max, bool memsw)",
            "{",
            "\tbool enlarge = false;",
            "\tbool drained = false;",
            "\tint ret;",
            "\tbool limits_invariant;",
            "\tstruct page_counter *counter = memsw ? &memcg->memsw : &memcg->memory;",
            "",
            "\tdo {",
            "\t\tif (signal_pending(current)) {",
            "\t\t\tret = -EINTR;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tmutex_lock(&memcg_max_mutex);",
            "\t\t/*",
            "\t\t * Make sure that the new limit (memsw or memory limit) doesn't",
            "\t\t * break our basic invariant rule memory.max <= memsw.max.",
            "\t\t */",
            "\t\tlimits_invariant = memsw ? max >= READ_ONCE(memcg->memory.max) :",
            "\t\t\t\t\t   max <= memcg->memsw.max;",
            "\t\tif (!limits_invariant) {",
            "\t\t\tmutex_unlock(&memcg_max_mutex);",
            "\t\t\tret = -EINVAL;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tif (max > counter->max)",
            "\t\t\tenlarge = true;",
            "\t\tret = page_counter_set_max(counter, max);",
            "\t\tmutex_unlock(&memcg_max_mutex);",
            "",
            "\t\tif (!ret)",
            "\t\t\tbreak;",
            "",
            "\t\tif (!drained) {",
            "\t\t\tdrain_all_stock(memcg);",
            "\t\t\tdrained = true;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tif (!try_to_free_mem_cgroup_pages(memcg, 1, GFP_KERNEL,",
            "\t\t\t\t\tmemsw ? 0 : MEMCG_RECLAIM_MAY_SWAP)) {",
            "\t\t\tret = -EBUSY;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t} while (true);",
            "",
            "\tif (!ret && enlarge)",
            "\t\tmemcg1_oom_recover(memcg);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "memcg1_oom_recover, mem_cgroup_oom_synchronize, memcg1_oom_prepare, memcg1_oom_finish, mem_cgroup_resize_max",
          "description": "实现OOM恢复、同步及内存限制调整功能。包含OOM唤醒队列通知、OOM同步处理、内存限制动态调整及页面回收逻辑，通过循环尝试释放页面直到满足新限制条件。",
          "similarity": 0.6862790584564209
        },
        {
          "chunk_id": 7,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 1095,
          "end_line": 1203,
          "content": [
            "void memcg1_memcg_init(struct mem_cgroup *memcg)",
            "{",
            "\tINIT_LIST_HEAD(&memcg->oom_notify);",
            "\tmutex_init(&memcg->thresholds_lock);",
            "\tINIT_LIST_HEAD(&memcg->event_list);",
            "\tspin_lock_init(&memcg->event_list_lock);",
            "}",
            "void memcg1_css_offline(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup_event *event, *tmp;",
            "",
            "\t/*",
            "\t * Unregister events and notify userspace.",
            "\t * Notify userspace about cgroup removing only after rmdir of cgroup",
            "\t * directory to avoid race between userspace and kernelspace.",
            "\t */",
            "\tspin_lock_irq(&memcg->event_list_lock);",
            "\tlist_for_each_entry_safe(event, tmp, &memcg->event_list, list) {",
            "\t\tlist_del_init(&event->list);",
            "\t\tschedule_work(&event->remove);",
            "\t}",
            "\tspin_unlock_irq(&memcg->event_list_lock);",
            "}",
            "static bool mem_cgroup_oom_trylock(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup *iter, *failed = NULL;",
            "",
            "\tspin_lock(&memcg_oom_lock);",
            "",
            "\tfor_each_mem_cgroup_tree(iter, memcg) {",
            "\t\tif (iter->oom_lock) {",
            "\t\t\t/*",
            "\t\t\t * this subtree of our hierarchy is already locked",
            "\t\t\t * so we cannot give a lock.",
            "\t\t\t */",
            "\t\t\tfailed = iter;",
            "\t\t\tmem_cgroup_iter_break(memcg, iter);",
            "\t\t\tbreak;",
            "\t\t} else",
            "\t\t\titer->oom_lock = true;",
            "\t}",
            "",
            "\tif (failed) {",
            "\t\t/*",
            "\t\t * OK, we failed to lock the whole subtree so we have",
            "\t\t * to clean up what we set up to the failing subtree",
            "\t\t */",
            "\t\tfor_each_mem_cgroup_tree(iter, memcg) {",
            "\t\t\tif (iter == failed) {",
            "\t\t\t\tmem_cgroup_iter_break(memcg, iter);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t\titer->oom_lock = false;",
            "\t\t}",
            "\t} else",
            "\t\tmutex_acquire(&memcg_oom_lock_dep_map, 0, 1, _RET_IP_);",
            "",
            "\tspin_unlock(&memcg_oom_lock);",
            "",
            "\treturn !failed;",
            "}",
            "static void mem_cgroup_oom_unlock(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup *iter;",
            "",
            "\tspin_lock(&memcg_oom_lock);",
            "\tmutex_release(&memcg_oom_lock_dep_map, _RET_IP_);",
            "\tfor_each_mem_cgroup_tree(iter, memcg)",
            "\t\titer->oom_lock = false;",
            "\tspin_unlock(&memcg_oom_lock);",
            "}",
            "static void mem_cgroup_mark_under_oom(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup *iter;",
            "",
            "\tspin_lock(&memcg_oom_lock);",
            "\tfor_each_mem_cgroup_tree(iter, memcg)",
            "\t\titer->under_oom++;",
            "\tspin_unlock(&memcg_oom_lock);",
            "}",
            "static void mem_cgroup_unmark_under_oom(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup *iter;",
            "",
            "\t/*",
            "\t * Be careful about under_oom underflows because a child memcg",
            "\t * could have been added after mem_cgroup_mark_under_oom.",
            "\t */",
            "\tspin_lock(&memcg_oom_lock);",
            "\tfor_each_mem_cgroup_tree(iter, memcg)",
            "\t\tif (iter->under_oom > 0)",
            "\t\t\titer->under_oom--;",
            "\tspin_unlock(&memcg_oom_lock);",
            "}",
            "static int memcg_oom_wake_function(wait_queue_entry_t *wait,",
            "\tunsigned mode, int sync, void *arg)",
            "{",
            "\tstruct mem_cgroup *wake_memcg = (struct mem_cgroup *)arg;",
            "\tstruct mem_cgroup *oom_wait_memcg;",
            "\tstruct oom_wait_info *oom_wait_info;",
            "",
            "\toom_wait_info = container_of(wait, struct oom_wait_info, wait);",
            "\toom_wait_memcg = oom_wait_info->memcg;",
            "",
            "\tif (!mem_cgroup_is_descendant(wake_memcg, oom_wait_memcg) &&",
            "\t    !mem_cgroup_is_descendant(oom_wait_memcg, wake_memcg))",
            "\t\treturn 0;",
            "\treturn autoremove_wake_function(wait, mode, sync, arg);",
            "}"
          ],
          "function_name": "memcg1_memcg_init, memcg1_css_offline, mem_cgroup_oom_trylock, mem_cgroup_oom_unlock, mem_cgroup_mark_under_oom, mem_cgroup_unmark_under_oom, memcg_oom_wake_function",
          "description": "初始化和管理内存控制组的OOM状态同步机制，包含OOM锁分配尝试、状态标记、事件列表离线处理等。通过遍历cgroup树实现跨层级的OOM状态传播控制。",
          "similarity": 0.5953212380409241
        },
        {
          "chunk_id": 6,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 816,
          "end_line": 1057,
          "content": [
            "static int mem_cgroup_oom_register_event(struct mem_cgroup *memcg,",
            "\tstruct eventfd_ctx *eventfd, const char *args)",
            "{",
            "\tstruct mem_cgroup_eventfd_list *event;",
            "",
            "\tevent = kmalloc(sizeof(*event),\tGFP_KERNEL);",
            "\tif (!event)",
            "\t\treturn -ENOMEM;",
            "",
            "\tspin_lock(&memcg_oom_lock);",
            "",
            "\tevent->eventfd = eventfd;",
            "\tlist_add(&event->list, &memcg->oom_notify);",
            "",
            "\t/* already in OOM ? */",
            "\tif (memcg->under_oom)",
            "\t\teventfd_signal(eventfd);",
            "\tspin_unlock(&memcg_oom_lock);",
            "",
            "\treturn 0;",
            "}",
            "static void mem_cgroup_oom_unregister_event(struct mem_cgroup *memcg,",
            "\tstruct eventfd_ctx *eventfd)",
            "{",
            "\tstruct mem_cgroup_eventfd_list *ev, *tmp;",
            "",
            "\tspin_lock(&memcg_oom_lock);",
            "",
            "\tlist_for_each_entry_safe(ev, tmp, &memcg->oom_notify, list) {",
            "\t\tif (ev->eventfd == eventfd) {",
            "\t\t\tlist_del(&ev->list);",
            "\t\t\tkfree(ev);",
            "\t\t}",
            "\t}",
            "",
            "\tspin_unlock(&memcg_oom_lock);",
            "}",
            "static void memcg_event_remove(struct work_struct *work)",
            "{",
            "\tstruct mem_cgroup_event *event =",
            "\t\tcontainer_of(work, struct mem_cgroup_event, remove);",
            "\tstruct mem_cgroup *memcg = event->memcg;",
            "",
            "\tremove_wait_queue(event->wqh, &event->wait);",
            "",
            "\tevent->unregister_event(memcg, event->eventfd);",
            "",
            "\t/* Notify userspace the event is going away. */",
            "\teventfd_signal(event->eventfd);",
            "",
            "\teventfd_ctx_put(event->eventfd);",
            "\tkfree(event);",
            "\tcss_put(&memcg->css);",
            "}",
            "static int memcg_event_wake(wait_queue_entry_t *wait, unsigned mode,",
            "\t\t\t    int sync, void *key)",
            "{",
            "\tstruct mem_cgroup_event *event =",
            "\t\tcontainer_of(wait, struct mem_cgroup_event, wait);",
            "\tstruct mem_cgroup *memcg = event->memcg;",
            "\t__poll_t flags = key_to_poll(key);",
            "",
            "\tif (flags & EPOLLHUP) {",
            "\t\t/*",
            "\t\t * If the event has been detached at cgroup removal, we",
            "\t\t * can simply return knowing the other side will cleanup",
            "\t\t * for us.",
            "\t\t *",
            "\t\t * We can't race against event freeing since the other",
            "\t\t * side will require wqh->lock via remove_wait_queue(),",
            "\t\t * which we hold.",
            "\t\t */",
            "\t\tspin_lock(&memcg->event_list_lock);",
            "\t\tif (!list_empty(&event->list)) {",
            "\t\t\tlist_del_init(&event->list);",
            "\t\t\t/*",
            "\t\t\t * We are in atomic context, but cgroup_event_remove()",
            "\t\t\t * may sleep, so we have to call it in workqueue.",
            "\t\t\t */",
            "\t\t\tschedule_work(&event->remove);",
            "\t\t}",
            "\t\tspin_unlock(&memcg->event_list_lock);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static void memcg_event_ptable_queue_proc(struct file *file,",
            "\t\twait_queue_head_t *wqh, poll_table *pt)",
            "{",
            "\tstruct mem_cgroup_event *event =",
            "\t\tcontainer_of(pt, struct mem_cgroup_event, pt);",
            "",
            "\tevent->wqh = wqh;",
            "\tadd_wait_queue(wqh, &event->wait);",
            "}",
            "static ssize_t memcg_write_event_control(struct kernfs_open_file *of,",
            "\t\t\t\t\t char *buf, size_t nbytes, loff_t off)",
            "{",
            "\tstruct cgroup_subsys_state *css = of_css(of);",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);",
            "\tstruct mem_cgroup_event *event;",
            "\tstruct cgroup_subsys_state *cfile_css;",
            "\tunsigned int efd, cfd;",
            "\tstruct fd efile;",
            "\tstruct fd cfile;",
            "\tstruct dentry *cdentry;",
            "\tconst char *name;",
            "\tchar *endp;",
            "\tint ret;",
            "",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\treturn -EOPNOTSUPP;",
            "",
            "\tbuf = strstrip(buf);",
            "",
            "\tefd = simple_strtoul(buf, &endp, 10);",
            "\tif (*endp != ' ')",
            "\t\treturn -EINVAL;",
            "\tbuf = endp + 1;",
            "",
            "\tcfd = simple_strtoul(buf, &endp, 10);",
            "\tif (*endp == '\\0')",
            "\t\tbuf = endp;",
            "\telse if (*endp == ' ')",
            "\t\tbuf = endp + 1;",
            "\telse",
            "\t\treturn -EINVAL;",
            "",
            "\tevent = kzalloc(sizeof(*event), GFP_KERNEL);",
            "\tif (!event)",
            "\t\treturn -ENOMEM;",
            "",
            "\tevent->memcg = memcg;",
            "\tINIT_LIST_HEAD(&event->list);",
            "\tinit_poll_funcptr(&event->pt, memcg_event_ptable_queue_proc);",
            "\tinit_waitqueue_func_entry(&event->wait, memcg_event_wake);",
            "\tINIT_WORK(&event->remove, memcg_event_remove);",
            "",
            "\tefile = fdget(efd);",
            "\tif (!efile.file) {",
            "\t\tret = -EBADF;",
            "\t\tgoto out_kfree;",
            "\t}",
            "",
            "\tevent->eventfd = eventfd_ctx_fileget(efile.file);",
            "\tif (IS_ERR(event->eventfd)) {",
            "\t\tret = PTR_ERR(event->eventfd);",
            "\t\tgoto out_put_efile;",
            "\t}",
            "",
            "\tcfile = fdget(cfd);",
            "\tif (!cfile.file) {",
            "\t\tret = -EBADF;",
            "\t\tgoto out_put_eventfd;",
            "\t}",
            "",
            "\t/* the process need read permission on control file */",
            "\t/* AV: shouldn't we check that it's been opened for read instead? */",
            "\tret = file_permission(cfile.file, MAY_READ);",
            "\tif (ret < 0)",
            "\t\tgoto out_put_cfile;",
            "",
            "\t/*",
            "\t * The control file must be a regular cgroup1 file. As a regular cgroup",
            "\t * file can't be renamed, it's safe to access its name afterwards.",
            "\t */",
            "\tcdentry = cfile.file->f_path.dentry;",
            "\tif (cdentry->d_sb->s_type != &cgroup_fs_type || !d_is_reg(cdentry)) {",
            "\t\tret = -EINVAL;",
            "\t\tgoto out_put_cfile;",
            "\t}",
            "",
            "\t/*",
            "\t * Determine the event callbacks and set them in @event.  This used",
            "\t * to be done via struct cftype but cgroup core no longer knows",
            "\t * about these events.  The following is crude but the whole thing",
            "\t * is for compatibility anyway.",
            "\t *",
            "\t * DO NOT ADD NEW FILES.",
            "\t */",
            "\tname = cdentry->d_name.name;",
            "",
            "\tif (!strcmp(name, \"memory.usage_in_bytes\")) {",
            "\t\tevent->register_event = mem_cgroup_usage_register_event;",
            "\t\tevent->unregister_event = mem_cgroup_usage_unregister_event;",
            "\t} else if (!strcmp(name, \"memory.oom_control\")) {",
            "\t\tevent->register_event = mem_cgroup_oom_register_event;",
            "\t\tevent->unregister_event = mem_cgroup_oom_unregister_event;",
            "\t} else if (!strcmp(name, \"memory.pressure_level\")) {",
            "\t\tevent->register_event = vmpressure_register_event;",
            "\t\tevent->unregister_event = vmpressure_unregister_event;",
            "\t} else if (!strcmp(name, \"memory.memsw.usage_in_bytes\")) {",
            "\t\tevent->register_event = memsw_cgroup_usage_register_event;",
            "\t\tevent->unregister_event = memsw_cgroup_usage_unregister_event;",
            "\t} else {",
            "\t\tret = -EINVAL;",
            "\t\tgoto out_put_cfile;",
            "\t}",
            "",
            "\t/*",
            "\t * Verify @cfile should belong to @css.  Also, remaining events are",
            "\t * automatically removed on cgroup destruction but the removal is",
            "\t * asynchronous, so take an extra ref on @css.",
            "\t */",
            "\tcfile_css = css_tryget_online_from_dir(cdentry->d_parent,",
            "\t\t\t\t\t       &memory_cgrp_subsys);",
            "\tret = -EINVAL;",
            "\tif (IS_ERR(cfile_css))",
            "\t\tgoto out_put_cfile;",
            "\tif (cfile_css != css) {",
            "\t\tcss_put(cfile_css);",
            "\t\tgoto out_put_cfile;",
            "\t}",
            "",
            "\tret = event->register_event(memcg, event->eventfd, buf);",
            "\tif (ret)",
            "\t\tgoto out_put_css;",
            "",
            "\tvfs_poll(efile.file, &event->pt);",
            "",
            "\tspin_lock_irq(&memcg->event_list_lock);",
            "\tlist_add(&event->list, &memcg->event_list);",
            "\tspin_unlock_irq(&memcg->event_list_lock);",
            "",
            "\tfdput(cfile);",
            "\tfdput(efile);",
            "",
            "\treturn nbytes;",
            "",
            "out_put_css:",
            "\tcss_put(css);",
            "out_put_cfile:",
            "\tfdput(cfile);",
            "out_put_eventfd:",
            "\teventfd_ctx_put(event->eventfd);",
            "out_put_efile:",
            "\tfdput(efile);",
            "out_kfree:",
            "\tkfree(event);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "mem_cgroup_oom_register_event, mem_cgroup_oom_unregister_event, memcg_event_remove, memcg_event_wake, memcg_event_ptable_queue_proc, memcg_write_event_control",
          "description": "提供OOM事件注册/注销接口及等待队列处理逻辑，通过eventfd跟踪OOM通知订阅者。包含事件唤醒回调、poll表注册函数及控制文件接口，支持通过cgroup子系统配置内存相关事件回调函数。",
          "similarity": 0.5885217785835266
        },
        {
          "chunk_id": 4,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 537,
          "end_line": 698,
          "content": [
            "static void memcg1_check_events(struct mem_cgroup *memcg, int nid)",
            "{",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\treturn;",
            "",
            "\t/* threshold event is triggered in finer grain than soft limit */",
            "\tif (unlikely(memcg1_event_ratelimit(memcg,",
            "\t\t\t\t\t\tMEM_CGROUP_TARGET_THRESH))) {",
            "\t\tbool do_softlimit;",
            "",
            "\t\tdo_softlimit = memcg1_event_ratelimit(memcg,",
            "\t\t\t\t\t\tMEM_CGROUP_TARGET_SOFTLIMIT);",
            "\t\tmem_cgroup_threshold(memcg);",
            "\t\tif (unlikely(do_softlimit))",
            "\t\t\tmemcg1_update_tree(memcg, nid);",
            "\t}",
            "}",
            "void memcg1_commit_charge(struct folio *folio, struct mem_cgroup *memcg)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\tmemcg1_charge_statistics(memcg, folio_nr_pages(folio));",
            "\tmemcg1_check_events(memcg, folio_nid(folio));",
            "\tlocal_irq_restore(flags);",
            "}",
            "void memcg1_swapout(struct folio *folio, struct mem_cgroup *memcg)",
            "{",
            "\t/*",
            "\t * Interrupts should be disabled here because the caller holds the",
            "\t * i_pages lock which is taken with interrupts-off. It is",
            "\t * important here to have the interrupts disabled because it is the",
            "\t * only synchronisation we have for updating the per-CPU variables.",
            "\t */",
            "\tpreempt_disable_nested();",
            "\tVM_WARN_ON_IRQS_ENABLED();",
            "\tmemcg1_charge_statistics(memcg, -folio_nr_pages(folio));",
            "\tpreempt_enable_nested();",
            "\tmemcg1_check_events(memcg, folio_nid(folio));",
            "}",
            "void memcg1_uncharge_batch(struct mem_cgroup *memcg, unsigned long pgpgout,",
            "\t\t\t   unsigned long nr_memory, int nid)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\t__count_memcg_events(memcg, PGPGOUT, pgpgout);",
            "\t__this_cpu_add(memcg->events_percpu->nr_page_events, nr_memory);",
            "\tmemcg1_check_events(memcg, nid);",
            "\tlocal_irq_restore(flags);",
            "}",
            "static int compare_thresholds(const void *a, const void *b)",
            "{",
            "\tconst struct mem_cgroup_threshold *_a = a;",
            "\tconst struct mem_cgroup_threshold *_b = b;",
            "",
            "\tif (_a->threshold > _b->threshold)",
            "\t\treturn 1;",
            "",
            "\tif (_a->threshold < _b->threshold)",
            "\t\treturn -1;",
            "",
            "\treturn 0;",
            "}",
            "static int mem_cgroup_oom_notify_cb(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup_eventfd_list *ev;",
            "",
            "\tspin_lock(&memcg_oom_lock);",
            "",
            "\tlist_for_each_entry(ev, &memcg->oom_notify, list)",
            "\t\teventfd_signal(ev->eventfd);",
            "",
            "\tspin_unlock(&memcg_oom_lock);",
            "\treturn 0;",
            "}",
            "static void mem_cgroup_oom_notify(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup *iter;",
            "",
            "\tfor_each_mem_cgroup_tree(iter, memcg)",
            "\t\tmem_cgroup_oom_notify_cb(iter);",
            "}",
            "static int __mem_cgroup_usage_register_event(struct mem_cgroup *memcg,",
            "\tstruct eventfd_ctx *eventfd, const char *args, enum res_type type)",
            "{",
            "\tstruct mem_cgroup_thresholds *thresholds;",
            "\tstruct mem_cgroup_threshold_ary *new;",
            "\tunsigned long threshold;",
            "\tunsigned long usage;",
            "\tint i, size, ret;",
            "",
            "\tret = page_counter_memparse(args, \"-1\", &threshold);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tmutex_lock(&memcg->thresholds_lock);",
            "",
            "\tif (type == _MEM) {",
            "\t\tthresholds = &memcg->thresholds;",
            "\t\tusage = mem_cgroup_usage(memcg, false);",
            "\t} else if (type == _MEMSWAP) {",
            "\t\tthresholds = &memcg->memsw_thresholds;",
            "\t\tusage = mem_cgroup_usage(memcg, true);",
            "\t} else",
            "\t\tBUG();",
            "",
            "\t/* Check if a threshold crossed before adding a new one */",
            "\tif (thresholds->primary)",
            "\t\t__mem_cgroup_threshold(memcg, type == _MEMSWAP);",
            "",
            "\tsize = thresholds->primary ? thresholds->primary->size + 1 : 1;",
            "",
            "\t/* Allocate memory for new array of thresholds */",
            "\tnew = kmalloc(struct_size(new, entries, size), GFP_KERNEL);",
            "\tif (!new) {",
            "\t\tret = -ENOMEM;",
            "\t\tgoto unlock;",
            "\t}",
            "\tnew->size = size;",
            "",
            "\t/* Copy thresholds (if any) to new array */",
            "\tif (thresholds->primary)",
            "\t\tmemcpy(new->entries, thresholds->primary->entries,",
            "\t\t       flex_array_size(new, entries, size - 1));",
            "",
            "\t/* Add new threshold */",
            "\tnew->entries[size - 1].eventfd = eventfd;",
            "\tnew->entries[size - 1].threshold = threshold;",
            "",
            "\t/* Sort thresholds. Registering of new threshold isn't time-critical */",
            "\tsort(new->entries, size, sizeof(*new->entries),",
            "\t\t\tcompare_thresholds, NULL);",
            "",
            "\t/* Find current threshold */",
            "\tnew->current_threshold = -1;",
            "\tfor (i = 0; i < size; i++) {",
            "\t\tif (new->entries[i].threshold <= usage) {",
            "\t\t\t/*",
            "\t\t\t * new->current_threshold will not be used until",
            "\t\t\t * rcu_assign_pointer(), so it's safe to increment",
            "\t\t\t * it here.",
            "\t\t\t */",
            "\t\t\t++new->current_threshold;",
            "\t\t} else",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\t/* Free old spare buffer and save old primary buffer as spare */",
            "\tkfree(thresholds->spare);",
            "\tthresholds->spare = thresholds->primary;",
            "",
            "\trcu_assign_pointer(thresholds->primary, new);",
            "",
            "\t/* To be sure that nobody uses thresholds */",
            "\tsynchronize_rcu();",
            "",
            "unlock:",
            "\tmutex_unlock(&memcg->thresholds_lock);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "memcg1_check_events, memcg1_commit_charge, memcg1_swapout, memcg1_uncharge_batch, compare_thresholds, mem_cgroup_oom_notify_cb, mem_cgroup_oom_notify, __mem_cgroup_usage_register_event",
          "description": "集成内存使用事件检测与通知系统，包含页面计数更新、事件触发检查、OOM通知传播等功能，通过RCU机制安全更新阈值数组，并处理内存分配/释放时的统计与监控任务。",
          "similarity": 0.584460437297821
        },
        {
          "chunk_id": 2,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 222,
          "end_line": 364,
          "content": [
            "void memcg1_remove_from_trees(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup_tree_per_node *mctz;",
            "\tstruct mem_cgroup_per_node *mz;",
            "\tint nid;",
            "",
            "\tfor_each_node(nid) {",
            "\t\tmz = memcg->nodeinfo[nid];",
            "\t\tmctz = soft_limit_tree.rb_tree_per_node[nid];",
            "\t\tif (mctz)",
            "\t\t\tmem_cgroup_remove_exceeded(mz, mctz);",
            "\t}",
            "}",
            "static int mem_cgroup_soft_reclaim(struct mem_cgroup *root_memcg,",
            "\t\t\t\t   pg_data_t *pgdat,",
            "\t\t\t\t   gfp_t gfp_mask,",
            "\t\t\t\t   unsigned long *total_scanned)",
            "{",
            "\tstruct mem_cgroup *victim = NULL;",
            "\tint total = 0;",
            "\tint loop = 0;",
            "\tunsigned long excess;",
            "\tunsigned long nr_scanned;",
            "\tstruct mem_cgroup_reclaim_cookie reclaim = {",
            "\t\t.pgdat = pgdat,",
            "\t};",
            "",
            "\texcess = soft_limit_excess(root_memcg);",
            "",
            "\twhile (1) {",
            "\t\tvictim = mem_cgroup_iter(root_memcg, victim, &reclaim);",
            "\t\tif (!victim) {",
            "\t\t\tloop++;",
            "\t\t\tif (loop >= 2) {",
            "\t\t\t\t/*",
            "\t\t\t\t * If we have not been able to reclaim",
            "\t\t\t\t * anything, it might because there are",
            "\t\t\t\t * no reclaimable pages under this hierarchy",
            "\t\t\t\t */",
            "\t\t\t\tif (!total)",
            "\t\t\t\t\tbreak;",
            "\t\t\t\t/*",
            "\t\t\t\t * We want to do more targeted reclaim.",
            "\t\t\t\t * excess >> 2 is not to excessive so as to",
            "\t\t\t\t * reclaim too much, nor too less that we keep",
            "\t\t\t\t * coming back to reclaim from this cgroup",
            "\t\t\t\t */",
            "\t\t\t\tif (total >= (excess >> 2) ||",
            "\t\t\t\t\t(loop > MEM_CGROUP_MAX_RECLAIM_LOOPS))",
            "\t\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\ttotal += mem_cgroup_shrink_node(victim, gfp_mask, false,",
            "\t\t\t\t\tpgdat, &nr_scanned);",
            "\t\t*total_scanned += nr_scanned;",
            "\t\tif (!soft_limit_excess(root_memcg))",
            "\t\t\tbreak;",
            "\t}",
            "\tmem_cgroup_iter_break(root_memcg, victim);",
            "\treturn total;",
            "}",
            "unsigned long memcg1_soft_limit_reclaim(pg_data_t *pgdat, int order,",
            "\t\t\t\t\t    gfp_t gfp_mask,",
            "\t\t\t\t\t    unsigned long *total_scanned)",
            "{",
            "\tunsigned long nr_reclaimed = 0;",
            "\tstruct mem_cgroup_per_node *mz, *next_mz = NULL;",
            "\tunsigned long reclaimed;",
            "\tint loop = 0;",
            "\tstruct mem_cgroup_tree_per_node *mctz;",
            "\tunsigned long excess;",
            "",
            "\tif (lru_gen_enabled())",
            "\t\treturn 0;",
            "",
            "\tif (order > 0)",
            "\t\treturn 0;",
            "",
            "\tmctz = soft_limit_tree.rb_tree_per_node[pgdat->node_id];",
            "",
            "\t/*",
            "\t * Do not even bother to check the largest node if the root",
            "\t * is empty. Do it lockless to prevent lock bouncing. Races",
            "\t * are acceptable as soft limit is best effort anyway.",
            "\t */",
            "\tif (!mctz || RB_EMPTY_ROOT(&mctz->rb_root))",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * This loop can run a while, specially if mem_cgroup's continuously",
            "\t * keep exceeding their soft limit and putting the system under",
            "\t * pressure",
            "\t */",
            "\tdo {",
            "\t\tif (next_mz)",
            "\t\t\tmz = next_mz;",
            "\t\telse",
            "\t\t\tmz = mem_cgroup_largest_soft_limit_node(mctz);",
            "\t\tif (!mz)",
            "\t\t\tbreak;",
            "",
            "\t\treclaimed = mem_cgroup_soft_reclaim(mz->memcg, pgdat,",
            "\t\t\t\t\t\t    gfp_mask, total_scanned);",
            "\t\tnr_reclaimed += reclaimed;",
            "\t\tspin_lock_irq(&mctz->lock);",
            "",
            "\t\t/*",
            "\t\t * If we failed to reclaim anything from this memory cgroup",
            "\t\t * it is time to move on to the next cgroup",
            "\t\t */",
            "\t\tnext_mz = NULL;",
            "\t\tif (!reclaimed)",
            "\t\t\tnext_mz = __mem_cgroup_largest_soft_limit_node(mctz);",
            "",
            "\t\texcess = soft_limit_excess(mz->memcg);",
            "\t\t/*",
            "\t\t * One school of thought says that we should not add",
            "\t\t * back the node to the tree if reclaim returns 0.",
            "\t\t * But our reclaim could return 0, simply because due",
            "\t\t * to priority we are exposing a smaller subset of",
            "\t\t * memory to reclaim from. Consider this as a longer",
            "\t\t * term TODO.",
            "\t\t */",
            "\t\t/* If excess == 0, no tree ops */",
            "\t\t__mem_cgroup_insert_exceeded(mz, mctz, excess);",
            "\t\tspin_unlock_irq(&mctz->lock);",
            "\t\tcss_put(&mz->memcg->css);",
            "\t\tloop++;",
            "\t\t/*",
            "\t\t * Could not reclaim anything and there are no more",
            "\t\t * mem cgroups to try or we seem to be looping without",
            "\t\t * reclaiming anything.",
            "\t\t */",
            "\t\tif (!nr_reclaimed &&",
            "\t\t\t(next_mz == NULL ||",
            "\t\t\tloop > MEM_CGROUP_MAX_SOFT_LIMIT_RECLAIM_LOOPS))",
            "\t\t\tbreak;",
            "\t} while (!nr_reclaimed);",
            "\tif (next_mz)",
            "\t\tcss_put(&next_mz->memcg->css);",
            "\treturn nr_reclaimed;",
            "}"
          ],
          "function_name": "memcg1_remove_from_trees, mem_cgroup_soft_reclaim, memcg1_soft_limit_reclaim",
          "description": "提供内存回收逻辑，当内存控制组超过软限制时，通过迭代寻找目标cgroup执行内存回收操作，并通过循环控制防止无限回收，最终返回回收的页面数量。",
          "similarity": 0.5811134576797485
        }
      ]
    }
  ]
}