{
  "query": "Linux内存管理子系统源码分析",
  "timestamp": "2025-12-22 14:00:19",
  "retrieved_files": [
    {
      "source_file": "mm/memcontrol.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:39:41\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memcontrol.c`\n\n---\n\n# memcontrol.c 技术文档\n\n## 1. 文件概述\n\n`memcontrol.c` 是 Linux 内核中内存控制组（Memory Cgroup, memcg）的核心实现文件，负责对进程组的内存资源进行隔离、限制、统计和回收。该文件实现了基于 cgroup v1 和 v2 的统一内存控制器，支持用户内存、内核内存、套接字内存以及 BPF 内存等多种内存类型的细粒度管理，并集成了内存压力通知（vmpressure）、OOM 控制、页面回收等关键机制。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `memory_cgrp_subsys`：cgroup 子系统实例，注册为内存控制器。\n- `root_mem_cgroup`：根内存控制组，所有未显式归属的内存默认计入此组。\n- `int_active_memcg`（per-CPU）：中断上下文中使用的活跃 memcg 指针。\n- `cgroup_memory_nosocket` / `cgroup_memory_nokmem` / `cgroup_memory_nobpf`：控制是否启用套接字、内核内存、BPF 内存的会计功能。\n- `memcg_kmem_online_key` / `memcg_bpf_enabled_key`：静态分支键，用于优化内存会计路径。\n\n### 关键数据结构\n- `struct mem_cgroup`：内存控制组的核心结构，包含内存计数器、LRU 链表、压力监控、OOM 状态等。\n- `struct obj_cgroup`：用于内核对象（如 slab）内存会计的辅助结构，通过引用计数管理生命周期。\n\n### 主要函数\n- `mem_cgroup_css_from_folio()`：根据 folio 获取其所属 memcg 的 cgroup_subsys_state（css）。\n- `page_cgroup_ino()`：获取页面所归属 memcg 的 cgroup inode 编号（用于 procfs 等接口）。\n- `obj_cgroup_release()`：当 obj_cgroup 引用计数归零时释放剩余未清账的内存页。\n- `obj_cgroup_alloc()`：分配并初始化一个新的 obj_cgroup 实例。\n- `memcg_reparent_objcgs()`：在 memcg 被销毁时，将其关联的 obj_cgroup 重新归属到父 memcg。\n- `mem_cgroup_kmem_disabled()`：查询内核内存会计是否被禁用。\n- `memcg_to_vmpressure()` / `vmpressure_to_memcg()`：在 memcg 与 vmpressure 结构之间相互转换。\n\n## 3. 关键实现\n\n### 内存会计模型\n- **统一层级模型**：支持 cgroup v2 的统一层级（unified hierarchy），同时兼容 v1 的多层级模式。\n- **锁无关页面跟踪**：通过 per-CPU stock 机制减少高频内存分配/释放路径上的锁竞争。\n- **对象级内存会计**：使用 `obj_cgroup` 对 slab 等内核对象进行精确计费，支持延迟清账（deferred uncharge）。\n\n### 生命周期管理\n- `obj_cgroup` 使用 `percpu_ref` 引用计数机制，确保在所有 CPU 上的操作完成后再释放资源。\n- 在 memcg 销毁时，通过 `memcg_reparent_objcgs()` 将未释放的 obj_cgroup 安全迁移至父 memcg，避免内存泄漏。\n\n### 中断上下文支持\n- 通过 `int_active_memcg` per-CPU 变量，在中断或软中断上下文中临时绑定当前 memcg，使得网络、块设备等子系统可在中断中正确进行内存会计。\n\n### 内存压力监控\n- 每个 memcg 内嵌 `struct vmpressure`，用于检测内存压力等级（low/medium/critical），触发用户态通知或后台回收。\n\n### 安全与健壮性\n- `page_cgroup_ino()` 明确标注为“racy”，仅适用于不要求强一致性的只读接口（如 `/proc/pid/smaps`）。\n- 在 `obj_cgroup_release()` 中校验 `nr_charged_bytes` 是否对齐 PAGE_SIZE，防止非整页残留导致会计错误。\n\n## 4. 依赖关系\n\n### 头文件依赖\n- **核心内存管理**：`<linux/mm.h>`, `<linux/page_counter.h>`, `<linux/vmpressure.h>`, `<linux/swap.h>`\n- **cgroup 基础设施**：`<linux/cgroup.h>`, `\"internal.h\"`\n- **slab 分配器**：`\"slab.h\"`, `\"memcontrol-v1.h\"`\n- **网络子系统**：`<net/sock.h>`（用于 socket 内存会计）\n- **追踪与调试**：`<trace/events/vmscan.h>`, `<linux/kmemleak.h>`\n\n### 功能依赖\n- **页面回收**：与 vmscan 子系统紧密集成，参与 LRU 链表管理和直接/后台回收。\n- **OOM Killer**：提供 memcg 级别的 OOM 判定和 victim 选择支持。\n- **PSI（Pressure Stall Information）**：与 psi 子系统协作提供资源压力指标。\n- **Writeback 控制**：通过 `CONFIG_CGROUP_WRITEBACK` 支持脏页回写带宽限制。\n- **Zswap 与交换**：与 zswap、swap_cgroup 协同管理压缩交换内存。\n\n## 5. 使用场景\n\n- **容器资源隔离**：Docker、Kubernetes 等容器运行时通过 memcg 限制单个容器的内存使用上限。\n- **多租户系统**：云平台利用 memcg 防止单个租户耗尽系统内存。\n- **内核内存防护**：通过 `memory.kmem.limit_in_bytes` 限制 slab 等内核内存，防止内核内存耗尽（KMEM accounting）。\n- **内存压力响应**：应用程序监听 memory.pressure 接口，在内存紧张时主动释放缓存。\n- **性能分析**：通过 `/sys/fs/cgroup/memory/.../memory.stat` 等接口监控各 memcg 的内存分布和回收行为。\n- **OOM 管理**：当 memcg 超限时触发局部 OOM，仅杀死该组内进程，不影响系统其他部分。",
      "similarity": 0.6593286991119385,
      "chunks": [
        {
          "chunk_id": 15,
          "file_path": "mm/memcontrol.c",
          "start_line": 3052,
          "end_line": 3157,
          "content": [
            "unsigned long mem_cgroup_usage(struct mem_cgroup *memcg, bool swap)",
            "{",
            "\tunsigned long val;",
            "",
            "\tif (mem_cgroup_is_root(memcg)) {",
            "\t\t/*",
            "\t\t * Approximate root's usage from global state. This isn't",
            "\t\t * perfect, but the root usage was always an approximation.",
            "\t\t */",
            "\t\tval = global_node_page_state(NR_FILE_PAGES) +",
            "\t\t\tglobal_node_page_state(NR_ANON_MAPPED);",
            "\t\tif (swap)",
            "\t\t\tval += total_swap_pages - get_nr_swap_pages();",
            "\t} else {",
            "\t\tif (!swap)",
            "\t\t\tval = page_counter_read(&memcg->memory);",
            "\t\telse",
            "\t\t\tval = page_counter_read(&memcg->memsw);",
            "\t}",
            "\treturn val;",
            "}",
            "static int memcg_online_kmem(struct mem_cgroup *memcg)",
            "{",
            "\tstruct obj_cgroup *objcg;",
            "",
            "\tif (mem_cgroup_kmem_disabled())",
            "\t\treturn 0;",
            "",
            "\tif (unlikely(mem_cgroup_is_root(memcg)))",
            "\t\treturn 0;",
            "",
            "\tobjcg = obj_cgroup_alloc();",
            "\tif (!objcg)",
            "\t\treturn -ENOMEM;",
            "",
            "\tobjcg->memcg = memcg;",
            "\trcu_assign_pointer(memcg->objcg, objcg);",
            "\tobj_cgroup_get(objcg);",
            "\tmemcg->orig_objcg = objcg;",
            "",
            "\tstatic_branch_enable(&memcg_kmem_online_key);",
            "",
            "\tmemcg->kmemcg_id = memcg->id.id;",
            "",
            "\treturn 0;",
            "}",
            "static void memcg_offline_kmem(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup *parent;",
            "",
            "\tif (mem_cgroup_kmem_disabled())",
            "\t\treturn;",
            "",
            "\tif (unlikely(mem_cgroup_is_root(memcg)))",
            "\t\treturn;",
            "",
            "\tparent = parent_mem_cgroup(memcg);",
            "\tif (!parent)",
            "\t\tparent = root_mem_cgroup;",
            "",
            "\tmemcg_reparent_objcgs(memcg, parent);",
            "",
            "\t/*",
            "\t * After we have finished memcg_reparent_objcgs(), all list_lrus",
            "\t * corresponding to this cgroup are guaranteed to remain empty.",
            "\t * The ordering is imposed by list_lru_node->lock taken by",
            "\t * memcg_reparent_list_lrus().",
            "\t */",
            "\tmemcg_reparent_list_lrus(memcg, parent);",
            "}",
            "static int memcg_wb_domain_init(struct mem_cgroup *memcg, gfp_t gfp)",
            "{",
            "\treturn wb_domain_init(&memcg->cgwb_domain, gfp);",
            "}",
            "static void memcg_wb_domain_exit(struct mem_cgroup *memcg)",
            "{",
            "\twb_domain_exit(&memcg->cgwb_domain);",
            "}",
            "static void memcg_wb_domain_size_changed(struct mem_cgroup *memcg)",
            "{",
            "\twb_domain_size_changed(&memcg->cgwb_domain);",
            "}",
            "void mem_cgroup_wb_stats(struct bdi_writeback *wb, unsigned long *pfilepages,",
            "\t\t\t unsigned long *pheadroom, unsigned long *pdirty,",
            "\t\t\t unsigned long *pwriteback)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(wb->memcg_css);",
            "\tstruct mem_cgroup *parent;",
            "",
            "\tmem_cgroup_flush_stats_ratelimited(memcg);",
            "",
            "\t*pdirty = memcg_page_state(memcg, NR_FILE_DIRTY);",
            "\t*pwriteback = memcg_page_state(memcg, NR_WRITEBACK);",
            "\t*pfilepages = memcg_page_state(memcg, NR_INACTIVE_FILE) +",
            "\t\t\tmemcg_page_state(memcg, NR_ACTIVE_FILE);",
            "",
            "\t*pheadroom = PAGE_COUNTER_MAX;",
            "\twhile ((parent = parent_mem_cgroup(memcg))) {",
            "\t\tunsigned long ceiling = min(READ_ONCE(memcg->memory.max),",
            "\t\t\t\t\t    READ_ONCE(memcg->memory.high));",
            "\t\tunsigned long used = page_counter_read(&memcg->memory);",
            "",
            "\t\t*pheadroom = min(*pheadroom, ceiling - min(ceiling, used));",
            "\t\tmemcg = parent;",
            "\t}",
            "}"
          ],
          "function_name": "mem_cgroup_usage, memcg_online_kmem, memcg_offline_kmem, memcg_wb_domain_init, memcg_wb_domain_exit, memcg_wb_domain_size_changed, mem_cgroup_wb_stats",
          "description": "该代码段实现内存控制组（memcg）的核心资源管理功能，涵盖内存使用统计、KMEM对象管理及写回域控制。  \n`mem_cgroup_usage` 计算内存控制组的当前使用量（含/不含交换），`memcg_online_kmem`/`memcg_offline_kmem` 管理KMEM对象的动态注册与迁移，`wb_domain_*` 函数序列化写回域生命周期并维护统计信息。  \n`mem_cgroup_wb_stats` 收集并递归汇总内存控制组的脏页、写回页等统计指标，用于内存压力评估与回收决策。",
          "similarity": 0.6158148646354675
        },
        {
          "chunk_id": 22,
          "file_path": "mm/memcontrol.c",
          "start_line": 4225,
          "end_line": 4326,
          "content": [
            "static ssize_t memory_reclaim(struct kernfs_open_file *of, char *buf,",
            "\t\t\t      size_t nbytes, loff_t off)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));",
            "\tunsigned int nr_retries = MAX_RECLAIM_RETRIES;",
            "\tunsigned long nr_to_reclaim, nr_reclaimed = 0;",
            "\tunsigned int reclaim_options;",
            "\tint err;",
            "",
            "\tbuf = strstrip(buf);",
            "\terr = page_counter_memparse(buf, \"\", &nr_to_reclaim);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\treclaim_options\t= MEMCG_RECLAIM_MAY_SWAP | MEMCG_RECLAIM_PROACTIVE;",
            "\twhile (nr_reclaimed < nr_to_reclaim) {",
            "\t\tunsigned long reclaimed;",
            "",
            "\t\tif (signal_pending(current))",
            "\t\t\treturn -EINTR;",
            "",
            "\t\t/*",
            "\t\t * This is the final attempt, drain percpu lru caches in the",
            "\t\t * hope of introducing more evictable pages for",
            "\t\t * try_to_free_mem_cgroup_pages().",
            "\t\t */",
            "\t\tif (!nr_retries)",
            "\t\t\tlru_add_drain_all();",
            "",
            "\t\treclaimed = try_to_free_mem_cgroup_pages(memcg,",
            "\t\t\t\t\tmin(nr_to_reclaim - nr_reclaimed, SWAP_CLUSTER_MAX),",
            "\t\t\t\t\tGFP_KERNEL, reclaim_options);",
            "",
            "\t\tif (!reclaimed && !nr_retries--)",
            "\t\t\treturn -EAGAIN;",
            "",
            "\t\tnr_reclaimed += reclaimed;",
            "\t}",
            "",
            "\treturn nbytes;",
            "}",
            "void mem_cgroup_calculate_protection(struct mem_cgroup *root,",
            "\t\t\t\t     struct mem_cgroup *memcg)",
            "{",
            "\tbool recursive_protection =",
            "\t\tcgrp_dfl_root.flags & CGRP_ROOT_MEMORY_RECURSIVE_PROT;",
            "",
            "\tif (mem_cgroup_disabled())",
            "\t\treturn;",
            "",
            "\tif (!root)",
            "\t\troot = root_mem_cgroup;",
            "",
            "\tpage_counter_calculate_protection(&root->memory, &memcg->memory, recursive_protection);",
            "}",
            "static int charge_memcg(struct folio *folio, struct mem_cgroup *memcg,",
            "\t\t\tgfp_t gfp)",
            "{",
            "\tint ret;",
            "",
            "\tret = try_charge(memcg, gfp, folio_nr_pages(folio));",
            "\tif (ret)",
            "\t\tgoto out;",
            "",
            "\tcss_get(&memcg->css);",
            "\tcommit_charge(folio, memcg);",
            "\tmemcg1_commit_charge(folio, memcg);",
            "out:",
            "\treturn ret;",
            "}",
            "int __mem_cgroup_charge(struct folio *folio, struct mm_struct *mm, gfp_t gfp)",
            "{",
            "\tstruct mem_cgroup *memcg;",
            "\tint ret;",
            "",
            "\tmemcg = get_mem_cgroup_from_mm(mm);",
            "\tret = charge_memcg(folio, memcg, gfp);",
            "\tcss_put(&memcg->css);",
            "",
            "\treturn ret;",
            "}",
            "int mem_cgroup_charge_hugetlb(struct folio *folio, gfp_t gfp)",
            "{",
            "\tstruct mem_cgroup *memcg = get_mem_cgroup_from_current();",
            "\tint ret = 0;",
            "",
            "\t/*",
            "\t * Even memcg does not account for hugetlb, we still want to update",
            "\t * system-level stats via lruvec_stat_mod_folio. Return 0, and skip",
            "\t * charging the memcg.",
            "\t */",
            "\tif (mem_cgroup_disabled() || !memcg_accounts_hugetlb() ||",
            "\t\t!memcg || !cgroup_subsys_on_dfl(memory_cgrp_subsys))",
            "\t\tgoto out;",
            "",
            "\tif (charge_memcg(folio, memcg, gfp))",
            "\t\tret = -ENOMEM;",
            "",
            "out:",
            "\tmem_cgroup_put(memcg);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "memory_reclaim, mem_cgroup_calculate_protection, charge_memcg, __mem_cgroup_charge, mem_cgroup_charge_hugetlb",
          "description": "实现内存回收逻辑、保护比例计算及内存页充电机制，支持普通页和HugeTLB页的内存计费管理。",
          "similarity": 0.6076546907424927
        },
        {
          "chunk_id": 0,
          "file_path": "mm/memcontrol.c",
          "start_line": 1,
          "end_line": 95,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-or-later",
            "/* memcontrol.c - Memory Controller",
            " *",
            " * Copyright IBM Corporation, 2007",
            " * Author Balbir Singh <balbir@linux.vnet.ibm.com>",
            " *",
            " * Copyright 2007 OpenVZ SWsoft Inc",
            " * Author: Pavel Emelianov <xemul@openvz.org>",
            " *",
            " * Memory thresholds",
            " * Copyright (C) 2009 Nokia Corporation",
            " * Author: Kirill A. Shutemov",
            " *",
            " * Kernel Memory Controller",
            " * Copyright (C) 2012 Parallels Inc. and Google Inc.",
            " * Authors: Glauber Costa and Suleiman Souhlal",
            " *",
            " * Native page reclaim",
            " * Charge lifetime sanitation",
            " * Lockless page tracking & accounting",
            " * Unified hierarchy configuration model",
            " * Copyright (C) 2015 Red Hat, Inc., Johannes Weiner",
            " *",
            " * Per memcg lru locking",
            " * Copyright (C) 2020 Alibaba, Inc, Alex Shi",
            " */",
            "",
            "#include <linux/page_counter.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/vm_event_item.h>",
            "#include <linux/smp.h>",
            "#include <linux/page-flags.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/bit_spinlock.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/limits.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/rbtree.h>",
            "#include <linux/slab.h>",
            "#include <linux/swapops.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/fs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/vmpressure.h>",
            "#include <linux/memremap.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/swap_cgroup.h>",
            "#include <linux/cpu.h>",
            "#include <linux/oom.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/resume_user_mode.h>",
            "#include <linux/psi.h>",
            "#include <linux/seq_buf.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/zswap.h>",
            "#include <linux/kmemleak.h>",
            "#include \"internal.h\"",
            "#include <net/sock.h>",
            "#include <net/ip.h>",
            "#include \"slab.h\"",
            "#include \"memcontrol-v1.h\"",
            "",
            "#include <linux/uaccess.h>",
            "",
            "#include <trace/events/vmscan.h>",
            "",
            "struct cgroup_subsys memory_cgrp_subsys __read_mostly;",
            "EXPORT_SYMBOL(memory_cgrp_subsys);",
            "",
            "struct mem_cgroup *root_mem_cgroup __read_mostly;",
            "",
            "/* Active memory cgroup to use from an interrupt context */",
            "DEFINE_PER_CPU(struct mem_cgroup *, int_active_memcg);",
            "EXPORT_PER_CPU_SYMBOL_GPL(int_active_memcg);",
            "",
            "/* Socket memory accounting disabled? */",
            "static bool cgroup_memory_nosocket __ro_after_init;",
            "",
            "/* Kernel memory accounting disabled? */",
            "static bool cgroup_memory_nokmem __ro_after_init = true;",
            "",
            "/* BPF memory accounting disabled? */",
            "static bool cgroup_memory_nobpf __ro_after_init;",
            "",
            "#ifdef CONFIG_CGROUP_WRITEBACK",
            "static DECLARE_WAIT_QUEUE_HEAD(memcg_cgwb_frn_waitq);",
            "#endif",
            ""
          ],
          "function_name": null,
          "description": "声明内存控制器子系统及全局变量，初始化内存组（mem_cgroup）相关结构，定义控制内核/套接字/BPF内存会计的标志位，包含大量头文件并导出符号。",
          "similarity": 0.6048265099525452
        },
        {
          "chunk_id": 21,
          "file_path": "mm/memcontrol.c",
          "start_line": 4113,
          "end_line": 4214,
          "content": [
            "static void __memory_events_show(struct seq_file *m, atomic_long_t *events)",
            "{",
            "\tseq_printf(m, \"low %lu\\n\", atomic_long_read(&events[MEMCG_LOW]));",
            "\tseq_printf(m, \"high %lu\\n\", atomic_long_read(&events[MEMCG_HIGH]));",
            "\tseq_printf(m, \"max %lu\\n\", atomic_long_read(&events[MEMCG_MAX]));",
            "\tseq_printf(m, \"oom %lu\\n\", atomic_long_read(&events[MEMCG_OOM]));",
            "\tseq_printf(m, \"oom_kill %lu\\n\",",
            "\t\t   atomic_long_read(&events[MEMCG_OOM_KILL]));",
            "\tseq_printf(m, \"oom_group_kill %lu\\n\",",
            "\t\t   atomic_long_read(&events[MEMCG_OOM_GROUP_KILL]));",
            "}",
            "static int memory_events_show(struct seq_file *m, void *v)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);",
            "",
            "\t__memory_events_show(m, memcg->memory_events);",
            "\treturn 0;",
            "}",
            "static int memory_events_local_show(struct seq_file *m, void *v)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);",
            "",
            "\t__memory_events_show(m, memcg->memory_events_local);",
            "\treturn 0;",
            "}",
            "int memory_stat_show(struct seq_file *m, void *v)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);",
            "\tchar *buf = kmalloc(PAGE_SIZE, GFP_KERNEL);",
            "\tstruct seq_buf s;",
            "",
            "\tif (!buf)",
            "\t\treturn -ENOMEM;",
            "\tseq_buf_init(&s, buf, PAGE_SIZE);",
            "\tmemory_stat_format(memcg, &s);",
            "\tseq_puts(m, buf);",
            "\tkfree(buf);",
            "\treturn 0;",
            "}",
            "static inline unsigned long lruvec_page_state_output(struct lruvec *lruvec,",
            "\t\t\t\t\t\t     int item)",
            "{",
            "\treturn lruvec_page_state(lruvec, item) *",
            "\t\tmemcg_page_state_output_unit(item);",
            "}",
            "static int memory_numa_stat_show(struct seq_file *m, void *v)",
            "{",
            "\tint i;",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);",
            "",
            "\tmem_cgroup_flush_stats(memcg);",
            "",
            "\tfor (i = 0; i < ARRAY_SIZE(memory_stats); i++) {",
            "\t\tint nid;",
            "",
            "\t\tif (memory_stats[i].idx >= NR_VM_NODE_STAT_ITEMS)",
            "\t\t\tcontinue;",
            "",
            "\t\tseq_printf(m, \"%s\", memory_stats[i].name);",
            "\t\tfor_each_node_state(nid, N_MEMORY) {",
            "\t\t\tu64 size;",
            "\t\t\tstruct lruvec *lruvec;",
            "",
            "\t\t\tlruvec = mem_cgroup_lruvec(memcg, NODE_DATA(nid));",
            "\t\t\tsize = lruvec_page_state_output(lruvec,",
            "\t\t\t\t\t\t\tmemory_stats[i].idx);",
            "\t\t\tseq_printf(m, \" N%d=%llu\", nid, size);",
            "\t\t}",
            "\t\tseq_putc(m, '\\n');",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int memory_oom_group_show(struct seq_file *m, void *v)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(m);",
            "",
            "\tseq_printf(m, \"%d\\n\", READ_ONCE(memcg->oom_group));",
            "",
            "\treturn 0;",
            "}",
            "static ssize_t memory_oom_group_write(struct kernfs_open_file *of,",
            "\t\t\t\t      char *buf, size_t nbytes, loff_t off)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));",
            "\tint ret, oom_group;",
            "",
            "\tbuf = strstrip(buf);",
            "\tif (!buf)",
            "\t\treturn -EINVAL;",
            "",
            "\tret = kstrtoint(buf, 0, &oom_group);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tif (oom_group != 0 && oom_group != 1)",
            "\t\treturn -EINVAL;",
            "",
            "\tWRITE_ONCE(memcg->oom_group, oom_group);",
            "",
            "\treturn nbytes;",
            "}"
          ],
          "function_name": "__memory_events_show, memory_events_show, memory_events_local_show, memory_stat_show, lruvec_page_state_output, memory_numa_stat_show, memory_oom_group_show, memory_oom_group_write",
          "description": "提供内存事件统计、NUMA节点统计、OOM组配置等功能的读取接口，展示内存控制组的各类统计信息及事件计数。",
          "similarity": 0.6031121015548706
        },
        {
          "chunk_id": 25,
          "file_path": "mm/memcontrol.c",
          "start_line": 4738,
          "end_line": 4854,
          "content": [
            "void mem_cgroup_sk_free(struct sock *sk)",
            "{",
            "\tif (sk->sk_memcg)",
            "\t\tcss_put(&sk->sk_memcg->css);",
            "}",
            "bool mem_cgroup_charge_skmem(struct mem_cgroup *memcg, unsigned int nr_pages,",
            "\t\t\t     gfp_t gfp_mask)",
            "{",
            "\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys))",
            "\t\treturn memcg1_charge_skmem(memcg, nr_pages, gfp_mask);",
            "",
            "\tif (try_charge(memcg, gfp_mask, nr_pages) == 0) {",
            "\t\tmod_memcg_state(memcg, MEMCG_SOCK, nr_pages);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "void mem_cgroup_uncharge_skmem(struct mem_cgroup *memcg, unsigned int nr_pages)",
            "{",
            "\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys)) {",
            "\t\tmemcg1_uncharge_skmem(memcg, nr_pages);",
            "\t\treturn;",
            "\t}",
            "",
            "\tmod_memcg_state(memcg, MEMCG_SOCK, -nr_pages);",
            "",
            "\trefill_stock(memcg, nr_pages);",
            "}",
            "static int __init cgroup_memory(char *s)",
            "{",
            "\tchar *token;",
            "",
            "\twhile ((token = strsep(&s, \",\")) != NULL) {",
            "\t\tif (!*token)",
            "\t\t\tcontinue;",
            "\t\tif (!strcmp(token, \"nosocket\"))",
            "\t\t\tcgroup_memory_nosocket = true;",
            "\t\tif (!strcmp(token, \"nokmem\"))",
            "\t\t\tcgroup_memory_nokmem = true;",
            "\t\telse if (!strcmp(token, \"kmem\"))",
            "\t\t\tcgroup_memory_nokmem = false;",
            "\t\tif (!strcmp(token, \"nobpf\"))",
            "\t\t\tcgroup_memory_nobpf = true;",
            "\t}",
            "\treturn 1;",
            "}",
            "static int __init mem_cgroup_init(void)",
            "{",
            "\tint cpu;",
            "",
            "\t/*",
            "\t * Currently s32 type (can refer to struct batched_lruvec_stat) is",
            "\t * used for per-memcg-per-cpu caching of per-node statistics. In order",
            "\t * to work fine, we should make sure that the overfill threshold can't",
            "\t * exceed S32_MAX / PAGE_SIZE.",
            "\t */",
            "\tBUILD_BUG_ON(MEMCG_CHARGE_BATCH > S32_MAX / PAGE_SIZE);",
            "",
            "\tcpuhp_setup_state_nocalls(CPUHP_MM_MEMCQ_DEAD, \"mm/memctrl:dead\", NULL,",
            "\t\t\t\t  memcg_hotplug_cpu_dead);",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tINIT_WORK(&per_cpu_ptr(&memcg_stock, cpu)->work,",
            "\t\t\t  drain_local_stock);",
            "",
            "\treturn 0;",
            "}",
            "void mem_cgroup_swapout(struct folio *folio, swp_entry_t entry)",
            "{",
            "\tstruct mem_cgroup *memcg, *swap_memcg;",
            "\tunsigned int nr_entries;",
            "",
            "\tVM_BUG_ON_FOLIO(folio_test_lru(folio), folio);",
            "\tVM_BUG_ON_FOLIO(folio_ref_count(folio), folio);",
            "",
            "\tif (mem_cgroup_disabled())",
            "\t\treturn;",
            "",
            "\tif (!do_memsw_account())",
            "\t\treturn;",
            "",
            "\tmemcg = folio_memcg(folio);",
            "",
            "\tVM_WARN_ON_ONCE_FOLIO(!memcg, folio);",
            "\tif (!memcg)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * In case the memcg owning these pages has been offlined and doesn't",
            "\t * have an ID allocated to it anymore, charge the closest online",
            "\t * ancestor for the swap instead and transfer the memory+swap charge.",
            "\t */",
            "\tswap_memcg = mem_cgroup_id_get_online(memcg);",
            "\tnr_entries = folio_nr_pages(folio);",
            "\t/* Get references for the tail pages, too */",
            "\tif (nr_entries > 1)",
            "\t\tmem_cgroup_id_get_many(swap_memcg, nr_entries - 1);",
            "\tmod_memcg_state(swap_memcg, MEMCG_SWAP, nr_entries);",
            "",
            "\tswap_cgroup_record(folio, mem_cgroup_id(swap_memcg), entry);",
            "",
            "\tfolio_unqueue_deferred_split(folio);",
            "\tfolio->memcg_data = 0;",
            "",
            "\tif (!mem_cgroup_is_root(memcg))",
            "\t\tpage_counter_uncharge(&memcg->memory, nr_entries);",
            "",
            "\tif (memcg != swap_memcg) {",
            "\t\tif (!mem_cgroup_is_root(swap_memcg))",
            "\t\t\tpage_counter_charge(&swap_memcg->memsw, nr_entries);",
            "\t\tpage_counter_uncharge(&memcg->memsw, nr_entries);",
            "\t}",
            "",
            "\tmemcg1_swapout(folio, memcg);",
            "\tcss_put(&memcg->css);",
            "}"
          ],
          "function_name": "mem_cgroup_sk_free, mem_cgroup_charge_skmem, mem_cgroup_uncharge_skmem, cgroup_memory, mem_cgroup_init, mem_cgroup_swapout",
          "description": "该代码块实现了内存控制组（memcg）对socket内存的管理，包括释放socket内存引用、分配/回收socket内存以及初始化交换相关功能。其中mem_cgroup_sk_free释放socket内存引用，mem_cgroup_charge_skmem/uncharge_skmem处理socket内存分配回收，mem_cgroup_swapout负责交换页面时的内存账本更新，通过memcg层级传递内存计数并处理离线memcg的迁移。",
          "similarity": 0.5995425581932068
        }
      ]
    },
    {
      "source_file": "kernel/module/main.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:04:44\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `module\\main.c`\n\n---\n\n# `module/main.c` 技术文档\n\n## 1. 文件概述\n\n`module/main.c` 是 Linux 内核模块子系统的核心实现文件，负责模块的加载、卸载、符号解析、内存管理、状态跟踪以及模块间依赖关系的维护。该文件实现了内核模块机制的基础框架，包括模块列表管理、模块内存布局控制、符号查找、模块通知机制、模块引用计数等关键功能，是内核动态加载模块能力的核心支撑。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct mod_tree_root mod_tree`**：用于加速地址到模块映射的全局模块地址范围树，包含 `addr_min`/`addr_max`（及可选的 `data_addr_min`/`data_addr_max`）。\n- **`LIST_HEAD(modules)`**：全局模块链表，存储所有已加载模块。\n- **`DEFINE_MUTEX(module_mutex)`**：保护模块列表、模块使用关系及地址边界的关键互斥锁。\n- **`struct symsearch`**：用于描述符号搜索范围，包含符号起止位置、CRC 校验数组及许可证类型。\n- **`struct find_symbol_arg`**：符号查找的参数结构体，用于传递查找目标及接收结果（所有者、符号指针、CRC、许可证等）。\n\n### 主要函数与接口\n\n- **模块注册/注销通知**：\n  - `register_module_notifier()` / `unregister_module_notifier()`：注册/注销模块生命周期事件通知回调。\n- **模块引用管理**：\n  - `strong_try_module_get()`：强引用获取，拒绝处于 `COMING` 状态的模块。\n  - `__module_put_and_kthread_exit()`：专用于内核线程在退出前释放模块引用。\n- **模块内存边界管理**：\n  - `__mod_update_bounds()` / `mod_update_bounds()`：更新全局模块地址范围，用于加速 `__module_address()`。\n- **ELF 节区辅助函数**：\n  - `find_sec()` / `find_any_sec()`：根据名称查找 ELF 节区索引。\n  - `section_addr()` / `section_objs()`：获取节区地址及对象数量。\n- **符号查找**：\n  - `find_symbol()`：在内核及已加载模块中查找导出符号。\n  - `find_exported_symbol_in_section()`：在指定符号段中二分查找符号。\n- **模块状态与安全**：\n  - `add_taint_module()`：为模块添加污点标记（taint flag）。\n- **全局控制**：\n  - `modules_disabled`：通过 `nomodule` 内核参数控制是否禁用模块加载。\n\n### 全局变量与工作队列\n\n- **`init_free_wq`**：用于异步释放模块初始化段（`.init`）内存的工作队列。\n- **`init_free_list`**：待释放初始化内存的无锁链表。\n- **`module_wq`**：等待模块初始化完成的等待队列。\n\n## 3. 关键实现\n\n### 模块地址范围加速\n\n通过 `mod_tree` 全局结构维护所有模块（或核心数据）的最小/最大虚拟地址。`__module_address()` 可先检查目标地址是否落在 `[addr_min, addr_max]` 范围内，若不在则直接返回 `NULL`，避免遍历整个模块链表，显著提升性能。\n\n### 符号查找机制\n\n- 使用 `bsearch()` 在已排序的导出符号表中进行二分查找，时间复杂度为 O(log n)。\n- 支持符号命名空间（namespace）和 GPL 许可证检查：非 GPL 模块无法使用 `GPL_ONLY` 符号。\n- 通过 `symsearch` 数组统一管理内核及各模块的符号段，实现统一查找接口。\n\n### 模块内存管理\n\n- 模块内存按 `mod_mem_type`（如代码、只读数据、可写数据、初始化段等）分类管理。\n- 初始化段（`.init`）在模块初始化成功后通过工作队列异步释放，节省内存。\n- 支持 `CONFIG_ARCH_WANTS_MODULES_DATA_IN_VMALLOC` 架构选项，将模块数据段单独纳入地址范围管理。\n\n### 模块状态与引用安全\n\n- `strong_try_module_get()` 确保不会对处于 `MODULE_STATE_COMING`（正在初始化）或 `MODULE_STATE_UNFORMED`（未形成）状态的模块增加引用，防止竞态。\n- `__module_put_and_kthread_exit()` 为内核线程提供安全退出路径，在释放模块引用后终止线程。\n\n### 模块通知机制\n\n基于 `blocking_notifier_chain` 实现模块生命周期事件（如加载、卸载、初始化完成等）的通知，允许其他子系统（如 livepatch、ftrace）监听并响应模块状态变化。\n\n### 构建标识与版本校验\n\n- 通过 `INCLUDE_VERMAGIC` 宏包含模块魔数（vermagic）信息，用于加载时内核版本兼容性检查。\n- 支持 `CONFIG_MODVERSIONS`，在符号查找时返回 CRC 校验值，确保符号 ABI 兼容性。\n\n## 4. 依赖关系\n\n- **架构相关**：\n  - 依赖 `asm/cacheflush.h`、`asm/mmu_context.h`、`asm/sections.h` 等架构头文件，处理指令缓存刷新、内存映射等。\n  - 使用 `CONFIG_HAVE_ARCH_PREL32_RELOCATIONS` 优化符号字符串存储。\n- **内核子系统**：\n  - **内存管理**：`vmalloc`、`slab` 用于模块内存分配。\n  - **安全机制**：`capability`、`audit`、`module_signature` 用于模块加载权限和签名验证。\n  - **调试与追踪**：`kallsyms`、`trace_events`、`ftrace`、`dynamic_debug`、`debugfs` 提供模块调试支持。\n  - **并发控制**：`RCU`、`mutex`、`percpu` 用于同步。\n  - **文件系统**：`fs.h`、`kernel_read_file.h` 用于从文件加载模块。\n- **内部依赖**：\n  - 依赖同目录下的 `internal.h`，包含模块子系统内部数据结构和函数声明。\n  - 使用 `uapi/linux/module.h` 定义用户空间接口常量。\n\n## 5. 使用场景\n\n- **动态加载内核模块**：通过 `init_module()` 或 `finit_module()` 系统调用加载 `.ko` 文件时，该文件中的函数负责解析 ELF、重定位、符号解析、执行初始化函数。\n- **模块卸载**：通过 `delete_module()` 系统调用卸载模块时，管理模块引用计数、执行清理函数、释放内存。\n- **内核符号解析**：当模块或内核其他部分调用 `symbol_get()` 或通过 `EXPORT_SYMBOL` 机制访问符号时，`find_symbol()` 被调用。\n- **运行时模块查询**：`/proc/modules`、`/sys/module/` 等接口依赖此文件维护的模块列表和状态信息。\n- **内核热补丁（Livepatch）**：依赖模块通知机制和符号查找功能实现函数替换。\n- **内核调试与性能分析**：ftrace、kprobes 等工具依赖模块地址范围和符号信息进行函数跟踪。",
      "similarity": 0.6457041501998901,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/module/main.c",
          "start_line": 96,
          "end_line": 202,
          "content": [
            "static void __mod_update_bounds(enum mod_mem_type type __maybe_unused, void *base,",
            "\t\t\t\tunsigned int size, struct mod_tree_root *tree)",
            "{",
            "\tunsigned long min = (unsigned long)base;",
            "\tunsigned long max = min + size;",
            "",
            "#ifdef CONFIG_ARCH_WANTS_MODULES_DATA_IN_VMALLOC",
            "\tif (mod_mem_type_is_core_data(type)) {",
            "\t\tif (min < tree->data_addr_min)",
            "\t\t\ttree->data_addr_min = min;",
            "\t\tif (max > tree->data_addr_max)",
            "\t\t\ttree->data_addr_max = max;",
            "\t\treturn;",
            "\t}",
            "#endif",
            "\tif (min < tree->addr_min)",
            "\t\ttree->addr_min = min;",
            "\tif (max > tree->addr_max)",
            "\t\ttree->addr_max = max;",
            "}",
            "static void mod_update_bounds(struct module *mod)",
            "{",
            "\tfor_each_mod_mem_type(type) {",
            "\t\tstruct module_memory *mod_mem = &mod->mem[type];",
            "",
            "\t\tif (mod_mem->size)",
            "\t\t\t__mod_update_bounds(type, mod_mem->base, mod_mem->size, &mod_tree);",
            "\t}",
            "}",
            "int register_module_notifier(struct notifier_block *nb)",
            "{",
            "\treturn blocking_notifier_chain_register(&module_notify_list, nb);",
            "}",
            "int unregister_module_notifier(struct notifier_block *nb)",
            "{",
            "\treturn blocking_notifier_chain_unregister(&module_notify_list, nb);",
            "}",
            "static inline int strong_try_module_get(struct module *mod)",
            "{",
            "\tBUG_ON(mod && mod->state == MODULE_STATE_UNFORMED);",
            "\tif (mod && mod->state == MODULE_STATE_COMING)",
            "\t\treturn -EBUSY;",
            "\tif (try_module_get(mod))",
            "\t\treturn 0;",
            "\telse",
            "\t\treturn -ENOENT;",
            "}",
            "static inline void add_taint_module(struct module *mod, unsigned flag,",
            "\t\t\t\t    enum lockdep_ok lockdep_ok)",
            "{",
            "\tadd_taint(flag, lockdep_ok);",
            "\tset_bit(flag, &mod->taints);",
            "}",
            "void __noreturn __module_put_and_kthread_exit(struct module *mod, long code)",
            "{",
            "\tmodule_put(mod);",
            "\tkthread_exit(code);",
            "}",
            "static unsigned int find_sec(const struct load_info *info, const char *name)",
            "{",
            "\tunsigned int i;",
            "",
            "\tfor (i = 1; i < info->hdr->e_shnum; i++) {",
            "\t\tElf_Shdr *shdr = &info->sechdrs[i];",
            "\t\t/* Alloc bit cleared means \"ignore it.\" */",
            "\t\tif ((shdr->sh_flags & SHF_ALLOC)",
            "\t\t    && strcmp(info->secstrings + shdr->sh_name, name) == 0)",
            "\t\t\treturn i;",
            "\t}",
            "\treturn 0;",
            "}",
            "static unsigned int find_any_sec(const struct load_info *info, const char *name)",
            "{",
            "\tunsigned int i;",
            "",
            "\tfor (i = 1; i < info->hdr->e_shnum; i++) {",
            "\t\tElf_Shdr *shdr = &info->sechdrs[i];",
            "\t\tif (strcmp(info->secstrings + shdr->sh_name, name) == 0)",
            "\t\t\treturn i;",
            "\t}",
            "\treturn 0;",
            "}",
            "int cmp_name(const void *name, const void *sym)",
            "{",
            "\treturn strcmp(name, kernel_symbol_name(sym));",
            "}",
            "static bool find_exported_symbol_in_section(const struct symsearch *syms,",
            "\t\t\t\t\t    struct module *owner,",
            "\t\t\t\t\t    struct find_symbol_arg *fsa)",
            "{",
            "\tstruct kernel_symbol *sym;",
            "",
            "\tif (!fsa->gplok && syms->license == GPL_ONLY)",
            "\t\treturn false;",
            "",
            "\tsym = bsearch(fsa->name, syms->start, syms->stop - syms->start,",
            "\t\t\tsizeof(struct kernel_symbol), cmp_name);",
            "\tif (!sym)",
            "\t\treturn false;",
            "",
            "\tfsa->owner = owner;",
            "\tfsa->crc = symversion(syms->crcs, sym - syms->start);",
            "\tfsa->sym = sym;",
            "\tfsa->license = syms->license;",
            "",
            "\treturn true;",
            "}"
          ],
          "function_name": "__mod_update_bounds, mod_update_bounds, register_module_notifier, unregister_module_notifier, strong_try_module_get, add_taint_module, __module_put_and_kthread_exit, find_sec, find_any_sec, cmp_name, find_exported_symbol_in_section",
          "description": "实现模块内存边界更新逻辑、模块状态变更通知注册与注销接口，以及强引用获取检查函数，用于维护模块内存范围并控制模块生命周期事件。",
          "similarity": 0.6003092527389526
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/module/main.c",
          "start_line": 1925,
          "end_line": 2029,
          "content": [
            "static int copy_chunked_from_user(void *dst, const void __user *usrc, unsigned long len)",
            "{",
            "\tdo {",
            "\t\tunsigned long n = min(len, COPY_CHUNK_SIZE);",
            "",
            "\t\tif (copy_from_user(dst, usrc, n) != 0)",
            "\t\t\treturn -EFAULT;",
            "\t\tcond_resched();",
            "\t\tdst += n;",
            "\t\tusrc += n;",
            "\t\tlen -= n;",
            "\t} while (len);",
            "\treturn 0;",
            "}",
            "static int check_modinfo_livepatch(struct module *mod, struct load_info *info)",
            "{",
            "#ifdef CONFIG_LIVEPATCH_WO_FTRACE",
            "\tif (!get_modinfo(info, \"livepatch\")) {",
            "\t\tset_mod_klp_rel_state(mod, MODULE_KLP_REL_NONE);",
            "\t\treturn 0;",
            "\t}",
            "\tset_mod_klp_rel_state(mod, MODULE_KLP_REL_UNDO);",
            "#else /* !CONFIG_LIVEPATCH_WO_FTRACE */",
            "\tif (!get_modinfo(info, \"livepatch\"))",
            "\t\t/* Nothing more to do */",
            "\t\treturn 0;",
            "#endif /* CONFIG_LIVEPATCH_WO_FTRACE */",
            "",
            "\tif (set_livepatch_module(mod))",
            "\t\treturn 0;",
            "",
            "\tpr_err(\"%s: module is marked as livepatch module, but livepatch support is disabled\",",
            "\t       mod->name);",
            "\treturn -ENOEXEC;",
            "}",
            "static void check_modinfo_retpoline(struct module *mod, struct load_info *info)",
            "{",
            "\tif (retpoline_module_ok(get_modinfo(info, \"retpoline\")))",
            "\t\treturn;",
            "",
            "\tpr_warn(\"%s: loading module not compiled with retpoline compiler.\\n\",",
            "\t\tmod->name);",
            "}",
            "static int copy_module_from_user(const void __user *umod, unsigned long len,",
            "\t\t\t\t  struct load_info *info)",
            "{",
            "\tint err;",
            "",
            "\tinfo->len = len;",
            "\tif (info->len < sizeof(*(info->hdr)))",
            "\t\treturn -ENOEXEC;",
            "",
            "\terr = security_kernel_load_data(LOADING_MODULE, true);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\t/* Suck in entire file: we'll want most of it. */",
            "\tinfo->hdr = __vmalloc(info->len, GFP_KERNEL | __GFP_NOWARN);",
            "\tif (!info->hdr)",
            "\t\treturn -ENOMEM;",
            "",
            "\tif (copy_chunked_from_user(info->hdr, umod, info->len) != 0) {",
            "\t\terr = -EFAULT;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\terr = security_kernel_post_load_data((char *)info->hdr, info->len,",
            "\t\t\t\t\t     LOADING_MODULE, \"init_module\");",
            "out:",
            "\tif (err)",
            "\t\tvfree(info->hdr);",
            "",
            "\treturn err;",
            "}",
            "static void free_copy(struct load_info *info, int flags)",
            "{",
            "\tif (flags & MODULE_INIT_COMPRESSED_FILE)",
            "\t\tmodule_decompress_cleanup(info);",
            "\telse",
            "\t\tvfree(info->hdr);",
            "}",
            "static int rewrite_section_headers(struct load_info *info, int flags)",
            "{",
            "\tunsigned int i;",
            "",
            "\t/* This should always be true, but let's be sure. */",
            "\tinfo->sechdrs[0].sh_addr = 0;",
            "",
            "\tfor (i = 1; i < info->hdr->e_shnum; i++) {",
            "\t\tElf_Shdr *shdr = &info->sechdrs[i];",
            "",
            "\t\t/*",
            "\t\t * Mark all sections sh_addr with their address in the",
            "\t\t * temporary image.",
            "\t\t */",
            "\t\tshdr->sh_addr = (size_t)info->hdr + shdr->sh_offset;",
            "",
            "\t}",
            "",
            "\t/* Track but don't keep modinfo and version sections. */",
            "\tinfo->sechdrs[info->index.vers].sh_flags &= ~(unsigned long)SHF_ALLOC;",
            "\tinfo->sechdrs[info->index.info].sh_flags &= ~(unsigned long)SHF_ALLOC;",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "copy_chunked_from_user, check_modinfo_livepatch, check_modinfo_retpoline, copy_module_from_user, free_copy, rewrite_section_headers",
          "description": "实现分块从用户空间复制数据到内核缓冲区，检查模块livepatch属性，校验retpoline标志，复制模块元信息到内核，释放动态分配的模块数据，重写ELF节头地址以匹配实际内存布局",
          "similarity": 0.5823366641998291
        },
        {
          "chunk_id": 12,
          "file_path": "kernel/module/main.c",
          "start_line": 2256,
          "end_line": 2359,
          "content": [
            "static int move_module(struct module *mod, struct load_info *info)",
            "{",
            "\tint i;",
            "\tvoid *ptr;",
            "\tenum mod_mem_type t = 0;",
            "\tint ret = -ENOMEM;",
            "",
            "\tfor_each_mod_mem_type(type) {",
            "\t\tif (!mod->mem[type].size) {",
            "\t\t\tmod->mem[type].base = NULL;",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tmod->mem[type].size = PAGE_ALIGN(mod->mem[type].size);",
            "\t\tptr = module_memory_alloc(mod->mem[type].size, type);",
            "\t\t/*",
            "                 * The pointer to these blocks of memory are stored on the module",
            "                 * structure and we keep that around so long as the module is",
            "                 * around. We only free that memory when we unload the module.",
            "                 * Just mark them as not being a leak then. The .init* ELF",
            "                 * sections *do* get freed after boot so we *could* treat them",
            "                 * slightly differently with kmemleak_ignore() and only grey",
            "                 * them out as they work as typical memory allocations which",
            "                 * *do* eventually get freed, but let's just keep things simple",
            "                 * and avoid *any* false positives.",
            "\t\t */",
            "\t\tkmemleak_not_leak(ptr);",
            "\t\tif (!ptr) {",
            "\t\t\tt = type;",
            "\t\t\tgoto out_enomem;",
            "\t\t}",
            "\t\tmemset(ptr, 0, mod->mem[type].size);",
            "\t\tmod->mem[type].base = ptr;",
            "\t}",
            "",
            "\t/* Transfer each section which specifies SHF_ALLOC */",
            "\tpr_debug(\"Final section addresses for %s:\\n\", mod->name);",
            "\tfor (i = 0; i < info->hdr->e_shnum; i++) {",
            "\t\tvoid *dest;",
            "\t\tElf_Shdr *shdr = &info->sechdrs[i];",
            "\t\tenum mod_mem_type type = shdr->sh_entsize >> SH_ENTSIZE_TYPE_SHIFT;",
            "",
            "\t\tif (!(shdr->sh_flags & SHF_ALLOC))",
            "\t\t\tcontinue;",
            "",
            "\t\tdest = mod->mem[type].base + (shdr->sh_entsize & SH_ENTSIZE_OFFSET_MASK);",
            "",
            "\t\tif (shdr->sh_type != SHT_NOBITS) {",
            "\t\t\t/*",
            "\t\t\t * Our ELF checker already validated this, but let's",
            "\t\t\t * be pedantic and make the goal clearer. We actually",
            "\t\t\t * end up copying over all modifications made to the",
            "\t\t\t * userspace copy of the entire struct module.",
            "\t\t\t */",
            "\t\t\tif (i == info->index.mod &&",
            "\t\t\t   (WARN_ON_ONCE(shdr->sh_size != sizeof(struct module)))) {",
            "\t\t\t\tret = -ENOEXEC;",
            "\t\t\t\tgoto out_enomem;",
            "\t\t\t}",
            "\t\t\tmemcpy(dest, (void *)shdr->sh_addr, shdr->sh_size);",
            "\t\t}",
            "\t\t/*",
            "\t\t * Update the userspace copy's ELF section address to point to",
            "\t\t * our newly allocated memory as a pure convenience so that",
            "\t\t * users of info can keep taking advantage and using the newly",
            "\t\t * minted official memory area.",
            "\t\t */",
            "\t\tshdr->sh_addr = (unsigned long)dest;",
            "\t\tpr_debug(\"\\t0x%lx 0x%.8lx %s\\n\", (long)shdr->sh_addr,",
            "\t\t\t (long)shdr->sh_size, info->secstrings + shdr->sh_name);",
            "\t}",
            "",
            "\treturn 0;",
            "out_enomem:",
            "\tfor (t--; t >= 0; t--)",
            "\t\tmodule_memory_free(mod->mem[t].base, t, true);",
            "\treturn ret;",
            "}",
            "static int check_export_symbol_versions(struct module *mod)",
            "{",
            "#ifdef CONFIG_MODVERSIONS",
            "\tif ((mod->num_syms && !mod->crcs) ||",
            "\t    (mod->num_gpl_syms && !mod->gpl_crcs)) {",
            "\t\treturn try_to_force_load(mod,",
            "\t\t\t\t\t \"no versions for exported symbols\");",
            "\t}",
            "#endif",
            "\treturn 0;",
            "}",
            "void flush_module_icache(const struct module *mod)",
            "{",
            "\t/*",
            "\t * Flush the instruction cache, since we've played with text.",
            "\t * Do it before processing of module parameters, so the module",
            "\t * can provide parameter accessor functions of its own.",
            "\t */",
            "\tfor_each_mod_mem_type(type) {",
            "\t\tconst struct module_memory *mod_mem = &mod->mem[type];",
            "",
            "\t\tif (mod_mem->size) {",
            "\t\t\tflush_icache_range((unsigned long)mod_mem->base,",
            "\t\t\t\t\t   (unsigned long)mod_mem->base + mod_mem->size);",
            "\t\t}",
            "\t}",
            "}"
          ],
          "function_name": "move_module, check_export_symbol_versions, flush_module_icache",
          "description": "为模块各内存类型分配物理页框，将ELF节区内容拷贝至对应内存区域，检查导出符号版本一致性，刷新指令高速缓存以确保新代码可见",
          "similarity": 0.5731836557388306
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/module/main.c",
          "start_line": 1071,
          "end_line": 1218,
          "content": [
            "static int verify_namespace_is_imported(const struct load_info *info,",
            "\t\t\t\t\tconst struct kernel_symbol *sym,",
            "\t\t\t\t\tstruct module *mod)",
            "{",
            "\tconst char *namespace;",
            "\tchar *imported_namespace;",
            "",
            "\tnamespace = kernel_symbol_namespace(sym);",
            "\tif (namespace && namespace[0]) {",
            "\t\tfor_each_modinfo_entry(imported_namespace, info, \"import_ns\") {",
            "\t\t\tif (strcmp(namespace, imported_namespace) == 0)",
            "\t\t\t\treturn 0;",
            "\t\t}",
            "#ifdef CONFIG_MODULE_ALLOW_MISSING_NAMESPACE_IMPORTS",
            "\t\tpr_warn(",
            "#else",
            "\t\tpr_err(",
            "#endif",
            "\t\t\t\"%s: module uses symbol (%s) from namespace %s, but does not import it.\\n\",",
            "\t\t\tmod->name, kernel_symbol_name(sym), namespace);",
            "#ifndef CONFIG_MODULE_ALLOW_MISSING_NAMESPACE_IMPORTS",
            "\t\treturn -EINVAL;",
            "#endif",
            "\t}",
            "\treturn 0;",
            "}",
            "static bool inherit_taint(struct module *mod, struct module *owner, const char *name)",
            "{",
            "\tif (!owner || !test_bit(TAINT_PROPRIETARY_MODULE, &owner->taints))",
            "\t\treturn true;",
            "",
            "\tif (mod->using_gplonly_symbols) {",
            "\t\tpr_err(\"%s: module using GPL-only symbols uses symbols %s from proprietary module %s.\\n\",",
            "\t\t\tmod->name, name, owner->name);",
            "\t\treturn false;",
            "\t}",
            "",
            "\tif (!test_bit(TAINT_PROPRIETARY_MODULE, &mod->taints)) {",
            "\t\tpr_warn(\"%s: module uses symbols %s from proprietary module %s, inheriting taint.\\n\",",
            "\t\t\tmod->name, name, owner->name);",
            "\t\tset_bit(TAINT_PROPRIETARY_MODULE, &mod->taints);",
            "\t}",
            "\treturn true;",
            "}",
            "void __weak module_memfree(void *module_region)",
            "{",
            "\t/*",
            "\t * This memory may be RO, and freeing RO memory in an interrupt is not",
            "\t * supported by vmalloc.",
            "\t */",
            "\tWARN_ON(in_interrupt());",
            "\tvfree(module_region);",
            "}",
            "void __weak module_arch_cleanup(struct module *mod)",
            "{",
            "}",
            "void __weak module_arch_freeing_init(struct module *mod)",
            "{",
            "}",
            "static bool mod_mem_use_vmalloc(enum mod_mem_type type)",
            "{",
            "\treturn IS_ENABLED(CONFIG_ARCH_WANTS_MODULES_DATA_IN_VMALLOC) &&",
            "\t\tmod_mem_type_is_core_data(type);",
            "}",
            "static void module_memory_free(void *ptr, enum mod_mem_type type,",
            "\t\t\t       bool unload_codetags)",
            "{",
            "\tif (!unload_codetags && mod_mem_type_is_core_data(type))",
            "\t\treturn;",
            "",
            "\tif (mod_mem_use_vmalloc(type))",
            "\t\tvfree(ptr);",
            "\telse",
            "\t\tmodule_memfree(ptr);",
            "}",
            "static void free_mod_mem(struct module *mod, bool unload_codetags)",
            "{",
            "\tfor_each_mod_mem_type(type) {",
            "\t\tstruct module_memory *mod_mem = &mod->mem[type];",
            "",
            "\t\tif (type == MOD_DATA)",
            "\t\t\tcontinue;",
            "",
            "\t\t/* Free lock-classes; relies on the preceding sync_rcu(). */",
            "\t\tlockdep_free_key_range(mod_mem->base, mod_mem->size);",
            "\t\tif (mod_mem->size)",
            "\t\t\tmodule_memory_free(mod_mem->base, type,",
            "\t\t\t\t\t   unload_codetags);",
            "\t}",
            "",
            "\t/* MOD_DATA hosts mod, so free it at last */",
            "\tlockdep_free_key_range(mod->mem[MOD_DATA].base, mod->mem[MOD_DATA].size);",
            "\tmodule_memory_free(mod->mem[MOD_DATA].base, MOD_DATA, unload_codetags);",
            "}",
            "static void free_module(struct module *mod)",
            "{",
            "\tbool unload_codetags;",
            "",
            "\ttrace_module_free(mod);",
            "",
            "\tunload_codetags = codetag_unload_module(mod);",
            "\tif (!unload_codetags)",
            "\t\tpr_warn(\"%s: memory allocation(s) from the module still alive, cannot unload cleanly\\n\",",
            "\t\t\tmod->name);",
            "",
            "\tmod_sysfs_teardown(mod);",
            "",
            "\t/*",
            "\t * We leave it in list to prevent duplicate loads, but make sure",
            "\t * that noone uses it while it's being deconstructed.",
            "\t */",
            "\tmutex_lock(&module_mutex);",
            "\tmod->state = MODULE_STATE_UNFORMED;",
            "\tmutex_unlock(&module_mutex);",
            "",
            "\t/* Arch-specific cleanup. */",
            "\tmodule_arch_cleanup(mod);",
            "",
            "\t/* Module unload stuff */",
            "\tmodule_unload_free(mod);",
            "",
            "\t/* Free any allocated parameters. */",
            "\tdestroy_params(mod->kp, mod->num_kp);",
            "",
            "\tif (is_livepatch_module(mod))",
            "\t\tfree_module_elf(mod);",
            "",
            "\t/* Now we can delete it from the lists */",
            "\tmutex_lock(&module_mutex);",
            "\t/* Unlink carefully: kallsyms could be walking list. */",
            "\tlist_del_rcu(&mod->list);",
            "\tmod_tree_remove(mod);",
            "\t/* Remove this module from bug list, this uses list_del_rcu */",
            "\tmodule_bug_cleanup(mod);",
            "\t/* Wait for RCU-sched synchronizing before releasing mod->list and buglist. */",
            "\tsynchronize_rcu();",
            "\tif (try_add_tainted_module(mod))",
            "\t\tpr_err(\"%s: adding tainted module to the unloaded tainted modules list failed.\\n\",",
            "\t\t       mod->name);",
            "\tmutex_unlock(&module_mutex);",
            "",
            "\t/* This may be empty, but that's OK */",
            "\tmodule_arch_freeing_init(mod);",
            "\tkfree(mod->args);",
            "\tpercpu_modfree(mod);",
            "",
            "\tfree_mod_mem(mod, unload_codetags);",
            "}"
          ],
          "function_name": "verify_namespace_is_imported, inherit_taint, module_memfree, module_arch_cleanup, module_arch_freeing_init, mod_mem_use_vmalloc, module_memory_free, free_mod_mem, free_module",
          "description": "实现模块符号命名空间验证(verify_namespace_is_imported)、污点继承逻辑(herit_taint)、内存释放(module_memory_free/free_mod_mem)及架构特定清理(module_arch_cleanup/module_arch_freeing_init)，包含弱符号声明供架构扩展。",
          "similarity": 0.5656065940856934
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/module/main.c",
          "start_line": 303,
          "end_line": 412,
          "content": [
            "bool find_symbol(struct find_symbol_arg *fsa)",
            "{",
            "\tstatic const struct symsearch arr[] = {",
            "\t\t{ __start___ksymtab, __stop___ksymtab, __start___kcrctab,",
            "\t\t  NOT_GPL_ONLY },",
            "\t\t{ __start___ksymtab_gpl, __stop___ksymtab_gpl,",
            "\t\t  __start___kcrctab_gpl,",
            "\t\t  GPL_ONLY },",
            "\t};",
            "\tstruct module *mod;",
            "\tunsigned int i;",
            "",
            "\tmodule_assert_mutex_or_preempt();",
            "",
            "\tfor (i = 0; i < ARRAY_SIZE(arr); i++)",
            "\t\tif (find_exported_symbol_in_section(&arr[i], NULL, fsa))",
            "\t\t\treturn true;",
            "",
            "\tlist_for_each_entry_rcu(mod, &modules, list,",
            "\t\t\t\tlockdep_is_held(&module_mutex)) {",
            "\t\tstruct symsearch arr[] = {",
            "\t\t\t{ mod->syms, mod->syms + mod->num_syms, mod->crcs,",
            "\t\t\t  NOT_GPL_ONLY },",
            "\t\t\t{ mod->gpl_syms, mod->gpl_syms + mod->num_gpl_syms,",
            "\t\t\t  mod->gpl_crcs,",
            "\t\t\t  GPL_ONLY },",
            "\t\t};",
            "",
            "\t\tif (mod->state == MODULE_STATE_UNFORMED)",
            "\t\t\tcontinue;",
            "",
            "\t\tfor (i = 0; i < ARRAY_SIZE(arr); i++)",
            "\t\t\tif (find_exported_symbol_in_section(&arr[i], mod, fsa))",
            "\t\t\t\treturn true;",
            "\t}",
            "",
            "\tpr_debug(\"Failed to find symbol %s\\n\", fsa->name);",
            "\treturn false;",
            "}",
            "static int percpu_modalloc(struct module *mod, struct load_info *info)",
            "{",
            "\tElf_Shdr *pcpusec = &info->sechdrs[info->index.pcpu];",
            "\tunsigned long align = pcpusec->sh_addralign;",
            "",
            "\tif (!pcpusec->sh_size)",
            "\t\treturn 0;",
            "",
            "\tif (align > PAGE_SIZE) {",
            "\t\tpr_warn(\"%s: per-cpu alignment %li > %li\\n\",",
            "\t\t\tmod->name, align, PAGE_SIZE);",
            "\t\talign = PAGE_SIZE;",
            "\t}",
            "",
            "\tmod->percpu = __alloc_reserved_percpu(pcpusec->sh_size, align);",
            "\tif (!mod->percpu) {",
            "\t\tpr_warn(\"%s: Could not allocate %lu bytes percpu data\\n\",",
            "\t\t\tmod->name, (unsigned long)pcpusec->sh_size);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "\tmod->percpu_size = pcpusec->sh_size;",
            "\treturn 0;",
            "}",
            "static void percpu_modfree(struct module *mod)",
            "{",
            "\tfree_percpu(mod->percpu);",
            "}",
            "static unsigned int find_pcpusec(struct load_info *info)",
            "{",
            "\treturn find_sec(info, \".data..percpu\");",
            "}",
            "static void percpu_modcopy(struct module *mod,",
            "\t\t\t   const void *from, unsigned long size)",
            "{",
            "\tint cpu;",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tmemcpy(per_cpu_ptr(mod->percpu, cpu), from, size);",
            "}",
            "bool __is_module_percpu_address(unsigned long addr, unsigned long *can_addr)",
            "{",
            "\tstruct module *mod;",
            "\tunsigned int cpu;",
            "",
            "\tpreempt_disable();",
            "",
            "\tlist_for_each_entry_rcu(mod, &modules, list) {",
            "\t\tif (mod->state == MODULE_STATE_UNFORMED)",
            "\t\t\tcontinue;",
            "\t\tif (!mod->percpu_size)",
            "\t\t\tcontinue;",
            "\t\tfor_each_possible_cpu(cpu) {",
            "\t\t\tvoid *start = per_cpu_ptr(mod->percpu, cpu);",
            "\t\t\tvoid *va = (void *)addr;",
            "",
            "\t\t\tif (va >= start && va < start + mod->percpu_size) {",
            "\t\t\t\tif (can_addr) {",
            "\t\t\t\t\t*can_addr = (unsigned long) (va - start);",
            "\t\t\t\t\t*can_addr += (unsigned long)",
            "\t\t\t\t\t\tper_cpu_ptr(mod->percpu,",
            "\t\t\t\t\t\t\t    get_boot_cpu_id());",
            "\t\t\t\t}",
            "\t\t\t\tpreempt_enable();",
            "\t\t\t\treturn true;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "\tpreempt_enable();",
            "\treturn false;",
            "}"
          ],
          "function_name": "find_symbol, percpu_modalloc, percpu_modfree, find_pcpusec, percpu_modcopy, __is_module_percpu_address",
          "description": "提供符号查找核心实现，通过遍历内核符号表和模块符号表定位目标符号；实现Per-CPU数据区的动态分配、复制和释放机制，确保多CPU环境下模块数据的正确访问。",
          "similarity": 0.5466680526733398
        }
      ]
    },
    {
      "source_file": "mm/vmscan.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:33:46\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `vmscan.c`\n\n---\n\n# vmscan.c 技术文档\n\n## 1. 文件概述\n\n`vmscan.c` 是 Linux 内核内存管理子系统中的核心文件，主要负责**页面回收（page reclaim）**机制的实现。该文件实现了内核在内存压力下如何选择并释放不再活跃或可回收的物理页帧（pages），以维持系统可用内存水位。其核心功能包括：\n\n- 实现 `kswapd` 内核线程，用于后台异步回收内存\n- 提供直接回收（direct reclaim）路径，供分配器在内存不足时同步触发\n- 管理匿名页（anonymous pages）和文件缓存页（file-backed pages）的回收策略\n- 支持基于内存控制组（memcg）的层级化内存回收\n- 与交换（swap）、压缩（compaction）、OOM killer 等子系统协同工作\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct scan_control`**  \n  页面回收上下文控制结构，包含本次回收操作的所有参数和状态：\n  - `nr_to_reclaim`：目标回收页数\n  - `target_mem_cgroup`：目标内存 cgroup（用于 memcg 回收）\n  - `may_unmap` / `may_swap` / `may_writepage`：控制是否允许解除映射、交换、写回\n  - `priority`：扫描优先级（0~12，值越低压力越大）\n  - `order`：请求分配的阶数（影响回收激进程度）\n  - `nr_scanned` / `nr_reclaimed`：已扫描和已回收页数统计\n  - `anon_cost` / `file_cost`：用于平衡匿名页与文件页回收比例\n\n- **全局变量**\n  - `vm_swappiness`（默认 60）：控制系统倾向于回收匿名页（需 swap）还是文件页（可丢弃）\n\n### 主要函数（部分在代码片段中体现）\n\n- `cgroup_reclaim()` / `root_reclaim()`：判断当前回收是否针对特定 memcg 或全局\n- `writeback_throttling_sane()`：判断是否可使用标准脏页限流机制\n- `set_task_reclaim_state()` / `flush_reclaim_state()`：管理任务的 slab 回收状态\n- （注：核心回收函数如 `shrink_lruvec()`、`kswapd()` 等未在片段中展示）\n\n## 3. 关键实现\n\n### 内存回收控制逻辑\n\n- **回收目标决策**：通过 `scan_control` 结构传递回收上下文，区分直接回收（分配失败触发）与 kswapd 后台回收。\n- **LRU 链管理**：利用 `prefetchw_prev_lru_folio` 宏优化 LRU 链遍历时的 CPU 缓存预取性能。\n- **Memcg 集成**：\n  - 若 `target_mem_cgroup` 非空，则优先回收该 cgroup 的内存\n  - 支持 `memory.low` 保护机制：当常规回收无法满足需求且跳过受保护 cgroup 时，会触发二次强制回收（`memcg_low_reclaim`）\n- **脏页处理策略**：\n  - 在传统 memcg 模式下，禁用标准 `balance_dirty_pages()` 限流，改用直接阻塞回收（`writeback_throttling_sane()` 判断）\n  - 通过 `may_writepage` 控制是否在 laptop mode 下批量写回脏页\n\n### 回收统计与状态同步\n\n- **Slab 回收计数**：通过 `reclaim_state` 结构将非 LRU 回收（如 slab 释放）计入全局统计，但**仅在全局回收时计入**，避免 memcg 回收时高估实际效果导致欠回收。\n- **PSI/Trace 集成**：包含 `<trace/events/vmscan.h>` 用于性能分析，支持压力状态指示器（PSI）监控内存压力。\n\n## 4. 依赖关系\n\n### 头文件依赖\n\n- **核心内存管理**：`<linux/mm.h>`, `<linux/gfp.h>`, `<linux/swap.h>`, `<linux/vmstat.h>`\n- **LRU 与反向映射**：`<linux/rmap.h>`, `<linux/pagemap.h>`\n- **内存控制组**：`<linux/memcontrol.h>`\n- **IO 与写回**：`<linux/writeback.h>`, `<linux/backing-dev.h>`\n- **压缩与迁移**：`<linux/compaction.h>`, `<linux/migrate.h>`\n- **体系结构相关**：`<asm/tlbflush.h>`\n\n### 子系统交互\n\n- **Swap 子系统**：通过 `swapops.h` 和 `swap.h` 实现匿名页换出\n- **Slab 分配器**：通过 `reclaim_state` 接收 slab 回收通知\n- **OOM Killer**：当回收无法释放足够内存时触发\n- **Khugepaged**：大页合并/拆分与回收协同\n- **Memory Tiering**：支持分层内存架构中的页降级（demotion）控制\n\n## 5. 使用场景\n\n- **内存分配失败时的直接回收**：当 `alloc_pages()` 等分配函数无法满足请求时，同步调用回收路径。\n- **kswapd 后台回收**：当空闲内存低于 `watermark[low]` 时，唤醒 `kswapd` 线程异步回收至 `watermark[high]`。\n- **Memcg 内存超限时的层级回收**：当某个 cgroup 超过其内存限制时，仅回收该 cgroup 及其子树的页面。\n- **系统休眠（Hibernation）**：通过 `hibernation_mode` 标志优化休眠过程中的内存回收。\n- **主动内存回收（Proactive Reclaim）**：用户空间通过 `memory.reclaim` 接口触发预清回收。\n- **内存压缩准备**：当 `compaction_ready` 置位时，回收操作会为后续内存压缩腾出连续空间。",
      "similarity": 0.6438980102539062,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "mm/vmscan.c",
          "start_line": 1,
          "end_line": 194,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " *  Copyright (C) 1991, 1992, 1993, 1994  Linus Torvalds",
            " *",
            " *  Swap reorganised 29.12.95, Stephen Tweedie.",
            " *  kswapd added: 7.1.96  sct",
            " *  Removed kswapd_ctl limits, and swap out as many pages as needed",
            " *  to bring the system back to freepages.high: 2.4.97, Rik van Riel.",
            " *  Zone aware kswapd started 02/00, Kanoj Sarcar (kanoj@sgi.com).",
            " *  Multiqueue VM started 5.8.00, Rik van Riel.",
            " */",
            "",
            "#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt",
            "",
            "#include <linux/mm.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/init.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmpressure.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/file.h>",
            "#include <linux/writeback.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/buffer_head.h>\t/* for buffer_heads_over_limit */",
            "#include <linux/mm_inline.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/rmap.h>",
            "#include <linux/topology.h>",
            "#include <linux/cpu.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/compaction.h>",
            "#include <linux/notifier.h>",
            "#include <linux/delay.h>",
            "#include <linux/kthread.h>",
            "#include <linux/freezer.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/migrate.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/memory-tiers.h>",
            "#include <linux/oom.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/printk.h>",
            "#include <linux/dax.h>",
            "#include <linux/psi.h>",
            "#include <linux/pagewalk.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/random.h>",
            "#include <linux/etmem.h>",
            "#include <linux/mmu_notifier.h>",
            "",
            "#include <asm/tlbflush.h>",
            "#include <asm/div64.h>",
            "",
            "#include <linux/swapops.h>",
            "#include <linux/balloon_compaction.h>",
            "#include <linux/sched/sysctl.h>",
            "",
            "#include \"internal.h\"",
            "#include \"swap.h\"",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/vmscan.h>",
            "",
            "struct scan_control {",
            "\t/* How many pages shrink_list() should reclaim */",
            "\tunsigned long nr_to_reclaim;",
            "",
            "\t/*",
            "\t * Nodemask of nodes allowed by the caller. If NULL, all nodes",
            "\t * are scanned.",
            "\t */",
            "\tnodemask_t\t*nodemask;",
            "",
            "\t/*",
            "\t * The memory cgroup that hit its limit and as a result is the",
            "\t * primary target of this reclaim invocation.",
            "\t */",
            "\tstruct mem_cgroup *target_mem_cgroup;",
            "",
            "\t/*",
            "\t * Scan pressure balancing between anon and file LRUs",
            "\t */",
            "\tunsigned long\tanon_cost;",
            "\tunsigned long\tfile_cost;",
            "",
            "\t/* Can active folios be deactivated as part of reclaim? */",
            "#define DEACTIVATE_ANON 1",
            "#define DEACTIVATE_FILE 2",
            "\tunsigned int may_deactivate:2;",
            "\tunsigned int force_deactivate:1;",
            "\tunsigned int skipped_deactivate:1;",
            "",
            "\t/* Writepage batching in laptop mode; RECLAIM_WRITE */",
            "\tunsigned int may_writepage:1;",
            "",
            "\t/* Can mapped folios be reclaimed? */",
            "\tunsigned int may_unmap:1;",
            "",
            "\t/* Can folios be swapped as part of reclaim? */",
            "\tunsigned int may_swap:1;",
            "",
            "\t/* Proactive reclaim invoked by userspace through memory.reclaim */",
            "\tunsigned int proactive:1;",
            "",
            "\t/*",
            "\t * Cgroup memory below memory.low is protected as long as we",
            "\t * don't threaten to OOM. If any cgroup is reclaimed at",
            "\t * reduced force or passed over entirely due to its memory.low",
            "\t * setting (memcg_low_skipped), and nothing is reclaimed as a",
            "\t * result, then go back for one more cycle that reclaims the protected",
            "\t * memory (memcg_low_reclaim) to avert OOM.",
            "\t */",
            "\tunsigned int memcg_low_reclaim:1;",
            "\tunsigned int memcg_low_skipped:1;",
            "",
            "\tunsigned int hibernation_mode:1;",
            "",
            "\t/* One of the zones is ready for compaction */",
            "\tunsigned int compaction_ready:1;",
            "",
            "\t/* There is easily reclaimable cold cache in the current node */",
            "\tunsigned int cache_trim_mode:1;",
            "",
            "\t/* The file folios on the current node are dangerously low */",
            "\tunsigned int file_is_tiny:1;",
            "",
            "\t/* Always discard instead of demoting to lower tier memory */",
            "\tunsigned int no_demotion:1;",
            "",
            "\t/* Allocation order */",
            "\ts8 order;",
            "",
            "\t/* Scan (total_size >> priority) pages at once */",
            "\ts8 priority;",
            "",
            "\t/* The highest zone to isolate folios for reclaim from */",
            "\ts8 reclaim_idx;",
            "",
            "\t/* This context's GFP mask */",
            "\tgfp_t gfp_mask;",
            "",
            "\t/* Incremented by the number of inactive pages that were scanned */",
            "\tunsigned long nr_scanned;",
            "",
            "\t/* Number of pages freed so far during a call to shrink_zones() */",
            "\tunsigned long nr_reclaimed;",
            "",
            "\tstruct {",
            "\t\tunsigned int dirty;",
            "\t\tunsigned int unqueued_dirty;",
            "\t\tunsigned int congested;",
            "\t\tunsigned int writeback;",
            "\t\tunsigned int immediate;",
            "\t\tunsigned int file_taken;",
            "\t\tunsigned int taken;",
            "\t} nr;",
            "",
            "\t/* for recording the reclaimed slab by now */",
            "\tstruct reclaim_state reclaim_state;",
            "};",
            "",
            "#ifdef ARCH_HAS_PREFETCHW",
            "#define prefetchw_prev_lru_folio(_folio, _base, _field)\t\t\t\\",
            "\tdo {\t\t\t\t\t\t\t\t\\",
            "\t\tif ((_folio)->lru.prev != _base) {\t\t\t\\",
            "\t\t\tstruct folio *prev;\t\t\t\t\\",
            "\t\t\t\t\t\t\t\t\t\\",
            "\t\t\tprev = lru_to_folio(&(_folio->lru));\t\t\\",
            "\t\t\tprefetchw(&prev->_field);\t\t\t\\",
            "\t\t}\t\t\t\t\t\t\t\\",
            "\t} while (0)",
            "#else",
            "#define prefetchw_prev_lru_folio(_folio, _base, _field) do { } while (0)",
            "#endif",
            "",
            "/*",
            " * From 0 .. 200.  Higher means more swappy.",
            " */",
            "int vm_swappiness = 60;",
            "",
            "#ifdef CONFIG_MEMCG",
            "",
            "/* Returns true for reclaim through cgroup limits or cgroup interfaces. */"
          ],
          "function_name": null,
          "description": "定义了内存扫描控制结构体scan_control及其相关字段，用于管理内存回收过程中目标内存组、回收策略、权限标志位及统计信息，是内存回收核心参数容器。",
          "similarity": 0.5942487120628357
        },
        {
          "chunk_id": 11,
          "file_path": "mm/vmscan.c",
          "start_line": 2156,
          "end_line": 2324,
          "content": [
            "unsigned long reclaim_pages(struct list_head *folio_list, bool ignore_references)",
            "{",
            "\tint nid;",
            "\tunsigned int nr_reclaimed = 0;",
            "\tLIST_HEAD(node_folio_list);",
            "\tunsigned int noreclaim_flag;",
            "",
            "\tif (list_empty(folio_list))",
            "\t\treturn nr_reclaimed;",
            "",
            "\tnoreclaim_flag = memalloc_noreclaim_save();",
            "",
            "\tnid = folio_nid(lru_to_folio(folio_list));",
            "\tdo {",
            "\t\tstruct folio *folio = lru_to_folio(folio_list);",
            "",
            "\t\tif (nid == folio_nid(folio)) {",
            "\t\t\tfolio_clear_active(folio);",
            "\t\t\tlist_move(&folio->lru, &node_folio_list);",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tnr_reclaimed += reclaim_folio_list(&node_folio_list, NODE_DATA(nid),",
            "\t\t\t\t\t\t   ignore_references);",
            "\t\tnid = folio_nid(lru_to_folio(folio_list));",
            "\t} while (!list_empty(folio_list));",
            "",
            "\tnr_reclaimed += reclaim_folio_list(&node_folio_list, NODE_DATA(nid), ignore_references);",
            "",
            "\tmemalloc_noreclaim_restore(noreclaim_flag);",
            "",
            "\treturn nr_reclaimed;",
            "}",
            "static unsigned long shrink_list(enum lru_list lru, unsigned long nr_to_scan,",
            "\t\t\t\t struct lruvec *lruvec, struct scan_control *sc)",
            "{",
            "\tif (is_active_lru(lru)) {",
            "\t\tif (sc->may_deactivate & (1 << is_file_lru(lru)))",
            "\t\t\tshrink_active_list(nr_to_scan, lruvec, sc, lru);",
            "\t\telse",
            "\t\t\tsc->skipped_deactivate = 1;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn shrink_inactive_list(nr_to_scan, lruvec, sc, lru);",
            "}",
            "static bool inactive_is_low(struct lruvec *lruvec, enum lru_list inactive_lru)",
            "{",
            "\tenum lru_list active_lru = inactive_lru + LRU_ACTIVE;",
            "\tunsigned long inactive, active;",
            "\tunsigned long inactive_ratio;",
            "\tunsigned long gb;",
            "",
            "\tinactive = lruvec_page_state(lruvec, NR_LRU_BASE + inactive_lru);",
            "\tactive = lruvec_page_state(lruvec, NR_LRU_BASE + active_lru);",
            "",
            "\tgb = (inactive + active) >> (30 - PAGE_SHIFT);",
            "\tif (gb)",
            "\t\tinactive_ratio = int_sqrt(10 * gb);",
            "\telse",
            "\t\tinactive_ratio = 1;",
            "",
            "\treturn inactive * inactive_ratio < active;",
            "}",
            "static void prepare_scan_control(pg_data_t *pgdat, struct scan_control *sc)",
            "{",
            "\tunsigned long file;",
            "\tstruct lruvec *target_lruvec;",
            "",
            "\tif (lru_gen_enabled())",
            "\t\treturn;",
            "",
            "\ttarget_lruvec = mem_cgroup_lruvec(sc->target_mem_cgroup, pgdat);",
            "",
            "\t/*",
            "\t * Flush the memory cgroup stats, so that we read accurate per-memcg",
            "\t * lruvec stats for heuristics.",
            "\t */",
            "\tmem_cgroup_flush_stats(sc->target_mem_cgroup);",
            "",
            "\t/*",
            "\t * Determine the scan balance between anon and file LRUs.",
            "\t */",
            "\tspin_lock_irq(&target_lruvec->lru_lock);",
            "\tsc->anon_cost = target_lruvec->anon_cost;",
            "\tsc->file_cost = target_lruvec->file_cost;",
            "\tspin_unlock_irq(&target_lruvec->lru_lock);",
            "",
            "\t/*",
            "\t * Target desirable inactive:active list ratios for the anon",
            "\t * and file LRU lists.",
            "\t */",
            "\tif (!sc->force_deactivate) {",
            "\t\tunsigned long refaults;",
            "",
            "\t\t/*",
            "\t\t * When refaults are being observed, it means a new",
            "\t\t * workingset is being established. Deactivate to get",
            "\t\t * rid of any stale active pages quickly.",
            "\t\t */",
            "\t\trefaults = lruvec_page_state(target_lruvec,",
            "\t\t\t\tWORKINGSET_ACTIVATE_ANON);",
            "\t\tif (refaults != target_lruvec->refaults[WORKINGSET_ANON] ||",
            "\t\t\tinactive_is_low(target_lruvec, LRU_INACTIVE_ANON))",
            "\t\t\tsc->may_deactivate |= DEACTIVATE_ANON;",
            "\t\telse",
            "\t\t\tsc->may_deactivate &= ~DEACTIVATE_ANON;",
            "",
            "\t\trefaults = lruvec_page_state(target_lruvec,",
            "\t\t\t\tWORKINGSET_ACTIVATE_FILE);",
            "\t\tif (refaults != target_lruvec->refaults[WORKINGSET_FILE] ||",
            "\t\t    inactive_is_low(target_lruvec, LRU_INACTIVE_FILE))",
            "\t\t\tsc->may_deactivate |= DEACTIVATE_FILE;",
            "\t\telse",
            "\t\t\tsc->may_deactivate &= ~DEACTIVATE_FILE;",
            "\t} else",
            "\t\tsc->may_deactivate = DEACTIVATE_ANON | DEACTIVATE_FILE;",
            "",
            "\t/*",
            "\t * If we have plenty of inactive file pages that aren't",
            "\t * thrashing, try to reclaim those first before touching",
            "\t * anonymous pages.",
            "\t */",
            "\tfile = lruvec_page_state(target_lruvec, NR_INACTIVE_FILE);",
            "\tif (file >> sc->priority && !(sc->may_deactivate & DEACTIVATE_FILE))",
            "\t\tsc->cache_trim_mode = 1;",
            "\telse",
            "\t\tsc->cache_trim_mode = 0;",
            "",
            "\t/*",
            "\t * Prevent the reclaimer from falling into the cache trap: as",
            "\t * cache pages start out inactive, every cache fault will tip",
            "\t * the scan balance towards the file LRU.  And as the file LRU",
            "\t * shrinks, so does the window for rotation from references.",
            "\t * This means we have a runaway feedback loop where a tiny",
            "\t * thrashing file LRU becomes infinitely more attractive than",
            "\t * anon pages.  Try to detect this based on file LRU size.",
            "\t */",
            "\tif (!cgroup_reclaim(sc)) {",
            "\t\tunsigned long total_high_wmark = 0;",
            "\t\tunsigned long free, anon;",
            "\t\tint z;",
            "",
            "\t\tfree = sum_zone_node_page_state(pgdat->node_id, NR_FREE_PAGES);",
            "\t\tfile = node_page_state(pgdat, NR_ACTIVE_FILE) +",
            "\t\t\t   node_page_state(pgdat, NR_INACTIVE_FILE);",
            "",
            "\t\tfor (z = 0; z < MAX_NR_ZONES; z++) {",
            "\t\t\tstruct zone *zone = &pgdat->node_zones[z];",
            "",
            "\t\t\tif (!managed_zone(zone))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\ttotal_high_wmark += high_wmark_pages(zone);",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Consider anon: if that's low too, this isn't a",
            "\t\t * runaway file reclaim problem, but rather just",
            "\t\t * extreme pressure. Reclaim as per usual then.",
            "\t\t */",
            "\t\tanon = node_page_state(pgdat, NR_INACTIVE_ANON);",
            "",
            "\t\tsc->file_is_tiny =",
            "\t\t\tfile + free <= total_high_wmark &&",
            "\t\t\t!(sc->may_deactivate & DEACTIVATE_ANON) &&",
            "\t\t\tanon >> sc->priority;",
            "\t}",
            "}"
          ],
          "function_name": "reclaim_pages, shrink_list, inactive_is_low, prepare_scan_control",
          "description": "该代码块包含`reclaim_pages`用于跨节点回收页面，`shrink_list`根据LRU类型选择回收策略，`inactive_is_low`检测非活动列表是否低于阈值，`prepare_scan_control`配置扫描控制参数，包括基于swap空间、内存组保护及文件/匿名页比例的扫描权重计算。",
          "similarity": 0.5769015550613403
        },
        {
          "chunk_id": 19,
          "file_path": "mm/vmscan.c",
          "start_line": 3605,
          "end_line": 3729,
          "content": [
            "static int walk_pud_range(p4d_t *p4d, unsigned long start, unsigned long end,",
            "\t\t\t  struct mm_walk *args)",
            "{",
            "\tint i;",
            "\tpud_t *pud;",
            "\tunsigned long addr;",
            "\tunsigned long next;",
            "\tstruct lru_gen_mm_walk *walk = args->private;",
            "",
            "\tVM_WARN_ON_ONCE(p4d_leaf(*p4d));",
            "",
            "\tpud = pud_offset(p4d, start & P4D_MASK);",
            "restart:",
            "\tfor (i = pud_index(start), addr = start; addr != end; i++, addr = next) {",
            "\t\tpud_t val = READ_ONCE(pud[i]);",
            "",
            "\t\tnext = pud_addr_end(addr, end);",
            "",
            "\t\tif (!pud_present(val) || WARN_ON_ONCE(pud_leaf(val)))",
            "\t\t\tcontinue;",
            "",
            "\t\twalk_pmd_range(&val, addr, next, args);",
            "",
            "\t\tif (need_resched() || walk->batched >= MAX_LRU_BATCH) {",
            "\t\t\tend = (addr | ~PUD_MASK) + 1;",
            "\t\t\tgoto done;",
            "\t\t}",
            "\t}",
            "",
            "\tif (i < PTRS_PER_PUD && get_next_vma(P4D_MASK, PUD_SIZE, args, &start, &end))",
            "\t\tgoto restart;",
            "",
            "\tend = round_up(end, P4D_SIZE);",
            "done:",
            "\tif (!end || !args->vma)",
            "\t\treturn 1;",
            "",
            "\twalk->next_addr = max(end, args->vma->vm_start);",
            "",
            "\treturn -EAGAIN;",
            "}",
            "static void walk_mm(struct mm_struct *mm, struct lru_gen_mm_walk *walk)",
            "{",
            "\tstatic const struct mm_walk_ops mm_walk_ops = {",
            "\t\t.test_walk = should_skip_vma,",
            "\t\t.p4d_entry = walk_pud_range,",
            "\t\t.walk_lock = PGWALK_RDLOCK,",
            "\t};",
            "\tint err;",
            "\tstruct lruvec *lruvec = walk->lruvec;",
            "",
            "\twalk->next_addr = FIRST_USER_ADDRESS;",
            "",
            "\tdo {",
            "\t\tDEFINE_MAX_SEQ(lruvec);",
            "",
            "\t\terr = -EBUSY;",
            "",
            "\t\t/* another thread might have called inc_max_seq() */",
            "\t\tif (walk->seq != max_seq)",
            "\t\t\tbreak;",
            "",
            "\t\t/* the caller might be holding the lock for write */",
            "\t\tif (mmap_read_trylock(mm)) {",
            "\t\t\terr = walk_page_range(mm, walk->next_addr, ULONG_MAX, &mm_walk_ops, walk);",
            "",
            "\t\t\tmmap_read_unlock(mm);",
            "\t\t}",
            "",
            "\t\tif (walk->batched) {",
            "\t\t\tspin_lock_irq(&lruvec->lru_lock);",
            "\t\t\treset_batch_size(walk);",
            "\t\t\tspin_unlock_irq(&lruvec->lru_lock);",
            "\t\t}",
            "",
            "\t\tcond_resched();",
            "\t} while (err == -EAGAIN);",
            "}",
            "static void clear_mm_walk(void)",
            "{",
            "\tstruct lru_gen_mm_walk *walk = current->reclaim_state->mm_walk;",
            "",
            "\tVM_WARN_ON_ONCE(walk && memchr_inv(walk->nr_pages, 0, sizeof(walk->nr_pages)));",
            "\tVM_WARN_ON_ONCE(walk && memchr_inv(walk->mm_stats, 0, sizeof(walk->mm_stats)));",
            "",
            "\tcurrent->reclaim_state->mm_walk = NULL;",
            "",
            "\tif (!current_is_kswapd())",
            "\t\tkfree(walk);",
            "}",
            "static bool inc_min_seq(struct lruvec *lruvec, int type, bool can_swap)",
            "{",
            "\tint zone;",
            "\tint remaining = MAX_LRU_BATCH;",
            "\tstruct lru_gen_folio *lrugen = &lruvec->lrugen;",
            "\tint new_gen, old_gen = lru_gen_from_seq(lrugen->min_seq[type]);",
            "",
            "\tif (type == LRU_GEN_ANON && !can_swap)",
            "\t\tgoto done;",
            "",
            "\t/* prevent cold/hot inversion if force_scan is true */",
            "\tfor (zone = 0; zone < MAX_NR_ZONES; zone++) {",
            "\t\tstruct list_head *head = &lrugen->folios[old_gen][type][zone];",
            "",
            "\t\twhile (!list_empty(head)) {",
            "\t\t\tstruct folio *folio = lru_to_folio(head);",
            "",
            "\t\t\tVM_WARN_ON_ONCE_FOLIO(folio_test_unevictable(folio), folio);",
            "\t\t\tVM_WARN_ON_ONCE_FOLIO(folio_test_active(folio), folio);",
            "\t\t\tVM_WARN_ON_ONCE_FOLIO(folio_is_file_lru(folio) != type, folio);",
            "\t\t\tVM_WARN_ON_ONCE_FOLIO(folio_zonenum(folio) != zone, folio);",
            "",
            "\t\t\tnew_gen = folio_inc_gen(lruvec, folio, false);",
            "\t\t\tlist_move_tail(&folio->lru, &lrugen->folios[new_gen][type][zone]);",
            "",
            "\t\t\tif (!--remaining)",
            "\t\t\t\treturn false;",
            "\t\t}",
            "\t}",
            "done:",
            "\treset_ctrl_pos(lruvec, type, true);",
            "\tWRITE_ONCE(lrugen->min_seq[type], lrugen->min_seq[type] + 1);",
            "",
            "\treturn true;",
            "}"
          ],
          "function_name": "walk_pud_range, walk_mm, clear_mm_walk, inc_min_seq",
          "description": "执行全内存扫描流程，通过多级页表遍历收集页面信息，维护最小序列号推进机制并清理扫描状态",
          "similarity": 0.5645978450775146
        },
        {
          "chunk_id": 24,
          "file_path": "mm/vmscan.c",
          "start_line": 4269,
          "end_line": 4377,
          "content": [
            "void lru_gen_soft_reclaim(struct mem_cgroup *memcg, int nid)",
            "{",
            "\tstruct lruvec *lruvec = get_lruvec(memcg, nid);",
            "",
            "\t/* see the comment on MEMCG_NR_GENS */",
            "\tif (READ_ONCE(lruvec->lrugen.seg) != MEMCG_LRU_HEAD)",
            "\t\tlru_gen_rotate_memcg(lruvec, MEMCG_LRU_HEAD);",
            "}",
            "static bool sort_folio(struct lruvec *lruvec, struct folio *folio, struct scan_control *sc,",
            "\t\t       int tier_idx)",
            "{",
            "\tbool success;",
            "\tint gen = folio_lru_gen(folio);",
            "\tint type = folio_is_file_lru(folio);",
            "\tint zone = folio_zonenum(folio);",
            "\tint delta = folio_nr_pages(folio);",
            "\tint refs = folio_lru_refs(folio);",
            "\tint tier = lru_tier_from_refs(refs);",
            "\tstruct lru_gen_folio *lrugen = &lruvec->lrugen;",
            "",
            "\tVM_WARN_ON_ONCE_FOLIO(gen >= MAX_NR_GENS, folio);",
            "",
            "\t/* unevictable */",
            "\tif (!folio_evictable(folio)) {",
            "\t\tsuccess = lru_gen_del_folio(lruvec, folio, true);",
            "\t\tVM_WARN_ON_ONCE_FOLIO(!success, folio);",
            "\t\tfolio_set_unevictable(folio);",
            "\t\tlruvec_add_folio(lruvec, folio);",
            "\t\t__count_vm_events(UNEVICTABLE_PGCULLED, delta);",
            "\t\treturn true;",
            "\t}",
            "",
            "\t/* dirty lazyfree */",
            "\tif (type == LRU_GEN_FILE && folio_test_anon(folio) && folio_test_dirty(folio)) {",
            "\t\tsuccess = lru_gen_del_folio(lruvec, folio, true);",
            "\t\tVM_WARN_ON_ONCE_FOLIO(!success, folio);",
            "\t\tfolio_set_swapbacked(folio);",
            "\t\tlruvec_add_folio_tail(lruvec, folio);",
            "\t\treturn true;",
            "\t}",
            "",
            "\t/* promoted */",
            "\tif (gen != lru_gen_from_seq(lrugen->min_seq[type])) {",
            "\t\tlist_move(&folio->lru, &lrugen->folios[gen][type][zone]);",
            "\t\treturn true;",
            "\t}",
            "",
            "\t/* protected */",
            "\tif (tier > tier_idx || refs == BIT(LRU_REFS_WIDTH)) {",
            "\t\tint hist = lru_hist_from_seq(lrugen->min_seq[type]);",
            "",
            "\t\tgen = folio_inc_gen(lruvec, folio, false);",
            "\t\tlist_move_tail(&folio->lru, &lrugen->folios[gen][type][zone]);",
            "",
            "\t\tWRITE_ONCE(lrugen->protected[hist][type][tier - 1],",
            "\t\t\t   lrugen->protected[hist][type][tier - 1] + delta);",
            "\t\treturn true;",
            "\t}",
            "",
            "\t/* ineligible */",
            "\tif (zone > sc->reclaim_idx) {",
            "\t\tgen = folio_inc_gen(lruvec, folio, false);",
            "\t\tlist_move_tail(&folio->lru, &lrugen->folios[gen][type][zone]);",
            "\t\treturn true;",
            "\t}",
            "",
            "\t/* waiting for writeback */",
            "\tif (folio_test_locked(folio) || folio_test_writeback(folio) ||",
            "\t    (type == LRU_GEN_FILE && folio_test_dirty(folio))) {",
            "\t\tgen = folio_inc_gen(lruvec, folio, true);",
            "\t\tlist_move(&folio->lru, &lrugen->folios[gen][type][zone]);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static bool isolate_folio(struct lruvec *lruvec, struct folio *folio, struct scan_control *sc)",
            "{",
            "\tbool success;",
            "",
            "\t/* swap constrained */",
            "\tif (!(sc->gfp_mask & __GFP_IO) &&",
            "\t    (folio_test_dirty(folio) ||",
            "\t     (folio_test_anon(folio) && !folio_test_swapcache(folio))))",
            "\t\treturn false;",
            "",
            "\t/* raced with release_pages() */",
            "\tif (!folio_try_get(folio))",
            "\t\treturn false;",
            "",
            "\t/* raced with another isolation */",
            "\tif (!folio_test_clear_lru(folio)) {",
            "\t\tfolio_put(folio);",
            "\t\treturn false;",
            "\t}",
            "",
            "\t/* see the comment on MAX_NR_TIERS */",
            "\tif (!folio_test_referenced(folio))",
            "\t\tset_mask_bits(&folio->flags, LRU_REFS_MASK | LRU_REFS_FLAGS, 0);",
            "",
            "\t/* for shrink_folio_list() */",
            "\tfolio_clear_reclaim(folio);",
            "\tfolio_clear_referenced(folio);",
            "",
            "\tsuccess = lru_gen_del_folio(lruvec, folio, true);",
            "\tVM_WARN_ON_ONCE_FOLIO(!success, folio);",
            "",
            "\treturn true;",
            "}"
          ],
          "function_name": "lru_gen_soft_reclaim, sort_folio, isolate_folio",
          "description": "该代码段实现了内存组（memcg）的LRU分级管理逻辑，核心功能是通过`lru_gen_soft_reclaim`触发LRU链表旋转，`sort_folio`根据页面属性（如脏/匿名/引用位）将其归类至不同层级的LRU队列，`isolate_folio`则负责安全隔离可回收页面并更新统计信息。三者协同完成基于生成代数（gen）的页面分类与回收决策。",
          "similarity": 0.5577154159545898
        },
        {
          "chunk_id": 15,
          "file_path": "mm/vmscan.c",
          "start_line": 2960,
          "end_line": 3095,
          "content": [
            "static bool iterate_mm_list(struct lru_gen_mm_walk *walk, struct mm_struct **iter)",
            "{",
            "\tbool first = false;",
            "\tbool last = false;",
            "\tstruct mm_struct *mm = NULL;",
            "\tstruct lruvec *lruvec = walk->lruvec;",
            "\tstruct mem_cgroup *memcg = lruvec_memcg(lruvec);",
            "\tstruct lru_gen_mm_list *mm_list = get_mm_list(memcg);",
            "\tstruct lru_gen_mm_state *mm_state = get_mm_state(lruvec);",
            "",
            "\t/*",
            "\t * mm_state->seq is incremented after each iteration of mm_list. There",
            "\t * are three interesting cases for this page table walker:",
            "\t * 1. It tries to start a new iteration with a stale max_seq: there is",
            "\t *    nothing left to do.",
            "\t * 2. It started the next iteration: it needs to reset the Bloom filter",
            "\t *    so that a fresh set of PTE tables can be recorded.",
            "\t * 3. It ended the current iteration: it needs to reset the mm stats",
            "\t *    counters and tell its caller to increment max_seq.",
            "\t */",
            "\tspin_lock(&mm_list->lock);",
            "",
            "\tVM_WARN_ON_ONCE(mm_state->seq + 1 < walk->seq);",
            "",
            "\tif (walk->seq <= mm_state->seq)",
            "\t\tgoto done;",
            "",
            "\tif (!mm_state->head)",
            "\t\tmm_state->head = &mm_list->fifo;",
            "",
            "\tif (mm_state->head == &mm_list->fifo)",
            "\t\tfirst = true;",
            "",
            "\tdo {",
            "\t\tmm_state->head = mm_state->head->next;",
            "\t\tif (mm_state->head == &mm_list->fifo) {",
            "\t\t\tWRITE_ONCE(mm_state->seq, mm_state->seq + 1);",
            "\t\t\tlast = true;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\t/* force scan for those added after the last iteration */",
            "\t\tif (!mm_state->tail || mm_state->tail == mm_state->head) {",
            "\t\t\tmm_state->tail = mm_state->head->next;",
            "\t\t\twalk->force_scan = true;",
            "\t\t}",
            "\t} while (!(mm = get_next_mm(walk)));",
            "done:",
            "\tif (*iter || last)",
            "\t\treset_mm_stats(walk, last);",
            "",
            "\tspin_unlock(&mm_list->lock);",
            "",
            "\tif (mm && first)",
            "\t\treset_bloom_filter(mm_state, walk->seq + 1);",
            "",
            "\tif (*iter)",
            "\t\tmmput_async(*iter);",
            "",
            "\t*iter = mm;",
            "",
            "\treturn last;",
            "}",
            "static bool iterate_mm_list_nowalk(struct lruvec *lruvec, unsigned long seq)",
            "{",
            "\tbool success = false;",
            "\tstruct mem_cgroup *memcg = lruvec_memcg(lruvec);",
            "\tstruct lru_gen_mm_list *mm_list = get_mm_list(memcg);",
            "\tstruct lru_gen_mm_state *mm_state = get_mm_state(lruvec);",
            "",
            "\tspin_lock(&mm_list->lock);",
            "",
            "\tVM_WARN_ON_ONCE(mm_state->seq + 1 < seq);",
            "",
            "\tif (seq > mm_state->seq) {",
            "\t\tmm_state->head = NULL;",
            "\t\tmm_state->tail = NULL;",
            "\t\tWRITE_ONCE(mm_state->seq, mm_state->seq + 1);",
            "\t\tsuccess = true;",
            "\t}",
            "",
            "\tspin_unlock(&mm_list->lock);",
            "",
            "\treturn success;",
            "}",
            "static void read_ctrl_pos(struct lruvec *lruvec, int type, int tier, int gain,",
            "\t\t\t  struct ctrl_pos *pos)",
            "{",
            "\tstruct lru_gen_folio *lrugen = &lruvec->lrugen;",
            "\tint hist = lru_hist_from_seq(lrugen->min_seq[type]);",
            "",
            "\tpos->refaulted = lrugen->avg_refaulted[type][tier] +",
            "\t\t\t atomic_long_read(&lrugen->refaulted[hist][type][tier]);",
            "\tpos->total = lrugen->avg_total[type][tier] +",
            "\t\t     atomic_long_read(&lrugen->evicted[hist][type][tier]);",
            "\tif (tier)",
            "\t\tpos->total += lrugen->protected[hist][type][tier - 1];",
            "\tpos->gain = gain;",
            "}",
            "static void reset_ctrl_pos(struct lruvec *lruvec, int type, bool carryover)",
            "{",
            "\tint hist, tier;",
            "\tstruct lru_gen_folio *lrugen = &lruvec->lrugen;",
            "\tbool clear = carryover ? NR_HIST_GENS == 1 : NR_HIST_GENS > 1;",
            "\tunsigned long seq = carryover ? lrugen->min_seq[type] : lrugen->max_seq + 1;",
            "",
            "\tlockdep_assert_held(&lruvec->lru_lock);",
            "",
            "\tif (!carryover && !clear)",
            "\t\treturn;",
            "",
            "\thist = lru_hist_from_seq(seq);",
            "",
            "\tfor (tier = 0; tier < MAX_NR_TIERS; tier++) {",
            "\t\tif (carryover) {",
            "\t\t\tunsigned long sum;",
            "",
            "\t\t\tsum = lrugen->avg_refaulted[type][tier] +",
            "\t\t\t      atomic_long_read(&lrugen->refaulted[hist][type][tier]);",
            "\t\t\tWRITE_ONCE(lrugen->avg_refaulted[type][tier], sum / 2);",
            "",
            "\t\t\tsum = lrugen->avg_total[type][tier] +",
            "\t\t\t      atomic_long_read(&lrugen->evicted[hist][type][tier]);",
            "\t\t\tif (tier)",
            "\t\t\t\tsum += lrugen->protected[hist][type][tier - 1];",
            "\t\t\tWRITE_ONCE(lrugen->avg_total[type][tier], sum / 2);",
            "\t\t}",
            "",
            "\t\tif (clear) {",
            "\t\t\tatomic_long_set(&lrugen->refaulted[hist][type][tier], 0);",
            "\t\t\tatomic_long_set(&lrugen->evicted[hist][type][tier], 0);",
            "\t\t\tif (tier)",
            "\t\t\t\tWRITE_ONCE(lrugen->protected[hist][type][tier - 1], 0);",
            "\t\t}",
            "\t}",
            "}"
          ],
          "function_name": "iterate_mm_list, iterate_mm_list_nowalk, read_ctrl_pos, reset_ctrl_pos",
          "description": "实现内存映射列表迭代逻辑，通过锁保护维护seq序号和头尾指针，用于跟踪页面表的变化并触发相应的统计重置或Bloom过滤器重置",
          "similarity": 0.5542212724685669
        }
      ]
    }
  ]
}