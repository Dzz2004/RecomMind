{
  "query": "perf 工具 进程资源分析",
  "timestamp": "2025-12-26 14:34:19",
  "retrieved_files": [
    {
      "source_file": "kernel/trace/trace_event_perf.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:17:36\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `trace\\trace_event_perf.c`\n\n---\n\n# `trace/trace_event_perf.c` 技术文档\n\n## 1. 文件概述\n\n`trace/trace_event_perf.c` 是 Linux 内核中连接 **ftrace 事件子系统** 与 **perf 性能监控子系统** 的关键桥梁。该文件实现了将 ftrace 定义的 tracepoint、kprobe 和 uprobe 事件作为 perf event 使用的能力，使得用户空间可以通过 `perf_event_open()` 系统调用对内核 trace 事件进行采样、计数或原始数据采集。同时，该文件负责权限控制、资源管理、生命周期维护以及安全策略实施，确保 trace 事件在 perf 上下文中的安全和高效使用。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`perf_trace_buf[PERF_NR_CONTEXTS]`**  \n  每 CPU 的预分配缓冲区数组，用于在 perf 上下文中暂存 trace 事件数据，避免动态分配开销。类型为 `perf_trace_t`（对齐的 `unsigned long` 数组），大小为 `PERF_MAX_TRACE_SIZE`。\n\n- **`total_ref_count`**  \n  全局引用计数器，跟踪当前系统中所有通过 perf 使用的 trace 事件实例总数，用于管理全局缓冲区的分配与释放。\n\n- **`trace_event_call::perf_refcount`**  \n  每个 trace 事件的 perf 引用计数，用于管理该事件在 perf 上下文中的注册状态。\n\n- **`trace_event_call::perf_events`**  \n  指向 per-CPU 的 `hlist_head` 数组，用于存储与该 trace 事件关联的所有 perf event 实例。\n\n### 主要函数\n\n- **`perf_trace_event_perm()`**  \n  执行 trace 事件在 perf 上下文中的权限检查，包括 root 权限要求、函数 trace 的特殊限制（如禁止用户态调用链和栈采样）等。\n\n- **`perf_trace_event_reg()` / `perf_trace_event_unreg()`**  \n  负责 trace 事件在 perf 中的注册与注销，包括分配 per-CPU 列表、调用事件类的注册回调、管理全局缓冲区生命周期。\n\n- **`perf_trace_event_open()` / `perf_trace_event_close()`**  \n  对应 perf event 的打开与关闭操作，调用 trace 事件类的相应回调。\n\n- **`perf_trace_init()` / `perf_trace_destroy()`**  \n  perf event 初始化与销毁的入口函数，用于标准 tracepoint 事件。\n\n- **`perf_kprobe_init()` / `perf_kprobe_destroy()`**  \n  支持通过 perf 接口动态创建和销毁 kprobe/kretprobe 事件。\n\n- **`perf_uprobe_init()` / `perf_uprobe_destroy()`**  \n  支持通过 perf 接口动态创建和销毁 uprobe/uretprobe 事件。\n\n## 3. 关键实现\n\n### 权限与安全控制\n- **函数 trace 限制**：`ftrace_event_is_function()` 标记的事件（如 `function` tracepoint）仅允许 root 用户使用，且禁止启用 `PERF_SAMPLE_CALLCHAIN`（用户态部分）和 `PERF_SAMPLE_STACK_USER`，以避免在页错误处理路径中发生嵌套页错误。\n- **原始数据访问控制**：当 perf event 请求 `PERF_SAMPLE_RAW` 时，若非 `PERF_ATTACH_TASK` 模式或事件未设置 `TRACE_EVENT_FL_CAP_ANY` 标志，则必须为 root 用户。\n- **权限检查时机**：仅在 `perf_event_open()` 路径下检查当前进程权限，子事件（`p_event->parent`）继承父事件权限。\n\n### 资源管理\n- **Per-CPU 缓冲区池**：全局 `perf_trace_buf` 数组在首次有 perf trace 事件注册时分配，所有事件共享，按上下文（`PERF_NR_CONTEXTS`）区分，避免频繁分配。\n- **引用计数机制**：\n  - `total_ref_count` 控制全局缓冲区的生命周期。\n  - 每个 `trace_event_call` 的 `perf_refcount` 控制其 per-CPU 事件列表和底层 tracepoint 注册状态。\n- **同步注销**：`perf_trace_event_unreg()` 调用 `tracepoint_synchronize_unregister()` 确保所有 CPU 上的 tracepoint 回调执行完毕后再释放资源。\n\n### 动态探针支持\n- **Kprobe/Uprobe 集成**：通过 `create_local_trace_kprobe/uprobe()` 动态创建临时 trace 事件，绑定到 perf event 生命周期，销毁时自动清理。\n- **用户空间参数处理**：使用 `strndup_user()` 安全拷贝用户提供的函数名或文件路径，并进行长度和空值校验。\n\n### 事件注册流程\n1. **权限检查** (`perf_trace_event_perm`)\n2. **事件注册** (`perf_trace_event_reg`)：分配 per-CPU 列表，首次使用时分配全局缓冲区，调用 `TRACE_REG_PERF_REGISTER`\n3. **事件打开** (`perf_trace_event_open`)：调用 `TRACE_REG_PERF_OPEN`\n\n## 4. 依赖关系\n\n- **核心依赖**：\n  - `<linux/perf_event.h>`：perf event 核心接口（通过 `trace.h` 间接包含）\n  - `\"trace.h\"`：ftrace 核心基础设施，包括 `trace_event_call`、`trace_event_class`、`ftrace_events` 列表等\n  - `\"trace_probe.h\"`：kprobe/uprobe 动态事件创建接口（`create_local_trace_kprobe/uprobe`）\n- **可选依赖**：\n  - `CONFIG_KPROBE_EVENTS`：启用 kprobe perf 支持\n  - `CONFIG_UPROBE_EVENTS`：启用 uprobe perf 支持\n- **同步原语**：\n  - `event_mutex`：保护 ftrace 事件列表的并发访问\n  - `tracepoint_synchronize_unregister()`：RCU 同步，确保 tracepoint 回调安全注销\n\n## 5. 使用场景\n\n- **用户空间 perf 工具**：`perf record -e 'tracepoint:*'` 或 `perf record -e 'kprobe:func'` 等命令通过此模块将 trace 事件转换为 perf event。\n- **动态内核探针**：应用程序通过 `perf_event_open()` 动态插入 kprobe/uprobe 监控特定函数或用户态地址，无需预定义 tracepoint。\n- **安全审计与性能分析**：结合 perf 的采样能力，对内核关键路径（如调度、内存管理）进行低开销监控，同时通过权限控制防止敏感数据泄露。\n- **eBPF 程序附加**：eBPF 程序可附加到 perf event 对应的 tracepoint/kprobe，此模块为 eBPF 提供底层事件源支持。",
      "similarity": 0.6529838442802429,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/trace/trace_event_perf.c",
          "start_line": 27,
          "end_line": 151,
          "content": [
            "static int perf_trace_event_perm(struct trace_event_call *tp_event,",
            "\t\t\t\t struct perf_event *p_event)",
            "{",
            "\tint ret;",
            "",
            "\tif (tp_event->perf_perm) {",
            "\t\tret = tp_event->perf_perm(tp_event, p_event);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\t/*",
            "\t * We checked and allowed to create parent,",
            "\t * allow children without checking.",
            "\t */",
            "\tif (p_event->parent)",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * It's ok to check current process (owner) permissions in here,",
            "\t * because code below is called only via perf_event_open syscall.",
            "\t */",
            "",
            "\t/* The ftrace function trace is allowed only for root. */",
            "\tif (ftrace_event_is_function(tp_event)) {",
            "\t\tret = perf_allow_tracepoint(&p_event->attr);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "",
            "\t\tif (!is_sampling_event(p_event))",
            "\t\t\treturn 0;",
            "",
            "\t\t/*",
            "\t\t * We don't allow user space callchains for  function trace",
            "\t\t * event, due to issues with page faults while tracing page",
            "\t\t * fault handler and its overall trickiness nature.",
            "\t\t */",
            "\t\tif (!p_event->attr.exclude_callchain_user)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * Same reason to disable user stack dump as for user space",
            "\t\t * callchains above.",
            "\t\t */",
            "\t\tif (p_event->attr.sample_type & PERF_SAMPLE_STACK_USER)",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "",
            "\t/* No tracing, just counting, so no obvious leak */",
            "\tif (!(p_event->attr.sample_type & PERF_SAMPLE_RAW))",
            "\t\treturn 0;",
            "",
            "\t/* Some events are ok to be traced by non-root users... */",
            "\tif (p_event->attach_state == PERF_ATTACH_TASK) {",
            "\t\tif (tp_event->flags & TRACE_EVENT_FL_CAP_ANY)",
            "\t\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * ...otherwise raw tracepoint data can be a severe data leak,",
            "\t * only allow root to have these.",
            "\t */",
            "\tret = perf_allow_tracepoint(&p_event->attr);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\treturn 0;",
            "}",
            "static int perf_trace_event_reg(struct trace_event_call *tp_event,",
            "\t\t\t\tstruct perf_event *p_event)",
            "{",
            "\tstruct hlist_head __percpu *list;",
            "\tint ret = -ENOMEM;",
            "\tint cpu;",
            "",
            "\tp_event->tp_event = tp_event;",
            "\tif (tp_event->perf_refcount++ > 0)",
            "\t\treturn 0;",
            "",
            "\tlist = alloc_percpu(struct hlist_head);",
            "\tif (!list)",
            "\t\tgoto fail;",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tINIT_HLIST_HEAD(per_cpu_ptr(list, cpu));",
            "",
            "\ttp_event->perf_events = list;",
            "",
            "\tif (!total_ref_count) {",
            "\t\tchar __percpu *buf;",
            "\t\tint i;",
            "",
            "\t\tfor (i = 0; i < PERF_NR_CONTEXTS; i++) {",
            "\t\t\tbuf = (char __percpu *)alloc_percpu(perf_trace_t);",
            "\t\t\tif (!buf)",
            "\t\t\t\tgoto fail;",
            "",
            "\t\t\tperf_trace_buf[i] = buf;",
            "\t\t}",
            "\t}",
            "",
            "\tret = tp_event->class->reg(tp_event, TRACE_REG_PERF_REGISTER, NULL);",
            "\tif (ret)",
            "\t\tgoto fail;",
            "",
            "\ttotal_ref_count++;",
            "\treturn 0;",
            "",
            "fail:",
            "\tif (!total_ref_count) {",
            "\t\tint i;",
            "",
            "\t\tfor (i = 0; i < PERF_NR_CONTEXTS; i++) {",
            "\t\t\tfree_percpu(perf_trace_buf[i]);",
            "\t\t\tperf_trace_buf[i] = NULL;",
            "\t\t}",
            "\t}",
            "",
            "\tif (!--tp_event->perf_refcount) {",
            "\t\tfree_percpu(tp_event->perf_events);",
            "\t\ttp_event->perf_events = NULL;",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "perf_trace_event_perm, perf_trace_event_reg",
          "description": "perf_trace_event_perm检查事件权限，限制非root用户访问敏感trace点；perf_trace_event_reg注册事件，分配per-CPU哈希表头并初始化引用计数。",
          "similarity": 0.6440994739532471
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/trace/trace_event_perf.c",
          "start_line": 154,
          "end_line": 276,
          "content": [
            "static void perf_trace_event_unreg(struct perf_event *p_event)",
            "{",
            "\tstruct trace_event_call *tp_event = p_event->tp_event;",
            "\tint i;",
            "",
            "\tif (--tp_event->perf_refcount > 0)",
            "\t\treturn;",
            "",
            "\ttp_event->class->reg(tp_event, TRACE_REG_PERF_UNREGISTER, NULL);",
            "",
            "\t/*",
            "\t * Ensure our callback won't be called anymore. The buffers",
            "\t * will be freed after that.",
            "\t */",
            "\ttracepoint_synchronize_unregister();",
            "",
            "\tfree_percpu(tp_event->perf_events);",
            "\ttp_event->perf_events = NULL;",
            "",
            "\tif (!--total_ref_count) {",
            "\t\tfor (i = 0; i < PERF_NR_CONTEXTS; i++) {",
            "\t\t\tfree_percpu(perf_trace_buf[i]);",
            "\t\t\tperf_trace_buf[i] = NULL;",
            "\t\t}",
            "\t}",
            "}",
            "static int perf_trace_event_open(struct perf_event *p_event)",
            "{",
            "\tstruct trace_event_call *tp_event = p_event->tp_event;",
            "\treturn tp_event->class->reg(tp_event, TRACE_REG_PERF_OPEN, p_event);",
            "}",
            "static void perf_trace_event_close(struct perf_event *p_event)",
            "{",
            "\tstruct trace_event_call *tp_event = p_event->tp_event;",
            "\ttp_event->class->reg(tp_event, TRACE_REG_PERF_CLOSE, p_event);",
            "}",
            "static int perf_trace_event_init(struct trace_event_call *tp_event,",
            "\t\t\t\t struct perf_event *p_event)",
            "{",
            "\tint ret;",
            "",
            "\tret = perf_trace_event_perm(tp_event, p_event);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = perf_trace_event_reg(tp_event, p_event);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = perf_trace_event_open(p_event);",
            "\tif (ret) {",
            "\t\tperf_trace_event_unreg(p_event);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int perf_trace_init(struct perf_event *p_event)",
            "{",
            "\tstruct trace_event_call *tp_event;",
            "\tu64 event_id = p_event->attr.config;",
            "\tint ret = -EINVAL;",
            "",
            "\tmutex_lock(&event_mutex);",
            "\tlist_for_each_entry(tp_event, &ftrace_events, list) {",
            "\t\tif (tp_event->event.type == event_id &&",
            "\t\t    tp_event->class && tp_event->class->reg &&",
            "\t\t    trace_event_try_get_ref(tp_event)) {",
            "\t\t\tret = perf_trace_event_init(tp_event, p_event);",
            "\t\t\tif (ret)",
            "\t\t\t\ttrace_event_put_ref(tp_event);",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "\tmutex_unlock(&event_mutex);",
            "",
            "\treturn ret;",
            "}",
            "void perf_trace_destroy(struct perf_event *p_event)",
            "{",
            "\tmutex_lock(&event_mutex);",
            "\tperf_trace_event_close(p_event);",
            "\tperf_trace_event_unreg(p_event);",
            "\ttrace_event_put_ref(p_event->tp_event);",
            "\tmutex_unlock(&event_mutex);",
            "}",
            "int perf_kprobe_init(struct perf_event *p_event, bool is_retprobe)",
            "{",
            "\tint ret;",
            "\tchar *func = NULL;",
            "\tstruct trace_event_call *tp_event;",
            "",
            "\tif (p_event->attr.kprobe_func) {",
            "\t\tfunc = strndup_user(u64_to_user_ptr(p_event->attr.kprobe_func),",
            "\t\t\t\t    KSYM_NAME_LEN);",
            "\t\tif (IS_ERR(func)) {",
            "\t\t\tret = PTR_ERR(func);",
            "\t\t\treturn (ret == -EINVAL) ? -E2BIG : ret;",
            "\t\t}",
            "",
            "\t\tif (func[0] == '\\0') {",
            "\t\t\tkfree(func);",
            "\t\t\tfunc = NULL;",
            "\t\t}",
            "\t}",
            "",
            "\ttp_event = create_local_trace_kprobe(",
            "\t\tfunc, (void *)(unsigned long)(p_event->attr.kprobe_addr),",
            "\t\tp_event->attr.probe_offset, is_retprobe);",
            "\tif (IS_ERR(tp_event)) {",
            "\t\tret = PTR_ERR(tp_event);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tmutex_lock(&event_mutex);",
            "\tret = perf_trace_event_init(tp_event, p_event);",
            "\tif (ret)",
            "\t\tdestroy_local_trace_kprobe(tp_event);",
            "\tmutex_unlock(&event_mutex);",
            "out:",
            "\tkfree(func);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "perf_trace_event_unreg, perf_trace_event_open, perf_trace_event_close, perf_trace_event_init, perf_trace_init, perf_trace_destroy, perf_kprobe_init",
          "description": "perf_trace_event_unreg卸载事件并释放资源；perf_trace_event_open/close调用注册接口；perf_trace_init查找匹配事件类型并初始化；perf_kprobe_init创建本地kprobe跟踪事件。",
          "similarity": 0.6414976119995117
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/trace/trace_event_perf.c",
          "start_line": 425,
          "end_line": 524,
          "content": [
            "void perf_trace_buf_update(void *record, u16 type)",
            "{",
            "\tstruct trace_entry *entry = record;",
            "",
            "\ttracing_generic_entry_update(entry, type, tracing_gen_ctx());",
            "}",
            "static void",
            "perf_ftrace_function_call(unsigned long ip, unsigned long parent_ip,",
            "\t\t\t  struct ftrace_ops *ops,  struct ftrace_regs *fregs)",
            "{",
            "\tstruct ftrace_entry *entry;",
            "\tstruct perf_event *event;",
            "\tstruct hlist_head head;",
            "\tstruct pt_regs regs;",
            "\tint rctx;",
            "\tint bit;",
            "",
            "\tif (!rcu_is_watching())",
            "\t\treturn;",
            "",
            "\tbit = ftrace_test_recursion_trylock(ip, parent_ip);",
            "\tif (bit < 0)",
            "\t\treturn;",
            "",
            "\tif ((unsigned long)ops->private != smp_processor_id())",
            "\t\tgoto out;",
            "",
            "\tevent = container_of(ops, struct perf_event, ftrace_ops);",
            "",
            "\t/*",
            "\t * @event->hlist entry is NULL (per INIT_HLIST_NODE), and all",
            "\t * the perf code does is hlist_for_each_entry_rcu(), so we can",
            "\t * get away with simply setting the @head.first pointer in order",
            "\t * to create a singular list.",
            "\t */",
            "\thead.first = &event->hlist_entry;",
            "",
            "#define ENTRY_SIZE (ALIGN(sizeof(struct ftrace_entry) + sizeof(u32), \\",
            "\t\t    sizeof(u64)) - sizeof(u32))",
            "",
            "\tBUILD_BUG_ON(ENTRY_SIZE > PERF_MAX_TRACE_SIZE);",
            "",
            "\tmemset(&regs, 0, sizeof(regs));",
            "\tperf_fetch_caller_regs(&regs);",
            "",
            "\tentry = perf_trace_buf_alloc(ENTRY_SIZE, NULL, &rctx);",
            "\tif (!entry)",
            "\t\tgoto out;",
            "",
            "\tentry->ip = ip;",
            "\tentry->parent_ip = parent_ip;",
            "\tperf_trace_buf_submit(entry, ENTRY_SIZE, rctx, TRACE_FN,",
            "\t\t\t      1, &regs, &head, NULL);",
            "",
            "out:",
            "\tftrace_test_recursion_unlock(bit);",
            "#undef ENTRY_SIZE",
            "}",
            "static int perf_ftrace_function_register(struct perf_event *event)",
            "{",
            "\tstruct ftrace_ops *ops = &event->ftrace_ops;",
            "",
            "\tops->func    = perf_ftrace_function_call;",
            "\tops->private = (void *)(unsigned long)nr_cpu_ids;",
            "",
            "\treturn register_ftrace_function(ops);",
            "}",
            "static int perf_ftrace_function_unregister(struct perf_event *event)",
            "{",
            "\tstruct ftrace_ops *ops = &event->ftrace_ops;",
            "\tint ret = unregister_ftrace_function(ops);",
            "\tftrace_free_filter(ops);",
            "\treturn ret;",
            "}",
            "int perf_ftrace_event_register(struct trace_event_call *call,",
            "\t\t\t       enum trace_reg type, void *data)",
            "{",
            "\tstruct perf_event *event = data;",
            "",
            "\tswitch (type) {",
            "\tcase TRACE_REG_REGISTER:",
            "\tcase TRACE_REG_UNREGISTER:",
            "\t\tbreak;",
            "\tcase TRACE_REG_PERF_REGISTER:",
            "\tcase TRACE_REG_PERF_UNREGISTER:",
            "\t\treturn 0;",
            "\tcase TRACE_REG_PERF_OPEN:",
            "\t\treturn perf_ftrace_function_register(data);",
            "\tcase TRACE_REG_PERF_CLOSE:",
            "\t\treturn perf_ftrace_function_unregister(data);",
            "\tcase TRACE_REG_PERF_ADD:",
            "\t\tevent->ftrace_ops.private = (void *)(unsigned long)smp_processor_id();",
            "\t\treturn 1;",
            "\tcase TRACE_REG_PERF_DEL:",
            "\t\tevent->ftrace_ops.private = (void *)(unsigned long)nr_cpu_ids;",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn -EINVAL;",
            "}"
          ],
          "function_name": "perf_trace_buf_update, perf_ftrace_function_call, perf_ftrace_function_register, perf_ftrace_function_unregister, perf_ftrace_event_register",
          "description": "perf_trace_buf_update更新跟踪条目；perf_ftrace_function_call作为函数入口点收集执行信息；perf_ftrace_function_register/unregister管理ftrace钩子注册；perf_ftrace_event_register处理不同注册类型的分发。",
          "similarity": 0.6312098503112793
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/trace/trace_event_perf.c",
          "start_line": 285,
          "end_line": 389,
          "content": [
            "void perf_kprobe_destroy(struct perf_event *p_event)",
            "{",
            "\tmutex_lock(&event_mutex);",
            "\tperf_trace_event_close(p_event);",
            "\tperf_trace_event_unreg(p_event);",
            "\ttrace_event_put_ref(p_event->tp_event);",
            "\tmutex_unlock(&event_mutex);",
            "",
            "\tdestroy_local_trace_kprobe(p_event->tp_event);",
            "}",
            "int perf_uprobe_init(struct perf_event *p_event,",
            "\t\t     unsigned long ref_ctr_offset, bool is_retprobe)",
            "{",
            "\tint ret;",
            "\tchar *path = NULL;",
            "\tstruct trace_event_call *tp_event;",
            "",
            "\tif (!p_event->attr.uprobe_path)",
            "\t\treturn -EINVAL;",
            "",
            "\tpath = strndup_user(u64_to_user_ptr(p_event->attr.uprobe_path),",
            "\t\t\t    PATH_MAX);",
            "\tif (IS_ERR(path)) {",
            "\t\tret = PTR_ERR(path);",
            "\t\treturn (ret == -EINVAL) ? -E2BIG : ret;",
            "\t}",
            "\tif (path[0] == '\\0') {",
            "\t\tret = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\ttp_event = create_local_trace_uprobe(path, p_event->attr.probe_offset,",
            "\t\t\t\t\t     ref_ctr_offset, is_retprobe);",
            "\tif (IS_ERR(tp_event)) {",
            "\t\tret = PTR_ERR(tp_event);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * local trace_uprobe need to hold event_mutex to call",
            "\t * uprobe_buffer_enable() and uprobe_buffer_disable().",
            "\t * event_mutex is not required for local trace_kprobes.",
            "\t */",
            "\tmutex_lock(&event_mutex);",
            "\tret = perf_trace_event_init(tp_event, p_event);",
            "\tif (ret)",
            "\t\tdestroy_local_trace_uprobe(tp_event);",
            "\tmutex_unlock(&event_mutex);",
            "out:",
            "\tkfree(path);",
            "\treturn ret;",
            "}",
            "void perf_uprobe_destroy(struct perf_event *p_event)",
            "{",
            "\tmutex_lock(&event_mutex);",
            "\tperf_trace_event_close(p_event);",
            "\tperf_trace_event_unreg(p_event);",
            "\ttrace_event_put_ref(p_event->tp_event);",
            "\tmutex_unlock(&event_mutex);",
            "\tdestroy_local_trace_uprobe(p_event->tp_event);",
            "}",
            "int perf_trace_add(struct perf_event *p_event, int flags)",
            "{",
            "\tstruct trace_event_call *tp_event = p_event->tp_event;",
            "\tstruct hw_perf_event *hwc = &p_event->hw;",
            "",
            "\tif (!(flags & PERF_EF_START))",
            "\t\tp_event->hw.state = PERF_HES_STOPPED;",
            "",
            "\tif (is_sampling_event(p_event)) {",
            "\t\thwc->last_period = hwc->sample_period;",
            "\t\tperf_swevent_set_period(p_event);",
            "\t}",
            "",
            "\t/*",
            "\t * If TRACE_REG_PERF_ADD returns false; no custom action was performed",
            "\t * and we need to take the default action of enqueueing our event on",
            "\t * the right per-cpu hlist.",
            "\t */",
            "\tif (!tp_event->class->reg(tp_event, TRACE_REG_PERF_ADD, p_event)) {",
            "\t\tstruct hlist_head __percpu *pcpu_list;",
            "\t\tstruct hlist_head *list;",
            "",
            "\t\tpcpu_list = tp_event->perf_events;",
            "\t\tif (WARN_ON_ONCE(!pcpu_list))",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\tlist = this_cpu_ptr(pcpu_list);",
            "\t\thlist_add_head_rcu(&p_event->hlist_entry, list);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void perf_trace_del(struct perf_event *p_event, int flags)",
            "{",
            "\tstruct trace_event_call *tp_event = p_event->tp_event;",
            "",
            "\t/*",
            "\t * If TRACE_REG_PERF_DEL returns false; no custom action was performed",
            "\t * and we need to take the default action of dequeueing our event from",
            "\t * the right per-cpu hlist.",
            "\t */",
            "\tif (!tp_event->class->reg(tp_event, TRACE_REG_PERF_DEL, p_event))",
            "\t\thlist_del_rcu(&p_event->hlist_entry);",
            "}"
          ],
          "function_name": "perf_kprobe_destroy, perf_uprobe_init, perf_uprobe_destroy, perf_trace_add, perf_trace_del",
          "description": "perf_kprobe_destroy清理kprobe跟踪；perf_uprobe_init创建uprobe跟踪；perf_trace_add/del管理事件在CPU哈希表中的加入/移除。",
          "similarity": 0.606107771396637
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/trace/trace_event_perf.c",
          "start_line": 1,
          "end_line": 26,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * trace event based perf event profiling/tracing",
            " *",
            " * Copyright (C) 2009 Red Hat Inc, Peter Zijlstra",
            " * Copyright (C) 2009-2010 Frederic Weisbecker <fweisbec@gmail.com>",
            " */",
            "",
            "#include <linux/module.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/security.h>",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "",
            "static char __percpu *perf_trace_buf[PERF_NR_CONTEXTS];",
            "",
            "/*",
            " * Force it to be aligned to unsigned long to avoid misaligned accesses",
            " * surprises",
            " */",
            "typedef typeof(unsigned long [PERF_MAX_TRACE_SIZE / sizeof(unsigned long)])",
            "\tperf_trace_t;",
            "",
            "/* Count the events in use (per event id, not per instance) */",
            "static int\ttotal_ref_count;",
            ""
          ],
          "function_name": null,
          "description": "定义perf_trace_buf数组用于存储Perf事件的缓冲区，total_ref_count记录全局事件引用计数，perf_trace_t类型通过align到unsigned long防止对齐问题。",
          "similarity": 0.5714521408081055
        }
      ]
    },
    {
      "source_file": "kernel/bpf/task_iter.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:33:05\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\task_iter.c`\n\n---\n\n# `bpf/task_iter.c` 技术文档\n\n## 1. 文件概述\n\n`bpf/task_iter.c` 是 Linux 内核中 BPF（Berkeley Packet Filter）子系统的一部分，实现了基于 BPF 的任务（task）迭代器（iterator）。该文件提供了两种 BPF 迭代器：\n\n- **`task` 迭代器**：用于遍历内核中的 `task_struct`（即进程/线程）对象。\n- **`task_file` 迭代器**：用于遍历指定任务（或所有任务）打开的文件描述符及其对应的 `file` 对象。\n\n这些迭代器允许 BPF 程序以安全、高效的方式遍历内核中的任务和文件资源，常用于系统监控、安全审计和性能分析等场景。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct bpf_iter_seq_task_common`  \n  任务迭代器的通用上下文，包含 PID 命名空间、迭代类型（ALL/TID/PID）、目标 PID 和当前访问的 PID。\n\n- `struct bpf_iter_seq_task_info`  \n  用于 `task` 迭代器的私有数据，继承自 `bpf_iter_seq_task_common`，并记录当前线程 ID（TID）。\n\n- `struct bpf_iter_seq_task_file_info`  \n  用于 `task_file` 迭代器的私有数据，包含当前任务、TID 和当前文件描述符（fd）。\n\n- `struct bpf_iter__task` / `struct bpf_iter__task_file`  \n  BPF 程序的元数据上下文结构，分别用于向 BPF 程序传递 `task_struct` 或 `task_struct + file` 信息。\n\n### 主要函数\n\n- `task_seq_get_next()`  \n  根据迭代类型（ALL/TID/TGID）获取下一个有效的 `task_struct`。\n\n- `task_group_seq_get_next()`  \n  专门用于遍历指定线程组（TGID）内的所有线程。\n\n- `task_seq_start()` / `task_seq_next()` / `task_seq_stop()` / `task_seq_show()`  \n  实现标准 `seq_file` 接口，用于 `task` 迭代器的序列化遍历。\n\n- `task_file_seq_get_next()`  \n  遍历当前任务的文件描述符表，返回下一个有效的 `file` 对象。\n\n- `task_file_seq_start()` / `task_file_seq_next()`  \n  实现 `task_file` 迭代器的 `seq_file` 接口。\n\n- `bpf_iter_attach_task()`  \n  解析 BPF 迭代器链接时传入的参数（如 TID、PID 或 pidfd），初始化迭代器上下文。\n\n- `__task_seq_show()` / `DEFINE_BPF_ITER_FUNC(task, ...)`  \n  调用关联的 BPF 程序，并传入当前任务（或任务+文件）作为上下文。\n\n## 3. 关键实现\n\n### 迭代类型支持\n\n迭代器支持三种模式：\n- **`BPF_TASK_ITER_ALL`**：遍历命名空间中所有任务（按 PID 递增顺序）。\n- **`BPF_TASK_ITER_TID`**：仅遍历指定线程 ID（TID）对应的任务。\n- **`BPF_TASK_ITER_TGID`**：遍历指定线程组 ID（TGID，即主线程 PID）下的所有线程。\n\n### 安全遍历机制\n\n- 使用 `rcu_read_lock()` 保护对任务和 PID 哈希表的访问。\n- 通过 `get_pid_task()` 和 `put_task_struct()` 管理任务引用计数，防止遍历过程中任务被释放。\n- 在 `task_file` 迭代器中使用 `task_lookup_next_fdget_rcu()` 安全地遍历文件描述符表。\n\n### 文件去重逻辑\n\n在 `task_file` 迭代器中，若启用 `skip_if_dup_files`（实际在 `task_file_seq_get_next` 中硬编码为 `true`），会跳过与线程组 leader 共享 `files` 结构的非主线程，避免重复遍历同一组文件描述符。\n\n### PID 命名空间支持\n\n所有 PID 查找均通过 `find_pid_ns()` 和 `pid_nr_ns()` 在指定的 `pid_namespace` 中进行，确保容器环境下的正确性。\n\n### BPF 程序回调\n\n通过 `bpf_iter_run_prog()` 在每次 `show` 阶段调用用户态加载的 BPF 程序，传递当前任务（或任务+文件）作为上下文。`stop` 阶段也会调用一次 BPF 程序（`in_stop=true`），用于清理或最终处理。\n\n## 4. 依赖关系\n\n- **内核核心模块**：\n  - `<linux/pid_namespace.h>`：PID 命名空间管理。\n  - `<linux/sched.h>`（隐式）：`task_struct`、`next_thread()`、`thread_group_leader()` 等任务操作。\n  - `<linux/file.h>` / `<linux/fdtable.h>`：文件描述符表遍历。\n  - `<linux/bpf.h>` / `<linux/filter.h>`：BPF 核心框架和迭代器接口。\n  - `<linux/bpf_mem_alloc.h>`：BPF 内存分配。\n  - `\"mmap_unlock_work.h\"`：可能用于处理 mmap 锁相关上下文（具体用途需结合其他代码）。\n\n- **BPF 子系统**：\n  - 依赖 `bpf_iter_get_info()` 和 `bpf_iter_run_prog()` 等通用迭代器运行时支持。\n  - 使用 `DEFINE_BPF_ITER_FUNC` 宏注册 `task` 类型的 BPF 迭代器。\n\n## 5. 使用场景\n\n- **系统监控工具**：如 `bpftool` 可通过 `task` 迭代器收集所有进程的内存、CPU 或安全上下文信息。\n- **安全策略实施**：BPF 程序可遍历任务并检查其凭证（cred）、命名空间或打开的文件，实现运行时策略。\n- **资源审计**：`task_file` 迭代器可用于审计进程打开的文件、套接字或设备，检测异常行为。\n- **容器环境调试**：在容器（PID namespace）中精确遍历特定进程组的任务和资源。\n- **性能分析**：高效遍历任务结构，避免传统 `/proc` 文件系统解析开销。",
      "similarity": 0.6255935430526733,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/bpf/task_iter.c",
          "start_line": 198,
          "end_line": 303,
          "content": [
            "static int __task_seq_show(struct seq_file *seq, struct task_struct *task,",
            "\t\t\t   bool in_stop)",
            "{",
            "\tstruct bpf_iter_meta meta;",
            "\tstruct bpf_iter__task ctx;",
            "\tstruct bpf_prog *prog;",
            "",
            "\tmeta.seq = seq;",
            "\tprog = bpf_iter_get_info(&meta, in_stop);",
            "\tif (!prog)",
            "\t\treturn 0;",
            "",
            "\tctx.meta = &meta;",
            "\tctx.task = task;",
            "\treturn bpf_iter_run_prog(prog, &ctx);",
            "}",
            "static int task_seq_show(struct seq_file *seq, void *v)",
            "{",
            "\treturn __task_seq_show(seq, v, false);",
            "}",
            "static void task_seq_stop(struct seq_file *seq, void *v)",
            "{",
            "\tif (!v)",
            "\t\t(void)__task_seq_show(seq, v, true);",
            "\telse",
            "\t\tput_task_struct((struct task_struct *)v);",
            "}",
            "static int bpf_iter_attach_task(struct bpf_prog *prog,",
            "\t\t\t\tunion bpf_iter_link_info *linfo,",
            "\t\t\t\tstruct bpf_iter_aux_info *aux)",
            "{",
            "\tunsigned int flags;",
            "\tstruct pid *pid;",
            "\tpid_t tgid;",
            "",
            "\tif ((!!linfo->task.tid + !!linfo->task.pid + !!linfo->task.pid_fd) > 1)",
            "\t\treturn -EINVAL;",
            "",
            "\taux->task.type = BPF_TASK_ITER_ALL;",
            "\tif (linfo->task.tid != 0) {",
            "\t\taux->task.type = BPF_TASK_ITER_TID;",
            "\t\taux->task.pid = linfo->task.tid;",
            "\t}",
            "\tif (linfo->task.pid != 0) {",
            "\t\taux->task.type = BPF_TASK_ITER_TGID;",
            "\t\taux->task.pid = linfo->task.pid;",
            "\t}",
            "\tif (linfo->task.pid_fd != 0) {",
            "\t\taux->task.type = BPF_TASK_ITER_TGID;",
            "",
            "\t\tpid = pidfd_get_pid(linfo->task.pid_fd, &flags);",
            "\t\tif (IS_ERR(pid))",
            "\t\t\treturn PTR_ERR(pid);",
            "",
            "\t\ttgid = pid_nr_ns(pid, task_active_pid_ns(current));",
            "\t\taux->task.pid = tgid;",
            "\t\tput_pid(pid);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int __task_file_seq_show(struct seq_file *seq, struct file *file,",
            "\t\t\t\tbool in_stop)",
            "{",
            "\tstruct bpf_iter_seq_task_file_info *info = seq->private;",
            "\tstruct bpf_iter__task_file ctx;",
            "\tstruct bpf_iter_meta meta;",
            "\tstruct bpf_prog *prog;",
            "",
            "\tmeta.seq = seq;",
            "\tprog = bpf_iter_get_info(&meta, in_stop);",
            "\tif (!prog)",
            "\t\treturn 0;",
            "",
            "\tctx.meta = &meta;",
            "\tctx.task = info->task;",
            "\tctx.fd = info->fd;",
            "\tctx.file = file;",
            "\treturn bpf_iter_run_prog(prog, &ctx);",
            "}",
            "static int task_file_seq_show(struct seq_file *seq, void *v)",
            "{",
            "\treturn __task_file_seq_show(seq, v, false);",
            "}",
            "static void task_file_seq_stop(struct seq_file *seq, void *v)",
            "{",
            "\tstruct bpf_iter_seq_task_file_info *info = seq->private;",
            "",
            "\tif (!v) {",
            "\t\t(void)__task_file_seq_show(seq, v, true);",
            "\t} else {",
            "\t\tfput((struct file *)v);",
            "\t\tput_task_struct(info->task);",
            "\t\tinfo->task = NULL;",
            "\t}",
            "}",
            "static int init_seq_pidns(void *priv_data, struct bpf_iter_aux_info *aux)",
            "{",
            "\tstruct bpf_iter_seq_task_common *common = priv_data;",
            "",
            "\tcommon->ns = get_pid_ns(task_active_pid_ns(current));",
            "\tcommon->type = aux->task.type;",
            "\tcommon->pid = aux->task.pid;",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "__task_seq_show, task_seq_show, task_seq_stop, bpf_iter_attach_task, __task_file_seq_show, task_file_seq_show, task_file_seq_stop, init_seq_pidns",
          "description": "实现任务迭代器的显示逻辑和链接参数解析，包含 __task_seq_show 显示任务信息，task_seq_stop 清理资源，bpf_iter_attach_task 解析任务类型（TID/TGID），及关联文件描述符的扩展功能。",
          "similarity": 0.6281654834747314
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/bpf/task_iter.c",
          "start_line": 421,
          "end_line": 535,
          "content": [
            "static void fini_seq_pidns(void *priv_data)",
            "{",
            "\tstruct bpf_iter_seq_task_common *common = priv_data;",
            "",
            "\tput_pid_ns(common->ns);",
            "}",
            "static int __task_vma_seq_show(struct seq_file *seq, bool in_stop)",
            "{",
            "\tstruct bpf_iter_seq_task_vma_info *info = seq->private;",
            "\tstruct bpf_iter__task_vma ctx;",
            "\tstruct bpf_iter_meta meta;",
            "\tstruct bpf_prog *prog;",
            "",
            "\tmeta.seq = seq;",
            "\tprog = bpf_iter_get_info(&meta, in_stop);",
            "\tif (!prog)",
            "\t\treturn 0;",
            "",
            "\tctx.meta = &meta;",
            "\tctx.task = info->task;",
            "\tctx.vma = info->vma;",
            "\treturn bpf_iter_run_prog(prog, &ctx);",
            "}",
            "static int task_vma_seq_show(struct seq_file *seq, void *v)",
            "{",
            "\treturn __task_vma_seq_show(seq, false);",
            "}",
            "static void task_vma_seq_stop(struct seq_file *seq, void *v)",
            "{",
            "\tstruct bpf_iter_seq_task_vma_info *info = seq->private;",
            "",
            "\tif (!v) {",
            "\t\t(void)__task_vma_seq_show(seq, true);",
            "\t} else {",
            "\t\t/* info->vma has not been seen by the BPF program. If the",
            "\t\t * user space reads more, task_vma_seq_get_next should",
            "\t\t * return this vma again. Set prev_vm_start to ~0UL,",
            "\t\t * so that we don't skip the vma returned by the next",
            "\t\t * find_vma() (case task_vma_iter_find_vma in",
            "\t\t * task_vma_seq_get_next()).",
            "\t\t */",
            "\t\tinfo->prev_vm_start = ~0UL;",
            "\t\tinfo->prev_vm_end = info->vma->vm_end;",
            "\t\tmmap_read_unlock(info->mm);",
            "\t\tmmput(info->mm);",
            "\t\tinfo->mm = NULL;",
            "\t\tput_task_struct(info->task);",
            "\t\tinfo->task = NULL;",
            "\t}",
            "}",
            "static int bpf_iter_fill_link_info(const struct bpf_iter_aux_info *aux, struct bpf_link_info *info)",
            "{",
            "\tswitch (aux->task.type) {",
            "\tcase BPF_TASK_ITER_TID:",
            "\t\tinfo->iter.task.tid = aux->task.pid;",
            "\t\tbreak;",
            "\tcase BPF_TASK_ITER_TGID:",
            "\t\tinfo->iter.task.pid = aux->task.pid;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tbreak;",
            "\t}",
            "\treturn 0;",
            "}",
            "static void bpf_iter_task_show_fdinfo(const struct bpf_iter_aux_info *aux, struct seq_file *seq)",
            "{",
            "\tseq_printf(seq, \"task_type:\\t%s\\n\", iter_task_type_names[aux->task.type]);",
            "\tif (aux->task.type == BPF_TASK_ITER_TID)",
            "\t\tseq_printf(seq, \"tid:\\t%u\\n\", aux->task.pid);",
            "\telse if (aux->task.type == BPF_TASK_ITER_TGID)",
            "\t\tseq_printf(seq, \"pid:\\t%u\\n\", aux->task.pid);",
            "}",
            "__bpf_kfunc int bpf_iter_task_vma_new(struct bpf_iter_task_vma *it,",
            "\t\t\t\t      struct task_struct *task, u64 addr)",
            "{",
            "\tstruct bpf_iter_task_vma_kern *kit = (void *)it;",
            "\tbool irq_work_busy = false;",
            "\tint err;",
            "",
            "\tBUILD_BUG_ON(sizeof(struct bpf_iter_task_vma_kern) != sizeof(struct bpf_iter_task_vma));",
            "\tBUILD_BUG_ON(__alignof__(struct bpf_iter_task_vma_kern) != __alignof__(struct bpf_iter_task_vma));",
            "",
            "\t/* is_iter_reg_valid_uninit guarantees that kit hasn't been initialized",
            "\t * before, so non-NULL kit->data doesn't point to previously",
            "\t * bpf_mem_alloc'd bpf_iter_task_vma_kern_data",
            "\t */",
            "\tkit->data = bpf_mem_alloc(&bpf_global_ma, sizeof(struct bpf_iter_task_vma_kern_data));",
            "\tif (!kit->data)",
            "\t\treturn -ENOMEM;",
            "",
            "\tkit->data->task = get_task_struct(task);",
            "\tkit->data->mm = task->mm;",
            "\tif (!kit->data->mm) {",
            "\t\terr = -ENOENT;",
            "\t\tgoto err_cleanup_iter;",
            "\t}",
            "",
            "\t/* kit->data->work == NULL is valid after bpf_mmap_unlock_get_irq_work */",
            "\tirq_work_busy = bpf_mmap_unlock_get_irq_work(&kit->data->work);",
            "\tif (irq_work_busy || !mmap_read_trylock(kit->data->mm)) {",
            "\t\terr = -EBUSY;",
            "\t\tgoto err_cleanup_iter;",
            "\t}",
            "",
            "\tvma_iter_init(&kit->data->vmi, kit->data->mm, addr);",
            "\treturn 0;",
            "",
            "err_cleanup_iter:",
            "\tif (kit->data->task)",
            "\t\tput_task_struct(kit->data->task);",
            "\tbpf_mem_free(&bpf_global_ma, kit->data);",
            "\t/* NULL kit->data signals failed bpf_iter_task_vma initialization */",
            "\tkit->data = NULL;",
            "\treturn err;",
            "}"
          ],
          "function_name": "fini_seq_pidns, __task_vma_seq_show, task_vma_seq_show, task_vma_seq_stop, bpf_iter_fill_link_info, bpf_iter_task_show_fdinfo, bpf_iter_task_vma_new",
          "description": "处理 VMA 区间遍历逻辑，包含 __task_vma_seq_show 显示 VMA 信息，task_vma_seq_stop 终止遍历并释放资源，提供 bpf_iter_fill_link_info 填充链接信息，以及 bpf_iter_task_vma_new 初始化 VMA 迭代器的内核态数据结构。",
          "similarity": 0.5668377876281738
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/task_iter.c",
          "start_line": 1,
          "end_line": 197,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/* Copyright (c) 2020 Facebook */",
            "",
            "#include <linux/init.h>",
            "#include <linux/namei.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/fs.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf_mem_alloc.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/mm_types.h>",
            "#include \"mmap_unlock_work.h\"",
            "",
            "static const char * const iter_task_type_names[] = {",
            "\t\"ALL\",",
            "\t\"TID\",",
            "\t\"PID\",",
            "};",
            "",
            "struct bpf_iter_seq_task_common {",
            "\tstruct pid_namespace *ns;",
            "\tenum bpf_iter_task_type\ttype;",
            "\tu32 pid;",
            "\tu32 pid_visiting;",
            "};",
            "",
            "struct bpf_iter_seq_task_info {",
            "\t/* The first field must be struct bpf_iter_seq_task_common.",
            "\t * this is assumed by {init, fini}_seq_pidns() callback functions.",
            "\t */",
            "\tstruct bpf_iter_seq_task_common common;",
            "\tu32 tid;",
            "};",
            "",
            "static struct task_struct *task_group_seq_get_next(struct bpf_iter_seq_task_common *common,",
            "\t\t\t\t\t\t   u32 *tid,",
            "\t\t\t\t\t\t   bool skip_if_dup_files)",
            "{",
            "\tstruct task_struct *task, *next_task;",
            "\tstruct pid *pid;",
            "\tu32 saved_tid;",
            "",
            "\tif (!*tid) {",
            "\t\t/* The first time, the iterator calls this function. */",
            "\t\tpid = find_pid_ns(common->pid, common->ns);",
            "\t\tif (!pid)",
            "\t\t\treturn NULL;",
            "",
            "\t\ttask = get_pid_task(pid, PIDTYPE_TGID);",
            "\t\tif (!task)",
            "\t\t\treturn NULL;",
            "",
            "\t\t*tid = common->pid;",
            "\t\tcommon->pid_visiting = common->pid;",
            "",
            "\t\treturn task;",
            "\t}",
            "",
            "\t/* If the control returns to user space and comes back to the",
            "\t * kernel again, *tid and common->pid_visiting should be the",
            "\t * same for task_seq_start() to pick up the correct task.",
            "\t */",
            "\tif (*tid == common->pid_visiting) {",
            "\t\tpid = find_pid_ns(common->pid_visiting, common->ns);",
            "\t\ttask = get_pid_task(pid, PIDTYPE_PID);",
            "",
            "\t\treturn task;",
            "\t}",
            "",
            "\tpid = find_pid_ns(common->pid_visiting, common->ns);",
            "\tif (!pid)",
            "\t\treturn NULL;",
            "",
            "\ttask = get_pid_task(pid, PIDTYPE_PID);",
            "\tif (!task)",
            "\t\treturn NULL;",
            "",
            "retry:",
            "\tif (!pid_alive(task)) {",
            "\t\tput_task_struct(task);",
            "\t\treturn NULL;",
            "\t}",
            "",
            "\tnext_task = next_thread(task);",
            "\tput_task_struct(task);",
            "\tif (!next_task)",
            "\t\treturn NULL;",
            "",
            "\tsaved_tid = *tid;",
            "\t*tid = __task_pid_nr_ns(next_task, PIDTYPE_PID, common->ns);",
            "\tif (!*tid || *tid == common->pid) {",
            "\t\t/* Run out of tasks of a process.  The tasks of a",
            "\t\t * thread_group are linked as circular linked list.",
            "\t\t */",
            "\t\t*tid = saved_tid;",
            "\t\treturn NULL;",
            "\t}",
            "",
            "\tget_task_struct(next_task);",
            "\tcommon->pid_visiting = *tid;",
            "",
            "\tif (skip_if_dup_files && task->files == task->group_leader->files) {",
            "\t\ttask = next_task;",
            "\t\tgoto retry;",
            "\t}",
            "",
            "\treturn next_task;",
            "}",
            "",
            "static struct task_struct *task_seq_get_next(struct bpf_iter_seq_task_common *common,",
            "\t\t\t\t\t     u32 *tid,",
            "\t\t\t\t\t     bool skip_if_dup_files)",
            "{",
            "\tstruct task_struct *task = NULL;",
            "\tstruct pid *pid;",
            "",
            "\tif (common->type == BPF_TASK_ITER_TID) {",
            "\t\tif (*tid && *tid != common->pid)",
            "\t\t\treturn NULL;",
            "\t\trcu_read_lock();",
            "\t\tpid = find_pid_ns(common->pid, common->ns);",
            "\t\tif (pid) {",
            "\t\t\ttask = get_pid_task(pid, PIDTYPE_PID);",
            "\t\t\t*tid = common->pid;",
            "\t\t}",
            "\t\trcu_read_unlock();",
            "",
            "\t\treturn task;",
            "\t}",
            "",
            "\tif (common->type == BPF_TASK_ITER_TGID) {",
            "\t\trcu_read_lock();",
            "\t\ttask = task_group_seq_get_next(common, tid, skip_if_dup_files);",
            "\t\trcu_read_unlock();",
            "",
            "\t\treturn task;",
            "\t}",
            "",
            "\trcu_read_lock();",
            "retry:",
            "\tpid = find_ge_pid(*tid, common->ns);",
            "\tif (pid) {",
            "\t\t*tid = pid_nr_ns(pid, common->ns);",
            "\t\ttask = get_pid_task(pid, PIDTYPE_PID);",
            "\t\tif (!task) {",
            "\t\t\t++*tid;",
            "\t\t\tgoto retry;",
            "\t\t} else if (skip_if_dup_files && !thread_group_leader(task) &&",
            "\t\t\t   task->files == task->group_leader->files) {",
            "\t\t\tput_task_struct(task);",
            "\t\t\ttask = NULL;",
            "\t\t\t++*tid;",
            "\t\t\tgoto retry;",
            "\t\t}",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\treturn task;",
            "}",
            "",
            "static void *task_seq_start(struct seq_file *seq, loff_t *pos)",
            "{",
            "\tstruct bpf_iter_seq_task_info *info = seq->private;",
            "\tstruct task_struct *task;",
            "",
            "\ttask = task_seq_get_next(&info->common, &info->tid, false);",
            "\tif (!task)",
            "\t\treturn NULL;",
            "",
            "\tif (*pos == 0)",
            "\t\t++*pos;",
            "\treturn task;",
            "}",
            "",
            "static void *task_seq_next(struct seq_file *seq, void *v, loff_t *pos)",
            "{",
            "\tstruct bpf_iter_seq_task_info *info = seq->private;",
            "\tstruct task_struct *task;",
            "",
            "\t++*pos;",
            "\t++info->tid;",
            "\tput_task_struct((struct task_struct *)v);",
            "\ttask = task_seq_get_next(&info->common, &info->tid, false);",
            "\tif (!task)",
            "\t\treturn NULL;",
            "",
            "\treturn task;",
            "}",
            "",
            "struct bpf_iter__task {",
            "\t__bpf_md_ptr(struct bpf_iter_meta *, meta);",
            "\t__bpf_md_ptr(struct task_struct *, task);",
            "};",
            "",
            "DEFINE_BPF_ITER_FUNC(task, struct bpf_iter_meta *meta, struct task_struct *task)",
            ""
          ],
          "function_name": null,
          "description": "定义任务迭代器相关结构体和函数，支持根据 TID/PID 遍历进程/线程，提供 task_group_seq_get_next 和 task_seq_get_next 等核心函数用于获取下一个任务实体，通过 RCU 锁保护并处理进程状态检查。",
          "similarity": 0.5423884391784668
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/bpf/task_iter.c",
          "start_line": 900,
          "end_line": 1010,
          "content": [
            "__bpf_kfunc void bpf_iter_task_vma_destroy(struct bpf_iter_task_vma *it)",
            "{",
            "\tstruct bpf_iter_task_vma_kern *kit = (void *)it;",
            "",
            "\tif (kit->data) {",
            "\t\tbpf_mmap_unlock_mm(kit->data->work, kit->data->mm);",
            "\t\tput_task_struct(kit->data->task);",
            "\t\tbpf_mem_free(&bpf_global_ma, kit->data);",
            "\t}",
            "}",
            "__bpf_kfunc int bpf_iter_css_task_new(struct bpf_iter_css_task *it,",
            "\t\tstruct cgroup_subsys_state *css, unsigned int flags)",
            "{",
            "\tstruct bpf_iter_css_task_kern *kit = (void *)it;",
            "",
            "\tBUILD_BUG_ON(sizeof(struct bpf_iter_css_task_kern) != sizeof(struct bpf_iter_css_task));",
            "\tBUILD_BUG_ON(__alignof__(struct bpf_iter_css_task_kern) !=",
            "\t\t\t\t\t__alignof__(struct bpf_iter_css_task));",
            "\tkit->css_it = NULL;",
            "\tswitch (flags) {",
            "\tcase CSS_TASK_ITER_PROCS | CSS_TASK_ITER_THREADED:",
            "\tcase CSS_TASK_ITER_PROCS:",
            "\tcase 0:",
            "\t\tbreak;",
            "\tdefault:",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tkit->css_it = bpf_mem_alloc(&bpf_global_ma, sizeof(struct css_task_iter));",
            "\tif (!kit->css_it)",
            "\t\treturn -ENOMEM;",
            "\tcss_task_iter_start(css, flags, kit->css_it);",
            "\treturn 0;",
            "}",
            "__bpf_kfunc void bpf_iter_css_task_destroy(struct bpf_iter_css_task *it)",
            "{",
            "\tstruct bpf_iter_css_task_kern *kit = (void *)it;",
            "",
            "\tif (!kit->css_it)",
            "\t\treturn;",
            "\tcss_task_iter_end(kit->css_it);",
            "\tbpf_mem_free(&bpf_global_ma, kit->css_it);",
            "}",
            "__bpf_kfunc int bpf_iter_task_new(struct bpf_iter_task *it,",
            "\t\tstruct task_struct *task__nullable, unsigned int flags)",
            "{",
            "\tstruct bpf_iter_task_kern *kit = (void *)it;",
            "",
            "\tBUILD_BUG_ON(sizeof(struct bpf_iter_task_kern) > sizeof(struct bpf_iter_task));",
            "\tBUILD_BUG_ON(__alignof__(struct bpf_iter_task_kern) !=",
            "\t\t\t\t\t__alignof__(struct bpf_iter_task));",
            "",
            "\tkit->task = kit->pos = NULL;",
            "\tswitch (flags) {",
            "\tcase BPF_TASK_ITER_ALL_THREADS:",
            "\tcase BPF_TASK_ITER_ALL_PROCS:",
            "\t\tbreak;",
            "\tcase BPF_TASK_ITER_PROC_THREADS:",
            "\t\tif (!task__nullable)",
            "\t\t\treturn -EINVAL;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tif (flags == BPF_TASK_ITER_PROC_THREADS)",
            "\t\tkit->task = task__nullable;",
            "\telse",
            "\t\tkit->task = &init_task;",
            "\tkit->pos = kit->task;",
            "\tkit->flags = flags;",
            "\treturn 0;",
            "}",
            "__bpf_kfunc void bpf_iter_task_destroy(struct bpf_iter_task *it)",
            "{",
            "}",
            "static void do_mmap_read_unlock(struct irq_work *entry)",
            "{",
            "\tstruct mmap_unlock_irq_work *work;",
            "",
            "\tif (WARN_ON_ONCE(IS_ENABLED(CONFIG_PREEMPT_RT)))",
            "\t\treturn;",
            "",
            "\twork = container_of(entry, struct mmap_unlock_irq_work, irq_work);",
            "\tmmap_read_unlock_non_owner(work->mm);",
            "}",
            "static int __init task_iter_init(void)",
            "{",
            "\tstruct mmap_unlock_irq_work *work;",
            "\tint ret, cpu;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\twork = per_cpu_ptr(&mmap_unlock_work, cpu);",
            "\t\tinit_irq_work(&work->irq_work, do_mmap_read_unlock);",
            "\t}",
            "",
            "\ttask_reg_info.ctx_arg_info[0].btf_id = btf_tracing_ids[BTF_TRACING_TYPE_TASK];",
            "\tret = bpf_iter_reg_target(&task_reg_info);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\ttask_file_reg_info.ctx_arg_info[0].btf_id = btf_tracing_ids[BTF_TRACING_TYPE_TASK];",
            "\ttask_file_reg_info.ctx_arg_info[1].btf_id = btf_tracing_ids[BTF_TRACING_TYPE_FILE];",
            "\tret =  bpf_iter_reg_target(&task_file_reg_info);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\ttask_vma_reg_info.ctx_arg_info[0].btf_id = btf_tracing_ids[BTF_TRACING_TYPE_TASK];",
            "\ttask_vma_reg_info.ctx_arg_info[1].btf_id = btf_tracing_ids[BTF_TRACING_TYPE_VMA];",
            "\treturn bpf_iter_reg_target(&task_vma_reg_info);",
            "}"
          ],
          "function_name": "bpf_iter_task_vma_destroy, bpf_iter_css_task_new, bpf_iter_css_task_destroy, bpf_iter_task_new, bpf_iter_task_destroy, do_mmap_read_unlock, task_iter_init",
          "description": "实现 CSS 任务迭代器和通用任务迭代器的创建/销毁接口，包含 bpf_iter_task_new 创建任务迭代器，do_mmap_read_unlock 卸载 mmap 读锁，task_iter_init 注册 BPF 目标追踪模块到内核跟踪系统。",
          "similarity": 0.5412518382072449
        }
      ]
    },
    {
      "source_file": "kernel/trace/trace_irqsoff.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:26:52\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `trace\\trace_irqsoff.c`\n\n---\n\n# `trace_irqsoff.c` 技术文档\n\n## 1. 文件概述\n\n`trace_irqsoff.c` 是 Linux 内核中用于追踪 **中断关闭（IRQs-off）** 和 **抢占关闭（preempt-off）** 关键路径延迟的核心模块。该文件实现了 `irqsoff` 和 `preemptoff` 两种延迟追踪器（tracer），用于检测系统中因长时间关闭中断或禁止抢占而导致的延迟问题，是内核延迟分析（latency tracing）的重要组成部分。\n\n该模块通过监控中断和抢占状态的变化，记录最长的关闭时间（即“关键路径”），帮助开发者识别潜在的实时性瓶颈。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `irqsoff_trace`：全局 `trace_array` 指针，代表当前激活的追踪实例。\n- `tracer_enabled`：追踪器是否启用的全局标志。\n- `tracing_cpu`（per-CPU）：标记当前 CPU 是否处于被追踪状态。\n- `max_trace_lock`：保护最大延迟记录的原始自旋锁。\n- `trace_type`：指示当前追踪类型（`TRACER_IRQS_OFF` 或 `TRACER_PREEMPT_OFF`）。\n- `max_sequence`：用于避免并发最大值更新干扰的序列计数器（cache-line 对齐）。\n\n### 主要函数\n\n- `irq_trace()` / `preempt_trace()`：判断当前是否应追踪中断或抢占关闭状态。\n- `func_prolog_dec()`：函数追踪的通用前置处理，检查是否应记录当前调用。\n- `irqsoff_tracer_call()`：函数追踪回调，记录函数调用事件。\n- `irqsoff_graph_entry()` / `irqsoff_graph_return()`：函数图追踪（function graph tracer）的入口和返回回调。\n- `check_critical_timing()`：检查当前关闭时间是否构成新的最大延迟（未完整显示，但为关键逻辑）。\n- `report_latency()`：判断是否应报告或记录当前延迟（基于阈值或历史最大值）。\n- `irqsoff_display_graph()`：切换函数图显示模式。\n- `irqsoff_print_line()` / `irqsoff_print_header()`：格式化输出追踪结果。\n\n## 3. 关键实现\n\n### 延迟检测机制\n\n- 模块通过 `preemptirq:preempt_disable/enable` 和 `irq_disable/enable` 等 tracepoint（来自 `trace/events/preemptirq.h`）感知中断/抢占状态变化。\n- 当进入关闭状态时开始计时，恢复时计算持续时间（`delta`）。\n- 使用 `report_latency()` 判断该 `delta` 是否值得记录：若设置了 `tracing_thresh`，则只记录超过阈值的延迟；否则只记录超过当前 `max_latency` 的延迟。\n\n### 并发安全与准确性\n\n- 使用 per-CPU 变量 `tracing_cpu` 标记正在追踪的 CPU，避免跨 CPU 干扰。\n- 通过 `max_sequence` 序列号机制防止多个 CPU 同时更新最大延迟时互相覆盖或受串扰（如控制台输出）影响。\n- 使用 `atomic_inc_return(&data->disabled)` 确保同一 CPU 上追踪回调不会嵌套执行，避免重复记录。\n\n### 函数追踪集成\n\n- 若启用 `CONFIG_FUNCTION_TRACER`，使用自定义的 `irqsoff_tracer_call` 作为 ftrace 回调，仅在关键路径期间记录函数调用。\n- 若启用 `CONFIG_FUNCTION_GRAPH_TRACER`，则进一步支持函数调用图（call graph）追踪，通过 `fgraph_ops` 注册入口/返回钩子。\n- 通过 `is_graph(tr)` 动态判断是否使用图模式输出，并调用相应的格式化函数（如 `print_graph_function_flags`）。\n\n### 模式切换与资源管理\n\n- `start_irqsoff_tracer()` / `stop_irqsoff_tracer()`（声明但未在片段中定义）负责启用/禁用底层追踪机制（如注册 ftrace ops）。\n- 切换图模式时会重置追踪状态（清零 `tracing_cpu`、`max_latency` 并重置缓冲区）。\n\n## 4. 依赖关系\n\n- **核心依赖**：\n  - `trace.h`：提供通用追踪基础设施（`trace_array`, `trace_function` 等）。\n  - `trace/events/preemptirq.h`：提供中断/抢占状态变化的 tracepoint。\n  - `ftrace.h` / `kprobes.h`：支持动态函数追踪。\n- **条件编译依赖**：\n  - `CONFIG_IRQSOFF_TRACER`：启用中断关闭追踪。\n  - `CONFIG_PREEMPT_TRACER`：启用抢占关闭追踪。\n  - `CONFIG_FUNCTION_TRACER`：启用函数级追踪。\n  - `CONFIG_FUNCTION_GRAPH_TRACER`：启用函数调用图追踪。\n- **运行时依赖**：依赖内核的 per-CPU 数据、原子操作、自旋锁等同步原语。\n\n## 5. 使用场景\n\n- **实时系统调试**：在实时内核（如 PREEMPT_RT）开发中，用于定位导致调度延迟的长关键路径。\n- **性能分析**：通过 `/sys/kernel/debug/tracing/` 接口启用 `irqsoff` 或 `preemptoff` 追踪器，分析系统最大中断/抢占关闭时间。\n- **阈值告警**：结合 `tracing_thresh` 设置延迟阈值，仅记录超限事件，减少日志噪音。\n- **函数路径分析**：配合函数图追踪，可视化导致长延迟的具体函数调用链。\n- **内核开发与测试**：在提交可能影响中断/抢占延迟的补丁前，使用该追踪器验证性能影响。",
      "similarity": 0.6220731139183044,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/trace/trace_irqsoff.c",
          "start_line": 217,
          "end_line": 355,
          "content": [
            "static void irqsoff_graph_return(struct ftrace_graph_ret *trace,",
            "\t\t\t\t struct fgraph_ops *gops,",
            "\t\t\t\t struct ftrace_regs *fregs)",
            "{",
            "\tstruct trace_array *tr = irqsoff_trace;",
            "\tstruct trace_array_cpu *data;",
            "\tunsigned long flags;",
            "\tunsigned int trace_ctx;",
            "\tu64 *calltime;",
            "\tint size;",
            "",
            "\tftrace_graph_addr_finish(gops, trace);",
            "",
            "\tif (!func_prolog_dec(tr, &data, &flags))",
            "\t\treturn;",
            "",
            "\tcalltime = fgraph_retrieve_data(gops->idx, &size);",
            "\tif (!calltime)",
            "\t\treturn;",
            "\ttrace->calltime = *calltime;",
            "",
            "\ttrace_ctx = tracing_gen_ctx_flags(flags);",
            "\t__trace_graph_return(tr, trace, trace_ctx);",
            "\tatomic_dec(&data->disabled);",
            "}",
            "static void irqsoff_trace_open(struct trace_iterator *iter)",
            "{",
            "\tif (is_graph(iter->tr))",
            "\t\tgraph_trace_open(iter);",
            "}",
            "static void irqsoff_trace_close(struct trace_iterator *iter)",
            "{",
            "\tif (iter->private)",
            "\t\tgraph_trace_close(iter);",
            "}",
            "static enum print_line_t irqsoff_print_line(struct trace_iterator *iter)",
            "{",
            "\t/*",
            "\t * In graph mode call the graph tracer output function,",
            "\t * otherwise go with the TRACE_FN event handler",
            "\t */",
            "\tif (is_graph(iter->tr))",
            "\t\treturn print_graph_function_flags(iter, GRAPH_TRACER_FLAGS);",
            "",
            "\treturn TRACE_TYPE_UNHANDLED;",
            "}",
            "static void irqsoff_print_header(struct seq_file *s)",
            "{",
            "\tstruct trace_array *tr = irqsoff_trace;",
            "",
            "\tif (is_graph(tr))",
            "\t\tprint_graph_headers_flags(s, GRAPH_TRACER_FLAGS);",
            "\telse",
            "\t\ttrace_default_header(s);",
            "}",
            "static void",
            "__trace_function(struct trace_array *tr,",
            "\t\t unsigned long ip, unsigned long parent_ip,",
            "\t\t unsigned int trace_ctx)",
            "{",
            "\tif (is_graph(tr))",
            "\t\ttrace_graph_function(tr, ip, parent_ip, trace_ctx);",
            "\telse",
            "\t\ttrace_function(tr, ip, parent_ip, trace_ctx);",
            "}",
            "static enum print_line_t irqsoff_print_line(struct trace_iterator *iter)",
            "{",
            "\treturn TRACE_TYPE_UNHANDLED;",
            "}",
            "static void irqsoff_trace_open(struct trace_iterator *iter) { }",
            "static void irqsoff_trace_close(struct trace_iterator *iter) { }",
            "static void irqsoff_print_header(struct seq_file *s)",
            "{",
            "\ttrace_default_header(s);",
            "}",
            "static void irqsoff_print_header(struct seq_file *s)",
            "{",
            "\ttrace_latency_header(s);",
            "}",
            "static bool report_latency(struct trace_array *tr, u64 delta)",
            "{",
            "\tif (tracing_thresh) {",
            "\t\tif (delta < tracing_thresh)",
            "\t\t\treturn false;",
            "\t} else {",
            "\t\tif (delta <= tr->max_latency)",
            "\t\t\treturn false;",
            "\t}",
            "\treturn true;",
            "}",
            "static void",
            "check_critical_timing(struct trace_array *tr,",
            "\t\t      struct trace_array_cpu *data,",
            "\t\t      unsigned long parent_ip,",
            "\t\t      int cpu)",
            "{",
            "\tu64 T0, T1, delta;",
            "\tunsigned long flags;",
            "\tunsigned int trace_ctx;",
            "",
            "\tT0 = data->preempt_timestamp;",
            "\tT1 = ftrace_now(cpu);",
            "\tdelta = T1-T0;",
            "",
            "\ttrace_ctx = tracing_gen_ctx();",
            "",
            "\tif (!report_latency(tr, delta))",
            "\t\tgoto out;",
            "",
            "\traw_spin_lock_irqsave(&max_trace_lock, flags);",
            "",
            "\t/* check if we are still the max latency */",
            "\tif (!report_latency(tr, delta))",
            "\t\tgoto out_unlock;",
            "",
            "\t__trace_function(tr, CALLER_ADDR0, parent_ip, trace_ctx);",
            "\t/* Skip 5 functions to get to the irq/preempt enable function */",
            "\t__trace_stack(tr, trace_ctx, 5);",
            "",
            "\tif (data->critical_sequence != max_sequence)",
            "\t\tgoto out_unlock;",
            "",
            "\tdata->critical_end = parent_ip;",
            "",
            "\tif (likely(!is_tracing_stopped())) {",
            "\t\ttr->max_latency = delta;",
            "\t\tupdate_max_tr_single(tr, current, cpu);",
            "\t}",
            "",
            "\tmax_sequence++;",
            "",
            "out_unlock:",
            "\traw_spin_unlock_irqrestore(&max_trace_lock, flags);",
            "",
            "out:",
            "\tdata->critical_sequence = max_sequence;",
            "\tdata->preempt_timestamp = ftrace_now(cpu);",
            "\t__trace_function(tr, CALLER_ADDR0, parent_ip, trace_ctx);",
            "}"
          ],
          "function_name": "irqsoff_graph_return, irqsoff_trace_open, irqsoff_trace_close, irqsoff_print_line, irqsoff_print_header, __trace_function, irqsoff_print_line, irqsoff_trace_open, irqsoff_trace_close, irqsoff_print_header, irqsoff_print_header, report_latency, check_critical_timing",
          "description": "提供跟踪事件输出格式化支持，包含关键路径延迟检测逻辑，通过时间差计算确定是否记录异常延迟事件",
          "similarity": 0.5964033603668213
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/trace/trace_irqsoff.c",
          "start_line": 44,
          "end_line": 167,
          "content": [
            "static inline int",
            "preempt_trace(int pc)",
            "{",
            "\treturn ((trace_type & TRACER_PREEMPT_OFF) && pc);",
            "}",
            "static inline int",
            "irq_trace(void)",
            "{",
            "\treturn ((trace_type & TRACER_IRQS_OFF) &&",
            "\t\tirqs_disabled());",
            "}",
            "static inline int irqsoff_display_graph(struct trace_array *tr, int set)",
            "{",
            "\treturn -EINVAL;",
            "}",
            "static int func_prolog_dec(struct trace_array *tr,",
            "\t\t\t   struct trace_array_cpu **data,",
            "\t\t\t   unsigned long *flags)",
            "{",
            "\tlong disabled;",
            "\tint cpu;",
            "",
            "\t/*",
            "\t * Does not matter if we preempt. We test the flags",
            "\t * afterward, to see if irqs are disabled or not.",
            "\t * If we preempt and get a false positive, the flags",
            "\t * test will fail.",
            "\t */",
            "\tcpu = raw_smp_processor_id();",
            "\tif (likely(!per_cpu(tracing_cpu, cpu)))",
            "\t\treturn 0;",
            "",
            "\tlocal_save_flags(*flags);",
            "\t/*",
            "\t * Slight chance to get a false positive on tracing_cpu,",
            "\t * although I'm starting to think there isn't a chance.",
            "\t * Leave this for now just to be paranoid.",
            "\t */",
            "\tif (!irqs_disabled_flags(*flags) && !preempt_count())",
            "\t\treturn 0;",
            "",
            "\t*data = per_cpu_ptr(tr->array_buffer.data, cpu);",
            "\tdisabled = atomic_inc_return(&(*data)->disabled);",
            "",
            "\tif (likely(disabled == 1))",
            "\t\treturn 1;",
            "",
            "\tatomic_dec(&(*data)->disabled);",
            "",
            "\treturn 0;",
            "}",
            "static void",
            "irqsoff_tracer_call(unsigned long ip, unsigned long parent_ip,",
            "\t\t    struct ftrace_ops *op, struct ftrace_regs *fregs)",
            "{",
            "\tstruct trace_array *tr = irqsoff_trace;",
            "\tstruct trace_array_cpu *data;",
            "\tunsigned long flags;",
            "\tunsigned int trace_ctx;",
            "",
            "\tif (!func_prolog_dec(tr, &data, &flags))",
            "\t\treturn;",
            "",
            "\ttrace_ctx = tracing_gen_ctx_flags(flags);",
            "",
            "\ttrace_function(tr, ip, parent_ip, trace_ctx);",
            "",
            "\tatomic_dec(&data->disabled);",
            "}",
            "static int irqsoff_display_graph(struct trace_array *tr, int set)",
            "{",
            "\tint cpu;",
            "",
            "\tif (!(is_graph(tr) ^ set))",
            "\t\treturn 0;",
            "",
            "\tstop_irqsoff_tracer(irqsoff_trace, !set);",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tper_cpu(tracing_cpu, cpu) = 0;",
            "",
            "\ttr->max_latency = 0;",
            "\ttracing_reset_online_cpus(&irqsoff_trace->array_buffer);",
            "",
            "\treturn start_irqsoff_tracer(irqsoff_trace, set);",
            "}",
            "static int irqsoff_graph_entry(struct ftrace_graph_ent *trace,",
            "\t\t\t       struct fgraph_ops *gops,",
            "\t\t\t       struct ftrace_regs *fregs)",
            "{",
            "\tstruct trace_array *tr = irqsoff_trace;",
            "\tstruct trace_array_cpu *data;",
            "\tunsigned long flags;",
            "\tunsigned int trace_ctx;",
            "\tu64 *calltime;",
            "\tint ret;",
            "",
            "\tif (ftrace_graph_ignore_func(gops, trace))",
            "\t\treturn 0;",
            "\t/*",
            "\t * Do not trace a function if it's filtered by set_graph_notrace.",
            "\t * Make the index of ret stack negative to indicate that it should",
            "\t * ignore further functions.  But it needs its own ret stack entry",
            "\t * to recover the original index in order to continue tracing after",
            "\t * returning from the function.",
            "\t */",
            "\tif (ftrace_graph_notrace_addr(trace->func))",
            "\t\treturn 1;",
            "",
            "\tif (!func_prolog_dec(tr, &data, &flags))",
            "\t\treturn 0;",
            "",
            "\tcalltime = fgraph_reserve_data(gops->idx, sizeof(*calltime));",
            "\tif (!calltime)",
            "\t\treturn 0;",
            "",
            "\t*calltime = trace_clock_local();",
            "",
            "\ttrace_ctx = tracing_gen_ctx_flags(flags);",
            "\tret = __trace_graph_entry(tr, trace, trace_ctx);",
            "\tatomic_dec(&data->disabled);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "preempt_trace, irq_trace, irqsoff_display_graph, func_prolog_dec, irqsoff_tracer_call, irqsoff_display_graph, irqsoff_graph_entry",
          "description": "实现抢占/中断关闭状态检测及跟踪点标记逻辑，包含函数用于识别中断禁用状态、管理跟踪数据流及图模式下的事件记录",
          "similarity": 0.5794916152954102
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/trace/trace_irqsoff.c",
          "start_line": 387,
          "end_line": 490,
          "content": [
            "static nokprobe_inline void",
            "start_critical_timing(unsigned long ip, unsigned long parent_ip)",
            "{",
            "\tint cpu;",
            "\tstruct trace_array *tr = irqsoff_trace;",
            "\tstruct trace_array_cpu *data;",
            "",
            "\tif (!tracer_enabled || !tracing_is_enabled())",
            "\t\treturn;",
            "",
            "\tcpu = raw_smp_processor_id();",
            "",
            "\tif (per_cpu(tracing_cpu, cpu))",
            "\t\treturn;",
            "",
            "\tdata = per_cpu_ptr(tr->array_buffer.data, cpu);",
            "",
            "\tif (unlikely(!data) || atomic_read(&data->disabled))",
            "\t\treturn;",
            "",
            "\tatomic_inc(&data->disabled);",
            "",
            "\tdata->critical_sequence = max_sequence;",
            "\tdata->preempt_timestamp = ftrace_now(cpu);",
            "\tdata->critical_start = parent_ip ? : ip;",
            "",
            "\t__trace_function(tr, ip, parent_ip, tracing_gen_ctx());",
            "",
            "\tper_cpu(tracing_cpu, cpu) = 1;",
            "",
            "\tatomic_dec(&data->disabled);",
            "}",
            "static nokprobe_inline void",
            "stop_critical_timing(unsigned long ip, unsigned long parent_ip)",
            "{",
            "\tint cpu;",
            "\tstruct trace_array *tr = irqsoff_trace;",
            "\tstruct trace_array_cpu *data;",
            "\tunsigned int trace_ctx;",
            "",
            "\tcpu = raw_smp_processor_id();",
            "\t/* Always clear the tracing cpu on stopping the trace */",
            "\tif (unlikely(per_cpu(tracing_cpu, cpu)))",
            "\t\tper_cpu(tracing_cpu, cpu) = 0;",
            "\telse",
            "\t\treturn;",
            "",
            "\tif (!tracer_enabled || !tracing_is_enabled())",
            "\t\treturn;",
            "",
            "\tdata = per_cpu_ptr(tr->array_buffer.data, cpu);",
            "",
            "\tif (unlikely(!data) ||",
            "\t    !data->critical_start || atomic_read(&data->disabled))",
            "\t\treturn;",
            "",
            "\tatomic_inc(&data->disabled);",
            "",
            "\ttrace_ctx = tracing_gen_ctx();",
            "\t__trace_function(tr, ip, parent_ip, trace_ctx);",
            "\tcheck_critical_timing(tr, data, parent_ip ? : ip, cpu);",
            "\tdata->critical_start = 0;",
            "\tatomic_dec(&data->disabled);",
            "}",
            "void start_critical_timings(void)",
            "{",
            "\tif (preempt_trace(preempt_count()) || irq_trace())",
            "\t\tstart_critical_timing(CALLER_ADDR0, CALLER_ADDR1);",
            "}",
            "void stop_critical_timings(void)",
            "{",
            "\tif (preempt_trace(preempt_count()) || irq_trace())",
            "\t\tstop_critical_timing(CALLER_ADDR0, CALLER_ADDR1);",
            "}",
            "static int register_irqsoff_function(struct trace_array *tr, int graph, int set)",
            "{",
            "\tint ret;",
            "",
            "\t/* 'set' is set if TRACE_ITER_FUNCTION is about to be set */",
            "\tif (function_enabled || (!set && !(tr->trace_flags & TRACE_ITER_FUNCTION)))",
            "\t\treturn 0;",
            "",
            "\tif (graph)",
            "\t\tret = register_ftrace_graph(&fgraph_ops);",
            "\telse",
            "\t\tret = register_ftrace_function(tr->ops);",
            "",
            "\tif (!ret)",
            "\t\tfunction_enabled = true;",
            "",
            "\treturn ret;",
            "}",
            "static void unregister_irqsoff_function(struct trace_array *tr, int graph)",
            "{",
            "\tif (!function_enabled)",
            "\t\treturn;",
            "",
            "\tif (graph)",
            "\t\tunregister_ftrace_graph(&fgraph_ops);",
            "\telse",
            "\t\tunregister_ftrace_function(tr->ops);",
            "",
            "\tfunction_enabled = false;",
            "}"
          ],
          "function_name": "start_critical_timing, stop_critical_timing, start_critical_timings, stop_critical_timings, register_irqsoff_function, unregister_irqsoff_function",
          "description": "实现中断关闭时间段的起止标记功能，管理跟踪器注册/注销流程，协调FTrace图形跟踪与普通函数跟踪模式",
          "similarity": 0.5598945617675781
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/trace/trace_irqsoff.c",
          "start_line": 625,
          "end_line": 688,
          "content": [
            "void tracer_hardirqs_on(unsigned long a0, unsigned long a1)",
            "{",
            "\tif (!preempt_trace(preempt_count()) && irq_trace())",
            "\t\tstop_critical_timing(a0, a1);",
            "}",
            "void tracer_hardirqs_off(unsigned long a0, unsigned long a1)",
            "{",
            "\tif (!preempt_trace(preempt_count()) && irq_trace())",
            "\t\tstart_critical_timing(a0, a1);",
            "}",
            "static int irqsoff_tracer_init(struct trace_array *tr)",
            "{",
            "\ttrace_type = TRACER_IRQS_OFF;",
            "",
            "\treturn __irqsoff_tracer_init(tr);",
            "}",
            "static void irqsoff_tracer_reset(struct trace_array *tr)",
            "{",
            "\t__irqsoff_tracer_reset(tr);",
            "}",
            "void tracer_preempt_on(unsigned long a0, unsigned long a1)",
            "{",
            "\tif (preempt_trace(preempt_count()) && !irq_trace())",
            "\t\tstop_critical_timing(a0, a1);",
            "}",
            "void tracer_preempt_off(unsigned long a0, unsigned long a1)",
            "{",
            "\tif (preempt_trace(preempt_count()) && !irq_trace())",
            "\t\tstart_critical_timing(a0, a1);",
            "}",
            "static int preemptoff_tracer_init(struct trace_array *tr)",
            "{",
            "\ttrace_type = TRACER_PREEMPT_OFF;",
            "",
            "\treturn __irqsoff_tracer_init(tr);",
            "}",
            "static void preemptoff_tracer_reset(struct trace_array *tr)",
            "{",
            "\t__irqsoff_tracer_reset(tr);",
            "}",
            "static int preemptirqsoff_tracer_init(struct trace_array *tr)",
            "{",
            "\ttrace_type = TRACER_IRQS_OFF | TRACER_PREEMPT_OFF;",
            "",
            "\treturn __irqsoff_tracer_init(tr);",
            "}",
            "static void preemptirqsoff_tracer_reset(struct trace_array *tr)",
            "{",
            "\t__irqsoff_tracer_reset(tr);",
            "}",
            "__init static int init_irqsoff_tracer(void)",
            "{",
            "#ifdef CONFIG_IRQSOFF_TRACER",
            "\tregister_tracer(&irqsoff_tracer);",
            "#endif",
            "#ifdef CONFIG_PREEMPT_TRACER",
            "\tregister_tracer(&preemptoff_tracer);",
            "#endif",
            "#if defined(CONFIG_IRQSOFF_TRACER) && defined(CONFIG_PREEMPT_TRACER)",
            "\tregister_tracer(&preemptirqsoff_tracer);",
            "#endif",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "tracer_hardirqs_on, tracer_hardirqs_off, irqsoff_tracer_init, irqsoff_tracer_reset, tracer_preempt_on, tracer_preempt_off, preemptoff_tracer_init, preemptoff_tracer_reset, preemptirqsoff_tracer_init, preemptirqsoff_tracer_reset, init_irqsoff_tracer",
          "description": "该代码段实现了对硬中断和抢占状态变化的跟踪逻辑，提供三种跟踪模式（仅中断禁用、仅抢占禁用、两者均禁用）。各函数通过判断当前上下文是否处于中断/抢占禁用状态，调用`start_critical_timing`/`stop_critical_timing`记录关键时间点，具体实现依赖未展示的底层函数。代码通过条件编译注册对应跟踪器，但因上下文不完整无法确认全部细节。",
          "similarity": 0.5253167152404785
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/trace/trace_irqsoff.c",
          "start_line": 505,
          "end_line": 608,
          "content": [
            "static int irqsoff_function_set(struct trace_array *tr, u32 mask, int set)",
            "{",
            "\tif (!(mask & TRACE_ITER_FUNCTION))",
            "\t\treturn 0;",
            "",
            "\tif (set)",
            "\t\tregister_irqsoff_function(tr, is_graph(tr), 1);",
            "\telse",
            "\t\tunregister_irqsoff_function(tr, is_graph(tr));",
            "\treturn 1;",
            "}",
            "static int register_irqsoff_function(struct trace_array *tr, int graph, int set)",
            "{",
            "\treturn 0;",
            "}",
            "static void unregister_irqsoff_function(struct trace_array *tr, int graph) { }",
            "static inline int irqsoff_function_set(struct trace_array *tr, u32 mask, int set)",
            "{",
            "\treturn 0;",
            "}",
            "static int irqsoff_flag_changed(struct trace_array *tr, u32 mask, int set)",
            "{",
            "\tstruct tracer *tracer = tr->current_trace;",
            "",
            "\tif (irqsoff_function_set(tr, mask, set))",
            "\t\treturn 0;",
            "",
            "#ifdef CONFIG_FUNCTION_GRAPH_TRACER",
            "\tif (mask & TRACE_ITER_DISPLAY_GRAPH)",
            "\t\treturn irqsoff_display_graph(tr, set);",
            "#endif",
            "",
            "\treturn trace_keep_overwrite(tracer, mask, set);",
            "}",
            "static int start_irqsoff_tracer(struct trace_array *tr, int graph)",
            "{",
            "\tint ret;",
            "",
            "\tret = register_irqsoff_function(tr, graph, 0);",
            "",
            "\tif (!ret && tracing_is_enabled())",
            "\t\ttracer_enabled = 1;",
            "\telse",
            "\t\ttracer_enabled = 0;",
            "",
            "\treturn ret;",
            "}",
            "static void stop_irqsoff_tracer(struct trace_array *tr, int graph)",
            "{",
            "\ttracer_enabled = 0;",
            "",
            "\tunregister_irqsoff_function(tr, graph);",
            "}",
            "static int __irqsoff_tracer_init(struct trace_array *tr)",
            "{",
            "\tif (irqsoff_busy)",
            "\t\treturn -EBUSY;",
            "",
            "\tsave_flags = tr->trace_flags;",
            "",
            "\t/* non overwrite screws up the latency tracers */",
            "\tset_tracer_flag(tr, TRACE_ITER_OVERWRITE, 1);",
            "\tset_tracer_flag(tr, TRACE_ITER_LATENCY_FMT, 1);",
            "\t/* without pause, we will produce garbage if another latency occurs */",
            "\tset_tracer_flag(tr, TRACE_ITER_PAUSE_ON_TRACE, 1);",
            "",
            "\ttr->max_latency = 0;",
            "\tirqsoff_trace = tr;",
            "\t/* make sure that the tracer is visible */",
            "\tsmp_wmb();",
            "",
            "\tftrace_init_array_ops(tr, irqsoff_tracer_call);",
            "",
            "\t/* Only toplevel instance supports graph tracing */",
            "\tif (start_irqsoff_tracer(tr, (tr->flags & TRACE_ARRAY_FL_GLOBAL &&",
            "\t\t\t\t      is_graph(tr))))",
            "\t\tprintk(KERN_ERR \"failed to start irqsoff tracer\\n\");",
            "",
            "\tirqsoff_busy = true;",
            "\treturn 0;",
            "}",
            "static void __irqsoff_tracer_reset(struct trace_array *tr)",
            "{",
            "\tint lat_flag = save_flags & TRACE_ITER_LATENCY_FMT;",
            "\tint overwrite_flag = save_flags & TRACE_ITER_OVERWRITE;",
            "\tint pause_flag = save_flags & TRACE_ITER_PAUSE_ON_TRACE;",
            "",
            "\tstop_irqsoff_tracer(tr, is_graph(tr));",
            "",
            "\tset_tracer_flag(tr, TRACE_ITER_LATENCY_FMT, lat_flag);",
            "\tset_tracer_flag(tr, TRACE_ITER_OVERWRITE, overwrite_flag);",
            "\tset_tracer_flag(tr, TRACE_ITER_PAUSE_ON_TRACE, pause_flag);",
            "\tftrace_reset_array_ops(tr);",
            "",
            "\tirqsoff_busy = false;",
            "}",
            "static void irqsoff_tracer_start(struct trace_array *tr)",
            "{",
            "\ttracer_enabled = 1;",
            "}",
            "static void irqsoff_tracer_stop(struct trace_array *tr)",
            "{",
            "\ttracer_enabled = 0;",
            "}"
          ],
          "function_name": "irqsoff_function_set, register_irqsoff_function, unregister_irqsoff_function, irqsoff_function_set, irqsoff_flag_changed, start_irqsoff_tracer, stop_irqsoff_tracer, __irqsoff_tracer_init, __irqsoff_tracer_reset, irqsoff_tracer_start, irqsoff_tracer_stop",
          "description": "定义跟踪器初始化与重置逻辑，控制跟踪器标志位配置，管理跟踪器启动/停止状态及与FTrace框架的集成",
          "similarity": 0.47904184460639954
        }
      ]
    }
  ]
}