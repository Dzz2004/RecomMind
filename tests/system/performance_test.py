#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGç³»ç»Ÿæ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•æŒ‡æ ‡ï¼š
1. æ£€ç´¢é˜¶æ®µè€—æ—¶
2. é¦–å­—ç”Ÿæˆæ—¶é—´ï¼ˆTime to First Token, TTFTï¼‰
3. æ¨ç†ç”Ÿæˆæ—¶é—´
"""

import os
import sys
import json
import time
import statistics
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass, asdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from simple_rag_workflow import SimpleRAGWorkflow, CodeRAGWorkflow, WorkflowResponse, RetrievedChunk

# ==================== æ•°æ®æ¨¡å‹ ====================

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®æ¨¡å‹"""
    test_id: int
    question: str
    retrieval_time: float  # æ£€ç´¢é˜¶æ®µè€—æ—¶ï¼ˆç§’ï¼‰
    ttft: float  # é¦–å­—ç”Ÿæˆæ—¶é—´ï¼ˆç§’ï¼‰
    generation_time: float  # æ¨ç†ç”Ÿæˆæ—¶é—´ï¼ˆç§’ï¼‰
    total_time: float  # æ€»è€—æ—¶ï¼ˆç§’ï¼‰
    retrieved_chunks_count: int  # æ£€ç´¢åˆ°çš„chunkæ•°é‡
    response_length: int  # å“åº”é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
    success: bool  # æ˜¯å¦æˆåŠŸ
    error_message: Optional[str] = None  # é”™è¯¯ä¿¡æ¯

@dataclass
class TestSummary:
    """æµ‹è¯•æ‘˜è¦"""
    total_tests: int
    successful_tests: int
    failed_tests: int
    avg_retrieval_time: float
    avg_ttft: float
    avg_generation_time: float
    avg_total_time: float
    median_retrieval_time: float
    median_ttft: float
    median_generation_time: float
    median_total_time: float
    min_retrieval_time: float
    min_ttft: float
    min_generation_time: float
    min_total_time: float
    max_retrieval_time: float
    max_ttft: float
    max_generation_time: float
    max_total_time: float

# ==================== æ€§èƒ½æµ‹è¯•ç±» ====================

class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, workflow):
        """
        åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•å™¨
        
        Args:
            workflow: RAGå·¥ä½œæµå®ä¾‹ï¼ˆSimpleRAGWorkflow æˆ– CodeRAGWorkflowï¼‰
        """
        self.workflow = workflow
        self.metrics: List[PerformanceMetrics] = []
        # åˆ¤æ–­å·¥ä½œæµç±»å‹
        self.is_code_rag = isinstance(workflow, CodeRAGWorkflow)
    
    def test_single_query(self, test_id: int, question: str) -> PerformanceMetrics:
        """
        æµ‹è¯•å•ä¸ªæŸ¥è¯¢çš„æ€§èƒ½
        
        Args:
            test_id: æµ‹è¯•ID
            question: æµ‹è¯•é—®é¢˜
            
        Returns:
            æ€§èƒ½æŒ‡æ ‡
        """
        print(f"\n{'='*80}")
        print(f"æµ‹è¯• {test_id}: {question}")
        print(f"{'='*80}")
        
        # åˆå§‹åŒ–æ—¶é—´æˆ³
        start_time = time.time()
        retrieval_start_time = None
        retrieval_end_time = None
        generation_start_time = None
        first_token_time = None
        generation_end_time = None
        
        ttft = None
        generation_time = None
        retrieval_time = None
        total_time = None
        retrieved_chunks_count = 0
        response_length = 0
        success = False
        error_message = None
        
        try:
            # è®°å½•æ£€ç´¢å¼€å§‹æ—¶é—´
            retrieval_start_time = time.time()
            
            # åˆ›å»ºè‡ªå®šä¹‰çš„æµå¼å›è°ƒæ¥æµ‹é‡TTFTå’ŒåŒºåˆ†æ£€ç´¢/ç”Ÿæˆé˜¶æ®µ
            first_token_received = False
            retrieval_end_time = None
            
            def stream_callback(data: Dict[str, Any]) -> None:
                nonlocal first_token_time, first_token_received, retrieval_end_time
                
                # æ£€æµ‹æ£€ç´¢é˜¶æ®µç»“æŸï¼ˆå½“æ”¶åˆ°answer_chunkæˆ–code_description_chunkæ—¶ï¼Œè¯´æ˜æ£€ç´¢å·²å®Œæˆï¼Œå¼€å§‹ç”Ÿæˆï¼‰
                callback_type = data.get("type")
                is_answer_chunk = callback_type in ["answer_chunk", "code_description_chunk"]
                
                if is_answer_chunk:
                    # è®°å½•æ£€ç´¢ç»“æŸæ—¶é—´ï¼ˆç¬¬ä¸€æ¬¡æ”¶åˆ°answer_chunkæ—¶ï¼‰
                    if retrieval_end_time is None:
                        retrieval_end_time = time.time()
                    
                    # è®°å½•ç¬¬ä¸€ä¸ªtokençš„æ—¶é—´
                    if not first_token_received:
                        first_token_received = True
                        first_token_time = time.time()
            
            # æ‰§è¡ŒæŸ¥è¯¢ï¼ˆæ ¹æ®å·¥ä½œæµç±»å‹é€‰æ‹©ä¸åŒçš„æ–¹æ³•ï¼‰
            if self.is_code_rag:
                # ä»£ç æ£€ç´¢ä½¿ç”¨ process_code_query
                response: WorkflowResponse = self.workflow.process_code_query(
                    question,
                    stream_callback=stream_callback
                )
            else:
                # æ–‡æ¡£RAGä½¿ç”¨ process_user_query
                response: WorkflowResponse = self.workflow.process_user_query(
                    question,
                    stream_callback=stream_callback
                )
            
            # å¦‚æœæ£€ç´¢ç»“æŸæ—¶é—´æœªè®°å½•ï¼ˆå¯èƒ½æ²¡æœ‰æµå¼å›è°ƒæˆ–æ£€ç´¢é˜¶æ®µæ²¡æœ‰è§¦å‘å›è°ƒï¼‰ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
            if retrieval_end_time is None:
                # å°è¯•ä»å“åº”ä¸­æ¨æ–­ï¼šå¦‚æœå·²ç»æœ‰å“åº”ï¼Œè¯´æ˜æ£€ç´¢å·²å®Œæˆ
                # è¿™é‡Œæˆ‘ä»¬å‡è®¾æ£€ç´¢åœ¨ç”Ÿæˆä¹‹å‰å®Œæˆï¼Œæ‰€ä»¥ä½¿ç”¨ä¸€ä¸ªä¿å®ˆçš„ä¼°è®¡
                # å®é™…ä¸Šï¼Œæˆ‘ä»¬éœ€è¦åœ¨process_user_queryå†…éƒ¨æ·»åŠ æ—¶é—´æˆ³æ‰èƒ½å‡†ç¡®æµ‹é‡
                # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨æ€»æ—¶é—´çš„ä¸€éƒ¨åˆ†ä½œä¸ºæ£€ç´¢æ—¶é—´
                retrieval_end_time = time.time()
            
            # è®°å½•ç”Ÿæˆç»“æŸæ—¶é—´
            generation_end_time = time.time()
            
            # è®¡ç®—å„é¡¹æŒ‡æ ‡
            retrieval_time = retrieval_end_time - retrieval_start_time
            
            # TTFT: ä»æ£€ç´¢ç»“æŸï¼ˆç”Ÿæˆå¼€å§‹ï¼‰åˆ°ç¬¬ä¸€ä¸ªtokenè¿”å›çš„æ—¶é—´
            # æ³¨æ„ï¼šè¿™é‡ŒTTFTåŒ…æ‹¬å‡†å¤‡ç”Ÿæˆçš„æ—¶é—´ï¼ˆæ„å»ºä¸Šä¸‹æ–‡ã€ç¼–ç ç­‰ï¼‰å’Œæ¨¡å‹ç”Ÿæˆç¬¬ä¸€ä¸ªtokençš„æ—¶é—´
            if first_token_time is not None and retrieval_end_time is not None:
                ttft = first_token_time - retrieval_end_time
            else:
                # å¦‚æœæ²¡æœ‰æ”¶åˆ°ç¬¬ä¸€ä¸ªtokenï¼Œä½¿ç”¨ç”Ÿæˆæ€»æ—¶é—´ä½œä¸ºTTFTï¼ˆä¿å®ˆä¼°è®¡ï¼‰
                ttft = generation_end_time - retrieval_end_time if retrieval_end_time else 0
            
            # æ¨ç†ç”Ÿæˆæ—¶é—´ï¼šä»ç¬¬ä¸€ä¸ªtokenåˆ°ç”Ÿæˆå®Œæˆ
            if first_token_time is not None:
                generation_time = generation_end_time - first_token_time
            else:
                # å¦‚æœæ²¡æœ‰æ”¶åˆ°ç¬¬ä¸€ä¸ªtokenï¼Œä½¿ç”¨ä»æ£€ç´¢ç»“æŸåˆ°ç”Ÿæˆç»“æŸçš„æ—¶é—´
                generation_time = generation_end_time - retrieval_end_time if retrieval_end_time else 0
            
            total_time = generation_end_time - start_time
            
            retrieved_chunks_count = len(response.retrieved_chunks)
            response_length = len(response.llm_response)
            success = True
            
            print(f"\nâœ… æµ‹è¯• {test_id} å®Œæˆ")
            print(f"   æ£€ç´¢è€—æ—¶: {retrieval_time:.3f}ç§’")
            print(f"   é¦–å­—ç”Ÿæˆæ—¶é—´: {ttft:.3f}ç§’")
            print(f"   æ¨ç†ç”Ÿæˆæ—¶é—´: {generation_time:.3f}ç§’")
            print(f"   æ€»è€—æ—¶: {total_time:.3f}ç§’")
            print(f"   æ£€ç´¢åˆ° {retrieved_chunks_count} ä¸ªchunk")
            print(f"   å“åº”é•¿åº¦: {response_length} å­—ç¬¦")
            
        except Exception as e:
            error_message = str(e)
            success = False
            total_time = time.time() - start_time if start_time else 0
            
            print(f"\nâŒ æµ‹è¯• {test_id} å¤±è´¥: {error_message}")
            import traceback
            traceback.print_exc()
        
        # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡å¯¹è±¡
        metrics = PerformanceMetrics(
            test_id=test_id,
            question=question,
            retrieval_time=retrieval_time or 0,
            ttft=ttft or 0,
            generation_time=generation_time or 0,
            total_time=total_time or 0,
            retrieved_chunks_count=retrieved_chunks_count,
            response_length=response_length,
            success=success,
            error_message=error_message
        )
        
        self.metrics.append(metrics)
        return metrics
    
    def generate_summary(self) -> TestSummary:
        """
        ç”Ÿæˆæµ‹è¯•æ‘˜è¦
        
        Returns:
            æµ‹è¯•æ‘˜è¦
        """
        if not self.metrics:
            return TestSummary(
                total_tests=0,
                successful_tests=0,
                failed_tests=0,
                avg_retrieval_time=0,
                avg_ttft=0,
                avg_generation_time=0,
                avg_total_time=0,
                median_retrieval_time=0,
                median_ttft=0,
                median_generation_time=0,
                median_total_time=0,
                min_retrieval_time=0,
                min_ttft=0,
                min_generation_time=0,
                min_total_time=0,
                max_retrieval_time=0,
                max_ttft=0,
                max_generation_time=0,
                max_total_time=0
            )
        
        successful_metrics = [m for m in self.metrics if m.success]
        failed_metrics = [m for m in self.metrics if not m.success]
        
        if not successful_metrics:
            return TestSummary(
                total_tests=len(self.metrics),
                successful_tests=0,
                failed_tests=len(failed_metrics),
                avg_retrieval_time=0,
                avg_ttft=0,
                avg_generation_time=0,
                avg_total_time=0,
                median_retrieval_time=0,
                median_ttft=0,
                median_generation_time=0,
                median_total_time=0,
                min_retrieval_time=0,
                min_ttft=0,
                min_generation_time=0,
                min_total_time=0,
                max_retrieval_time=0,
                max_ttft=0,
                max_generation_time=0,
                max_total_time=0
            )
        
        # æå–å„é¡¹æŒ‡æ ‡
        retrieval_times = [m.retrieval_time for m in successful_metrics]
        ttfts = [m.ttft for m in successful_metrics]
        generation_times = [m.generation_time for m in successful_metrics]
        total_times = [m.total_time for m in successful_metrics]
        
        return TestSummary(
            total_tests=len(self.metrics),
            successful_tests=len(successful_metrics),
            failed_tests=len(failed_metrics),
            avg_retrieval_time=statistics.mean(retrieval_times),
            avg_ttft=statistics.mean(ttfts),
            avg_generation_time=statistics.mean(generation_times),
            avg_total_time=statistics.mean(total_times),
            median_retrieval_time=statistics.median(retrieval_times),
            median_ttft=statistics.median(ttfts),
            median_generation_time=statistics.median(generation_times),
            median_total_time=statistics.median(total_times),
            min_retrieval_time=min(retrieval_times),
            min_ttft=min(ttfts),
            min_generation_time=min(generation_times),
            min_total_time=min(total_times),
            max_retrieval_time=max(retrieval_times),
            max_ttft=max(ttfts),
            max_generation_time=max(generation_times),
            max_total_time=max(total_times)
        )
    
    def save_results(self, output_file: str):
        """
        ä¿å­˜æµ‹è¯•ç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        results = {
            "timestamp": datetime.now().isoformat(),
            "metrics": [asdict(m) for m in self.metrics],
            "summary": asdict(self.generate_summary())
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        summary = self.generate_summary()
        
        print(f"\n{'='*80}")
        print("æµ‹è¯•æ‘˜è¦")
        print(f"{'='*80}")
        print(f"æ€»æµ‹è¯•æ•°: {summary.total_tests}")
        print(f"æˆåŠŸ: {summary.successful_tests}")
        print(f"å¤±è´¥: {summary.failed_tests}")
        print(f"\næ£€ç´¢é˜¶æ®µè€—æ—¶:")
        print(f"  å¹³å‡: {summary.avg_retrieval_time:.3f}ç§’")
        print(f"  ä¸­ä½æ•°: {summary.median_retrieval_time:.3f}ç§’")
        print(f"  æœ€å°: {summary.min_retrieval_time:.3f}ç§’")
        print(f"  æœ€å¤§: {summary.max_retrieval_time:.3f}ç§’")
        print(f"\né¦–å­—ç”Ÿæˆæ—¶é—´ (TTFT):")
        print(f"  å¹³å‡: {summary.avg_ttft:.3f}ç§’")
        print(f"  ä¸­ä½æ•°: {summary.median_ttft:.3f}ç§’")
        print(f"  æœ€å°: {summary.min_ttft:.3f}ç§’")
        print(f"  æœ€å¤§: {summary.max_ttft:.3f}ç§’")
        print(f"\næ¨ç†ç”Ÿæˆæ—¶é—´:")
        print(f"  å¹³å‡: {summary.avg_generation_time:.3f}ç§’")
        print(f"  ä¸­ä½æ•°: {summary.median_generation_time:.3f}ç§’")
        print(f"  æœ€å°: {summary.min_generation_time:.3f}ç§’")
        print(f"  æœ€å¤§: {summary.max_generation_time:.3f}ç§’")
        print(f"\næ€»è€—æ—¶:")
        print(f"  å¹³å‡: {summary.avg_total_time:.3f}ç§’")
        print(f"  ä¸­ä½æ•°: {summary.median_total_time:.3f}ç§’")
        print(f"  æœ€å°: {summary.min_total_time:.3f}ç§’")
        print(f"  æœ€å¤§: {summary.max_total_time:.3f}ç§’")
        print(f"{'='*80}\n")

# ==================== ä¸»å‡½æ•° ====================

def load_test_cases(test_cases_file: str) -> List[Dict[str, Any]]:
    """
    åŠ è½½æµ‹è¯•ç”¨ä¾‹
    
    Args:
        test_cases_file: æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶è·¯å¾„
        
    Returns:
        æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
    """
    test_cases = []
    with open(test_cases_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                test_cases.append(json.loads(line))
    return test_cases

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='RAGç³»ç»Ÿæ€§èƒ½æµ‹è¯•')
    parser.add_argument(
        '--test-cases',
        type=str,
        default=os.path.join(os.path.dirname(__file__), 'test_cases.jsonl'),
        help='æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--output',
        type=str,
        default=os.path.join(os.path.dirname(__file__), 'performance_results.json'),
        help='æµ‹è¯•ç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--limit',
        type=int,
        default=None,
        help='é™åˆ¶æµ‹è¯•ç”¨ä¾‹æ•°é‡ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰'
    )
    parser.add_argument(
        '--llm-path',
        type=str,
        default="../../../models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5",
        help='LLMæ¨¡å‹è·¯å¾„'
    )
    parser.add_argument(
        '--embedding-model-path',
        type=str,
        default="/home/ubuntu/.cache/huggingface/hub/models--BAAI--bge-m3/snapshots/5617a9f61b028005a4858fdac845db406aefb181/",
        help='åµŒå…¥æ¨¡å‹è·¯å¾„'
    )
    parser.add_argument(
        '--db-path',
        type=str,
        default="../../vector_db",
        help='å‘é‡æ•°æ®åº“è·¯å¾„'
    )
    parser.add_argument(
        '--similarity-threshold',
        type=float,
        default=0.0,
        help='ç›¸ä¼¼åº¦é˜ˆå€¼'
    )
    parser.add_argument(
        '--use-quantization',
        type=bool,
        default=True,
        help='æ˜¯å¦ä½¿ç”¨4ä½é‡åŒ–'
    )
    parser.add_argument(
        '--test-type',
        type=str,
        choices=['rag', 'code', 'both'],
        default='rag',
        help='æµ‹è¯•ç±»å‹: rag=æ–‡æ¡£RAG, code=ä»£ç æ£€ç´¢, both=ä¸¤è€…éƒ½æµ‹è¯•'
    )
    parser.add_argument(
        '--chroma-md-path',
        type=str,
        default=os.path.join(project_root, "dzz_retrieval", "chroma_md"),
        help='ä»£ç æ£€ç´¢çš„ChromaDBè·¯å¾„ï¼ˆä»…ç”¨äºä»£ç æ£€ç´¢ï¼‰'
    )
    parser.add_argument(
        '--top-files',
        type=int,
        default=3,
        help='ä»£ç æ£€ç´¢çš„æ–‡ä»¶çº§æ£€ç´¢æ•°é‡ï¼ˆä»…ç”¨äºä»£ç æ£€ç´¢ï¼‰'
    )
    parser.add_argument(
        '--top-chunks',
        type=int,
        default=5,
        help='ä»£ç æ£€ç´¢çš„ä»£ç å—çº§æ£€ç´¢æ•°é‡ï¼ˆä»…ç”¨äºä»£ç æ£€ç´¢ï¼‰'
    )
    
    args = parser.parse_args()
    
    print("="*80)
    print("RAGç³»ç»Ÿæ€§èƒ½æµ‹è¯•")
    print("="*80)
    print(f"æµ‹è¯•ç±»å‹: {args.test_type}")
    print(f"æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶: {args.test_cases}")
    print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    if args.limit:
        print(f"é™åˆ¶æµ‹è¯•æ•°é‡: {args.limit}")
    print("="*80)
    
    # åŠ è½½æµ‹è¯•ç”¨ä¾‹
    print("\nğŸ“‹ åŠ è½½æµ‹è¯•ç”¨ä¾‹...")
    test_cases = load_test_cases(args.test_cases)
    if args.limit:
        test_cases = test_cases[:args.limit]
    print(f"âœ… åŠ è½½äº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    
    # æ ¹æ®æµ‹è¯•ç±»å‹æ‰§è¡Œæµ‹è¯•
    test_types = []
    if args.test_type in ['rag', 'both']:
        test_types.append('rag')
    if args.test_type in ['code', 'both']:
        test_types.append('code')
    
    all_results = {}
    
    for test_type in test_types:
        print(f"\n{'='*80}")
        print(f"ğŸš€ åˆå§‹åŒ–{'æ–‡æ¡£RAG' if test_type == 'rag' else 'ä»£ç æ£€ç´¢'}å·¥ä½œæµ...")
        print(f"{'='*80}")
        
        # åŸºç¡€é…ç½®
        base_config = {
            "llm_path": args.llm_path,
            "embedding_model_path": args.embedding_model_path,
            "db_path": args.db_path,
            "similarity_threshold": args.similarity_threshold,
            "use_quantization": args.use_quantization
        }
        
        try:
            if test_type == 'rag':
                # æ–‡æ¡£RAGå·¥ä½œæµ
                workflow = SimpleRAGWorkflow(**base_config)
                print("âœ… æ–‡æ¡£RAGå·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
            else:
                # ä»£ç æ£€ç´¢å·¥ä½œæµ
                code_config = {
                    **base_config,
                    "chroma_md_path": args.chroma_md_path,
                    "top_files": args.top_files,
                    "top_chunks": args.top_chunks
                }
                workflow = CodeRAGWorkflow(**code_config)
                print("âœ… ä»£ç æ£€ç´¢å·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ {'æ–‡æ¡£RAG' if test_type == 'rag' else 'ä»£ç æ£€ç´¢'}å·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
        
        # åˆ›å»ºæ€§èƒ½æµ‹è¯•å™¨
        tester = PerformanceTester(workflow)
        
        # æ‰§è¡Œæµ‹è¯•
        print(f"\nğŸ§ª å¼€å§‹æ‰§è¡Œ{'æ–‡æ¡£RAG' if test_type == 'rag' else 'ä»£ç æ£€ç´¢'}æ€§èƒ½æµ‹è¯•...")
        start_time = time.time()
        
        for test_case in test_cases:
            test_id = test_case.get('id', 0)
            question = test_case.get('question', '')
            tester.test_single_query(test_id, question)
        
        end_time = time.time()
        total_test_time = end_time - start_time
        
        print(f"\nâœ… {'æ–‡æ¡£RAG' if test_type == 'rag' else 'ä»£ç æ£€ç´¢'}æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {total_test_time:.2f}ç§’")
        
        # æ‰“å°æ‘˜è¦
        tester.print_summary()
        
        # ä¿å­˜ç»“æœ
        output_file = args.output
        if len(test_types) > 1:
            # å¦‚æœæµ‹è¯•å¤šç§ç±»å‹ï¼Œä¸ºæ¯ç§ç±»å‹ç”Ÿæˆå•ç‹¬çš„ç»“æœæ–‡ä»¶
            base_name = os.path.splitext(output_file)[0]
            ext = os.path.splitext(output_file)[1]
            output_file = f"{base_name}_{test_type}{ext}"
        
        tester.save_results(output_file)
        all_results[test_type] = tester
        
        print(f"\nğŸ‰ {'æ–‡æ¡£RAG' if test_type == 'rag' else 'ä»£ç æ£€ç´¢'}æ€§èƒ½æµ‹è¯•å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # å¦‚æœæµ‹è¯•äº†ä¸¤ç§ç±»å‹ï¼Œæ‰“å°å¯¹æ¯”æ‘˜è¦
    if len(all_results) > 1:
        print(f"\n{'='*80}")
        print("ğŸ“Š æ€§èƒ½å¯¹æ¯”æ‘˜è¦")
        print(f"{'='*80}")
        for test_type, tester in all_results.items():
            summary = tester.generate_summary()
            print(f"\n{test_type.upper()} ({'æ–‡æ¡£RAG' if test_type == 'rag' else 'ä»£ç æ£€ç´¢'}):")
            print(f"  å¹³å‡æ£€ç´¢æ—¶é—´: {summary.avg_retrieval_time:.3f}ç§’")
            print(f"  å¹³å‡TTFT: {summary.avg_ttft:.3f}ç§’")
            print(f"  å¹³å‡ç”Ÿæˆæ—¶é—´: {summary.avg_generation_time:.3f}ç§’")
            print(f"  å¹³å‡æ€»æ—¶é—´: {summary.avg_total_time:.3f}ç§’")
        print(f"{'='*80}\n")

if __name__ == "__main__":
    main()

