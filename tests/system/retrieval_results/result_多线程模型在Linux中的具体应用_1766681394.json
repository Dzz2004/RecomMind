{
  "query": "多线程模型在Linux中的具体应用",
  "timestamp": "2025-12-26 00:49:54",
  "retrieved_files": [
    {
      "source_file": "kernel/power/energy_model.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:20:12\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `power\\energy_model.c`\n\n---\n\n# `power/energy_model.c` 技术文档\n\n## 1. 文件概述\n\n`power/energy_model.c` 是 Linux 内核中实现 **能量模型（Energy Model, EM）** 的核心文件，主要用于描述设备（尤其是 CPU）在不同性能状态（Performance State, OPP）下的功耗、频率、性能和能效成本等信息。该模型为 **能耗感知调度器（Energy Aware Scheduling, EAS）** 提供关键数据支持，以实现更优的任务调度和能效管理。\n\n该文件由 Arm Ltd. 开发并维护，支持动态注册/更新设备的性能域（Performance Domain），并通过 debugfs 提供调试接口（在 `CONFIG_DEBUG_FS` 启用时）。\n\n---\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct em_perf_domain`：表示一个性能域，包含多个性能状态。\n- `struct em_perf_state`：描述单个性能状态，包含 `frequency`、`power`、`performance`、`cost` 和 `flags` 等字段。\n- `struct em_perf_table`：包含性能状态数组及引用计数（`kref`）和 RCU 释放机制。\n- `struct em_data_callback`：用于从驱动获取功耗/成本数据的回调接口（部分在头文件中定义）。\n\n### 主要函数\n\n| 函数 | 功能说明 |\n|------|--------|\n| `em_table_alloc()` | 为性能域分配新的 EM 表，初始化引用计数 |\n| `em_table_free()` | 安全释放 EM 表（基于 `kref` 和 RCU） |\n| `em_init_performance()` | 为 CPU 设备初始化 `performance` 字段（基于最大频率和 CPU 容量） |\n| `em_compute_costs()` | 计算每个性能状态的 `cost`（功耗/性能比）并标记低效状态 |\n| `em_dev_compute_costs()` | 对外接口，用于运行时更新 EM 表的成本值 |\n| `em_debug_create_pd()` / `em_debug_remove_pd()` | 创建/移除 debugfs 调试节点（仅当 `CONFIG_DEBUG_FS` 启用） |\n| `_is_cpu_device()` | 判断设备是否为 CPU 子系统设备 |\n\n### 全局变量与机制\n\n- `em_pd_mutex`：互斥锁，用于串行化性能域注册和回调执行。\n- `em_update_work`：延迟工作队列，用于异步更新 EM（部分实现在其他文件）。\n- RCU + `kref` 机制：确保 EM 表在多读者场景下的安全释放。\n\n---\n\n## 3. 关键实现\n\n### 3.1 性能与成本计算\n\n- **性能值（`performance`）**：  \n  对于 CPU，通过线性映射计算：\n  ```\n  performance[i] = (arch_scale_cpu_capacity(cpu) * freq[i]) / max_freq\n  ```\n  其中 `arch_scale_cpu_capacity()` 返回 CPU 的最大计算能力（通常由调度器拓扑初始化）。\n\n- **成本值（`cost`）**：  \n  默认使用 `cost = (power * 10) / performance`，提高精度。  \n  若设备标记为 `EM_PERF_DOMAIN_ARTIFICIAL` 且提供 `get_cost` 回调，则使用驱动提供的成本值。\n\n- **低效状态标记**：  \n  从高频到低频遍历，若当前状态的 `cost` 不小于前一状态，则标记为 `EM_PERF_STATE_INEFFICIENT`，供 EAS 调度时避开。\n\n### 3.2 内存管理与生命周期\n\n- EM 表通过 `kref` 管理引用计数，确保在无使用者时才释放。\n- 释放通过 `call_rcu()` 异步执行，避免在 RCU 读侧临界区访问已释放内存。\n- `em_table_free()` 是唯一释放入口，保证线程安全。\n\n### 3.3 Debugfs 调试支持\n\n当启用 `CONFIG_DEBUG_FS` 时：\n- 在 `/sys/kernel/debug/energy_model/` 下为每个设备创建目录。\n- 每个性能状态（`ps:freq`）有独立子目录，包含 `frequency`、`power`、`cost`、`performance`、`inefficient` 等只读文件。\n- CPU 设备额外提供 `cpus` 文件，显示所属 CPU 掩码。\n\n---\n\n## 4. 依赖关系\n\n- **调度子系统**：依赖 `#include <linux/sched/topology.h>` 获取 CPU 拓扑和容量信息。\n- **CPUFreq 子系统**：通过 `#include <linux/cpufreq.h>` 与 OPP（Operating Performance Point）机制交互。\n- **设备模型**：使用 `cpu_subsys` 判断设备类型。\n- **内存管理**：使用 `kzalloc`、`devm_kcalloc` 等分配内存。\n- **同步机制**：依赖 `mutex`、`RCU` 和 `kref` 实现安全并发。\n- **调试支持**：可选依赖 `debugfs`。\n\n---\n\n## 5. 使用场景\n\n1. **EAS（Energy Aware Scheduling）**：  \n   调度器在任务迁移或唤醒时，查询目标 CPU 的 EM 表，选择能效最优的 CPU 和频率。\n\n2. **热插拔与 DVFS**：  \n   在 CPU 热插拔或频率切换时，EM 表提供功耗预测依据。\n\n3. **运行时 EM 更新**：  \n   通过 `em_dev_compute_costs()` 动态更新 EM 表（例如在 thermal 事件后调整 OPP）。\n\n4. **系统调试与验证**：  \n   开发者可通过 debugfs 检查 EM 数据是否符合预期，验证低效状态标记是否正确。\n\n5. **异构多核系统（如 big.LITTLE）**：  \n   不同 CPU 集群拥有独立 EM 表，EAS 利用这些信息实现大小核任务分配优化。",
      "similarity": 0.5953420996665955,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 345,
          "end_line": 456,
          "content": [
            "static int em_create_perf_table(struct device *dev, struct em_perf_domain *pd,",
            "\t\t\t\tstruct em_perf_state *table,",
            "\t\t\t\tstruct em_data_callback *cb,",
            "\t\t\t\tunsigned long flags)",
            "{",
            "\tunsigned long power, freq, prev_freq = 0;",
            "\tint nr_states = pd->nr_perf_states;",
            "\tint i, ret;",
            "",
            "\t/* Build the list of performance states for this performance domain */",
            "\tfor (i = 0, freq = 0; i < nr_states; i++, freq++) {",
            "\t\t/*",
            "\t\t * active_power() is a driver callback which ceils 'freq' to",
            "\t\t * lowest performance state of 'dev' above 'freq' and updates",
            "\t\t * 'power' and 'freq' accordingly.",
            "\t\t */",
            "\t\tret = cb->active_power(dev, &power, &freq);",
            "\t\tif (ret) {",
            "\t\t\tdev_err(dev, \"EM: invalid perf. state: %d\\n\",",
            "\t\t\t\tret);",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * We expect the driver callback to increase the frequency for",
            "\t\t * higher performance states.",
            "\t\t */",
            "\t\tif (freq <= prev_freq) {",
            "\t\t\tdev_err(dev, \"EM: non-increasing freq: %lu\\n\",",
            "\t\t\t\tfreq);",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * The power returned by active_state() is expected to be",
            "\t\t * positive and be in range.",
            "\t\t */",
            "\t\tif (!power || power > EM_MAX_POWER) {",
            "\t\t\tdev_err(dev, \"EM: invalid power: %lu\\n\",",
            "\t\t\t\tpower);",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\ttable[i].power = power;",
            "\t\ttable[i].frequency = prev_freq = freq;",
            "\t}",
            "",
            "\tem_init_performance(dev, pd, table, nr_states);",
            "",
            "\tret = em_compute_costs(dev, table, cb, nr_states, flags);",
            "\tif (ret)",
            "\t\treturn -EINVAL;",
            "",
            "\treturn 0;",
            "}",
            "static int em_create_pd(struct device *dev, int nr_states,",
            "\t\t\tstruct em_data_callback *cb, cpumask_t *cpus,",
            "\t\t\tunsigned long flags)",
            "{",
            "\tstruct em_perf_table __rcu *em_table;",
            "\tstruct em_perf_domain *pd;",
            "\tstruct device *cpu_dev;",
            "\tint cpu, ret, num_cpus;",
            "",
            "\tif (_is_cpu_device(dev)) {",
            "\t\tnum_cpus = cpumask_weight(cpus);",
            "",
            "\t\t/* Prevent max possible energy calculation to not overflow */",
            "\t\tif (num_cpus > EM_MAX_NUM_CPUS) {",
            "\t\t\tdev_err(dev, \"EM: too many CPUs, overflow possible\\n\");",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\tpd = kzalloc(sizeof(*pd) + cpumask_size(), GFP_KERNEL);",
            "\t\tif (!pd)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\t\tcpumask_copy(em_span_cpus(pd), cpus);",
            "\t} else {",
            "\t\tpd = kzalloc(sizeof(*pd), GFP_KERNEL);",
            "\t\tif (!pd)",
            "\t\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\tpd->nr_perf_states = nr_states;",
            "",
            "\tem_table = em_table_alloc(pd);",
            "\tif (!em_table)",
            "\t\tgoto free_pd;",
            "",
            "\tret = em_create_perf_table(dev, pd, em_table->state, cb, flags);",
            "\tif (ret)",
            "\t\tgoto free_pd_table;",
            "",
            "\trcu_assign_pointer(pd->em_table, em_table);",
            "",
            "\tif (_is_cpu_device(dev))",
            "\t\tfor_each_cpu(cpu, cpus) {",
            "\t\t\tcpu_dev = get_cpu_device(cpu);",
            "\t\t\tcpu_dev->em_pd = pd;",
            "\t\t}",
            "",
            "\tdev->em_pd = pd;",
            "",
            "\treturn 0;",
            "",
            "free_pd_table:",
            "\tkfree(em_table);",
            "free_pd:",
            "\tkfree(pd);",
            "\treturn -EINVAL;",
            "}"
          ],
          "function_name": "em_create_perf_table, em_create_pd",
          "description": "创建性能表和性能域结构，验证CPU容量一致性，分配资源并建立设备与性能域的关联",
          "similarity": 0.5607767105102539
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 188,
          "end_line": 290,
          "content": [
            "void em_table_free(struct em_perf_table __rcu *table)",
            "{",
            "\tkref_put(&table->kref, em_release_table_kref);",
            "}",
            "static void em_init_performance(struct device *dev, struct em_perf_domain *pd,",
            "\t\t\t\tstruct em_perf_state *table, int nr_states)",
            "{",
            "\tu64 fmax, max_cap;",
            "\tint i, cpu;",
            "",
            "\t/* This is needed only for CPUs and EAS skip other devices */",
            "\tif (!_is_cpu_device(dev))",
            "\t\treturn;",
            "",
            "\tcpu = cpumask_first(em_span_cpus(pd));",
            "",
            "\t/*",
            "\t * Calculate the performance value for each frequency with",
            "\t * linear relationship. The final CPU capacity might not be ready at",
            "\t * boot time, but the EM will be updated a bit later with correct one.",
            "\t */",
            "\tfmax = (u64) table[nr_states - 1].frequency;",
            "\tmax_cap = (u64) arch_scale_cpu_capacity(cpu);",
            "\tfor (i = 0; i < nr_states; i++)",
            "\t\ttable[i].performance = div64_u64(max_cap * table[i].frequency,",
            "\t\t\t\t\t\t fmax);",
            "}",
            "static int em_compute_costs(struct device *dev, struct em_perf_state *table,",
            "\t\t\t    struct em_data_callback *cb, int nr_states,",
            "\t\t\t    unsigned long flags)",
            "{",
            "\tunsigned long prev_cost = ULONG_MAX;",
            "\tint i, ret;",
            "",
            "\t/* This is needed only for CPUs and EAS skip other devices */",
            "\tif (!_is_cpu_device(dev))",
            "\t\treturn 0;",
            "",
            "\t/* Compute the cost of each performance state. */",
            "\tfor (i = nr_states - 1; i >= 0; i--) {",
            "\t\tunsigned long power_res, cost;",
            "",
            "\t\tif ((flags & EM_PERF_DOMAIN_ARTIFICIAL) && cb->get_cost) {",
            "\t\t\tret = cb->get_cost(dev, table[i].frequency, &cost);",
            "\t\t\tif (ret || !cost || cost > EM_MAX_POWER) {",
            "\t\t\t\tdev_err(dev, \"EM: invalid cost %lu %d\\n\",",
            "\t\t\t\t\tcost, ret);",
            "\t\t\t\treturn -EINVAL;",
            "\t\t\t}",
            "\t\t} else {",
            "\t\t\t/* increase resolution of 'cost' precision */",
            "\t\t\tpower_res = table[i].power * 10;",
            "\t\t\tcost = power_res / table[i].performance;",
            "\t\t}",
            "",
            "\t\ttable[i].cost = cost;",
            "",
            "\t\tif (table[i].cost >= prev_cost) {",
            "\t\t\ttable[i].flags = EM_PERF_STATE_INEFFICIENT;",
            "\t\t\tdev_dbg(dev, \"EM: OPP:%lu is inefficient\\n\",",
            "\t\t\t\ttable[i].frequency);",
            "\t\t} else {",
            "\t\t\tprev_cost = table[i].cost;",
            "\t\t}",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int em_dev_compute_costs(struct device *dev, struct em_perf_state *table,",
            "\t\t\t int nr_states)",
            "{",
            "\treturn em_compute_costs(dev, table, NULL, nr_states, 0);",
            "}",
            "int em_dev_update_perf_domain(struct device *dev,",
            "\t\t\t      struct em_perf_table __rcu *new_table)",
            "{",
            "\tstruct em_perf_table __rcu *old_table;",
            "\tstruct em_perf_domain *pd;",
            "",
            "\tif (!dev)",
            "\t\treturn -EINVAL;",
            "",
            "\t/* Serialize update/unregister or concurrent updates */",
            "\tmutex_lock(&em_pd_mutex);",
            "",
            "\tif (!dev->em_pd) {",
            "\t\tmutex_unlock(&em_pd_mutex);",
            "\t\treturn -EINVAL;",
            "\t}",
            "\tpd = dev->em_pd;",
            "",
            "\tkref_get(&new_table->kref);",
            "",
            "\told_table = pd->em_table;",
            "\trcu_assign_pointer(pd->em_table, new_table);",
            "",
            "\tem_cpufreq_update_efficiencies(dev, new_table->state);",
            "",
            "\tem_table_free(old_table);",
            "",
            "\tmutex_unlock(&em_pd_mutex);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "em_table_free, em_init_performance, em_compute_costs, em_dev_compute_costs, em_dev_update_perf_domain",
          "description": "实现性能状态计算逻辑，初始化性能值、计算功耗成本、标记低效状态，更新性能域表结构",
          "similarity": 0.5586025714874268
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 645,
          "end_line": 772,
          "content": [
            "void em_dev_unregister_perf_domain(struct device *dev)",
            "{",
            "\tif (IS_ERR_OR_NULL(dev) || !dev->em_pd)",
            "\t\treturn;",
            "",
            "\tif (_is_cpu_device(dev))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * The mutex separates all register/unregister requests and protects",
            "\t * from potential clean-up/setup issues in the debugfs directories.",
            "\t * The debugfs directory name is the same as device's name.",
            "\t */",
            "\tmutex_lock(&em_pd_mutex);",
            "\tem_debug_remove_pd(dev);",
            "",
            "\tem_table_free(dev->em_pd->em_table);",
            "",
            "\tkfree(dev->em_pd);",
            "\tdev->em_pd = NULL;",
            "\tmutex_unlock(&em_pd_mutex);",
            "}",
            "static void em_adjust_new_capacity(struct device *dev,",
            "\t\t\t\t   struct em_perf_domain *pd,",
            "\t\t\t\t   u64 max_cap)",
            "{",
            "\tstruct em_perf_table __rcu *em_table;",
            "\tstruct em_perf_state *ps, *new_ps;",
            "\tint ret, ps_size;",
            "",
            "\tem_table = em_table_alloc(pd);",
            "\tif (!em_table) {",
            "\t\tdev_warn(dev, \"EM: allocation failed\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tnew_ps = em_table->state;",
            "",
            "\trcu_read_lock();",
            "\tps = em_perf_state_from_pd(pd);",
            "\t/* Initialize data based on old table */",
            "\tps_size = sizeof(struct em_perf_state) * pd->nr_perf_states;",
            "\tmemcpy(new_ps, ps, ps_size);",
            "",
            "\trcu_read_unlock();",
            "",
            "\tem_init_performance(dev, pd, new_ps, pd->nr_perf_states);",
            "\tret = em_compute_costs(dev, new_ps, NULL, pd->nr_perf_states,",
            "\t\t\t       pd->flags);",
            "\tif (ret) {",
            "\t\tdev_warn(dev, \"EM: compute costs failed\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tret = em_dev_update_perf_domain(dev, em_table);",
            "\tif (ret)",
            "\t\tdev_warn(dev, \"EM: update failed %d\\n\", ret);",
            "",
            "\t/*",
            "\t * This is one-time-update, so give up the ownership in this updater.",
            "\t * The EM framework has incremented the usage counter and from now",
            "\t * will keep the reference (then free the memory when needed).",
            "\t */",
            "\tem_table_free(em_table);",
            "}",
            "static void em_check_capacity_update(void)",
            "{",
            "\tcpumask_var_t cpu_done_mask;",
            "\tstruct em_perf_state *table;",
            "\tstruct em_perf_domain *pd;",
            "\tunsigned long cpu_capacity;",
            "\tint cpu;",
            "",
            "\tif (!zalloc_cpumask_var(&cpu_done_mask, GFP_KERNEL)) {",
            "\t\tpr_warn(\"no free memory\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* Check if CPUs capacity has changed than update EM */",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tstruct cpufreq_policy *policy;",
            "\t\tunsigned long em_max_perf;",
            "\t\tstruct device *dev;",
            "\t\tint nr_states;",
            "",
            "\t\tif (cpumask_test_cpu(cpu, cpu_done_mask))",
            "\t\t\tcontinue;",
            "",
            "\t\tpolicy = cpufreq_cpu_get(cpu);",
            "\t\tif (!policy) {",
            "\t\t\tpr_debug(\"Accessing cpu%d policy failed\\n\", cpu);",
            "\t\t\tschedule_delayed_work(&em_update_work,",
            "\t\t\t\t\t      msecs_to_jiffies(1000));",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tcpufreq_cpu_put(policy);",
            "",
            "\t\tpd = em_cpu_get(cpu);",
            "\t\tif (!pd || em_is_artificial(pd))",
            "\t\t\tcontinue;",
            "",
            "\t\tcpumask_or(cpu_done_mask, cpu_done_mask,",
            "\t\t\t   em_span_cpus(pd));",
            "",
            "\t\tnr_states = pd->nr_perf_states;",
            "\t\tcpu_capacity = arch_scale_cpu_capacity(cpu);",
            "",
            "\t\trcu_read_lock();",
            "\t\ttable = em_perf_state_from_pd(pd);",
            "\t\tem_max_perf = table[pd->nr_perf_states - 1].performance;",
            "\t\trcu_read_unlock();",
            "",
            "\t\t/*",
            "\t\t * Check if the CPU capacity has been adjusted during boot",
            "\t\t * and trigger the update for new performance values.",
            "\t\t */",
            "\t\tif (em_max_perf == cpu_capacity)",
            "\t\t\tcontinue;",
            "",
            "\t\tpr_debug(\"updating cpu%d cpu_cap=%lu old capacity=%lu\\n\",",
            "\t\t\t cpu, cpu_capacity, em_max_perf);",
            "",
            "\t\tdev = get_cpu_device(cpu);",
            "\t\tem_adjust_new_capacity(dev, pd, cpu_capacity);",
            "\t}",
            "",
            "\tfree_cpumask_var(cpu_done_mask);",
            "}"
          ],
          "function_name": "em_dev_unregister_perf_domain, em_adjust_new_capacity, em_check_capacity_update",
          "description": "实现性能域注销逻辑，释放关联资源并清理debugfs目录；通过调整新容量重新初始化性能状态表并更新能耗模型；监控CPU容量变化以动态更新性能状态",
          "similarity": 0.5540305376052856
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 1,
          "end_line": 31,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Energy Model of devices",
            " *",
            " * Copyright (c) 2018-2021, Arm ltd.",
            " * Written by: Quentin Perret, Arm ltd.",
            " * Improvements provided by: Lukasz Luba, Arm ltd.",
            " */",
            "",
            "#define pr_fmt(fmt) \"energy_model: \" fmt",
            "",
            "#include <linux/cpu.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/slab.h>",
            "",
            "/*",
            " * Mutex serializing the registrations of performance domains and letting",
            " * callbacks defined by drivers sleep.",
            " */",
            "static DEFINE_MUTEX(em_pd_mutex);",
            "",
            "static void em_cpufreq_update_efficiencies(struct device *dev,",
            "\t\t\t\t\t   struct em_perf_state *table);",
            "static void em_check_capacity_update(void);",
            "static void em_update_workfn(struct work_struct *work);",
            "static DECLARE_DELAYED_WORK(em_update_work, em_update_workfn);",
            ""
          ],
          "function_name": null,
          "description": "定义能量模型的互斥锁和延迟工作队列，用于串行化性能域注册和回调睡眠，提供基础同步机制",
          "similarity": 0.5096877217292786
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 32,
          "end_line": 136,
          "content": [
            "static bool _is_cpu_device(struct device *dev)",
            "{",
            "\treturn (dev->bus == &cpu_subsys);",
            "}",
            "static void em_debug_create_ps(struct em_perf_domain *em_pd,",
            "\t\t\t       struct em_dbg_info *em_dbg, int i,",
            "\t\t\t       struct dentry *pd)",
            "{",
            "\tstruct em_perf_state *table;",
            "\tunsigned long freq;",
            "\tstruct dentry *d;",
            "\tchar name[24];",
            "",
            "\tem_dbg[i].pd = em_pd;",
            "\tem_dbg[i].ps_id = i;",
            "",
            "\trcu_read_lock();",
            "\ttable = em_perf_state_from_pd(em_pd);",
            "\tfreq = table[i].frequency;",
            "\trcu_read_unlock();",
            "",
            "\tsnprintf(name, sizeof(name), \"ps:%lu\", freq);",
            "",
            "\t/* Create per-ps directory */",
            "\td = debugfs_create_dir(name, pd);",
            "\tdebugfs_create_file(\"frequency\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_frequency_fops);",
            "\tdebugfs_create_file(\"power\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_power_fops);",
            "\tdebugfs_create_file(\"cost\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_cost_fops);",
            "\tdebugfs_create_file(\"performance\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_performance_fops);",
            "\tdebugfs_create_file(\"inefficient\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_inefficiency_fops);",
            "}",
            "static int em_debug_cpus_show(struct seq_file *s, void *unused)",
            "{",
            "\tseq_printf(s, \"%*pbl\\n\", cpumask_pr_args(to_cpumask(s->private)));",
            "",
            "\treturn 0;",
            "}",
            "static int em_debug_flags_show(struct seq_file *s, void *unused)",
            "{",
            "\tstruct em_perf_domain *pd = s->private;",
            "",
            "\tseq_printf(s, \"%#lx\\n\", pd->flags);",
            "",
            "\treturn 0;",
            "}",
            "static void em_debug_create_pd(struct device *dev)",
            "{",
            "\tstruct em_dbg_info *em_dbg;",
            "\tstruct dentry *d;",
            "\tint i;",
            "",
            "\t/* Create the directory of the performance domain */",
            "\td = debugfs_create_dir(dev_name(dev), rootdir);",
            "",
            "\tif (_is_cpu_device(dev))",
            "\t\tdebugfs_create_file(\"cpus\", 0444, d, dev->em_pd->cpus,",
            "\t\t\t\t    &em_debug_cpus_fops);",
            "",
            "\tdebugfs_create_file(\"flags\", 0444, d, dev->em_pd,",
            "\t\t\t    &em_debug_flags_fops);",
            "",
            "\tem_dbg = devm_kcalloc(dev, dev->em_pd->nr_perf_states,",
            "\t\t\t      sizeof(*em_dbg), GFP_KERNEL);",
            "\tif (!em_dbg)",
            "\t\treturn;",
            "",
            "\t/* Create a sub-directory for each performance state */",
            "\tfor (i = 0; i < dev->em_pd->nr_perf_states; i++)",
            "\t\tem_debug_create_ps(dev->em_pd, em_dbg, i, d);",
            "",
            "}",
            "static void em_debug_remove_pd(struct device *dev)",
            "{",
            "\tdebugfs_lookup_and_remove(dev_name(dev), rootdir);",
            "}",
            "static int __init em_debug_init(void)",
            "{",
            "\t/* Create /sys/kernel/debug/energy_model directory */",
            "\trootdir = debugfs_create_dir(\"energy_model\", NULL);",
            "",
            "\treturn 0;",
            "}",
            "static void em_debug_create_pd(struct device *dev) {}",
            "static void em_debug_remove_pd(struct device *dev) {}",
            "static void em_destroy_table_rcu(struct rcu_head *rp)",
            "{",
            "\tstruct em_perf_table __rcu *table;",
            "",
            "\ttable = container_of(rp, struct em_perf_table, rcu);",
            "\tkfree(table);",
            "}",
            "static void em_release_table_kref(struct kref *kref)",
            "{",
            "\tstruct em_perf_table __rcu *table;",
            "",
            "\t/* It was the last owner of this table so we can free */",
            "\ttable = container_of(kref, struct em_perf_table, kref);",
            "",
            "\tcall_rcu(&table->rcu, em_destroy_table_rcu);",
            "}"
          ],
          "function_name": "_is_cpu_device, em_debug_create_ps, em_debug_cpus_show, em_debug_flags_show, em_debug_create_pd, em_debug_remove_pd, em_debug_init, em_debug_create_pd, em_debug_remove_pd, em_destroy_table_rcu, em_release_table_kref",
          "description": "包含调试接口实现，创建/删除性能域调试目录，暴露频率/功率/效率等信息，存在重复函数声明导致上下文不完整",
          "similarity": 0.4997047185897827
        }
      ]
    },
    {
      "source_file": "kernel/rcu/tree.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:46:46\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `rcu\\tree.c`\n\n---\n\n# `rcu/tree.c` 技术文档\n\n## 1. 文件概述\n\n`rcu/tree.c` 是 Linux 内核中 **Read-Copy Update (RCU)** 机制的树形（tree-based）实现核心文件。RCU 是一种高性能的同步原语，用于在读多写少的场景下实现无锁读取与安全更新。该文件实现了基于分层树结构的 RCU 状态管理、宽限期（Grace Period）检测、回调处理、CPU 离线/上线处理以及与调度器、中断、kthread 等子系统的集成。树形结构的设计使得 RCU 能够高效扩展到大规模多核系统（数百甚至上千 CPU）。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct rcu_data`**（每 CPU）  \n  存储每个 CPU 的 RCU 状态，包括待处理的回调链表、宽限期序列号、QS（Quiescent State）状态等。\n  \n- **`struct rcu_state`**（全局）  \n  全局 RCU 状态机，包含宽限期状态（`gp_state`）、序列号（`gp_seq`）、树形节点层级结构（`level[]`）、互斥锁（如 `barrier_mutex`、`exp_mutex`）等。\n\n- **`struct rcu_node`**（层级节点）  \n  构成 RCU 树的内部节点，用于聚合子节点（CPU 或下层 `rcu_node`）的宽限期完成状态，实现分层检测，减少全局同步开销。\n\n- **全局变量**：\n  - `rcu_scheduler_active`：指示调度器是否已激活，影响 RCU 初始化和优化策略。\n  - `rcu_scheduler_fully_active`：指示 RCU 是否已完全初始化（包括 kthread 启动）。\n  - `rcu_num_lvls` / `num_rcu_lvl[]` / `rcu_num_nodes`：描述 RCU 树的层级结构和节点数量。\n  - 多个模块参数（如 `use_softirq`, `rcu_fanout_leaf`, `kthread_prio` 等）用于运行时调优和调试。\n\n### 主要函数（声明/定义）\n\n- **宽限期管理**：\n  - `rcu_report_qs_rnp()`：向上报告某 `rcu_node` 的 QS 状态。\n  - `invoke_rcu_core()`：触发 RCU 核心处理（如宽限期推进或回调执行）。\n\n- **回调处理**：\n  - `rcu_report_exp_rdp()`：报告扩展（expedited）宽限期完成。\n  - `check_cb_ovld_locked()`：检查回调过载情况。\n\n- **CPU 热插拔支持**：\n  - `rcu_boost_kthread_setaffinity()`：调整 RCU boost kthread 的 CPU 亲和性。\n  - `sync_sched_exp_online_cleanup()`：清理 CPU 上线时的扩展同步状态。\n  - `rcu_cleanup_dead_rnp()` / `rcu_init_new_rnp()`：处理 CPU 离线/上线时的 `rcu_node` 结构。\n\n- **辅助函数**：\n  - `rcu_rdp_is_offloaded()`：判断 RCU 回调是否被卸载到专用 kthread（NO_HZ_FULL/NO_CB 场景）。\n  - `rcu_rdp_cpu_online()`：检查对应 CPU 是否在线。\n  - `rcu_init_invoked()`：判断 RCU 初始化是否已启动。\n\n- **导出接口**：\n  - `rcu_get_gp_kthreads_prio()`：供 `rcutorture` 等测试模块获取 RCU kthread 优先级。\n\n## 3. 关键实现\n\n### 树形宽限期检测机制\nRCU 使用分层树结构（`rcu_node` 树）来高效检测宽限期完成：\n- 叶子层对应 CPU，上层节点聚合子节点状态。\n- 每个 `rcu_node` 维护一个位图（`qsmask`），记录哪些子节点尚未报告 QS。\n- 当所有子节点都报告 QS 后，该节点向上层报告，最终根节点完成整个宽限期。\n- 此设计将 O(N) 的全局同步开销降低为 O(log N)，适用于大规模系统。\n\n### 宽限期状态机\n- 全局状态 `rcu_state.gp_state` 控制宽限期生命周期（IDLE → WAITING → DONE 等）。\n- 使用 64 位序列号 `gp_seq` 标识宽限期，通过位移（`RCU_SEQ_CTR_SHIFT`）区分状态。\n- 初始序列号设为 `(0UL - 300UL) << RCU_SEQ_CTR_SHIFT`，确保启动时处于有效状态。\n\n### 调度器集成与启动阶段优化\n- `rcu_scheduler_active` 分三阶段：\n  1. `RCU_SCHEDULER_INACTIVE`：单任务阶段，`synchronize_rcu()` 退化为内存屏障。\n  2. `RCU_SCHEDULER_INIT`：调度器启动但 RCU 未完全初始化。\n  3. `RCU_SCHEDULER_RUNNING`：RCU 完全激活。\n- `rcu_scheduler_fully_active` 确保 RCU 回调和 kthread 在调度器支持多任务后才启用。\n\n### 回调处理策略\n- 支持两种回调执行模式：\n  - **软中断（`RCU_SOFTIRQ`）**：默认模式，通过 `rcu_softirq` 处理。\n  - **专用 kthread（`rcuc`/`rcub`）**：在 `PREEMPT_RT` 或配置 `NO_CB` 时使用，避免软中断延迟。\n- 通过 `use_softirq` 模块参数控制模式选择。\n\n### 调试与调优支持\n- 多个延迟参数（`gp_preinit_delay` 等）用于注入延迟以暴露竞态条件。\n- `rcu_unlock_delay` 在 `CONFIG_RCU_STRICT_GRACE_PERIOD` 下强制延迟 `rcu_read_unlock()`。\n- `dump_tree` 参数可在启动时打印 RCU 树结构用于验证。\n- `rcu_fanout_leaf` 和 `rcu_fanout_exact` 控制树的扇出（fanout）结构。\n\n### 内存与资源管理\n- `rcu_min_cached_objs` 控制每 CPU 缓存的最小对象数（以页为单位）。\n- `rcu_delay_page_cache_fill_msec` 在内存压力下延迟填充 RCU 缓存，避免与页回收冲突。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - 基础内核设施：`<linux/smp.h>`, `<linux/sched.h>`, `<linux/interrupt.h>`, `<linux/percpu.h>` 等。\n  - 时间子系统：`<linux/tick.h>`, `<linux/jiffies.h>`。\n  - 内存管理：`<linux/mm.h>`, `<linux/slab.h>`, `<linux/vmalloc.h>`。\n  - 调试与追踪：`<linux/lockdep.h>`, `<linux/ftrace.h>`, `<linux/kasan.h>`。\n  - RCU 内部头文件：`\"tree.h\"`, `\"rcu.h\"`。\n\n- **模块依赖**：\n  - 与调度器深度集成（`rcu_scheduler_active` 状态依赖 `sched/`）。\n  - 依赖中断子系统处理 QS 检测（如 tick 中断）。\n  - 与 CPU 热插拔机制协同（`cpuhp` 框架）。\n  - 在 `PREEMPT_RT` 下依赖实时调度特性。\n  - 与内存回收（shrinker）交互以管理缓存。\n\n## 5. 使用场景\n\n- **内核同步原语**：为 `synchronize_rcu()`, `call_rcu()` 等 API 提供底层实现。\n- **大规模多核系统**：通过树形结构支持数百至数千 CPU 的高效宽限期检测。\n- **实时系统**：通过 `rcuc` kthread 和优先级控制（`kthread_prio`）满足实时性要求。\n- **CPU 热插拔**：动态调整 RCU 树结构以适应 CPU 在线/离线。\n- **内存压力场景**：与页回收协同，避免 RCU 缓存加剧内存紧张。\n- **内核调试与测试**：\n  - `rcutorture` 模块利用此文件接口进行压力测试。\n  - 通过延迟参数和 `dump_tree` 辅助调试竞态和结构问题。\n- **低延迟场景**：在 `NO_HZ_FULL` 或 `NO_CB` 配置下，将 RCU 回调卸载到专用 CPU，减少主 CPU 干扰。",
      "similarity": 0.5788976550102234,
      "chunks": [
        {
          "chunk_id": 14,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 2523,
          "end_line": 2628,
          "content": [
            "static void rcu_cpu_kthread_park(unsigned int cpu)",
            "{",
            "\tper_cpu(rcu_data.rcu_cpu_kthread_status, cpu) = RCU_KTHREAD_OFFCPU;",
            "}",
            "static int rcu_cpu_kthread_should_run(unsigned int cpu)",
            "{",
            "\treturn __this_cpu_read(rcu_data.rcu_cpu_has_work);",
            "}",
            "static void rcu_cpu_kthread(unsigned int cpu)",
            "{",
            "\tunsigned int *statusp = this_cpu_ptr(&rcu_data.rcu_cpu_kthread_status);",
            "\tchar work, *workp = this_cpu_ptr(&rcu_data.rcu_cpu_has_work);",
            "\tunsigned long *j = this_cpu_ptr(&rcu_data.rcuc_activity);",
            "\tint spincnt;",
            "",
            "\ttrace_rcu_utilization(TPS(\"Start CPU kthread@rcu_run\"));",
            "\tfor (spincnt = 0; spincnt < 10; spincnt++) {",
            "\t\tWRITE_ONCE(*j, jiffies);",
            "\t\tlocal_bh_disable();",
            "\t\t*statusp = RCU_KTHREAD_RUNNING;",
            "\t\tlocal_irq_disable();",
            "\t\twork = *workp;",
            "\t\tWRITE_ONCE(*workp, 0);",
            "\t\tlocal_irq_enable();",
            "\t\tif (work)",
            "\t\t\trcu_core();",
            "\t\tlocal_bh_enable();",
            "\t\tif (!READ_ONCE(*workp)) {",
            "\t\t\ttrace_rcu_utilization(TPS(\"End CPU kthread@rcu_wait\"));",
            "\t\t\t*statusp = RCU_KTHREAD_WAITING;",
            "\t\t\treturn;",
            "\t\t}",
            "\t}",
            "\t*statusp = RCU_KTHREAD_YIELDING;",
            "\ttrace_rcu_utilization(TPS(\"Start CPU kthread@rcu_yield\"));",
            "\tschedule_timeout_idle(2);",
            "\ttrace_rcu_utilization(TPS(\"End CPU kthread@rcu_yield\"));",
            "\t*statusp = RCU_KTHREAD_WAITING;",
            "\tWRITE_ONCE(*j, jiffies);",
            "}",
            "static int __init rcu_spawn_core_kthreads(void)",
            "{",
            "\tint cpu;",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tper_cpu(rcu_data.rcu_cpu_has_work, cpu) = 0;",
            "\tif (use_softirq)",
            "\t\treturn 0;",
            "\tWARN_ONCE(smpboot_register_percpu_thread(&rcu_cpu_thread_spec),",
            "\t\t  \"%s: Could not start rcuc kthread, OOM is now expected behavior\\n\", __func__);",
            "\treturn 0;",
            "}",
            "static void rcutree_enqueue(struct rcu_data *rdp, struct rcu_head *head, rcu_callback_t func)",
            "{",
            "\trcu_segcblist_enqueue(&rdp->cblist, head);",
            "\tif (__is_kvfree_rcu_offset((unsigned long)func))",
            "\t\ttrace_rcu_kvfree_callback(rcu_state.name, head,",
            "\t\t\t\t\t (unsigned long)func,",
            "\t\t\t\t\t rcu_segcblist_n_cbs(&rdp->cblist));",
            "\telse",
            "\t\ttrace_rcu_callback(rcu_state.name, head,",
            "\t\t\t\t   rcu_segcblist_n_cbs(&rdp->cblist));",
            "\ttrace_rcu_segcb_stats(&rdp->cblist, TPS(\"SegCBQueued\"));",
            "}",
            "static void call_rcu_core(struct rcu_data *rdp, struct rcu_head *head,",
            "\t\t\t  rcu_callback_t func, unsigned long flags)",
            "{",
            "\trcutree_enqueue(rdp, head, func);",
            "\t/*",
            "\t * If called from an extended quiescent state, invoke the RCU",
            "\t * core in order to force a re-evaluation of RCU's idleness.",
            "\t */",
            "\tif (!rcu_is_watching())",
            "\t\tinvoke_rcu_core();",
            "",
            "\t/* If interrupts were disabled or CPU offline, don't invoke RCU core. */",
            "\tif (irqs_disabled_flags(flags) || cpu_is_offline(smp_processor_id()))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Force the grace period if too many callbacks or too long waiting.",
            "\t * Enforce hysteresis, and don't invoke rcu_force_quiescent_state()",
            "\t * if some other CPU has recently done so.  Also, don't bother",
            "\t * invoking rcu_force_quiescent_state() if the newly enqueued callback",
            "\t * is the only one waiting for a grace period to complete.",
            "\t */",
            "\tif (unlikely(rcu_segcblist_n_cbs(&rdp->cblist) >",
            "\t\t     rdp->qlen_last_fqs_check + qhimark)) {",
            "",
            "\t\t/* Are we ignoring a completed grace period? */",
            "\t\tnote_gp_changes(rdp);",
            "",
            "\t\t/* Start a new grace period if one not already started. */",
            "\t\tif (!rcu_gp_in_progress()) {",
            "\t\t\trcu_accelerate_cbs_unlocked(rdp->mynode, rdp);",
            "\t\t} else {",
            "\t\t\t/* Give the grace period a kick. */",
            "\t\t\trdp->blimit = DEFAULT_MAX_RCU_BLIMIT;",
            "\t\t\tif (READ_ONCE(rcu_state.n_force_qs) == rdp->n_force_qs_snap &&",
            "\t\t\t    rcu_segcblist_first_pend_cb(&rdp->cblist) != head)",
            "\t\t\t\trcu_force_quiescent_state();",
            "\t\t\trdp->n_force_qs_snap = READ_ONCE(rcu_state.n_force_qs);",
            "\t\t\trdp->qlen_last_fqs_check = rcu_segcblist_n_cbs(&rdp->cblist);",
            "\t\t}",
            "\t}",
            "}"
          ],
          "function_name": "rcu_cpu_kthread_park, rcu_cpu_kthread_should_run, rcu_cpu_kthread, rcu_spawn_core_kthreads, rcutree_enqueue, call_rcu_core",
          "description": "实现RCU k线程管理与回调分发基础设施，包含线程启动、回调入队及触发条件判断逻辑，提供跨CPU的异步处理能力",
          "similarity": 0.5782358050346375
        },
        {
          "chunk_id": 27,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 4895,
          "end_line": 5082,
          "content": [
            "static void __init rcu_init_one(void)",
            "{",
            "\tstatic const char * const buf[] = RCU_NODE_NAME_INIT;",
            "\tstatic const char * const fqs[] = RCU_FQS_NAME_INIT;",
            "\tstatic struct lock_class_key rcu_node_class[RCU_NUM_LVLS];",
            "\tstatic struct lock_class_key rcu_fqs_class[RCU_NUM_LVLS];",
            "",
            "\tint levelspread[RCU_NUM_LVLS];\t\t/* kids/node in each level. */",
            "\tint cpustride = 1;",
            "\tint i;",
            "\tint j;",
            "\tstruct rcu_node *rnp;",
            "",
            "\tBUILD_BUG_ON(RCU_NUM_LVLS > ARRAY_SIZE(buf));  /* Fix buf[] init! */",
            "",
            "\t/* Silence gcc 4.8 false positive about array index out of range. */",
            "\tif (rcu_num_lvls <= 0 || rcu_num_lvls > RCU_NUM_LVLS)",
            "\t\tpanic(\"rcu_init_one: rcu_num_lvls out of range\");",
            "",
            "\t/* Initialize the level-tracking arrays. */",
            "",
            "\tfor (i = 1; i < rcu_num_lvls; i++)",
            "\t\trcu_state.level[i] =",
            "\t\t\trcu_state.level[i - 1] + num_rcu_lvl[i - 1];",
            "\trcu_init_levelspread(levelspread, num_rcu_lvl);",
            "",
            "\t/* Initialize the elements themselves, starting from the leaves. */",
            "",
            "\tfor (i = rcu_num_lvls - 1; i >= 0; i--) {",
            "\t\tcpustride *= levelspread[i];",
            "\t\trnp = rcu_state.level[i];",
            "\t\tfor (j = 0; j < num_rcu_lvl[i]; j++, rnp++) {",
            "\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rnp, lock));",
            "\t\t\tlockdep_set_class_and_name(&ACCESS_PRIVATE(rnp, lock),",
            "\t\t\t\t\t\t   &rcu_node_class[i], buf[i]);",
            "\t\t\traw_spin_lock_init(&rnp->fqslock);",
            "\t\t\tlockdep_set_class_and_name(&rnp->fqslock,",
            "\t\t\t\t\t\t   &rcu_fqs_class[i], fqs[i]);",
            "\t\t\trnp->gp_seq = rcu_state.gp_seq;",
            "\t\t\trnp->gp_seq_needed = rcu_state.gp_seq;",
            "\t\t\trnp->completedqs = rcu_state.gp_seq;",
            "\t\t\trnp->qsmask = 0;",
            "\t\t\trnp->qsmaskinit = 0;",
            "\t\t\trnp->grplo = j * cpustride;",
            "\t\t\trnp->grphi = (j + 1) * cpustride - 1;",
            "\t\t\tif (rnp->grphi >= nr_cpu_ids)",
            "\t\t\t\trnp->grphi = nr_cpu_ids - 1;",
            "\t\t\tif (i == 0) {",
            "\t\t\t\trnp->grpnum = 0;",
            "\t\t\t\trnp->grpmask = 0;",
            "\t\t\t\trnp->parent = NULL;",
            "\t\t\t} else {",
            "\t\t\t\trnp->grpnum = j % levelspread[i - 1];",
            "\t\t\t\trnp->grpmask = BIT(rnp->grpnum);",
            "\t\t\t\trnp->parent = rcu_state.level[i - 1] +",
            "\t\t\t\t\t      j / levelspread[i - 1];",
            "\t\t\t}",
            "\t\t\trnp->level = i;",
            "\t\t\tINIT_LIST_HEAD(&rnp->blkd_tasks);",
            "\t\t\trcu_init_one_nocb(rnp);",
            "\t\t\tinit_waitqueue_head(&rnp->exp_wq[0]);",
            "\t\t\tinit_waitqueue_head(&rnp->exp_wq[1]);",
            "\t\t\tinit_waitqueue_head(&rnp->exp_wq[2]);",
            "\t\t\tinit_waitqueue_head(&rnp->exp_wq[3]);",
            "\t\t\tspin_lock_init(&rnp->exp_lock);",
            "\t\t\tmutex_init(&rnp->boost_kthread_mutex);",
            "\t\t\traw_spin_lock_init(&rnp->exp_poll_lock);",
            "\t\t\trnp->exp_seq_poll_rq = RCU_GET_STATE_COMPLETED;",
            "\t\t\tINIT_WORK(&rnp->exp_poll_wq, sync_rcu_do_polled_gp);",
            "\t\t}",
            "\t}",
            "",
            "\tinit_swait_queue_head(&rcu_state.gp_wq);",
            "\tinit_swait_queue_head(&rcu_state.expedited_wq);",
            "\trnp = rcu_first_leaf_node();",
            "\tfor_each_possible_cpu(i) {",
            "\t\twhile (i > rnp->grphi)",
            "\t\t\trnp++;",
            "\t\tper_cpu_ptr(&rcu_data, i)->mynode = rnp;",
            "\t\trcu_boot_init_percpu_data(i);",
            "\t}",
            "}",
            "static void __init sanitize_kthread_prio(void)",
            "{",
            "\tint kthread_prio_in = kthread_prio;",
            "",
            "\tif (IS_ENABLED(CONFIG_RCU_BOOST) && kthread_prio < 2",
            "\t    && IS_BUILTIN(CONFIG_RCU_TORTURE_TEST))",
            "\t\tkthread_prio = 2;",
            "\telse if (IS_ENABLED(CONFIG_RCU_BOOST) && kthread_prio < 1)",
            "\t\tkthread_prio = 1;",
            "\telse if (kthread_prio < 0)",
            "\t\tkthread_prio = 0;",
            "\telse if (kthread_prio > 99)",
            "\t\tkthread_prio = 99;",
            "",
            "\tif (kthread_prio != kthread_prio_in)",
            "\t\tpr_alert(\"%s: Limited prio to %d from %d\\n\",",
            "\t\t\t __func__, kthread_prio, kthread_prio_in);",
            "}",
            "void rcu_init_geometry(void)",
            "{",
            "\tulong d;",
            "\tint i;",
            "\tstatic unsigned long old_nr_cpu_ids;",
            "\tint rcu_capacity[RCU_NUM_LVLS];",
            "\tstatic bool initialized;",
            "",
            "\tif (initialized) {",
            "\t\t/*",
            "\t\t * Warn if setup_nr_cpu_ids() had not yet been invoked,",
            "\t\t * unless nr_cpus_ids == NR_CPUS, in which case who cares?",
            "\t\t */",
            "\t\tWARN_ON_ONCE(old_nr_cpu_ids != nr_cpu_ids);",
            "\t\treturn;",
            "\t}",
            "",
            "\told_nr_cpu_ids = nr_cpu_ids;",
            "\tinitialized = true;",
            "",
            "\t/*",
            "\t * Initialize any unspecified boot parameters.",
            "\t * The default values of jiffies_till_first_fqs and",
            "\t * jiffies_till_next_fqs are set to the RCU_JIFFIES_TILL_FORCE_QS",
            "\t * value, which is a function of HZ, then adding one for each",
            "\t * RCU_JIFFIES_FQS_DIV CPUs that might be on the system.",
            "\t */",
            "\td = RCU_JIFFIES_TILL_FORCE_QS + nr_cpu_ids / RCU_JIFFIES_FQS_DIV;",
            "\tif (jiffies_till_first_fqs == ULONG_MAX)",
            "\t\tjiffies_till_first_fqs = d;",
            "\tif (jiffies_till_next_fqs == ULONG_MAX)",
            "\t\tjiffies_till_next_fqs = d;",
            "\tadjust_jiffies_till_sched_qs();",
            "",
            "\t/* If the compile-time values are accurate, just leave. */",
            "\tif (rcu_fanout_leaf == RCU_FANOUT_LEAF &&",
            "\t    nr_cpu_ids == NR_CPUS)",
            "\t\treturn;",
            "\tpr_info(\"Adjusting geometry for rcu_fanout_leaf=%d, nr_cpu_ids=%u\\n\",",
            "\t\trcu_fanout_leaf, nr_cpu_ids);",
            "",
            "\t/*",
            "\t * The boot-time rcu_fanout_leaf parameter must be at least two",
            "\t * and cannot exceed the number of bits in the rcu_node masks.",
            "\t * Complain and fall back to the compile-time values if this",
            "\t * limit is exceeded.",
            "\t */",
            "\tif (rcu_fanout_leaf < 2 ||",
            "\t    rcu_fanout_leaf > sizeof(unsigned long) * 8) {",
            "\t\trcu_fanout_leaf = RCU_FANOUT_LEAF;",
            "\t\tWARN_ON(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/*",
            "\t * Compute number of nodes that can be handled an rcu_node tree",
            "\t * with the given number of levels.",
            "\t */",
            "\trcu_capacity[0] = rcu_fanout_leaf;",
            "\tfor (i = 1; i < RCU_NUM_LVLS; i++)",
            "\t\trcu_capacity[i] = rcu_capacity[i - 1] * RCU_FANOUT;",
            "",
            "\t/*",
            "\t * The tree must be able to accommodate the configured number of CPUs.",
            "\t * If this limit is exceeded, fall back to the compile-time values.",
            "\t */",
            "\tif (nr_cpu_ids > rcu_capacity[RCU_NUM_LVLS - 1]) {",
            "\t\trcu_fanout_leaf = RCU_FANOUT_LEAF;",
            "\t\tWARN_ON(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* Calculate the number of levels in the tree. */",
            "\tfor (i = 0; nr_cpu_ids > rcu_capacity[i]; i++) {",
            "\t}",
            "\trcu_num_lvls = i + 1;",
            "",
            "\t/* Calculate the number of rcu_nodes at each level of the tree. */",
            "\tfor (i = 0; i < rcu_num_lvls; i++) {",
            "\t\tint cap = rcu_capacity[(rcu_num_lvls - 1) - i];",
            "\t\tnum_rcu_lvl[i] = DIV_ROUND_UP(nr_cpu_ids, cap);",
            "\t}",
            "",
            "\t/* Calculate the total number of rcu_node structures. */",
            "\trcu_num_nodes = 0;",
            "\tfor (i = 0; i < rcu_num_lvls; i++)",
            "\t\trcu_num_nodes += num_rcu_lvl[i];",
            "}"
          ],
          "function_name": "rcu_init_one, sanitize_kthread_prio, rcu_init_geometry",
          "description": "构建多级RCU节点树结构，初始化各层级的锁类和节点属性，动态调整RCU树的几何形态以适配当前CPU数量和层级分布需求。",
          "similarity": 0.5479567050933838
        },
        {
          "chunk_id": 24,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 4444,
          "end_line": 4559,
          "content": [
            "static void __init",
            "rcu_boot_init_percpu_data(int cpu)",
            "{",
            "\tstruct context_tracking *ct = this_cpu_ptr(&context_tracking);",
            "\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);",
            "",
            "\t/* Set up local state, ensuring consistent view of global state. */",
            "\trdp->grpmask = leaf_node_cpu_bit(rdp->mynode, cpu);",
            "\tINIT_WORK(&rdp->strict_work, strict_work_handler);",
            "\tWARN_ON_ONCE(ct->dynticks_nesting != 1);",
            "\tWARN_ON_ONCE(rcu_dynticks_in_eqs(rcu_dynticks_snap(cpu)));",
            "\trdp->barrier_seq_snap = rcu_state.barrier_sequence;",
            "\trdp->rcu_ofl_gp_seq = rcu_state.gp_seq;",
            "\trdp->rcu_ofl_gp_flags = RCU_GP_CLEANED;",
            "\trdp->rcu_onl_gp_seq = rcu_state.gp_seq;",
            "\trdp->rcu_onl_gp_flags = RCU_GP_CLEANED;",
            "\trdp->last_sched_clock = jiffies;",
            "\trdp->cpu = cpu;",
            "\trcu_boot_init_nocb_percpu_data(rdp);",
            "}",
            "int rcutree_prepare_cpu(unsigned int cpu)",
            "{",
            "\tunsigned long flags;",
            "\tstruct context_tracking *ct = per_cpu_ptr(&context_tracking, cpu);",
            "\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);",
            "\tstruct rcu_node *rnp = rcu_get_root();",
            "",
            "\t/* Set up local state, ensuring consistent view of global state. */",
            "\traw_spin_lock_irqsave_rcu_node(rnp, flags);",
            "\trdp->qlen_last_fqs_check = 0;",
            "\trdp->n_force_qs_snap = READ_ONCE(rcu_state.n_force_qs);",
            "\trdp->blimit = blimit;",
            "\tct->dynticks_nesting = 1;\t/* CPU not up, no tearing. */",
            "\traw_spin_unlock_rcu_node(rnp);\t\t/* irqs remain disabled. */",
            "",
            "\t/*",
            "\t * Only non-NOCB CPUs that didn't have early-boot callbacks need to be",
            "\t * (re-)initialized.",
            "\t */",
            "\tif (!rcu_segcblist_is_enabled(&rdp->cblist))",
            "\t\trcu_segcblist_init(&rdp->cblist);  /* Re-enable callbacks. */",
            "",
            "\t/*",
            "\t * Add CPU to leaf rcu_node pending-online bitmask.  Any needed",
            "\t * propagation up the rcu_node tree will happen at the beginning",
            "\t * of the next grace period.",
            "\t */",
            "\trnp = rdp->mynode;",
            "\traw_spin_lock_rcu_node(rnp);\t\t/* irqs already disabled. */",
            "\trdp->gp_seq = READ_ONCE(rnp->gp_seq);",
            "\trdp->gp_seq_needed = rdp->gp_seq;",
            "\trdp->cpu_no_qs.b.norm = true;",
            "\trdp->core_needs_qs = false;",
            "\trdp->rcu_iw_pending = false;",
            "\trdp->rcu_iw = IRQ_WORK_INIT_HARD(rcu_iw_handler);",
            "\trdp->rcu_iw_gp_seq = rdp->gp_seq - 1;",
            "\ttrace_rcu_grace_period(rcu_state.name, rdp->gp_seq, TPS(\"cpuonl\"));",
            "\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "",
            "\trcu_preempt_deferred_qs_init(rdp);",
            "\trcu_spawn_one_boost_kthread(rnp);",
            "\trcu_spawn_cpu_nocb_kthread(cpu);",
            "\tWRITE_ONCE(rcu_state.n_online_cpus, rcu_state.n_online_cpus + 1);",
            "",
            "\treturn 0;",
            "}",
            "static void rcutree_affinity_setting(unsigned int cpu, int outgoing)",
            "{",
            "\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);",
            "",
            "\trcu_boost_kthread_setaffinity(rdp->mynode, outgoing);",
            "}",
            "bool rcu_cpu_beenfullyonline(int cpu)",
            "{",
            "\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);",
            "",
            "\treturn smp_load_acquire(&rdp->beenonline);",
            "}",
            "int rcutree_online_cpu(unsigned int cpu)",
            "{",
            "\tunsigned long flags;",
            "\tstruct rcu_data *rdp;",
            "\tstruct rcu_node *rnp;",
            "",
            "\trdp = per_cpu_ptr(&rcu_data, cpu);",
            "\trnp = rdp->mynode;",
            "\traw_spin_lock_irqsave_rcu_node(rnp, flags);",
            "\trnp->ffmask |= rdp->grpmask;",
            "\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "\tif (rcu_scheduler_active == RCU_SCHEDULER_INACTIVE)",
            "\t\treturn 0; /* Too early in boot for scheduler work. */",
            "\tsync_sched_exp_online_cleanup(cpu);",
            "\trcutree_affinity_setting(cpu, -1);",
            "",
            "\t// Stop-machine done, so allow nohz_full to disable tick.",
            "\ttick_dep_clear(TICK_DEP_BIT_RCU);",
            "\treturn 0;",
            "}",
            "int rcutree_offline_cpu(unsigned int cpu)",
            "{",
            "\tunsigned long flags;",
            "\tstruct rcu_data *rdp;",
            "\tstruct rcu_node *rnp;",
            "",
            "\trdp = per_cpu_ptr(&rcu_data, cpu);",
            "\trnp = rdp->mynode;",
            "\traw_spin_lock_irqsave_rcu_node(rnp, flags);",
            "\trnp->ffmask &= ~rdp->grpmask;",
            "\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "",
            "\trcutree_affinity_setting(cpu, cpu);",
            "",
            "\t// nohz_full CPUs need the tick for stop-machine to work quickly",
            "\ttick_dep_set(TICK_DEP_BIT_RCU);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "rcu_boot_init_percpu_data, rcutree_prepare_cpu, rcutree_affinity_setting, rcu_cpu_beenfullyonline, rcutree_online_cpu, rcutree_offline_cpu",
          "description": "初始化每个CPU的RCU私有数据结构，处理CPU上线/下线时的RCU状态同步，配置中断亲和性，更新全局在线CPU计数器",
          "similarity": 0.5363243818283081
        },
        {
          "chunk_id": 16,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 2977,
          "end_line": 3111,
          "content": [
            "static inline bool",
            "put_cached_bnode(struct kfree_rcu_cpu *krcp,",
            "\tstruct kvfree_rcu_bulk_data *bnode)",
            "{",
            "\t// Check the limit.",
            "\tif (krcp->nr_bkv_objs >= rcu_min_cached_objs)",
            "\t\treturn false;",
            "",
            "\tllist_add((struct llist_node *) bnode, &krcp->bkvcache);",
            "\tWRITE_ONCE(krcp->nr_bkv_objs, krcp->nr_bkv_objs + 1);",
            "\treturn true;",
            "}",
            "static int",
            "drain_page_cache(struct kfree_rcu_cpu *krcp)",
            "{",
            "\tunsigned long flags;",
            "\tstruct llist_node *page_list, *pos, *n;",
            "\tint freed = 0;",
            "",
            "\tif (!rcu_min_cached_objs)",
            "\t\treturn 0;",
            "",
            "\traw_spin_lock_irqsave(&krcp->lock, flags);",
            "\tpage_list = llist_del_all(&krcp->bkvcache);",
            "\tWRITE_ONCE(krcp->nr_bkv_objs, 0);",
            "\traw_spin_unlock_irqrestore(&krcp->lock, flags);",
            "",
            "\tllist_for_each_safe(pos, n, page_list) {",
            "\t\tfree_page((unsigned long)pos);",
            "\t\tfreed++;",
            "\t}",
            "",
            "\treturn freed;",
            "}",
            "static void",
            "kvfree_rcu_bulk(struct kfree_rcu_cpu *krcp,",
            "\tstruct kvfree_rcu_bulk_data *bnode, int idx)",
            "{",
            "\tunsigned long flags;",
            "\tint i;",
            "",
            "\tif (!WARN_ON_ONCE(!poll_state_synchronize_rcu_full(&bnode->gp_snap))) {",
            "\t\tdebug_rcu_bhead_unqueue(bnode);",
            "\t\trcu_lock_acquire(&rcu_callback_map);",
            "\t\tif (idx == 0) { // kmalloc() / kfree().",
            "\t\t\ttrace_rcu_invoke_kfree_bulk_callback(",
            "\t\t\t\trcu_state.name, bnode->nr_records,",
            "\t\t\t\tbnode->records);",
            "",
            "\t\t\tkfree_bulk(bnode->nr_records, bnode->records);",
            "\t\t} else { // vmalloc() / vfree().",
            "\t\t\tfor (i = 0; i < bnode->nr_records; i++) {",
            "\t\t\t\ttrace_rcu_invoke_kvfree_callback(",
            "\t\t\t\t\trcu_state.name, bnode->records[i], 0);",
            "",
            "\t\t\t\tvfree(bnode->records[i]);",
            "\t\t\t}",
            "\t\t}",
            "\t\trcu_lock_release(&rcu_callback_map);",
            "\t}",
            "",
            "\traw_spin_lock_irqsave(&krcp->lock, flags);",
            "\tif (put_cached_bnode(krcp, bnode))",
            "\t\tbnode = NULL;",
            "\traw_spin_unlock_irqrestore(&krcp->lock, flags);",
            "",
            "\tif (bnode)",
            "\t\tfree_page((unsigned long) bnode);",
            "",
            "\tcond_resched_tasks_rcu_qs();",
            "}",
            "static void",
            "kvfree_rcu_list(struct rcu_head *head)",
            "{",
            "\tstruct rcu_head *next;",
            "",
            "\tfor (; head; head = next) {",
            "\t\tvoid *ptr = (void *) head->func;",
            "\t\tunsigned long offset = (void *) head - ptr;",
            "",
            "\t\tnext = head->next;",
            "\t\tdebug_rcu_head_unqueue((struct rcu_head *)ptr);",
            "\t\trcu_lock_acquire(&rcu_callback_map);",
            "\t\ttrace_rcu_invoke_kvfree_callback(rcu_state.name, head, offset);",
            "",
            "\t\tif (!WARN_ON_ONCE(!__is_kvfree_rcu_offset(offset)))",
            "\t\t\tkvfree(ptr);",
            "",
            "\t\trcu_lock_release(&rcu_callback_map);",
            "\t\tcond_resched_tasks_rcu_qs();",
            "\t}",
            "}",
            "static void kfree_rcu_work(struct work_struct *work)",
            "{",
            "\tunsigned long flags;",
            "\tstruct kvfree_rcu_bulk_data *bnode, *n;",
            "\tstruct list_head bulk_head[FREE_N_CHANNELS];",
            "\tstruct rcu_head *head;",
            "\tstruct kfree_rcu_cpu *krcp;",
            "\tstruct kfree_rcu_cpu_work *krwp;",
            "\tstruct rcu_gp_oldstate head_gp_snap;",
            "\tint i;",
            "",
            "\tkrwp = container_of(to_rcu_work(work),",
            "\t\tstruct kfree_rcu_cpu_work, rcu_work);",
            "\tkrcp = krwp->krcp;",
            "",
            "\traw_spin_lock_irqsave(&krcp->lock, flags);",
            "\t// Channels 1 and 2.",
            "\tfor (i = 0; i < FREE_N_CHANNELS; i++)",
            "\t\tlist_replace_init(&krwp->bulk_head_free[i], &bulk_head[i]);",
            "",
            "\t// Channel 3.",
            "\thead = krwp->head_free;",
            "\tkrwp->head_free = NULL;",
            "\thead_gp_snap = krwp->head_free_gp_snap;",
            "\traw_spin_unlock_irqrestore(&krcp->lock, flags);",
            "",
            "\t// Handle the first two channels.",
            "\tfor (i = 0; i < FREE_N_CHANNELS; i++) {",
            "\t\t// Start from the tail page, so a GP is likely passed for it.",
            "\t\tlist_for_each_entry_safe(bnode, n, &bulk_head[i], list)",
            "\t\t\tkvfree_rcu_bulk(krcp, bnode, i);",
            "\t}",
            "",
            "\t/*",
            "\t * This is used when the \"bulk\" path can not be used for the",
            "\t * double-argument of kvfree_rcu().  This happens when the",
            "\t * page-cache is empty, which means that objects are instead",
            "\t * queued on a linked list through their rcu_head structures.",
            "\t * This list is named \"Channel 3\".",
            "\t */",
            "\tif (head && !WARN_ON_ONCE(!poll_state_synchronize_rcu_full(&head_gp_snap)))",
            "\t\tkvfree_rcu_list(head);",
            "}"
          ],
          "function_name": "put_cached_bnode, drain_page_cache, kvfree_rcu_bulk, kvfree_rcu_list, kfree_rcu_work",
          "description": "处理批量内存释放，通过缓存节点管理、页面缓存填充及多通道分类释放机制实现高效内存回收。",
          "similarity": 0.5293964147567749
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 1840,
          "end_line": 1973,
          "content": [
            "static int __noreturn rcu_gp_kthread(void *unused)",
            "{",
            "\trcu_bind_gp_kthread();",
            "\tfor (;;) {",
            "",
            "\t\t/* Handle grace-period start. */",
            "\t\tfor (;;) {",
            "\t\t\ttrace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq,",
            "\t\t\t\t\t       TPS(\"reqwait\"));",
            "\t\t\tWRITE_ONCE(rcu_state.gp_state, RCU_GP_WAIT_GPS);",
            "\t\t\tswait_event_idle_exclusive(rcu_state.gp_wq,",
            "\t\t\t\t\t READ_ONCE(rcu_state.gp_flags) &",
            "\t\t\t\t\t RCU_GP_FLAG_INIT);",
            "\t\t\trcu_gp_torture_wait();",
            "\t\t\tWRITE_ONCE(rcu_state.gp_state, RCU_GP_DONE_GPS);",
            "\t\t\t/* Locking provides needed memory barrier. */",
            "\t\t\tif (rcu_gp_init())",
            "\t\t\t\tbreak;",
            "\t\t\tcond_resched_tasks_rcu_qs();",
            "\t\t\tWRITE_ONCE(rcu_state.gp_activity, jiffies);",
            "\t\t\tWARN_ON(signal_pending(current));",
            "\t\t\ttrace_rcu_grace_period(rcu_state.name, rcu_state.gp_seq,",
            "\t\t\t\t\t       TPS(\"reqwaitsig\"));",
            "\t\t}",
            "",
            "\t\t/* Handle quiescent-state forcing. */",
            "\t\trcu_gp_fqs_loop();",
            "",
            "\t\t/* Handle grace-period end. */",
            "\t\tWRITE_ONCE(rcu_state.gp_state, RCU_GP_CLEANUP);",
            "\t\trcu_gp_cleanup();",
            "\t\tWRITE_ONCE(rcu_state.gp_state, RCU_GP_CLEANED);",
            "\t}",
            "}",
            "static void rcu_report_qs_rsp(unsigned long flags)",
            "\t__releases(rcu_get_root()->lock)",
            "{",
            "\traw_lockdep_assert_held_rcu_node(rcu_get_root());",
            "\tWARN_ON_ONCE(!rcu_gp_in_progress());",
            "\tWRITE_ONCE(rcu_state.gp_flags,",
            "\t\t   READ_ONCE(rcu_state.gp_flags) | RCU_GP_FLAG_FQS);",
            "\traw_spin_unlock_irqrestore_rcu_node(rcu_get_root(), flags);",
            "\trcu_gp_kthread_wake();",
            "}",
            "static void rcu_report_qs_rnp(unsigned long mask, struct rcu_node *rnp,",
            "\t\t\t      unsigned long gps, unsigned long flags)",
            "\t__releases(rnp->lock)",
            "{",
            "\tunsigned long oldmask = 0;",
            "\tstruct rcu_node *rnp_c;",
            "",
            "\traw_lockdep_assert_held_rcu_node(rnp);",
            "",
            "\t/* Walk up the rcu_node hierarchy. */",
            "\tfor (;;) {",
            "\t\tif ((!(rnp->qsmask & mask) && mask) || rnp->gp_seq != gps) {",
            "",
            "\t\t\t/*",
            "\t\t\t * Our bit has already been cleared, or the",
            "\t\t\t * relevant grace period is already over, so done.",
            "\t\t\t */",
            "\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\tWARN_ON_ONCE(oldmask); /* Any child must be all zeroed! */",
            "\t\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp) &&",
            "\t\t\t     rcu_preempt_blocked_readers_cgp(rnp));",
            "\t\tWRITE_ONCE(rnp->qsmask, rnp->qsmask & ~mask);",
            "\t\ttrace_rcu_quiescent_state_report(rcu_state.name, rnp->gp_seq,",
            "\t\t\t\t\t\t mask, rnp->qsmask, rnp->level,",
            "\t\t\t\t\t\t rnp->grplo, rnp->grphi,",
            "\t\t\t\t\t\t !!rnp->gp_tasks);",
            "\t\tif (rnp->qsmask != 0 || rcu_preempt_blocked_readers_cgp(rnp)) {",
            "",
            "\t\t\t/* Other bits still set at this level, so done. */",
            "\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\trnp->completedqs = rnp->gp_seq;",
            "\t\tmask = rnp->grpmask;",
            "\t\tif (rnp->parent == NULL) {",
            "",
            "\t\t\t/* No more levels.  Exit loop holding root lock. */",
            "",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "\t\trnp_c = rnp;",
            "\t\trnp = rnp->parent;",
            "\t\traw_spin_lock_irqsave_rcu_node(rnp, flags);",
            "\t\toldmask = READ_ONCE(rnp_c->qsmask);",
            "\t}",
            "",
            "\t/*",
            "\t * Get here if we are the last CPU to pass through a quiescent",
            "\t * state for this grace period.  Invoke rcu_report_qs_rsp()",
            "\t * to clean up and start the next grace period if one is needed.",
            "\t */",
            "\trcu_report_qs_rsp(flags); /* releases rnp->lock. */",
            "}",
            "static void __maybe_unused",
            "rcu_report_unblock_qs_rnp(struct rcu_node *rnp, unsigned long flags)",
            "\t__releases(rnp->lock)",
            "{",
            "\tunsigned long gps;",
            "\tunsigned long mask;",
            "\tstruct rcu_node *rnp_p;",
            "",
            "\traw_lockdep_assert_held_rcu_node(rnp);",
            "\tif (WARN_ON_ONCE(!IS_ENABLED(CONFIG_PREEMPT_RCU)) ||",
            "\t    WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp)) ||",
            "\t    rnp->qsmask != 0) {",
            "\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "\t\treturn;  /* Still need more quiescent states! */",
            "\t}",
            "",
            "\trnp->completedqs = rnp->gp_seq;",
            "\trnp_p = rnp->parent;",
            "\tif (rnp_p == NULL) {",
            "\t\t/*",
            "\t\t * Only one rcu_node structure in the tree, so don't",
            "\t\t * try to report up to its nonexistent parent!",
            "\t\t */",
            "\t\trcu_report_qs_rsp(flags);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* Report up the rest of the hierarchy, tracking current ->gp_seq. */",
            "\tgps = rnp->gp_seq;",
            "\tmask = rnp->grpmask;",
            "\traw_spin_unlock_rcu_node(rnp);\t/* irqs remain disabled. */",
            "\traw_spin_lock_rcu_node(rnp_p);\t/* irqs already disabled. */",
            "\trcu_report_qs_rnp(mask, rnp_p, gps, flags);",
            "}"
          ],
          "function_name": "rcu_gp_kthread, rcu_report_qs_rsp, rcu_report_qs_rnp, rcu_report_unblock_qs_rnp",
          "description": "实现RCU grace period的主线程循环，处理grace period启动、强制quiescent状态报告及结束逻辑，通过锁和状态标志协调各子系统同步",
          "similarity": 0.5288283824920654
        }
      ]
    },
    {
      "source_file": "kernel/time/timer.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:57:06\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `time\\timer.c`\n\n---\n\n# `time/timer.c` 技术文档\n\n## 1. 文件概述\n\n`time/timer.c` 是 Linux 内核中实现**内核定时器子系统**的核心文件，负责管理基于**定时器轮（timer wheel）** 的动态定时器机制。该文件提供了高效、可扩展的定时器调度框架，支持高精度超时处理、SMP（对称多处理）环境下的 per-CPU 定时器管理，以及与 NO_HZ（动态 tick）节能机制的集成。其设计目标是在保证大多数超时场景（如网络、I/O 超时）性能的同时，通过多级粒度结构避免传统定时器轮中频繁的级联（cascading）操作，从而提升系统可扩展性。\n\n## 2. 核心功能\n\n### 主要数据结构\n- **`jiffies_64`**：全局 64 位 jiffies 计数器，记录自系统启动以来的时钟滴答数，对齐缓存行以优化 SMP 访问。\n- **多级定时器轮（Timer Wheel）结构**：\n  - 由 `LVL_DEPTH` 层（通常为 8 或 9）组成，每层包含 `LVL_SIZE`（64）个桶（buckets）。\n  - 每层具有不同的时间粒度（granularity），随层级升高而增大。\n- **定时器基础（Timer Bases）**：\n  - `BASE_STD`：标准定时器基础，用于普通定时器。\n  - `BASE_DEF`：可延迟定时器基础（仅当 `CONFIG_NO_HZ_COMMON` 启用时存在），用于在 CPU 空闲时可推迟执行的定时器。\n\n### 关键宏定义\n- `LVL_CLK_SHIFT` / `LVL_CLK_DIV`：定义层级间的时间粒度缩放因子（默认为 8 倍）。\n- `LVL_GRAN(n)`：第 `n` 层的时间粒度（单位：jiffies）。\n- `LVL_START(n)`：第 `n` 层的起始偏移时间，用于计算定时器应插入的层级。\n- `WHEEL_TIMEOUT_CUTOFF` / `WHEEL_TIMEOUT_MAX`：定时器轮的最大支持超时时间（约 12 天 @ HZ=1000）。\n\n### 主要功能\n- 定时器的注册（`add_timer`）、删除（`del_timer`）和修改（`mod_timer`）。\n- 定时器到期处理（软中断上下文执行）。\n- 与 tick 管理子系统（`tick.h`）和 NO_HZ 模式协同工作。\n- 提供 `sys_sysinfo` 系统调用的底层支持。\n\n## 3. 关键实现\n\n### 多级定时器轮算法\n- **层级设计**：定时器根据其到期时间的远近被分配到不同层级。近到期定时器放入低层（高精度），远到期放入高层（低精度）。\n- **无级联机制**：与经典定时器轮不同，本实现**不进行定时器的级联迁移**。高层定时器到期时直接触发，牺牲少量精度换取显著性能提升。\n- **隐式批处理**：高层的粗粒度天然实现超时事件的批处理，减少中断和软中断开销。\n- **超时截断**：超过 `WHEEL_TIMEOUT_MAX` 的定时器会被强制设为最大支持超时值，实测表明实际使用中超时极少超过 5 天。\n\n### 粒度与范围（以 HZ=1000 为例）\n| 层级 | 偏移 | 粒度 | 范围 |\n|------|------|------|------|\n| 0 | 0 | 1 ms | 0 – 63 ms |\n| 1 | 64 | 8 ms | 64 – 511 ms |\n| ... | ... | ... | ... |\n| 8 | 512 | ~4 小时 | ~1 天 – ~12 天 |\n\n### NO_HZ 支持\n- 当启用 `CONFIG_NO_HZ_COMMON` 时，系统维护**两个独立的定时器轮**：\n  - `BASE_STD`：标准定时器，必须准时触发。\n  - `BASE_DEF`：可延迟定时器，在 CPU 进入空闲状态时可推迟执行，用于节能。\n\n### SMP 优化\n- 定时器默认绑定到注册时的 CPU，利用 per-CPU 数据结构减少锁竞争。\n- `jiffies_64` 使用 `__cacheline_aligned_in_smp` 对齐，避免 false sharing。\n\n## 4. 依赖关系\n\n### 头文件依赖\n- **时间子系统**：`<linux/time.h>`, `<linux/jiffies.h>`, `<asm/timex.h>`\n- **调度与中断**：`<linux/interrupt.h>`, `<linux/irq_work.h>`, `<linux/sched/*.h>`\n- **内存管理**：`<linux/slab.h>`, `<linux/mm.h>`\n- **系统调用**：`<linux/syscalls.h>`, `<linux/uaccess.h>`\n- **内部模块**：`\"tick-internal.h\"`（tick 管理）、`<trace/events/timer.h>`（跟踪点）\n\n### 内核子系统交互\n- **Tick 管理**：通过 `tick.h` 接口获取时钟事件，驱动定时器轮推进。\n- **软中断**：定时器到期回调在 `TIMER_SOFTIRQ` 软中断上下文中执行。\n- **POSIX 定时器**：为 `<linux/posix-timers.h>` 提供底层支持。\n- **CPU 热插拔**：通过 `cpu.h` 处理 CPU 上下线时的定时器迁移。\n- **电源管理**：与 `NO_HZ` 和 `sched/nohz.h` 协同实现动态 tick。\n\n## 5. 使用场景\n\n- **内核超时机制**：网络协议栈（TCP 重传、连接超时）、块设备 I/O 超时、文件系统缓存回收等。\n- **延迟执行任务**：通过 `mod_timer` 实现延迟工作队列（如 `delayed_work`）。\n- **系统时间维护**：为 `jiffies` 和 `get_jiffies_64()` 提供原子更新。\n- **用户空间接口**：支撑 `sysinfo` 系统调用返回 uptime、负载等信息。\n- **高精度定时需求**：短超时（<64ms @ HZ=1000）可获得毫秒级精度，满足实时性要求。\n- **低功耗系统**：在 `NO_HZ_IDLE` 或 `NO_HZ_FULL` 模式下，通过 `BASE_DEF` 减少不必要的 tick 中断。",
      "similarity": 0.5717936754226685,
      "chunks": [
        {
          "chunk_id": 11,
          "file_path": "kernel/time/timer.c",
          "start_line": 2190,
          "end_line": 2292,
          "content": [
            "signed long __sched schedule_timeout_killable(signed long timeout)",
            "{",
            "\t__set_current_state(TASK_KILLABLE);",
            "\treturn schedule_timeout(timeout);",
            "}",
            "signed long __sched schedule_timeout_uninterruptible(signed long timeout)",
            "{",
            "\t__set_current_state(TASK_UNINTERRUPTIBLE);",
            "\treturn schedule_timeout(timeout);",
            "}",
            "signed long __sched schedule_timeout_idle(signed long timeout)",
            "{",
            "\t__set_current_state(TASK_IDLE);",
            "\treturn schedule_timeout(timeout);",
            "}",
            "static void migrate_timer_list(struct timer_base *new_base, struct hlist_head *head)",
            "{",
            "\tstruct timer_list *timer;",
            "\tint cpu = new_base->cpu;",
            "",
            "\twhile (!hlist_empty(head)) {",
            "\t\ttimer = hlist_entry(head->first, struct timer_list, entry);",
            "\t\tdetach_timer(timer, false);",
            "\t\ttimer->flags = (timer->flags & ~TIMER_BASEMASK) | cpu;",
            "\t\tinternal_add_timer(new_base, timer);",
            "\t}",
            "}",
            "int timers_prepare_cpu(unsigned int cpu)",
            "{",
            "\tstruct timer_base *base;",
            "\tint b;",
            "",
            "\tfor (b = 0; b < NR_BASES; b++) {",
            "\t\tbase = per_cpu_ptr(&timer_bases[b], cpu);",
            "\t\tbase->clk = jiffies;",
            "\t\tbase->next_expiry = base->clk + NEXT_TIMER_MAX_DELTA;",
            "\t\tbase->next_expiry_recalc = false;",
            "\t\tbase->timers_pending = false;",
            "\t\tbase->is_idle = false;",
            "\t}",
            "\treturn 0;",
            "}",
            "int timers_dead_cpu(unsigned int cpu)",
            "{",
            "\tstruct timer_base *old_base;",
            "\tstruct timer_base *new_base;",
            "\tint b, i;",
            "",
            "\tfor (b = 0; b < NR_BASES; b++) {",
            "\t\told_base = per_cpu_ptr(&timer_bases[b], cpu);",
            "\t\tnew_base = get_cpu_ptr(&timer_bases[b]);",
            "\t\t/*",
            "\t\t * The caller is globally serialized and nobody else",
            "\t\t * takes two locks at once, deadlock is not possible.",
            "\t\t */",
            "\t\traw_spin_lock_irq(&new_base->lock);",
            "\t\traw_spin_lock_nested(&old_base->lock, SINGLE_DEPTH_NESTING);",
            "",
            "\t\t/*",
            "\t\t * The current CPUs base clock might be stale. Update it",
            "\t\t * before moving the timers over.",
            "\t\t */",
            "\t\tforward_timer_base(new_base);",
            "",
            "\t\tWARN_ON_ONCE(old_base->running_timer);",
            "\t\told_base->running_timer = NULL;",
            "",
            "\t\tfor (i = 0; i < WHEEL_SIZE; i++)",
            "\t\t\tmigrate_timer_list(new_base, old_base->vectors + i);",
            "",
            "\t\traw_spin_unlock(&old_base->lock);",
            "\t\traw_spin_unlock_irq(&new_base->lock);",
            "\t\tput_cpu_ptr(&timer_bases);",
            "\t}",
            "\treturn 0;",
            "}",
            "static void __init init_timer_cpu(int cpu)",
            "{",
            "\tstruct timer_base *base;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < NR_BASES; i++) {",
            "\t\tbase = per_cpu_ptr(&timer_bases[i], cpu);",
            "\t\tbase->cpu = cpu;",
            "\t\traw_spin_lock_init(&base->lock);",
            "\t\tbase->clk = jiffies;",
            "\t\tbase->next_expiry = base->clk + NEXT_TIMER_MAX_DELTA;",
            "\t\ttimer_base_init_expiry_lock(base);",
            "\t}",
            "}",
            "static void __init init_timer_cpus(void)",
            "{",
            "\tint cpu;",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tinit_timer_cpu(cpu);",
            "}",
            "void __init init_timers(void)",
            "{",
            "\tinit_timer_cpus();",
            "\tposix_cputimers_init_work();",
            "\topen_softirq(TIMER_SOFTIRQ, run_timer_softirq);",
            "}"
          ],
          "function_name": "schedule_timeout_killable, schedule_timeout_uninterruptible, schedule_timeout_idle, migrate_timer_list, timers_prepare_cpu, timers_dead_cpu, init_timer_cpu, init_timer_cpus, init_timers",
          "description": "该代码段实现Linux内核中的定时器管理和进程睡眠控制功能。  \n三个`schedule_timeout_*`函数通过设置任务状态（可中断/不可中断/空闲）实现进程睡眠并返回超时值；`migrate_timer_list`及`timers_prepare_cpu`/`timers_dead_cpu`系列函数负责多CPU环境下定时器列表的迁移与初始化，保障定时器在CPU热插拔时的数据一致性。  \n其余函数（`init_timer_cpu`/`init_timer_cpus`/`init_timers`）完成全局定时器基础结构的初始化，构建多核系统中定时器调度所需的底层资源。",
          "similarity": 0.6134558320045471
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/time/timer.c",
          "start_line": 460,
          "end_line": 560,
          "content": [
            "unsigned long __round_jiffies_up_relative(unsigned long j, int cpu)",
            "{",
            "\tunsigned long j0 = jiffies;",
            "",
            "\t/* Use j0 because jiffies might change while we run */",
            "\treturn round_jiffies_common(j + j0, cpu, true) - j0;",
            "}",
            "unsigned long round_jiffies_up(unsigned long j)",
            "{",
            "\treturn round_jiffies_common(j, raw_smp_processor_id(), true);",
            "}",
            "unsigned long round_jiffies_up_relative(unsigned long j)",
            "{",
            "\treturn __round_jiffies_up_relative(j, raw_smp_processor_id());",
            "}",
            "static inline unsigned int timer_get_idx(struct timer_list *timer)",
            "{",
            "\treturn (timer->flags & TIMER_ARRAYMASK) >> TIMER_ARRAYSHIFT;",
            "}",
            "static inline void timer_set_idx(struct timer_list *timer, unsigned int idx)",
            "{",
            "\ttimer->flags = (timer->flags & ~TIMER_ARRAYMASK) |",
            "\t\t\tidx << TIMER_ARRAYSHIFT;",
            "}",
            "static inline unsigned calc_index(unsigned long expires, unsigned lvl,",
            "\t\t\t\t  unsigned long *bucket_expiry)",
            "{",
            "",
            "\t/*",
            "\t * The timer wheel has to guarantee that a timer does not fire",
            "\t * early. Early expiry can happen due to:",
            "\t * - Timer is armed at the edge of a tick",
            "\t * - Truncation of the expiry time in the outer wheel levels",
            "\t *",
            "\t * Round up with level granularity to prevent this.",
            "\t */",
            "\texpires = (expires >> LVL_SHIFT(lvl)) + 1;",
            "\t*bucket_expiry = expires << LVL_SHIFT(lvl);",
            "\treturn LVL_OFFS(lvl) + (expires & LVL_MASK);",
            "}",
            "static int calc_wheel_index(unsigned long expires, unsigned long clk,",
            "\t\t\t    unsigned long *bucket_expiry)",
            "{",
            "\tunsigned long delta = expires - clk;",
            "\tunsigned int idx;",
            "",
            "\tif (delta < LVL_START(1)) {",
            "\t\tidx = calc_index(expires, 0, bucket_expiry);",
            "\t} else if (delta < LVL_START(2)) {",
            "\t\tidx = calc_index(expires, 1, bucket_expiry);",
            "\t} else if (delta < LVL_START(3)) {",
            "\t\tidx = calc_index(expires, 2, bucket_expiry);",
            "\t} else if (delta < LVL_START(4)) {",
            "\t\tidx = calc_index(expires, 3, bucket_expiry);",
            "\t} else if (delta < LVL_START(5)) {",
            "\t\tidx = calc_index(expires, 4, bucket_expiry);",
            "\t} else if (delta < LVL_START(6)) {",
            "\t\tidx = calc_index(expires, 5, bucket_expiry);",
            "\t} else if (delta < LVL_START(7)) {",
            "\t\tidx = calc_index(expires, 6, bucket_expiry);",
            "\t} else if (LVL_DEPTH > 8 && delta < LVL_START(8)) {",
            "\t\tidx = calc_index(expires, 7, bucket_expiry);",
            "\t} else if ((long) delta < 0) {",
            "\t\tidx = clk & LVL_MASK;",
            "\t\t*bucket_expiry = clk;",
            "\t} else {",
            "\t\t/*",
            "\t\t * Force expire obscene large timeouts to expire at the",
            "\t\t * capacity limit of the wheel.",
            "\t\t */",
            "\t\tif (delta >= WHEEL_TIMEOUT_CUTOFF)",
            "\t\t\texpires = clk + WHEEL_TIMEOUT_MAX;",
            "",
            "\t\tidx = calc_index(expires, LVL_DEPTH - 1, bucket_expiry);",
            "\t}",
            "\treturn idx;",
            "}",
            "static void",
            "trigger_dyntick_cpu(struct timer_base *base, struct timer_list *timer)",
            "{",
            "\tif (!is_timers_nohz_active())",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * TODO: This wants some optimizing similar to the code below, but we",
            "\t * will do that when we switch from push to pull for deferrable timers.",
            "\t */",
            "\tif (timer->flags & TIMER_DEFERRABLE) {",
            "\t\tif (tick_nohz_full_cpu(base->cpu))",
            "\t\t\twake_up_nohz_cpu(base->cpu);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/*",
            "\t * We might have to IPI the remote CPU if the base is idle and the",
            "\t * timer is not deferrable. If the other CPU is on the way to idle",
            "\t * then it can't set base->is_idle as we hold the base lock:",
            "\t */",
            "\tif (base->is_idle)",
            "\t\twake_up_nohz_cpu(base->cpu);",
            "}"
          ],
          "function_name": "__round_jiffies_up_relative, round_jiffies_up, round_jiffies_up_relative, timer_get_idx, timer_set_idx, calc_index, calc_wheel_index, trigger_dyntick_cpu",
          "description": "实现定时器层级索引计算逻辑和动态tick触发机制，通过层级间转换规则确定定时器存储位置，处理非活动CPU上的定时器唤醒需求。",
          "similarity": 0.5468560457229614
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/time/timer.c",
          "start_line": 1,
          "end_line": 230,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " *  Kernel internal timers",
            " *",
            " *  Copyright (C) 1991, 1992  Linus Torvalds",
            " *",
            " *  1997-01-28  Modified by Finn Arne Gangstad to make timers scale better.",
            " *",
            " *  1997-09-10  Updated NTP code according to technical memorandum Jan '96",
            " *              \"A Kernel Model for Precision Timekeeping\" by Dave Mills",
            " *  1998-12-24  Fixed a xtime SMP race (we need the xtime_lock rw spinlock to",
            " *              serialize accesses to xtime/lost_ticks).",
            " *                              Copyright (C) 1998  Andrea Arcangeli",
            " *  1999-03-10  Improved NTP compatibility by Ulrich Windl",
            " *  2002-05-31\tMove sys_sysinfo here and make its locking sane, Robert Love",
            " *  2000-10-05  Implemented scalable SMP per-CPU timer handling.",
            " *                              Copyright (C) 2000, 2001, 2002  Ingo Molnar",
            " *              Designed by David S. Miller, Alexey Kuznetsov and Ingo Molnar",
            " */",
            "",
            "#include <linux/kernel_stat.h>",
            "#include <linux/export.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/percpu.h>",
            "#include <linux/init.h>",
            "#include <linux/mm.h>",
            "#include <linux/swap.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/notifier.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/time.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/cpu.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/delay.h>",
            "#include <linux/tick.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/slab.h>",
            "#include <linux/compat.h>",
            "#include <linux/random.h>",
            "#include <linux/sysctl.h>",
            "",
            "#include <linux/uaccess.h>",
            "#include <asm/unistd.h>",
            "#include <asm/div64.h>",
            "#include <asm/timex.h>",
            "#include <asm/io.h>",
            "",
            "#include \"tick-internal.h\"",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/timer.h>",
            "",
            "__visible u64 jiffies_64 __cacheline_aligned_in_smp = INITIAL_JIFFIES;",
            "",
            "EXPORT_SYMBOL(jiffies_64);",
            "",
            "/*",
            " * The timer wheel has LVL_DEPTH array levels. Each level provides an array of",
            " * LVL_SIZE buckets. Each level is driven by its own clock and therefor each",
            " * level has a different granularity.",
            " *",
            " * The level granularity is:\t\tLVL_CLK_DIV ^ lvl",
            " * The level clock frequency is:\tHZ / (LVL_CLK_DIV ^ level)",
            " *",
            " * The array level of a newly armed timer depends on the relative expiry",
            " * time. The farther the expiry time is away the higher the array level and",
            " * therefor the granularity becomes.",
            " *",
            " * Contrary to the original timer wheel implementation, which aims for 'exact'",
            " * expiry of the timers, this implementation removes the need for recascading",
            " * the timers into the lower array levels. The previous 'classic' timer wheel",
            " * implementation of the kernel already violated the 'exact' expiry by adding",
            " * slack to the expiry time to provide batched expiration. The granularity",
            " * levels provide implicit batching.",
            " *",
            " * This is an optimization of the original timer wheel implementation for the",
            " * majority of the timer wheel use cases: timeouts. The vast majority of",
            " * timeout timers (networking, disk I/O ...) are canceled before expiry. If",
            " * the timeout expires it indicates that normal operation is disturbed, so it",
            " * does not matter much whether the timeout comes with a slight delay.",
            " *",
            " * The only exception to this are networking timers with a small expiry",
            " * time. They rely on the granularity. Those fit into the first wheel level,",
            " * which has HZ granularity.",
            " *",
            " * We don't have cascading anymore. timers with a expiry time above the",
            " * capacity of the last wheel level are force expired at the maximum timeout",
            " * value of the last wheel level. From data sampling we know that the maximum",
            " * value observed is 5 days (network connection tracking), so this should not",
            " * be an issue.",
            " *",
            " * The currently chosen array constants values are a good compromise between",
            " * array size and granularity.",
            " *",
            " * This results in the following granularity and range levels:",
            " *",
            " * HZ 1000 steps",
            " * Level Offset  Granularity            Range",
            " *  0      0         1 ms                0 ms -         63 ms",
            " *  1     64         8 ms               64 ms -        511 ms",
            " *  2    128        64 ms              512 ms -       4095 ms (512ms - ~4s)",
            " *  3    192       512 ms             4096 ms -      32767 ms (~4s - ~32s)",
            " *  4    256      4096 ms (~4s)      32768 ms -     262143 ms (~32s - ~4m)",
            " *  5    320     32768 ms (~32s)    262144 ms -    2097151 ms (~4m - ~34m)",
            " *  6    384    262144 ms (~4m)    2097152 ms -   16777215 ms (~34m - ~4h)",
            " *  7    448   2097152 ms (~34m)  16777216 ms -  134217727 ms (~4h - ~1d)",
            " *  8    512  16777216 ms (~4h)  134217728 ms - 1073741822 ms (~1d - ~12d)",
            " *",
            " * HZ  300",
            " * Level Offset  Granularity            Range",
            " *  0\t   0         3 ms                0 ms -        210 ms",
            " *  1\t  64        26 ms              213 ms -       1703 ms (213ms - ~1s)",
            " *  2\t 128       213 ms             1706 ms -      13650 ms (~1s - ~13s)",
            " *  3\t 192      1706 ms (~1s)      13653 ms -     109223 ms (~13s - ~1m)",
            " *  4\t 256     13653 ms (~13s)    109226 ms -     873810 ms (~1m - ~14m)",
            " *  5\t 320    109226 ms (~1m)     873813 ms -    6990503 ms (~14m - ~1h)",
            " *  6\t 384    873813 ms (~14m)   6990506 ms -   55924050 ms (~1h - ~15h)",
            " *  7\t 448   6990506 ms (~1h)   55924053 ms -  447392423 ms (~15h - ~5d)",
            " *  8    512  55924053 ms (~15h) 447392426 ms - 3579139406 ms (~5d - ~41d)",
            " *",
            " * HZ  250",
            " * Level Offset  Granularity            Range",
            " *  0\t   0         4 ms                0 ms -        255 ms",
            " *  1\t  64        32 ms              256 ms -       2047 ms (256ms - ~2s)",
            " *  2\t 128       256 ms             2048 ms -      16383 ms (~2s - ~16s)",
            " *  3\t 192      2048 ms (~2s)      16384 ms -     131071 ms (~16s - ~2m)",
            " *  4\t 256     16384 ms (~16s)    131072 ms -    1048575 ms (~2m - ~17m)",
            " *  5\t 320    131072 ms (~2m)    1048576 ms -    8388607 ms (~17m - ~2h)",
            " *  6\t 384   1048576 ms (~17m)   8388608 ms -   67108863 ms (~2h - ~18h)",
            " *  7\t 448   8388608 ms (~2h)   67108864 ms -  536870911 ms (~18h - ~6d)",
            " *  8    512  67108864 ms (~18h) 536870912 ms - 4294967288 ms (~6d - ~49d)",
            " *",
            " * HZ  100",
            " * Level Offset  Granularity            Range",
            " *  0\t   0         10 ms               0 ms -        630 ms",
            " *  1\t  64         80 ms             640 ms -       5110 ms (640ms - ~5s)",
            " *  2\t 128        640 ms            5120 ms -      40950 ms (~5s - ~40s)",
            " *  3\t 192       5120 ms (~5s)     40960 ms -     327670 ms (~40s - ~5m)",
            " *  4\t 256      40960 ms (~40s)   327680 ms -    2621430 ms (~5m - ~43m)",
            " *  5\t 320     327680 ms (~5m)   2621440 ms -   20971510 ms (~43m - ~5h)",
            " *  6\t 384    2621440 ms (~43m) 20971520 ms -  167772150 ms (~5h - ~1d)",
            " *  7\t 448   20971520 ms (~5h) 167772160 ms - 1342177270 ms (~1d - ~15d)",
            " */",
            "",
            "/* Clock divisor for the next level */",
            "#define LVL_CLK_SHIFT\t3",
            "#define LVL_CLK_DIV\t(1UL << LVL_CLK_SHIFT)",
            "#define LVL_CLK_MASK\t(LVL_CLK_DIV - 1)",
            "#define LVL_SHIFT(n)\t((n) * LVL_CLK_SHIFT)",
            "#define LVL_GRAN(n)\t(1UL << LVL_SHIFT(n))",
            "",
            "/*",
            " * The time start value for each level to select the bucket at enqueue",
            " * time. We start from the last possible delta of the previous level",
            " * so that we can later add an extra LVL_GRAN(n) to n (see calc_index()).",
            " */",
            "#define LVL_START(n)\t((LVL_SIZE - 1) << (((n) - 1) * LVL_CLK_SHIFT))",
            "",
            "/* Size of each clock level */",
            "#define LVL_BITS\t6",
            "#define LVL_SIZE\t(1UL << LVL_BITS)",
            "#define LVL_MASK\t(LVL_SIZE - 1)",
            "#define LVL_OFFS(n)\t((n) * LVL_SIZE)",
            "",
            "/* Level depth */",
            "#if HZ > 100",
            "# define LVL_DEPTH\t9",
            "# else",
            "# define LVL_DEPTH\t8",
            "#endif",
            "",
            "/* The cutoff (max. capacity of the wheel) */",
            "#define WHEEL_TIMEOUT_CUTOFF\t(LVL_START(LVL_DEPTH))",
            "#define WHEEL_TIMEOUT_MAX\t(WHEEL_TIMEOUT_CUTOFF - LVL_GRAN(LVL_DEPTH - 1))",
            "",
            "/*",
            " * The resulting wheel size. If NOHZ is configured we allocate two",
            " * wheels so we have a separate storage for the deferrable timers.",
            " */",
            "#define WHEEL_SIZE\t(LVL_SIZE * LVL_DEPTH)",
            "",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "# define NR_BASES\t2",
            "# define BASE_STD\t0",
            "# define BASE_DEF\t1",
            "#else",
            "# define NR_BASES\t1",
            "# define BASE_STD\t0",
            "# define BASE_DEF\t0",
            "#endif",
            "",
            "struct timer_base {",
            "\traw_spinlock_t\t\tlock;",
            "\tstruct timer_list\t*running_timer;",
            "#ifdef CONFIG_PREEMPT_RT",
            "\tspinlock_t\t\texpiry_lock;",
            "\tatomic_t\t\ttimer_waiters;",
            "#endif",
            "\tunsigned long\t\tclk;",
            "\tunsigned long\t\tnext_expiry;",
            "\tunsigned int\t\tcpu;",
            "\tbool\t\t\tnext_expiry_recalc;",
            "\tbool\t\t\tis_idle;",
            "\tbool\t\t\ttimers_pending;",
            "\tDECLARE_BITMAP(pending_map, WHEEL_SIZE);",
            "\tstruct hlist_head\tvectors[WHEEL_SIZE];",
            "} ____cacheline_aligned;",
            "",
            "static DEFINE_PER_CPU(struct timer_base, timer_bases[NR_BASES]);",
            "",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "",
            "static DEFINE_STATIC_KEY_FALSE(timers_nohz_active);",
            "static DEFINE_MUTEX(timer_keys_mutex);",
            "",
            "static void timer_update_keys(struct work_struct *work);",
            "static DECLARE_WORK(timer_update_work, timer_update_keys);",
            "",
            "#ifdef CONFIG_SMP",
            "static unsigned int sysctl_timer_migration = 1;",
            "",
            "DEFINE_STATIC_KEY_FALSE(timers_migration_enabled);",
            ""
          ],
          "function_name": null,
          "description": "定义并实现了内核定时器轮（timer wheel）的数据结构和宏观布局，通过多层级桶结构管理定时器，支持不同粒度的超时处理，包含对NOHZ模式的支持及动态调整机制。",
          "similarity": 0.5343495607376099
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/time/timer.c",
          "start_line": 231,
          "end_line": 333,
          "content": [
            "static void timers_update_migration(void)",
            "{",
            "\tif (sysctl_timer_migration && tick_nohz_active)",
            "\t\tstatic_branch_enable(&timers_migration_enabled);",
            "\telse",
            "\t\tstatic_branch_disable(&timers_migration_enabled);",
            "}",
            "static int timer_migration_handler(struct ctl_table *table, int write,",
            "\t\t\t    void *buffer, size_t *lenp, loff_t *ppos)",
            "{",
            "\tint ret;",
            "",
            "\tmutex_lock(&timer_keys_mutex);",
            "\tret = proc_dointvec_minmax(table, write, buffer, lenp, ppos);",
            "\tif (!ret && write)",
            "\t\ttimers_update_migration();",
            "\tmutex_unlock(&timer_keys_mutex);",
            "\treturn ret;",
            "}",
            "static int __init timer_sysctl_init(void)",
            "{",
            "\tregister_sysctl(\"kernel\", timer_sysctl);",
            "\treturn 0;",
            "}",
            "static inline void timers_update_migration(void) { }",
            "static void timer_update_keys(struct work_struct *work)",
            "{",
            "\tmutex_lock(&timer_keys_mutex);",
            "\ttimers_update_migration();",
            "\tstatic_branch_enable(&timers_nohz_active);",
            "\tmutex_unlock(&timer_keys_mutex);",
            "}",
            "void timers_update_nohz(void)",
            "{",
            "\tschedule_work(&timer_update_work);",
            "}",
            "static inline bool is_timers_nohz_active(void)",
            "{",
            "\treturn static_branch_unlikely(&timers_nohz_active);",
            "}",
            "static inline bool is_timers_nohz_active(void) { return false; }",
            "static unsigned long round_jiffies_common(unsigned long j, int cpu,",
            "\t\tbool force_up)",
            "{",
            "\tint rem;",
            "\tunsigned long original = j;",
            "",
            "\t/*",
            "\t * We don't want all cpus firing their timers at once hitting the",
            "\t * same lock or cachelines, so we skew each extra cpu with an extra",
            "\t * 3 jiffies. This 3 jiffies came originally from the mm/ code which",
            "\t * already did this.",
            "\t * The skew is done by adding 3*cpunr, then round, then subtract this",
            "\t * extra offset again.",
            "\t */",
            "\tj += cpu * 3;",
            "",
            "\trem = j % HZ;",
            "",
            "\t/*",
            "\t * If the target jiffie is just after a whole second (which can happen",
            "\t * due to delays of the timer irq, long irq off times etc etc) then",
            "\t * we should round down to the whole second, not up. Use 1/4th second",
            "\t * as cutoff for this rounding as an extreme upper bound for this.",
            "\t * But never round down if @force_up is set.",
            "\t */",
            "\tif (rem < HZ/4 && !force_up) /* round down */",
            "\t\tj = j - rem;",
            "\telse /* round up */",
            "\t\tj = j - rem + HZ;",
            "",
            "\t/* now that we have rounded, subtract the extra skew again */",
            "\tj -= cpu * 3;",
            "",
            "\t/*",
            "\t * Make sure j is still in the future. Otherwise return the",
            "\t * unmodified value.",
            "\t */",
            "\treturn time_is_after_jiffies(j) ? j : original;",
            "}",
            "unsigned long __round_jiffies(unsigned long j, int cpu)",
            "{",
            "\treturn round_jiffies_common(j, cpu, false);",
            "}",
            "unsigned long __round_jiffies_relative(unsigned long j, int cpu)",
            "{",
            "\tunsigned long j0 = jiffies;",
            "",
            "\t/* Use j0 because jiffies might change while we run */",
            "\treturn round_jiffies_common(j + j0, cpu, false) - j0;",
            "}",
            "unsigned long round_jiffies(unsigned long j)",
            "{",
            "\treturn round_jiffies_common(j, raw_smp_processor_id(), false);",
            "}",
            "unsigned long round_jiffies_relative(unsigned long j)",
            "{",
            "\treturn __round_jiffies_relative(j, raw_smp_processor_id());",
            "}",
            "unsigned long __round_jiffies_up(unsigned long j, int cpu)",
            "{",
            "\treturn round_jiffies_common(j, cpu, true);",
            "}"
          ],
          "function_name": "timers_update_migration, timer_migration_handler, timer_sysctl_init, timers_update_migration, timer_update_keys, timers_update_nohz, is_timers_nohz_active, is_timers_nohz_active, round_jiffies_common, __round_jiffies, __round_jiffies_relative, round_jiffies, round_jiffies_relative, __round_jiffies_up",
          "description": "提供定时器迁移策略控制、Jiffies值调整逻辑及NOHZ相关功能，包含迁移开关配置、定时器分布优化算法和基于CPU负载的超时时间调整方法。",
          "similarity": 0.5210071206092834
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/time/timer.c",
          "start_line": 2030,
          "end_line": 2130,
          "content": [
            "static __latent_entropy void run_timer_softirq(struct softirq_action *h)",
            "{",
            "\tstruct timer_base *base = this_cpu_ptr(&timer_bases[BASE_STD]);",
            "",
            "\t__run_timers(base);",
            "\tif (IS_ENABLED(CONFIG_NO_HZ_COMMON))",
            "\t\t__run_timers(this_cpu_ptr(&timer_bases[BASE_DEF]));",
            "}",
            "static void run_local_timers(void)",
            "{",
            "\tstruct timer_base *base = this_cpu_ptr(&timer_bases[BASE_STD]);",
            "",
            "\thrtimer_run_queues();",
            "\t/* Raise the softirq only if required. */",
            "\tif (time_before(jiffies, base->next_expiry)) {",
            "\t\tif (!IS_ENABLED(CONFIG_NO_HZ_COMMON))",
            "\t\t\treturn;",
            "\t\t/* CPU is awake, so check the deferrable base. */",
            "\t\tbase++;",
            "\t\tif (time_before(jiffies, base->next_expiry))",
            "\t\t\treturn;",
            "\t}",
            "\traise_timer_softirq(TIMER_SOFTIRQ);",
            "}",
            "void update_process_times(int user_tick)",
            "{",
            "\tstruct task_struct *p = current;",
            "",
            "\t/* Note: this timer irq context must be accounted for as well. */",
            "\taccount_process_tick(p, user_tick);",
            "\trun_local_timers();",
            "\trcu_sched_clock_irq(user_tick);",
            "#ifdef CONFIG_IRQ_WORK",
            "\tif (in_irq())",
            "\t\tirq_work_tick();",
            "#endif",
            "\tsched_tick();",
            "\tif (IS_ENABLED(CONFIG_POSIX_TIMERS))",
            "\t\trun_posix_cpu_timers();",
            "}",
            "static void process_timeout(struct timer_list *t)",
            "{",
            "\tstruct process_timer *timeout = from_timer(timeout, t, timer);",
            "",
            "\twake_up_process(timeout->task);",
            "}",
            "signed long __sched schedule_timeout(signed long timeout)",
            "{",
            "\tstruct process_timer timer;",
            "\tunsigned long expire;",
            "",
            "\tswitch (timeout)",
            "\t{",
            "\tcase MAX_SCHEDULE_TIMEOUT:",
            "\t\t/*",
            "\t\t * These two special cases are useful to be comfortable",
            "\t\t * in the caller. Nothing more. We could take",
            "\t\t * MAX_SCHEDULE_TIMEOUT from one of the negative value",
            "\t\t * but I' d like to return a valid offset (>=0) to allow",
            "\t\t * the caller to do everything it want with the retval.",
            "\t\t */",
            "\t\tschedule();",
            "\t\tgoto out;",
            "\tdefault:",
            "\t\t/*",
            "\t\t * Another bit of PARANOID. Note that the retval will be",
            "\t\t * 0 since no piece of kernel is supposed to do a check",
            "\t\t * for a negative retval of schedule_timeout() (since it",
            "\t\t * should never happens anyway). You just have the printk()",
            "\t\t * that will tell you if something is gone wrong and where.",
            "\t\t */",
            "\t\tif (timeout < 0) {",
            "\t\t\tprintk(KERN_ERR \"schedule_timeout: wrong timeout \"",
            "\t\t\t\t\"value %lx\\n\", timeout);",
            "\t\t\tdump_stack();",
            "\t\t\t__set_current_state(TASK_RUNNING);",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t}",
            "",
            "\texpire = timeout + jiffies;",
            "",
            "\ttimer.task = current;",
            "\ttimer_setup_on_stack(&timer.timer, process_timeout, 0);",
            "\t__mod_timer(&timer.timer, expire, MOD_TIMER_NOTPENDING);",
            "\tschedule();",
            "\tdel_timer_sync(&timer.timer);",
            "",
            "\t/* Remove the timer from the object tracker */",
            "\tdestroy_timer_on_stack(&timer.timer);",
            "",
            "\ttimeout = expire - jiffies;",
            "",
            " out:",
            "\treturn timeout < 0 ? 0 : timeout;",
            "}",
            "signed long __sched schedule_timeout_interruptible(signed long timeout)",
            "{",
            "\t__set_current_state(TASK_INTERRUPTIBLE);",
            "\treturn schedule_timeout(timeout);",
            "}"
          ],
          "function_name": "run_timer_softirq, run_local_timers, update_process_times, process_timeout, schedule_timeout, schedule_timeout_interruptible",
          "description": "该代码段核心功能是处理定时器相关操作，涵盖软中断处理、本地定时器管理、进程时间更新及休眠超时控制。  \n`run_timer_softirq`和`run_local_timers`分别用于处理软中断中的定时器队列和本地定时器检查，`update_process_times`更新进程时间并触发本地定时器，`schedule_timeout`系列通过定时器实现进程休眠与超时唤醒。  \n上下文不完整：部分关键函数（如`__run_timers`、`hrtimer_run_queues`）的实现未展示，依赖外部知识理解其行为。",
          "similarity": 0.5047191381454468
        }
      ]
    }
  ]
}