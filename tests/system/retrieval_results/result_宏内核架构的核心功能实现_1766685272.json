{
  "query": "宏内核架构的核心功能实现",
  "timestamp": "2025-12-26 01:54:32",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/lockdep_internals.h",
      "md_summary": "> 自动生成时间: 2025-10-25 14:38:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\lockdep_internals.h`\n\n---\n\n# `locking/lockdep_internals.h` 技术文档\n\n## 1. 文件概述\n\n`lockdep_internals.h` 是 Linux 内核锁依赖（Lock Dependency，简称 lockdep）子系统的内部头文件，定义了 lockdep 运行时验证器所依赖的核心数据结构、枚举、宏和全局变量。该文件不对外暴露 API，仅供 lockdep 子系统内部使用，用于跟踪锁的使用状态、依赖关系、调用链以及统计信息，以检测潜在的死锁、锁顺序违规和中断上下文不一致等问题。\n\n## 2. 核心功能\n\n### 枚举与宏定义\n- `enum lock_usage_bit`：定义锁类（lock class）在不同上下文中的使用状态位（如 IRQ、softirq、hardirq 等）。\n- `LOCK_USAGE_*_MASK`：用于解析锁使用状态位的掩码（读/写方向、上下文类型）。\n- `LOCKF_*` 系列宏与常量：将使用状态位转换为位掩码，便于位运算操作，如 `LOCKF_ENABLED_IRQ`、`LOCKF_USED_IN_IRQ_READ` 等。\n- `LOCKF_IRQ` 与 `LOCKF_IRQ_READ`：组合宏，用于快速判断锁是否在中断上下文中被启用或使用。\n\n### 配置相关宏（内存优化）\n- `CONFIG_LOCKDEP_SMALL`：针对内存受限架构（如 SPARC）启用的小内存配置，限制 lockdep 数据结构的最大规模。\n- `MAX_LOCKDEP_ENTRIES`、`MAX_LOCKDEP_CHAINS_BITS`、`MAX_STACK_TRACE_ENTRIES`、`STACK_TRACE_HASH_SIZE`：定义 lockdep 跟踪能力的上限。\n\n### 锁链（Lock Chain）上下文标志\n- `LOCK_CHAIN_SOFTIRQ_CONTEXT` / `LOCK_CHAIN_HARDIRQ_CONTEXT`：标识锁链所处的中断上下文类型。\n\n### 全局变量声明\n- `lock_classes[]`：所有锁类的静态数组。\n- `lock_chains[]`：所有锁依赖链的静态数组。\n- 各类计数器：如 `nr_lock_classes`、`max_lockdep_depth`、`nr_stack_trace_entries` 等，用于跟踪 lockdep 运行状态。\n- 中断/软中断/进程上下文链数量统计：`nr_hardirq_chains`、`nr_softirq_chains`、`nr_process_chains`。\n- 内存使用统计：`nr_lost_chain_hlocks`、`nr_large_chain_blocks` 等。\n\n### 函数声明\n- `get_usage_chars()`：将锁类的使用状态转换为可读字符串。\n- `__get_key_name()`：获取锁子类键的名称。\n- `lock_chain_get_class()`：从锁链中获取第 i 个锁类。\n- `lockdep_next_lockchain()` / `lock_chain_count()`：遍历和统计锁链。\n- `lockdep_count_forward_deps()` / `lockdep_count_backward_deps()`（仅在 `CONFIG_PROVE_LOCKING` 下有效）：计算锁类的前向/后向依赖数量。\n- `lockdep_stack_trace_count()` / `lockdep_stack_hash_count()`（仅在 `CONFIG_TRACE_IRQFLAGS` 下有效）：返回栈跟踪相关统计。\n\n### 调试统计结构（`CONFIG_DEBUG_LOCKDEP`）\n- `struct lockdep_stats`：每 CPU 的 lockdep 调试统计信息，包括：\n  - 链查找命中/未命中次数\n  - 中断开关事件计数（含冗余事件）\n  - 各类检查次数（循环、前向/后向使用查找等）\n  - 每个锁类的操作计数（`lock_class_ops`）\n- 提供原子操作宏：`debug_atomic_inc/dec/read` 和 `debug_class_ops_inc/read`，用于安全更新和读取统计值。\n\n## 3. 关键实现\n\n### 锁使用状态编码\n- 使用 `lockdep_states.h` 中定义的状态（如 IRQ、SOFTIRQ、HARDIRQ 等）通过宏展开生成两组状态位：\n  - `USED_IN_*`：表示锁在该上下文中被实际使用（加锁）。\n  - `ENABLED_*`：表示锁在该上下文中被启用（即允许在该上下文中获取）。\n- 每个状态同时存在普通（写）和 `_READ`（读）版本，支持读写锁语义。\n- 状态位总数由 `LOCK_USAGE_STATES` 表示，并通过 `static_assert` 确保与 `LOCK_TRACE_STATES` 一致。\n\n### 位掩码构建\n- 利用 C 预处理器的 `#include` 技巧，在枚举和常量定义中重复包含 `lockdep_states.h`，动态生成所有状态对应的位掩码常量（如 `LOCKF_ENABLED_IRQ` 是所有 `LOCKF_ENABLED_*` 的按位或）。\n- 这种设计避免了手动维护大量状态组合，提高了可扩展性和一致性。\n\n### 内存布局优化\n- 通过 `CONFIG_LOCKDEP_SMALL` 宏，为资源受限平台（如 SPARC）提供较小的静态数组尺寸，确保内核镜像不超过 32MB 限制。\n- 默认配置则通过 Kconfig 选项（如 `CONFIG_LOCKDEP_BITS`）动态设定数据结构大小，以平衡内存占用与跟踪能力。\n\n### 调试统计的每 CPU 设计\n- 在 `CONFIG_DEBUG_LOCKDEP` 启用时，统计信息存储在 per-CPU 变量中，避免在 fast path 中因全局锁或缓存行竞争导致性能下降。\n- 提供封装宏确保在中断关闭上下文中更新统计（通过 `WARN_ON_ONCE(!irqs_disabled())` 强制约束）。\n\n## 4. 依赖关系\n\n- **依赖头文件**：\n  - `\"lockdep_states.h\"`：定义 lockdep 支持的上下文状态列表。\n  - `<asm/local.h>`：提供 per-CPU 变量操作原语（仅在 `CONFIG_DEBUG_LOCKDEP` 下）。\n- **被依赖模块**：\n  - `kernel/lockdep.c`：lockdep 主逻辑实现，大量使用本文件定义的数据结构和宏。\n  - `kernel/lockdep_proc.c`：通过本文件声明的全局变量和函数生成 `/proc/lockdep*` 调试信息。\n- **配置依赖**：\n  - `CONFIG_LOCKDEP`：启用 lockdep 子系统。\n  - `CONFIG_PROVE_LOCKING`：启用锁正确性证明（依赖前向/后向依赖计数）。\n  - `CONFIG_TRACE_IRQFLAGS`：启用中断状态跟踪（影响栈跟踪统计）。\n  - `CONFIG_DEBUG_LOCKDEP`：启用详细调试统计。\n\n## 5. 使用场景\n\n- **死锁检测**：通过 `lock_classes` 和 `lock_chains` 构建锁依赖图，运行时检测循环依赖。\n- **锁顺序验证**：记录锁获取顺序，防止违反既定顺序导致的潜在死锁。\n- **中断上下文一致性检查**：利用 `LOCKF_ENABLED_*` 和 `LOCKF_USED_IN_*` 位，确保锁不会在不允许的中断上下文中被获取（如在 hardirq 中获取仅在进程上下文启用的锁）。\n- **性能分析与调试**：通过 `lockdep_stats` 统计 lockdep 自身开销（如链查找效率、冗余检查次数），辅助优化。\n- **内核调试接口**：为 `/proc/lockdep`、`/proc/lockdep_chains` 等提供底层数据支持，供开发者分析锁行为。\n- **内存受限系统适配**：在 SPARC 等平台上，通过 `CONFIG_LOCKDEP_SMALL` 保证 lockdep 功能可用而不突破内存限制。",
      "similarity": 0.5933532118797302,
      "chunks": []
    },
    {
      "source_file": "kernel/sys_ni.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:31:37\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sys_ni.c`\n\n---\n\n# sys_ni.c 技术文档\n\n## 1. 文件概述\n\n`sys_ni.c` 是 Linux 内核中用于处理**未实现系统调用（Not Implemented Syscall）**的核心文件。当某个系统调用在当前架构或配置下未被实现时，内核会将其重定向到 `sys_ni_syscall()` 函数，该函数统一返回 `-ENOSYS` 错误码（表示“Function not implemented”）。此机制确保了即使某些系统调用未被支持，用户空间程序调用它们时也不会导致内核崩溃，而是获得标准错误响应。\n\n此外，该文件通过宏 `COND_SYSCALL` 和 `COND_SYSCALL_COMPAT` 为大量系统调用提供**弱符号（weak symbol）定义**，使得链接器在找不到具体实现时自动链接到 `sys_ni_syscall`，从而实现“按需启用、默认未实现”的灵活架构。\n\n## 2. 核心功能\n\n### 主要函数\n- **`sys_ni_syscall(void)`**  \n  所有未实现系统调用的默认入口点，返回 `-ENOSYS`。\n\n### 关键宏定义\n- **`COND_SYSCALL(name)`**  \n  展开为 `cond_syscall(sys_##name)`，为指定系统调用名生成弱符号引用。\n- **`COND_SYSCALL_COMPAT(name)`**  \n  展开为 `cond_syscall(compat_sys_##name)`，为 32 位兼容模式下的系统调用生成弱符号引用。\n- **`cond_syscall()`**（由链接器脚本或汇编支持）  \n  实际由链接器处理，将未定义的系统调用符号指向 `sys_ni_syscall`。\n\n## 3. 关键实现\n\n### 未实现系统调用的统一处理\n- 所有未在内核中实际实现的系统调用最终都会跳转到 `sys_ni_syscall()`，该函数仅返回 `-ENOSYS`，实现简洁且安全。\n- 通过 `asmlinkage` 修饰符确保函数使用正确的调用约定（通常为栈传参），与系统调用入口一致。\n\n### 弱符号机制\n- 使用 `COND_SYSCALL(name)` 宏为每个可能未实现的系统调用生成一个弱符号声明。\n- 在链接阶段，若某系统调用（如 `sys_io_setup`）有实际实现，则链接器使用其实现；若无，则自动绑定到 `sys_ni_syscall`。\n- 此机制避免了为每个架构手动维护大量空 stub 函数，提高了代码可维护性。\n\n### 兼容性支持\n- `COND_SYSCALL_COMPAT` 专门处理 32 位兼容层（如 x86_64 上运行 32 位程序）的系统调用，确保兼容模式下未实现的调用同样返回 `-ENOSYS`。\n- 支持架构特定的 syscall wrapper（通过 `CONFIG_ARCH_HAS_SYSCALL_WRAPPER`），允许某些架构自定义 `COND_SYSCALL` 行为。\n\n### 系统调用列表组织\n- 列表严格遵循 `include/uapi/asm-generic/unistd.h` 中的顺序，便于维护一致性。\n- 包含：\n  - 通用系统调用（如 `io_uring_*`, `epoll_*`, `timerfd_*`）\n  - 架构特定调用（如 x86 的 `vm86`、s390 的 `s390_ipc`）\n  - 已废弃但仍被某些架构需要的调用（如 `epoll_create`, `inotify_init`）\n  - 条件编译调用（如 `__ARCH_WANT_SYS_CLONE3` 控制的 `clone3`）\n\n## 4. 依赖关系\n\n### 头文件依赖\n- `<linux/linkage.h>`：提供 `asmlinkage` 宏定义\n- `<linux/errno.h>`：提供 `-ENOSYS` 错误码\n- `<asm/unistd.h>`：包含架构相关的系统调用编号定义\n- `<asm/syscall_wrapper.h>`（条件包含）：允许架构覆盖 `COND_SYSCALL` 宏\n\n### 内核构建系统依赖\n- 依赖链接器脚本（如 `vmlinux.lds`）中的 `__cond_syscall` 段处理弱符号\n- 与 `arch/*/kernel/syscall_table.c` 或等效文件协同工作，后者提供实际系统调用表\n\n### 配置选项依赖\n- `CONFIG_ARCH_HAS_SYSCALL_WRAPPER`：控制是否使用架构自定义 syscall wrapper\n- 各种 `CONFIG_*` 选项（如 `CONFIG_MMU`、`CONFIG_FANOTIFY`）间接影响哪些 `COND_SYSCALL` 条目生效\n\n## 5. 使用场景\n\n### 内核构建时\n- 在编译内核时，若某系统调用未被任何源文件实现（例如因配置选项关闭或架构不支持），链接器自动将其绑定到 `sys_ni_syscall`。\n- 避免链接错误，同时保证系统调用表完整性。\n\n### 用户空间调用未实现 syscall 时\n- 用户程序调用未实现的系统调用（如在不支持 `landlock` 的内核上调用 `landlock_create_ruleset`）。\n- 内核安全返回 `-ENOSYS`，程序可据此进行功能检测或降级处理。\n\n### 架构移植与兼容层\n- 新架构移植时，无需立即实现所有系统调用，未实现部分自动返回 `-ENOSYS`。\n- 32/64 位兼容层（如 x86_64 的 compat 模式）中，未实现的 32 位专用 syscall 同样得到正确处理。\n\n### 废弃 syscall 的平滑过渡\n- 对于已废弃但仍保留在 uAPI 中的系统调用（如 `epoll_create`），通过此机制确保旧程序在新内核上仍能获得明确错误而非崩溃。",
      "similarity": 0.5832824110984802,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/sys_ni.c",
          "start_line": 1,
          "end_line": 19,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "",
            "#include <linux/linkage.h>",
            "#include <linux/errno.h>",
            "",
            "#include <asm/unistd.h>",
            "",
            "#ifdef CONFIG_ARCH_HAS_SYSCALL_WRAPPER",
            "/* Architectures may override COND_SYSCALL and COND_SYSCALL_COMPAT */",
            "#include <asm/syscall_wrapper.h>",
            "#endif /* CONFIG_ARCH_HAS_SYSCALL_WRAPPER */",
            "",
            "/*  we can't #include <linux/syscalls.h> here,",
            "    but tell gcc to not warn with -Wmissing-prototypes  */",
            "asmlinkage long sys_ni_syscall(void);",
            "",
            "/*",
            " * Non-implemented system calls get redirected here.",
            " */"
          ],
          "function_name": null,
          "description": "该代码块声明处理未实现系统调用的入口函数sys_ni_syscall，并包含必要头文件及架构相关兼容性支持，但缺少函数具体实现，上下文不完整",
          "similarity": 0.48388147354125977
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/sys_ni.c",
          "start_line": 20,
          "end_line": 23,
          "content": [
            "asmlinkage long sys_ni_syscall(void)",
            "{",
            "\treturn -ENOSYS;",
            "}"
          ],
          "function_name": "sys_ni_syscall",
          "description": "该函数实现作为默认的未实现系统调用处理程序，始终返回-ENOSYS错误码以指示系统调用不可用",
          "similarity": 0.4395127296447754
        }
      ]
    },
    {
      "source_file": "kernel/rcu/srcutree.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:43:41\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `rcu\\srcutree.c`\n\n---\n\n# `rcu/srcutree.c` 技术文档\n\n## 1. 文件概述\n\n`rcu/srcutree.c` 是 Linux 内核中 **Sleepable Read-Copy Update (SRCU)** 机制的核心实现文件之一。SRCU 是 RCU（Read-Copy Update）的一种变体，专为**允许在读端临界区内睡眠**的场景设计，适用于需要在持有读锁时执行可能阻塞操作（如内存分配、文件 I/O 等）的子系统。\n\n该文件主要负责 SRCU 结构体的动态初始化、层级树（combining tree）构建、每 CPU 数据结构管理，以及与宽限期（grace period）和回调处理相关的底层支持逻辑。它实现了可扩展的、基于树状结构的 SRCU，以支持大规模多核系统下的高效同步。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct srcu_struct`：SRCU 同步域的顶层结构，用户通过它调用 `srcu_read_lock()`、`synchronize_srcu()` 等接口。\n- `struct srcu_data`：每 CPU 数据结构，用于记录本地读端计数、回调链表、宽限期状态等。\n- `struct srcu_node`：SRCU 树的内部节点，用于聚合子节点的宽限期完成状态，减少全局同步开销。\n- `struct srcu_usage`（通过 `ssp->srcu_sup` 指向）：包含 SRCU 实例的共享元数据，如互斥锁、树节点指针、大小状态等。\n\n### 主要函数\n- `init_srcu_struct_data()`：初始化 `srcu_struct` 的每 CPU `srcu_data` 实例。\n- `init_srcu_struct_nodes()`：动态分配并初始化 SRCU 的层级树（`srcu_node` 数组），建立父子关系和 CPU 覆盖范围。\n- `init_srcu_struct_fields()`：初始化 `srcu_struct` 的非静态字段，包括分配 `srcu_usage` 结构、初始化互斥锁等。\n- `srcu_invoke_callbacks()` / `srcu_reschedule()` / `process_srcu()` / `srcu_delay_timer()`：回调处理与延迟调度相关的工作队列和定时器函数（部分在代码片段中声明但未完整定义）。\n\n### 关键宏定义\n- `spin_lock_rcu_node()` 等系列宏：封装对 `srcu_node` 或 `srcu_data` 中自旋锁的安全访问，并插入必要的内存屏障（`smp_mb__after_unlock_lock()`）。\n- `SRCU_SIZING_*` 系列常量与宏：控制 SRCU 实例是否从“小模式”（无树结构）动态转换为“大模式”（带树结构）的策略。\n\n## 3. 关键实现\n\n### 动态树结构初始化\n- `init_srcu_struct_nodes()` 根据系统 CPU 数量和 RCU 几何配置（`rcu_num_lvls`, `num_rcu_lvl`, `levelspread`）动态构建多层 `srcu_node` 树。\n- 叶子层（`level = rcu_num_lvls - 1`）的每个 `srcu_node` 覆盖若干 CPU，每个 CPU 的 `srcu_data->mynode` 指向其对应的叶子节点。\n- 通过 `grplo`/`grphi` 字段记录每个 `srcu_node` 所覆盖的 CPU 范围，`grpmask` 表示该 CPU 在其叶子节点中的位掩码。\n- 初始化时，所有 `srcu_have_cbs[]` 和 `srcu_gp_seq_needed_exp` 被设为特殊值 `SRCU_SNP_INIT_SEQ`（`0x2`），表示无效状态，避免早期误判。\n\n### 大小模式转换策略（SRCU Size Scaling）\n- 支持从轻量级“小模式”（仅每 CPU 计数器）动态升级到可扩展“大模式”（带树结构），以平衡小系统开销与大系统可扩展性。\n- 通过模块参数 `convert_to_big` 控制转换策略：\n  - `0`：永不转换；\n  - `1`：在 `init_srcu_struct()` 时立即转换；\n  - `2`：由 `rcutorture` 测试触发；\n  - `3`（默认）：根据系统 CPU 数量（`big_cpu_lim=128`）自动决定；\n  - `0x1x`：在检测到高锁争用（`small_contention_lim=100` 次/每 jiffy）时转换。\n- `srcu_size_state` 字段跟踪当前模式状态（如 `SRCU_SIZE_SMALL`, `SRCU_SIZE_WAIT_BARRIER`）。\n\n### 安全锁封装与内存序\n- 所有对 `srcu_node` 和 `srcu_data` 中自旋锁的操作均通过宏封装（如 `spin_lock_rcu_node()`）。\n- 这些宏在获取锁后调用 `smp_mb__after_unlock_lock()`，确保后续内存访问不会被重排到锁获取之前，满足 RCU 对内存顺序的严格要求。\n\n### 早期启动支持\n- 使用 `srcu_boot_list` 链表和 `srcu_init_done` 标志支持在内核早期启动阶段（尚无锁机制）注册 SRCU 结构，待初始化完成后批量处理。\n\n## 4. 依赖关系\n\n- **内部依赖**：\n  - `rcu.h`：RCU 通用头文件，包含几何配置（`rcu_num_lvls` 等）和辅助宏。\n  - `rcu_segcblist.h`：提供分段回调链表（`rcu_segcblist`）实现，用于管理 SRCU 回调。\n- **内核子系统依赖**：\n  - `<linux/rcupdate_wait.h>`：提供宽限期等待基础设施。\n  - `<linux/smp.h>` / `<linux/preempt.h>`：SMP 和抢占控制原语。\n  - `<linux/workqueue.h>` / `<linux/timer.h>`：用于回调延迟处理（通过 `work_struct` 和 `timer_list`）。\n  - `<linux/slab.h>`：动态内存分配（`kzalloc`, `kcalloc`）。\n- **用户**：被需要睡眠读端的子系统使用，如设备驱动、文件系统（如 Btrfs）、虚拟化（KVM）等。\n\n## 5. 使用场景\n\n- **需要在 RCU 读端临界区内睡眠的场景**：标准 RCU 禁止在 `rcu_read_lock()`/`rcu_read_unlock()` 之间睡眠，而 SRCU 允许。\n- **高并发读端 + 低频同步**：适用于读操作远多于写操作（调用 `synchronize_srcu()`）的场景，如配置更新、模块卸载检查。\n- **大规模 NUMA 系统**：通过树状结构减少宽限期同步的全局开销，提升可扩展性。\n- **动态资源管理**：如内核模块动态创建/销毁 SRCU 域，或子系统根据负载自动调整同步策略（通过大小模式转换）。",
      "similarity": 0.5795430541038513,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/rcu/srcutree.c",
          "start_line": 644,
          "end_line": 749,
          "content": [
            "void cleanup_srcu_struct(struct srcu_struct *ssp)",
            "{",
            "\tint cpu;",
            "\tstruct srcu_usage *sup = ssp->srcu_sup;",
            "",
            "\tif (WARN_ON(!srcu_get_delay(ssp)))",
            "\t\treturn; /* Just leak it! */",
            "\tif (WARN_ON(srcu_readers_active(ssp)))",
            "\t\treturn; /* Just leak it! */",
            "\tflush_delayed_work(&sup->work);",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tstruct srcu_data *sdp = per_cpu_ptr(ssp->sda, cpu);",
            "",
            "\t\tdel_timer_sync(&sdp->delay_work);",
            "\t\tflush_work(&sdp->work);",
            "\t\tif (WARN_ON(rcu_segcblist_n_cbs(&sdp->srcu_cblist)))",
            "\t\t\treturn; /* Forgot srcu_barrier(), so just leak it! */",
            "\t}",
            "\tif (WARN_ON(rcu_seq_state(READ_ONCE(sup->srcu_gp_seq)) != SRCU_STATE_IDLE) ||",
            "\t    WARN_ON(rcu_seq_current(&sup->srcu_gp_seq) != sup->srcu_gp_seq_needed) ||",
            "\t    WARN_ON(srcu_readers_active(ssp))) {",
            "\t\tpr_info(\"%s: Active srcu_struct %p read state: %d gp state: %lu/%lu\\n\",",
            "\t\t\t__func__, ssp, rcu_seq_state(READ_ONCE(sup->srcu_gp_seq)),",
            "\t\t\trcu_seq_current(&sup->srcu_gp_seq), sup->srcu_gp_seq_needed);",
            "\t\treturn; /* Caller forgot to stop doing call_srcu()? */",
            "\t}",
            "\tkfree(sup->node);",
            "\tsup->node = NULL;",
            "\tsup->srcu_size_state = SRCU_SIZE_SMALL;",
            "\tif (!sup->sda_is_static) {",
            "\t\tfree_percpu(ssp->sda);",
            "\t\tssp->sda = NULL;",
            "\t\tkfree(sup);",
            "\t\tssp->srcu_sup = NULL;",
            "\t}",
            "}",
            "void srcu_check_nmi_safety(struct srcu_struct *ssp, bool nmi_safe)",
            "{",
            "\tint nmi_safe_mask = 1 << nmi_safe;",
            "\tint old_nmi_safe_mask;",
            "\tstruct srcu_data *sdp;",
            "",
            "\t/* NMI-unsafe use in NMI is a bad sign */",
            "\tWARN_ON_ONCE(!nmi_safe && in_nmi());",
            "\tsdp = raw_cpu_ptr(ssp->sda);",
            "\told_nmi_safe_mask = READ_ONCE(sdp->srcu_nmi_safety);",
            "\tif (!old_nmi_safe_mask) {",
            "\t\tWRITE_ONCE(sdp->srcu_nmi_safety, nmi_safe_mask);",
            "\t\treturn;",
            "\t}",
            "\tWARN_ONCE(old_nmi_safe_mask != nmi_safe_mask, \"CPU %d old state %d new state %d\\n\", sdp->cpu, old_nmi_safe_mask, nmi_safe_mask);",
            "}",
            "int __srcu_read_lock(struct srcu_struct *ssp)",
            "{",
            "\tint idx;",
            "",
            "\tidx = READ_ONCE(ssp->srcu_idx) & 0x1;",
            "\tthis_cpu_inc(ssp->sda->srcu_lock_count[idx].counter);",
            "\tsmp_mb(); /* B */  /* Avoid leaking the critical section. */",
            "\treturn idx;",
            "}",
            "void __srcu_read_unlock(struct srcu_struct *ssp, int idx)",
            "{",
            "\tsmp_mb(); /* C */  /* Avoid leaking the critical section. */",
            "\tthis_cpu_inc(ssp->sda->srcu_unlock_count[idx].counter);",
            "}",
            "int __srcu_read_lock_nmisafe(struct srcu_struct *ssp)",
            "{",
            "\tint idx;",
            "\tstruct srcu_data *sdp = raw_cpu_ptr(ssp->sda);",
            "",
            "\tidx = READ_ONCE(ssp->srcu_idx) & 0x1;",
            "\tatomic_long_inc(&sdp->srcu_lock_count[idx]);",
            "\tsmp_mb__after_atomic(); /* B */  /* Avoid leaking the critical section. */",
            "\treturn idx;",
            "}",
            "void __srcu_read_unlock_nmisafe(struct srcu_struct *ssp, int idx)",
            "{",
            "\tstruct srcu_data *sdp = raw_cpu_ptr(ssp->sda);",
            "",
            "\tsmp_mb__before_atomic(); /* C */  /* Avoid leaking the critical section. */",
            "\tatomic_long_inc(&sdp->srcu_unlock_count[idx]);",
            "}",
            "static void srcu_gp_start(struct srcu_struct *ssp)",
            "{",
            "\tstruct srcu_data *sdp;",
            "\tint state;",
            "",
            "\tif (smp_load_acquire(&ssp->srcu_sup->srcu_size_state) < SRCU_SIZE_WAIT_BARRIER)",
            "\t\tsdp = per_cpu_ptr(ssp->sda, get_boot_cpu_id());",
            "\telse",
            "\t\tsdp = this_cpu_ptr(ssp->sda);",
            "\tlockdep_assert_held(&ACCESS_PRIVATE(ssp->srcu_sup, lock));",
            "\tWARN_ON_ONCE(ULONG_CMP_GE(ssp->srcu_sup->srcu_gp_seq, ssp->srcu_sup->srcu_gp_seq_needed));",
            "\tspin_lock_rcu_node(sdp);  /* Interrupts already disabled. */",
            "\trcu_segcblist_advance(&sdp->srcu_cblist,",
            "\t\t\t      rcu_seq_current(&ssp->srcu_sup->srcu_gp_seq));",
            "\tWARN_ON_ONCE(!rcu_segcblist_segempty(&sdp->srcu_cblist, RCU_NEXT_TAIL));",
            "\tspin_unlock_rcu_node(sdp);  /* Interrupts remain disabled. */",
            "\tWRITE_ONCE(ssp->srcu_sup->srcu_gp_start, jiffies);",
            "\tWRITE_ONCE(ssp->srcu_sup->srcu_n_exp_nodelay, 0);",
            "\tsmp_mb(); /* Order prior store to ->srcu_gp_seq_needed vs. GP start. */",
            "\trcu_seq_start(&ssp->srcu_sup->srcu_gp_seq);",
            "\tstate = rcu_seq_state(ssp->srcu_sup->srcu_gp_seq);",
            "\tWARN_ON_ONCE(state != SRCU_STATE_SCAN1);",
            "}"
          ],
          "function_name": "cleanup_srcu_struct, srcu_check_nmi_safety, __srcu_read_lock, __srcu_read_unlock, __srcu_read_lock_nmisafe, __srcu_read_unlock_nmisafe, srcu_gp_start",
          "description": "实现SRCU读写锁操作、NMI安全性检查及垃圾回收周期启动，负责资源清理与状态同步管理。",
          "similarity": 0.5294935703277588
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/rcu/srcutree.c",
          "start_line": 122,
          "end_line": 262,
          "content": [
            "static void init_srcu_struct_data(struct srcu_struct *ssp)",
            "{",
            "\tint cpu;",
            "\tstruct srcu_data *sdp;",
            "",
            "\t/*",
            "\t * Initialize the per-CPU srcu_data array, which feeds into the",
            "\t * leaves of the srcu_node tree.",
            "\t */",
            "\tWARN_ON_ONCE(ARRAY_SIZE(sdp->srcu_lock_count) !=",
            "\t\t     ARRAY_SIZE(sdp->srcu_unlock_count));",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tsdp = per_cpu_ptr(ssp->sda, cpu);",
            "\t\tspin_lock_init(&ACCESS_PRIVATE(sdp, lock));",
            "\t\trcu_segcblist_init(&sdp->srcu_cblist);",
            "\t\tsdp->srcu_cblist_invoking = false;",
            "\t\tsdp->srcu_gp_seq_needed = ssp->srcu_sup->srcu_gp_seq;",
            "\t\tsdp->srcu_gp_seq_needed_exp = ssp->srcu_sup->srcu_gp_seq;",
            "\t\tsdp->mynode = NULL;",
            "\t\tsdp->cpu = cpu;",
            "\t\tINIT_WORK(&sdp->work, srcu_invoke_callbacks);",
            "\t\ttimer_setup(&sdp->delay_work, srcu_delay_timer, 0);",
            "\t\tsdp->ssp = ssp;",
            "\t}",
            "}",
            "static inline bool srcu_invl_snp_seq(unsigned long s)",
            "{",
            "\treturn s == SRCU_SNP_INIT_SEQ;",
            "}",
            "static bool init_srcu_struct_nodes(struct srcu_struct *ssp, gfp_t gfp_flags)",
            "{",
            "\tint cpu;",
            "\tint i;",
            "\tint level = 0;",
            "\tint levelspread[RCU_NUM_LVLS];",
            "\tstruct srcu_data *sdp;",
            "\tstruct srcu_node *snp;",
            "\tstruct srcu_node *snp_first;",
            "",
            "\t/* Initialize geometry if it has not already been initialized. */",
            "\trcu_init_geometry();",
            "\tssp->srcu_sup->node = kcalloc(rcu_num_nodes, sizeof(*ssp->srcu_sup->node), gfp_flags);",
            "\tif (!ssp->srcu_sup->node)",
            "\t\treturn false;",
            "",
            "\t/* Work out the overall tree geometry. */",
            "\tssp->srcu_sup->level[0] = &ssp->srcu_sup->node[0];",
            "\tfor (i = 1; i < rcu_num_lvls; i++)",
            "\t\tssp->srcu_sup->level[i] = ssp->srcu_sup->level[i - 1] + num_rcu_lvl[i - 1];",
            "\trcu_init_levelspread(levelspread, num_rcu_lvl);",
            "",
            "\t/* Each pass through this loop initializes one srcu_node structure. */",
            "\tsrcu_for_each_node_breadth_first(ssp, snp) {",
            "\t\tspin_lock_init(&ACCESS_PRIVATE(snp, lock));",
            "\t\tWARN_ON_ONCE(ARRAY_SIZE(snp->srcu_have_cbs) !=",
            "\t\t\t     ARRAY_SIZE(snp->srcu_data_have_cbs));",
            "\t\tfor (i = 0; i < ARRAY_SIZE(snp->srcu_have_cbs); i++) {",
            "\t\t\tsnp->srcu_have_cbs[i] = SRCU_SNP_INIT_SEQ;",
            "\t\t\tsnp->srcu_data_have_cbs[i] = 0;",
            "\t\t}",
            "\t\tsnp->srcu_gp_seq_needed_exp = SRCU_SNP_INIT_SEQ;",
            "\t\tsnp->grplo = -1;",
            "\t\tsnp->grphi = -1;",
            "\t\tif (snp == &ssp->srcu_sup->node[0]) {",
            "\t\t\t/* Root node, special case. */",
            "\t\t\tsnp->srcu_parent = NULL;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\t/* Non-root node. */",
            "\t\tif (snp == ssp->srcu_sup->level[level + 1])",
            "\t\t\tlevel++;",
            "\t\tsnp->srcu_parent = ssp->srcu_sup->level[level - 1] +",
            "\t\t\t\t   (snp - ssp->srcu_sup->level[level]) /",
            "\t\t\t\t   levelspread[level - 1];",
            "\t}",
            "",
            "\t/*",
            "\t * Initialize the per-CPU srcu_data array, which feeds into the",
            "\t * leaves of the srcu_node tree.",
            "\t */",
            "\tlevel = rcu_num_lvls - 1;",
            "\tsnp_first = ssp->srcu_sup->level[level];",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tsdp = per_cpu_ptr(ssp->sda, cpu);",
            "\t\tsdp->mynode = &snp_first[cpu / levelspread[level]];",
            "\t\tfor (snp = sdp->mynode; snp != NULL; snp = snp->srcu_parent) {",
            "\t\t\tif (snp->grplo < 0)",
            "\t\t\t\tsnp->grplo = cpu;",
            "\t\t\tsnp->grphi = cpu;",
            "\t\t}",
            "\t\tsdp->grpmask = 1UL << (cpu - sdp->mynode->grplo);",
            "\t}",
            "\tsmp_store_release(&ssp->srcu_sup->srcu_size_state, SRCU_SIZE_WAIT_BARRIER);",
            "\treturn true;",
            "}",
            "static int init_srcu_struct_fields(struct srcu_struct *ssp, bool is_static)",
            "{",
            "\tif (!is_static)",
            "\t\tssp->srcu_sup = kzalloc(sizeof(*ssp->srcu_sup), GFP_KERNEL);",
            "\tif (!ssp->srcu_sup)",
            "\t\treturn -ENOMEM;",
            "\tif (!is_static)",
            "\t\tspin_lock_init(&ACCESS_PRIVATE(ssp->srcu_sup, lock));",
            "\tssp->srcu_sup->srcu_size_state = SRCU_SIZE_SMALL;",
            "\tssp->srcu_sup->node = NULL;",
            "\tmutex_init(&ssp->srcu_sup->srcu_cb_mutex);",
            "\tmutex_init(&ssp->srcu_sup->srcu_gp_mutex);",
            "\tssp->srcu_idx = 0;",
            "\tssp->srcu_sup->srcu_gp_seq = 0;",
            "\tssp->srcu_sup->srcu_barrier_seq = 0;",
            "\tmutex_init(&ssp->srcu_sup->srcu_barrier_mutex);",
            "\tatomic_set(&ssp->srcu_sup->srcu_barrier_cpu_cnt, 0);",
            "\tINIT_DELAYED_WORK(&ssp->srcu_sup->work, process_srcu);",
            "\tssp->srcu_sup->sda_is_static = is_static;",
            "\tif (!is_static)",
            "\t\tssp->sda = alloc_percpu(struct srcu_data);",
            "\tif (!ssp->sda) {",
            "\t\tif (!is_static)",
            "\t\t\tkfree(ssp->srcu_sup);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "\tinit_srcu_struct_data(ssp);",
            "\tssp->srcu_sup->srcu_gp_seq_needed_exp = 0;",
            "\tssp->srcu_sup->srcu_last_gp_end = ktime_get_mono_fast_ns();",
            "\tif (READ_ONCE(ssp->srcu_sup->srcu_size_state) == SRCU_SIZE_SMALL && SRCU_SIZING_IS_INIT()) {",
            "\t\tif (!init_srcu_struct_nodes(ssp, GFP_ATOMIC)) {",
            "\t\t\tif (!ssp->srcu_sup->sda_is_static) {",
            "\t\t\t\tfree_percpu(ssp->sda);",
            "\t\t\t\tssp->sda = NULL;",
            "\t\t\t\tkfree(ssp->srcu_sup);",
            "\t\t\t\treturn -ENOMEM;",
            "\t\t\t}",
            "\t\t} else {",
            "\t\t\tWRITE_ONCE(ssp->srcu_sup->srcu_size_state, SRCU_SIZE_BIG);",
            "\t\t}",
            "\t}",
            "\tssp->srcu_sup->srcu_ssp = ssp;",
            "\tsmp_store_release(&ssp->srcu_sup->srcu_gp_seq_needed, 0); /* Init done. */",
            "\treturn 0;",
            "}"
          ],
          "function_name": "init_srcu_struct_data, srcu_invl_snp_seq, init_srcu_struct_nodes, init_srcu_struct_fields",
          "description": "初始化SRCU结构体的底层数据结构，包括per-CPU数据、节点树层级关系及回调工作队列的创建。",
          "similarity": 0.5138054490089417
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/rcu/srcutree.c",
          "start_line": 285,
          "end_line": 393,
          "content": [
            "int __init_srcu_struct(struct srcu_struct *ssp, const char *name,",
            "\t\t       struct lock_class_key *key)",
            "{",
            "\t/* Don't re-initialize a lock while it is held. */",
            "\tdebug_check_no_locks_freed((void *)ssp, sizeof(*ssp));",
            "\tlockdep_init_map(&ssp->dep_map, name, key, 0);",
            "\treturn init_srcu_struct_fields(ssp, false);",
            "}",
            "int init_srcu_struct(struct srcu_struct *ssp)",
            "{",
            "\treturn init_srcu_struct_fields(ssp, false);",
            "}",
            "static void __srcu_transition_to_big(struct srcu_struct *ssp)",
            "{",
            "\tlockdep_assert_held(&ACCESS_PRIVATE(ssp->srcu_sup, lock));",
            "\tsmp_store_release(&ssp->srcu_sup->srcu_size_state, SRCU_SIZE_ALLOC);",
            "}",
            "static void srcu_transition_to_big(struct srcu_struct *ssp)",
            "{",
            "\tunsigned long flags;",
            "",
            "\t/* Double-checked locking on ->srcu_size-state. */",
            "\tif (smp_load_acquire(&ssp->srcu_sup->srcu_size_state) != SRCU_SIZE_SMALL)",
            "\t\treturn;",
            "\tspin_lock_irqsave_rcu_node(ssp->srcu_sup, flags);",
            "\tif (smp_load_acquire(&ssp->srcu_sup->srcu_size_state) != SRCU_SIZE_SMALL) {",
            "\t\tspin_unlock_irqrestore_rcu_node(ssp->srcu_sup, flags);",
            "\t\treturn;",
            "\t}",
            "\t__srcu_transition_to_big(ssp);",
            "\tspin_unlock_irqrestore_rcu_node(ssp->srcu_sup, flags);",
            "}",
            "static void spin_lock_irqsave_check_contention(struct srcu_struct *ssp)",
            "{",
            "\tunsigned long j;",
            "",
            "\tif (!SRCU_SIZING_IS_CONTEND() || ssp->srcu_sup->srcu_size_state)",
            "\t\treturn;",
            "\tj = jiffies;",
            "\tif (ssp->srcu_sup->srcu_size_jiffies != j) {",
            "\t\tssp->srcu_sup->srcu_size_jiffies = j;",
            "\t\tssp->srcu_sup->srcu_n_lock_retries = 0;",
            "\t}",
            "\tif (++ssp->srcu_sup->srcu_n_lock_retries <= small_contention_lim)",
            "\t\treturn;",
            "\t__srcu_transition_to_big(ssp);",
            "}",
            "static void spin_lock_irqsave_sdp_contention(struct srcu_data *sdp, unsigned long *flags)",
            "{",
            "\tstruct srcu_struct *ssp = sdp->ssp;",
            "",
            "\tif (spin_trylock_irqsave_rcu_node(sdp, *flags))",
            "\t\treturn;",
            "\tspin_lock_irqsave_rcu_node(ssp->srcu_sup, *flags);",
            "\tspin_lock_irqsave_check_contention(ssp);",
            "\tspin_unlock_irqrestore_rcu_node(ssp->srcu_sup, *flags);",
            "\tspin_lock_irqsave_rcu_node(sdp, *flags);",
            "}",
            "static void spin_lock_irqsave_ssp_contention(struct srcu_struct *ssp, unsigned long *flags)",
            "{",
            "\tif (spin_trylock_irqsave_rcu_node(ssp->srcu_sup, *flags))",
            "\t\treturn;",
            "\tspin_lock_irqsave_rcu_node(ssp->srcu_sup, *flags);",
            "\tspin_lock_irqsave_check_contention(ssp);",
            "}",
            "static void check_init_srcu_struct(struct srcu_struct *ssp)",
            "{",
            "\tunsigned long flags;",
            "",
            "\t/* The smp_load_acquire() pairs with the smp_store_release(). */",
            "\tif (!rcu_seq_state(smp_load_acquire(&ssp->srcu_sup->srcu_gp_seq_needed))) /*^^^*/",
            "\t\treturn; /* Already initialized. */",
            "\tspin_lock_irqsave_rcu_node(ssp->srcu_sup, flags);",
            "\tif (!rcu_seq_state(ssp->srcu_sup->srcu_gp_seq_needed)) {",
            "\t\tspin_unlock_irqrestore_rcu_node(ssp->srcu_sup, flags);",
            "\t\treturn;",
            "\t}",
            "\tinit_srcu_struct_fields(ssp, true);",
            "\tspin_unlock_irqrestore_rcu_node(ssp->srcu_sup, flags);",
            "}",
            "static unsigned long srcu_readers_lock_idx(struct srcu_struct *ssp, int idx)",
            "{",
            "\tint cpu;",
            "\tunsigned long sum = 0;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tstruct srcu_data *cpuc = per_cpu_ptr(ssp->sda, cpu);",
            "",
            "\t\tsum += atomic_long_read(&cpuc->srcu_lock_count[idx]);",
            "\t}",
            "\treturn sum;",
            "}",
            "static unsigned long srcu_readers_unlock_idx(struct srcu_struct *ssp, int idx)",
            "{",
            "\tint cpu;",
            "\tunsigned long mask = 0;",
            "\tunsigned long sum = 0;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tstruct srcu_data *cpuc = per_cpu_ptr(ssp->sda, cpu);",
            "",
            "\t\tsum += atomic_long_read(&cpuc->srcu_unlock_count[idx]);",
            "\t\tif (IS_ENABLED(CONFIG_PROVE_RCU))",
            "\t\t\tmask = mask | READ_ONCE(cpuc->srcu_nmi_safety);",
            "\t}",
            "\tWARN_ONCE(IS_ENABLED(CONFIG_PROVE_RCU) && (mask & (mask >> 1)),",
            "\t\t  \"Mixed NMI-safe readers for srcu_struct at %ps.\\n\", ssp);",
            "\treturn sum;",
            "}"
          ],
          "function_name": "__init_srcu_struct, init_srcu_struct, __srcu_transition_to_big, srcu_transition_to_big, spin_lock_irqsave_check_contention, spin_lock_irqsave_sdp_contention, spin_lock_irqsave_ssp_contention, check_init_srcu_struct, srcu_readers_lock_idx, srcu_readers_unlock_idx",
          "description": "实现SRCU结构体的动态扩展逻辑，通过竞争检测和锁状态分析决定是否升级到大尺寸结构。",
          "similarity": 0.503813624382019
        },
        {
          "chunk_id": 9,
          "file_path": "kernel/rcu/srcutree.c",
          "start_line": 1409,
          "end_line": 1564,
          "content": [
            "void synchronize_srcu_expedited(struct srcu_struct *ssp)",
            "{",
            "\t__synchronize_srcu(ssp, rcu_gp_is_normal());",
            "}",
            "void synchronize_srcu(struct srcu_struct *ssp)",
            "{",
            "\tif (srcu_might_be_idle(ssp) || rcu_gp_is_expedited())",
            "\t\tsynchronize_srcu_expedited(ssp);",
            "\telse",
            "\t\t__synchronize_srcu(ssp, true);",
            "}",
            "unsigned long get_state_synchronize_srcu(struct srcu_struct *ssp)",
            "{",
            "\t// Any prior manipulation of SRCU-protected data must happen",
            "\t// before the load from ->srcu_gp_seq.",
            "\tsmp_mb();",
            "\treturn rcu_seq_snap(&ssp->srcu_sup->srcu_gp_seq);",
            "}",
            "unsigned long start_poll_synchronize_srcu(struct srcu_struct *ssp)",
            "{",
            "\treturn srcu_gp_start_if_needed(ssp, NULL, true);",
            "}",
            "bool poll_state_synchronize_srcu(struct srcu_struct *ssp, unsigned long cookie)",
            "{",
            "\tif (!rcu_seq_done(&ssp->srcu_sup->srcu_gp_seq, cookie))",
            "\t\treturn false;",
            "\t// Ensure that the end of the SRCU grace period happens before",
            "\t// any subsequent code that the caller might execute.",
            "\tsmp_mb(); // ^^^",
            "\treturn true;",
            "}",
            "static void srcu_barrier_cb(struct rcu_head *rhp)",
            "{",
            "\tstruct srcu_data *sdp;",
            "\tstruct srcu_struct *ssp;",
            "",
            "\tsdp = container_of(rhp, struct srcu_data, srcu_barrier_head);",
            "\tssp = sdp->ssp;",
            "\tif (atomic_dec_and_test(&ssp->srcu_sup->srcu_barrier_cpu_cnt))",
            "\t\tcomplete(&ssp->srcu_sup->srcu_barrier_completion);",
            "}",
            "static void srcu_barrier_one_cpu(struct srcu_struct *ssp, struct srcu_data *sdp)",
            "{",
            "\tspin_lock_irq_rcu_node(sdp);",
            "\tatomic_inc(&ssp->srcu_sup->srcu_barrier_cpu_cnt);",
            "\tsdp->srcu_barrier_head.func = srcu_barrier_cb;",
            "\tdebug_rcu_head_queue(&sdp->srcu_barrier_head);",
            "\tif (!rcu_segcblist_entrain(&sdp->srcu_cblist,",
            "\t\t\t\t   &sdp->srcu_barrier_head)) {",
            "\t\tdebug_rcu_head_unqueue(&sdp->srcu_barrier_head);",
            "\t\tatomic_dec(&ssp->srcu_sup->srcu_barrier_cpu_cnt);",
            "\t}",
            "\tspin_unlock_irq_rcu_node(sdp);",
            "}",
            "void srcu_barrier(struct srcu_struct *ssp)",
            "{",
            "\tint cpu;",
            "\tint idx;",
            "\tunsigned long s = rcu_seq_snap(&ssp->srcu_sup->srcu_barrier_seq);",
            "",
            "\tcheck_init_srcu_struct(ssp);",
            "\tmutex_lock(&ssp->srcu_sup->srcu_barrier_mutex);",
            "\tif (rcu_seq_done(&ssp->srcu_sup->srcu_barrier_seq, s)) {",
            "\t\tsmp_mb(); /* Force ordering following return. */",
            "\t\tmutex_unlock(&ssp->srcu_sup->srcu_barrier_mutex);",
            "\t\treturn; /* Someone else did our work for us. */",
            "\t}",
            "\trcu_seq_start(&ssp->srcu_sup->srcu_barrier_seq);",
            "\tinit_completion(&ssp->srcu_sup->srcu_barrier_completion);",
            "",
            "\t/* Initial count prevents reaching zero until all CBs are posted. */",
            "\tatomic_set(&ssp->srcu_sup->srcu_barrier_cpu_cnt, 1);",
            "",
            "\tidx = __srcu_read_lock_nmisafe(ssp);",
            "\tif (smp_load_acquire(&ssp->srcu_sup->srcu_size_state) < SRCU_SIZE_WAIT_BARRIER)",
            "\t\tsrcu_barrier_one_cpu(ssp, per_cpu_ptr(ssp->sda,\tget_boot_cpu_id()));",
            "\telse",
            "\t\tfor_each_possible_cpu(cpu)",
            "\t\t\tsrcu_barrier_one_cpu(ssp, per_cpu_ptr(ssp->sda, cpu));",
            "\t__srcu_read_unlock_nmisafe(ssp, idx);",
            "",
            "\t/* Remove the initial count, at which point reaching zero can happen. */",
            "\tif (atomic_dec_and_test(&ssp->srcu_sup->srcu_barrier_cpu_cnt))",
            "\t\tcomplete(&ssp->srcu_sup->srcu_barrier_completion);",
            "\twait_for_completion(&ssp->srcu_sup->srcu_barrier_completion);",
            "",
            "\trcu_seq_end(&ssp->srcu_sup->srcu_barrier_seq);",
            "\tmutex_unlock(&ssp->srcu_sup->srcu_barrier_mutex);",
            "}",
            "unsigned long srcu_batches_completed(struct srcu_struct *ssp)",
            "{",
            "\treturn READ_ONCE(ssp->srcu_idx);",
            "}",
            "static void srcu_advance_state(struct srcu_struct *ssp)",
            "{",
            "\tint idx;",
            "",
            "\tmutex_lock(&ssp->srcu_sup->srcu_gp_mutex);",
            "",
            "\t/*",
            "\t * Because readers might be delayed for an extended period after",
            "\t * fetching ->srcu_idx for their index, at any point in time there",
            "\t * might well be readers using both idx=0 and idx=1.  We therefore",
            "\t * need to wait for readers to clear from both index values before",
            "\t * invoking a callback.",
            "\t *",
            "\t * The load-acquire ensures that we see the accesses performed",
            "\t * by the prior grace period.",
            "\t */",
            "\tidx = rcu_seq_state(smp_load_acquire(&ssp->srcu_sup->srcu_gp_seq)); /* ^^^ */",
            "\tif (idx == SRCU_STATE_IDLE) {",
            "\t\tspin_lock_irq_rcu_node(ssp->srcu_sup);",
            "\t\tif (ULONG_CMP_GE(ssp->srcu_sup->srcu_gp_seq, ssp->srcu_sup->srcu_gp_seq_needed)) {",
            "\t\t\tWARN_ON_ONCE(rcu_seq_state(ssp->srcu_sup->srcu_gp_seq));",
            "\t\t\tspin_unlock_irq_rcu_node(ssp->srcu_sup);",
            "\t\t\tmutex_unlock(&ssp->srcu_sup->srcu_gp_mutex);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\tidx = rcu_seq_state(READ_ONCE(ssp->srcu_sup->srcu_gp_seq));",
            "\t\tif (idx == SRCU_STATE_IDLE)",
            "\t\t\tsrcu_gp_start(ssp);",
            "\t\tspin_unlock_irq_rcu_node(ssp->srcu_sup);",
            "\t\tif (idx != SRCU_STATE_IDLE) {",
            "\t\t\tmutex_unlock(&ssp->srcu_sup->srcu_gp_mutex);",
            "\t\t\treturn; /* Someone else started the grace period. */",
            "\t\t}",
            "\t}",
            "",
            "\tif (rcu_seq_state(READ_ONCE(ssp->srcu_sup->srcu_gp_seq)) == SRCU_STATE_SCAN1) {",
            "\t\tidx = 1 ^ (ssp->srcu_idx & 1);",
            "\t\tif (!try_check_zero(ssp, idx, 1)) {",
            "\t\t\tmutex_unlock(&ssp->srcu_sup->srcu_gp_mutex);",
            "\t\t\treturn; /* readers present, retry later. */",
            "\t\t}",
            "\t\tsrcu_flip(ssp);",
            "\t\tspin_lock_irq_rcu_node(ssp->srcu_sup);",
            "\t\trcu_seq_set_state(&ssp->srcu_sup->srcu_gp_seq, SRCU_STATE_SCAN2);",
            "\t\tssp->srcu_sup->srcu_n_exp_nodelay = 0;",
            "\t\tspin_unlock_irq_rcu_node(ssp->srcu_sup);",
            "\t}",
            "",
            "\tif (rcu_seq_state(READ_ONCE(ssp->srcu_sup->srcu_gp_seq)) == SRCU_STATE_SCAN2) {",
            "",
            "\t\t/*",
            "\t\t * SRCU read-side critical sections are normally short,",
            "\t\t * so check at least twice in quick succession after a flip.",
            "\t\t */",
            "\t\tidx = 1 ^ (ssp->srcu_idx & 1);",
            "\t\tif (!try_check_zero(ssp, idx, 2)) {",
            "\t\t\tmutex_unlock(&ssp->srcu_sup->srcu_gp_mutex);",
            "\t\t\treturn; /* readers present, retry later. */",
            "\t\t}",
            "\t\tssp->srcu_sup->srcu_n_exp_nodelay = 0;",
            "\t\tsrcu_gp_end(ssp);  /* Releases ->srcu_gp_mutex. */",
            "\t}",
            "}"
          ],
          "function_name": "synchronize_srcu_expedited, synchronize_srcu, get_state_synchronize_srcu, start_poll_synchronize_srcu, poll_state_synchronize_srcu, srcu_barrier_cb, srcu_barrier_one_cpu, srcu_barrier, srcu_batches_completed, srcu_advance_state",
          "description": "实现SRCU同步机制，包含barrier操作、状态检查及完成通知，确保所有回调处理完成后才继续执行。",
          "similarity": 0.502426028251648
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/rcu/srcutree.c",
          "start_line": 1079,
          "end_line": 1180,
          "content": [
            "static bool try_check_zero(struct srcu_struct *ssp, int idx, int trycount)",
            "{",
            "\tunsigned long curdelay;",
            "",
            "\tcurdelay = !srcu_get_delay(ssp);",
            "",
            "\tfor (;;) {",
            "\t\tif (srcu_readers_active_idx_check(ssp, idx))",
            "\t\t\treturn true;",
            "\t\tif ((--trycount + curdelay) <= 0)",
            "\t\t\treturn false;",
            "\t\tudelay(srcu_retry_check_delay);",
            "\t}",
            "}",
            "static void srcu_flip(struct srcu_struct *ssp)",
            "{",
            "\t/*",
            "\t * Because the flip of ->srcu_idx is executed only if the",
            "\t * preceding call to srcu_readers_active_idx_check() found that",
            "\t * the ->srcu_unlock_count[] and ->srcu_lock_count[] sums matched",
            "\t * and because that summing uses atomic_long_read(), there is",
            "\t * ordering due to a control dependency between that summing and",
            "\t * the WRITE_ONCE() in this call to srcu_flip().  This ordering",
            "\t * ensures that if this updater saw a given reader's increment from",
            "\t * __srcu_read_lock(), that reader was using a value of ->srcu_idx",
            "\t * from before the previous call to srcu_flip(), which should be",
            "\t * quite rare.  This ordering thus helps forward progress because",
            "\t * the grace period could otherwise be delayed by additional",
            "\t * calls to __srcu_read_lock() using that old (soon to be new)",
            "\t * value of ->srcu_idx.",
            "\t *",
            "\t * This sum-equality check and ordering also ensures that if",
            "\t * a given call to __srcu_read_lock() uses the new value of",
            "\t * ->srcu_idx, this updater's earlier scans cannot have seen",
            "\t * that reader's increments, which is all to the good, because",
            "\t * this grace period need not wait on that reader.  After all,",
            "\t * if those earlier scans had seen that reader, there would have",
            "\t * been a sum mismatch and this code would not be reached.",
            "\t *",
            "\t * This means that the following smp_mb() is redundant, but",
            "\t * it stays until either (1) Compilers learn about this sort of",
            "\t * control dependency or (2) Some production workload running on",
            "\t * a production system is unduly delayed by this slowpath smp_mb().",
            "\t */",
            "\tsmp_mb(); /* E */  /* Pairs with B and C. */",
            "",
            "\tWRITE_ONCE(ssp->srcu_idx, ssp->srcu_idx + 1); // Flip the counter.",
            "",
            "\t/*",
            "\t * Ensure that if the updater misses an __srcu_read_unlock()",
            "\t * increment, that task's __srcu_read_lock() following its next",
            "\t * __srcu_read_lock() or __srcu_read_unlock() will see the above",
            "\t * counter update.  Note that both this memory barrier and the",
            "\t * one in srcu_readers_active_idx_check() provide the guarantee",
            "\t * for __srcu_read_lock().",
            "\t */",
            "\tsmp_mb(); /* D */  /* Pairs with C. */",
            "}",
            "static bool srcu_might_be_idle(struct srcu_struct *ssp)",
            "{",
            "\tunsigned long curseq;",
            "\tunsigned long flags;",
            "\tstruct srcu_data *sdp;",
            "\tunsigned long t;",
            "\tunsigned long tlast;",
            "",
            "\tcheck_init_srcu_struct(ssp);",
            "\t/* If the local srcu_data structure has callbacks, not idle.  */",
            "\tsdp = raw_cpu_ptr(ssp->sda);",
            "\tspin_lock_irqsave_rcu_node(sdp, flags);",
            "\tif (rcu_segcblist_pend_cbs(&sdp->srcu_cblist)) {",
            "\t\tspin_unlock_irqrestore_rcu_node(sdp, flags);",
            "\t\treturn false; /* Callbacks already present, so not idle. */",
            "\t}",
            "\tspin_unlock_irqrestore_rcu_node(sdp, flags);",
            "",
            "\t/*",
            "\t * No local callbacks, so probabilistically probe global state.",
            "\t * Exact information would require acquiring locks, which would",
            "\t * kill scalability, hence the probabilistic nature of the probe.",
            "\t */",
            "",
            "\t/* First, see if enough time has passed since the last GP. */",
            "\tt = ktime_get_mono_fast_ns();",
            "\ttlast = READ_ONCE(ssp->srcu_sup->srcu_last_gp_end);",
            "\tif (exp_holdoff == 0 ||",
            "\t    time_in_range_open(t, tlast, tlast + exp_holdoff))",
            "\t\treturn false; /* Too soon after last GP. */",
            "",
            "\t/* Next, check for probable idleness. */",
            "\tcurseq = rcu_seq_current(&ssp->srcu_sup->srcu_gp_seq);",
            "\tsmp_mb(); /* Order ->srcu_gp_seq with ->srcu_gp_seq_needed. */",
            "\tif (ULONG_CMP_LT(curseq, READ_ONCE(ssp->srcu_sup->srcu_gp_seq_needed)))",
            "\t\treturn false; /* Grace period in progress, so not idle. */",
            "\tsmp_mb(); /* Order ->srcu_gp_seq with prior access. */",
            "\tif (curseq != rcu_seq_current(&ssp->srcu_sup->srcu_gp_seq))",
            "\t\treturn false; /* GP # changed, so not idle. */",
            "\treturn true; /* With reasonable probability, idle! */",
            "}",
            "static void srcu_leak_callback(struct rcu_head *rhp)",
            "{",
            "}"
          ],
          "function_name": "try_check_zero, srcu_flip, srcu_might_be_idle, srcu_leak_callback",
          "description": "维护SRCU索引计数器，检测读端临界区空闲状态，并通过内存屏障确保操作顺序性。",
          "similarity": 0.48214608430862427
        }
      ]
    }
  ]
}