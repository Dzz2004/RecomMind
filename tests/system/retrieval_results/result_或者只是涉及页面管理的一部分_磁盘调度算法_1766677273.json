{
  "query": "或者只是涉及页面管理的一部分 磁盘调度算法",
  "timestamp": "2025-12-25 23:41:13",
  "retrieved_files": [
    {
      "source_file": "mm/compaction.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:44:52\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `compaction.c`\n\n---\n\n# compaction.c 技术文档\n\n## 1. 文件概述\n\n`compaction.c` 是 Linux 内核内存管理子系统中实现**内存压缩（Memory Compaction）**功能的核心文件。其主要目标是**减少外部碎片（external fragmentation）**，通过迁移可移动页面，将物理内存中的空闲页聚集形成连续的大块内存区域，从而满足高阶（high-order）内存分配请求（如透明大页 THP 或 HugeTLB）。该机制高度依赖页面迁移（page migration）来完成实际的页面移动工作。\n\n## 2. 核心功能\n\n### 主要函数\n- **`PageMovable()` / `__SetPageMovable()` / `__ClearPageMovable()`**: 管理页面的可移动性标记，用于标识页面是否可通过注册的 `movable_operations` 进行迁移。\n- **`defer_compaction()` / `compaction_deferred()` / `compaction_defer_reset()`**: 实现**压缩延迟（deferred compaction）**机制，避免在压缩失败后频繁重试，提升系统性能。\n- **`compaction_restarting()`**: 判断是否因多次失败后重新启动压缩流程。\n- **`isolation_suitable()`**: 检查指定 pageblock 是否适合进行页面隔离（用于迁移）。\n- **`reset_cached_positions()`**: 重置压缩控制结构中缓存的扫描位置（迁移源和空闲目标页的起始 PFN）。\n- **`release_free_list()`**: 将临时空闲页面列表中的页面释放回伙伴系统。\n- **`skip_offline_sections()` / `skip_offline_sections_reverse()`**: 在 SPARSEMEM 内存模型下跳过离线内存段。\n\n### 关键数据结构与宏\n- **`struct compact_control`**: 压缩操作的控制上下文（定义在 `internal.h` 中），包含扫描范围、迁移/空闲页面列表等。\n- **`COMPACTION_HPAGE_ORDER`**: 用于计算节点/区域“碎片分数（fragmentation score）”的参考阶数，通常为透明大页或 HugeTLB 的阶数。\n- **`COMPACT_MAX_DEFER_SHIFT`**: 压缩延迟的最大次数（64 次）。\n- **`zone->compact_*` 字段**: 包括 `compact_considered`, `compact_defer_shift`, `compact_order_failed`, `compact_cached_*_pfn` 等，用于跟踪压缩状态和优化扫描。\n\n## 3. 关键实现\n\n### 内存压缩流程\n1. **扫描阶段**：从区域两端向中间扫描：\n   - **迁移源扫描器（migrate scanner）**：从低地址向高地址扫描，寻找可迁移的页面。\n   - **空闲目标扫描器（free scanner）**：从高地址向低地址扫描，寻找空闲页面块。\n2. **页面隔离**：将找到的可迁移页面加入迁移列表，空闲页面加入空闲列表。\n3. **页面迁移**：调用 `migrate_pages()` 将迁移列表中的页面移动到空闲列表提供的目标位置。\n4. **结果处理**：迁移成功后，原位置变为空闲，可能形成更大的连续空闲块；失败则回滚。\n\n### 压缩延迟机制（Deferred Compaction）\n- 当压缩未能成功分配指定 `order` 的页面时，调用 `defer_compaction()` 增加延迟计数器 `compact_defer_shift`。\n- 后续分配请求会通过 `compaction_deferred()` 检查是否应跳过压缩（基于 `compact_considered` 计数和 `defer_limit = 1 << compact_defer_shift`）。\n- 若分配成功或预期成功，则通过 `compaction_defer_reset()` 重置延迟状态。\n- 当延迟达到最大值（`COMPACT_MAX_DEFER_SHIFT`）且考虑次数足够多时，`compaction_restarting()` 返回 true，强制重启完整压缩流程。\n\n### 碎片分数与主动压缩\n- 通过 `COMPACTION_HPAGE_ORDER` 定义的阶数评估区域的外部碎片程度。\n- 主动压缩（proactive compaction）定期（`HPAGE_FRAG_CHECK_INTERVAL_MSEC = 500ms`）检查碎片分数，并在需要时触发后台压缩。\n- `is_via_compact_memory()` 用于识别通过 `/proc/sys/vm/compact_memory` 等接口发起的全量压缩请求（`order = -1`）。\n\n### 页面可移动性管理\n- `__SetPageMovable()` 将 `movable_operations` 指针编码到 `page->mapping` 中，并设置 `PAGE_MAPPING_MOVABLE` 标志。\n- `PageMovable()` 验证页面是否被正确标记为可移动，并确保其操作集有效。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm.h>`, `internal.h`, `mm_inline.h` 提供的伙伴系统、页面分配/释放、zone 管理等基础功能。\n- **页面迁移**：紧密集成 `<linux/migrate.h>`，压缩的核心操作由 `migrate_pages()` 完成。\n- **内存模型**：针对 `CONFIG_SPARSEMEM` 提供离线内存段跳过逻辑。\n- **大页支持**：根据 `CONFIG_TRANSPARENT_HUGEPAGE` 或 `CONFIG_HUGETLBFS` 确定 `COMPACTION_HPAGE_ORDER`。\n- **调试与追踪**：使用 `kasan.h`, `page_owner.h` 进行调试；通过 `trace/events/compaction.h` 提供 ftrace 事件。\n- **系统调用与接口**：通过 sysctl (`/proc/sys/vm/`) 和 sysfs (`/sys/devices/system/node/`) 暴露用户空间控制接口。\n- **进程与调度**：使用 `kthread.h`, `freezer.h` 管理后台压缩线程；`psi.h` 用于压力状态监控。\n\n## 5. 使用场景\n\n1. **高阶内存分配失败时**：当 `alloc_pages()` 请求高阶页面（如 order ≥ 3）失败时，内核会尝试同步内存压缩以满足请求。\n2. **透明大页（THP）分配**：THP 需要连续的 2MB 物理内存，压缩是满足此类请求的关键机制。\n3. **主动后台压缩**：通过 `vm.compaction_proactiveness` sysctl 参数配置，内核定期评估内存碎片并主动压缩，预防分配延迟。\n4. **用户空间触发**：管理员可通过写入 `/proc/sys/vm/compact_memory` 或特定 NUMA 节点的 `compact` sysfs 文件，手动触发全量内存压缩。\n5. **CMA（Contiguous Memory Allocator）**：在 CMA 区域分配大块连续内存前，使用压缩机制迁移占用页面以腾出空间（需 `CONFIG_CMA`）。",
      "similarity": 0.6132725477218628,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/compaction.c",
          "start_line": 34,
          "end_line": 141,
          "content": [
            "static inline void count_compact_event(enum vm_event_item item)",
            "{",
            "\tcount_vm_event(item);",
            "}",
            "static inline void count_compact_events(enum vm_event_item item, long delta)",
            "{",
            "\tcount_vm_events(item, delta);",
            "}",
            "static inline bool is_via_compact_memory(int order)",
            "{",
            "\treturn order == -1;",
            "}",
            "static inline bool is_via_compact_memory(int order) { return false; }",
            "static unsigned long release_free_list(struct list_head *freepages)",
            "{",
            "\tint order;",
            "\tunsigned long high_pfn = 0;",
            "",
            "\tfor (order = 0; order < NR_PAGE_ORDERS; order++) {",
            "\t\tstruct page *page, *next;",
            "",
            "\t\tlist_for_each_entry_safe(page, next, &freepages[order], lru) {",
            "\t\t\tunsigned long pfn = page_to_pfn(page);",
            "",
            "\t\t\tlist_del(&page->lru);",
            "\t\t\t/*",
            "\t\t\t * Convert free pages into post allocation pages, so",
            "\t\t\t * that we can free them via __free_page.",
            "\t\t\t */",
            "\t\t\tmark_allocated(page, order, __GFP_MOVABLE);",
            "\t\t\t__free_pages(page, order);",
            "\t\t\tif (pfn > high_pfn)",
            "\t\t\t\thigh_pfn = pfn;",
            "\t\t}",
            "\t}",
            "\treturn high_pfn;",
            "}",
            "bool PageMovable(struct page *page)",
            "{",
            "\tconst struct movable_operations *mops;",
            "",
            "\tVM_BUG_ON_PAGE(!PageLocked(page), page);",
            "\tif (!__PageMovable(page))",
            "\t\treturn false;",
            "",
            "\tmops = page_movable_ops(page);",
            "\tif (mops)",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "void __SetPageMovable(struct page *page, const struct movable_operations *mops)",
            "{",
            "\tVM_BUG_ON_PAGE(!PageLocked(page), page);",
            "\tVM_BUG_ON_PAGE((unsigned long)mops & PAGE_MAPPING_MOVABLE, page);",
            "\tpage->mapping = (void *)((unsigned long)mops | PAGE_MAPPING_MOVABLE);",
            "}",
            "void __ClearPageMovable(struct page *page)",
            "{",
            "\tVM_BUG_ON_PAGE(!PageMovable(page), page);",
            "\t/*",
            "\t * This page still has the type of a movable page, but it's",
            "\t * actually not movable any more.",
            "\t */",
            "\tpage->mapping = (void *)PAGE_MAPPING_MOVABLE;",
            "}",
            "static void defer_compaction(struct zone *zone, int order)",
            "{",
            "\tzone->compact_considered = 0;",
            "\tzone->compact_defer_shift++;",
            "",
            "\tif (order < zone->compact_order_failed)",
            "\t\tzone->compact_order_failed = order;",
            "",
            "\tif (zone->compact_defer_shift > COMPACT_MAX_DEFER_SHIFT)",
            "\t\tzone->compact_defer_shift = COMPACT_MAX_DEFER_SHIFT;",
            "",
            "\ttrace_mm_compaction_defer_compaction(zone, order);",
            "}",
            "static bool compaction_deferred(struct zone *zone, int order)",
            "{",
            "\tunsigned long defer_limit = 1UL << zone->compact_defer_shift;",
            "",
            "\tif (order < zone->compact_order_failed)",
            "\t\treturn false;",
            "",
            "\t/* Avoid possible overflow */",
            "\tif (++zone->compact_considered >= defer_limit) {",
            "\t\tzone->compact_considered = defer_limit;",
            "\t\treturn false;",
            "\t}",
            "",
            "\ttrace_mm_compaction_deferred(zone, order);",
            "",
            "\treturn true;",
            "}",
            "void compaction_defer_reset(struct zone *zone, int order,",
            "\t\tbool alloc_success)",
            "{",
            "\tif (alloc_success) {",
            "\t\tzone->compact_considered = 0;",
            "\t\tzone->compact_defer_shift = 0;",
            "\t}",
            "\tif (order >= zone->compact_order_failed)",
            "\t\tzone->compact_order_failed = order + 1;",
            "",
            "\ttrace_mm_compaction_defer_reset(zone, order);",
            "}"
          ],
          "function_name": "count_compact_event, count_compact_events, is_via_compact_memory, is_via_compact_memory, release_free_list, PageMovable, __SetPageMovable, __ClearPageMovable, defer_compaction, compaction_deferred, compaction_defer_reset",
          "description": "提供内存压缩事件计数、页面可移动性检测、空闲列表释放、延迟压缩逻辑及页面块隔离辅助函数，包含重复定义可能导致冲突",
          "similarity": 0.6503582000732422
        },
        {
          "chunk_id": 10,
          "file_path": "mm/compaction.c",
          "start_line": 1888,
          "end_line": 2042,
          "content": [
            "static void compaction_free(struct folio *dst, unsigned long data)",
            "{",
            "\tstruct compact_control *cc = (struct compact_control *)data;",
            "\tint order = folio_order(dst);",
            "\tstruct page *page = &dst->page;",
            "",
            "\tif (folio_put_testzero(dst)) {",
            "\t\tfree_pages_prepare(page, order);",
            "\t\tlist_add(&dst->lru, &cc->freepages[order]);",
            "\t\tcc->nr_freepages += 1 << order;",
            "\t}",
            "\tcc->nr_migratepages += 1 << order;",
            "\t/*",
            "\t * someone else has referenced the page, we cannot take it back to our",
            "\t * free list.",
            "\t */",
            "}",
            "static inline void",
            "update_fast_start_pfn(struct compact_control *cc, unsigned long pfn)",
            "{",
            "\tif (cc->fast_start_pfn == ULONG_MAX)",
            "\t\treturn;",
            "",
            "\tif (!cc->fast_start_pfn)",
            "\t\tcc->fast_start_pfn = pfn;",
            "",
            "\tcc->fast_start_pfn = min(cc->fast_start_pfn, pfn);",
            "}",
            "static inline unsigned long",
            "reinit_migrate_pfn(struct compact_control *cc)",
            "{",
            "\tif (!cc->fast_start_pfn || cc->fast_start_pfn == ULONG_MAX)",
            "\t\treturn cc->migrate_pfn;",
            "",
            "\tcc->migrate_pfn = cc->fast_start_pfn;",
            "\tcc->fast_start_pfn = ULONG_MAX;",
            "",
            "\treturn cc->migrate_pfn;",
            "}",
            "static unsigned long fast_find_migrateblock(struct compact_control *cc)",
            "{",
            "\tunsigned int limit = freelist_scan_limit(cc);",
            "\tunsigned int nr_scanned = 0;",
            "\tunsigned long distance;",
            "\tunsigned long pfn = cc->migrate_pfn;",
            "\tunsigned long high_pfn;",
            "\tint order;",
            "\tbool found_block = false;",
            "",
            "\t/* Skip hints are relied on to avoid repeats on the fast search */",
            "\tif (cc->ignore_skip_hint)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * If the pageblock should be finished then do not select a different",
            "\t * pageblock.",
            "\t */",
            "\tif (cc->finish_pageblock)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * If the migrate_pfn is not at the start of a zone or the start",
            "\t * of a pageblock then assume this is a continuation of a previous",
            "\t * scan restarted due to COMPACT_CLUSTER_MAX.",
            "\t */",
            "\tif (pfn != cc->zone->zone_start_pfn && pfn != pageblock_start_pfn(pfn))",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * For smaller orders, just linearly scan as the number of pages",
            "\t * to migrate should be relatively small and does not necessarily",
            "\t * justify freeing up a large block for a small allocation.",
            "\t */",
            "\tif (cc->order <= PAGE_ALLOC_COSTLY_ORDER)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * Only allow kcompactd and direct requests for movable pages to",
            "\t * quickly clear out a MOVABLE pageblock for allocation. This",
            "\t * reduces the risk that a large movable pageblock is freed for",
            "\t * an unmovable/reclaimable small allocation.",
            "\t */",
            "\tif (cc->direct_compaction && cc->migratetype != MIGRATE_MOVABLE)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * When starting the migration scanner, pick any pageblock within the",
            "\t * first half of the search space. Otherwise try and pick a pageblock",
            "\t * within the first eighth to reduce the chances that a migration",
            "\t * target later becomes a source.",
            "\t */",
            "\tdistance = (cc->free_pfn - cc->migrate_pfn) >> 1;",
            "\tif (cc->migrate_pfn != cc->zone->zone_start_pfn)",
            "\t\tdistance >>= 2;",
            "\thigh_pfn = pageblock_start_pfn(cc->migrate_pfn + distance);",
            "",
            "\tfor (order = cc->order - 1;",
            "\t     order >= PAGE_ALLOC_COSTLY_ORDER && !found_block && nr_scanned < limit;",
            "\t     order--) {",
            "\t\tstruct free_area *area = &cc->zone->free_area[order];",
            "\t\tstruct list_head *freelist;",
            "\t\tunsigned long flags;",
            "\t\tstruct page *freepage;",
            "",
            "\t\tif (!area->nr_free)",
            "\t\t\tcontinue;",
            "",
            "\t\tspin_lock_irqsave(&cc->zone->lock, flags);",
            "\t\tfreelist = &area->free_list[MIGRATE_MOVABLE];",
            "\t\tlist_for_each_entry(freepage, freelist, buddy_list) {",
            "\t\t\tunsigned long free_pfn;",
            "",
            "\t\t\tif (nr_scanned++ >= limit) {",
            "\t\t\t\tmove_freelist_tail(freelist, freepage);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "",
            "\t\t\tfree_pfn = page_to_pfn(freepage);",
            "\t\t\tif (free_pfn < high_pfn) {",
            "\t\t\t\t/*",
            "\t\t\t\t * Avoid if skipped recently. Ideally it would",
            "\t\t\t\t * move to the tail but even safe iteration of",
            "\t\t\t\t * the list assumes an entry is deleted, not",
            "\t\t\t\t * reordered.",
            "\t\t\t\t */",
            "\t\t\t\tif (get_pageblock_skip(freepage))",
            "\t\t\t\t\tcontinue;",
            "",
            "\t\t\t\t/* Reorder to so a future search skips recent pages */",
            "\t\t\t\tmove_freelist_tail(freelist, freepage);",
            "",
            "\t\t\t\tupdate_fast_start_pfn(cc, free_pfn);",
            "\t\t\t\tpfn = pageblock_start_pfn(free_pfn);",
            "\t\t\t\tif (pfn < cc->zone->zone_start_pfn)",
            "\t\t\t\t\tpfn = cc->zone->zone_start_pfn;",
            "\t\t\t\tcc->fast_search_fail = 0;",
            "\t\t\t\tfound_block = true;",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t}",
            "\t\tspin_unlock_irqrestore(&cc->zone->lock, flags);",
            "\t}",
            "",
            "\tcc->total_migrate_scanned += nr_scanned;",
            "",
            "\t/*",
            "\t * If fast scanning failed then use a cached entry for a page block",
            "\t * that had free pages as the basis for starting a linear scan.",
            "\t */",
            "\tif (!found_block) {",
            "\t\tcc->fast_search_fail++;",
            "\t\tpfn = reinit_migrate_pfn(cc);",
            "\t}",
            "\treturn pfn;",
            "}"
          ],
          "function_name": "compaction_free, update_fast_start_pfn, reinit_migrate_pfn, fast_find_migrateblock",
          "description": "实现内存碎片整理中页面释放与迁移扫描逻辑，compaction_free处理页面回收，update_fast_start_pfn维护快速扫描起点，reinit_migrate_pfn重置迁移扫描位置，fast_find_migrateblock寻找适合迁移的页块，优先考虑可移动类型且未被跳过的页块",
          "similarity": 0.610458493232727
        },
        {
          "chunk_id": 14,
          "file_path": "mm/compaction.c",
          "start_line": 2489,
          "end_line": 2740,
          "content": [
            "static enum compact_result",
            "compaction_suit_allocation_order(struct zone *zone, unsigned int order,",
            "\t\t\t\t int highest_zoneidx, unsigned int alloc_flags)",
            "{",
            "\tunsigned long watermark;",
            "",
            "\twatermark = wmark_pages(zone, alloc_flags & ALLOC_WMARK_MASK);",
            "\tif (zone_watermark_ok(zone, order, watermark, highest_zoneidx,",
            "\t\t\t      alloc_flags))",
            "\t\treturn COMPACT_SUCCESS;",
            "",
            "\tif (!compaction_suitable(zone, order, highest_zoneidx))",
            "\t\treturn COMPACT_SKIPPED;",
            "",
            "\treturn COMPACT_CONTINUE;",
            "}",
            "static enum compact_result",
            "compact_zone(struct compact_control *cc, struct capture_control *capc)",
            "{",
            "\tenum compact_result ret;",
            "\tunsigned long start_pfn = cc->zone->zone_start_pfn;",
            "\tunsigned long end_pfn = zone_end_pfn(cc->zone);",
            "\tunsigned long last_migrated_pfn;",
            "\tconst bool sync = cc->mode != MIGRATE_ASYNC;",
            "\tbool update_cached;",
            "\tunsigned int nr_succeeded = 0, nr_migratepages;",
            "\tint order;",
            "",
            "\t/*",
            "\t * These counters track activities during zone compaction.  Initialize",
            "\t * them before compacting a new zone.",
            "\t */",
            "\tcc->total_migrate_scanned = 0;",
            "\tcc->total_free_scanned = 0;",
            "\tcc->nr_migratepages = 0;",
            "\tcc->nr_freepages = 0;",
            "\tfor (order = 0; order < NR_PAGE_ORDERS; order++)",
            "\t\tINIT_LIST_HEAD(&cc->freepages[order]);",
            "\tINIT_LIST_HEAD(&cc->migratepages);",
            "",
            "\tcc->migratetype = gfp_migratetype(cc->gfp_mask);",
            "",
            "\tif (!is_via_compact_memory(cc->order)) {",
            "\t\tret = compaction_suit_allocation_order(cc->zone, cc->order,",
            "\t\t\t\t\t\t       cc->highest_zoneidx,",
            "\t\t\t\t\t\t       cc->alloc_flags);",
            "\t\tif (ret != COMPACT_CONTINUE)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\t/*",
            "\t * Clear pageblock skip if there were failures recently and compaction",
            "\t * is about to be retried after being deferred.",
            "\t */",
            "\tif (compaction_restarting(cc->zone, cc->order))",
            "\t\t__reset_isolation_suitable(cc->zone);",
            "",
            "\t/*",
            "\t * Setup to move all movable pages to the end of the zone. Used cached",
            "\t * information on where the scanners should start (unless we explicitly",
            "\t * want to compact the whole zone), but check that it is initialised",
            "\t * by ensuring the values are within zone boundaries.",
            "\t */",
            "\tcc->fast_start_pfn = 0;",
            "\tif (cc->whole_zone) {",
            "\t\tcc->migrate_pfn = start_pfn;",
            "\t\tcc->free_pfn = pageblock_start_pfn(end_pfn - 1);",
            "\t} else {",
            "\t\tcc->migrate_pfn = cc->zone->compact_cached_migrate_pfn[sync];",
            "\t\tcc->free_pfn = cc->zone->compact_cached_free_pfn;",
            "\t\tif (cc->free_pfn < start_pfn || cc->free_pfn >= end_pfn) {",
            "\t\t\tcc->free_pfn = pageblock_start_pfn(end_pfn - 1);",
            "\t\t\tcc->zone->compact_cached_free_pfn = cc->free_pfn;",
            "\t\t}",
            "\t\tif (cc->migrate_pfn < start_pfn || cc->migrate_pfn >= end_pfn) {",
            "\t\t\tcc->migrate_pfn = start_pfn;",
            "\t\t\tcc->zone->compact_cached_migrate_pfn[0] = cc->migrate_pfn;",
            "\t\t\tcc->zone->compact_cached_migrate_pfn[1] = cc->migrate_pfn;",
            "\t\t}",
            "",
            "\t\tif (cc->migrate_pfn <= cc->zone->compact_init_migrate_pfn)",
            "\t\t\tcc->whole_zone = true;",
            "\t}",
            "",
            "\tlast_migrated_pfn = 0;",
            "",
            "\t/*",
            "\t * Migrate has separate cached PFNs for ASYNC and SYNC* migration on",
            "\t * the basis that some migrations will fail in ASYNC mode. However,",
            "\t * if the cached PFNs match and pageblocks are skipped due to having",
            "\t * no isolation candidates, then the sync state does not matter.",
            "\t * Until a pageblock with isolation candidates is found, keep the",
            "\t * cached PFNs in sync to avoid revisiting the same blocks.",
            "\t */",
            "\tupdate_cached = !sync &&",
            "\t\tcc->zone->compact_cached_migrate_pfn[0] == cc->zone->compact_cached_migrate_pfn[1];",
            "",
            "\ttrace_mm_compaction_begin(cc, start_pfn, end_pfn, sync);",
            "",
            "\t/* lru_add_drain_all could be expensive with involving other CPUs */",
            "\tlru_add_drain();",
            "",
            "\twhile ((ret = compact_finished(cc)) == COMPACT_CONTINUE) {",
            "\t\tint err;",
            "\t\tunsigned long iteration_start_pfn = cc->migrate_pfn;",
            "",
            "\t\t/*",
            "\t\t * Avoid multiple rescans of the same pageblock which can",
            "\t\t * happen if a page cannot be isolated (dirty/writeback in",
            "\t\t * async mode) or if the migrated pages are being allocated",
            "\t\t * before the pageblock is cleared.  The first rescan will",
            "\t\t * capture the entire pageblock for migration. If it fails,",
            "\t\t * it'll be marked skip and scanning will proceed as normal.",
            "\t\t */",
            "\t\tcc->finish_pageblock = false;",
            "\t\tif (pageblock_start_pfn(last_migrated_pfn) ==",
            "\t\t    pageblock_start_pfn(iteration_start_pfn)) {",
            "\t\t\tcc->finish_pageblock = true;",
            "\t\t}",
            "",
            "rescan:",
            "\t\tswitch (isolate_migratepages(cc)) {",
            "\t\tcase ISOLATE_ABORT:",
            "\t\t\tret = COMPACT_CONTENDED;",
            "\t\t\tputback_movable_pages(&cc->migratepages);",
            "\t\t\tcc->nr_migratepages = 0;",
            "\t\t\tgoto out;",
            "\t\tcase ISOLATE_NONE:",
            "\t\t\tif (update_cached) {",
            "\t\t\t\tcc->zone->compact_cached_migrate_pfn[1] =",
            "\t\t\t\t\tcc->zone->compact_cached_migrate_pfn[0];",
            "\t\t\t}",
            "",
            "\t\t\t/*",
            "\t\t\t * We haven't isolated and migrated anything, but",
            "\t\t\t * there might still be unflushed migrations from",
            "\t\t\t * previous cc->order aligned block.",
            "\t\t\t */",
            "\t\t\tgoto check_drain;",
            "\t\tcase ISOLATE_SUCCESS:",
            "\t\t\tupdate_cached = false;",
            "\t\t\tlast_migrated_pfn = max(cc->zone->zone_start_pfn,",
            "\t\t\t\tpageblock_start_pfn(cc->migrate_pfn - 1));",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Record the number of pages to migrate since the",
            "\t\t * compaction_alloc/free() will update cc->nr_migratepages",
            "\t\t * properly.",
            "\t\t */",
            "\t\tnr_migratepages = cc->nr_migratepages;",
            "\t\terr = migrate_pages(&cc->migratepages, compaction_alloc,",
            "\t\t\t\tcompaction_free, (unsigned long)cc, cc->mode,",
            "\t\t\t\tMR_COMPACTION, &nr_succeeded);",
            "",
            "\t\ttrace_mm_compaction_migratepages(nr_migratepages, nr_succeeded);",
            "",
            "\t\t/* All pages were either migrated or will be released */",
            "\t\tcc->nr_migratepages = 0;",
            "\t\tif (err) {",
            "\t\t\tputback_movable_pages(&cc->migratepages);",
            "\t\t\t/*",
            "\t\t\t * migrate_pages() may return -ENOMEM when scanners meet",
            "\t\t\t * and we want compact_finished() to detect it",
            "\t\t\t */",
            "\t\t\tif (err == -ENOMEM && !compact_scanners_met(cc)) {",
            "\t\t\t\tret = COMPACT_CONTENDED;",
            "\t\t\t\tgoto out;",
            "\t\t\t}",
            "\t\t\t/*",
            "\t\t\t * If an ASYNC or SYNC_LIGHT fails to migrate a page",
            "\t\t\t * within the pageblock_order-aligned block and",
            "\t\t\t * fast_find_migrateblock may be used then scan the",
            "\t\t\t * remainder of the pageblock. This will mark the",
            "\t\t\t * pageblock \"skip\" to avoid rescanning in the near",
            "\t\t\t * future. This will isolate more pages than necessary",
            "\t\t\t * for the request but avoid loops due to",
            "\t\t\t * fast_find_migrateblock revisiting blocks that were",
            "\t\t\t * recently partially scanned.",
            "\t\t\t */",
            "\t\t\tif (!pageblock_aligned(cc->migrate_pfn) &&",
            "\t\t\t    !cc->ignore_skip_hint && !cc->finish_pageblock &&",
            "\t\t\t    (cc->mode < MIGRATE_SYNC)) {",
            "\t\t\t\tcc->finish_pageblock = true;",
            "",
            "\t\t\t\t/*",
            "\t\t\t\t * Draining pcplists does not help THP if",
            "\t\t\t\t * any page failed to migrate. Even after",
            "\t\t\t\t * drain, the pageblock will not be free.",
            "\t\t\t\t */",
            "\t\t\t\tif (cc->order == COMPACTION_HPAGE_ORDER)",
            "\t\t\t\t\tlast_migrated_pfn = 0;",
            "",
            "\t\t\t\tgoto rescan;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\t/* Stop if a page has been captured */",
            "\t\tif (capc && capc->page) {",
            "\t\t\tret = COMPACT_SUCCESS;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "check_drain:",
            "\t\t/*",
            "\t\t * Has the migration scanner moved away from the previous",
            "\t\t * cc->order aligned block where we migrated from? If yes,",
            "\t\t * flush the pages that were freed, so that they can merge and",
            "\t\t * compact_finished() can detect immediately if allocation",
            "\t\t * would succeed.",
            "\t\t */",
            "\t\tif (cc->order > 0 && last_migrated_pfn) {",
            "\t\t\tunsigned long current_block_start =",
            "\t\t\t\tblock_start_pfn(cc->migrate_pfn, cc->order);",
            "",
            "\t\t\tif (last_migrated_pfn < current_block_start) {",
            "\t\t\t\tlru_add_drain_cpu_zone(cc->zone);",
            "\t\t\t\t/* No more flushing until we migrate again */",
            "\t\t\t\tlast_migrated_pfn = 0;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "out:",
            "\t/*",
            "\t * Release free pages and update where the free scanner should restart,",
            "\t * so we don't leave any returned pages behind in the next attempt.",
            "\t */",
            "\tif (cc->nr_freepages > 0) {",
            "\t\tunsigned long free_pfn = release_free_list(cc->freepages);",
            "",
            "\t\tcc->nr_freepages = 0;",
            "\t\tVM_BUG_ON(free_pfn == 0);",
            "\t\t/* The cached pfn is always the first in a pageblock */",
            "\t\tfree_pfn = pageblock_start_pfn(free_pfn);",
            "\t\t/*",
            "\t\t * Only go back, not forward. The cached pfn might have been",
            "\t\t * already reset to zone end in compact_finished()",
            "\t\t */",
            "\t\tif (free_pfn > cc->zone->compact_cached_free_pfn)",
            "\t\t\tcc->zone->compact_cached_free_pfn = free_pfn;",
            "\t}",
            "",
            "\tcount_compact_events(COMPACTMIGRATE_SCANNED, cc->total_migrate_scanned);",
            "\tcount_compact_events(COMPACTFREE_SCANNED, cc->total_free_scanned);",
            "",
            "\ttrace_mm_compaction_end(cc, start_pfn, end_pfn, sync, ret);",
            "",
            "\tVM_BUG_ON(!list_empty(&cc->migratepages));",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "compaction_suit_allocation_order, compact_zone",
          "description": "compaction_suit_allocation_order检查分配顺序兼容性，compact_zone执行核心压缩流程，迁移页面并调整缓存扫描起点，处理页块扫描和迁移结果",
          "similarity": 0.5969280004501343
        },
        {
          "chunk_id": 4,
          "file_path": "mm/compaction.c",
          "start_line": 501,
          "end_line": 675,
          "content": [
            "static inline bool isolation_suitable(struct compact_control *cc,",
            "\t\t\t\t\tstruct page *page)",
            "{",
            "\treturn true;",
            "}",
            "static inline bool pageblock_skip_persistent(struct page *page)",
            "{",
            "\treturn false;",
            "}",
            "static inline void update_pageblock_skip(struct compact_control *cc,",
            "\t\t\tstruct page *page, unsigned long pfn)",
            "{",
            "}",
            "static void update_cached_migrate(struct compact_control *cc, unsigned long pfn)",
            "{",
            "}",
            "static bool test_and_set_skip(struct compact_control *cc, struct page *page)",
            "{",
            "\treturn false;",
            "}",
            "static bool compact_lock_irqsave(spinlock_t *lock, unsigned long *flags,",
            "\t\t\t\t\t\tstruct compact_control *cc)",
            "\t__acquires(lock)",
            "{",
            "\t/* Track if the lock is contended in async mode */",
            "\tif (cc->mode == MIGRATE_ASYNC && !cc->contended) {",
            "\t\tif (spin_trylock_irqsave(lock, *flags))",
            "\t\t\treturn true;",
            "",
            "\t\tcc->contended = true;",
            "\t}",
            "",
            "\tspin_lock_irqsave(lock, *flags);",
            "\treturn true;",
            "}",
            "static bool compact_unlock_should_abort(spinlock_t *lock,",
            "\t\tunsigned long flags, bool *locked, struct compact_control *cc)",
            "{",
            "\tif (*locked) {",
            "\t\tspin_unlock_irqrestore(lock, flags);",
            "\t\t*locked = false;",
            "\t}",
            "",
            "\tif (fatal_signal_pending(current)) {",
            "\t\tcc->contended = true;",
            "\t\treturn true;",
            "\t}",
            "",
            "\tcond_resched();",
            "",
            "\treturn false;",
            "}",
            "static unsigned long isolate_freepages_block(struct compact_control *cc,",
            "\t\t\t\tunsigned long *start_pfn,",
            "\t\t\t\tunsigned long end_pfn,",
            "\t\t\t\tstruct list_head *freelist,",
            "\t\t\t\tunsigned int stride,",
            "\t\t\t\tbool strict)",
            "{",
            "\tint nr_scanned = 0, total_isolated = 0;",
            "\tstruct page *page;",
            "\tunsigned long flags = 0;",
            "\tbool locked = false;",
            "\tunsigned long blockpfn = *start_pfn;",
            "\tunsigned int order;",
            "",
            "\t/* Strict mode is for isolation, speed is secondary */",
            "\tif (strict)",
            "\t\tstride = 1;",
            "",
            "\tpage = pfn_to_page(blockpfn);",
            "",
            "\t/* Isolate free pages. */",
            "\tfor (; blockpfn < end_pfn; blockpfn += stride, page += stride) {",
            "\t\tint isolated;",
            "",
            "\t\t/*",
            "\t\t * Periodically drop the lock (if held) regardless of its",
            "\t\t * contention, to give chance to IRQs. Abort if fatal signal",
            "\t\t * pending.",
            "\t\t */",
            "\t\tif (!(blockpfn % COMPACT_CLUSTER_MAX)",
            "\t\t    && compact_unlock_should_abort(&cc->zone->lock, flags,",
            "\t\t\t\t\t\t\t\t&locked, cc))",
            "\t\t\tbreak;",
            "",
            "\t\tnr_scanned++;",
            "",
            "\t\t/*",
            "\t\t * For compound pages such as THP and hugetlbfs, we can save",
            "\t\t * potentially a lot of iterations if we skip them at once.",
            "\t\t * The check is racy, but we can consider only valid values",
            "\t\t * and the only danger is skipping too much.",
            "\t\t */",
            "\t\tif (PageCompound(page)) {",
            "\t\t\tconst unsigned int order = compound_order(page);",
            "",
            "\t\t\tif ((order <= MAX_PAGE_ORDER) &&",
            "\t\t\t    (blockpfn + (1UL << order) <= end_pfn)) {",
            "\t\t\t\tblockpfn += (1UL << order) - 1;",
            "\t\t\t\tpage += (1UL << order) - 1;",
            "\t\t\t\tnr_scanned += (1UL << order) - 1;",
            "\t\t\t}",
            "",
            "\t\t\tgoto isolate_fail;",
            "\t\t}",
            "",
            "\t\tif (!PageBuddy(page))",
            "\t\t\tgoto isolate_fail;",
            "",
            "\t\t/* If we already hold the lock, we can skip some rechecking. */",
            "\t\tif (!locked) {",
            "\t\t\tlocked = compact_lock_irqsave(&cc->zone->lock,",
            "\t\t\t\t\t\t\t\t&flags, cc);",
            "",
            "\t\t\t/* Recheck this is a buddy page under lock */",
            "\t\t\tif (!PageBuddy(page))",
            "\t\t\t\tgoto isolate_fail;",
            "\t\t}",
            "",
            "\t\t/* Found a free page, will break it into order-0 pages */",
            "\t\torder = buddy_order(page);",
            "\t\tisolated = __isolate_free_page(page, order);",
            "\t\tif (!isolated)",
            "\t\t\tbreak;",
            "\t\tset_page_private(page, order);",
            "",
            "\t\tnr_scanned += isolated - 1;",
            "\t\ttotal_isolated += isolated;",
            "\t\tcc->nr_freepages += isolated;",
            "\t\tlist_add_tail(&page->lru, &freelist[order]);",
            "",
            "\t\tif (!strict && cc->nr_migratepages <= cc->nr_freepages) {",
            "\t\t\tblockpfn += isolated;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\t/* Advance to the end of split page */",
            "\t\tblockpfn += isolated - 1;",
            "\t\tpage += isolated - 1;",
            "\t\tcontinue;",
            "",
            "isolate_fail:",
            "\t\tif (strict)",
            "\t\t\tbreak;",
            "",
            "\t}",
            "",
            "\tif (locked)",
            "\t\tspin_unlock_irqrestore(&cc->zone->lock, flags);",
            "",
            "\t/*",
            "\t * Be careful to not go outside of the pageblock.",
            "\t */",
            "\tif (unlikely(blockpfn > end_pfn))",
            "\t\tblockpfn = end_pfn;",
            "",
            "\ttrace_mm_compaction_isolate_freepages(*start_pfn, blockpfn,",
            "\t\t\t\t\tnr_scanned, total_isolated);",
            "",
            "\t/* Record how far we have got within the block */",
            "\t*start_pfn = blockpfn;",
            "",
            "\t/*",
            "\t * If strict isolation is requested by CMA then check that all the",
            "\t * pages requested were isolated. If there were any failures, 0 is",
            "\t * returned and CMA will fail.",
            "\t */",
            "\tif (strict && blockpfn < end_pfn)",
            "\t\ttotal_isolated = 0;",
            "",
            "\tcc->total_free_scanned += nr_scanned;",
            "\tif (total_isolated)",
            "\t\tcount_compact_events(COMPACTISOLATED, total_isolated);",
            "\treturn total_isolated;",
            "}"
          ],
          "function_name": "isolation_suitable, pageblock_skip_persistent, update_pageblock_skip, update_cached_migrate, test_and_set_skip, compact_lock_irqsave, compact_unlock_should_abort, isolate_freepages_block",
          "description": "实现页面块隔离核心逻辑，包含并发锁管理、页面扫描与隔离、严格模式下强制隔离等功能，支持CMA内存分配需求",
          "similarity": 0.5966569185256958
        },
        {
          "chunk_id": 5,
          "file_path": "mm/compaction.c",
          "start_line": 725,
          "end_line": 837,
          "content": [
            "unsigned long",
            "isolate_freepages_range(struct compact_control *cc,",
            "\t\t\tunsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tunsigned long isolated, pfn, block_start_pfn, block_end_pfn;",
            "\tint order;",
            "",
            "\tfor (order = 0; order < NR_PAGE_ORDERS; order++)",
            "\t\tINIT_LIST_HEAD(&cc->freepages[order]);",
            "",
            "\tpfn = start_pfn;",
            "\tblock_start_pfn = pageblock_start_pfn(pfn);",
            "\tif (block_start_pfn < cc->zone->zone_start_pfn)",
            "\t\tblock_start_pfn = cc->zone->zone_start_pfn;",
            "\tblock_end_pfn = pageblock_end_pfn(pfn);",
            "",
            "\tfor (; pfn < end_pfn; pfn += isolated,",
            "\t\t\t\tblock_start_pfn = block_end_pfn,",
            "\t\t\t\tblock_end_pfn += pageblock_nr_pages) {",
            "\t\t/* Protect pfn from changing by isolate_freepages_block */",
            "\t\tunsigned long isolate_start_pfn = pfn;",
            "",
            "\t\t/*",
            "\t\t * pfn could pass the block_end_pfn if isolated freepage",
            "\t\t * is more than pageblock order. In this case, we adjust",
            "\t\t * scanning range to right one.",
            "\t\t */",
            "\t\tif (pfn >= block_end_pfn) {",
            "\t\t\tblock_start_pfn = pageblock_start_pfn(pfn);",
            "\t\t\tblock_end_pfn = pageblock_end_pfn(pfn);",
            "\t\t}",
            "",
            "\t\tblock_end_pfn = min(block_end_pfn, end_pfn);",
            "",
            "\t\tif (!pageblock_pfn_to_page(block_start_pfn,",
            "\t\t\t\t\tblock_end_pfn, cc->zone))",
            "\t\t\tbreak;",
            "",
            "\t\tisolated = isolate_freepages_block(cc, &isolate_start_pfn,",
            "\t\t\t\t\tblock_end_pfn, cc->freepages, 0, true);",
            "",
            "\t\t/*",
            "\t\t * In strict mode, isolate_freepages_block() returns 0 if",
            "\t\t * there are any holes in the block (ie. invalid PFNs or",
            "\t\t * non-free pages).",
            "\t\t */",
            "\t\tif (!isolated)",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * If we managed to isolate pages, it is always (1 << n) *",
            "\t\t * pageblock_nr_pages for some non-negative n.  (Max order",
            "\t\t * page may span two pageblocks).",
            "\t\t */",
            "\t}",
            "",
            "\tif (pfn < end_pfn) {",
            "\t\t/* Loop terminated early, cleanup. */",
            "\t\trelease_free_list(cc->freepages);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/* We don't use freelists for anything. */",
            "\treturn pfn;",
            "}",
            "static bool too_many_isolated(struct compact_control *cc)",
            "{",
            "\tpg_data_t *pgdat = cc->zone->zone_pgdat;",
            "\tbool too_many;",
            "",
            "\tunsigned long active, inactive, isolated;",
            "",
            "\tinactive = node_page_state(pgdat, NR_INACTIVE_FILE) +",
            "\t\t\tnode_page_state(pgdat, NR_INACTIVE_ANON);",
            "\tactive = node_page_state(pgdat, NR_ACTIVE_FILE) +",
            "\t\t\tnode_page_state(pgdat, NR_ACTIVE_ANON);",
            "\tisolated = node_page_state(pgdat, NR_ISOLATED_FILE) +",
            "\t\t\tnode_page_state(pgdat, NR_ISOLATED_ANON);",
            "",
            "\t/*",
            "\t * Allow GFP_NOFS to isolate past the limit set for regular",
            "\t * compaction runs. This prevents an ABBA deadlock when other",
            "\t * compactors have already isolated to the limit, but are",
            "\t * blocked on filesystem locks held by the GFP_NOFS thread.",
            "\t */",
            "\tif (cc->gfp_mask & __GFP_FS) {",
            "\t\tinactive >>= 3;",
            "\t\tactive >>= 3;",
            "\t}",
            "",
            "\ttoo_many = isolated > (inactive + active) / 2;",
            "\tif (!too_many)",
            "\t\twake_throttle_isolated(pgdat);",
            "",
            "\treturn too_many;",
            "}",
            "static bool skip_isolation_on_order(int order, int target_order)",
            "{",
            "\t/*",
            "\t * Unless we are performing global compaction (i.e.,",
            "\t * is_via_compact_memory), skip any folios that are larger than the",
            "\t * target order: we wouldn't be here if we'd have a free folio with",
            "\t * the desired target_order, so migrating this folio would likely fail",
            "\t * later.",
            "\t */",
            "\tif (!is_via_compact_memory(target_order) && order >= target_order)",
            "\t\treturn true;",
            "\t/*",
            "\t * We limit memory compaction to pageblocks and won't try",
            "\t * creating free blocks of memory that are larger than that.",
            "\t */",
            "\treturn order >= pageblock_order;",
            "}"
          ],
          "function_name": "isolate_freepages_range, too_many_isolated, skip_isolation_on_order",
          "description": "isolate_freepages_range扫描指定PFN范围内的页面块，隔离空闲页至freepages数组；too_many_isolated检测当前系统是否已隔离过多页面以避免死锁；skip_isolation_on_order判断是否跳过大于目标顺序的页面",
          "similarity": 0.5896381139755249
        }
      ]
    },
    {
      "source_file": "kernel/sched/core_sched.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:00:47\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\core_sched.c`\n\n---\n\n# `sched/core_sched.c` 技术文档\n\n## 1. 文件概述\n\n`sched/core_sched.c` 是 Linux 内核调度器中用于实现 **核心调度（Core Scheduling）** 功能的核心文件之一。核心调度是一种安全机制，旨在防止来自不同安全上下文的任务在同一个物理 CPU 核心（特别是超线程/SMT 共享核心）上并发执行，从而缓解侧信道攻击（如 Spectre、MDS 等）。\n\n该文件主要负责管理任务的 **调度 cookie**（`core_cookie`），通过引用计数的 cookie 对象将具有相同安全上下文的任务分组，确保只有拥有相同 cookie 的任务才能在同一个 CPU 核心上并发运行。\n\n## 2. 核心功能\n\n### 数据结构\n\n- **`struct sched_core_cookie`**  \n  表示一个调度 cookie，仅包含一个引用计数器 `refcnt`。其内存地址本身即作为 cookie 值使用。\n\n### 主要函数\n\n| 函数 | 功能描述 |\n|------|--------|\n| `sched_core_alloc_cookie()` | 分配一个新的 `sched_core_cookie` 对象，初始化引用计数为 1，并启用核心调度全局状态。返回 cookie 地址（转换为 `unsigned long`）。 |\n| `sched_core_put_cookie(unsigned long cookie)` | 释放 cookie 引用；若引用计数归零，则释放内存并关闭核心调度全局状态。 |\n| `sched_core_get_cookie(unsigned long cookie)` | 增加 cookie 引用计数，返回原 cookie 值。 |\n| `sched_core_update_cookie(struct task_struct *p, unsigned long cookie)` | 原子地更新任务 `p` 的 `core_cookie`，处理任务在运行队列中的入队/出队，并在必要时触发重调度。 |\n| `sched_core_clone_cookie(struct task_struct *p)` | 安全地复制任务 `p` 的当前 cookie（带锁保护），用于 fork 或共享操作。 |\n| `sched_core_fork(struct task_struct *p)` | 在 `fork()` 时初始化子任务的核心调度状态，继承父进程的 cookie。 |\n| `sched_core_free(struct task_struct *p)` | 在任务退出时释放其持有的 cookie 引用。 |\n| `__sched_core_set(struct task_struct *p, unsigned long cookie)` | 设置任务 `p` 的 cookie，自动处理引用计数的获取与释放。 |\n| `sched_core_share_pid(...)` | 用户空间通过 `prctl(PR_SCHED_CORE, ...)` 调用的核心接口，支持创建、查询、共享 cookie。 |\n| `__sched_core_account_forceidle(struct rq *rq)` | （仅当 `CONFIG_SCHEDSTATS` 启用）统计核心强制空闲（force-idle）时间，并分摊到相关任务。 |\n| `__sched_core_tick(struct rq *rq)` | 在调度 tick 中调用，用于更新强制空闲时间统计。 |\n\n## 3. 关键实现\n\n### Cookie 生命周期管理\n- Cookie 通过 `kmalloc` 动态分配，其地址作为唯一标识。\n- 使用 `refcount_t` 实现线程安全的引用计数。\n- `sched_core_get()` / `sched_core_put()` 控制全局核心调度使能状态。\n\n### 任务 Cookie 更新\n- 在 `task_rq_lock()` 保护下更新 `p->core_cookie`，确保调度器一致性。\n- 若任务已在运行队列中，先出队再根据新 cookie 决定是否重新入队。\n- 若任务正在 CPU 上运行，调用 `resched_curr()` 触发重调度，以确保新 cookie 策略立即生效。\n\n### 安全访问控制\n- 通过 `ptrace_may_access()` 检查调用者是否有权限操作目标进程的 cookie。\n- 仅当系统存在 SMT（超线程）时（`sched_smt_present` 为真），才允许使用核心调度功能。\n\n### prctl 接口支持\n- 支持四种命令：\n  - `PR_SCHED_CORE_CREATE`：创建新 cookie。\n  - `PR_SCHED_CORE_SHARE_TO`：将当前进程的 cookie 应用于目标进程（或进程组）。\n  - `PR_SCHED_CORE_SHARE_FROM`：将目标进程的 cookie 应用于当前进程。\n  - `PR_SCHED_CORE_GET`：获取目标进程的 cookie 哈希值（用于用户空间识别）。\n- 支持作用域：线程（`PIDTYPE_PID`）、线程组（`PIDTYPE_TGID`）、进程组（`PIDTYPE_PGID`）。\n\n### 强制空闲时间统计（`CONFIG_SCHEDSTATS`）\n- 当核心因 cookie 不兼容而进入强制空闲状态时，记录空闲时间。\n- 时间按 `core_forceidle_count / core_forceidle_occupation` 比例分摊到所有相关 CPU 上的非 idle 任务。\n- 通过 `__account_forceidle_time()` 更新任务的调度统计信息。\n\n## 4. 依赖关系\n\n- **调度器核心**：依赖 `kernel/sched/` 下的通用调度器基础设施，如 `task_rq_lock()`、`resched_curr()`、`rq` 结构等。\n- **SMT 检测**：依赖 `sched_smt_present` 静态分支判断系统是否支持超线程。\n- **内存管理**：使用 `kmalloc`/`kfree` 进行动态内存分配。\n- **进程管理**：依赖 `find_task_by_vpid()`、`tasklist_lock`、`do_each_pid_thread` 等进程遍历机制。\n- **安全机制**：依赖 `ptrace_may_access()` 进行权限检查。\n- **调度统计**：`__sched_core_account_forceidle` 依赖 `CONFIG_SCHEDSTATS` 和 `__account_forceidle_time`。\n\n## 5. 使用场景\n\n- **安全敏感应用**：如浏览器、虚拟机监控器（VMM）、加密服务等，需防止跨任务的侧信道攻击。\n- **用户空间控制**：通过 `prctl(PR_SCHED_CORE, ...)` 接口，应用程序可显式创建和共享调度 cookie，将信任的任务分组。\n- **进程 fork 行为**：子进程自动继承父进程的 cookie，确保同源任务保持调度兼容性。\n- **系统资源隔离**：在多租户或容器环境中，确保不同租户的任务不会在同一个物理核心上并发执行。\n- **性能调优与监控**：通过 `CONFIG_SCHEDSTATS` 收集核心强制空闲开销，评估安全策略对性能的影响。",
      "similarity": 0.6116269826889038,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/core_sched.c",
          "start_line": 11,
          "end_line": 216,
          "content": [
            "static unsigned long sched_core_alloc_cookie(void)",
            "{",
            "\tstruct sched_core_cookie *ck = kmalloc(sizeof(*ck), GFP_KERNEL);",
            "\tif (!ck)",
            "\t\treturn 0;",
            "",
            "\trefcount_set(&ck->refcnt, 1);",
            "\tsched_core_get();",
            "",
            "\treturn (unsigned long)ck;",
            "}",
            "static void sched_core_put_cookie(unsigned long cookie)",
            "{",
            "\tstruct sched_core_cookie *ptr = (void *)cookie;",
            "",
            "\tif (ptr && refcount_dec_and_test(&ptr->refcnt)) {",
            "\t\tkfree(ptr);",
            "\t\tsched_core_put();",
            "\t}",
            "}",
            "static unsigned long sched_core_get_cookie(unsigned long cookie)",
            "{",
            "\tstruct sched_core_cookie *ptr = (void *)cookie;",
            "",
            "\tif (ptr)",
            "\t\trefcount_inc(&ptr->refcnt);",
            "",
            "\treturn cookie;",
            "}",
            "static unsigned long sched_core_update_cookie(struct task_struct *p,",
            "\t\t\t\t\t      unsigned long cookie)",
            "{",
            "\tunsigned long old_cookie;",
            "\tstruct rq_flags rf;",
            "\tstruct rq *rq;",
            "",
            "\trq = task_rq_lock(p, &rf);",
            "",
            "\t/*",
            "\t * Since creating a cookie implies sched_core_get(), and we cannot set",
            "\t * a cookie until after we've created it, similarly, we cannot destroy",
            "\t * a cookie until after we've removed it, we must have core scheduling",
            "\t * enabled here.",
            "\t */",
            "\tSCHED_WARN_ON((p->core_cookie || cookie) && !sched_core_enabled(rq));",
            "",
            "\tif (sched_core_enqueued(p))",
            "\t\tsched_core_dequeue(rq, p, DEQUEUE_SAVE);",
            "",
            "\told_cookie = p->core_cookie;",
            "\tp->core_cookie = cookie;",
            "",
            "\t/*",
            "\t * Consider the cases: !prev_cookie and !cookie.",
            "\t */",
            "\tif (cookie && task_on_rq_queued(p))",
            "\t\tsched_core_enqueue(rq, p);",
            "",
            "\t/*",
            "\t * If task is currently running, it may not be compatible anymore after",
            "\t * the cookie change, so enter the scheduler on its CPU to schedule it",
            "\t * away.",
            "\t *",
            "\t * Note that it is possible that as a result of this cookie change, the",
            "\t * core has now entered/left forced idle state. Defer accounting to the",
            "\t * next scheduling edge, rather than always forcing a reschedule here.",
            "\t */",
            "\tif (task_on_cpu(rq, p))",
            "\t\tresched_curr(rq);",
            "",
            "\ttask_rq_unlock(rq, p, &rf);",
            "",
            "\treturn old_cookie;",
            "}",
            "static unsigned long sched_core_clone_cookie(struct task_struct *p)",
            "{",
            "\tunsigned long cookie, flags;",
            "",
            "\traw_spin_lock_irqsave(&p->pi_lock, flags);",
            "\tcookie = sched_core_get_cookie(p->core_cookie);",
            "\traw_spin_unlock_irqrestore(&p->pi_lock, flags);",
            "",
            "\treturn cookie;",
            "}",
            "void sched_core_fork(struct task_struct *p)",
            "{",
            "\tRB_CLEAR_NODE(&p->core_node);",
            "\tp->core_cookie = sched_core_clone_cookie(current);",
            "}",
            "void sched_core_free(struct task_struct *p)",
            "{",
            "\tsched_core_put_cookie(p->core_cookie);",
            "}",
            "static void __sched_core_set(struct task_struct *p, unsigned long cookie)",
            "{",
            "\tcookie = sched_core_get_cookie(cookie);",
            "\tcookie = sched_core_update_cookie(p, cookie);",
            "\tsched_core_put_cookie(cookie);",
            "}",
            "int sched_core_share_pid(unsigned int cmd, pid_t pid, enum pid_type type,",
            "\t\t\t unsigned long uaddr)",
            "{",
            "\tunsigned long cookie = 0, id = 0;",
            "\tstruct task_struct *task, *p;",
            "\tstruct pid *grp;",
            "\tint err = 0;",
            "",
            "\tif (!static_branch_likely(&sched_smt_present))",
            "\t\treturn -ENODEV;",
            "",
            "\tBUILD_BUG_ON(PR_SCHED_CORE_SCOPE_THREAD != PIDTYPE_PID);",
            "\tBUILD_BUG_ON(PR_SCHED_CORE_SCOPE_THREAD_GROUP != PIDTYPE_TGID);",
            "\tBUILD_BUG_ON(PR_SCHED_CORE_SCOPE_PROCESS_GROUP != PIDTYPE_PGID);",
            "",
            "\tif (type > PIDTYPE_PGID || cmd >= PR_SCHED_CORE_MAX || pid < 0 ||",
            "\t    (cmd != PR_SCHED_CORE_GET && uaddr))",
            "\t\treturn -EINVAL;",
            "",
            "\trcu_read_lock();",
            "\tif (pid == 0) {",
            "\t\ttask = current;",
            "\t} else {",
            "\t\ttask = find_task_by_vpid(pid);",
            "\t\tif (!task) {",
            "\t\t\trcu_read_unlock();",
            "\t\t\treturn -ESRCH;",
            "\t\t}",
            "\t}",
            "\tget_task_struct(task);",
            "\trcu_read_unlock();",
            "",
            "\t/*",
            "\t * Check if this process has the right to modify the specified",
            "\t * process. Use the regular \"ptrace_may_access()\" checks.",
            "\t */",
            "\tif (!ptrace_may_access(task, PTRACE_MODE_READ_REALCREDS)) {",
            "\t\terr = -EPERM;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tswitch (cmd) {",
            "\tcase PR_SCHED_CORE_GET:",
            "\t\tif (type != PIDTYPE_PID || uaddr & 7) {",
            "\t\t\terr = -EINVAL;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t\tcookie = sched_core_clone_cookie(task);",
            "\t\tif (cookie) {",
            "\t\t\t/* XXX improve ? */",
            "\t\t\tptr_to_hashval((void *)cookie, &id);",
            "\t\t}",
            "\t\terr = put_user(id, (u64 __user *)uaddr);",
            "\t\tgoto out;",
            "",
            "\tcase PR_SCHED_CORE_CREATE:",
            "\t\tcookie = sched_core_alloc_cookie();",
            "\t\tif (!cookie) {",
            "\t\t\terr = -ENOMEM;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t\tbreak;",
            "",
            "\tcase PR_SCHED_CORE_SHARE_TO:",
            "\t\tcookie = sched_core_clone_cookie(current);",
            "\t\tbreak;",
            "",
            "\tcase PR_SCHED_CORE_SHARE_FROM:",
            "\t\tif (type != PIDTYPE_PID) {",
            "\t\t\terr = -EINVAL;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t\tcookie = sched_core_clone_cookie(task);",
            "\t\t__sched_core_set(current, cookie);",
            "\t\tgoto out;",
            "",
            "\tdefault:",
            "\t\terr = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (type == PIDTYPE_PID) {",
            "\t\t__sched_core_set(task, cookie);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tread_lock(&tasklist_lock);",
            "\tgrp = task_pid_type(task, type);",
            "",
            "\tdo_each_pid_thread(grp, type, p) {",
            "\t\tif (!ptrace_may_access(p, PTRACE_MODE_READ_REALCREDS)) {",
            "\t\t\terr = -EPERM;",
            "\t\t\tgoto out_tasklist;",
            "\t\t}",
            "\t} while_each_pid_thread(grp, type, p);",
            "",
            "\tdo_each_pid_thread(grp, type, p) {",
            "\t\t__sched_core_set(p, cookie);",
            "\t} while_each_pid_thread(grp, type, p);",
            "out_tasklist:",
            "\tread_unlock(&tasklist_lock);",
            "",
            "out:",
            "\tsched_core_put_cookie(cookie);",
            "\tput_task_struct(task);",
            "\treturn err;",
            "}"
          ],
          "function_name": "sched_core_alloc_cookie, sched_core_put_cookie, sched_core_get_cookie, sched_core_update_cookie, sched_core_clone_cookie, sched_core_fork, sched_core_free, __sched_core_set, sched_core_share_pid",
          "description": "实现了核心调度 cookie 的分配、释放、获取和更新机制，包含 cookie 分配/回收、任务核心绑定变更、进程克隆共享及核心调度策略控制等功能",
          "similarity": 0.622842013835907
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/core_sched.c",
          "start_line": 1,
          "end_line": 10,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "",
            "/*",
            " * A simple wrapper around refcount. An allocated sched_core_cookie's",
            " * address is used to compute the cookie of the task.",
            " */",
            "struct sched_core_cookie {",
            "\trefcount_t refcnt;",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义了 sched_core_cookie 结构体，用于核心调度系统中管理任务的 cookie 引用计数，通过结构体地址计算 cookie 值",
          "similarity": 0.5670969486236572
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/core_sched.c",
          "start_line": 240,
          "end_line": 297,
          "content": [
            "void __sched_core_account_forceidle(struct rq *rq)",
            "{",
            "\tconst struct cpumask *smt_mask = cpu_smt_mask(cpu_of(rq));",
            "\tu64 delta, now = rq_clock(rq->core);",
            "\tstruct rq *rq_i;",
            "\tstruct task_struct *p;",
            "\tint i;",
            "",
            "\tlockdep_assert_rq_held(rq);",
            "",
            "\tWARN_ON_ONCE(!rq->core->core_forceidle_count);",
            "",
            "\tif (rq->core->core_forceidle_start == 0)",
            "\t\treturn;",
            "",
            "\tdelta = now - rq->core->core_forceidle_start;",
            "\tif (unlikely((s64)delta <= 0))",
            "\t\treturn;",
            "",
            "\trq->core->core_forceidle_start = now;",
            "",
            "\tif (WARN_ON_ONCE(!rq->core->core_forceidle_occupation)) {",
            "\t\t/* can't be forced idle without a running task */",
            "\t} else if (rq->core->core_forceidle_count > 1 ||",
            "\t\t   rq->core->core_forceidle_occupation > 1) {",
            "\t\t/*",
            "\t\t * For larger SMT configurations, we need to scale the charged",
            "\t\t * forced idle amount since there can be more than one forced",
            "\t\t * idle sibling and more than one running cookied task.",
            "\t\t */",
            "\t\tdelta *= rq->core->core_forceidle_count;",
            "\t\tdelta = div_u64(delta, rq->core->core_forceidle_occupation);",
            "\t}",
            "",
            "\tfor_each_cpu(i, smt_mask) {",
            "\t\trq_i = cpu_rq(i);",
            "\t\tp = rq_i->core_pick ?: rq_i->curr;",
            "",
            "\t\tif (p == rq_i->idle)",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * Note: this will account forceidle to the current cpu, even",
            "\t\t * if it comes from our SMT sibling.",
            "\t\t */",
            "\t\t__account_forceidle_time(p, delta);",
            "\t}",
            "}",
            "void __sched_core_tick(struct rq *rq)",
            "{",
            "\tif (!rq->core->core_forceidle_count)",
            "\t\treturn;",
            "",
            "\tif (rq != rq->core)",
            "\t\tupdate_rq_clock(rq->core);",
            "",
            "\t__sched_core_account_forceidle(rq);",
            "}"
          ],
          "function_name": "__sched_core_account_forceidle, __sched_core_tick",
          "description": "提供强制空闲时间统计功能，通过遍历 SMT 核心计算并分摊强制空闲时间消耗，tick 中断触发强制空闲会计入逻辑",
          "similarity": 0.5366507172584534
        }
      ]
    },
    {
      "source_file": "mm/balloon_compaction.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:41:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `balloon_compaction.c`\n\n---\n\n# balloon_compaction.c 技术文档\n\n## 1. 文件概述\n\n`balloon_compaction.c` 是 Linux 内核中用于支持内存气球（Memory Ballooning）机制与内存压缩（Compaction）协同工作的核心模块。该文件提供了通用接口，使得由气球驱动程序管理的页面可以被内存压缩子系统识别为可迁移（movable），从而在内存碎片整理过程中安全地移动这些页面，提升高阶内存分配的成功率。此机制主要用于虚拟化环境中，允许宿主机动态调整客户机（Guest）的可用内存。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`balloon_page_alloc()`**  \n  分配一个新的页面，专用于加入气球页面列表。使用特殊的 GFP 标志（如 `__GFP_NOMEMALLOC`, `__GFP_NORETRY`, `__GFP_NOWARN`）以避免在内存压力下触发 OOM 或重试。\n\n- **`balloon_page_enqueue()`**  \n  将单个通过 `balloon_page_alloc()` 分配的页面插入到指定气球设备的页面列表中，并增加 `BALLOON_INFLATE` 统计计数。\n\n- **`balloon_page_list_enqueue()`**  \n  批量将一个页面链表中的所有页面插入到气球设备的页面列表中，适用于高效批量操作。\n\n- **`balloon_page_dequeue()`**  \n  从气球设备的页面列表中移除并返回一个页面，供驱动释放回系统。若无法出队且无孤立页面，则触发 `BUG()` 防止死循环。\n\n- **`balloon_page_list_dequeue()`**  \n  批量从气球设备中取出最多 `n_req_pages` 个页面，放入调用者提供的链表中，用于批量释放。\n\n- **`balloon_page_isolate()`**（仅当 `CONFIG_BALLOON_COMPACTION` 启用）  \n  在内存压缩过程中，将气球页面从主列表中隔离，防止并发访问，并增加 `isolated_pages` 计数。\n\n- **`balloon_page_putback()`**（仅当 `CONFIG_BALLOON_COMPACTION` 启用）  \n  将被隔离的气球页面重新放回主页面列表，并减少 `isolated_pages` 计数。\n\n- **`balloon_page_migrate()`**（仅当 `CONFIG_BALLOON_COMPACTION` 启用）  \n  实现气球页面的迁移逻辑，作为内存压缩中 `move_to_new_page()` 的对应处理函数（代码片段未完整）。\n\n### 关键数据结构\n\n- **`struct balloon_dev_info`**  \n  气球设备信息结构体，包含：\n  - `pages`：已入队的气球页面链表\n  - `pages_lock`：保护页面列表的自旋锁\n  - `isolated_pages`：当前被压缩子系统隔离的页面数量（仅在 `CONFIG_BALLOON_COMPACTION` 下使用）\n\n## 3. 关键实现\n\n- **线程安全与并发控制**  \n  所有对 `balloon_dev_info->pages` 链表的操作均受 `pages_lock` 自旋锁保护，并在中断禁用上下文中执行（`spin_lock_irqsave`），确保在高并发或中断上下文中的安全性。\n\n- **页面锁定机制**  \n  在入队和出队时使用 `trylock_page()` 确保当前是唯一持有页面引用的实体。若加锁失败，说明存在并发访问，可能意味着内存损坏或状态不一致，此时会跳过或报错。\n\n- **与内存压缩集成**  \n  当启用 `CONFIG_BALLOON_COMPACTION` 时，气球页面可通过 `PageIsolated()` 标志被识别为正在被压缩子系统处理。出队操作会跳过这些页面，避免破坏压缩流程。\n\n- **统计计数**  \n  使用 `__count_vm_event(BALLOON_INFLATE)` 和 `__count_vm_event(BALLOON_DEFLATE)` 跟踪气球膨胀/收缩操作次数，便于性能监控和调试。\n\n- **错误检测与防御性编程**  \n  在 `balloon_page_dequeue()` 中，若页面列表为空且无孤立页面，说明页面丢失，触发 `BUG()` 以防止驱动陷入无限循环。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/mm.h>`：内存管理基础接口\n  - `<linux/slab.h>`：内存分配\n  - `<linux/balloon_compaction.h>`：气球压缩相关声明（如 `balloon_page_insert`, `balloon_page_delete`, `balloon_page_device` 等）\n\n- **内核配置依赖**：\n  - `CONFIG_MEMORY_BALLOONING`：启用内存气球机制\n  - `CONFIG_BALLOON_COMPACTION`：启用气球页面的可压缩支持（条件编译）\n\n- **与其他子系统交互**：\n  - **内存压缩子系统（mm/compaction.c）**：通过注册的 `isolate` / `migrate` 回调函数参与页面迁移\n  - **虚拟化驱动（如 virtio_balloon）**：作为使用者调用本模块提供的 enqueue/dequeue 接口管理气球内存\n\n## 5. 使用场景\n\n- **虚拟化环境中的内存动态调整**  \n  客户机操作系统通过气球驱动（如 `virtio_balloon`）向宿主机“归还”内存时，调用 `balloon_page_alloc()` + `balloon_page_enqueue()` 将页面加入气球列表；当宿主机释放内存给客户机时，驱动调用 `balloon_page_dequeue()` 获取页面并释放回 buddy allocator。\n\n- **高阶内存分配优化**  \n  当系统需要大块连续物理内存（如透明大页 THP）但存在碎片时，内存压缩子系统会尝试迁移可移动页面。气球页面因本模块支持而被视为可移动，从而被安全迁移，帮助形成连续内存区域。\n\n- **内存热插拔与 NUMA 迁移**  \n  在 NUMA 节点间迁移内存或热移除内存区域时，气球页面可被压缩机制迁移，提高操作成功率。\n\n- **OOM 避免与内存回收**  \n  气球机制本身是一种主动内存回收手段，配合压缩可进一步提升内存利用率，减少 OOM 发生概率。",
      "similarity": 0.6110355257987976,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/balloon_compaction.c",
          "start_line": 14,
          "end_line": 129,
          "content": [
            "static void balloon_page_enqueue_one(struct balloon_dev_info *b_dev_info,",
            "\t\t\t\t     struct page *page)",
            "{",
            "\t/*",
            "\t * Block others from accessing the 'page' when we get around to",
            "\t * establishing additional references. We should be the only one",
            "\t * holding a reference to the 'page' at this point. If we are not, then",
            "\t * memory corruption is possible and we should stop execution.",
            "\t */",
            "\tBUG_ON(!trylock_page(page));",
            "\tballoon_page_insert(b_dev_info, page);",
            "\tunlock_page(page);",
            "\t__count_vm_event(BALLOON_INFLATE);",
            "}",
            "size_t balloon_page_list_enqueue(struct balloon_dev_info *b_dev_info,",
            "\t\t\t\t struct list_head *pages)",
            "{",
            "\tstruct page *page, *tmp;",
            "\tunsigned long flags;",
            "\tsize_t n_pages = 0;",
            "",
            "\tspin_lock_irqsave(&b_dev_info->pages_lock, flags);",
            "\tlist_for_each_entry_safe(page, tmp, pages, lru) {",
            "\t\tlist_del(&page->lru);",
            "\t\tballoon_page_enqueue_one(b_dev_info, page);",
            "\t\tn_pages++;",
            "\t}",
            "\tspin_unlock_irqrestore(&b_dev_info->pages_lock, flags);",
            "\treturn n_pages;",
            "}",
            "size_t balloon_page_list_dequeue(struct balloon_dev_info *b_dev_info,",
            "\t\t\t\t struct list_head *pages, size_t n_req_pages)",
            "{",
            "\tstruct page *page, *tmp;",
            "\tunsigned long flags;",
            "\tsize_t n_pages = 0;",
            "",
            "\tspin_lock_irqsave(&b_dev_info->pages_lock, flags);",
            "\tlist_for_each_entry_safe(page, tmp, &b_dev_info->pages, lru) {",
            "\t\tif (n_pages == n_req_pages)",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * Block others from accessing the 'page' while we get around to",
            "\t\t * establishing additional references and preparing the 'page'",
            "\t\t * to be released by the balloon driver.",
            "\t\t */",
            "\t\tif (!trylock_page(page))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (IS_ENABLED(CONFIG_BALLOON_COMPACTION) &&",
            "\t\t    PageIsolated(page)) {",
            "\t\t\t/* raced with isolation */",
            "\t\t\tunlock_page(page);",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tballoon_page_delete(page);",
            "\t\t__count_vm_event(BALLOON_DEFLATE);",
            "\t\tlist_add(&page->lru, pages);",
            "\t\tunlock_page(page);",
            "\t\tn_pages++;",
            "\t}",
            "\tspin_unlock_irqrestore(&b_dev_info->pages_lock, flags);",
            "",
            "\treturn n_pages;",
            "}",
            "void balloon_page_enqueue(struct balloon_dev_info *b_dev_info,",
            "\t\t\t  struct page *page)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tspin_lock_irqsave(&b_dev_info->pages_lock, flags);",
            "\tballoon_page_enqueue_one(b_dev_info, page);",
            "\tspin_unlock_irqrestore(&b_dev_info->pages_lock, flags);",
            "}",
            "static bool balloon_page_isolate(struct page *page, isolate_mode_t mode)",
            "",
            "{",
            "\tstruct balloon_dev_info *b_dev_info = balloon_page_device(page);",
            "\tunsigned long flags;",
            "",
            "\tspin_lock_irqsave(&b_dev_info->pages_lock, flags);",
            "\tlist_del(&page->lru);",
            "\tb_dev_info->isolated_pages++;",
            "\tspin_unlock_irqrestore(&b_dev_info->pages_lock, flags);",
            "",
            "\treturn true;",
            "}",
            "static void balloon_page_putback(struct page *page)",
            "{",
            "\tstruct balloon_dev_info *b_dev_info = balloon_page_device(page);",
            "\tunsigned long flags;",
            "",
            "\tspin_lock_irqsave(&b_dev_info->pages_lock, flags);",
            "\tlist_add(&page->lru, &b_dev_info->pages);",
            "\tb_dev_info->isolated_pages--;",
            "\tspin_unlock_irqrestore(&b_dev_info->pages_lock, flags);",
            "}",
            "static int balloon_page_migrate(struct page *newpage, struct page *page,",
            "\t\tenum migrate_mode mode)",
            "{",
            "\tstruct balloon_dev_info *balloon = balloon_page_device(page);",
            "",
            "\t/*",
            "\t * We can not easily support the no copy case here so ignore it as it",
            "\t * is unlikely to be used with balloon pages. See include/linux/hmm.h",
            "\t * for a user of the MIGRATE_SYNC_NO_COPY mode.",
            "\t */",
            "\tif (mode == MIGRATE_SYNC_NO_COPY)",
            "\t\treturn -EINVAL;",
            "",
            "\tVM_BUG_ON_PAGE(!PageLocked(page), page);",
            "\tVM_BUG_ON_PAGE(!PageLocked(newpage), newpage);",
            "",
            "\treturn balloon->migratepage(balloon, newpage, page, mode);",
            "}"
          ],
          "function_name": "balloon_page_enqueue_one, balloon_page_list_enqueue, balloon_page_list_dequeue, balloon_page_enqueue, balloon_page_isolate, balloon_page_putback, balloon_page_migrate",
          "description": "提供气球内存页的并发控制及迁移管理，通过自旋锁保护页表操作，实现页面在LRU链表间的移动、隔离和迁移，支持气球膨胀/收缩事件统计",
          "similarity": 0.5778106451034546
        },
        {
          "chunk_id": 0,
          "file_path": "mm/balloon_compaction.c",
          "start_line": 1,
          "end_line": 13,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * mm/balloon_compaction.c",
            " *",
            " * Common interface for making balloon pages movable by compaction.",
            " *",
            " * Copyright (C) 2012, Red Hat, Inc.  Rafael Aquini <aquini@redhat.com>",
            " */",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/export.h>",
            "#include <linux/balloon_compaction.h>",
            ""
          ],
          "function_name": null,
          "description": "上下文不完整",
          "similarity": 0.4897949993610382
        }
      ]
    }
  ]
}