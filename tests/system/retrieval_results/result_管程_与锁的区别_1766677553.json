{
  "query": "管程 与锁的区别",
  "timestamp": "2025-12-25 23:45:53",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/rtmutex_api.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:49:05\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\rtmutex_api.c`\n\n---\n\n# `locking/rtmutex_api.c` 技术文档\n\n## 1. 文件概述\n\n`rtmutex_api.c` 是 Linux 内核中实时互斥锁（Real-Time Mutex, rtmutex）的公共 API 实现文件。该文件封装了底层 rtmutex 核心逻辑（定义在 `rtmutex.c` 中），为内核其他子系统提供统一、安全、可调试的互斥锁操作接口。它支持多种锁获取模式（不可中断、可中断、可终止）、调试锁依赖（lockdep）、PI（Priority Inheritance，优先级继承）机制，并为 futex（快速用户空间互斥）提供专用变体接口。该文件通过条件编译适配是否启用锁调试功能（`CONFIG_DEBUG_LOCK_ALLOC`）。\n\n## 2. 核心功能\n\n### 全局变量\n- `max_lock_depth`: 定义优先级继承链（boosting chain）的最大遍历深度，防止死锁检测时无限循环，默认值为 1024。\n\n### 主要函数\n\n#### 初始化与销毁\n- `rt_mutex_base_init()`: 初始化 `rt_mutex_base` 结构体的基础字段。\n- `__rt_mutex_init()`: 完整初始化一个 `rt_mutex`，包括底层 rtmutex 和 lockdep 调试信息。\n- `rt_mutex_init_proxy_locked()`: 为 PI-futex 场景初始化并立即锁定 rtmutex，指定代理持有者（proxy owner）。\n- `rt_mutex_proxy_unlock()`: 为 PI-futex 场景释放由代理持有的 rtmutex。\n\n#### 锁获取（Locking）\n- `rt_mutex_lock[_nested]()`: 以不可中断方式获取 rtmutex（支持 lockdep 嵌套子类）。\n- `_rt_mutex_lock_nest_lock()`: 获取 rtmutex 并关联一个嵌套锁（nest lock）用于 lockdep。\n- `rt_mutex_lock_interruptible()`: 以可被信号中断的方式获取 rtmutex。\n- `rt_mutex_lock_killable()`: 以可被致命信号中断的方式获取 rtmutex。\n- `rt_mutex_trylock()`: 尝试非阻塞获取 rtmutex，成功返回 1，失败返回 0。\n\n#### 锁释放（Unlocking）\n- `rt_mutex_unlock()`: 释放 rtmutex。\n- `rt_mutex_futex_unlock()`: 专用于 futex 的 rtmutex 释放接口。\n- `__rt_mutex_futex_unlock()`: futex 释放的内部实现，需配合 `rt_mutex_postunlock()` 使用。\n\n#### Futex 专用接口\n- `rt_mutex_futex_trylock()`: futex 使用的非阻塞尝试锁接口。\n- `__rt_mutex_futex_trylock()`: futex 尝试锁的底层实现。\n\n#### 代理锁操作（Proxy Locking，用于 PI-futex）\n- `__rt_mutex_start_proxy_lock()`: 为另一个任务启动代理锁获取流程（仅入队，不阻塞等待）。\n\n## 3. 关键实现\n\n### 锁操作通用封装\n- `__rt_mutex_lock_common()` 是所有阻塞式锁获取函数的统一入口。它负责：\n  - 调用 `might_sleep()` 提示可能睡眠。\n  - 通过 `mutex_acquire_nest()` 向 lockdep 子系统注册锁获取事件。\n  - 调用底层 `__rt_mutex_lock()` 执行实际的锁逻辑。\n  - 若获取失败（如被信号中断），则调用 `mutex_release()` 通知 lockdep 释放。\n\n### 调试支持\n- 在 `CONFIG_DEBUG_LOCK_ALLOC` 启用时，提供带 lockdep 子类和嵌套锁参数的锁接口（如 `rt_mutex_lock_nested`），增强死锁检测能力。\n- `rt_mutex_trylock()` 在调试模式下会检查调用上下文是否为任务上下文（`in_task()`），防止在中断上下文中误用。\n- 初始化函数 `__rt_mutex_init()` 调用 `debug_check_no_locks_freed()` 防止对已释放内存初始化锁。\n\n### Futex 特殊处理\n- Futex 相关接口（如 `rt_mutex_futex_unlock`）绕过 rtmutex 的 fast-path，直接使用 slow-path 实现。\n- `rt_mutex_init_proxy_locked()` 为 PI-futex 场景中的 `wait_lock` 分配独立的 lockdep 类键（`pi_futex_key`），避免与 futex 哈希桶自旋锁产生虚假的锁递归警告。\n- `__rt_mutex_futex_unlock()` 在释放锁时，若存在等待者，则调用 `mark_wakeup_next_waiter()` 准备唤醒，并返回 `true` 指示需后续调用 `rt_mutex_postunlock()` 完成唤醒。\n\n### 代理锁机制\n- 代理锁函数（如 `rt_mutex_init_proxy_locked` 和 `__rt_mutex_start_proxy_lock`）用于 PI-futex 实现，允许内核代表用户空间任务持有或竞争锁，是优先级继承在 futex 上的关键支撑。\n\n## 4. 依赖关系\n\n- **底层实现**: 通过 `#include \"rtmutex.c\"`（配合 `RT_MUTEX_BUILD_MUTEX` 宏）内联包含 `rtmutex.c` 中的核心逻辑（如 `__rt_mutex_lock`, `__rt_mutex_unlock` 等）。\n- **同步原语**: 依赖 `<linux/spinlock.h>` 提供自旋锁操作（如 `raw_spin_lock_irqsave`）。\n- **调试子系统**: \n  - 依赖 Lockdep（`<linux/lockdep.h>` 隐式包含）进行锁依赖和死锁检测。\n  - 依赖 RT Mutex 调试（`CONFIG_DEBUG_RT_MUTEXES`）进行运行时检查。\n- **调度器**: 使用 `TASK_*` 状态常量（如 `TASK_INTERRUPTIBLE`）与调度器交互，支持可中断睡眠。\n- **导出符号**: 通过 `EXPORT_SYMBOL` 和 `EXPORT_SYMBOL_GPL` 向内核其他模块（如 futex、PI 子系统）提供 API。\n\n## 5. 使用场景\n\n- **实时互斥锁**: 作为内核中支持优先级继承的互斥锁实现，用于需要避免优先级反转的实时任务同步。\n- **PI-futex 支持**: 为用户空间的 PI-aware futex（`FUTEX_LOCK_PI` 等操作）提供内核态代理锁管理，实现跨进程的优先级继承。\n- **内核子系统同步**: 被需要强优先级继承语义的内核子系统（如某些设备驱动、实时调度相关代码）直接使用。\n- **调试与验证**: 在启用锁调试的内核配置下，为 lockdep 提供详细的锁获取/释放轨迹，辅助死锁分析。",
      "similarity": 0.49798083305358887,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 22,
          "end_line": 127,
          "content": [
            "static __always_inline int __rt_mutex_lock_common(struct rt_mutex *lock,",
            "\t\t\t\t\t\t  unsigned int state,",
            "\t\t\t\t\t\t  struct lockdep_map *nest_lock,",
            "\t\t\t\t\t\t  unsigned int subclass)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, _RET_IP_);",
            "\tret = __rt_mutex_lock(&lock->rtmutex, state);",
            "\tif (ret)",
            "\t\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\treturn ret;",
            "}",
            "void rt_mutex_base_init(struct rt_mutex_base *rtb)",
            "{",
            "\t__rt_mutex_base_init(rtb);",
            "}",
            "void __sched rt_mutex_lock_nested(struct rt_mutex *lock, unsigned int subclass)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, subclass);",
            "}",
            "void __sched _rt_mutex_lock_nest_lock(struct rt_mutex *lock, struct lockdep_map *nest_lock)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, nest_lock, 0);",
            "}",
            "void __sched rt_mutex_lock(struct rt_mutex *lock)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_lock_interruptible(struct rt_mutex *lock)",
            "{",
            "\treturn __rt_mutex_lock_common(lock, TASK_INTERRUPTIBLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_lock_killable(struct rt_mutex *lock)",
            "{",
            "\treturn __rt_mutex_lock_common(lock, TASK_KILLABLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_trylock(struct rt_mutex *lock)",
            "{",
            "\tint ret;",
            "",
            "\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))",
            "\t\treturn 0;",
            "",
            "\tret = __rt_mutex_trylock(&lock->rtmutex);",
            "\tif (ret)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn ret;",
            "}",
            "void __sched rt_mutex_unlock(struct rt_mutex *lock)",
            "{",
            "\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\t__rt_mutex_unlock(&lock->rtmutex);",
            "}",
            "int __sched rt_mutex_futex_trylock(struct rt_mutex_base *lock)",
            "{",
            "\treturn rt_mutex_slowtrylock(lock);",
            "}",
            "int __sched __rt_mutex_futex_trylock(struct rt_mutex_base *lock)",
            "{",
            "\treturn __rt_mutex_slowtrylock(lock);",
            "}",
            "bool __sched __rt_mutex_futex_unlock(struct rt_mutex_base *lock,",
            "\t\t\t\t     struct rt_wake_q_head *wqh)",
            "{",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tdebug_rt_mutex_unlock(lock);",
            "",
            "\tif (!rt_mutex_has_waiters(lock)) {",
            "\t\tlock->owner = NULL;",
            "\t\treturn false; /* done */",
            "\t}",
            "",
            "\t/*",
            "\t * We've already deboosted, mark_wakeup_next_waiter() will",
            "\t * retain preempt_disabled when we drop the wait_lock, to",
            "\t * avoid inversion prior to the wakeup.  preempt_disable()",
            "\t * therein pairs with rt_mutex_postunlock().",
            "\t */",
            "\tmark_wakeup_next_waiter(wqh, lock);",
            "",
            "\treturn true; /* call postunlock() */",
            "}",
            "void __sched rt_mutex_futex_unlock(struct rt_mutex_base *lock)",
            "{",
            "\tDEFINE_RT_WAKE_Q(wqh);",
            "\tunsigned long flags;",
            "\tbool postunlock;",
            "",
            "\traw_spin_lock_irqsave(&lock->wait_lock, flags);",
            "\tpostunlock = __rt_mutex_futex_unlock(lock, &wqh);",
            "\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);",
            "",
            "\tif (postunlock)",
            "\t\trt_mutex_postunlock(&wqh);",
            "}",
            "void __sched __rt_mutex_init(struct rt_mutex *lock, const char *name,",
            "\t\t\t     struct lock_class_key *key)",
            "{",
            "\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));",
            "\t__rt_mutex_base_init(&lock->rtmutex);",
            "\tlockdep_init_map_wait(&lock->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "}"
          ],
          "function_name": "__rt_mutex_lock_common, rt_mutex_base_init, rt_mutex_lock_nested, _rt_mutex_lock_nest_lock, rt_mutex_lock, rt_mutex_lock_interruptible, rt_mutex_lock_killable, rt_mutex_trylock, rt_mutex_unlock, rt_mutex_futex_trylock, __rt_mutex_futex_trylock, __rt_mutex_futex_unlock, rt_mutex_futex_unlock, __rt_mutex_init",
          "description": "实现多种rtmutex操作接口，包括常规加锁、尝试加锁、解锁及嵌套锁管理，通过统一入口函数处理不同睡眠状态和锁依赖追踪，维护锁状态转换和抢占控制。",
          "similarity": 0.49665871262550354
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 236,
          "end_line": 354,
          "content": [
            "void __sched rt_mutex_init_proxy_locked(struct rt_mutex_base *lock,",
            "\t\t\t\t\tstruct task_struct *proxy_owner)",
            "{",
            "\tstatic struct lock_class_key pi_futex_key;",
            "",
            "\t__rt_mutex_base_init(lock);",
            "\t/*",
            "\t * On PREEMPT_RT the futex hashbucket spinlock becomes 'sleeping'",
            "\t * and rtmutex based. That causes a lockdep false positive, because",
            "\t * some of the futex functions invoke spin_unlock(&hb->lock) with",
            "\t * the wait_lock of the rtmutex associated to the pi_futex held.",
            "\t * spin_unlock() in turn takes wait_lock of the rtmutex on which",
            "\t * the spinlock is based, which makes lockdep notice a lock",
            "\t * recursion. Give the futex/rtmutex wait_lock a separate key.",
            "\t */",
            "\tlockdep_set_class(&lock->wait_lock, &pi_futex_key);",
            "\trt_mutex_set_owner(lock, proxy_owner);",
            "}",
            "void __sched rt_mutex_proxy_unlock(struct rt_mutex_base *lock)",
            "{",
            "\tdebug_rt_mutex_proxy_unlock(lock);",
            "\trt_mutex_clear_owner(lock);",
            "}",
            "int __sched __rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t\tstruct rt_mutex_waiter *waiter,",
            "\t\t\t\t\tstruct task_struct *task)",
            "{",
            "\tint ret;",
            "",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tif (try_to_take_rt_mutex(lock, task, NULL))",
            "\t\treturn 1;",
            "",
            "\t/* We enforce deadlock detection for futexes */",
            "\tret = task_blocks_on_rt_mutex(lock, waiter, task, NULL,",
            "\t\t\t\t      RT_MUTEX_FULL_CHAINWALK);",
            "",
            "\tif (ret && !rt_mutex_owner(lock)) {",
            "\t\t/*",
            "\t\t * Reset the return value. We might have",
            "\t\t * returned with -EDEADLK and the owner",
            "\t\t * released the lock while we were walking the",
            "\t\t * pi chain.  Let the waiter sort it out.",
            "\t\t */",
            "\t\tret = 0;",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "int __sched rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t      struct rt_mutex_waiter *waiter,",
            "\t\t\t\t      struct task_struct *task)",
            "{",
            "\tint ret;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\tret = __rt_mutex_start_proxy_lock(lock, waiter, task);",
            "\tif (unlikely(ret))",
            "\t\tremove_waiter(lock, waiter);",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn ret;",
            "}",
            "int __sched rt_mutex_wait_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t     struct hrtimer_sleeper *to,",
            "\t\t\t\t     struct rt_mutex_waiter *waiter)",
            "{",
            "\tint ret;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\t/* sleep on the mutex */",
            "\tset_current_state(TASK_INTERRUPTIBLE);",
            "\tret = rt_mutex_slowlock_block(lock, NULL, TASK_INTERRUPTIBLE, to, waiter);",
            "\t/*",
            "\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might",
            "\t * have to fix that up.",
            "\t */",
            "\tfixup_rt_mutex_waiters(lock, true);",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn ret;",
            "}",
            "bool __sched rt_mutex_cleanup_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t\t struct rt_mutex_waiter *waiter)",
            "{",
            "\tbool cleanup = false;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\t/*",
            "\t * Do an unconditional try-lock, this deals with the lock stealing",
            "\t * state where __rt_mutex_futex_unlock() -> mark_wakeup_next_waiter()",
            "\t * sets a NULL owner.",
            "\t *",
            "\t * We're not interested in the return value, because the subsequent",
            "\t * test on rt_mutex_owner() will infer that. If the trylock succeeded,",
            "\t * we will own the lock and it will have removed the waiter. If we",
            "\t * failed the trylock, we're still not owner and we need to remove",
            "\t * ourselves.",
            "\t */",
            "\ttry_to_take_rt_mutex(lock, current, waiter);",
            "\t/*",
            "\t * Unless we're the owner; we're still enqueued on the wait_list.",
            "\t * So check if we became owner, if not, take us off the wait_list.",
            "\t */",
            "\tif (rt_mutex_owner(lock) != current) {",
            "\t\tremove_waiter(lock, waiter);",
            "\t\tcleanup = true;",
            "\t}",
            "\t/*",
            "\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might",
            "\t * have to fix that up.",
            "\t */",
            "\tfixup_rt_mutex_waiters(lock, false);",
            "",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn cleanup;",
            "}"
          ],
          "function_name": "rt_mutex_init_proxy_locked, rt_mutex_proxy_unlock, __rt_mutex_start_proxy_lock, rt_mutex_start_proxy_lock, rt_mutex_wait_proxy_lock, rt_mutex_cleanup_proxy_lock",
          "description": "处理锁代理机制，包含代理锁初始化、释放逻辑及死锁检测流程，通过遍历锁链进行优先级继承调整，确保多线程环境下的锁所有权安全转移。",
          "similarity": 0.47643548250198364
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 453,
          "end_line": 554,
          "content": [
            "void __sched rt_mutex_adjust_pi(struct task_struct *task)",
            "{",
            "\tstruct rt_mutex_waiter *waiter;",
            "\tstruct rt_mutex_base *next_lock;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&task->pi_lock, flags);",
            "",
            "\twaiter = task->pi_blocked_on;",
            "\tif (!waiter || rt_waiter_node_equal(&waiter->tree, task_to_waiter_node(task))) {",
            "\t\traw_spin_unlock_irqrestore(&task->pi_lock, flags);",
            "\t\treturn;",
            "\t}",
            "\tnext_lock = waiter->lock;",
            "\traw_spin_unlock_irqrestore(&task->pi_lock, flags);",
            "",
            "\t/* gets dropped in rt_mutex_adjust_prio_chain()! */",
            "\tget_task_struct(task);",
            "",
            "\trt_mutex_adjust_prio_chain(task, RT_MUTEX_MIN_CHAINWALK, NULL,",
            "\t\t\t\t   next_lock, NULL, task);",
            "}",
            "void __sched rt_mutex_postunlock(struct rt_wake_q_head *wqh)",
            "{",
            "\trt_mutex_wake_up_q(wqh);",
            "}",
            "void rt_mutex_debug_task_free(struct task_struct *task)",
            "{",
            "\tDEBUG_LOCKS_WARN_ON(!RB_EMPTY_ROOT(&task->pi_waiters.rb_root));",
            "\tDEBUG_LOCKS_WARN_ON(task->pi_blocked_on);",
            "}",
            "void __mutex_rt_init(struct mutex *mutex, const char *name,",
            "\t\t     struct lock_class_key *key)",
            "{",
            "\tdebug_check_no_locks_freed((void *)mutex, sizeof(*mutex));",
            "\tlockdep_init_map_wait(&mutex->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "}",
            "static __always_inline int __mutex_lock_common(struct mutex *lock,",
            "\t\t\t\t\t       unsigned int state,",
            "\t\t\t\t\t       unsigned int subclass,",
            "\t\t\t\t\t       struct lockdep_map *nest_lock,",
            "\t\t\t\t\t       unsigned long ip)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);",
            "\tret = __rt_mutex_lock(&lock->rtmutex, state);",
            "\tif (ret)",
            "\t\tmutex_release(&lock->dep_map, ip);",
            "\telse",
            "\t\tlock_acquired(&lock->dep_map, ip);",
            "\treturn ret;",
            "}",
            "void __sched mutex_lock_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched _mutex_lock_nest_lock(struct mutex *lock,",
            "\t\t\t\t   struct lockdep_map *nest_lock)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, nest_lock, _RET_IP_);",
            "}",
            "int __sched mutex_lock_interruptible_nested(struct mutex *lock,",
            "\t\t\t\t\t    unsigned int subclass)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_killable_nested(struct mutex *lock,",
            "\t\t\t\t\t    unsigned int subclass)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched mutex_lock_io_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\tint token;",
            "",
            "\tmight_sleep();",
            "",
            "\ttoken = io_schedule_prepare();",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "\tio_schedule_finish(token);",
            "}",
            "void __sched mutex_lock(struct mutex *lock)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_interruptible(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_killable(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);",
            "}",
            "void __sched mutex_lock_io(struct mutex *lock)",
            "{",
            "\tint token = io_schedule_prepare();",
            "",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "\tio_schedule_finish(token);",
            "}"
          ],
          "function_name": "rt_mutex_adjust_pi, rt_mutex_postunlock, rt_mutex_debug_task_free, __mutex_rt_init, __mutex_lock_common, mutex_lock_nested, _mutex_lock_nest_lock, mutex_lock_interruptible_nested, mutex_lock_killable_nested, mutex_lock_io_nested, mutex_lock, mutex_lock_interruptible, mutex_lock_killable, mutex_lock_io",
          "description": "提供标准互斥锁（mutex）的封装接口，将rtmutex操作映射到传统mutex接口，包含嵌套加锁、I/O路径加锁、优先级调整等特殊场景的支持实现。",
          "similarity": 0.47218984365463257
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 590,
          "end_line": 607,
          "content": [
            "int __sched mutex_trylock(struct mutex *lock)",
            "{",
            "\tint ret;",
            "",
            "\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))",
            "\t\treturn 0;",
            "",
            "\tret = __rt_mutex_trylock(&lock->rtmutex);",
            "\tif (ret)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn ret;",
            "}",
            "void __sched mutex_unlock(struct mutex *lock)",
            "{",
            "\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\t__rt_mutex_unlock(&lock->rtmutex);",
            "}"
          ],
          "function_name": "mutex_trylock, mutex_unlock",
          "description": "实现互斥锁的尝试获取和释放操作，通过底层rtmutex_trylock进行非阻塞获取，成功时记录锁占用状态，释放时触发锁依赖跟踪和底层解锁流程。",
          "similarity": 0.46206170320510864
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 1,
          "end_line": 21,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * rtmutex API",
            " */",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "",
            "#define RT_MUTEX_BUILD_MUTEX",
            "#include \"rtmutex.c\"",
            "",
            "/*",
            " * Max number of times we'll walk the boosting chain:",
            " */",
            "int max_lock_depth = 1024;",
            "",
            "/*",
            " * Debug aware fast / slowpath lock,trylock,unlock",
            " *",
            " * The atomic acquire/release ops are compiled away, when either the",
            " * architecture does not support cmpxchg or when debugging is enabled.",
            " */"
          ],
          "function_name": null,
          "description": "定义实时互斥锁（rtmutex）的核心参数和调试相关配置，通过宏引入rtmutex实现文件，并设置最大锁深度限制，启用原子操作优化和调试支持。",
          "similarity": 0.44966360926628113
        }
      ]
    },
    {
      "source_file": "kernel/watch_queue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:50:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `watch_queue.c`\n\n---\n\n# watch_queue.c 技术文档\n\n## 文件概述\n\n`watch_queue.c` 实现了 Linux 内核中的**监视队列**（Watch Queue）机制，这是一种基于管道（pipe）构建的通用事件通知系统。该机制允许内核子系统（如文件系统、密钥管理、设备驱动等）向用户空间异步发送结构化通知。用户空间通过创建特殊类型的管道并关联监视队列，即可接收来自内核的各类事件通知。该文件定义了通知的投递、过滤、缓冲管理及与管道集成的核心逻辑。\n\n## 核心功能\n\n### 主要函数\n\n- **`__post_watch_notification()`**  \n  核心通知投递函数。遍历指定 `watch_list` 中所有匹配 `id` 的监视器（`watch`），对每个关联的 `watch_queue` 应用过滤规则、安全检查，并将通知写入底层管道。\n\n- **`post_one_notification()`**  \n  将单个通知写入指定 `watch_queue` 的底层管道缓冲区。负责从预分配的通知页中获取空闲槽位、填充数据、更新管道头指针并唤醒等待读取的进程。\n\n- **`filter_watch_notification()`**  \n  根据 `watch_filter` 中的类型、子类型和信息掩码规则，判断是否允许特定通知通过。\n\n- **`watch_queue_set_size()`**  \n  为监视队列分配预分配的通知缓冲区（页数组和位图），并调整底层管道的环形缓冲区大小。\n\n- **`watch_queue_pipe_buf_release()`**  \n  管道缓冲区释放回调。当用户空间读取完通知后，将对应的通知槽位在位图中标记为空闲，供后续复用。\n\n### 关键数据结构\n\n- **`struct watch_queue`**  \n  表示一个监视队列，包含：\n  - 指向底层 `pipe_inode_info` 的指针\n  - 预分配的通知页数组（`notes`）\n  - 通知槽位空闲位图（`notes_bitmap`）\n  - 通知过滤器（`filter`）\n  - 保护锁（`lock`）\n\n- **`struct watch_notification`**  \n  通用通知记录格式，包含类型（`type`）、子类型（`subtype`）、信息字段（`info`，含长度和ID）及可变负载。\n\n- **`struct watch_filter` / `struct watch_type_filter`**  \n  定义通知过滤规则，支持按类型、子类型及信息字段的位掩码进行精确过滤。\n\n- **`watch_queue_pipe_buf_ops`**  \n  自定义的 `pipe_buf_operations`，用于管理监视队列专用管道缓冲区的生命周期。\n\n## 关键实现\n\n### 基于管道的通知传输\n- 监视队列复用内核管道（`pipe_inode_info`）作为通知传输通道，利用其成熟的读写、轮询、异步通知机制。\n- 通过自定义 `pipe_buf_operations`（`watch_queue_pipe_buf_ops`）实现通知槽位的回收：当用户读取通知后，`release` 回调将对应槽位在 `notes_bitmap` 中置位，标记为空闲。\n\n### 预分配通知缓冲区\n- 通知数据存储在预分配的内核页（`notes`）中，每页划分为多个固定大小（128字节）的槽位（`WATCH_QUEUE_NOTE_SIZE`）。\n- 使用位图（`notes_bitmap`）跟踪槽位使用状态，1 表示空闲。投递通知时通过 `find_first_bit()` 快速查找空闲槽位。\n- 缓冲区大小由用户通过 `watch_queue_set_size()` 设置（1-512个通知），并受管道缓冲区配额限制。\n\n### 通知投递流程\n1. **匹配监视器**：遍历 `watch_list`，查找 `id` 匹配的 `watch`。\n2. **应用过滤**：若队列配置了过滤器，调用 `filter_watch_notification()` 决定是否丢弃。\n3. **安全检查**：调用 LSM 钩子 `security_post_notification()` 进行权限验证。\n4. **写入管道**：\n   - 获取空闲通知槽位，复制通知数据。\n   - 构造 `pipe_buffer` 指向该槽位，设置自定义操作集。\n   - 更新管道 `head` 指针，唤醒等待读取的进程。\n   - 若缓冲区满，标记前一个缓冲区为 `PIPE_BUF_FLAG_LOSS` 表示丢包。\n\n### 并发与同步\n- **RCU 保护**：`watch_list` 和 `watch_queue` 的访问通过 RCU 机制保护，确保遍历时结构体不被释放。\n- **自旋锁**：\n  - `wqueue->lock`：保护 `wqueue` 状态（如 `pipe` 指针有效性）。\n  - `pipe->rd_wait.lock`：保护管道环形缓冲区的读写操作。\n- **原子操作**：管道 `head` 指针使用 `smp_store_release()` 更新，确保与 `pipe_read()` 的同步。\n\n## 依赖关系\n\n- **管道子系统**（`fs/pipe.c`）  \n  依赖管道的核心数据结构（`pipe_inode_info`、`pipe_buffer`）和操作接口（`pipe_buf()`、`pipe_full()`、`generic_pipe_buf_*`）。\n\n- **内存管理**  \n  使用 `alloc_page()`、`kmap_atomic()` 管理通知缓冲区页，`bitmap_alloc()` 管理槽位位图。\n\n- **安全模块**（LSM）  \n  通过 `security_post_notification()` 钩子集成安全策略。\n\n- **用户空间接口**  \n  与 `fs/watch_queue.c` 中的系统调用（如 `watch_queue_set_size()`）协同工作，后者负责创建监视队列并与管道关联。\n\n- **头文件依赖**  \n  `linux/watch_queue.h`（核心数据结构定义）、`linux/pipe_fs_i.h`（管道内部接口）。\n\n## 使用场景\n\n- **文件系统事件监控**  \n  如 `fsnotify` 子系统可通过监视队列向用户空间报告文件访问、修改等事件。\n\n- **密钥管理通知**  \n  内核密钥环（`KEYS`）子系统使用该机制通知密钥状态变更（如过期、撤销）。\n\n- **设备事件上报**  \n  设备驱动可利用监视队列异步上报硬件状态变化或错误事件。\n\n- **通用内核事件分发**  \n  任何需要向特权用户空间守护进程（如 `systemd`）发送结构化事件的内核子系统均可集成此机制。\n\n- **用户空间消费**  \n  应用程序通过 `open(\"/dev/watch_queue\")` 获取监视队列文件描述符，调用 `ioctl()` 设置缓冲区大小和过滤器，然后像读取普通管道一样接收通知。",
      "similarity": 0.4844186305999756,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/watch_queue.c",
          "start_line": 42,
          "end_line": 154,
          "content": [
            "static inline bool lock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_lock_bh(&wqueue->lock);",
            "\tif (unlikely(!wqueue->pipe)) {",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "\t\treturn false;",
            "\t}",
            "\treturn true;",
            "}",
            "static inline void unlock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_unlock_bh(&wqueue->lock);",
            "}",
            "static void watch_queue_pipe_buf_release(struct pipe_inode_info *pipe,",
            "\t\t\t\t\t struct pipe_buffer *buf)",
            "{",
            "\tstruct watch_queue *wqueue = (struct watch_queue *)buf->private;",
            "\tstruct page *page;",
            "\tunsigned int bit;",
            "",
            "\t/* We need to work out which note within the page this refers to, but",
            "\t * the note might have been maximum size, so merely ANDing the offset",
            "\t * off doesn't work.  OTOH, the note must've been more than zero size.",
            "\t */",
            "\tbit = buf->offset + buf->len;",
            "\tif ((bit & (WATCH_QUEUE_NOTE_SIZE - 1)) == 0)",
            "\t\tbit -= WATCH_QUEUE_NOTE_SIZE;",
            "\tbit /= WATCH_QUEUE_NOTE_SIZE;",
            "",
            "\tpage = buf->page;",
            "\tbit += page->index;",
            "",
            "\tset_bit(bit, wqueue->notes_bitmap);",
            "\tgeneric_pipe_buf_release(pipe, buf);",
            "}",
            "static bool post_one_notification(struct watch_queue *wqueue,",
            "\t\t\t\t  struct watch_notification *n)",
            "{",
            "\tvoid *p;",
            "\tstruct pipe_inode_info *pipe = wqueue->pipe;",
            "\tstruct pipe_buffer *buf;",
            "\tstruct page *page;",
            "\tunsigned int head, tail, note, offset, len;",
            "\tbool done = false;",
            "",
            "\tspin_lock_irq(&pipe->rd_wait.lock);",
            "",
            "\thead = pipe->head;",
            "\ttail = pipe->tail;",
            "\tif (pipe_full(head, tail, pipe->ring_size))",
            "\t\tgoto lost;",
            "",
            "\tnote = find_first_bit(wqueue->notes_bitmap, wqueue->nr_notes);",
            "\tif (note >= wqueue->nr_notes)",
            "\t\tgoto lost;",
            "",
            "\tpage = wqueue->notes[note / WATCH_QUEUE_NOTES_PER_PAGE];",
            "\toffset = note % WATCH_QUEUE_NOTES_PER_PAGE * WATCH_QUEUE_NOTE_SIZE;",
            "\tget_page(page);",
            "\tlen = n->info & WATCH_INFO_LENGTH;",
            "\tp = kmap_atomic(page);",
            "\tmemcpy(p + offset, n, len);",
            "\tkunmap_atomic(p);",
            "",
            "\tbuf = pipe_buf(pipe, head);",
            "\tbuf->page = page;",
            "\tbuf->private = (unsigned long)wqueue;",
            "\tbuf->ops = &watch_queue_pipe_buf_ops;",
            "\tbuf->offset = offset;",
            "\tbuf->len = len;",
            "\tbuf->flags = PIPE_BUF_FLAG_WHOLE;",
            "\tsmp_store_release(&pipe->head, head + 1); /* vs pipe_read() */",
            "",
            "\tif (!test_and_clear_bit(note, wqueue->notes_bitmap)) {",
            "\t\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\t\tBUG();",
            "\t}",
            "\twake_up_interruptible_sync_poll_locked(&pipe->rd_wait, EPOLLIN | EPOLLRDNORM);",
            "\tdone = true;",
            "",
            "out:",
            "\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\tif (done)",
            "\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);",
            "\treturn done;",
            "",
            "lost:",
            "\tbuf = pipe_buf(pipe, head - 1);",
            "\tbuf->flags |= PIPE_BUF_FLAG_LOSS;",
            "\tgoto out;",
            "}",
            "static bool filter_watch_notification(const struct watch_filter *wf,",
            "\t\t\t\t      const struct watch_notification *n)",
            "{",
            "\tconst struct watch_type_filter *wt;",
            "\tunsigned int st_bits = sizeof(wt->subtype_filter[0]) * 8;",
            "\tunsigned int st_index = n->subtype / st_bits;",
            "\tunsigned int st_bit = 1U << (n->subtype % st_bits);",
            "\tint i;",
            "",
            "\tif (!test_bit(n->type, wf->type_filter))",
            "\t\treturn false;",
            "",
            "\tfor (i = 0; i < wf->nr_filters; i++) {",
            "\t\twt = &wf->filters[i];",
            "\t\tif (n->type == wt->type &&",
            "\t\t    (wt->subtype_filter[st_index] & st_bit) &&",
            "\t\t    (n->info & wt->info_mask) == wt->info_filter)",
            "\t\t\treturn true;",
            "\t}",
            "",
            "\treturn false; /* If there is a filter, the default is to reject. */",
            "}"
          ],
          "function_name": "lock_wqueue, unlock_wqueue, watch_queue_pipe_buf_release, post_one_notification, filter_watch_notification",
          "description": "实现了watch_queue的锁操作、缓冲区释放、通知提交及过滤逻辑。lock_wqueue/unlock_wqueue用于保护队列访问，watch_queue_pipe_buf_release处理缓冲区回收并更新位图，post_one_notification将通知数据写入管道，filter_watch_notification进行类型和子类型的匹配判断。",
          "similarity": 0.4863121807575226
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/watch_queue.c",
          "start_line": 602,
          "end_line": 680,
          "content": [
            "void watch_queue_clear(struct watch_queue *wqueue)",
            "{",
            "\tstruct watch_list *wlist;",
            "\tstruct watch *watch;",
            "\tbool release;",
            "",
            "\trcu_read_lock();",
            "\tspin_lock_bh(&wqueue->lock);",
            "",
            "\t/*",
            "\t * This pipe can be freed by callers like free_pipe_info().",
            "\t * Removing this reference also prevents new notifications.",
            "\t */",
            "\twqueue->pipe = NULL;",
            "",
            "\twhile (!hlist_empty(&wqueue->watches)) {",
            "\t\twatch = hlist_entry(wqueue->watches.first, struct watch, queue_node);",
            "\t\thlist_del_init_rcu(&watch->queue_node);",
            "\t\t/* We now own a ref on the watch. */",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "",
            "\t\t/* We can't do the next bit under the queue lock as we need to",
            "\t\t * get the list lock - which would cause a deadlock if someone",
            "\t\t * was removing from the opposite direction at the same time or",
            "\t\t * posting a notification.",
            "\t\t */",
            "\t\twlist = rcu_dereference(watch->watch_list);",
            "\t\tif (wlist) {",
            "\t\t\tvoid (*release_watch)(struct watch *);",
            "",
            "\t\t\tspin_lock(&wlist->lock);",
            "",
            "\t\t\trelease = !hlist_unhashed(&watch->list_node);",
            "\t\t\tif (release) {",
            "\t\t\t\thlist_del_init_rcu(&watch->list_node);",
            "\t\t\t\trcu_assign_pointer(watch->watch_list, NULL);",
            "",
            "\t\t\t\t/* We now own a second ref on the watch. */",
            "\t\t\t}",
            "",
            "\t\t\trelease_watch = wlist->release_watch;",
            "\t\t\tspin_unlock(&wlist->lock);",
            "",
            "\t\t\tif (release) {",
            "\t\t\t\tif (release_watch) {",
            "\t\t\t\t\trcu_read_unlock();",
            "\t\t\t\t\t/* This might need to call dput(), so",
            "\t\t\t\t\t * we have to drop all the locks.",
            "\t\t\t\t\t */",
            "\t\t\t\t\t(*release_watch)(watch);",
            "\t\t\t\t\trcu_read_lock();",
            "\t\t\t\t}",
            "\t\t\t\tput_watch(watch);",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tput_watch(watch);",
            "\t\tspin_lock_bh(&wqueue->lock);",
            "\t}",
            "",
            "\tspin_unlock_bh(&wqueue->lock);",
            "\trcu_read_unlock();",
            "}",
            "int watch_queue_init(struct pipe_inode_info *pipe)",
            "{",
            "\tstruct watch_queue *wqueue;",
            "",
            "\twqueue = kzalloc(sizeof(*wqueue), GFP_KERNEL);",
            "\tif (!wqueue)",
            "\t\treturn -ENOMEM;",
            "",
            "\twqueue->pipe = pipe;",
            "\tkref_init(&wqueue->usage);",
            "\tspin_lock_init(&wqueue->lock);",
            "\tINIT_HLIST_HEAD(&wqueue->watches);",
            "",
            "\tpipe->watch_queue = wqueue;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "watch_queue_clear, watch_queue_init",
          "description": "该代码实现了监视队列的初始化与清理功能。  \n`watch_queue_clear`通过RCU和自旋锁机制安全地移除所有监视项并释放资源，`watch_queue_init`初始化监视队列结构并绑定至管道对象。  \n上下文不完整：`release_watch`等关键函数依赖外部定义，部分RCU回调逻辑未完全展示。",
          "similarity": 0.4706331491470337
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/watch_queue.c",
          "start_line": 1,
          "end_line": 41,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/* Watch queue and general notification mechanism, built on pipes",
            " *",
            " * Copyright (C) 2020 Red Hat, Inc. All Rights Reserved.",
            " * Written by David Howells (dhowells@redhat.com)",
            " *",
            " * See Documentation/core-api/watch_queue.rst",
            " */",
            "",
            "#define pr_fmt(fmt) \"watchq: \" fmt",
            "#include <linux/module.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/printk.h>",
            "#include <linux/miscdevice.h>",
            "#include <linux/fs.h>",
            "#include <linux/mm.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/poll.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <linux/security.h>",
            "#include <linux/cred.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/watch_queue.h>",
            "#include <linux/pipe_fs_i.h>",
            "",
            "MODULE_DESCRIPTION(\"Watch queue\");",
            "MODULE_AUTHOR(\"Red Hat, Inc.\");",
            "",
            "#define WATCH_QUEUE_NOTE_SIZE 128",
            "#define WATCH_QUEUE_NOTES_PER_PAGE (PAGE_SIZE / WATCH_QUEUE_NOTE_SIZE)",
            "",
            "/*",
            " * This must be called under the RCU read-lock, which makes",
            " * sure that the wqueue still exists. It can then take the lock,",
            " * and check that the wqueue hasn't been destroyed, which in",
            " * turn makes sure that the notification pipe still exists.",
            " */"
          ],
          "function_name": null,
          "description": "定义了watch_queue模块的头部信息，包含常量WATCH_QUEUE_NOTE_SIZE和NOTES_PER_PAGE，声明模块许可证及作者信息，并引入相关内核头文件，为后续实现提供基础框架。",
          "similarity": 0.40634119510650635
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/watch_queue.c",
          "start_line": 315,
          "end_line": 422,
          "content": [
            "long watch_queue_set_filter(struct pipe_inode_info *pipe,",
            "\t\t\t    struct watch_notification_filter __user *_filter)",
            "{",
            "\tstruct watch_notification_type_filter *tf;",
            "\tstruct watch_notification_filter filter;",
            "\tstruct watch_type_filter *q;",
            "\tstruct watch_filter *wfilter;",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tint ret, nr_filter = 0, i;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "",
            "\tif (!_filter) {",
            "\t\t/* Remove the old filter */",
            "\t\twfilter = NULL;",
            "\t\tgoto set;",
            "\t}",
            "",
            "\t/* Grab the user's filter specification */",
            "\tif (copy_from_user(&filter, _filter, sizeof(filter)) != 0)",
            "\t\treturn -EFAULT;",
            "\tif (filter.nr_filters == 0 ||",
            "\t    filter.nr_filters > 16 ||",
            "\t    filter.__reserved != 0)",
            "\t\treturn -EINVAL;",
            "",
            "\ttf = memdup_array_user(_filter->filters, filter.nr_filters, sizeof(*tf));",
            "\tif (IS_ERR(tf))",
            "\t\treturn PTR_ERR(tf);",
            "",
            "\tret = -EINVAL;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif ((tf[i].info_filter & ~tf[i].info_mask) ||",
            "\t\t    tf[i].info_mask & WATCH_INFO_LENGTH)",
            "\t\t\tgoto err_filter;",
            "\t\t/* Ignore any unknown types */",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "\t\tnr_filter++;",
            "\t}",
            "",
            "\t/* Now we need to build the internal filter from only the relevant",
            "\t * user-specified filters.",
            "\t */",
            "\tret = -ENOMEM;",
            "\twfilter = kzalloc(struct_size(wfilter, filters, nr_filter), GFP_KERNEL);",
            "\tif (!wfilter)",
            "\t\tgoto err_filter;",
            "\twfilter->nr_filters = nr_filter;",
            "",
            "\tq = wfilter->filters;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "",
            "\t\tq->type\t\t\t= tf[i].type;",
            "\t\tq->info_filter\t\t= tf[i].info_filter;",
            "\t\tq->info_mask\t\t= tf[i].info_mask;",
            "\t\tq->subtype_filter[0]\t= tf[i].subtype_filter[0];",
            "\t\t__set_bit(q->type, wfilter->type_filter);",
            "\t\tq++;",
            "\t}",
            "",
            "\tkfree(tf);",
            "set:",
            "\tpipe_lock(pipe);",
            "\twfilter = rcu_replace_pointer(wqueue->filter, wfilter,",
            "\t\t\t\t      lockdep_is_held(&pipe->mutex));",
            "\tpipe_unlock(pipe);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\treturn 0;",
            "",
            "err_filter:",
            "\tkfree(tf);",
            "\treturn ret;",
            "}",
            "static void __put_watch_queue(struct kref *kref)",
            "{",
            "\tstruct watch_queue *wqueue =",
            "\t\tcontainer_of(kref, struct watch_queue, usage);",
            "\tstruct watch_filter *wfilter;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < wqueue->nr_pages; i++)",
            "\t\t__free_page(wqueue->notes[i]);",
            "\tkfree(wqueue->notes);",
            "\tbitmap_free(wqueue->notes_bitmap);",
            "",
            "\twfilter = rcu_access_pointer(wqueue->filter);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\tkfree_rcu(wqueue, rcu);",
            "}",
            "void put_watch_queue(struct watch_queue *wqueue)",
            "{",
            "\tkref_put(&wqueue->usage, __put_watch_queue);",
            "}",
            "static void free_watch(struct rcu_head *rcu)",
            "{",
            "\tstruct watch *watch = container_of(rcu, struct watch, rcu);",
            "",
            "\tput_watch_queue(rcu_access_pointer(watch->queue));",
            "\tatomic_dec(&watch->cred->user->nr_watches);",
            "\tput_cred(watch->cred);",
            "\tkfree(watch);",
            "}"
          ],
          "function_name": "watch_queue_set_filter, __put_watch_queue, put_watch_queue, free_watch",
          "description": "watch_queue_set_filter设置过滤规则并转换为内核内部结构，__put_watch_queue释放watch_queue相关资源包括页面、位图和过滤器，put_watch_queue通过引用计数管理watch_queue生命周期，free_watch执行RCU回调完成最终释放。",
          "similarity": 0.39998164772987366
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/watch_queue.c",
          "start_line": 432,
          "end_line": 556,
          "content": [
            "static void __put_watch(struct kref *kref)",
            "{",
            "\tstruct watch *watch = container_of(kref, struct watch, usage);",
            "",
            "\tcall_rcu(&watch->rcu, free_watch);",
            "}",
            "static void put_watch(struct watch *watch)",
            "{",
            "\tkref_put(&watch->usage, __put_watch);",
            "}",
            "void init_watch(struct watch *watch, struct watch_queue *wqueue)",
            "{",
            "\tkref_init(&watch->usage);",
            "\tINIT_HLIST_NODE(&watch->list_node);",
            "\tINIT_HLIST_NODE(&watch->queue_node);",
            "\trcu_assign_pointer(watch->queue, wqueue);",
            "}",
            "static int add_one_watch(struct watch *watch, struct watch_list *wlist, struct watch_queue *wqueue)",
            "{",
            "\tconst struct cred *cred;",
            "\tstruct watch *w;",
            "",
            "\thlist_for_each_entry(w, &wlist->watchers, list_node) {",
            "\t\tstruct watch_queue *wq = rcu_access_pointer(w->queue);",
            "\t\tif (wqueue == wq && watch->id == w->id)",
            "\t\t\treturn -EBUSY;",
            "\t}",
            "",
            "\tcred = current_cred();",
            "\tif (atomic_inc_return(&cred->user->nr_watches) > task_rlimit(current, RLIMIT_NOFILE)) {",
            "\t\tatomic_dec(&cred->user->nr_watches);",
            "\t\treturn -EAGAIN;",
            "\t}",
            "",
            "\twatch->cred = get_cred(cred);",
            "\trcu_assign_pointer(watch->watch_list, wlist);",
            "",
            "\tkref_get(&wqueue->usage);",
            "\tkref_get(&watch->usage);",
            "\thlist_add_head(&watch->queue_node, &wqueue->watches);",
            "\thlist_add_head_rcu(&watch->list_node, &wlist->watchers);",
            "\treturn 0;",
            "}",
            "int add_watch_to_object(struct watch *watch, struct watch_list *wlist)",
            "{",
            "\tstruct watch_queue *wqueue;",
            "\tint ret = -ENOENT;",
            "",
            "\trcu_read_lock();",
            "",
            "\twqueue = rcu_access_pointer(watch->queue);",
            "\tif (lock_wqueue(wqueue)) {",
            "\t\tspin_lock(&wlist->lock);",
            "\t\tret = add_one_watch(watch, wlist, wqueue);",
            "\t\tspin_unlock(&wlist->lock);",
            "\t\tunlock_wqueue(wqueue);",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "\treturn ret;",
            "}",
            "int remove_watch_from_object(struct watch_list *wlist, struct watch_queue *wq,",
            "\t\t\t     u64 id, bool all)",
            "{",
            "\tstruct watch_notification_removal n;",
            "\tstruct watch_queue *wqueue;",
            "\tstruct watch *watch;",
            "\tint ret = -EBADSLT;",
            "",
            "\trcu_read_lock();",
            "",
            "again:",
            "\tspin_lock(&wlist->lock);",
            "\thlist_for_each_entry(watch, &wlist->watchers, list_node) {",
            "\t\tif (all ||",
            "\t\t    (watch->id == id && rcu_access_pointer(watch->queue) == wq))",
            "\t\t\tgoto found;",
            "\t}",
            "\tspin_unlock(&wlist->lock);",
            "\tgoto out;",
            "",
            "found:",
            "\tret = 0;",
            "\thlist_del_init_rcu(&watch->list_node);",
            "\trcu_assign_pointer(watch->watch_list, NULL);",
            "\tspin_unlock(&wlist->lock);",
            "",
            "\t/* We now own the reference on watch that used to belong to wlist. */",
            "",
            "\tn.watch.type = WATCH_TYPE_META;",
            "\tn.watch.subtype = WATCH_META_REMOVAL_NOTIFICATION;",
            "\tn.watch.info = watch->info_id | watch_sizeof(n.watch);",
            "\tn.id = id;",
            "\tif (id != 0)",
            "\t\tn.watch.info = watch->info_id | watch_sizeof(n);",
            "",
            "\twqueue = rcu_dereference(watch->queue);",
            "",
            "\tif (lock_wqueue(wqueue)) {",
            "\t\tpost_one_notification(wqueue, &n.watch);",
            "",
            "\t\tif (!hlist_unhashed(&watch->queue_node)) {",
            "\t\t\thlist_del_init_rcu(&watch->queue_node);",
            "\t\t\tput_watch(watch);",
            "\t\t}",
            "",
            "\t\tunlock_wqueue(wqueue);",
            "\t}",
            "",
            "\tif (wlist->release_watch) {",
            "\t\tvoid (*release_watch)(struct watch *);",
            "",
            "\t\trelease_watch = wlist->release_watch;",
            "\t\trcu_read_unlock();",
            "\t\t(*release_watch)(watch);",
            "\t\trcu_read_lock();",
            "\t}",
            "\tput_watch(watch);",
            "",
            "\tif (all && !hlist_empty(&wlist->watchers))",
            "\t\tgoto again;",
            "out:",
            "\trcu_read_unlock();",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__put_watch, put_watch, init_watch, add_one_watch, add_watch_to_object, remove_watch_from_object",
          "description": "__put_watch通过RCU回调释放watch对象，init_watch初始化watch结构并绑定至watch_queue，add_one_watch将watch加入列表并增加引用计数，remove_watch_from_object安全移除watch并触发移除通知，维护watch列表的并发一致性。",
          "similarity": 0.3955520689487457
        }
      ]
    },
    {
      "source_file": "kernel/locking/locktorture.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:40:37\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\locktorture.c`\n\n---\n\n# `locking/locktorture.c` 技术文档\n\n## 1. 文件概述\n\n`locking/locktorture.c` 是 Linux 内核中的一个模块化压力测试（torture test）设施，用于对各种内核锁机制（如 spinlock、mutex、rwsem、rtmutex 等）进行高强度并发压力测试，以验证其正确性、健壮性和性能。该模块通过创建多个读/写线程，在高竞争、长持有、CPU 热插拔、优先级提升等极端场景下持续操作锁，检测潜在的死锁、竞态条件、内存泄漏或锁实现缺陷。\n\n该文件基于 RCU torture 测试框架（`kernel/rcu/torture.c`）构建，支持多种锁类型，并可通过内核模块参数灵活配置测试行为。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct lock_torture_ops`**  \n  锁操作抽象接口，定义了针对特定锁类型的初始化、加锁、解锁、延迟、RT 优先级提升等回调函数，支持不同锁机制的统一测试框架。\n  \n- **`struct lock_torture_cxt`**  \n  全局测试上下文，包含当前使用的锁操作集（`cur_ops`）、读者/写者线程数量、错误计数器、统计信息等。\n\n- **`struct lock_stress_stats`**  \n  用于记录每个线程的锁获取成功/失败次数，用于性能和正确性分析。\n\n- **`torture_param` 宏定义的模块参数**  \n  提供丰富的运行时配置选项，如线程数量、长持有时间、CPU 热插拔间隔、RT 优先级提升策略等。\n\n### 主要函数\n\n- **锁操作实现函数**（按锁类型分类）：\n  - `torture_spin_lock_write_lock()` / `torture_spin_lock_write_unlock()`：普通 spinlock 加/解锁。\n  - `torture_spin_lock_write_lock_irq()` / `torture_lock_spin_write_unlock_irq()`：带中断保存/恢复的 spinlock。\n  - `torture_lock_busted_*`：故意错误的“损坏”锁实现，用于验证测试框架能否检测异常行为。\n  - （代码片段未完整展示 mutex、rwsem、rtmutex 等实现，但框架支持）\n\n- **辅助函数**：\n  - `torture_lock_busted_write_delay()` / `torture_spin_lock_write_delay()`：模拟真实场景中的锁持有延迟，包括短延迟（微秒级）和偶尔的长延迟（毫秒级），以制造高竞争。\n  - `__torture_rt_boost()` / `torture_rt_boost()`：周期性将写线程提升为实时 FIFO 优先级，测试优先级继承（PI）和 RT 锁行为。\n  - `lock_torture_cleanup()`：测试结束时的资源清理（前向声明）。\n\n- **全局变量**：\n  - `writer_tasks` / `reader_tasks`：指向写/读测试线程的 `task_struct` 指针数组。\n  - `lock_is_write_held` / `lock_is_read_held`：用于检测锁状态一致性（如是否允许多个写者同时持有）。\n  - `last_lock_release`：记录上次释放锁的时间戳。\n\n## 3. 关键实现\n\n### 锁类型抽象与扩展\n通过 `lock_torture_ops` 结构体实现策略模式，不同锁类型只需实现对应的回调函数即可接入测试框架。当前支持：\n- `spin_lock`\n- `spin_lock_irq`\n- （完整代码中还包括 `mutex_lock`, `rwsem`, `rtmutex`, `raw_spin_lock` 等）\n\n默认锁类型根据 `CONFIG_PREEMPT_RT` 配置自动选择：RT 内核使用 `raw_spin_lock`，否则使用 `spin_lock`。\n\n### 高强度压力生成\n- **长持有延迟**：通过 `long_hold` 参数控制，偶尔让线程持有锁达数十至数百毫秒，极大增加竞争概率。\n- **随机延迟与抢占**：在锁持有期间插入随机微秒级延迟，并调用 `torture_preempt_schedule()` 主动触发抢占，测试锁在抢占式内核下的行为。\n- **嵌套锁支持**：通过 `nested_locks` 参数（最大 8 层）测试锁的嵌套使用，避免触发 lockdep 的 `MAX_LOCKDEP_CHAIN_HLOCKS` 限制。\n\n### 实时（RT）行为测试\n- **RT 优先级提升**：`rt_boost` 参数控制是否周期性将写线程设为 `SCHED_FIFO` 实时优先级。\n  - 模式 1：仅对 `rtmutex` 生效\n  - 模式 2：对所有锁类型生效\n- **PI（优先级继承）压力**：通过频繁提升/恢复优先级，触发 RT 锁的 PI 机制，验证其正确性。\n\n### 动态环境模拟\n- **CPU 热插拔**：通过 `onoff_holdoff` 和 `onoff_interval` 参数，在测试过程中动态上线/下线 CPU，检验锁在 CPU 拓扑变化时的稳定性。\n- **测试启停控制**：`stutter` 参数控制测试周期性暂停/恢复，模拟负载波动。\n\n### 错误检测机制\n- 使用 `atomic_t n_lock_torture_errors` 全局计数器记录检测到的错误（如违反锁互斥性）。\n- 通过 `lock_is_write_held` 和 `atomic_t lock_is_read_held` 检测写锁是否被多个线程同时持有，或读写锁状态不一致。\n\n## 4. 依赖关系\n\n- **内核核心组件**：\n  - `<linux/spinlock.h>`、`<linux/mutex.h>`、`<linux/rwsem.h>`、`<linux/rtmutex.h>`：提供被测试的锁原语。\n  - `<linux/kthread.h>`、`<linux/sched.h>`：用于创建和管理测试线程。\n  - `<linux/torture.h>`：提供通用 torture 测试框架（如随机数生成、线程控制、参数解析等）。\n  - `<linux/atomic.h>`、`<linux/delay.h>`：用于同步和延迟操作。\n- **配置依赖**：\n  - `CONFIG_PREEMPT_RT`：影响默认锁类型选择。\n  - `CONFIG_LOCKDEP`：嵌套锁深度受其 `MAX_LOCKDEP_CHAIN_HLOCKS` 限制。\n- **模块参数系统**：通过 `module_param` 和 `torture_param` 宏集成内核模块参数机制。\n\n## 5. 使用场景\n\n- **内核开发与测试**：\n  - 在开发新的锁实现或修改现有锁机制时，运行此模块进行回归测试。\n  - 在合并关键锁相关补丁前，通过长时间 torture 测试验证稳定性。\n- **实时系统验证**：\n  - 在 PREEMPT_RT 补丁集开发中，重点测试 `rtmutex` 和优先级继承行为。\n  - 验证系统在高优先级线程竞争锁时的响应性和正确性。\n- **硬件/平台压力测试**：\n  - 在新硬件平台或 NUMA 系统上运行，检测锁在复杂拓扑下的可扩展性和正确性。\n  - 结合 CPU 热插拔测试，验证锁在动态 CPU 环境下的鲁棒性。\n- **故障复现与调试**：\n  - 当怀疑存在锁相关的死锁或竞态条件时，通过配置特定参数（如高 `long_hold`、高线程数）复现问题。\n  - 利用 `verbose` 参数输出详细日志辅助调试。",
      "similarity": 0.47995054721832275,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "kernel/locking/locktorture.c",
          "start_line": 867,
          "end_line": 977,
          "content": [
            "static int lock_torture_reader(void *arg)",
            "{",
            "\tstruct lock_stress_stats *lrsp = arg;",
            "\tint tid = lrsp - cxt.lrsa;",
            "\tDEFINE_TORTURE_RANDOM(rand);",
            "",
            "\tVERBOSE_TOROUT_STRING(\"lock_torture_reader task started\");",
            "\tset_user_nice(current, MAX_NICE);",
            "",
            "\tdo {",
            "\t\tif ((torture_random(&rand) & 0xfffff) == 0)",
            "\t\t\tschedule_timeout_uninterruptible(1);",
            "",
            "\t\tcxt.cur_ops->readlock(tid);",
            "\t\tatomic_inc(&lock_is_read_held);",
            "\t\tif (WARN_ON_ONCE(lock_is_write_held))",
            "\t\t\tlrsp->n_lock_fail++; /* rare, but... */",
            "",
            "\t\tlrsp->n_lock_acquired++;",
            "\t\tcxt.cur_ops->read_delay(&rand);",
            "\t\tatomic_dec(&lock_is_read_held);",
            "\t\tcxt.cur_ops->readunlock(tid);",
            "",
            "\t\tstutter_wait(\"lock_torture_reader\");",
            "\t} while (!torture_must_stop());",
            "\ttorture_kthread_stopping(\"lock_torture_reader\");",
            "\treturn 0;",
            "}",
            "static void __torture_print_stats(char *page,",
            "\t\t\t\t  struct lock_stress_stats *statp, bool write)",
            "{",
            "\tlong cur;",
            "\tbool fail = false;",
            "\tint i, n_stress;",
            "\tlong max = 0, min = statp ? data_race(statp[0].n_lock_acquired) : 0;",
            "\tlong long sum = 0;",
            "",
            "\tn_stress = write ? cxt.nrealwriters_stress : cxt.nrealreaders_stress;",
            "\tfor (i = 0; i < n_stress; i++) {",
            "\t\tif (data_race(statp[i].n_lock_fail))",
            "\t\t\tfail = true;",
            "\t\tcur = data_race(statp[i].n_lock_acquired);",
            "\t\tsum += cur;",
            "\t\tif (max < cur)",
            "\t\t\tmax = cur;",
            "\t\tif (min > cur)",
            "\t\t\tmin = cur;",
            "\t}",
            "\tpage += sprintf(page,",
            "\t\t\t\"%s:  Total: %lld  Max/Min: %ld/%ld %s  Fail: %d %s\\n\",",
            "\t\t\twrite ? \"Writes\" : \"Reads \",",
            "\t\t\tsum, max, min,",
            "\t\t\t!onoff_interval && max / 2 > min ? \"???\" : \"\",",
            "\t\t\tfail, fail ? \"!!!\" : \"\");",
            "\tif (fail)",
            "\t\tatomic_inc(&cxt.n_lock_torture_errors);",
            "}",
            "static void lock_torture_stats_print(void)",
            "{",
            "\tint size = cxt.nrealwriters_stress * 200 + 8192;",
            "\tchar *buf;",
            "",
            "\tif (cxt.cur_ops->readlock)",
            "\t\tsize += cxt.nrealreaders_stress * 200 + 8192;",
            "",
            "\tbuf = kmalloc(size, GFP_KERNEL);",
            "\tif (!buf) {",
            "\t\tpr_err(\"lock_torture_stats_print: Out of memory, need: %d\",",
            "\t\t       size);",
            "\t\treturn;",
            "\t}",
            "",
            "\t__torture_print_stats(buf, cxt.lwsa, true);",
            "\tpr_alert(\"%s\", buf);",
            "\tkfree(buf);",
            "",
            "\tif (cxt.cur_ops->readlock) {",
            "\t\tbuf = kmalloc(size, GFP_KERNEL);",
            "\t\tif (!buf) {",
            "\t\t\tpr_err(\"lock_torture_stats_print: Out of memory, need: %d\",",
            "\t\t\t       size);",
            "\t\t\treturn;",
            "\t\t}",
            "",
            "\t\t__torture_print_stats(buf, cxt.lrsa, false);",
            "\t\tpr_alert(\"%s\", buf);",
            "\t\tkfree(buf);",
            "\t}",
            "}",
            "static int lock_torture_stats(void *arg)",
            "{",
            "\tVERBOSE_TOROUT_STRING(\"lock_torture_stats task started\");",
            "\tdo {",
            "\t\tschedule_timeout_interruptible(stat_interval * HZ);",
            "\t\tlock_torture_stats_print();",
            "\t\ttorture_shutdown_absorb(\"lock_torture_stats\");",
            "\t} while (!torture_must_stop());",
            "\ttorture_kthread_stopping(\"lock_torture_stats\");",
            "\treturn 0;",
            "}",
            "static inline void",
            "lock_torture_print_module_parms(struct lock_torture_ops *cur_ops,",
            "\t\t\t\tconst char *tag)",
            "{",
            "\tpr_alert(\"%s\" TORTURE_FLAG",
            "\t\t \"--- %s%s: nwriters_stress=%d nreaders_stress=%d nested_locks=%d stat_interval=%d verbose=%d shuffle_interval=%d stutter=%d shutdown_secs=%d onoff_interval=%d onoff_holdoff=%d\\n\",",
            "\t\t torture_type, tag, cxt.debug_lock ? \" [debug]\": \"\",",
            "\t\t cxt.nrealwriters_stress, cxt.nrealreaders_stress,",
            "\t\t nested_locks, stat_interval, verbose, shuffle_interval,",
            "\t\t stutter, shutdown_secs, onoff_interval, onoff_holdoff);",
            "}"
          ],
          "function_name": "lock_torture_reader, __torture_print_stats, lock_torture_stats_print, lock_torture_stats, lock_torture_print_module_parms",
          "description": "lock_torture_reader函数实现读者线程逻辑，通过读锁获取、延迟、释放完成数据访问；__torture_print_stats和lock_torture_stats_print用于收集并格式化显示锁竞争统计信息，lock_torture_print_module_parms输出模块运行参数和测试结果标识。",
          "similarity": 0.5181400179862976
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/locking/locktorture.c",
          "start_line": 1001,
          "end_line": 1279,
          "content": [
            "static void lock_torture_cleanup(void)",
            "{",
            "\tint i;",
            "",
            "\tif (torture_cleanup_begin())",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Indicates early cleanup, meaning that the test has not run,",
            "\t * such as when passing bogus args when loading the module.",
            "\t * However cxt->cur_ops.init() may have been invoked, so beside",
            "\t * perform the underlying torture-specific cleanups, cur_ops.exit()",
            "\t * will be invoked if needed.",
            "\t */",
            "\tif (!cxt.lwsa && !cxt.lrsa)",
            "\t\tgoto end;",
            "",
            "\tif (writer_tasks) {",
            "\t\tfor (i = 0; i < cxt.nrealwriters_stress; i++)",
            "\t\t\ttorture_stop_kthread(lock_torture_writer, writer_tasks[i]);",
            "\t\tkfree(writer_tasks);",
            "\t\twriter_tasks = NULL;",
            "\t}",
            "",
            "\tif (reader_tasks) {",
            "\t\tfor (i = 0; i < cxt.nrealreaders_stress; i++)",
            "\t\t\ttorture_stop_kthread(lock_torture_reader,",
            "\t\t\t\t\t     reader_tasks[i]);",
            "\t\tkfree(reader_tasks);",
            "\t\treader_tasks = NULL;",
            "\t}",
            "",
            "\ttorture_stop_kthread(lock_torture_stats, stats_task);",
            "\tlock_torture_stats_print();  /* -After- the stats thread is stopped! */",
            "",
            "\tif (atomic_read(&cxt.n_lock_torture_errors))",
            "\t\tlock_torture_print_module_parms(cxt.cur_ops,",
            "\t\t\t\t\t\t\"End of test: FAILURE\");",
            "\telse if (torture_onoff_failures())",
            "\t\tlock_torture_print_module_parms(cxt.cur_ops,",
            "\t\t\t\t\t\t\"End of test: LOCK_HOTPLUG\");",
            "\telse",
            "\t\tlock_torture_print_module_parms(cxt.cur_ops,",
            "\t\t\t\t\t\t\"End of test: SUCCESS\");",
            "",
            "\tkfree(cxt.lwsa);",
            "\tcxt.lwsa = NULL;",
            "\tkfree(cxt.lrsa);",
            "\tcxt.lrsa = NULL;",
            "",
            "end:",
            "\tif (cxt.init_called) {",
            "\t\tif (cxt.cur_ops->exit)",
            "\t\t\tcxt.cur_ops->exit();",
            "\t\tcxt.init_called = false;",
            "\t}",
            "\ttorture_cleanup_end();",
            "}",
            "static int __init lock_torture_init(void)",
            "{",
            "\tint i, j;",
            "\tint firsterr = 0;",
            "\tstatic struct lock_torture_ops *torture_ops[] = {",
            "\t\t&lock_busted_ops,",
            "\t\t&spin_lock_ops, &spin_lock_irq_ops,",
            "\t\t&raw_spin_lock_ops, &raw_spin_lock_irq_ops,",
            "\t\t&rw_lock_ops, &rw_lock_irq_ops,",
            "\t\t&mutex_lock_ops,",
            "\t\t&ww_mutex_lock_ops,",
            "#ifdef CONFIG_RT_MUTEXES",
            "\t\t&rtmutex_lock_ops,",
            "#endif",
            "\t\t&rwsem_lock_ops,",
            "\t\t&percpu_rwsem_lock_ops,",
            "\t};",
            "",
            "\tif (!torture_init_begin(torture_type, verbose))",
            "\t\treturn -EBUSY;",
            "",
            "\t/* Process args and tell the world that the torturer is on the job. */",
            "\tfor (i = 0; i < ARRAY_SIZE(torture_ops); i++) {",
            "\t\tcxt.cur_ops = torture_ops[i];",
            "\t\tif (strcmp(torture_type, cxt.cur_ops->name) == 0)",
            "\t\t\tbreak;",
            "\t}",
            "\tif (i == ARRAY_SIZE(torture_ops)) {",
            "\t\tpr_alert(\"lock-torture: invalid torture type: \\\"%s\\\"\\n\",",
            "\t\t\t torture_type);",
            "\t\tpr_alert(\"lock-torture types:\");",
            "\t\tfor (i = 0; i < ARRAY_SIZE(torture_ops); i++)",
            "\t\t\tpr_alert(\" %s\", torture_ops[i]->name);",
            "\t\tpr_alert(\"\\n\");",
            "\t\tfirsterr = -EINVAL;",
            "\t\tgoto unwind;",
            "\t}",
            "",
            "\tif (nwriters_stress == 0 &&",
            "\t    (!cxt.cur_ops->readlock || nreaders_stress == 0)) {",
            "\t\tpr_alert(\"lock-torture: must run at least one locking thread\\n\");",
            "\t\tfirsterr = -EINVAL;",
            "\t\tgoto unwind;",
            "\t}",
            "",
            "\tif (nwriters_stress >= 0)",
            "\t\tcxt.nrealwriters_stress = nwriters_stress;",
            "\telse",
            "\t\tcxt.nrealwriters_stress = 2 * num_online_cpus();",
            "",
            "\tif (cxt.cur_ops->init) {",
            "\t\tcxt.cur_ops->init();",
            "\t\tcxt.init_called = true;",
            "\t}",
            "",
            "#ifdef CONFIG_DEBUG_MUTEXES",
            "\tif (str_has_prefix(torture_type, \"mutex\"))",
            "\t\tcxt.debug_lock = true;",
            "#endif",
            "#ifdef CONFIG_DEBUG_RT_MUTEXES",
            "\tif (str_has_prefix(torture_type, \"rtmutex\"))",
            "\t\tcxt.debug_lock = true;",
            "#endif",
            "#ifdef CONFIG_DEBUG_SPINLOCK",
            "\tif ((str_has_prefix(torture_type, \"spin\")) ||",
            "\t    (str_has_prefix(torture_type, \"rw_lock\")))",
            "\t\tcxt.debug_lock = true;",
            "#endif",
            "",
            "\t/* Initialize the statistics so that each run gets its own numbers. */",
            "\tif (nwriters_stress) {",
            "\t\tlock_is_write_held = false;",
            "\t\tcxt.lwsa = kmalloc_array(cxt.nrealwriters_stress,",
            "\t\t\t\t\t sizeof(*cxt.lwsa),",
            "\t\t\t\t\t GFP_KERNEL);",
            "\t\tif (cxt.lwsa == NULL) {",
            "\t\t\tVERBOSE_TOROUT_STRING(\"cxt.lwsa: Out of memory\");",
            "\t\t\tfirsterr = -ENOMEM;",
            "\t\t\tgoto unwind;",
            "\t\t}",
            "",
            "\t\tfor (i = 0; i < cxt.nrealwriters_stress; i++) {",
            "\t\t\tcxt.lwsa[i].n_lock_fail = 0;",
            "\t\t\tcxt.lwsa[i].n_lock_acquired = 0;",
            "\t\t}",
            "\t}",
            "",
            "\tif (cxt.cur_ops->readlock) {",
            "\t\tif (nreaders_stress >= 0)",
            "\t\t\tcxt.nrealreaders_stress = nreaders_stress;",
            "\t\telse {",
            "\t\t\t/*",
            "\t\t\t * By default distribute evenly the number of",
            "\t\t\t * readers and writers. We still run the same number",
            "\t\t\t * of threads as the writer-only locks default.",
            "\t\t\t */",
            "\t\t\tif (nwriters_stress < 0) /* user doesn't care */",
            "\t\t\t\tcxt.nrealwriters_stress = num_online_cpus();",
            "\t\t\tcxt.nrealreaders_stress = cxt.nrealwriters_stress;",
            "\t\t}",
            "",
            "\t\tif (nreaders_stress) {",
            "\t\t\tcxt.lrsa = kmalloc_array(cxt.nrealreaders_stress,",
            "\t\t\t\t\t\t sizeof(*cxt.lrsa),",
            "\t\t\t\t\t\t GFP_KERNEL);",
            "\t\t\tif (cxt.lrsa == NULL) {",
            "\t\t\t\tVERBOSE_TOROUT_STRING(\"cxt.lrsa: Out of memory\");",
            "\t\t\t\tfirsterr = -ENOMEM;",
            "\t\t\t\tkfree(cxt.lwsa);",
            "\t\t\t\tcxt.lwsa = NULL;",
            "\t\t\t\tgoto unwind;",
            "\t\t\t}",
            "",
            "\t\t\tfor (i = 0; i < cxt.nrealreaders_stress; i++) {",
            "\t\t\t\tcxt.lrsa[i].n_lock_fail = 0;",
            "\t\t\t\tcxt.lrsa[i].n_lock_acquired = 0;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "\tlock_torture_print_module_parms(cxt.cur_ops, \"Start of test\");",
            "",
            "\t/* Prepare torture context. */",
            "\tif (onoff_interval > 0) {",
            "\t\tfirsterr = torture_onoff_init(onoff_holdoff * HZ,",
            "\t\t\t\t\t      onoff_interval * HZ, NULL);",
            "\t\tif (torture_init_error(firsterr))",
            "\t\t\tgoto unwind;",
            "\t}",
            "\tif (shuffle_interval > 0) {",
            "\t\tfirsterr = torture_shuffle_init(shuffle_interval);",
            "\t\tif (torture_init_error(firsterr))",
            "\t\t\tgoto unwind;",
            "\t}",
            "\tif (shutdown_secs > 0) {",
            "\t\tfirsterr = torture_shutdown_init(shutdown_secs,",
            "\t\t\t\t\t\t lock_torture_cleanup);",
            "\t\tif (torture_init_error(firsterr))",
            "\t\t\tgoto unwind;",
            "\t}",
            "\tif (stutter > 0) {",
            "\t\tfirsterr = torture_stutter_init(stutter, stutter);",
            "\t\tif (torture_init_error(firsterr))",
            "\t\t\tgoto unwind;",
            "\t}",
            "",
            "\tif (nwriters_stress) {",
            "\t\twriter_tasks = kcalloc(cxt.nrealwriters_stress,",
            "\t\t\t\t       sizeof(writer_tasks[0]),",
            "\t\t\t\t       GFP_KERNEL);",
            "\t\tif (writer_tasks == NULL) {",
            "\t\t\tTOROUT_ERRSTRING(\"writer_tasks: Out of memory\");",
            "\t\t\tfirsterr = -ENOMEM;",
            "\t\t\tgoto unwind;",
            "\t\t}",
            "\t}",
            "",
            "\t/* cap nested_locks to MAX_NESTED_LOCKS */",
            "\tif (nested_locks > MAX_NESTED_LOCKS)",
            "\t\tnested_locks = MAX_NESTED_LOCKS;",
            "",
            "\tif (cxt.cur_ops->readlock) {",
            "\t\treader_tasks = kcalloc(cxt.nrealreaders_stress,",
            "\t\t\t\t       sizeof(reader_tasks[0]),",
            "\t\t\t\t       GFP_KERNEL);",
            "\t\tif (reader_tasks == NULL) {",
            "\t\t\tTOROUT_ERRSTRING(\"reader_tasks: Out of memory\");",
            "\t\t\tkfree(writer_tasks);",
            "\t\t\twriter_tasks = NULL;",
            "\t\t\tfirsterr = -ENOMEM;",
            "\t\t\tgoto unwind;",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * Create the kthreads and start torturing (oh, those poor little locks).",
            "\t *",
            "\t * TODO: Note that we interleave writers with readers, giving writers a",
            "\t * slight advantage, by creating its kthread first. This can be modified",
            "\t * for very specific needs, or even let the user choose the policy, if",
            "\t * ever wanted.",
            "\t */",
            "\tfor (i = 0, j = 0; i < cxt.nrealwriters_stress ||",
            "\t\t    j < cxt.nrealreaders_stress; i++, j++) {",
            "\t\tif (i >= cxt.nrealwriters_stress)",
            "\t\t\tgoto create_reader;",
            "",
            "\t\t/* Create writer. */",
            "\t\tfirsterr = torture_create_kthread_cb(lock_torture_writer, &cxt.lwsa[i],",
            "\t\t\t\t\t\t     writer_tasks[i],",
            "\t\t\t\t\t\t     writer_fifo ? sched_set_fifo : NULL);",
            "\t\tif (torture_init_error(firsterr))",
            "\t\t\tgoto unwind;",
            "",
            "\tcreate_reader:",
            "\t\tif (cxt.cur_ops->readlock == NULL || (j >= cxt.nrealreaders_stress))",
            "\t\t\tcontinue;",
            "\t\t/* Create reader. */",
            "\t\tfirsterr = torture_create_kthread(lock_torture_reader, &cxt.lrsa[j],",
            "\t\t\t\t\t\t  reader_tasks[j]);",
            "\t\tif (torture_init_error(firsterr))",
            "\t\t\tgoto unwind;",
            "\t}",
            "\tif (stat_interval > 0) {",
            "\t\tfirsterr = torture_create_kthread(lock_torture_stats, NULL,",
            "\t\t\t\t\t\t  stats_task);",
            "\t\tif (torture_init_error(firsterr))",
            "\t\t\tgoto unwind;",
            "\t}",
            "\ttorture_init_end();",
            "\treturn 0;",
            "",
            "unwind:",
            "\ttorture_init_end();",
            "\tlock_torture_cleanup();",
            "\tif (shutdown_secs) {",
            "\t\tWARN_ON(!IS_MODULE(CONFIG_LOCK_TORTURE_TEST));",
            "\t\tkernel_power_off();",
            "\t}",
            "\treturn firsterr;",
            "}"
          ],
          "function_name": "lock_torture_cleanup, lock_torture_init",
          "description": "lock_torture_cleanup负责安全终止所有测试线程、释放内存资源并输出最终测试状态；lock_torture_init实现模块加载时的初始化流程，包括参数解析、线程创建、内存分配、锁类型适配器初始化，以及与系统其他组件（如电源管理、任务调度）的交互设置。",
          "similarity": 0.47815513610839844
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/locktorture.c",
          "start_line": 260,
          "end_line": 362,
          "content": [
            "static int torture_raw_spin_lock_write_lock(int tid __maybe_unused)",
            "__acquires(torture_raw_spinlock)",
            "{",
            "\traw_spin_lock(&torture_raw_spinlock);",
            "\treturn 0;",
            "}",
            "static void torture_raw_spin_lock_write_unlock(int tid __maybe_unused)",
            "__releases(torture_raw_spinlock)",
            "{",
            "\traw_spin_unlock(&torture_raw_spinlock);",
            "}",
            "static int torture_raw_spin_lock_write_lock_irq(int tid __maybe_unused)",
            "__acquires(torture_raw_spinlock)",
            "{",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&torture_raw_spinlock, flags);",
            "\tcxt.cur_ops->flags = flags;",
            "\treturn 0;",
            "}",
            "static void torture_raw_spin_lock_write_unlock_irq(int tid __maybe_unused)",
            "__releases(torture_raw_spinlock)",
            "{",
            "\traw_spin_unlock_irqrestore(&torture_raw_spinlock, cxt.cur_ops->flags);",
            "}",
            "static int torture_rwlock_write_lock(int tid __maybe_unused)",
            "__acquires(torture_rwlock)",
            "{",
            "\twrite_lock(&torture_rwlock);",
            "\treturn 0;",
            "}",
            "static void torture_rwlock_write_delay(struct torture_random_state *trsp)",
            "{",
            "\tconst unsigned long shortdelay_us = 2;",
            "\tconst unsigned long longdelay_ms = long_hold ? long_hold : ULONG_MAX;",
            "",
            "\t/* We want a short delay mostly to emulate likely code, and",
            "\t * we want a long delay occasionally to force massive contention.",
            "\t */",
            "\tif (!(torture_random(trsp) %",
            "\t      (cxt.nrealwriters_stress * 2000 * longdelay_ms)))",
            "\t\tmdelay(longdelay_ms);",
            "\telse",
            "\t\tudelay(shortdelay_us);",
            "}",
            "static void torture_rwlock_write_unlock(int tid __maybe_unused)",
            "__releases(torture_rwlock)",
            "{",
            "\twrite_unlock(&torture_rwlock);",
            "}",
            "static int torture_rwlock_read_lock(int tid __maybe_unused)",
            "__acquires(torture_rwlock)",
            "{",
            "\tread_lock(&torture_rwlock);",
            "\treturn 0;",
            "}",
            "static void torture_rwlock_read_delay(struct torture_random_state *trsp)",
            "{",
            "\tconst unsigned long shortdelay_us = 10;",
            "\tconst unsigned long longdelay_ms = 100;",
            "",
            "\t/* We want a short delay mostly to emulate likely code, and",
            "\t * we want a long delay occasionally to force massive contention.",
            "\t */",
            "\tif (!(torture_random(trsp) %",
            "\t      (cxt.nrealreaders_stress * 2000 * longdelay_ms)))",
            "\t\tmdelay(longdelay_ms);",
            "\telse",
            "\t\tudelay(shortdelay_us);",
            "}",
            "static void torture_rwlock_read_unlock(int tid __maybe_unused)",
            "__releases(torture_rwlock)",
            "{",
            "\tread_unlock(&torture_rwlock);",
            "}",
            "static int torture_rwlock_write_lock_irq(int tid __maybe_unused)",
            "__acquires(torture_rwlock)",
            "{",
            "\tunsigned long flags;",
            "",
            "\twrite_lock_irqsave(&torture_rwlock, flags);",
            "\tcxt.cur_ops->flags = flags;",
            "\treturn 0;",
            "}",
            "static void torture_rwlock_write_unlock_irq(int tid __maybe_unused)",
            "__releases(torture_rwlock)",
            "{",
            "\twrite_unlock_irqrestore(&torture_rwlock, cxt.cur_ops->flags);",
            "}",
            "static int torture_rwlock_read_lock_irq(int tid __maybe_unused)",
            "__acquires(torture_rwlock)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tread_lock_irqsave(&torture_rwlock, flags);",
            "\tcxt.cur_ops->flags = flags;",
            "\treturn 0;",
            "}",
            "static void torture_rwlock_read_unlock_irq(int tid __maybe_unused)",
            "__releases(torture_rwlock)",
            "{",
            "\tread_unlock_irqrestore(&torture_rwlock, cxt.cur_ops->flags);",
            "}"
          ],
          "function_name": "torture_raw_spin_lock_write_lock, torture_raw_spin_lock_write_unlock, torture_raw_spin_lock_write_lock_irq, torture_raw_spin_lock_write_unlock_irq, torture_rwlock_write_lock, torture_rwlock_write_delay, torture_rwlock_write_unlock, torture_rwlock_read_lock, torture_rwlock_read_delay, torture_rwlock_read_unlock, torture_rwlock_write_lock_irq, torture_rwlock_write_unlock_irq, torture_rwlock_read_lock_irq, torture_rwlock_read_unlock_irq",
          "description": "提供读写锁（rwlock）的测试函数，涵盖写锁获取、读锁获取、延迟操作及中断保护版本，支持对读写锁的并发访问压力测试。",
          "similarity": 0.465318500995636
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/locktorture.c",
          "start_line": 568,
          "end_line": 670,
          "content": [
            "static void torture_ww_mutex_unlock(int tid)",
            "__releases(torture_ww_mutex_0)",
            "__releases(torture_ww_mutex_1)",
            "__releases(torture_ww_mutex_2)",
            "{",
            "\tstruct ww_acquire_ctx *ctx = &ww_acquire_ctxs[tid];",
            "",
            "\tww_mutex_unlock(&torture_ww_mutex_0);",
            "\tww_mutex_unlock(&torture_ww_mutex_1);",
            "\tww_mutex_unlock(&torture_ww_mutex_2);",
            "\tww_acquire_fini(ctx);",
            "}",
            "static void torture_rtmutex_init(void)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < MAX_NESTED_LOCKS; i++)",
            "\t\t__rt_mutex_init(&torture_nested_rtmutexes[i], __func__,",
            "\t\t\t\t&nested_rtmutex_keys[i]);",
            "}",
            "static int torture_rtmutex_nested_lock(int tid __maybe_unused,",
            "\t\t\t\t       u32 lockset)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < nested_locks; i++)",
            "\t\tif (lockset & (1 << i))",
            "\t\t\trt_mutex_lock(&torture_nested_rtmutexes[i]);",
            "\treturn 0;",
            "}",
            "static int torture_rtmutex_lock(int tid __maybe_unused)",
            "__acquires(torture_rtmutex)",
            "{",
            "\trt_mutex_lock(&torture_rtmutex);",
            "\treturn 0;",
            "}",
            "static void torture_rtmutex_delay(struct torture_random_state *trsp)",
            "{",
            "\tconst unsigned long shortdelay_us = 2;",
            "\tconst unsigned long longdelay_ms = long_hold ? long_hold : ULONG_MAX;",
            "",
            "\t/*",
            "\t * We want a short delay mostly to emulate likely code, and",
            "\t * we want a long delay occasionally to force massive contention.",
            "\t */",
            "\tif (!(torture_random(trsp) %",
            "\t      (cxt.nrealwriters_stress * 2000 * longdelay_ms)))",
            "\t\tmdelay(longdelay_ms);",
            "\tif (!(torture_random(trsp) %",
            "\t      (cxt.nrealwriters_stress * 200 * shortdelay_us)))",
            "\t\tudelay(shortdelay_us);",
            "\tif (!(torture_random(trsp) % (cxt.nrealwriters_stress * 20000)))",
            "\t\ttorture_preempt_schedule();  /* Allow test to be preempted. */",
            "}",
            "static void torture_rtmutex_unlock(int tid __maybe_unused)",
            "__releases(torture_rtmutex)",
            "{",
            "\trt_mutex_unlock(&torture_rtmutex);",
            "}",
            "static void torture_rt_boost_rtmutex(struct torture_random_state *trsp)",
            "{",
            "\tif (!rt_boost)",
            "\t\treturn;",
            "",
            "\t__torture_rt_boost(trsp);",
            "}",
            "static void torture_rtmutex_nested_unlock(int tid __maybe_unused,",
            "\t\t\t\t\t  u32 lockset)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = nested_locks - 1; i >= 0; i--)",
            "\t\tif (lockset & (1 << i))",
            "\t\t\trt_mutex_unlock(&torture_nested_rtmutexes[i]);",
            "}",
            "static int torture_rwsem_down_write(int tid __maybe_unused)",
            "__acquires(torture_rwsem)",
            "{",
            "\tdown_write(&torture_rwsem);",
            "\treturn 0;",
            "}",
            "static void torture_rwsem_write_delay(struct torture_random_state *trsp)",
            "{",
            "\tconst unsigned long longdelay_ms = long_hold ? long_hold : ULONG_MAX;",
            "",
            "\t/* We want a long delay occasionally to force massive contention.  */",
            "\tif (!(torture_random(trsp) %",
            "\t      (cxt.nrealwriters_stress * 2000 * longdelay_ms)))",
            "\t\tmdelay(longdelay_ms * 10);",
            "\tif (!(torture_random(trsp) % (cxt.nrealwriters_stress * 20000)))",
            "\t\ttorture_preempt_schedule();  /* Allow test to be preempted. */",
            "}",
            "static void torture_rwsem_up_write(int tid __maybe_unused)",
            "__releases(torture_rwsem)",
            "{",
            "\tup_write(&torture_rwsem);",
            "}",
            "static int torture_rwsem_down_read(int tid __maybe_unused)",
            "__acquires(torture_rwsem)",
            "{",
            "\tdown_read(&torture_rwsem);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "torture_ww_mutex_unlock, torture_rtmutex_init, torture_rtmutex_nested_lock, torture_rtmutex_lock, torture_rtmutex_delay, torture_rtmutex_unlock, torture_rt_boost_rtmutex, torture_rtmutex_nested_unlock, torture_rwsem_down_write, torture_rwsem_write_delay, torture_rwsem_up_write, torture_rwsem_down_read",
          "description": "涵盖实时互斥锁（rtmutex）和读写信号量（rwsem）的测试函数，包含锁操作、延迟注入、优先级调整及资源竞争模拟，用于评估锁机制在实时系统中的表现。",
          "similarity": 0.4589230418205261
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/locktorture.c",
          "start_line": 1,
          "end_line": 111,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0+",
            "/*",
            " * Module-based torture test facility for locking",
            " *",
            " * Copyright (C) IBM Corporation, 2014",
            " *",
            " * Authors: Paul E. McKenney <paulmck@linux.ibm.com>",
            " *          Davidlohr Bueso <dave@stgolabs.net>",
            " *\tBased on kernel/rcu/torture.c.",
            " */",
            "",
            "#define pr_fmt(fmt) fmt",
            "",
            "#include <linux/kernel.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/mutex.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/smp.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/atomic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/slab.h>",
            "#include <linux/torture.h>",
            "#include <linux/reboot.h>",
            "",
            "MODULE_LICENSE(\"GPL\");",
            "MODULE_AUTHOR(\"Paul E. McKenney <paulmck@linux.ibm.com>\");",
            "",
            "torture_param(int, nwriters_stress, -1, \"Number of write-locking stress-test threads\");",
            "torture_param(int, nreaders_stress, -1, \"Number of read-locking stress-test threads\");",
            "torture_param(int, long_hold, 100, \"Do occasional long hold of lock (ms), 0=disable\");",
            "torture_param(int, onoff_holdoff, 0, \"Time after boot before CPU hotplugs (s)\");",
            "torture_param(int, onoff_interval, 0, \"Time between CPU hotplugs (s), 0=disable\");",
            "torture_param(int, shuffle_interval, 3, \"Number of jiffies between shuffles, 0=disable\");",
            "torture_param(int, shutdown_secs, 0, \"Shutdown time (j), <= zero to disable.\");",
            "torture_param(int, stat_interval, 60, \"Number of seconds between stats printk()s\");",
            "torture_param(int, stutter, 5, \"Number of jiffies to run/halt test, 0=disable\");",
            "torture_param(int, rt_boost, 2,",
            "\t\t   \"Do periodic rt-boost. 0=Disable, 1=Only for rt_mutex, 2=For all lock types.\");",
            "torture_param(int, rt_boost_factor, 50, \"A factor determining how often rt-boost happens.\");",
            "torture_param(int, writer_fifo, 0, \"Run writers at sched_set_fifo() priority\");",
            "torture_param(int, verbose, 1, \"Enable verbose debugging printk()s\");",
            "torture_param(int, nested_locks, 0, \"Number of nested locks (max = 8)\");",
            "/* Going much higher trips \"BUG: MAX_LOCKDEP_CHAIN_HLOCKS too low!\" errors */",
            "#define MAX_NESTED_LOCKS 8",
            "",
            "static char *torture_type = IS_ENABLED(CONFIG_PREEMPT_RT) ? \"raw_spin_lock\" : \"spin_lock\";",
            "module_param(torture_type, charp, 0444);",
            "MODULE_PARM_DESC(torture_type,",
            "\t\t \"Type of lock to torture (spin_lock, spin_lock_irq, mutex_lock, ...)\");",
            "",
            "static struct task_struct *stats_task;",
            "static struct task_struct **writer_tasks;",
            "static struct task_struct **reader_tasks;",
            "",
            "static bool lock_is_write_held;",
            "static atomic_t lock_is_read_held;",
            "static unsigned long last_lock_release;",
            "",
            "struct lock_stress_stats {",
            "\tlong n_lock_fail;",
            "\tlong n_lock_acquired;",
            "};",
            "",
            "/* Forward reference. */",
            "static void lock_torture_cleanup(void);",
            "",
            "/*",
            " * Operations vector for selecting different types of tests.",
            " */",
            "struct lock_torture_ops {",
            "\tvoid (*init)(void);",
            "\tvoid (*exit)(void);",
            "\tint (*nested_lock)(int tid, u32 lockset);",
            "\tint (*writelock)(int tid);",
            "\tvoid (*write_delay)(struct torture_random_state *trsp);",
            "\tvoid (*task_boost)(struct torture_random_state *trsp);",
            "\tvoid (*writeunlock)(int tid);",
            "\tvoid (*nested_unlock)(int tid, u32 lockset);",
            "\tint (*readlock)(int tid);",
            "\tvoid (*read_delay)(struct torture_random_state *trsp);",
            "\tvoid (*readunlock)(int tid);",
            "",
            "\tunsigned long flags; /* for irq spinlocks */",
            "\tconst char *name;",
            "};",
            "",
            "struct lock_torture_cxt {",
            "\tint nrealwriters_stress;",
            "\tint nrealreaders_stress;",
            "\tbool debug_lock;",
            "\tbool init_called;",
            "\tatomic_t n_lock_torture_errors;",
            "\tstruct lock_torture_ops *cur_ops;",
            "\tstruct lock_stress_stats *lwsa; /* writer statistics */",
            "\tstruct lock_stress_stats *lrsa; /* reader statistics */",
            "};",
            "static struct lock_torture_cxt cxt = { 0, 0, false, false,",
            "\t\t\t\t       ATOMIC_INIT(0),",
            "\t\t\t\t       NULL, NULL};",
            "/*",
            " * Definitions for lock torture testing.",
            " */",
            ""
          ],
          "function_name": null,
          "description": "定义锁压力测试模块的全局变量、参数及操作接口，用于配置不同锁类型的测试策略，包含锁类型选择、线程数控制、统计间隔等参数，以及用于记录测试状态的上下文结构。",
          "similarity": 0.456835001707077
        }
      ]
    }
  ]
}