{
  "query": "device driver framework",
  "timestamp": "2025-12-25 23:51:02",
  "retrieved_files": [
    {
      "source_file": "kernel/bpf/devmap.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:08:49\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\devmap.c`\n\n---\n\n# `bpf/devmap.c` 技术文档\n\n## 1. 文件概述\n\n`bpf/devmap.c` 实现了 BPF **设备映射（devmap）** 功能，主要用于支持 XDP（eXpress Data Path）程序中的 `bpf_redirect_map()` 辅助函数，实现高性能的网络数据包重定向到指定网络设备。该文件提供了两种类型的 BPF 映射：\n\n- `BPF_MAP_TYPE_DEVMAP`：基于数组索引的设备映射\n- `BPF_MAP_TYPE_DEVMAP_HASH`：基于哈希表的设备映射（以 ifindex 为键）\n\n核心设计目标是在数据路径（datapath）中**避免使用锁**，通过 RCU（Read-Copy-Update）机制和原子操作保证并发安全，同时支持设备注销时的安全清理。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct xdp_dev_bulk_queue`**  \n  每 CPU 的批量发送队列，用于暂存待重定向的数据包，包含：\n  - 最多 `DEV_MAP_BULK_SIZE` 个 `xdp_frame`\n  - 关联的目标设备 `dev` 和接收设备 `dev_rx`\n  - 可选的 XDP 程序 `xdp_prog`\n  - 队列计数器 `count`\n\n- **`struct bpf_dtab_netdev`**  \n  表示映射中一个设备条目，包含：\n  - 指向 `net_device` 的指针（必须为第一个成员，供 tracepoint 使用）\n  - 哈希链表节点 `index_hlist`（仅用于 `DEVMAP_HASH`）\n  - 关联的 XDP 程序 `xdp_prog`\n  - RCU 回调头 `rcu`\n  - 在数组中的索引 `idx`\n  - 设备值结构 `bpf_devmap_val`\n\n- **`struct bpf_dtab`**  \n  devmap 的主控制结构，继承自 `bpf_map`，包含：\n  - `netdev_map`：指向 `bpf_dtab_netdev*` 数组（仅用于 `DEVMAP`）\n  - `dev_index_head`：哈希桶数组（仅用于 `DEVMAP_HASH`）\n  - `index_lock`：保护哈希表的自旋锁\n  - `items` 和 `n_buckets`：哈希表项数和桶数\n  - 全局链表节点 `list`\n\n### 主要函数\n\n- **`dev_map_alloc()`**  \n  分配并初始化 devmap 实例，根据 `attr->map_type` 选择数组或哈希实现。\n\n- **`dev_map_free()`**  \n  安全释放 devmap，确保所有 RCU 读取和 flush 操作完成后再释放资源。\n\n- **`dev_map_init_map()`**  \n  验证 BPF 属性并初始化映射结构，强制设置 `BPF_F_RDONLY_PROG` 保证只读。\n\n- **`dev_map_create_hash()`**  \n  为 `DEVMAP_HASH` 类型分配并初始化哈希桶数组。\n\n- **`dev_map_index_hash()`**  \n  计算 ifindex 在哈希表中的桶位置（使用位掩码取模）。\n\n- **`dev_map_get_next_key()`**（未完整展示）  \n  支持 BPF 迭代器遍历映射键。\n\n## 3. 关键实现\n\n### 无锁数据路径设计\n- **读操作（lookup）**：在 RCU 临界区内直接读取 `netdev_map[idx]`，无锁。\n- **写操作（update/delete）**：使用 `xchg()` 原子替换指针，确保读侧看到一致状态。\n- **内存回收**：通过 `call_rcu()` 延迟释放旧条目，等待 RCU 宽限期结束。\n\n### Flush 机制\n- 每 CPU 维护 `dev_flush_list`，暂存待发送的数据包。\n- `bpf_dtab_netdev` 对象在 flush 列表清空前不会被销毁，确保 NAPI 上下文安全。\n\n### 设备注销处理\n- 通过 `netdev_unregister` 通知链扫描所有 devmap。\n- 使用 `cmpxchg()` 安全移除匹配的设备条目，防止并发更新导致误删。\n- 内核保证注销期间 `dev_get_by_index()` 失败，阻止新条目添加。\n\n### 两种映射类型\n- **`DEVMAP`**：简单数组，索引即键，适合密集 ifindex。\n- **`DEVMAP_HASH`**：哈希表实现，键为 ifindex，适合稀疏场景，避免内存浪费。\n- 两者共享数据包入队和发送逻辑，仅 lookup/insert 实现不同。\n\n### 安全与验证\n- 强制设置 `BPF_F_RDONLY_PROG`，防止 BPF 程序修改映射值。\n- 严格校验 `value_size`（仅允许 4 字节 ifindex 或 8 字节 ifindex+prog_fd）。\n\n## 4. 依赖关系\n\n- **BPF 子系统**：`<linux/bpf.h>`，提供基础映射框架和程序管理。\n- **XDP 框架**：`<net/xdp.h>`，定义 `xdp_frame` 和重定向接口。\n- **网络设备层**：依赖 `net_device` 结构和 `dev_put()`/`dev_hold()` 引用管理。\n- **RCU 机制**：用于无锁并发控制和安全内存回收。\n- **Tracepoint**：`<trace/events/xdp.h>`，支持 XDP 事件跟踪。\n- **BTF**：`<linux/btf_ids.h>`，用于类型信息导出。\n\n## 5. 使用场景\n\n- **XDP 重定向**：在 XDP 程序中调用 `bpf_redirect_map(map, key, flags)` 将数据包重定向到指定网络设备。\n- **高性能负载均衡**：结合 `DEVMAP_HASH` 实现基于 ifindex 的动态后端选择。\n- **服务网格/防火墙**：在数据路径中动态更新出口设备，无需内核协议栈介入。\n- **设备热插拔**：安全处理网络设备注销，自动清理映射中的无效条目。\n- **批量发送优化**：通过 per-CPU flush 队列聚合数据包，减少驱动调用次数。",
      "similarity": 0.5513573288917542,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/bpf/devmap.c",
          "start_line": 523,
          "end_line": 657,
          "content": [
            "int dev_xdp_enqueue(struct net_device *dev, struct xdp_frame *xdpf,",
            "\t\t    struct net_device *dev_rx)",
            "{",
            "\treturn __xdp_enqueue(dev, xdpf, dev_rx, NULL);",
            "}",
            "int dev_map_enqueue(struct bpf_dtab_netdev *dst, struct xdp_frame *xdpf,",
            "\t\t    struct net_device *dev_rx)",
            "{",
            "\tstruct net_device *dev = dst->dev;",
            "",
            "\treturn __xdp_enqueue(dev, xdpf, dev_rx, dst->xdp_prog);",
            "}",
            "static bool is_valid_dst(struct bpf_dtab_netdev *obj, struct xdp_frame *xdpf)",
            "{",
            "\tif (!obj)",
            "\t\treturn false;",
            "",
            "\tif (!(obj->dev->xdp_features & NETDEV_XDP_ACT_NDO_XMIT))",
            "\t\treturn false;",
            "",
            "\tif (unlikely(!(obj->dev->xdp_features & NETDEV_XDP_ACT_NDO_XMIT_SG) &&",
            "\t\t     xdp_frame_has_frags(xdpf)))",
            "\t\treturn false;",
            "",
            "\tif (xdp_ok_fwd_dev(obj->dev, xdp_get_frame_len(xdpf)))",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}",
            "static int dev_map_enqueue_clone(struct bpf_dtab_netdev *obj,",
            "\t\t\t\t struct net_device *dev_rx,",
            "\t\t\t\t struct xdp_frame *xdpf)",
            "{",
            "\tstruct xdp_frame *nxdpf;",
            "",
            "\tnxdpf = xdpf_clone(xdpf);",
            "\tif (!nxdpf)",
            "\t\treturn -ENOMEM;",
            "",
            "\tbq_enqueue(obj->dev, nxdpf, dev_rx, obj->xdp_prog);",
            "",
            "\treturn 0;",
            "}",
            "static inline bool is_ifindex_excluded(int *excluded, int num_excluded, int ifindex)",
            "{",
            "\twhile (num_excluded--) {",
            "\t\tif (ifindex == excluded[num_excluded])",
            "\t\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "static int get_upper_ifindexes(struct net_device *dev, int *indexes)",
            "{",
            "\tstruct net_device *upper;",
            "\tstruct list_head *iter;",
            "\tint n = 0;",
            "",
            "\tnetdev_for_each_upper_dev_rcu(dev, upper, iter) {",
            "\t\tindexes[n++] = upper->ifindex;",
            "\t}",
            "\treturn n;",
            "}",
            "int dev_map_enqueue_multi(struct xdp_frame *xdpf, struct net_device *dev_rx,",
            "\t\t\t  struct bpf_map *map, bool exclude_ingress)",
            "{",
            "\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);",
            "\tstruct bpf_dtab_netdev *dst, *last_dst = NULL;",
            "\tint excluded_devices[1+MAX_NEST_DEV];",
            "\tstruct hlist_head *head;",
            "\tint num_excluded = 0;",
            "\tunsigned int i;",
            "\tint err;",
            "",
            "\tif (exclude_ingress) {",
            "\t\tnum_excluded = get_upper_ifindexes(dev_rx, excluded_devices);",
            "\t\texcluded_devices[num_excluded++] = dev_rx->ifindex;",
            "\t}",
            "",
            "\tif (map->map_type == BPF_MAP_TYPE_DEVMAP) {",
            "\t\tfor (i = 0; i < map->max_entries; i++) {",
            "\t\t\tdst = rcu_dereference_check(dtab->netdev_map[i],",
            "\t\t\t\t\t\t    rcu_read_lock_bh_held());",
            "\t\t\tif (!is_valid_dst(dst, xdpf))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tif (is_ifindex_excluded(excluded_devices, num_excluded, dst->dev->ifindex))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\t/* we only need n-1 clones; last_dst enqueued below */",
            "\t\t\tif (!last_dst) {",
            "\t\t\t\tlast_dst = dst;",
            "\t\t\t\tcontinue;",
            "\t\t\t}",
            "",
            "\t\t\terr = dev_map_enqueue_clone(last_dst, dev_rx, xdpf);",
            "\t\t\tif (err)",
            "\t\t\t\treturn err;",
            "",
            "\t\t\tlast_dst = dst;",
            "\t\t}",
            "\t} else { /* BPF_MAP_TYPE_DEVMAP_HASH */",
            "\t\tfor (i = 0; i < dtab->n_buckets; i++) {",
            "\t\t\thead = dev_map_index_hash(dtab, i);",
            "\t\t\thlist_for_each_entry_rcu(dst, head, index_hlist,",
            "\t\t\t\t\t\t lockdep_is_held(&dtab->index_lock)) {",
            "\t\t\t\tif (!is_valid_dst(dst, xdpf))",
            "\t\t\t\t\tcontinue;",
            "",
            "\t\t\t\tif (is_ifindex_excluded(excluded_devices, num_excluded,",
            "\t\t\t\t\t\t\tdst->dev->ifindex))",
            "\t\t\t\t\tcontinue;",
            "",
            "\t\t\t\t/* we only need n-1 clones; last_dst enqueued below */",
            "\t\t\t\tif (!last_dst) {",
            "\t\t\t\t\tlast_dst = dst;",
            "\t\t\t\t\tcontinue;",
            "\t\t\t\t}",
            "",
            "\t\t\t\terr = dev_map_enqueue_clone(last_dst, dev_rx, xdpf);",
            "\t\t\t\tif (err)",
            "\t\t\t\t\treturn err;",
            "",
            "\t\t\t\tlast_dst = dst;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "\t/* consume the last copy of the frame */",
            "\tif (last_dst)",
            "\t\tbq_enqueue(last_dst->dev, xdpf, dev_rx, last_dst->xdp_prog);",
            "\telse",
            "\t\txdp_return_frame_rx_napi(xdpf); /* dtab is empty */",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "dev_xdp_enqueue, dev_map_enqueue, is_valid_dst, dev_map_enqueue_clone, is_ifindex_excluded, get_upper_ifindexes, dev_map_enqueue_multi",
          "description": "实现多目标数据包注入逻辑。dev_xdp_enqueue和dev_map_enqueue将帧注入指定设备，is_valid_dst校验目标设备有效性，dev_map_enqueue_clone克隆帧以避免竞争，dev_map_enqueue_multi处理多目标场景并排除入口设备，确保数据包正确路由。",
          "similarity": 0.5103193521499634
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/devmap.c",
          "start_line": 1,
          "end_line": 109,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/* Copyright (c) 2017 Covalent IO, Inc. http://covalent.io",
            " */",
            "",
            "/* Devmaps primary use is as a backend map for XDP BPF helper call",
            " * bpf_redirect_map(). Because XDP is mostly concerned with performance we",
            " * spent some effort to ensure the datapath with redirect maps does not use",
            " * any locking. This is a quick note on the details.",
            " *",
            " * We have three possible paths to get into the devmap control plane bpf",
            " * syscalls, bpf programs, and driver side xmit/flush operations. A bpf syscall",
            " * will invoke an update, delete, or lookup operation. To ensure updates and",
            " * deletes appear atomic from the datapath side xchg() is used to modify the",
            " * netdev_map array. Then because the datapath does a lookup into the netdev_map",
            " * array (read-only) from an RCU critical section we use call_rcu() to wait for",
            " * an rcu grace period before free'ing the old data structures. This ensures the",
            " * datapath always has a valid copy. However, the datapath does a \"flush\"",
            " * operation that pushes any pending packets in the driver outside the RCU",
            " * critical section. Each bpf_dtab_netdev tracks these pending operations using",
            " * a per-cpu flush list. The bpf_dtab_netdev object will not be destroyed  until",
            " * this list is empty, indicating outstanding flush operations have completed.",
            " *",
            " * BPF syscalls may race with BPF program calls on any of the update, delete",
            " * or lookup operations. As noted above the xchg() operation also keep the",
            " * netdev_map consistent in this case. From the devmap side BPF programs",
            " * calling into these operations are the same as multiple user space threads",
            " * making system calls.",
            " *",
            " * Finally, any of the above may race with a netdev_unregister notifier. The",
            " * unregister notifier must search for net devices in the map structure that",
            " * contain a reference to the net device and remove them. This is a two step",
            " * process (a) dereference the bpf_dtab_netdev object in netdev_map and (b)",
            " * check to see if the ifindex is the same as the net_device being removed.",
            " * When removing the dev a cmpxchg() is used to ensure the correct dev is",
            " * removed, in the case of a concurrent update or delete operation it is",
            " * possible that the initially referenced dev is no longer in the map. As the",
            " * notifier hook walks the map we know that new dev references can not be",
            " * added by the user because core infrastructure ensures dev_get_by_index()",
            " * calls will fail at this point.",
            " *",
            " * The devmap_hash type is a map type which interprets keys as ifindexes and",
            " * indexes these using a hashmap. This allows maps that use ifindex as key to be",
            " * densely packed instead of having holes in the lookup array for unused",
            " * ifindexes. The setup and packet enqueue/send code is shared between the two",
            " * types of devmap; only the lookup and insertion is different.",
            " */",
            "#include <linux/bpf.h>",
            "#include <net/xdp.h>",
            "#include <linux/filter.h>",
            "#include <trace/events/xdp.h>",
            "#include <linux/btf_ids.h>",
            "",
            "#define DEV_CREATE_FLAG_MASK \\",
            "\t(BPF_F_NUMA_NODE | BPF_F_RDONLY | BPF_F_WRONLY)",
            "",
            "struct xdp_dev_bulk_queue {",
            "\tstruct xdp_frame *q[DEV_MAP_BULK_SIZE];",
            "\tstruct list_head flush_node;",
            "\tstruct net_device *dev;",
            "\tstruct net_device *dev_rx;",
            "\tstruct bpf_prog *xdp_prog;",
            "\tunsigned int count;",
            "};",
            "",
            "struct bpf_dtab_netdev {",
            "\tstruct net_device *dev; /* must be first member, due to tracepoint */",
            "\tstruct hlist_node index_hlist;",
            "\tstruct bpf_prog *xdp_prog;",
            "\tstruct rcu_head rcu;",
            "\tunsigned int idx;",
            "\tstruct bpf_devmap_val val;",
            "};",
            "",
            "struct bpf_dtab {",
            "\tstruct bpf_map map;",
            "\tstruct bpf_dtab_netdev __rcu **netdev_map; /* DEVMAP type only */",
            "\tstruct list_head list;",
            "",
            "\t/* these are only used for DEVMAP_HASH type maps */",
            "\tstruct hlist_head *dev_index_head;",
            "\tspinlock_t index_lock;",
            "\tunsigned int items;",
            "\tu32 n_buckets;",
            "};",
            "",
            "static DEFINE_PER_CPU(struct list_head, dev_flush_list);",
            "static DEFINE_SPINLOCK(dev_map_lock);",
            "static LIST_HEAD(dev_map_list);",
            "",
            "static struct hlist_head *dev_map_create_hash(unsigned int entries,",
            "\t\t\t\t\t      int numa_node)",
            "{",
            "\tint i;",
            "\tstruct hlist_head *hash;",
            "",
            "\thash = bpf_map_area_alloc((u64) entries * sizeof(*hash), numa_node);",
            "\tif (hash != NULL)",
            "\t\tfor (i = 0; i < entries; i++)",
            "\t\t\tINIT_HLIST_HEAD(&hash[i]);",
            "",
            "\treturn hash;",
            "}",
            "",
            "static inline struct hlist_head *dev_map_index_hash(struct bpf_dtab *dtab,",
            "\t\t\t\t\t\t    int idx)",
            "{",
            "\treturn &dtab->dev_index_head[idx & (dtab->n_buckets - 1)];",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义了DEVMAP相关的结构体和辅助函数，用于支持基于ifindex的网络设备映射。包含两种类型（DEVMAP和DEVMAP_HASH）的实现差异，通过哈希表或数组组织网络设备条目，支持并发安全操作和RCU机制保证数据一致性。",
          "similarity": 0.49882152676582336
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/bpf/devmap.c",
          "start_line": 243,
          "end_line": 343,
          "content": [
            "static int dev_map_get_next_key(struct bpf_map *map, void *key, void *next_key)",
            "{",
            "\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);",
            "\tu32 index = key ? *(u32 *)key : U32_MAX;",
            "\tu32 *next = next_key;",
            "",
            "\tif (index >= dtab->map.max_entries) {",
            "\t\t*next = 0;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tif (index == dtab->map.max_entries - 1)",
            "\t\treturn -ENOENT;",
            "\t*next = index + 1;",
            "\treturn 0;",
            "}",
            "static int dev_map_hash_get_next_key(struct bpf_map *map, void *key,",
            "\t\t\t\t    void *next_key)",
            "{",
            "\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);",
            "\tu32 idx, *next = next_key;",
            "\tstruct bpf_dtab_netdev *dev, *next_dev;",
            "\tstruct hlist_head *head;",
            "\tint i = 0;",
            "",
            "\tif (!key)",
            "\t\tgoto find_first;",
            "",
            "\tidx = *(u32 *)key;",
            "",
            "\tdev = __dev_map_hash_lookup_elem(map, idx);",
            "\tif (!dev)",
            "\t\tgoto find_first;",
            "",
            "\tnext_dev = hlist_entry_safe(rcu_dereference_raw(hlist_next_rcu(&dev->index_hlist)),",
            "\t\t\t\t    struct bpf_dtab_netdev, index_hlist);",
            "",
            "\tif (next_dev) {",
            "\t\t*next = next_dev->idx;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\ti = idx & (dtab->n_buckets - 1);",
            "\ti++;",
            "",
            " find_first:",
            "\tfor (; i < dtab->n_buckets; i++) {",
            "\t\thead = dev_map_index_hash(dtab, i);",
            "",
            "\t\tnext_dev = hlist_entry_safe(rcu_dereference_raw(hlist_first_rcu(head)),",
            "\t\t\t\t\t    struct bpf_dtab_netdev,",
            "\t\t\t\t\t    index_hlist);",
            "\t\tif (next_dev) {",
            "\t\t\t*next = next_dev->idx;",
            "\t\t\treturn 0;",
            "\t\t}",
            "\t}",
            "",
            "\treturn -ENOENT;",
            "}",
            "static int dev_map_bpf_prog_run(struct bpf_prog *xdp_prog,",
            "\t\t\t\tstruct xdp_frame **frames, int n,",
            "\t\t\t\tstruct net_device *tx_dev,",
            "\t\t\t\tstruct net_device *rx_dev)",
            "{",
            "\tstruct xdp_txq_info txq = { .dev = tx_dev };",
            "\tstruct xdp_rxq_info rxq = { .dev = rx_dev };",
            "\tstruct xdp_buff xdp;",
            "\tint i, nframes = 0;",
            "",
            "\tfor (i = 0; i < n; i++) {",
            "\t\tstruct xdp_frame *xdpf = frames[i];",
            "\t\tu32 act;",
            "\t\tint err;",
            "",
            "\t\txdp_convert_frame_to_buff(xdpf, &xdp);",
            "\t\txdp.txq = &txq;",
            "\t\txdp.rxq = &rxq;",
            "",
            "\t\tact = bpf_prog_run_xdp(xdp_prog, &xdp);",
            "\t\tswitch (act) {",
            "\t\tcase XDP_PASS:",
            "\t\t\terr = xdp_update_frame_from_buff(&xdp, xdpf);",
            "\t\t\tif (unlikely(err < 0))",
            "\t\t\t\txdp_return_frame_rx_napi(xdpf);",
            "\t\t\telse",
            "\t\t\t\tframes[nframes++] = xdpf;",
            "\t\t\tbreak;",
            "\t\tdefault:",
            "\t\t\tbpf_warn_invalid_xdp_action(NULL, xdp_prog, act);",
            "\t\t\tfallthrough;",
            "\t\tcase XDP_ABORTED:",
            "\t\t\ttrace_xdp_exception(tx_dev, xdp_prog, act);",
            "\t\t\tfallthrough;",
            "\t\tcase XDP_DROP:",
            "\t\t\txdp_return_frame_rx_napi(xdpf);",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "\treturn nframes; /* sent frames count */",
            "}"
          ],
          "function_name": "dev_map_get_next_key, dev_map_hash_get_next_key, dev_map_bpf_prog_run",
          "description": "提供映射遍历和BPF程序执行接口。dev_map_get_next_key实现线性遍历，dev_map_hash_get_next_key处理哈希表遍历逻辑，dev_map_bpf_prog_run执行XDP程序对帧进行处理并根据动作决定转发或丢弃。",
          "similarity": 0.49054232239723206
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/bpf/devmap.c",
          "start_line": 801,
          "end_line": 946,
          "content": [
            "static void __dev_map_entry_free(struct rcu_head *rcu)",
            "{",
            "\tstruct bpf_dtab_netdev *dev;",
            "",
            "\tdev = container_of(rcu, struct bpf_dtab_netdev, rcu);",
            "\tif (dev->xdp_prog)",
            "\t\tbpf_prog_put(dev->xdp_prog);",
            "\tdev_put(dev->dev);",
            "\tkfree(dev);",
            "}",
            "static long dev_map_delete_elem(struct bpf_map *map, void *key)",
            "{",
            "\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);",
            "\tstruct bpf_dtab_netdev *old_dev;",
            "\tu32 k = *(u32 *)key;",
            "",
            "\tif (k >= map->max_entries)",
            "\t\treturn -EINVAL;",
            "",
            "\told_dev = unrcu_pointer(xchg(&dtab->netdev_map[k], NULL));",
            "\tif (old_dev) {",
            "\t\tcall_rcu(&old_dev->rcu, __dev_map_entry_free);",
            "\t\tatomic_dec((atomic_t *)&dtab->items);",
            "\t}",
            "\treturn 0;",
            "}",
            "static long dev_map_hash_delete_elem(struct bpf_map *map, void *key)",
            "{",
            "\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);",
            "\tstruct bpf_dtab_netdev *old_dev;",
            "\tu32 k = *(u32 *)key;",
            "\tunsigned long flags;",
            "\tint ret = -ENOENT;",
            "",
            "\tspin_lock_irqsave(&dtab->index_lock, flags);",
            "",
            "\told_dev = __dev_map_hash_lookup_elem(map, k);",
            "\tif (old_dev) {",
            "\t\tdtab->items--;",
            "\t\thlist_del_init_rcu(&old_dev->index_hlist);",
            "\t\tcall_rcu(&old_dev->rcu, __dev_map_entry_free);",
            "\t\tret = 0;",
            "\t}",
            "\tspin_unlock_irqrestore(&dtab->index_lock, flags);",
            "",
            "\treturn ret;",
            "}",
            "static long __dev_map_update_elem(struct net *net, struct bpf_map *map,",
            "\t\t\t\t  void *key, void *value, u64 map_flags)",
            "{",
            "\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);",
            "\tstruct bpf_dtab_netdev *dev, *old_dev;",
            "\tstruct bpf_devmap_val val = {};",
            "\tu32 i = *(u32 *)key;",
            "",
            "\tif (unlikely(map_flags > BPF_EXIST))",
            "\t\treturn -EINVAL;",
            "\tif (unlikely(i >= dtab->map.max_entries))",
            "\t\treturn -E2BIG;",
            "\tif (unlikely(map_flags == BPF_NOEXIST))",
            "\t\treturn -EEXIST;",
            "",
            "\t/* already verified value_size <= sizeof val */",
            "\tmemcpy(&val, value, map->value_size);",
            "",
            "\tif (!val.ifindex) {",
            "\t\tdev = NULL;",
            "\t\t/* can not specify fd if ifindex is 0 */",
            "\t\tif (val.bpf_prog.fd > 0)",
            "\t\t\treturn -EINVAL;",
            "\t} else {",
            "\t\tdev = __dev_map_alloc_node(net, dtab, &val, i);",
            "\t\tif (IS_ERR(dev))",
            "\t\t\treturn PTR_ERR(dev);",
            "\t}",
            "",
            "\t/* Use call_rcu() here to ensure rcu critical sections have completed",
            "\t * Remembering the driver side flush operation will happen before the",
            "\t * net device is removed.",
            "\t */",
            "\told_dev = unrcu_pointer(xchg(&dtab->netdev_map[i], RCU_INITIALIZER(dev)));",
            "\tif (old_dev)",
            "\t\tcall_rcu(&old_dev->rcu, __dev_map_entry_free);",
            "\telse",
            "\t\tatomic_inc((atomic_t *)&dtab->items);",
            "",
            "\treturn 0;",
            "}",
            "static long dev_map_update_elem(struct bpf_map *map, void *key, void *value,",
            "\t\t\t\tu64 map_flags)",
            "{",
            "\treturn __dev_map_update_elem(current->nsproxy->net_ns,",
            "\t\t\t\t     map, key, value, map_flags);",
            "}",
            "static long __dev_map_hash_update_elem(struct net *net, struct bpf_map *map,",
            "\t\t\t\t       void *key, void *value, u64 map_flags)",
            "{",
            "\tstruct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);",
            "\tstruct bpf_dtab_netdev *dev, *old_dev;",
            "\tstruct bpf_devmap_val val = {};",
            "\tu32 idx = *(u32 *)key;",
            "\tunsigned long flags;",
            "\tint err = -EEXIST;",
            "",
            "\t/* already verified value_size <= sizeof val */",
            "\tmemcpy(&val, value, map->value_size);",
            "",
            "\tif (unlikely(map_flags > BPF_EXIST || !val.ifindex))",
            "\t\treturn -EINVAL;",
            "",
            "\tspin_lock_irqsave(&dtab->index_lock, flags);",
            "",
            "\told_dev = __dev_map_hash_lookup_elem(map, idx);",
            "\tif (old_dev && (map_flags & BPF_NOEXIST))",
            "\t\tgoto out_err;",
            "",
            "\tdev = __dev_map_alloc_node(net, dtab, &val, idx);",
            "\tif (IS_ERR(dev)) {",
            "\t\terr = PTR_ERR(dev);",
            "\t\tgoto out_err;",
            "\t}",
            "",
            "\tif (old_dev) {",
            "\t\thlist_del_rcu(&old_dev->index_hlist);",
            "\t} else {",
            "\t\tif (dtab->items >= dtab->map.max_entries) {",
            "\t\t\tspin_unlock_irqrestore(&dtab->index_lock, flags);",
            "\t\t\tcall_rcu(&dev->rcu, __dev_map_entry_free);",
            "\t\t\treturn -E2BIG;",
            "\t\t}",
            "\t\tdtab->items++;",
            "\t}",
            "",
            "\thlist_add_head_rcu(&dev->index_hlist,",
            "\t\t\t   dev_map_index_hash(dtab, idx));",
            "\tspin_unlock_irqrestore(&dtab->index_lock, flags);",
            "",
            "\tif (old_dev)",
            "\t\tcall_rcu(&old_dev->rcu, __dev_map_entry_free);",
            "",
            "\treturn 0;",
            "",
            "out_err:",
            "\tspin_unlock_irqrestore(&dtab->index_lock, flags);",
            "\treturn err;",
            "}"
          ],
          "function_name": "__dev_map_entry_free, dev_map_delete_elem, dev_map_hash_delete_elem, __dev_map_update_elem, dev_map_update_elem, __dev_map_hash_update_elem",
          "description": "提供设备映射表的元素增删改操作，采用RCU机制安全释放旧条目，支持数组型和哈希型两种存储结构。包含删除指定索引项、更新元素值及处理并发访问的锁保护逻辑。",
          "similarity": 0.4728119671344757
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/bpf/devmap.c",
          "start_line": 365,
          "end_line": 492,
          "content": [
            "static void bq_xmit_all(struct xdp_dev_bulk_queue *bq, u32 flags)",
            "{",
            "\tstruct net_device *dev = bq->dev;",
            "\tunsigned int cnt = bq->count;",
            "\tint sent = 0, err = 0;",
            "\tint to_send = cnt;",
            "\tint i;",
            "",
            "\tif (unlikely(!cnt))",
            "\t\treturn;",
            "",
            "\tfor (i = 0; i < cnt; i++) {",
            "\t\tstruct xdp_frame *xdpf = bq->q[i];",
            "",
            "\t\tprefetch(xdpf);",
            "\t}",
            "",
            "\tif (bq->xdp_prog) {",
            "\t\tto_send = dev_map_bpf_prog_run(bq->xdp_prog, bq->q, cnt, dev, bq->dev_rx);",
            "\t\tif (!to_send)",
            "\t\t\tgoto out;",
            "\t}",
            "",
            "\tsent = dev->netdev_ops->ndo_xdp_xmit(dev, to_send, bq->q, flags);",
            "\tif (sent < 0) {",
            "\t\t/* If ndo_xdp_xmit fails with an errno, no frames have",
            "\t\t * been xmit'ed.",
            "\t\t */",
            "\t\terr = sent;",
            "\t\tsent = 0;",
            "\t}",
            "",
            "\t/* If not all frames have been transmitted, it is our",
            "\t * responsibility to free them",
            "\t */",
            "\tfor (i = sent; unlikely(i < to_send); i++)",
            "\t\txdp_return_frame_rx_napi(bq->q[i]);",
            "",
            "out:",
            "\tbq->count = 0;",
            "\ttrace_xdp_devmap_xmit(bq->dev_rx, dev, sent, cnt - sent, err);",
            "}",
            "void __dev_flush(void)",
            "{",
            "\tstruct list_head *flush_list = this_cpu_ptr(&dev_flush_list);",
            "\tstruct xdp_dev_bulk_queue *bq, *tmp;",
            "",
            "\tlist_for_each_entry_safe(bq, tmp, flush_list, flush_node) {",
            "\t\tbq_xmit_all(bq, XDP_XMIT_FLUSH);",
            "\t\tbq->dev_rx = NULL;",
            "\t\tbq->xdp_prog = NULL;",
            "\t\t__list_del_clearprev(&bq->flush_node);",
            "\t}",
            "}",
            "static void bq_enqueue(struct net_device *dev, struct xdp_frame *xdpf,",
            "\t\t       struct net_device *dev_rx, struct bpf_prog *xdp_prog)",
            "{",
            "\tstruct list_head *flush_list = this_cpu_ptr(&dev_flush_list);",
            "\tstruct xdp_dev_bulk_queue *bq = this_cpu_ptr(dev->xdp_bulkq);",
            "",
            "\tif (unlikely(bq->count == DEV_MAP_BULK_SIZE))",
            "\t\tbq_xmit_all(bq, 0);",
            "",
            "\t/* Ingress dev_rx will be the same for all xdp_frame's in",
            "\t * bulk_queue, because bq stored per-CPU and must be flushed",
            "\t * from net_device drivers NAPI func end.",
            "\t *",
            "\t * Do the same with xdp_prog and flush_list since these fields",
            "\t * are only ever modified together.",
            "\t */",
            "\tif (!bq->dev_rx) {",
            "\t\tbq->dev_rx = dev_rx;",
            "\t\tbq->xdp_prog = xdp_prog;",
            "\t\tlist_add(&bq->flush_node, flush_list);",
            "\t}",
            "",
            "\tbq->q[bq->count++] = xdpf;",
            "}",
            "static inline int __xdp_enqueue(struct net_device *dev, struct xdp_frame *xdpf,",
            "\t\t\t\tstruct net_device *dev_rx,",
            "\t\t\t\tstruct bpf_prog *xdp_prog)",
            "{",
            "\tint err;",
            "",
            "\tif (!(dev->xdp_features & NETDEV_XDP_ACT_NDO_XMIT))",
            "\t\treturn -EOPNOTSUPP;",
            "",
            "\tif (unlikely(!(dev->xdp_features & NETDEV_XDP_ACT_NDO_XMIT_SG) &&",
            "\t\t     xdp_frame_has_frags(xdpf)))",
            "\t\treturn -EOPNOTSUPP;",
            "",
            "\terr = xdp_ok_fwd_dev(dev, xdp_get_frame_len(xdpf));",
            "\tif (unlikely(err))",
            "\t\treturn err;",
            "",
            "\tbq_enqueue(dev, xdpf, dev_rx, xdp_prog);",
            "\treturn 0;",
            "}",
            "static u32 dev_map_bpf_prog_run_skb(struct sk_buff *skb, struct bpf_dtab_netdev *dst)",
            "{",
            "\tstruct xdp_txq_info txq = { .dev = dst->dev };",
            "\tstruct xdp_buff xdp;",
            "\tu32 act;",
            "",
            "\tif (!dst->xdp_prog)",
            "\t\treturn XDP_PASS;",
            "",
            "\t__skb_pull(skb, skb->mac_len);",
            "\txdp.txq = &txq;",
            "",
            "\tact = bpf_prog_run_generic_xdp(skb, &xdp, dst->xdp_prog);",
            "\tswitch (act) {",
            "\tcase XDP_PASS:",
            "\t\t__skb_push(skb, skb->mac_len);",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tbpf_warn_invalid_xdp_action(NULL, dst->xdp_prog, act);",
            "\t\tfallthrough;",
            "\tcase XDP_ABORTED:",
            "\t\ttrace_xdp_exception(dst->dev, dst->xdp_prog, act);",
            "\t\tfallthrough;",
            "\tcase XDP_DROP:",
            "\t\tkfree_skb(skb);",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn act;",
            "}"
          ],
          "function_name": "bq_xmit_all, __dev_flush, bq_enqueue, __xdp_enqueue, dev_map_bpf_prog_run_skb",
          "description": "实现批量数据传输和队列管理。bq_xmit_all批量发送数据帧并处理错误，__dev_flush清除CPU本地的待发送队列，bq_enqueue添加帧到批量队列，__xdp_enqueue验证设备特性并启动传输流程，dev_map_bpf_prog_run_skb处理SKB类型数据包的BPF程序执行。",
          "similarity": 0.4658847749233246
        }
      ]
    },
    {
      "source_file": "kernel/usermode_driver.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:47:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `usermode_driver.c`\n\n---\n\n# usermode_driver.c 技术文档\n\n## 文件概述\n\n`usermode_driver.c` 实现了 Linux 内核中用户态驱动（User Mode Driver, UMD）的支持机制。该文件提供了一套 API，允许内核模块将一段可执行的二进制数据（blob）加载为临时文件系统中的可执行文件，并以此为基础 fork 出一个用户态进程作为驱动程序运行。该机制常用于需要在用户空间执行复杂逻辑但又需与内核紧密协作的驱动场景（如某些固件加载器、安全模块或虚拟设备驱动）。\n\n## 核心功能\n\n### 主要函数\n\n- `blob_to_mnt(const void *data, size_t len, const char *name)`  \n  将二进制数据写入 tmpfs 文件系统中，返回挂载点（vfsmount）。\n\n- `umd_load_blob(struct umd_info *info, const void *data, size_t len)`  \n  将给定的二进制 blob 加载为可执行文件，并关联到 `umd_info` 结构中。\n\n- `umd_unload_blob(struct umd_info *info)`  \n  卸载之前加载的 blob，释放相关文件系统资源。\n\n- `fork_usermode_driver(struct umd_info *info)`  \n  基于已加载的 blob fork 并执行一个用户态驱动进程。\n\n- `umd_setup(struct subprocess_info *info, struct cred *new)`  \n  在子进程中设置执行环境，包括创建通信管道、设置工作目录等。\n\n- `umd_cleanup(struct subprocess_info *info)`  \n  子进程执行失败时的清理回调。\n\n- `umd_cleanup_helper(struct umd_info *info)`  \n  释放 `umd_setup` 中分配的资源（管道、PID 等）。\n\n### 关键数据结构\n\n- `struct umd_info`  \n  描述用户态驱动的上下文信息，包含：\n  - `wd`：工作目录（`struct path`），指向 tmpfs 中的可执行文件所在目录\n  - `driver_name`：驱动程序在 tmpfs 中的文件名\n  - `pipe_to_umh` / `pipe_from_umh`：与用户态进程通信的双向管道\n  - `tgid`：用户态驱动进程的线程组 ID（用于后续管理）\n\n## 关键实现\n\n### Blob 到可执行文件的转换\n\n`blob_to_mnt()` 函数通过以下步骤将内存中的二进制数据转换为可执行文件：\n\n1. 挂载 `tmpfs` 文件系统（使用 `kern_mount()`）\n2. 在挂载点根目录下以指定名称创建文件（权限 `0700`）\n3. 使用 `kernel_write()` 将数据写入文件\n4. 调用 `flush_delayed_fput()` 和 `task_work_run()` 确保文件描述符延迟释放完成，以便后续 `exec` 能以只读方式打开该文件\n\n此机制避免了将驱动二进制写入磁盘，提高了安全性和灵活性。\n\n### 用户态驱动进程的启动\n\n`fork_usermode_driver()` 利用内核的 `call_usermodehelper` 机制：\n\n- 使用 `call_usermodehelper_setup()` 注册 `umd_setup` 作为子进程初始化回调\n- 在 `umd_setup` 中：\n  - 创建两个匿名管道：一个用于内核向用户态发送数据（stdin 重定向），一个用于用户态向内核返回数据（stdout 重定向）\n  - 使用 `replace_fd()` 将标准输入/输出重定向到管道端点\n  - 设置当前进程的 pwd（工作目录）为 tmpfs 挂载点，使 `exec` 能直接以相对路径执行驱动文件\n  - 保存管道文件指针和子进程 TGID 到 `umd_info`\n- 执行 `call_usermodehelper_exec()` 启动进程\n\n### 资源管理与错误处理\n\n- `umd_load_blob()` 和 `umd_unload_blob()` 通过 `WARN_ON_ONCE` 确保状态一致性（避免重复加载/卸载）\n- 若 `exec` 失败，`umd_cleanup` 回调会调用 `umd_cleanup_helper` 释放管道和 PID\n- 所有资源（vfsmount、file、pipe、pid）均通过内核标准接口分配和释放，确保无泄漏\n\n## 依赖关系\n\n- **文件系统**：依赖 `tmpfs`（通过 `get_fs_type(\"tmpfs\")`），用于临时存储可执行 blob\n- **进程管理**：依赖 `call_usermodehelper` 子系统（`linux/kmod.h` 隐式包含），用于 fork/exec 用户态进程\n- **VFS 层**：使用 `kern_mount`/`kern_unmount`、`file_open_root_mnt`、`kernel_write` 等 VFS 接口\n- **IPC 机制**：依赖管道（`create_pipe_files`）实现内核与用户态驱动的双向通信\n- **内存管理**：依赖 `shmem_fs.h`（tmpfs 底层基于共享内存）\n- **任务工作队列**：调用 `task_work_run()` 确保文件描述符及时释放\n\n## 使用场景\n\n1. **动态用户态驱动加载**  \n   内核模块可将嵌入的 ELF 二进制或脚本作为 blob 加载，无需预先安装到文件系统。\n\n2. **安全隔离驱动**  \n   将可能含漏洞的驱动逻辑移至用户空间运行，通过管道与内核通信，降低内核攻击面。\n\n3. **固件或微码加载器**  \n   某些设备需要复杂的固件初始化逻辑，可通过 UMD 在用户态执行，避免内核复杂性。\n\n4. **虚拟设备后端**  \n   如 virtio-user、vhost-user 等场景，内核前端通过 UMD 与用户态后端进程协作。\n\n5. **测试与原型开发**  \n   快速验证驱动逻辑，无需频繁编译内核模块，提高开发效率。\n\n> **注意**：调用者需负责用户态进程的生命周期管理（健康检查、信号终止、管道关闭等）。",
      "similarity": 0.5497688055038452,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/usermode_driver.c",
          "start_line": 60,
          "end_line": 161,
          "content": [
            "int umd_load_blob(struct umd_info *info, const void *data, size_t len)",
            "{",
            "\tstruct vfsmount *mnt;",
            "",
            "\tif (WARN_ON_ONCE(info->wd.dentry || info->wd.mnt))",
            "\t\treturn -EBUSY;",
            "",
            "\tmnt = blob_to_mnt(data, len, info->driver_name);",
            "\tif (IS_ERR(mnt))",
            "\t\treturn PTR_ERR(mnt);",
            "",
            "\tinfo->wd.mnt = mnt;",
            "\tinfo->wd.dentry = mnt->mnt_root;",
            "\treturn 0;",
            "}",
            "int umd_unload_blob(struct umd_info *info)",
            "{",
            "\tif (WARN_ON_ONCE(!info->wd.mnt ||",
            "\t\t\t !info->wd.dentry ||",
            "\t\t\t info->wd.mnt->mnt_root != info->wd.dentry))",
            "\t\treturn -EINVAL;",
            "",
            "\tkern_unmount(info->wd.mnt);",
            "\tinfo->wd.mnt = NULL;",
            "\tinfo->wd.dentry = NULL;",
            "\treturn 0;",
            "}",
            "static int umd_setup(struct subprocess_info *info, struct cred *new)",
            "{",
            "\tstruct umd_info *umd_info = info->data;",
            "\tstruct file *from_umh[2];",
            "\tstruct file *to_umh[2];",
            "\tint err;",
            "",
            "\t/* create pipe to send data to umh */",
            "\terr = create_pipe_files(to_umh, 0);",
            "\tif (err)",
            "\t\treturn err;",
            "\terr = replace_fd(0, to_umh[0], 0);",
            "\tfput(to_umh[0]);",
            "\tif (err < 0) {",
            "\t\tfput(to_umh[1]);",
            "\t\treturn err;",
            "\t}",
            "",
            "\t/* create pipe to receive data from umh */",
            "\terr = create_pipe_files(from_umh, 0);",
            "\tif (err) {",
            "\t\tfput(to_umh[1]);",
            "\t\treplace_fd(0, NULL, 0);",
            "\t\treturn err;",
            "\t}",
            "\terr = replace_fd(1, from_umh[1], 0);",
            "\tfput(from_umh[1]);",
            "\tif (err < 0) {",
            "\t\tfput(to_umh[1]);",
            "\t\treplace_fd(0, NULL, 0);",
            "\t\tfput(from_umh[0]);",
            "\t\treturn err;",
            "\t}",
            "",
            "\tset_fs_pwd(current->fs, &umd_info->wd);",
            "\tumd_info->pipe_to_umh = to_umh[1];",
            "\tumd_info->pipe_from_umh = from_umh[0];",
            "\tumd_info->tgid = get_pid(task_tgid(current));",
            "\treturn 0;",
            "}",
            "static void umd_cleanup(struct subprocess_info *info)",
            "{",
            "\tstruct umd_info *umd_info = info->data;",
            "",
            "\t/* cleanup if umh_setup() was successful but exec failed */",
            "\tif (info->retval)",
            "\t\tumd_cleanup_helper(umd_info);",
            "}",
            "void umd_cleanup_helper(struct umd_info *info)",
            "{",
            "\tfput(info->pipe_to_umh);",
            "\tfput(info->pipe_from_umh);",
            "\tput_pid(info->tgid);",
            "\tinfo->tgid = NULL;",
            "}",
            "int fork_usermode_driver(struct umd_info *info)",
            "{",
            "\tstruct subprocess_info *sub_info;",
            "\tconst char *argv[] = { info->driver_name, NULL };",
            "\tint err;",
            "",
            "\tif (WARN_ON_ONCE(info->tgid))",
            "\t\treturn -EBUSY;",
            "",
            "\terr = -ENOMEM;",
            "\tsub_info = call_usermodehelper_setup(info->driver_name,",
            "\t\t\t\t\t     (char **)argv, NULL, GFP_KERNEL,",
            "\t\t\t\t\t     umd_setup, umd_cleanup, info);",
            "\tif (!sub_info)",
            "\t\tgoto out;",
            "",
            "\terr = call_usermodehelper_exec(sub_info, UMH_WAIT_EXEC);",
            "out:",
            "\treturn err;",
            "}"
          ],
          "function_name": "umd_load_blob, umd_unload_blob, umd_setup, umd_cleanup, umd_cleanup_helper, fork_usermode_driver",
          "description": "提供用户模式驱动程序的数据加载/卸载及子进程管理功能，包括挂载tmpfs、建立进程间管道通信、设置工作目录及清理资源，最终通过call_usermodehelper启动用户态驱动程序",
          "similarity": 0.5225961804389954
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/usermode_driver.c",
          "start_line": 1,
          "end_line": 59,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * umd - User mode driver support",
            " */",
            "#include <linux/shmem_fs.h>",
            "#include <linux/pipe_fs_i.h>",
            "#include <linux/mount.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/task_work.h>",
            "#include <linux/usermode_driver.h>",
            "",
            "static struct vfsmount *blob_to_mnt(const void *data, size_t len, const char *name)",
            "{",
            "\tstruct file_system_type *type;",
            "\tstruct vfsmount *mnt;",
            "\tstruct file *file;",
            "\tssize_t written;",
            "\tloff_t pos = 0;",
            "",
            "\ttype = get_fs_type(\"tmpfs\");",
            "\tif (!type)",
            "\t\treturn ERR_PTR(-ENODEV);",
            "",
            "\tmnt = kern_mount(type);",
            "\tput_filesystem(type);",
            "\tif (IS_ERR(mnt))",
            "\t\treturn mnt;",
            "",
            "\tfile = file_open_root_mnt(mnt, name, O_CREAT | O_WRONLY, 0700);",
            "\tif (IS_ERR(file)) {",
            "\t\tkern_unmount(mnt);",
            "\t\treturn ERR_CAST(file);",
            "\t}",
            "",
            "\twritten = kernel_write(file, data, len, &pos);",
            "\tif (written != len) {",
            "\t\tint err = written;",
            "\t\tif (err >= 0)",
            "\t\t\terr = -ENOMEM;",
            "\t\tfilp_close(file, NULL);",
            "\t\tkern_unmount(mnt);",
            "\t\treturn ERR_PTR(err);",
            "\t}",
            "",
            "\tfput(file);",
            "",
            "\t/* Flush delayed fput so exec can open the file read-only */",
            "\tflush_delayed_fput();",
            "\ttask_work_run();",
            "\treturn mnt;",
            "}",
            "",
            "/**",
            " * umd_load_blob - Remember a blob of bytes for fork_usermode_driver",
            " * @info: information about usermode driver",
            " * @data: a blob of bytes that can be executed as a file",
            " * @len:  The lentgh of the blob",
            " *",
            " */"
          ],
          "function_name": null,
          "description": "创建并挂载tmpfs文件系统以存储二进制数据，通过文件操作将输入数据写入新挂载点的指定名称文件，返回对应的vfsmount结构指针",
          "similarity": 0.4643806219100952
        }
      ]
    },
    {
      "source_file": "kernel/irq/devres.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:52:25\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\devres.c`\n\n---\n\n# `irq/devres.c` 技术文档\n\n## 1. 文件概述\n\n`irq/devres.c` 是 Linux 内核中用于实现**设备资源管理（Device Resource Management, devres）感知的中断（IRQ）申请与释放机制**的核心文件。该文件封装了标准 IRQ 操作（如 `request_irq`、`free_irq` 等）为“可自动释放”的资源管理版本，确保在设备驱动卸载或设备移除时，已申请的中断资源能被自动、安全地释放，避免资源泄漏。\n\n该机制基于内核的 `devres`（Device Resource）框架，将 IRQ 资源与 `struct device` 生命周期绑定，极大简化了驱动开发中的资源管理逻辑。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct irq_devres`**  \n  用于跟踪通过 `devm_*` 接口申请的中断资源，包含：\n  - `irq`：中断号\n  - `dev_id`：传递给中断处理函数的设备标识（用于共享中断的区分）\n\n- **`struct irq_desc_devres`**  \n  用于跟踪通过 `__devm_irq_alloc_descs` 分配的中断描述符范围，包含：\n  - `from`：分配的起始中断号\n  - `cnt`：分配的中断数量\n\n- **`struct irq_generic_chip_devres`**  \n  用于跟踪通过 `devm_irq_setup_generic_chip` 设置的通用中断芯片资源，包含：\n  - `gc`：指向 `irq_chip_generic` 结构的指针\n  - `msk`、`clr`、`set`：用于在释放时还原中断状态的参数\n\n### 主要函数\n\n| 函数名 | 功能描述 |\n|--------|--------|\n| `devm_request_threaded_irq` | 为设备申请带线程化处理的中断，自动管理生命周期 |\n| `devm_request_any_context_irq` | 为设备申请可在任意上下文（硬中断或线程）处理的中断 |\n| `devm_free_irq` | 手动释放由 `devm_*` 接口申请的中断（通常不需要调用） |\n| `__devm_irq_alloc_descs` | 为设备分配并管理一组中断描述符（IRQ descriptors） |\n| `devm_irq_alloc_generic_chip` | 为设备分配并初始化一个通用中断芯片结构（`irq_chip_generic`） |\n| `devm_irq_setup_generic_chip` | 为设备设置通用中断芯片的中断范围，并注册资源释放回调 |\n\n## 3. 关键实现\n\n### 资源自动释放机制\n- 所有 `devm_*` 接口在成功申请资源后，会通过 `devres_alloc()` 分配一个资源描述结构（如 `irq_devres`），并注册对应的释放函数（如 `devm_irq_release`）。\n- 该资源结构通过 `devres_add()` 绑定到 `struct device`。\n- 当设备被移除（`device_del`）或驱动卸载时，内核自动调用所有注册的 `devres` 释放函数，确保 `free_irq()` 或 `irq_free_descs()` 被正确调用。\n\n### 中断匹配逻辑\n- `devm_free_irq()` 使用 `devm_irq_match` 函数通过 `irq` 和 `dev_id` 精确匹配要释放的资源，确保不会误删其他中断。\n\n### 通用中断芯片支持\n- `devm_irq_alloc_generic_chip` 使用 `devm_kzalloc` 分配内存，确保芯片结构随设备生命周期自动释放。\n- `devm_irq_setup_generic_chip` 在设置芯片后注册 `devm_irq_remove_generic_chip` 回调，在设备移除时自动调用 `irq_remove_generic_chip` 清理中断配置。\n\n### 错误处理\n- 所有分配操作（如 `devres_alloc`）失败时返回 `-ENOMEM`。\n- 底层 IRQ 申请失败时，会释放已分配的 `devres` 结构，避免内存泄漏。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/device.h>`：提供 `devres` 框架接口（`devres_alloc`, `devres_add`, `devres_destroy` 等）\n  - `<linux/interrupt.h>`：提供标准 IRQ 接口（`request_threaded_irq`, `free_irq` 等）\n  - `<linux/irq.h>`：提供中断描述符管理接口（`__irq_alloc_descs`, `irq_free_descs`）\n  - `\"internals.h\"`：包含 IRQ 子系统内部实现细节\n\n- **内核配置依赖**：\n  - `CONFIG_GENERIC_IRQ_CHIP`：启用通用中断芯片支持（影响 `devm_irq_alloc_generic_chip` 和 `devm_irq_setup_generic_chip` 的编译）\n\n- **模块导出**：\n  - `devm_request_threaded_irq`、`devm_request_any_context_irq`、`devm_free_irq` 通过 `EXPORT_SYMBOL` 导出，供其他模块使用。\n  - 中断描述符和通用芯片相关函数通过 `EXPORT_SYMBOL_GPL` 导出，仅限 GPL 兼容模块使用。\n\n## 5. 使用场景\n\n- **驱动开发**：设备驱动在 `probe` 函数中使用 `devm_request_threaded_irq()` 申请中断，无需在 `remove` 函数中显式调用 `free_irq()`，简化代码并避免遗漏。\n- **虚拟中断分配**：平台驱动或中断控制器驱动使用 `__devm_irq_alloc_descs()` 为虚拟设备分配中断号范围，确保在设备移除时自动释放描述符。\n- **通用中断控制器**：使用 `devm_irq_alloc_generic_chip()` 和 `devm_irq_setup_generic_chip()` 管理基于 `irq_chip_generic` 的中断控制器，适用于 GPIO、I2C、SPI 等子系统中的中断复用场景。\n- **资源安全释放**：在驱动异常退出或设备热插拔场景下，内核自动释放 IRQ 资源，防止中断悬挂或资源冲突。",
      "similarity": 0.5479161739349365,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/devres.c",
          "start_line": 18,
          "end_line": 122,
          "content": [
            "static void devm_irq_release(struct device *dev, void *res)",
            "{",
            "\tstruct irq_devres *this = res;",
            "",
            "\tfree_irq(this->irq, this->dev_id);",
            "}",
            "static int devm_irq_match(struct device *dev, void *res, void *data)",
            "{",
            "\tstruct irq_devres *this = res, *match = data;",
            "",
            "\treturn this->irq == match->irq && this->dev_id == match->dev_id;",
            "}",
            "int devm_request_threaded_irq(struct device *dev, unsigned int irq,",
            "\t\t\t      irq_handler_t handler, irq_handler_t thread_fn,",
            "\t\t\t      unsigned long irqflags, const char *devname,",
            "\t\t\t      void *dev_id)",
            "{",
            "\tstruct irq_devres *dr;",
            "\tint rc;",
            "",
            "\tdr = devres_alloc(devm_irq_release, sizeof(struct irq_devres),",
            "\t\t\t  GFP_KERNEL);",
            "\tif (!dr)",
            "\t\treturn -ENOMEM;",
            "",
            "\tif (!devname)",
            "\t\tdevname = dev_name(dev);",
            "",
            "\trc = request_threaded_irq(irq, handler, thread_fn, irqflags, devname,",
            "\t\t\t\t  dev_id);",
            "\tif (rc) {",
            "\t\tdevres_free(dr);",
            "\t\treturn rc;",
            "\t}",
            "",
            "\tdr->irq = irq;",
            "\tdr->dev_id = dev_id;",
            "\tdevres_add(dev, dr);",
            "",
            "\treturn 0;",
            "}",
            "int devm_request_any_context_irq(struct device *dev, unsigned int irq,",
            "\t\t\t      irq_handler_t handler, unsigned long irqflags,",
            "\t\t\t      const char *devname, void *dev_id)",
            "{",
            "\tstruct irq_devres *dr;",
            "\tint rc;",
            "",
            "\tdr = devres_alloc(devm_irq_release, sizeof(struct irq_devres),",
            "\t\t\t  GFP_KERNEL);",
            "\tif (!dr)",
            "\t\treturn -ENOMEM;",
            "",
            "\tif (!devname)",
            "\t\tdevname = dev_name(dev);",
            "",
            "\trc = request_any_context_irq(irq, handler, irqflags, devname, dev_id);",
            "\tif (rc < 0) {",
            "\t\tdevres_free(dr);",
            "\t\treturn rc;",
            "\t}",
            "",
            "\tdr->irq = irq;",
            "\tdr->dev_id = dev_id;",
            "\tdevres_add(dev, dr);",
            "",
            "\treturn rc;",
            "}",
            "void devm_free_irq(struct device *dev, unsigned int irq, void *dev_id)",
            "{",
            "\tstruct irq_devres match_data = { irq, dev_id };",
            "",
            "\tWARN_ON(devres_destroy(dev, devm_irq_release, devm_irq_match,",
            "\t\t\t       &match_data));",
            "\tfree_irq(irq, dev_id);",
            "}",
            "static void devm_irq_desc_release(struct device *dev, void *res)",
            "{",
            "\tstruct irq_desc_devres *this = res;",
            "",
            "\tirq_free_descs(this->from, this->cnt);",
            "}",
            "int __devm_irq_alloc_descs(struct device *dev, int irq, unsigned int from,",
            "\t\t\t   unsigned int cnt, int node, struct module *owner,",
            "\t\t\t   const struct irq_affinity_desc *affinity)",
            "{",
            "\tstruct irq_desc_devres *dr;",
            "\tint base;",
            "",
            "\tdr = devres_alloc(devm_irq_desc_release, sizeof(*dr), GFP_KERNEL);",
            "\tif (!dr)",
            "\t\treturn -ENOMEM;",
            "",
            "\tbase = __irq_alloc_descs(irq, from, cnt, node, owner, affinity);",
            "\tif (base < 0) {",
            "\t\tdevres_free(dr);",
            "\t\treturn base;",
            "\t}",
            "",
            "\tdr->from = base;",
            "\tdr->cnt = cnt;",
            "\tdevres_add(dev, dr);",
            "",
            "\treturn base;",
            "}"
          ],
          "function_name": "devm_irq_release, devm_irq_match, devm_request_threaded_irq, devm_request_any_context_irq, devm_free_irq, devm_irq_desc_release, __devm_irq_alloc_descs",
          "description": "实现设备资源管理的中断申请与释放逻辑，包含中断线程处理注册、任意上下文中断申请、中断释放及中断描述符分配等功能，通过devres框架实现资源自动管理。",
          "similarity": 0.5307148098945618
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/devres.c",
          "start_line": 1,
          "end_line": 17,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/module.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/device.h>",
            "#include <linux/gfp.h>",
            "#include <linux/irq.h>",
            "",
            "#include \"internals.h\"",
            "",
            "/*",
            " * Device resource management aware IRQ request/free implementation.",
            " */",
            "struct irq_devres {",
            "\tunsigned int irq;",
            "\tvoid *dev_id;",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义irq_devres结构体，用于存储中断号和设备ID，作为设备资源管理中断请求的辅助数据结构。",
          "similarity": 0.5124855637550354
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/irq/devres.c",
          "start_line": 240,
          "end_line": 266,
          "content": [
            "static void devm_irq_remove_generic_chip(struct device *dev, void *res)",
            "{",
            "\tstruct irq_generic_chip_devres *this = res;",
            "",
            "\tirq_remove_generic_chip(this->gc, this->msk, this->clr, this->set);",
            "}",
            "int devm_irq_setup_generic_chip(struct device *dev, struct irq_chip_generic *gc,",
            "\t\t\t\tu32 msk, enum irq_gc_flags flags,",
            "\t\t\t\tunsigned int clr, unsigned int set)",
            "{",
            "\tstruct irq_generic_chip_devres *dr;",
            "",
            "\tdr = devres_alloc(devm_irq_remove_generic_chip,",
            "\t\t\t  sizeof(*dr), GFP_KERNEL);",
            "\tif (!dr)",
            "\t\treturn -ENOMEM;",
            "",
            "\tirq_setup_generic_chip(gc, msk, flags, clr, set);",
            "",
            "\tdr->gc = gc;",
            "\tdr->msk = msk;",
            "\tdr->clr = clr;",
            "\tdr->set = set;",
            "\tdevres_add(dev, dr);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "devm_irq_remove_generic_chip, devm_irq_setup_generic_chip",
          "description": "提供通用中断芯片的配置与清理接口，用于在设备初始化时设置中断控制器参数并在设备移除时安全地移除通用中断芯片配置。",
          "similarity": 0.46043479442596436
        }
      ]
    }
  ]
}