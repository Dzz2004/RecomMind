{
  "query": "perf工具分析系统调用性能瓶颈",
  "timestamp": "2025-12-26 01:39:23",
  "retrieved_files": [
    {
      "source_file": "kernel/events/callchain.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:21:29\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `events\\callchain.c`\n\n---\n\n# `events/callchain.c` 技术文档\n\n## 1. 文件概述\n\n`events/callchain.c` 是 Linux 内核性能事件（perf events）子系统中用于管理调用链（callchain）的核心实现文件。该文件负责为性能采样事件分配、管理和回收调用栈缓冲区，并提供统一接口用于在内核态和用户态采集函数调用链信息。调用链用于记录函数调用的层次结构，是性能分析（如火焰图）的关键数据来源。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct callchain_cpus_entries`**  \n  每 CPU 调用链条目数组的容器结构，通过 RCU 机制安全地管理生命周期。\n\n- **`struct perf_callchain_entry_ctx`**  \n  调用链构建上下文，包含当前条目指针、最大栈深度、已记录项数等状态信息（定义在 `internal.h` 中）。\n\n- **`struct perf_callchain_entry`**  \n  实际存储调用地址的结构（定义在 `<linux/perf_event.h>`），包含 `nr`（有效项数）和 `ip[]`（指令指针数组）。\n\n### 主要全局变量\n\n- `sysctl_perf_event_max_stack`：系统级调用栈最大深度（默认 `PERF_MAX_STACK_DEPTH`）。\n- `sysctl_perf_event_max_contexts_per_stack`：每个栈中允许的最大上下文标记数（如 `PERF_CONTEXT_KERNEL`/`USER`）。\n- `callchain_cpus_entries`：指向每 CPU 调用链缓冲区的全局指针，通过 RCU 保护。\n- `callchain_recursion`：每 CPU 递归上下文标记数组，防止在 NMI 或中断上下文中重复进入调用链采集。\n- `nr_callchain_events`：引用计数，跟踪当前活跃的需要调用链的 perf 事件数量。\n- `callchain_mutex`：保护缓冲区分配/释放和 sysctl 修改的互斥锁。\n\n### 主要函数\n\n- **`get_callchain_buffers()` / `put_callchain_buffers()`**  \n  引用计数式地分配和释放全局调用链缓冲区。\n\n- **`get_callchain_entry()` / `put_callchain_entry()`**  \n  获取/释放当前 CPU 上可用的调用链条目，支持多上下文（如中断、NMI）隔离。\n\n- **`get_perf_callchain()`**  \n  高层接口，根据寄存器状态采集内核态和/或用户态的完整调用链。\n\n- **`perf_callchain_kernel()` / `perf_callchain_user()`**  \n  弱符号函数，由各架构实现具体的栈回溯逻辑（如 x86 使用 `dump_trace()`）。\n\n- **`perf_event_max_stack_handler()`**  \n  sysctl 处理函数，允许动态调整最大栈深度（仅在无活跃事件时生效）。\n\n## 3. 关键实现\n\n### 调用链缓冲区管理\n\n- 使用 **每 CPU 独立缓冲区** 避免锁竞争，每个 CPU 分配 `PERF_NR_CONTEXTS` 个 `perf_callchain_entry`（支持中断、NMI 等多上下文）。\n- 缓冲区大小由 `perf_callchain_entry__sizeof()` 动态计算，结合 `sysctl_perf_event_max_stack` 和上下文标记数量。\n- 通过 **RCU 机制** 安全释放旧缓冲区，确保在可能的 NMI 上下文中仍可安全访问。\n\n### 递归上下文保护\n\n- `callchain_recursion` 数组标记当前 CPU 的调用链采集上下文（0=普通，1=NMI 等）。\n- `get_recursion_context()`/`put_recursion_context()` 确保同一上下文不会嵌套调用链采集，防止缓冲区覆盖。\n\n### 架构无关接口\n\n- `perf_callchain_kernel()` 和 `perf_callchain_user()` 为 **弱符号**，允许各架构（如 x86、ARM）提供具体实现。\n- 内核态回溯通常基于 `regs` 寄存器状态和内核栈；用户态回溯需切换到用户栈并解析 DWARF 或 frame pointer。\n\n### 安全限制\n\n- `get_callchain_buffers()` 检查请求的 `event_max_stack` 不超过全局上限，超限返回 `-EOVERFLOW`。\n- sysctl 修改需在无活跃事件时进行（`nr_callchain_events == 0`），否则返回 `-EBUSY`。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/perf_event.h>`：perf 事件核心定义。\n  - `<linux/slab.h>`：内存分配（`kmalloc`/`kfree`）。\n  - `<linux/sched/task_stack.h>`：任务栈相关辅助函数。\n  - `\"internal.h\"`：perf 子系统内部头文件，包含 `perf_callchain_entry_ctx` 等。\n\n- **架构依赖**：\n  - 各架构需实现 `perf_callchain_kernel()` 和 `perf_callchain_user()`（如 `arch/x86/events/core.c`）。\n\n- **子系统依赖**：\n  - RCU 机制（`call_rcu`, `rcu_dereference`）。\n  - Per-CPU 变量（`DEFINE_PER_CPU`, `this_cpu_ptr`）。\n  - 内存节点分配（`kmalloc_node`）。\n\n## 5. 使用场景\n\n- **性能分析工具**：`perf record -g` 采集调用链时，内核通过此模块记录函数调用栈。\n- **动态跟踪**：eBPF 程序或 ftrace 在需要栈回溯时调用 `get_perf_callchain()`。\n- **系统监控**：当 perf 事件配置为 `PERF_SAMPLE_CALLCHAIN` 时，采样中断处理中调用此模块。\n- **安全审计**：某些 LSM 模块可能利用调用链信息进行行为分析。\n- **调试场景**：内核 oops 或 lockdep 在需要栈信息时可能间接使用此机制。",
      "similarity": 0.6325830817222595,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/events/callchain.c",
          "start_line": 145,
          "end_line": 215,
          "content": [
            "void put_callchain_buffers(void)",
            "{",
            "\tif (atomic_dec_and_mutex_lock(&nr_callchain_events, &callchain_mutex)) {",
            "\t\trelease_callchain_buffers();",
            "\t\tmutex_unlock(&callchain_mutex);",
            "\t}",
            "}",
            "void",
            "put_callchain_entry(int rctx)",
            "{",
            "\tput_recursion_context(this_cpu_ptr(callchain_recursion), rctx);",
            "}",
            "static void fixup_uretprobe_trampoline_entries(struct perf_callchain_entry *entry,",
            "\t\t\t\t\t       int start_entry_idx)",
            "{",
            "#ifdef CONFIG_UPROBES",
            "\tstruct uprobe_task *utask = current->utask;",
            "\tstruct return_instance *ri;",
            "\t__u64 *cur_ip, *last_ip, tramp_addr;",
            "",
            "\tif (likely(!utask || !utask->return_instances))",
            "\t\treturn;",
            "",
            "\tcur_ip = &entry->ip[start_entry_idx];",
            "\tlast_ip = &entry->ip[entry->nr - 1];",
            "\tri = utask->return_instances;",
            "\ttramp_addr = uprobe_get_trampoline_vaddr();",
            "",
            "\t/*",
            "\t * If there are pending uretprobes for the current thread, they are",
            "\t * recorded in a list inside utask->return_instances; each such",
            "\t * pending uretprobe replaces traced user function's return address on",
            "\t * the stack, so when stack trace is captured, instead of seeing",
            "\t * actual function's return address, we'll have one or many uretprobe",
            "\t * trampoline addresses in the stack trace, which are not helpful and",
            "\t * misleading to users.",
            "\t * So here we go over the pending list of uretprobes, and each",
            "\t * encountered trampoline address is replaced with actual return",
            "\t * address.",
            "\t */",
            "\twhile (ri && cur_ip <= last_ip) {",
            "\t\tif (*cur_ip == tramp_addr) {",
            "\t\t\t*cur_ip = ri->orig_ret_vaddr;",
            "\t\t\tri = ri->next;",
            "\t\t}",
            "\t\tcur_ip++;",
            "\t}",
            "#endif",
            "}",
            "int perf_event_max_stack_handler(struct ctl_table *table, int write,",
            "\t\t\t\t void *buffer, size_t *lenp, loff_t *ppos)",
            "{",
            "\tint *value = table->data;",
            "\tint new_value = *value, ret;",
            "\tstruct ctl_table new_table = *table;",
            "",
            "\tnew_table.data = &new_value;",
            "\tret = proc_dointvec_minmax(&new_table, write, buffer, lenp, ppos);",
            "\tif (ret || !write)",
            "\t\treturn ret;",
            "",
            "\tmutex_lock(&callchain_mutex);",
            "\tif (atomic_read(&nr_callchain_events))",
            "\t\tret = -EBUSY;",
            "\telse",
            "\t\t*value = new_value;",
            "",
            "\tmutex_unlock(&callchain_mutex);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "put_callchain_buffers, put_callchain_entry, fixup_uretprobe_trampoline_entries, perf_event_max_stack_handler",
          "description": "提供调用链缓冲区的引用计数管理、URETPROBE陷阱地址修复逻辑，以及性能事件最大栈深度的动态配置处理函数，确保栈追踪数据的准确性与系统调参的原子性操作。",
          "similarity": 0.5703374743461609
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/events/callchain.c",
          "start_line": 26,
          "end_line": 131,
          "content": [
            "static inline size_t perf_callchain_entry__sizeof(void)",
            "{",
            "\treturn (sizeof(struct perf_callchain_entry) +",
            "\t\tsizeof(__u64) * (sysctl_perf_event_max_stack +",
            "\t\t\t\t sysctl_perf_event_max_contexts_per_stack));",
            "}",
            "__weak void perf_callchain_kernel(struct perf_callchain_entry_ctx *entry,",
            "\t\t\t\t  struct pt_regs *regs)",
            "{",
            "}",
            "__weak void perf_callchain_user(struct perf_callchain_entry_ctx *entry,",
            "\t\t\t\tstruct pt_regs *regs)",
            "{",
            "}",
            "static void release_callchain_buffers_rcu(struct rcu_head *head)",
            "{",
            "\tstruct callchain_cpus_entries *entries;",
            "\tint cpu;",
            "",
            "\tentries = container_of(head, struct callchain_cpus_entries, rcu_head);",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tkfree(entries->cpu_entries[cpu]);",
            "",
            "\tkfree(entries);",
            "}",
            "static void release_callchain_buffers(void)",
            "{",
            "\tstruct callchain_cpus_entries *entries;",
            "",
            "\tentries = callchain_cpus_entries;",
            "\tRCU_INIT_POINTER(callchain_cpus_entries, NULL);",
            "\tcall_rcu(&entries->rcu_head, release_callchain_buffers_rcu);",
            "}",
            "static int alloc_callchain_buffers(void)",
            "{",
            "\tint cpu;",
            "\tint size;",
            "\tstruct callchain_cpus_entries *entries;",
            "",
            "\t/*",
            "\t * We can't use the percpu allocation API for data that can be",
            "\t * accessed from NMI. Use a temporary manual per cpu allocation",
            "\t * until that gets sorted out.",
            "\t */",
            "\tsize = offsetof(struct callchain_cpus_entries, cpu_entries[nr_cpu_ids]);",
            "",
            "\tentries = kzalloc(size, GFP_KERNEL);",
            "\tif (!entries)",
            "\t\treturn -ENOMEM;",
            "",
            "\tsize = perf_callchain_entry__sizeof() * PERF_NR_CONTEXTS;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tentries->cpu_entries[cpu] = kmalloc_node(size, GFP_KERNEL,",
            "\t\t\t\t\t\t\t cpu_to_node(cpu));",
            "\t\tif (!entries->cpu_entries[cpu])",
            "\t\t\tgoto fail;",
            "\t}",
            "",
            "\trcu_assign_pointer(callchain_cpus_entries, entries);",
            "",
            "\treturn 0;",
            "",
            "fail:",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tkfree(entries->cpu_entries[cpu]);",
            "\tkfree(entries);",
            "",
            "\treturn -ENOMEM;",
            "}",
            "int get_callchain_buffers(int event_max_stack)",
            "{",
            "\tint err = 0;",
            "\tint count;",
            "",
            "\tmutex_lock(&callchain_mutex);",
            "",
            "\tcount = atomic_inc_return(&nr_callchain_events);",
            "\tif (WARN_ON_ONCE(count < 1)) {",
            "\t\terr = -EINVAL;",
            "\t\tgoto exit;",
            "\t}",
            "",
            "\t/*",
            "\t * If requesting per event more than the global cap,",
            "\t * return a different error to help userspace figure",
            "\t * this out.",
            "\t *",
            "\t * And also do it here so that we have &callchain_mutex held.",
            "\t */",
            "\tif (event_max_stack > sysctl_perf_event_max_stack) {",
            "\t\terr = -EOVERFLOW;",
            "\t\tgoto exit;",
            "\t}",
            "",
            "\tif (count == 1)",
            "\t\terr = alloc_callchain_buffers();",
            "exit:",
            "\tif (err)",
            "\t\tatomic_dec(&nr_callchain_events);",
            "",
            "\tmutex_unlock(&callchain_mutex);",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "perf_callchain_entry__sizeof, perf_callchain_kernel, perf_callchain_user, release_callchain_buffers_rcu, release_callchain_buffers, alloc_callchain_buffers, get_callchain_buffers",
          "description": "实现调用链缓冲区的动态分配与释放逻辑，包含缓冲区大小计算、跨CPU内存分配、RCU安全释放机制及根据当前事件栈需求进行缓冲区初始化和清理的操作。",
          "similarity": 0.509799599647522
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/events/callchain.c",
          "start_line": 1,
          "end_line": 25,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Performance events callchain code, extracted from core.c:",
            " *",
            " *  Copyright (C) 2008 Thomas Gleixner <tglx@linutronix.de>",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Ingo Molnar",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Peter Zijlstra",
            " *  Copyright  ©  2009 Paul Mackerras, IBM Corp. <paulus@au1.ibm.com>",
            " */",
            "",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/uprobes.h>",
            "",
            "#include \"internal.h\"",
            "",
            "struct callchain_cpus_entries {",
            "\tstruct rcu_head\t\t\trcu_head;",
            "\tstruct perf_callchain_entry\t*cpu_entries[];",
            "};",
            "",
            "int sysctl_perf_event_max_stack __read_mostly = PERF_MAX_STACK_DEPTH;",
            "int sysctl_perf_event_max_contexts_per_stack __read_mostly = PERF_MAX_CONTEXTS_PER_STACK;",
            ""
          ],
          "function_name": null,
          "description": "定义callchain_cpus_entries结构体用于存储每个CPU的调用链条目数组，并声明两个sysctl全局变量用于配置性能事件的最大栈深度和每个栈的最大上下文数。",
          "similarity": 0.47141897678375244
        }
      ]
    },
    {
      "source_file": "kernel/watchdog_perf.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:52:30\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `watchdog_perf.c`\n\n---\n\n# watchdog_perf.c 技术文档\n\n## 1. 文件概述\n\n`watchdog_perf.c` 是 Linux 内核中用于实现**硬锁死（hard lockup）检测机制**的核心文件。它基于 **perf 事件子系统**，通过在每个 CPU 上创建一个周期性溢出的硬件性能计数器（通常监控 CPU 周期），在非屏蔽中断（NMI）上下文中触发回调，从而检测 CPU 是否因长时间禁用中断或陷入死循环而无法响应。该机制是 NMI watchdog 的现代实现，替代了早期架构相关的实现方式，具有更好的可移植性和灵活性。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `wd_hw_attr` / `fallback_wd_hw_attr`：`struct perf_event_attr` 类型，定义用于硬锁死检测的 perf 事件属性（默认监控 `PERF_COUNT_HW_CPU_CYCLES`）。\n- `watchdog_ev`：每 CPU 变量，指向当前 CPU 上创建的 perf 事件对象。\n- `watchdog_cpus`：原子变量，记录当前已启用硬锁死检测的 CPU 数量。\n- （条件编译）`last_timestamp`：每 CPU 变量，记录上次 NMI 触发的时间戳（用于防误报）。\n- （条件编译）`nmi_rearmed`：每 CPU 变量，记录连续未满足时间阈值的 NMI 次数。\n- （条件编译）`watchdog_hrtimer_sample_threshold`：全局阈值，用于判断 NMI 采样间隔是否合理。\n\n### 主要函数\n\n- `watchdog_overflow_callback()`：perf 事件溢出时的回调函数，在 NMI 上下文中执行，负责调用硬锁死检查逻辑。\n- `hardlockup_detector_event_create()`：为当前 CPU 创建并初始化 perf 事件。\n- `watchdog_hardlockup_enable(cpu)`：启用指定 CPU 的硬锁死检测。\n- `watchdog_hardlockup_disable(cpu)`：禁用指定 CPU 的硬锁死检测。\n- `hardlockup_detector_perf_stop()` / `hardlockup_detector_perf_restart()`：全局暂停/恢复所有 CPU 的 watchdog 事件（用于处理 x86 超线程 bug）。\n- `watchdog_hardlockup_probe()`：探测当前系统是否支持基于 perf 的 NMI watchdog。\n- `hardlockup_config_perf_event(str)`：允许通过内核启动参数自定义 perf 事件的原始配置。\n- （条件编译）`watchdog_check_timestamp()`：检查 NMI 触发间隔是否过短，防止因 Turbo Boost 等导致的误报。\n- （条件编译）`watchdog_init_timestamp()`：初始化每 CPU 的时间戳。\n\n## 3. 关键实现\n\n### 硬锁死检测原理\n- 每个在线 CPU 启动一个 **pinned、disabled** 的 perf 事件，监控硬件 CPU 周期计数器。\n- 事件配置为在达到 `hw_nmi_get_sample_period(watchdog_thresh)` 周期后溢出，触发 NMI。\n- 在 NMI 回调 `watchdog_overflow_callback()` 中：\n  - 重置事件中断计数（防止被 perf 子系统节流）。\n  - （若启用 `CONFIG_HARDLOCKUP_CHECK_TIMESTAMP`）检查自上次 NMI 以来是否已过去足够时间（避免因 CPU 频率动态调整导致的过快触发）。\n  - 调用通用硬锁死检查函数 `watchdog_hardlockup_check()`。\n\n### 防误报机制 (`CONFIG_HARDLOCKUP_CHECK_TIMESTAMP`)\n- 引入 `watchdog_hrtimer_sample_threshold`（设为 `watchdog_thresh * 2` 纳秒）。\n- 若两次 NMI 间隔小于该阈值，则认为可能是因 CPU Turbo Boost 导致周期计数过快，暂时忽略此次触发。\n- 连续 10 次过快触发后强制通过检查，防止因系统时钟停滞（如 jiffies 停滞）导致 watchdog 失效。\n\n### 事件创建与回退\n- 优先使用 `wd_hw_attr` 创建事件。\n- 若失败（如硬件 PMU 资源不足），尝试使用相同的 `fallback_wd_hw_attr`（当前实现中两者相同，但保留扩展性）。\n- 创建失败则打印调试信息并返回错误。\n\n### 架构适配\n- 通过弱符号 `arch_perf_nmi_is_available()` 允许架构层声明是否支持 perf-based NMI。\n- 提供 `hardlockup_config_perf_event()` 接口，允许用户通过 `nmi_watchdog=` 内核参数指定原始 perf 事件编码，用于调试或适配特殊硬件。\n\n### 全局控制接口\n- `hardlockup_detector_perf_stop/restart` 用于在特定场景（如 x86 超线程 bug 修复）下临时全局禁用/启用所有 watchdog 事件，要求调用时持有 CPU hotplug 锁。\n\n## 4. 依赖关系\n\n- **perf_event 子系统**：核心依赖，用于创建和管理硬件性能计数器事件。\n- **NMI 子系统**：perf 事件溢出通过 NMI 触发回调，依赖 `linux/nmi.h`。\n- **调度器调试功能**：调用 `watchdog_hardlockup_check()`（定义在 `kernel/watchdog.c`），该函数会打印 CPU 状态和堆栈。\n- **架构特定代码**：\n  - `hw_nmi_get_sample_period()`：由架构提供，根据 `watchdog_thresh` 计算 perf 采样周期。\n  - `arch_perf_nmi_is_available()`：架构可覆盖此函数以禁用 perf watchdog。\n- **内核配置选项**：依赖 `CONFIG_HARDLOCKUP_DETECTOR` 和 `CONFIG_PERF_EVENTS`，可选依赖 `CONFIG_HARDLOCKUP_CHECK_TIMESTAMP`。\n\n## 5. 使用场景\n\n- **系统稳定性监控**：在生产环境中持续监控 CPU 是否发生硬锁死（即 CPU 长时间无法处理中断）。\n- **内核调试**：当系统无响应时，若 watchdog 触发，会打印出故障 CPU 的寄存器状态和调用栈，辅助定位死锁或无限循环问题。\n- **架构无关的 watchdog 实现**：作为通用框架，替代旧的 x86-specific NMI watchdog，便于在 ARM64、RISC-V 等架构上实现统一的硬锁死检测。\n- **动态配置**：通过内核参数（如 `nmi_watchdog=...`）允许用户指定特定的 perf 事件，用于在标准 CPU 周期计数器不可靠的平台上进行调试。\n- **与软锁死检测协同**：硬锁死检测（基于 NMI）与软锁死检测（基于高精度定时器）共同构成完整的内核 watchdog 机制，分别检测中断禁用和进程调度层面的锁死。",
      "similarity": 0.6270378232002258,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/watchdog_perf.c",
          "start_line": 177,
          "end_line": 280,
          "content": [
            "void watchdog_hardlockup_disable(unsigned int cpu)",
            "{",
            "\tstruct perf_event *event = this_cpu_read(watchdog_ev);",
            "",
            "\tWARN_ON_ONCE(cpu != smp_processor_id());",
            "",
            "\tif (event) {",
            "\t\tperf_event_disable(event);",
            "\t\tperf_event_release_kernel(event);",
            "\t\tthis_cpu_write(watchdog_ev, NULL);",
            "\t\tatomic_dec(&watchdog_cpus);",
            "\t}",
            "}",
            "void hardlockup_detector_perf_adjust_period(u64 period)",
            "{",
            "\tstruct perf_event *event = this_cpu_read(watchdog_ev);",
            "",
            "\tif (!(watchdog_enabled & WATCHDOG_HARDLOCKUP_ENABLED))",
            "\t\treturn;",
            "",
            "\tif (!event)",
            "\t\treturn;",
            "",
            "\tif (event->attr.sample_period == period)",
            "\t\treturn;",
            "",
            "\tif (perf_event_period(event, period))",
            "\t\tpr_err(\"failed to change period to %llu\\n\", period);",
            "}",
            "void __init hardlockup_detector_perf_stop(void)",
            "{",
            "\tint cpu;",
            "",
            "\tlockdep_assert_cpus_held();",
            "",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct perf_event *event = per_cpu(watchdog_ev, cpu);",
            "",
            "\t\tif (event)",
            "\t\t\tperf_event_disable(event);",
            "\t}",
            "}",
            "void __init hardlockup_detector_perf_restart(void)",
            "{",
            "\tint cpu;",
            "",
            "\tlockdep_assert_cpus_held();",
            "",
            "\tif (!(watchdog_enabled & WATCHDOG_HARDLOCKUP_ENABLED))",
            "\t\treturn;",
            "",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct perf_event *event = per_cpu(watchdog_ev, cpu);",
            "",
            "\t\tif (event)",
            "\t\t\tperf_event_enable(event);",
            "\t}",
            "}",
            "bool __weak __init arch_perf_nmi_is_available(void)",
            "{",
            "\treturn true;",
            "}",
            "int __init watchdog_hardlockup_probe(void)",
            "{",
            "\tint ret;",
            "",
            "\tif (!arch_perf_nmi_is_available())",
            "\t\treturn -ENODEV;",
            "",
            "\tret = hardlockup_detector_event_create();",
            "",
            "\tif (ret) {",
            "\t\tpr_info(\"Perf NMI watchdog permanently disabled\\n\");",
            "\t} else {",
            "\t\tperf_event_release_kernel(this_cpu_read(watchdog_ev));",
            "\t\tthis_cpu_write(watchdog_ev, NULL);",
            "\t}",
            "\treturn ret;",
            "}",
            "void __init hardlockup_config_perf_event(const char *str)",
            "{",
            "\tu64 config;",
            "\tchar buf[24];",
            "\tchar *comma = strchr(str, ',');",
            "",
            "\tif (!comma) {",
            "\t\tif (kstrtoull(str, 16, &config))",
            "\t\t\treturn;",
            "\t} else {",
            "\t\tunsigned int len = comma - str;",
            "",
            "\t\tif (len >= sizeof(buf))",
            "\t\t\treturn;",
            "",
            "\t\tif (strscpy(buf, str, sizeof(buf)) < 0)",
            "\t\t\treturn;",
            "\t\tbuf[len] = 0;",
            "\t\tif (kstrtoull(buf, 16, &config))",
            "\t\t\treturn;",
            "\t}",
            "",
            "\twd_hw_attr.type = PERF_TYPE_RAW;",
            "\twd_hw_attr.config = config;",
            "}"
          ],
          "function_name": "watchdog_hardlockup_disable, hardlockup_detector_perf_adjust_period, hardlockup_detector_perf_stop, hardlockup_detector_perf_restart, arch_perf_nmi_is_available, watchdog_hardlockup_probe, hardlockup_config_perf_event",
          "description": "提供硬锁检测的控制接口，包含事件周期调整、全局启停管理及初始化探测功能，支持动态配置perf事件参数并处理硬件兼容性检查。",
          "similarity": 0.5943650603294373
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/watchdog_perf.c",
          "start_line": 32,
          "end_line": 141,
          "content": [
            "void watchdog_update_hrtimer_threshold(u64 period)",
            "{",
            "\t/*",
            "\t * The hrtimer runs with a period of (watchdog_threshold * 2) / 5",
            "\t *",
            "\t * So it runs effectively with 2.5 times the rate of the NMI",
            "\t * watchdog. That means the hrtimer should fire 2-3 times before",
            "\t * the NMI watchdog expires. The NMI watchdog on x86 is based on",
            "\t * unhalted CPU cycles, so if Turbo-Mode is enabled the CPU cycles",
            "\t * might run way faster than expected and the NMI fires in a",
            "\t * smaller period than the one deduced from the nominal CPU",
            "\t * frequency. Depending on the Turbo-Mode factor this might be fast",
            "\t * enough to get the NMI period smaller than the hrtimer watchdog",
            "\t * period and trigger false positives.",
            "\t *",
            "\t * The sample threshold is used to check in the NMI handler whether",
            "\t * the minimum time between two NMI samples has elapsed. That",
            "\t * prevents false positives.",
            "\t *",
            "\t * Set this to 4/5 of the actual watchdog threshold period so the",
            "\t * hrtimer is guaranteed to fire at least once within the real",
            "\t * watchdog threshold.",
            "\t */",
            "\twatchdog_hrtimer_sample_threshold = period * 2;",
            "}",
            "static bool watchdog_check_timestamp(void)",
            "{",
            "\tktime_t delta, now = ktime_get_mono_fast_ns();",
            "",
            "\tdelta = now - __this_cpu_read(last_timestamp);",
            "\tif (delta < watchdog_hrtimer_sample_threshold) {",
            "\t\t/*",
            "\t\t * If ktime is jiffies based, a stalled timer would prevent",
            "\t\t * jiffies from being incremented and the filter would look",
            "\t\t * at a stale timestamp and never trigger.",
            "\t\t */",
            "\t\tif (__this_cpu_inc_return(nmi_rearmed) < 10)",
            "\t\t\treturn false;",
            "\t}",
            "\t__this_cpu_write(nmi_rearmed, 0);",
            "\t__this_cpu_write(last_timestamp, now);",
            "\treturn true;",
            "}",
            "static void watchdog_init_timestamp(void)",
            "{",
            "\t__this_cpu_write(nmi_rearmed, 0);",
            "\t__this_cpu_write(last_timestamp, ktime_get_mono_fast_ns());",
            "}",
            "static inline bool watchdog_check_timestamp(void) { return true; }",
            "static inline void watchdog_init_timestamp(void) { }",
            "static void watchdog_overflow_callback(struct perf_event *event,",
            "\t\t\t\t       struct perf_sample_data *data,",
            "\t\t\t\t       struct pt_regs *regs)",
            "{",
            "\t/* Ensure the watchdog never gets throttled */",
            "\tevent->hw.interrupts = 0;",
            "",
            "\tif (!watchdog_check_timestamp())",
            "\t\treturn;",
            "",
            "\twatchdog_hardlockup_check(smp_processor_id(), regs);",
            "}",
            "static int hardlockup_detector_event_create(void)",
            "{",
            "\tunsigned int cpu;",
            "\tstruct perf_event_attr *wd_attr;",
            "\tstruct perf_event *evt;",
            "",
            "\t/*",
            "\t * Preemption is not disabled because memory will be allocated.",
            "\t * Ensure CPU-locality by calling this in per-CPU kthread.",
            "\t */",
            "\tWARN_ON(!is_percpu_thread());",
            "\tcpu = raw_smp_processor_id();",
            "\twd_attr = &wd_hw_attr;",
            "\twd_attr->sample_period = hw_nmi_get_sample_period(watchdog_thresh);",
            "",
            "\t/* Try to register using hardware perf events */",
            "\tevt = perf_event_create_kernel_counter(wd_attr, cpu, NULL,",
            "\t\t\t\t\t       watchdog_overflow_callback, NULL);",
            "\tif (IS_ERR(evt)) {",
            "\t\twd_attr = &fallback_wd_hw_attr;",
            "\t\twd_attr->sample_period = hw_nmi_get_sample_period(watchdog_thresh);",
            "\t\tevt = perf_event_create_kernel_counter(wd_attr, cpu, NULL,",
            "\t\t\t\t\t\t       watchdog_overflow_callback, NULL);",
            "\t}",
            "",
            "\tif (IS_ERR(evt)) {",
            "\t\tpr_debug(\"Perf event create on CPU %d failed with %ld\\n\", cpu,",
            "\t\t\t PTR_ERR(evt));",
            "\t\treturn PTR_ERR(evt);",
            "\t}",
            "\tWARN_ONCE(this_cpu_read(watchdog_ev), \"unexpected watchdog_ev leak\");",
            "\tthis_cpu_write(watchdog_ev, evt);",
            "\treturn 0;",
            "}",
            "void watchdog_hardlockup_enable(unsigned int cpu)",
            "{",
            "\tWARN_ON_ONCE(cpu != smp_processor_id());",
            "",
            "\tif (hardlockup_detector_event_create())",
            "\t\treturn;",
            "",
            "\t/* use original value for check */",
            "\tif (!atomic_fetch_inc(&watchdog_cpus))",
            "\t\tpr_info(\"Enabled. Permanently consumes one hw-PMU counter.\\n\");",
            "",
            "\twatchdog_init_timestamp();",
            "\tperf_event_enable(this_cpu_read(watchdog_ev));",
            "}"
          ],
          "function_name": "watchdog_update_hrtimer_threshold, watchdog_check_timestamp, watchdog_init_timestamp, watchdog_check_timestamp, watchdog_init_timestamp, watchdog_overflow_callback, hardlockup_detector_event_create, watchdog_hardlockup_enable",
          "description": "实现硬锁检测核心逻辑，包括时间戳校验、事件回调处理及perf事件创建与启用，通过周期性采样检测CPU空转并触发动态检查机制。",
          "similarity": 0.5751944780349731
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/watchdog_perf.c",
          "start_line": 1,
          "end_line": 31,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Detect hard lockups on a system using perf",
            " *",
            " * started by Don Zickus, Copyright (C) 2010 Red Hat, Inc.",
            " *",
            " * Note: Most of this code is borrowed heavily from the original softlockup",
            " * detector, so thanks to Ingo for the initial implementation.",
            " * Some chunks also taken from the old x86-specific nmi watchdog code, thanks",
            " * to those contributors as well.",
            " */",
            "",
            "#define pr_fmt(fmt) \"NMI watchdog: \" fmt",
            "",
            "#include <linux/nmi.h>",
            "#include <linux/atomic.h>",
            "#include <linux/module.h>",
            "#include <linux/sched/debug.h>",
            "",
            "#include <asm/irq_regs.h>",
            "#include <linux/perf_event.h>",
            "",
            "static DEFINE_PER_CPU(struct perf_event *, watchdog_ev);",
            "",
            "static atomic_t watchdog_cpus = ATOMIC_INIT(0);",
            "",
            "#ifdef CONFIG_HARDLOCKUP_CHECK_TIMESTAMP",
            "static DEFINE_PER_CPU(ktime_t, last_timestamp);",
            "static DEFINE_PER_CPU(unsigned int, nmi_rearmed);",
            "static ktime_t watchdog_hrtimer_sample_threshold __read_mostly;",
            ""
          ],
          "function_name": null,
          "description": "定义硬锁检测使用的PERF_EVENT相关变量，包括per-CPU的perf事件指针、计数器原子变量及时间戳相关变量，用于追踪CPU状态和检测锁死情况。",
          "similarity": 0.5684773921966553
        }
      ]
    },
    {
      "source_file": "kernel/power/energy_model.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:20:12\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `power\\energy_model.c`\n\n---\n\n# `power/energy_model.c` 技术文档\n\n## 1. 文件概述\n\n`power/energy_model.c` 是 Linux 内核中实现 **能量模型（Energy Model, EM）** 的核心文件，主要用于描述设备（尤其是 CPU）在不同性能状态（Performance State, OPP）下的功耗、频率、性能和能效成本等信息。该模型为 **能耗感知调度器（Energy Aware Scheduling, EAS）** 提供关键数据支持，以实现更优的任务调度和能效管理。\n\n该文件由 Arm Ltd. 开发并维护，支持动态注册/更新设备的性能域（Performance Domain），并通过 debugfs 提供调试接口（在 `CONFIG_DEBUG_FS` 启用时）。\n\n---\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct em_perf_domain`：表示一个性能域，包含多个性能状态。\n- `struct em_perf_state`：描述单个性能状态，包含 `frequency`、`power`、`performance`、`cost` 和 `flags` 等字段。\n- `struct em_perf_table`：包含性能状态数组及引用计数（`kref`）和 RCU 释放机制。\n- `struct em_data_callback`：用于从驱动获取功耗/成本数据的回调接口（部分在头文件中定义）。\n\n### 主要函数\n\n| 函数 | 功能说明 |\n|------|--------|\n| `em_table_alloc()` | 为性能域分配新的 EM 表，初始化引用计数 |\n| `em_table_free()` | 安全释放 EM 表（基于 `kref` 和 RCU） |\n| `em_init_performance()` | 为 CPU 设备初始化 `performance` 字段（基于最大频率和 CPU 容量） |\n| `em_compute_costs()` | 计算每个性能状态的 `cost`（功耗/性能比）并标记低效状态 |\n| `em_dev_compute_costs()` | 对外接口，用于运行时更新 EM 表的成本值 |\n| `em_debug_create_pd()` / `em_debug_remove_pd()` | 创建/移除 debugfs 调试节点（仅当 `CONFIG_DEBUG_FS` 启用） |\n| `_is_cpu_device()` | 判断设备是否为 CPU 子系统设备 |\n\n### 全局变量与机制\n\n- `em_pd_mutex`：互斥锁，用于串行化性能域注册和回调执行。\n- `em_update_work`：延迟工作队列，用于异步更新 EM（部分实现在其他文件）。\n- RCU + `kref` 机制：确保 EM 表在多读者场景下的安全释放。\n\n---\n\n## 3. 关键实现\n\n### 3.1 性能与成本计算\n\n- **性能值（`performance`）**：  \n  对于 CPU，通过线性映射计算：\n  ```\n  performance[i] = (arch_scale_cpu_capacity(cpu) * freq[i]) / max_freq\n  ```\n  其中 `arch_scale_cpu_capacity()` 返回 CPU 的最大计算能力（通常由调度器拓扑初始化）。\n\n- **成本值（`cost`）**：  \n  默认使用 `cost = (power * 10) / performance`，提高精度。  \n  若设备标记为 `EM_PERF_DOMAIN_ARTIFICIAL` 且提供 `get_cost` 回调，则使用驱动提供的成本值。\n\n- **低效状态标记**：  \n  从高频到低频遍历，若当前状态的 `cost` 不小于前一状态，则标记为 `EM_PERF_STATE_INEFFICIENT`，供 EAS 调度时避开。\n\n### 3.2 内存管理与生命周期\n\n- EM 表通过 `kref` 管理引用计数，确保在无使用者时才释放。\n- 释放通过 `call_rcu()` 异步执行，避免在 RCU 读侧临界区访问已释放内存。\n- `em_table_free()` 是唯一释放入口，保证线程安全。\n\n### 3.3 Debugfs 调试支持\n\n当启用 `CONFIG_DEBUG_FS` 时：\n- 在 `/sys/kernel/debug/energy_model/` 下为每个设备创建目录。\n- 每个性能状态（`ps:freq`）有独立子目录，包含 `frequency`、`power`、`cost`、`performance`、`inefficient` 等只读文件。\n- CPU 设备额外提供 `cpus` 文件，显示所属 CPU 掩码。\n\n---\n\n## 4. 依赖关系\n\n- **调度子系统**：依赖 `#include <linux/sched/topology.h>` 获取 CPU 拓扑和容量信息。\n- **CPUFreq 子系统**：通过 `#include <linux/cpufreq.h>` 与 OPP（Operating Performance Point）机制交互。\n- **设备模型**：使用 `cpu_subsys` 判断设备类型。\n- **内存管理**：使用 `kzalloc`、`devm_kcalloc` 等分配内存。\n- **同步机制**：依赖 `mutex`、`RCU` 和 `kref` 实现安全并发。\n- **调试支持**：可选依赖 `debugfs`。\n\n---\n\n## 5. 使用场景\n\n1. **EAS（Energy Aware Scheduling）**：  \n   调度器在任务迁移或唤醒时，查询目标 CPU 的 EM 表，选择能效最优的 CPU 和频率。\n\n2. **热插拔与 DVFS**：  \n   在 CPU 热插拔或频率切换时，EM 表提供功耗预测依据。\n\n3. **运行时 EM 更新**：  \n   通过 `em_dev_compute_costs()` 动态更新 EM 表（例如在 thermal 事件后调整 OPP）。\n\n4. **系统调试与验证**：  \n   开发者可通过 debugfs 检查 EM 数据是否符合预期，验证低效状态标记是否正确。\n\n5. **异构多核系统（如 big.LITTLE）**：  \n   不同 CPU 集群拥有独立 EM 表，EAS 利用这些信息实现大小核任务分配优化。",
      "similarity": 0.622313916683197,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 32,
          "end_line": 136,
          "content": [
            "static bool _is_cpu_device(struct device *dev)",
            "{",
            "\treturn (dev->bus == &cpu_subsys);",
            "}",
            "static void em_debug_create_ps(struct em_perf_domain *em_pd,",
            "\t\t\t       struct em_dbg_info *em_dbg, int i,",
            "\t\t\t       struct dentry *pd)",
            "{",
            "\tstruct em_perf_state *table;",
            "\tunsigned long freq;",
            "\tstruct dentry *d;",
            "\tchar name[24];",
            "",
            "\tem_dbg[i].pd = em_pd;",
            "\tem_dbg[i].ps_id = i;",
            "",
            "\trcu_read_lock();",
            "\ttable = em_perf_state_from_pd(em_pd);",
            "\tfreq = table[i].frequency;",
            "\trcu_read_unlock();",
            "",
            "\tsnprintf(name, sizeof(name), \"ps:%lu\", freq);",
            "",
            "\t/* Create per-ps directory */",
            "\td = debugfs_create_dir(name, pd);",
            "\tdebugfs_create_file(\"frequency\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_frequency_fops);",
            "\tdebugfs_create_file(\"power\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_power_fops);",
            "\tdebugfs_create_file(\"cost\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_cost_fops);",
            "\tdebugfs_create_file(\"performance\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_performance_fops);",
            "\tdebugfs_create_file(\"inefficient\", 0444, d, &em_dbg[i],",
            "\t\t\t    &em_debug_inefficiency_fops);",
            "}",
            "static int em_debug_cpus_show(struct seq_file *s, void *unused)",
            "{",
            "\tseq_printf(s, \"%*pbl\\n\", cpumask_pr_args(to_cpumask(s->private)));",
            "",
            "\treturn 0;",
            "}",
            "static int em_debug_flags_show(struct seq_file *s, void *unused)",
            "{",
            "\tstruct em_perf_domain *pd = s->private;",
            "",
            "\tseq_printf(s, \"%#lx\\n\", pd->flags);",
            "",
            "\treturn 0;",
            "}",
            "static void em_debug_create_pd(struct device *dev)",
            "{",
            "\tstruct em_dbg_info *em_dbg;",
            "\tstruct dentry *d;",
            "\tint i;",
            "",
            "\t/* Create the directory of the performance domain */",
            "\td = debugfs_create_dir(dev_name(dev), rootdir);",
            "",
            "\tif (_is_cpu_device(dev))",
            "\t\tdebugfs_create_file(\"cpus\", 0444, d, dev->em_pd->cpus,",
            "\t\t\t\t    &em_debug_cpus_fops);",
            "",
            "\tdebugfs_create_file(\"flags\", 0444, d, dev->em_pd,",
            "\t\t\t    &em_debug_flags_fops);",
            "",
            "\tem_dbg = devm_kcalloc(dev, dev->em_pd->nr_perf_states,",
            "\t\t\t      sizeof(*em_dbg), GFP_KERNEL);",
            "\tif (!em_dbg)",
            "\t\treturn;",
            "",
            "\t/* Create a sub-directory for each performance state */",
            "\tfor (i = 0; i < dev->em_pd->nr_perf_states; i++)",
            "\t\tem_debug_create_ps(dev->em_pd, em_dbg, i, d);",
            "",
            "}",
            "static void em_debug_remove_pd(struct device *dev)",
            "{",
            "\tdebugfs_lookup_and_remove(dev_name(dev), rootdir);",
            "}",
            "static int __init em_debug_init(void)",
            "{",
            "\t/* Create /sys/kernel/debug/energy_model directory */",
            "\trootdir = debugfs_create_dir(\"energy_model\", NULL);",
            "",
            "\treturn 0;",
            "}",
            "static void em_debug_create_pd(struct device *dev) {}",
            "static void em_debug_remove_pd(struct device *dev) {}",
            "static void em_destroy_table_rcu(struct rcu_head *rp)",
            "{",
            "\tstruct em_perf_table __rcu *table;",
            "",
            "\ttable = container_of(rp, struct em_perf_table, rcu);",
            "\tkfree(table);",
            "}",
            "static void em_release_table_kref(struct kref *kref)",
            "{",
            "\tstruct em_perf_table __rcu *table;",
            "",
            "\t/* It was the last owner of this table so we can free */",
            "\ttable = container_of(kref, struct em_perf_table, kref);",
            "",
            "\tcall_rcu(&table->rcu, em_destroy_table_rcu);",
            "}"
          ],
          "function_name": "_is_cpu_device, em_debug_create_ps, em_debug_cpus_show, em_debug_flags_show, em_debug_create_pd, em_debug_remove_pd, em_debug_init, em_debug_create_pd, em_debug_remove_pd, em_destroy_table_rcu, em_release_table_kref",
          "description": "包含调试接口实现，创建/删除性能域调试目录，暴露频率/功率/效率等信息，存在重复函数声明导致上下文不完整",
          "similarity": 0.5930259823799133
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 188,
          "end_line": 290,
          "content": [
            "void em_table_free(struct em_perf_table __rcu *table)",
            "{",
            "\tkref_put(&table->kref, em_release_table_kref);",
            "}",
            "static void em_init_performance(struct device *dev, struct em_perf_domain *pd,",
            "\t\t\t\tstruct em_perf_state *table, int nr_states)",
            "{",
            "\tu64 fmax, max_cap;",
            "\tint i, cpu;",
            "",
            "\t/* This is needed only for CPUs and EAS skip other devices */",
            "\tif (!_is_cpu_device(dev))",
            "\t\treturn;",
            "",
            "\tcpu = cpumask_first(em_span_cpus(pd));",
            "",
            "\t/*",
            "\t * Calculate the performance value for each frequency with",
            "\t * linear relationship. The final CPU capacity might not be ready at",
            "\t * boot time, but the EM will be updated a bit later with correct one.",
            "\t */",
            "\tfmax = (u64) table[nr_states - 1].frequency;",
            "\tmax_cap = (u64) arch_scale_cpu_capacity(cpu);",
            "\tfor (i = 0; i < nr_states; i++)",
            "\t\ttable[i].performance = div64_u64(max_cap * table[i].frequency,",
            "\t\t\t\t\t\t fmax);",
            "}",
            "static int em_compute_costs(struct device *dev, struct em_perf_state *table,",
            "\t\t\t    struct em_data_callback *cb, int nr_states,",
            "\t\t\t    unsigned long flags)",
            "{",
            "\tunsigned long prev_cost = ULONG_MAX;",
            "\tint i, ret;",
            "",
            "\t/* This is needed only for CPUs and EAS skip other devices */",
            "\tif (!_is_cpu_device(dev))",
            "\t\treturn 0;",
            "",
            "\t/* Compute the cost of each performance state. */",
            "\tfor (i = nr_states - 1; i >= 0; i--) {",
            "\t\tunsigned long power_res, cost;",
            "",
            "\t\tif ((flags & EM_PERF_DOMAIN_ARTIFICIAL) && cb->get_cost) {",
            "\t\t\tret = cb->get_cost(dev, table[i].frequency, &cost);",
            "\t\t\tif (ret || !cost || cost > EM_MAX_POWER) {",
            "\t\t\t\tdev_err(dev, \"EM: invalid cost %lu %d\\n\",",
            "\t\t\t\t\tcost, ret);",
            "\t\t\t\treturn -EINVAL;",
            "\t\t\t}",
            "\t\t} else {",
            "\t\t\t/* increase resolution of 'cost' precision */",
            "\t\t\tpower_res = table[i].power * 10;",
            "\t\t\tcost = power_res / table[i].performance;",
            "\t\t}",
            "",
            "\t\ttable[i].cost = cost;",
            "",
            "\t\tif (table[i].cost >= prev_cost) {",
            "\t\t\ttable[i].flags = EM_PERF_STATE_INEFFICIENT;",
            "\t\t\tdev_dbg(dev, \"EM: OPP:%lu is inefficient\\n\",",
            "\t\t\t\ttable[i].frequency);",
            "\t\t} else {",
            "\t\t\tprev_cost = table[i].cost;",
            "\t\t}",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int em_dev_compute_costs(struct device *dev, struct em_perf_state *table,",
            "\t\t\t int nr_states)",
            "{",
            "\treturn em_compute_costs(dev, table, NULL, nr_states, 0);",
            "}",
            "int em_dev_update_perf_domain(struct device *dev,",
            "\t\t\t      struct em_perf_table __rcu *new_table)",
            "{",
            "\tstruct em_perf_table __rcu *old_table;",
            "\tstruct em_perf_domain *pd;",
            "",
            "\tif (!dev)",
            "\t\treturn -EINVAL;",
            "",
            "\t/* Serialize update/unregister or concurrent updates */",
            "\tmutex_lock(&em_pd_mutex);",
            "",
            "\tif (!dev->em_pd) {",
            "\t\tmutex_unlock(&em_pd_mutex);",
            "\t\treturn -EINVAL;",
            "\t}",
            "\tpd = dev->em_pd;",
            "",
            "\tkref_get(&new_table->kref);",
            "",
            "\told_table = pd->em_table;",
            "\trcu_assign_pointer(pd->em_table, new_table);",
            "",
            "\tem_cpufreq_update_efficiencies(dev, new_table->state);",
            "",
            "\tem_table_free(old_table);",
            "",
            "\tmutex_unlock(&em_pd_mutex);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "em_table_free, em_init_performance, em_compute_costs, em_dev_compute_costs, em_dev_update_perf_domain",
          "description": "实现性能状态计算逻辑，初始化性能值、计算功耗成本、标记低效状态，更新性能域表结构",
          "similarity": 0.5888972282409668
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 645,
          "end_line": 772,
          "content": [
            "void em_dev_unregister_perf_domain(struct device *dev)",
            "{",
            "\tif (IS_ERR_OR_NULL(dev) || !dev->em_pd)",
            "\t\treturn;",
            "",
            "\tif (_is_cpu_device(dev))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * The mutex separates all register/unregister requests and protects",
            "\t * from potential clean-up/setup issues in the debugfs directories.",
            "\t * The debugfs directory name is the same as device's name.",
            "\t */",
            "\tmutex_lock(&em_pd_mutex);",
            "\tem_debug_remove_pd(dev);",
            "",
            "\tem_table_free(dev->em_pd->em_table);",
            "",
            "\tkfree(dev->em_pd);",
            "\tdev->em_pd = NULL;",
            "\tmutex_unlock(&em_pd_mutex);",
            "}",
            "static void em_adjust_new_capacity(struct device *dev,",
            "\t\t\t\t   struct em_perf_domain *pd,",
            "\t\t\t\t   u64 max_cap)",
            "{",
            "\tstruct em_perf_table __rcu *em_table;",
            "\tstruct em_perf_state *ps, *new_ps;",
            "\tint ret, ps_size;",
            "",
            "\tem_table = em_table_alloc(pd);",
            "\tif (!em_table) {",
            "\t\tdev_warn(dev, \"EM: allocation failed\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tnew_ps = em_table->state;",
            "",
            "\trcu_read_lock();",
            "\tps = em_perf_state_from_pd(pd);",
            "\t/* Initialize data based on old table */",
            "\tps_size = sizeof(struct em_perf_state) * pd->nr_perf_states;",
            "\tmemcpy(new_ps, ps, ps_size);",
            "",
            "\trcu_read_unlock();",
            "",
            "\tem_init_performance(dev, pd, new_ps, pd->nr_perf_states);",
            "\tret = em_compute_costs(dev, new_ps, NULL, pd->nr_perf_states,",
            "\t\t\t       pd->flags);",
            "\tif (ret) {",
            "\t\tdev_warn(dev, \"EM: compute costs failed\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tret = em_dev_update_perf_domain(dev, em_table);",
            "\tif (ret)",
            "\t\tdev_warn(dev, \"EM: update failed %d\\n\", ret);",
            "",
            "\t/*",
            "\t * This is one-time-update, so give up the ownership in this updater.",
            "\t * The EM framework has incremented the usage counter and from now",
            "\t * will keep the reference (then free the memory when needed).",
            "\t */",
            "\tem_table_free(em_table);",
            "}",
            "static void em_check_capacity_update(void)",
            "{",
            "\tcpumask_var_t cpu_done_mask;",
            "\tstruct em_perf_state *table;",
            "\tstruct em_perf_domain *pd;",
            "\tunsigned long cpu_capacity;",
            "\tint cpu;",
            "",
            "\tif (!zalloc_cpumask_var(&cpu_done_mask, GFP_KERNEL)) {",
            "\t\tpr_warn(\"no free memory\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* Check if CPUs capacity has changed than update EM */",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tstruct cpufreq_policy *policy;",
            "\t\tunsigned long em_max_perf;",
            "\t\tstruct device *dev;",
            "\t\tint nr_states;",
            "",
            "\t\tif (cpumask_test_cpu(cpu, cpu_done_mask))",
            "\t\t\tcontinue;",
            "",
            "\t\tpolicy = cpufreq_cpu_get(cpu);",
            "\t\tif (!policy) {",
            "\t\t\tpr_debug(\"Accessing cpu%d policy failed\\n\", cpu);",
            "\t\t\tschedule_delayed_work(&em_update_work,",
            "\t\t\t\t\t      msecs_to_jiffies(1000));",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tcpufreq_cpu_put(policy);",
            "",
            "\t\tpd = em_cpu_get(cpu);",
            "\t\tif (!pd || em_is_artificial(pd))",
            "\t\t\tcontinue;",
            "",
            "\t\tcpumask_or(cpu_done_mask, cpu_done_mask,",
            "\t\t\t   em_span_cpus(pd));",
            "",
            "\t\tnr_states = pd->nr_perf_states;",
            "\t\tcpu_capacity = arch_scale_cpu_capacity(cpu);",
            "",
            "\t\trcu_read_lock();",
            "\t\ttable = em_perf_state_from_pd(pd);",
            "\t\tem_max_perf = table[pd->nr_perf_states - 1].performance;",
            "\t\trcu_read_unlock();",
            "",
            "\t\t/*",
            "\t\t * Check if the CPU capacity has been adjusted during boot",
            "\t\t * and trigger the update for new performance values.",
            "\t\t */",
            "\t\tif (em_max_perf == cpu_capacity)",
            "\t\t\tcontinue;",
            "",
            "\t\tpr_debug(\"updating cpu%d cpu_cap=%lu old capacity=%lu\\n\",",
            "\t\t\t cpu, cpu_capacity, em_max_perf);",
            "",
            "\t\tdev = get_cpu_device(cpu);",
            "\t\tem_adjust_new_capacity(dev, pd, cpu_capacity);",
            "\t}",
            "",
            "\tfree_cpumask_var(cpu_done_mask);",
            "}"
          ],
          "function_name": "em_dev_unregister_perf_domain, em_adjust_new_capacity, em_check_capacity_update",
          "description": "实现性能域注销逻辑，释放关联资源并清理debugfs目录；通过调整新容量重新初始化性能状态表并更新能耗模型；监控CPU容量变化以动态更新性能状态",
          "similarity": 0.5848339796066284
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 345,
          "end_line": 456,
          "content": [
            "static int em_create_perf_table(struct device *dev, struct em_perf_domain *pd,",
            "\t\t\t\tstruct em_perf_state *table,",
            "\t\t\t\tstruct em_data_callback *cb,",
            "\t\t\t\tunsigned long flags)",
            "{",
            "\tunsigned long power, freq, prev_freq = 0;",
            "\tint nr_states = pd->nr_perf_states;",
            "\tint i, ret;",
            "",
            "\t/* Build the list of performance states for this performance domain */",
            "\tfor (i = 0, freq = 0; i < nr_states; i++, freq++) {",
            "\t\t/*",
            "\t\t * active_power() is a driver callback which ceils 'freq' to",
            "\t\t * lowest performance state of 'dev' above 'freq' and updates",
            "\t\t * 'power' and 'freq' accordingly.",
            "\t\t */",
            "\t\tret = cb->active_power(dev, &power, &freq);",
            "\t\tif (ret) {",
            "\t\t\tdev_err(dev, \"EM: invalid perf. state: %d\\n\",",
            "\t\t\t\tret);",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * We expect the driver callback to increase the frequency for",
            "\t\t * higher performance states.",
            "\t\t */",
            "\t\tif (freq <= prev_freq) {",
            "\t\t\tdev_err(dev, \"EM: non-increasing freq: %lu\\n\",",
            "\t\t\t\tfreq);",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * The power returned by active_state() is expected to be",
            "\t\t * positive and be in range.",
            "\t\t */",
            "\t\tif (!power || power > EM_MAX_POWER) {",
            "\t\t\tdev_err(dev, \"EM: invalid power: %lu\\n\",",
            "\t\t\t\tpower);",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\ttable[i].power = power;",
            "\t\ttable[i].frequency = prev_freq = freq;",
            "\t}",
            "",
            "\tem_init_performance(dev, pd, table, nr_states);",
            "",
            "\tret = em_compute_costs(dev, table, cb, nr_states, flags);",
            "\tif (ret)",
            "\t\treturn -EINVAL;",
            "",
            "\treturn 0;",
            "}",
            "static int em_create_pd(struct device *dev, int nr_states,",
            "\t\t\tstruct em_data_callback *cb, cpumask_t *cpus,",
            "\t\t\tunsigned long flags)",
            "{",
            "\tstruct em_perf_table __rcu *em_table;",
            "\tstruct em_perf_domain *pd;",
            "\tstruct device *cpu_dev;",
            "\tint cpu, ret, num_cpus;",
            "",
            "\tif (_is_cpu_device(dev)) {",
            "\t\tnum_cpus = cpumask_weight(cpus);",
            "",
            "\t\t/* Prevent max possible energy calculation to not overflow */",
            "\t\tif (num_cpus > EM_MAX_NUM_CPUS) {",
            "\t\t\tdev_err(dev, \"EM: too many CPUs, overflow possible\\n\");",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\tpd = kzalloc(sizeof(*pd) + cpumask_size(), GFP_KERNEL);",
            "\t\tif (!pd)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\t\tcpumask_copy(em_span_cpus(pd), cpus);",
            "\t} else {",
            "\t\tpd = kzalloc(sizeof(*pd), GFP_KERNEL);",
            "\t\tif (!pd)",
            "\t\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\tpd->nr_perf_states = nr_states;",
            "",
            "\tem_table = em_table_alloc(pd);",
            "\tif (!em_table)",
            "\t\tgoto free_pd;",
            "",
            "\tret = em_create_perf_table(dev, pd, em_table->state, cb, flags);",
            "\tif (ret)",
            "\t\tgoto free_pd_table;",
            "",
            "\trcu_assign_pointer(pd->em_table, em_table);",
            "",
            "\tif (_is_cpu_device(dev))",
            "\t\tfor_each_cpu(cpu, cpus) {",
            "\t\t\tcpu_dev = get_cpu_device(cpu);",
            "\t\t\tcpu_dev->em_pd = pd;",
            "\t\t}",
            "",
            "\tdev->em_pd = pd;",
            "",
            "\treturn 0;",
            "",
            "free_pd_table:",
            "\tkfree(em_table);",
            "free_pd:",
            "\tkfree(pd);",
            "\treturn -EINVAL;",
            "}"
          ],
          "function_name": "em_create_perf_table, em_create_pd",
          "description": "创建性能表和性能域结构，验证CPU容量一致性，分配资源并建立设备与性能域的关联",
          "similarity": 0.5713986158370972
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/power/energy_model.c",
          "start_line": 459,
          "end_line": 577,
          "content": [
            "static void",
            "em_cpufreq_update_efficiencies(struct device *dev, struct em_perf_state *table)",
            "{",
            "\tstruct em_perf_domain *pd = dev->em_pd;",
            "\tstruct cpufreq_policy *policy;",
            "\tint found = 0;",
            "\tint i, cpu;",
            "",
            "\tif (!_is_cpu_device(dev))",
            "\t\treturn;",
            "",
            "\t/* Try to get a CPU which is active and in this PD */",
            "\tcpu = cpumask_first_and(em_span_cpus(pd), cpu_active_mask);",
            "\tif (cpu >= nr_cpu_ids) {",
            "\t\tdev_warn(dev, \"EM: No online CPU for CPUFreq policy\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tpolicy = cpufreq_cpu_get(cpu);",
            "\tif (!policy) {",
            "\t\tdev_warn(dev, \"EM: Access to CPUFreq policy failed\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tfor (i = 0; i < pd->nr_perf_states; i++) {",
            "\t\tif (!(table[i].flags & EM_PERF_STATE_INEFFICIENT))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (!cpufreq_table_set_inefficient(policy, table[i].frequency))",
            "\t\t\tfound++;",
            "\t}",
            "",
            "\tcpufreq_cpu_put(policy);",
            "",
            "\tif (!found)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Efficiencies have been installed in CPUFreq, inefficient frequencies",
            "\t * will be skipped. The EM can do the same.",
            "\t */",
            "\tpd->flags |= EM_PERF_DOMAIN_SKIP_INEFFICIENCIES;",
            "}",
            "int em_dev_register_perf_domain(struct device *dev, unsigned int nr_states,",
            "\t\t\t\tstruct em_data_callback *cb, cpumask_t *cpus,",
            "\t\t\t\tbool microwatts)",
            "{",
            "\tunsigned long cap, prev_cap = 0;",
            "\tunsigned long flags = 0;",
            "\tint cpu, ret;",
            "",
            "\tif (!dev || !nr_states || !cb)",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * Use a mutex to serialize the registration of performance domains and",
            "\t * let the driver-defined callback functions sleep.",
            "\t */",
            "\tmutex_lock(&em_pd_mutex);",
            "",
            "\tif (dev->em_pd) {",
            "\t\tret = -EEXIST;",
            "\t\tgoto unlock;",
            "\t}",
            "",
            "\tif (_is_cpu_device(dev)) {",
            "\t\tif (!cpus) {",
            "\t\t\tdev_err(dev, \"EM: invalid CPU mask\\n\");",
            "\t\t\tret = -EINVAL;",
            "\t\t\tgoto unlock;",
            "\t\t}",
            "",
            "\t\tfor_each_cpu(cpu, cpus) {",
            "\t\t\tif (em_cpu_get(cpu)) {",
            "\t\t\t\tdev_err(dev, \"EM: exists for CPU%d\\n\", cpu);",
            "\t\t\t\tret = -EEXIST;",
            "\t\t\t\tgoto unlock;",
            "\t\t\t}",
            "\t\t\t/*",
            "\t\t\t * All CPUs of a domain must have the same",
            "\t\t\t * micro-architecture since they all share the same",
            "\t\t\t * table.",
            "\t\t\t */",
            "\t\t\tcap = arch_scale_cpu_capacity(cpu);",
            "\t\t\tif (prev_cap && prev_cap != cap) {",
            "\t\t\t\tdev_err(dev, \"EM: CPUs of %*pbl must have the same capacity\\n\",",
            "\t\t\t\t\tcpumask_pr_args(cpus));",
            "",
            "\t\t\t\tret = -EINVAL;",
            "\t\t\t\tgoto unlock;",
            "\t\t\t}",
            "\t\t\tprev_cap = cap;",
            "\t\t}",
            "\t}",
            "",
            "\tif (microwatts)",
            "\t\tflags |= EM_PERF_DOMAIN_MICROWATTS;",
            "\telse if (cb->get_cost)",
            "\t\tflags |= EM_PERF_DOMAIN_ARTIFICIAL;",
            "",
            "\tret = em_create_pd(dev, nr_states, cb, cpus, flags);",
            "\tif (ret)",
            "\t\tgoto unlock;",
            "",
            "\tdev->em_pd->flags |= flags;",
            "",
            "\tem_cpufreq_update_efficiencies(dev, dev->em_pd->em_table->state);",
            "",
            "\tem_debug_create_pd(dev);",
            "\tdev_info(dev, \"EM: created perf domain\\n\");",
            "",
            "unlock:",
            "\tmutex_unlock(&em_pd_mutex);",
            "",
            "\tif (_is_cpu_device(dev))",
            "\t\tem_check_capacity_update();",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "em_cpufreq_update_efficiencies, em_dev_register_perf_domain",
          "description": "注册性能域主流程，集成CPUFreq标记低效频率，处理CPU容量更新，确保并发访问安全",
          "similarity": 0.5610518455505371
        }
      ]
    }
  ]
}