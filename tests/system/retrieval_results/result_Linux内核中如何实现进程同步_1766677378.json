{
  "query": "Linux内核中如何实现进程同步",
  "timestamp": "2025-12-25 23:42:58",
  "retrieved_files": [
    {
      "source_file": "kernel/async.c",
      "md_summary": "> 自动生成时间: 2025-10-25 11:49:14\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `async.c`\n\n---\n\n# async.c 技术文档\n\n## 1. 文件概述\n\n`async.c` 实现了 Linux 内核中的异步函数调用机制，主要用于优化系统启动性能。该机制允许在内核初始化阶段将原本串行执行的、相互独立的硬件探测和初始化操作并行化，从而显著缩短启动时间。其核心思想是在保持对外可见操作顺序一致性的前提下，内部执行过程可乱序进行，类似于乱序执行 CPU 的“按序提交”语义。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct async_entry`**：表示一个异步任务条目，包含：\n  - `domain_list` / `global_list`：分别链接到所属域和全局的待处理链表\n  - `work`：关联的 workqueue 工作项\n  - `cookie`：序列号，用于同步控制\n  - `func` / `data`：要执行的函数及其参数\n  - `domain`：所属的异步域\n\n- **`struct async_domain`**：异步执行域，用于将异步任务分组管理，默认使用 `async_dfl_domain`\n\n- **全局变量**：\n  - `next_cookie`：单调递增的序列号生成器\n  - `async_global_pending`：所有已注册域的全局待处理任务链表\n  - `async_dfl_domain`：默认异步域\n  - `async_lock`：保护异步任务队列的自旋锁\n  - `entry_count`：当前挂起的异步任务计数\n\n### 主要函数\n\n- **`async_schedule_node_domain()`**：在指定 NUMA 节点和异步域中调度异步函数\n- **`async_schedule_node()`**：在指定 NUMA 节点上调度异步函数（使用默认域）\n- **`async_schedule_dev_nocall()`**：基于设备的 NUMA 信息调度异步函数（失败时不回退到同步执行）\n- **`lowest_in_progress()`**：获取指定域或全局中最早（最小 cookie）的未完成任务\n- **`async_run_entry_fn()`**：workqueue 回调函数，实际执行异步任务并清理资源\n\n## 3. 关键实现\n\n### 序列 Cookie 机制\n- 每个异步任务分配一个单调递增的 `async_cookie_t`（64 位无符号整数）\n- 任务执行前可通过 `async_synchronize_cookie()` 等待所有小于等于指定 cookie 的任务完成\n- 保证对外部可见操作（如设备注册）的顺序一致性\n\n### 内存与负载控制\n- 使用 `GFP_ATOMIC` 分配内存，支持原子上下文调用\n- 当内存不足或挂起任务超过 `MAX_WORK`（32768）时，自动回退到同步执行\n- 通过 `entry_count` 原子计数器跟踪挂起任务数量\n\n### 双链表管理\n- 每个任务同时链接到：\n  - 所属域的 `domain->pending` 链表（按 cookie 顺序）\n  - 全局 `async_global_pending` 链表（仅当域已注册）\n- 保证域内和全局的同步操作都能正确等待\n\n### NUMA 感知调度\n- 通过 `queue_work_node()` 将任务调度到指定 NUMA 节点\n- 若节点无效则自动分发到可用 CPU\n\n### 资源清理与通知\n- 任务执行完成后从链表移除并释放内存\n- 通过 `wake_up(&async_done)` 唤醒等待同步完成的线程\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/async.h>`：异步 API 定义\n  - `<linux/workqueue.h>`：工作队列机制\n  - `\"workqueue_internal.h\"`：内部 workqueue 接口\n  - 其他基础内核头文件（atomic、slab、wait 等）\n\n- **核心子系统**：\n  - **Workqueue 子系统**：实际执行异步任务的底层机制\n  - **内存管理子系统**：任务结构体内存分配\n  - **调度器**：NUMA 节点感知的任务调度\n\n- **导出符号**：\n  - `async_schedule_node_domain`\n  - `async_schedule_node`\n\n## 5. 使用场景\n\n- **内核启动优化**：\n  - 并行执行设备探测（如 PCI、USB 控制器初始化）\n  - 异步加载固件或执行硬件自检\n\n- **驱动初始化**：\n  - 驱动可将耗时的初始化操作（如 PHY 配置、固件加载）放入异步任务\n  - 通过 `async_synchronize_full()` 确保在模块初始化完成前所有异步任务结束\n\n- **NUMA 优化**：\n  - 将设备相关的初始化任务调度到设备所在 NUMA 节点，减少远程内存访问\n\n- **资源受限环境**：\n  - 在内存压力下自动回退到同步执行，保证系统稳定性\n  - 通过 `MAX_WORK` 限制防止异步任务无限堆积",
      "similarity": 0.6868137121200562,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/async.c",
          "start_line": 241,
          "end_line": 290,
          "content": [
            "async_cookie_t async_schedule_node(async_func_t func, void *data, int node)",
            "{",
            "\treturn async_schedule_node_domain(func, data, node, &async_dfl_domain);",
            "}",
            "bool async_schedule_dev_nocall(async_func_t func, struct device *dev)",
            "{",
            "\tstruct async_entry *entry;",
            "",
            "\tentry = kzalloc(sizeof(struct async_entry), GFP_KERNEL);",
            "",
            "\t/* Give up if there is no memory or too much work. */",
            "\tif (!entry || atomic_read(&entry_count) > MAX_WORK) {",
            "\t\tkfree(entry);",
            "\t\treturn false;",
            "\t}",
            "",
            "\t__async_schedule_node_domain(func, dev, dev_to_node(dev),",
            "\t\t\t\t     &async_dfl_domain, entry);",
            "\treturn true;",
            "}",
            "void async_synchronize_full(void)",
            "{",
            "\tasync_synchronize_full_domain(NULL);",
            "}",
            "void async_synchronize_full_domain(struct async_domain *domain)",
            "{",
            "\tasync_synchronize_cookie_domain(ASYNC_COOKIE_MAX, domain);",
            "}",
            "void async_synchronize_cookie_domain(async_cookie_t cookie, struct async_domain *domain)",
            "{",
            "\tktime_t starttime;",
            "",
            "\tpr_debug(\"async_waiting @ %i\\n\", task_pid_nr(current));",
            "\tstarttime = ktime_get();",
            "",
            "\twait_event(async_done, lowest_in_progress(domain) >= cookie);",
            "",
            "\tpr_debug(\"async_continuing @ %i after %lli usec\\n\", task_pid_nr(current),",
            "\t\t microseconds_since(starttime));",
            "}",
            "void async_synchronize_cookie(async_cookie_t cookie)",
            "{",
            "\tasync_synchronize_cookie_domain(cookie, &async_dfl_domain);",
            "}",
            "bool current_is_async(void)",
            "{",
            "\tstruct worker *worker = current_wq_worker();",
            "",
            "\treturn worker && worker->current_func == async_run_entry_fn;",
            "}"
          ],
          "function_name": "async_schedule_node, async_schedule_dev_nocall, async_synchronize_full, async_synchronize_full_domain, async_synchronize_cookie_domain, async_synchronize_cookie, current_is_async",
          "description": "提供同步屏障接口和运行态检测，确保异步操作有序完成",
          "similarity": 0.6242072582244873
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/async.c",
          "start_line": 82,
          "end_line": 201,
          "content": [
            "static long long microseconds_since(ktime_t start)",
            "{",
            "\tktime_t now = ktime_get();",
            "\treturn ktime_to_ns(ktime_sub(now, start)) >> 10;",
            "}",
            "static async_cookie_t lowest_in_progress(struct async_domain *domain)",
            "{",
            "\tstruct async_entry *first = NULL;",
            "\tasync_cookie_t ret = ASYNC_COOKIE_MAX;",
            "\tunsigned long flags;",
            "",
            "\tspin_lock_irqsave(&async_lock, flags);",
            "",
            "\tif (domain) {",
            "\t\tif (!list_empty(&domain->pending))",
            "\t\t\tfirst = list_first_entry(&domain->pending,",
            "\t\t\t\t\tstruct async_entry, domain_list);",
            "\t} else {",
            "\t\tif (!list_empty(&async_global_pending))",
            "\t\t\tfirst = list_first_entry(&async_global_pending,",
            "\t\t\t\t\tstruct async_entry, global_list);",
            "\t}",
            "",
            "\tif (first)",
            "\t\tret = first->cookie;",
            "",
            "\tspin_unlock_irqrestore(&async_lock, flags);",
            "\treturn ret;",
            "}",
            "static void async_run_entry_fn(struct work_struct *work)",
            "{",
            "\tstruct async_entry *entry =",
            "\t\tcontainer_of(work, struct async_entry, work);",
            "\tunsigned long flags;",
            "\tktime_t calltime;",
            "",
            "\t/* 1) run (and print duration) */",
            "\tpr_debug(\"calling  %lli_%pS @ %i\\n\", (long long)entry->cookie,",
            "\t\t entry->func, task_pid_nr(current));",
            "\tcalltime = ktime_get();",
            "",
            "\tentry->func(entry->data, entry->cookie);",
            "",
            "\tpr_debug(\"initcall %lli_%pS returned after %lld usecs\\n\",",
            "\t\t (long long)entry->cookie, entry->func,",
            "\t\t microseconds_since(calltime));",
            "",
            "\t/* 2) remove self from the pending queues */",
            "\tspin_lock_irqsave(&async_lock, flags);",
            "\tlist_del_init(&entry->domain_list);",
            "\tlist_del_init(&entry->global_list);",
            "",
            "\t/* 3) free the entry */",
            "\tkfree(entry);",
            "\tatomic_dec(&entry_count);",
            "",
            "\tspin_unlock_irqrestore(&async_lock, flags);",
            "",
            "\t/* 4) wake up any waiters */",
            "\twake_up(&async_done);",
            "}",
            "static async_cookie_t __async_schedule_node_domain(async_func_t func,",
            "\t\t\t\t\t\t   void *data, int node,",
            "\t\t\t\t\t\t   struct async_domain *domain,",
            "\t\t\t\t\t\t   struct async_entry *entry)",
            "{",
            "\tasync_cookie_t newcookie;",
            "\tunsigned long flags;",
            "",
            "\tINIT_LIST_HEAD(&entry->domain_list);",
            "\tINIT_LIST_HEAD(&entry->global_list);",
            "\tINIT_WORK(&entry->work, async_run_entry_fn);",
            "\tentry->func = func;",
            "\tentry->data = data;",
            "\tentry->domain = domain;",
            "",
            "\tspin_lock_irqsave(&async_lock, flags);",
            "",
            "\t/* allocate cookie and queue */",
            "\tnewcookie = entry->cookie = next_cookie++;",
            "",
            "\tlist_add_tail(&entry->domain_list, &domain->pending);",
            "\tif (domain->registered)",
            "\t\tlist_add_tail(&entry->global_list, &async_global_pending);",
            "",
            "\tatomic_inc(&entry_count);",
            "\tspin_unlock_irqrestore(&async_lock, flags);",
            "",
            "\t/* schedule for execution */",
            "\tqueue_work_node(node, system_unbound_wq, &entry->work);",
            "",
            "\treturn newcookie;",
            "}",
            "async_cookie_t async_schedule_node_domain(async_func_t func, void *data,",
            "\t\t\t\t\t  int node, struct async_domain *domain)",
            "{",
            "\tstruct async_entry *entry;",
            "\tunsigned long flags;",
            "\tasync_cookie_t newcookie;",
            "",
            "\t/* allow irq-off callers */",
            "\tentry = kzalloc(sizeof(struct async_entry), GFP_ATOMIC);",
            "",
            "\t/*",
            "\t * If we're out of memory or if there's too much work",
            "\t * pending already, we execute synchronously.",
            "\t */",
            "\tif (!entry || atomic_read(&entry_count) > MAX_WORK) {",
            "\t\tkfree(entry);",
            "\t\tspin_lock_irqsave(&async_lock, flags);",
            "\t\tnewcookie = next_cookie++;",
            "\t\tspin_unlock_irqrestore(&async_lock, flags);",
            "",
            "\t\t/* low on memory.. run synchronously */",
            "\t\tfunc(data, newcookie);",
            "\t\treturn newcookie;",
            "\t}",
            "",
            "\treturn __async_schedule_node_domain(func, data, node, domain, entry);",
            "}"
          ],
          "function_name": "microseconds_since, lowest_in_progress, async_run_entry_fn, __async_schedule_node_domain, async_schedule_node_domain",
          "description": "实现异步任务调度与执行逻辑，包含时间测量、任务排队及工作队列调度",
          "similarity": 0.5964896082878113
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/async.c",
          "start_line": 1,
          "end_line": 81,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * async.c: Asynchronous function calls for boot performance",
            " *",
            " * (C) Copyright 2009 Intel Corporation",
            " * Author: Arjan van de Ven <arjan@linux.intel.com>",
            " */",
            "",
            "",
            "/*",
            "",
            "Goals and Theory of Operation",
            "",
            "The primary goal of this feature is to reduce the kernel boot time,",
            "by doing various independent hardware delays and discovery operations",
            "decoupled and not strictly serialized.",
            "",
            "More specifically, the asynchronous function call concept allows",
            "certain operations (primarily during system boot) to happen",
            "asynchronously, out of order, while these operations still",
            "have their externally visible parts happen sequentially and in-order.",
            "(not unlike how out-of-order CPUs retire their instructions in order)",
            "",
            "Key to the asynchronous function call implementation is the concept of",
            "a \"sequence cookie\" (which, although it has an abstracted type, can be",
            "thought of as a monotonically incrementing number).",
            "",
            "The async core will assign each scheduled event such a sequence cookie and",
            "pass this to the called functions.",
            "",
            "The asynchronously called function should before doing a globally visible",
            "operation, such as registering device numbers, call the",
            "async_synchronize_cookie() function and pass in its own cookie. The",
            "async_synchronize_cookie() function will make sure that all asynchronous",
            "operations that were scheduled prior to the operation corresponding with the",
            "cookie have completed.",
            "",
            "Subsystem/driver initialization code that scheduled asynchronous probe",
            "functions, but which shares global resources with other drivers/subsystems",
            "that do not use the asynchronous call feature, need to do a full",
            "synchronization with the async_synchronize_full() function, before returning",
            "from their init function. This is to maintain strict ordering between the",
            "asynchronous and synchronous parts of the kernel.",
            "",
            "*/",
            "",
            "#include <linux/async.h>",
            "#include <linux/atomic.h>",
            "#include <linux/export.h>",
            "#include <linux/ktime.h>",
            "#include <linux/pid.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/wait.h>",
            "#include <linux/workqueue.h>",
            "",
            "#include \"workqueue_internal.h\"",
            "",
            "static async_cookie_t next_cookie = 1;",
            "",
            "#define MAX_WORK\t\t32768",
            "#define ASYNC_COOKIE_MAX\tULLONG_MAX\t/* infinity cookie */",
            "",
            "static LIST_HEAD(async_global_pending);\t/* pending from all registered doms */",
            "static ASYNC_DOMAIN(async_dfl_domain);",
            "static DEFINE_SPINLOCK(async_lock);",
            "",
            "struct async_entry {",
            "\tstruct list_head\tdomain_list;",
            "\tstruct list_head\tglobal_list;",
            "\tstruct work_struct\twork;",
            "\tasync_cookie_t\t\tcookie;",
            "\tasync_func_t\t\tfunc;",
            "\tvoid\t\t\t*data;",
            "\tstruct async_domain\t*domain;",
            "};",
            "",
            "static DECLARE_WAIT_QUEUE_HEAD(async_done);",
            "",
            "static atomic_t entry_count;",
            ""
          ],
          "function_name": null,
          "description": "定义异步任务结构体和核心变量，支持多域异步调度",
          "similarity": 0.5320922136306763
        }
      ]
    },
    {
      "source_file": "kernel/fork.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:30:07\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `fork.c`\n\n---\n\n# fork.c 技术文档\n\n## 1. 文件概述\n\n`fork.c` 是 Linux 内核中实现进程创建（fork）系统调用的核心源文件。该文件包含了创建新进程所需的所有辅助例程，负责复制父进程的资源（如内存、文件描述符、信号处理等）以生成子进程。虽然 fork 逻辑本身概念简单，但其涉及的内存管理（尤其是写时复制 COW 机制）极为复杂，实际内存页的复制由 `mm/memory.c` 中的 `copy_page_range()` 等函数处理。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `total_forks`: 累计系统自启动以来创建的进程总数\n- `nr_threads`: 当前系统中的线程总数（不包括 idle 线程）\n- `max_threads`: 可配置的线程数量上限（默认为 `FUTEX_TID_MASK`）\n- `process_counts`: 每 CPU 的进程计数器（per-CPU 变量）\n- `tasklist_lock`: 保护任务链表的读写锁（全局任务列表的同步原语）\n\n### 关键辅助函数\n- `nr_processes()`: 计算系统中所有进程的总数（聚合各 CPU 的 `process_counts`）\n- `arch_release_task_struct()`: 架构相关的 task_struct 释放钩子（弱符号，默认为空）\n- `alloc_task_struct_node()` / `free_task_struct()`: 分配/释放 `task_struct` 结构（基于 slab 分配器）\n- `alloc_thread_stack_node()` / `thread_stack_delayed_free()`: 分配/延迟释放线程内核栈（支持 `CONFIG_VMAP_STACK`）\n\n### 核心数据结构\n- `resident_page_types[]`: 用于内存统计的页面类型名称映射数组\n- `vm_stack`: 用于 RCU 延迟释放的虚拟内存栈封装结构\n- `cached_stacks[NR_CACHED_STACKS]`: 每 CPU 的内核栈缓存（减少频繁 vmalloc/vfree 开销）\n\n## 3. 关键实现\n\n### 进程/线程计数管理\n- 使用 per-CPU 变量 `process_counts` 避免全局锁竞争\n- 全局计数器 `nr_threads` 和 `total_forks` 由 `tasklist_lock` 保护\n- `nr_processes()` 通过遍历所有可能的 CPU 聚合计数\n\n### 内核栈分配策略（`CONFIG_VMAP_STACK`）\n- **缓存机制**：每个 CPU 缓存最多 2 个已释放的栈（`NR_CACHED_STACKS`），减少 TLB 刷新和 vmalloc 开销\n- **内存分配**：\n  - 优先从本地缓存获取栈\n  - 缓存未命中时使用 `__vmalloc_node_range()` 分配连续虚拟地址空间\n  - 显式禁用 `__GFP_ACCOUNT`（因后续手动进行 memcg 计费）\n- **安全清理**：\n  - 重用栈时清零内存（`memset(stack, 0, THREAD_SIZE)`）\n  - KASAN 消毒（`kasan_unpoison_range`）和标签重置\n- **延迟释放**：\n  - 通过 RCU 机制延迟释放栈（`call_rcu`）\n  - 释放时尝试回填缓存，失败则直接 `vfree`\n\n### 内存控制组（memcg）集成\n- 手动对栈的每个物理页进行 memcg 计费（`memcg_kmem_charge_page`）\n- 计费失败时回滚已计费页面（`memcg_kmem_uncharge_page`）\n- 确保内核栈内存纳入 cgroup 内存限制\n\n### 锁与同步\n- `tasklist_lock` 作为全局任务列表的保护锁（读写锁）\n- 提供 `lockdep_tasklist_lock_is_held()` 供 RCU 锁验证使用\n- RCU 用于安全延迟释放内核栈资源\n\n## 4. 依赖关系\n\n### 内核子系统依赖\n- **内存管理 (MM)**：`<linux/mm.h>`, `<linux/vmalloc.h>`, `<linux/memcontrol.h>`\n- **调度器 (Scheduler)**：`<linux/sched/*.h>`, 任务状态和 CPU 绑定\n- **安全模块**：`<linux/security.h>`, `<linux/capability.h>`, `<linux/seccomp.h>`\n- **命名空间**：`<linux/nsproxy.h>`（UTS, IPC, PID, 网络等）\n- **文件系统**：`<linux/fs.h>`, `<linux/fdtable.h>`（文件描述符复制）\n- **跟踪与调试**：`<trace/events/sched.h>`, `<linux/ftrace.h>`, KASAN/KMSAN\n\n### 架构相关依赖\n- `<asm/pgalloc.h>`：页表分配\n- `<asm/mmu_context.h>`：MMU 上下文切换\n- `<asm/tlbflush.h>`：TLB 刷新操作\n- 架构特定的 `THREAD_SIZE` 和栈对齐要求\n\n### 配置选项依赖\n- `CONFIG_VMAP_STACK`：启用虚拟内存分配内核栈\n- `CONFIG_PROVE_RCU`：RCU 锁验证支持\n- `CONFIG_ARCH_TASK_STRUCT_ALLOCATOR`：架构自定义 task_struct 分配器\n- `CONFIG_MEMCG_KMEM`：内核内存 cgroup 支持\n\n## 5. 使用场景\n\n### 进程创建路径\n- **系统调用入口**：`sys_fork()`, `sys_vfork()`, `sys_clone()` 最终调用 `_do_fork()`\n- **内核线程创建**：`kthread_create()` 通过 `kernel_thread()` 触发 fork 逻辑\n- **容器/命名空间初始化**：新 PID/UTS/IPC 命名空间创建时伴随进程 fork\n\n### 资源复制关键点\n- **内存描述符 (mm_struct)**：通过 `dup_mm()` 复制地址空间（COW 页表）\n- **文件描述符表**：`dup_fd()` 复制打开文件表\n- **信号处理**：复制信号掩码和处理函数\n- **POSIX 定时器/异步 I/O**：复制相关上下文（如 `aio`, `posix-timers`）\n\n### 特殊场景处理\n- **写时复制优化**：避免物理内存立即复制，提升 fork 性能\n- **OOM Killer 集成**：在内存不足时参与进程选择\n- **审计与监控**：通过 `audit_alloc()` 和 `proc` 文件系统暴露进程信息\n- **实时性保障**：RT 任务 fork 时保持调度策略和优先级",
      "similarity": 0.6516983509063721,
      "chunks": [
        {
          "chunk_id": 8,
          "file_path": "kernel/fork.c",
          "start_line": 1503,
          "end_line": 1608,
          "content": [
            "int replace_mm_exe_file(struct mm_struct *mm, struct file *new_exe_file)",
            "{",
            "\tstruct vm_area_struct *vma;",
            "\tstruct file *old_exe_file;",
            "\tint ret = 0;",
            "",
            "\t/* Forbid mm->exe_file change if old file still mapped. */",
            "\told_exe_file = get_mm_exe_file(mm);",
            "\tif (old_exe_file) {",
            "\t\tVMA_ITERATOR(vmi, mm, 0);",
            "\t\tmmap_read_lock(mm);",
            "\t\tfor_each_vma(vmi, vma) {",
            "\t\t\tif (!vma->vm_file)",
            "\t\t\t\tcontinue;",
            "\t\t\tif (path_equal(&vma->vm_file->f_path,",
            "\t\t\t\t       &old_exe_file->f_path)) {",
            "\t\t\t\tret = -EBUSY;",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t}",
            "\t\tmmap_read_unlock(mm);",
            "\t\tfput(old_exe_file);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\tret = deny_write_access(new_exe_file);",
            "\tif (ret)",
            "\t\treturn -EACCES;",
            "\tget_file(new_exe_file);",
            "",
            "\t/* set the new file */",
            "\tmmap_write_lock(mm);",
            "\told_exe_file = rcu_dereference_raw(mm->exe_file);",
            "\trcu_assign_pointer(mm->exe_file, new_exe_file);",
            "\tmmap_write_unlock(mm);",
            "",
            "\tif (old_exe_file) {",
            "\t\tallow_write_access(old_exe_file);",
            "\t\tfput(old_exe_file);",
            "\t}",
            "\treturn 0;",
            "}",
            "static void complete_vfork_done(struct task_struct *tsk)",
            "{",
            "\tstruct completion *vfork;",
            "",
            "\ttask_lock(tsk);",
            "\tvfork = tsk->vfork_done;",
            "\tif (likely(vfork)) {",
            "\t\ttsk->vfork_done = NULL;",
            "\t\tcomplete(vfork);",
            "\t}",
            "\ttask_unlock(tsk);",
            "}",
            "static int wait_for_vfork_done(struct task_struct *child,",
            "\t\t\t\tstruct completion *vfork)",
            "{",
            "\tunsigned int state = TASK_UNINTERRUPTIBLE|TASK_KILLABLE|TASK_FREEZABLE;",
            "\tint killed;",
            "",
            "\tcgroup_enter_frozen();",
            "\tkilled = wait_for_completion_state(vfork, state);",
            "\tcgroup_leave_frozen(false);",
            "",
            "\tif (killed) {",
            "\t\ttask_lock(child);",
            "\t\tchild->vfork_done = NULL;",
            "\t\ttask_unlock(child);",
            "\t}",
            "",
            "\tput_task_struct(child);",
            "\treturn killed;",
            "}",
            "static void mm_release(struct task_struct *tsk, struct mm_struct *mm)",
            "{",
            "\tuprobe_free_utask(tsk);",
            "",
            "\t/* Get rid of any cached register state */",
            "\tdeactivate_mm(tsk, mm);",
            "",
            "\t/*",
            "\t * Signal userspace if we're not exiting with a core dump",
            "\t * because we want to leave the value intact for debugging",
            "\t * purposes.",
            "\t */",
            "\tif (tsk->clear_child_tid) {",
            "\t\tif (atomic_read(&mm->mm_users) > 1) {",
            "\t\t\t/*",
            "\t\t\t * We don't check the error code - if userspace has",
            "\t\t\t * not set up a proper pointer then tough luck.",
            "\t\t\t */",
            "\t\t\tput_user(0, tsk->clear_child_tid);",
            "\t\t\tdo_futex(tsk->clear_child_tid, FUTEX_WAKE,",
            "\t\t\t\t\t1, NULL, NULL, 0, 0);",
            "\t\t}",
            "\t\ttsk->clear_child_tid = NULL;",
            "\t}",
            "",
            "\t/*",
            "\t * All done, finally we can wake up parent and return this mm to him.",
            "\t * Also kthread_stop() uses this completion for synchronization.",
            "\t */",
            "\tif (tsk->vfork_done)",
            "\t\tcomplete_vfork_done(tsk);",
            "}"
          ],
          "function_name": "replace_mm_exe_file, complete_vfork_done, wait_for_vfork_done, mm_release",
          "description": "替换当前mm的可执行文件，完成vfork同步操作并等待子进程完成，释放mm时通知父进程完成vfork同步。",
          "similarity": 0.6316860914230347
        },
        {
          "chunk_id": 12,
          "file_path": "kernel/fork.c",
          "start_line": 2176,
          "end_line": 2282,
          "content": [
            "static void rv_task_fork(struct task_struct *p)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < RV_PER_TASK_MONITORS; i++)",
            "\t\tp->rv[i].da_mon.monitoring = false;",
            "}",
            "static inline void init_idle_pids(struct task_struct *idle)",
            "{",
            "\tenum pid_type type;",
            "",
            "\tfor (type = PIDTYPE_PID; type < PIDTYPE_MAX; ++type) {",
            "\t\tINIT_HLIST_NODE(&idle->pid_links[type]); /* not really needed */",
            "\t\tinit_task_pid(idle, type, &init_struct_pid);",
            "\t}",
            "}",
            "static int idle_dummy(void *dummy)",
            "{",
            "\t/* This function is never called */",
            "\treturn 0;",
            "}",
            "pid_t kernel_clone(struct kernel_clone_args *args)",
            "{",
            "\tu64 clone_flags = args->flags;",
            "\tstruct completion vfork;",
            "\tstruct pid *pid;",
            "\tstruct task_struct *p;",
            "\tint trace = 0;",
            "\tpid_t nr;",
            "",
            "\t/*",
            "\t * For legacy clone() calls, CLONE_PIDFD uses the parent_tid argument",
            "\t * to return the pidfd. Hence, CLONE_PIDFD and CLONE_PARENT_SETTID are",
            "\t * mutually exclusive. With clone3() CLONE_PIDFD has grown a separate",
            "\t * field in struct clone_args and it still doesn't make sense to have",
            "\t * them both point at the same memory location. Performing this check",
            "\t * here has the advantage that we don't need to have a separate helper",
            "\t * to check for legacy clone().",
            "\t */",
            "\tif ((args->flags & CLONE_PIDFD) &&",
            "\t    (args->flags & CLONE_PARENT_SETTID) &&",
            "\t    (args->pidfd == args->parent_tid))",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * Determine whether and which event to report to ptracer.  When",
            "\t * called from kernel_thread or CLONE_UNTRACED is explicitly",
            "\t * requested, no event is reported; otherwise, report if the event",
            "\t * for the type of forking is enabled.",
            "\t */",
            "\tif (!(clone_flags & CLONE_UNTRACED)) {",
            "\t\tif (clone_flags & CLONE_VFORK)",
            "\t\t\ttrace = PTRACE_EVENT_VFORK;",
            "\t\telse if (args->exit_signal != SIGCHLD)",
            "\t\t\ttrace = PTRACE_EVENT_CLONE;",
            "\t\telse",
            "\t\t\ttrace = PTRACE_EVENT_FORK;",
            "",
            "\t\tif (likely(!ptrace_event_enabled(current, trace)))",
            "\t\t\ttrace = 0;",
            "\t}",
            "",
            "\tp = copy_process(NULL, trace, NUMA_NO_NODE, args);",
            "\tadd_latent_entropy();",
            "",
            "\tif (IS_ERR(p))",
            "\t\treturn PTR_ERR(p);",
            "",
            "\t/*",
            "\t * Do this prior waking up the new thread - the thread pointer",
            "\t * might get invalid after that point, if the thread exits quickly.",
            "\t */",
            "\ttrace_sched_process_fork(current, p);",
            "",
            "\tpid = get_task_pid(p, PIDTYPE_PID);",
            "\tnr = pid_vnr(pid);",
            "",
            "\tif (clone_flags & CLONE_PARENT_SETTID)",
            "\t\tput_user(nr, args->parent_tid);",
            "",
            "\tif (clone_flags & CLONE_VFORK) {",
            "\t\tp->vfork_done = &vfork;",
            "\t\tinit_completion(&vfork);",
            "\t\tget_task_struct(p);",
            "\t}",
            "",
            "\tif (IS_ENABLED(CONFIG_LRU_GEN_WALKS_MMU) && !(clone_flags & CLONE_VM)) {",
            "\t\t/* lock the task to synchronize with memcg migration */",
            "\t\ttask_lock(p);",
            "\t\tlru_gen_add_mm(p->mm);",
            "\t\ttask_unlock(p);",
            "\t}",
            "",
            "\twake_up_new_task(p);",
            "",
            "\t/* forking complete and child started to run, tell ptracer */",
            "\tif (unlikely(trace))",
            "\t\tptrace_event_pid(trace, pid);",
            "",
            "\tif (clone_flags & CLONE_VFORK) {",
            "\t\tif (!wait_for_vfork_done(p, &vfork))",
            "\t\t\tptrace_event_pid(PTRACE_EVENT_VFORK_DONE, pid);",
            "\t}",
            "",
            "\tput_pid(pid);",
            "\treturn nr;",
            "}"
          ],
          "function_name": "rv_task_fork, init_idle_pids, idle_dummy, kernel_clone",
          "description": "实现kernel_clone核心逻辑，创建新进程并处理克隆标志，管理子进程启动、vfork等待及进程树遍历，包含空闲任务PID初始化与RV监控器重置",
          "similarity": 0.6203579902648926
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/fork.c",
          "start_line": 666,
          "end_line": 845,
          "content": [
            "static __latent_entropy int dup_mmap(struct mm_struct *mm,",
            "\t\t\t\t\tstruct mm_struct *oldmm)",
            "{",
            "\tstruct vm_area_struct *mpnt, *tmp;",
            "\tint retval;",
            "\tunsigned long charge = 0;",
            "\tLIST_HEAD(uf);",
            "\tVMA_ITERATOR(vmi, mm, 0);",
            "",
            "\tuprobe_start_dup_mmap();",
            "\tif (mmap_write_lock_killable(oldmm)) {",
            "\t\tretval = -EINTR;",
            "\t\tgoto fail_uprobe_end;",
            "\t}",
            "\tflush_cache_dup_mm(oldmm);",
            "\tuprobe_dup_mmap(oldmm, mm);",
            "\t/*",
            "\t * Not linked in yet - no deadlock potential:",
            "\t */",
            "\tmmap_write_lock_nested(mm, SINGLE_DEPTH_NESTING);",
            "",
            "\t/* No ordering required: file already has been exposed. */",
            "\tdup_mm_exe_file(mm, oldmm);",
            "",
            "\tmm->total_vm = oldmm->total_vm;",
            "\tmm->data_vm = oldmm->data_vm;",
            "\tmm->exec_vm = oldmm->exec_vm;",
            "\tmm->stack_vm = oldmm->stack_vm;",
            "",
            "\t/* Use __mt_dup() to efficiently build an identical maple tree. */",
            "\tretval = __mt_dup(&oldmm->mm_mt, &mm->mm_mt, GFP_KERNEL);",
            "\tif (unlikely(retval))",
            "\t\tgoto out;",
            "",
            "\tmt_clear_in_rcu(vmi.mas.tree);",
            "\tfor_each_vma(vmi, mpnt) {",
            "\t\tstruct file *file;",
            "",
            "\t\tvma_start_write(mpnt);",
            "\t\tif (mpnt->vm_flags & VM_DONTCOPY) {",
            "\t\t\tretval = vma_iter_clear_gfp(&vmi, mpnt->vm_start,",
            "\t\t\t\t\t\t    mpnt->vm_end, GFP_KERNEL);",
            "\t\t\tif (retval)",
            "\t\t\t\tgoto loop_out;",
            "",
            "\t\t\tvm_stat_account(mm, mpnt->vm_flags, -vma_pages(mpnt));",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tcharge = 0;",
            "\t\t/*",
            "\t\t * Don't duplicate many vmas if we've been oom-killed (for",
            "\t\t * example)",
            "\t\t */",
            "\t\tif (fatal_signal_pending(current)) {",
            "\t\t\tretval = -EINTR;",
            "\t\t\tgoto loop_out;",
            "\t\t}",
            "\t\tif (mpnt->vm_flags & VM_ACCOUNT) {",
            "\t\t\tunsigned long len = vma_pages(mpnt);",
            "",
            "\t\t\tif (security_vm_enough_memory_mm(oldmm, len)) /* sic */",
            "\t\t\t\tgoto fail_nomem;",
            "\t\t\tcharge = len;",
            "\t\t}",
            "\t\ttmp = vm_area_dup(mpnt);",
            "\t\tif (!tmp)",
            "\t\t\tgoto fail_nomem;",
            "",
            "\t\t/* track_pfn_copy() will later take care of copying internal state. */",
            "\t\tif (unlikely(tmp->vm_flags & VM_PFNMAP))",
            "\t\t\tuntrack_pfn_clear(tmp);",
            "",
            "\t\tretval = vma_dup_policy(mpnt, tmp);",
            "\t\tif (retval)",
            "\t\t\tgoto fail_nomem_policy;",
            "\t\ttmp->vm_mm = mm;",
            "\t\tretval = dup_userfaultfd(tmp, &uf);",
            "\t\tif (retval)",
            "\t\t\tgoto fail_nomem_anon_vma_fork;",
            "\t\tif (tmp->vm_flags & VM_WIPEONFORK) {",
            "\t\t\t/*",
            "\t\t\t * VM_WIPEONFORK gets a clean slate in the child.",
            "\t\t\t * Don't prepare anon_vma until fault since we don't",
            "\t\t\t * copy page for current vma.",
            "\t\t\t */",
            "\t\t\ttmp->anon_vma = NULL;",
            "\t\t} else if (anon_vma_fork(tmp, mpnt))",
            "\t\t\tgoto fail_nomem_anon_vma_fork;",
            "\t\tvm_flags_clear(tmp, VM_LOCKED_MASK);",
            "\t\tfile = tmp->vm_file;",
            "\t\tif (file) {",
            "\t\t\tstruct address_space *mapping = file->f_mapping;",
            "",
            "\t\t\tget_file(file);",
            "\t\t\ti_mmap_lock_write(mapping);",
            "\t\t\tif (vma_is_shared_maywrite(tmp))",
            "\t\t\t\tmapping_allow_writable(mapping);",
            "\t\t\tflush_dcache_mmap_lock(mapping);",
            "\t\t\t/* insert tmp into the share list, just after mpnt */",
            "\t\t\tvma_interval_tree_insert_after(tmp, mpnt,",
            "\t\t\t\t\t&mapping->i_mmap);",
            "\t\t\tflush_dcache_mmap_unlock(mapping);",
            "\t\t\ti_mmap_unlock_write(mapping);",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Copy/update hugetlb private vma information.",
            "\t\t */",
            "\t\tif (is_vm_hugetlb_page(tmp))",
            "\t\t\thugetlb_dup_vma_private(tmp);",
            "",
            "\t\t/*",
            "\t\t * Link the vma into the MT. After using __mt_dup(), memory",
            "\t\t * allocation is not necessary here, so it cannot fail.",
            "\t\t */",
            "\t\tvma_iter_bulk_store(&vmi, tmp);",
            "",
            "\t\tmm->map_count++;",
            "\t\tif (!(tmp->vm_flags & VM_WIPEONFORK))",
            "\t\t\tretval = copy_page_range(tmp, mpnt);",
            "",
            "\t\tif (tmp->vm_ops && tmp->vm_ops->open)",
            "\t\t\ttmp->vm_ops->open(tmp);",
            "",
            "\t\tif (retval) {",
            "\t\t\tmpnt = vma_next(&vmi);",
            "\t\t\tgoto loop_out;",
            "\t\t}",
            "\t}",
            "\t/* a new mm has just been created */",
            "\tretval = arch_dup_mmap(oldmm, mm);",
            "loop_out:",
            "\tvma_iter_free(&vmi);",
            "\tif (!retval) {",
            "\t\tmt_set_in_rcu(vmi.mas.tree);",
            "\t\tksm_fork(mm, oldmm);",
            "\t\tkhugepaged_fork(mm, oldmm);",
            "\t} else {",
            "",
            "\t\t/*",
            "\t\t * The entire maple tree has already been duplicated. If the",
            "\t\t * mmap duplication fails, mark the failure point with",
            "\t\t * XA_ZERO_ENTRY. In exit_mmap(), if this marker is encountered,",
            "\t\t * stop releasing VMAs that have not been duplicated after this",
            "\t\t * point.",
            "\t\t */",
            "\t\tif (mpnt) {",
            "\t\t\tmas_set_range(&vmi.mas, mpnt->vm_start, mpnt->vm_end - 1);",
            "\t\t\tmas_store(&vmi.mas, XA_ZERO_ENTRY);",
            "\t\t\t/* Avoid OOM iterating a broken tree */",
            "\t\t\tset_bit(MMF_OOM_SKIP, &mm->flags);",
            "\t\t}",
            "\t\t/*",
            "\t\t * The mm_struct is going to exit, but the locks will be dropped",
            "\t\t * first.  Set the mm_struct as unstable is advisable as it is",
            "\t\t * not fully initialised.",
            "\t\t */",
            "\t\tset_bit(MMF_UNSTABLE, &mm->flags);",
            "\t}",
            "out:",
            "\tmmap_write_unlock(mm);",
            "\tflush_tlb_mm(oldmm);",
            "\tmmap_write_unlock(oldmm);",
            "\tif (!retval)",
            "\t\tdup_userfaultfd_complete(&uf);",
            "\telse",
            "\t\tdup_userfaultfd_fail(&uf);",
            "fail_uprobe_end:",
            "\tuprobe_end_dup_mmap();",
            "\treturn retval;",
            "",
            "fail_nomem_anon_vma_fork:",
            "\tmpol_put(vma_policy(tmp));",
            "fail_nomem_policy:",
            "\tvm_area_free(tmp);",
            "fail_nomem:",
            "\tretval = -ENOMEM;",
            "\tvm_unacct_memory(charge);",
            "\tgoto loop_out;",
            "}"
          ],
          "function_name": "dup_mmap",
          "description": "实现进程fork时的内存映射复制逻辑，深度遍历原进程的VMA结构创建副本，处理共享文件映射、hugetlb页等特殊内存类型，并管理OOM异常情况下的失败恢复。",
          "similarity": 0.5997371673583984
        },
        {
          "chunk_id": 16,
          "file_path": "kernel/fork.c",
          "start_line": 3480,
          "end_line": 3518,
          "content": [
            "int unshare_files(void)",
            "{",
            "\tstruct task_struct *task = current;",
            "\tstruct files_struct *old, *copy = NULL;",
            "\tint error;",
            "",
            "\terror = unshare_fd(CLONE_FILES, &copy);",
            "\tif (error || !copy)",
            "\t\treturn error;",
            "",
            "\told = task->files;",
            "\ttask_lock(task);",
            "\ttask->files = copy;",
            "\ttask_unlock(task);",
            "\tput_files_struct(old);",
            "\treturn 0;",
            "}",
            "int sysctl_max_threads(struct ctl_table *table, int write,",
            "\t\t       void *buffer, size_t *lenp, loff_t *ppos)",
            "{",
            "\tstruct ctl_table t;",
            "\tint ret;",
            "\tint threads = max_threads;",
            "\tint min = 1;",
            "\tint max = MAX_THREADS;",
            "",
            "\tt = *table;",
            "\tt.data = &threads;",
            "\tt.extra1 = &min;",
            "\tt.extra2 = &max;",
            "",
            "\tret = proc_dointvec_minmax(&t, write, buffer, lenp, ppos);",
            "\tif (ret || !write)",
            "\t\treturn ret;",
            "",
            "\tmax_threads = threads;",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "unshare_files, sysctl_max_threads",
          "description": "unshare_files函数复制当前进程的文件表结构并将其绑定到当前任务，sysctl_max_threads函数通过proc_dointvec_minmax接口限制系统最大线程数，支持读取和写入操作，其中写入时会更新全局max_threads变量。",
          "similarity": 0.5686829686164856
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/fork.c",
          "start_line": 159,
          "end_line": 303,
          "content": [
            "int lockdep_tasklist_lock_is_held(void)",
            "{",
            "\treturn lockdep_is_held(&tasklist_lock);",
            "}",
            "int nr_processes(void)",
            "{",
            "\tint cpu;",
            "\tint total = 0;",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\ttotal += per_cpu(process_counts, cpu);",
            "",
            "\treturn total;",
            "}",
            "void __weak arch_release_task_struct(struct task_struct *tsk)",
            "{",
            "}",
            "static inline void free_task_struct(struct task_struct *tsk)",
            "{",
            "\tkmem_cache_free(task_struct_cachep, tsk);",
            "}",
            "static bool try_release_thread_stack_to_cache(struct vm_struct *vm)",
            "{",
            "\tunsigned int i;",
            "",
            "\tfor (i = 0; i < NR_CACHED_STACKS; i++) {",
            "\t\tif (this_cpu_cmpxchg(cached_stacks[i], NULL, vm) != NULL)",
            "\t\t\tcontinue;",
            "\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "static void thread_stack_free_rcu(struct rcu_head *rh)",
            "{",
            "\tstruct vm_stack *vm_stack = container_of(rh, struct vm_stack, rcu);",
            "",
            "\tif (try_release_thread_stack_to_cache(vm_stack->stack_vm_area))",
            "\t\treturn;",
            "",
            "\tvfree(vm_stack);",
            "}",
            "static void thread_stack_delayed_free(struct task_struct *tsk)",
            "{",
            "\tstruct vm_stack *vm_stack = tsk->stack;",
            "",
            "\tvm_stack->stack_vm_area = tsk->stack_vm_area;",
            "\tcall_rcu(&vm_stack->rcu, thread_stack_free_rcu);",
            "}",
            "static int free_vm_stack_cache(unsigned int cpu)",
            "{",
            "\tstruct vm_struct **cached_vm_stacks = per_cpu_ptr(cached_stacks, cpu);",
            "\tint i;",
            "",
            "\tfor (i = 0; i < NR_CACHED_STACKS; i++) {",
            "\t\tstruct vm_struct *vm_stack = cached_vm_stacks[i];",
            "",
            "\t\tif (!vm_stack)",
            "\t\t\tcontinue;",
            "",
            "\t\tvfree(vm_stack->addr);",
            "\t\tcached_vm_stacks[i] = NULL;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int memcg_charge_kernel_stack(struct vm_struct *vm)",
            "{",
            "\tint i;",
            "\tint ret;",
            "\tint nr_charged = 0;",
            "",
            "\tBUG_ON(vm->nr_pages != THREAD_SIZE / PAGE_SIZE);",
            "",
            "\tfor (i = 0; i < THREAD_SIZE / PAGE_SIZE; i++) {",
            "\t\tret = memcg_kmem_charge_page(vm->pages[i], GFP_KERNEL, 0);",
            "\t\tif (ret)",
            "\t\t\tgoto err;",
            "\t\tnr_charged++;",
            "\t}",
            "\treturn 0;",
            "err:",
            "\tfor (i = 0; i < nr_charged; i++)",
            "\t\tmemcg_kmem_uncharge_page(vm->pages[i], 0);",
            "\treturn ret;",
            "}",
            "static int alloc_thread_stack_node(struct task_struct *tsk, int node)",
            "{",
            "\tstruct vm_struct *vm;",
            "\tvoid *stack;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < NR_CACHED_STACKS; i++) {",
            "\t\tstruct vm_struct *s;",
            "",
            "\t\ts = this_cpu_xchg(cached_stacks[i], NULL);",
            "",
            "\t\tif (!s)",
            "\t\t\tcontinue;",
            "",
            "\t\t/* Reset stack metadata. */",
            "\t\tkasan_unpoison_range(s->addr, THREAD_SIZE);",
            "",
            "\t\tstack = kasan_reset_tag(s->addr);",
            "",
            "\t\t/* Clear stale pointers from reused stack. */",
            "\t\tmemset(stack, 0, THREAD_SIZE);",
            "",
            "\t\tif (memcg_charge_kernel_stack(s)) {",
            "\t\t\tvfree(s->addr);",
            "\t\t\treturn -ENOMEM;",
            "\t\t}",
            "",
            "\t\ttsk->stack_vm_area = s;",
            "\t\ttsk->stack = stack;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * Allocated stacks are cached and later reused by new threads,",
            "\t * so memcg accounting is performed manually on assigning/releasing",
            "\t * stacks to tasks. Drop __GFP_ACCOUNT.",
            "\t */",
            "\tstack = __vmalloc_node_range(THREAD_SIZE, THREAD_ALIGN,",
            "\t\t\t\t     VMALLOC_START, VMALLOC_END,",
            "\t\t\t\t     THREADINFO_GFP & ~__GFP_ACCOUNT,",
            "\t\t\t\t     PAGE_KERNEL,",
            "\t\t\t\t     0, node, __builtin_return_address(0));",
            "\tif (!stack)",
            "\t\treturn -ENOMEM;",
            "",
            "\tvm = find_vm_area(stack);",
            "\tif (memcg_charge_kernel_stack(vm)) {",
            "\t\tvfree(stack);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "\t/*",
            "\t * We can't call find_vm_area() in interrupt context, and",
            "\t * free_thread_stack() can be called in interrupt context,",
            "\t * so cache the vm_struct.",
            "\t */",
            "\ttsk->stack_vm_area = vm;",
            "\tstack = kasan_reset_tag(stack);",
            "\ttsk->stack = stack;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "lockdep_tasklist_lock_is_held, nr_processes, arch_release_task_struct, free_task_struct, try_release_thread_stack_to_cache, thread_stack_free_rcu, thread_stack_delayed_free, free_vm_stack_cache, memcg_charge_kernel_stack, alloc_thread_stack_node",
          "description": "实现任务列表锁状态检测、进程总数统计及线程栈分配释放逻辑，通过缓存机制优化线程栈复用并利用RCU实现延迟释放，包含栈内存管理和内存会计功能。",
          "similarity": 0.5619321465492249
        }
      ]
    },
    {
      "source_file": "kernel/stop_machine.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:30:03\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `stop_machine.c`\n\n---\n\n# `stop_machine.c` 技术文档\n\n## 1. 文件概述\n\n`stop_machine.c` 实现了 Linux 内核中用于在所有（或指定）CPU 上同步执行特定函数的机制，即 **stop_machine** 机制。该机制通过为每个 CPU 创建一个高优先级的内核线程（称为 stopper），在需要时唤醒这些线程以执行指定任务，并确保在执行期间其他任务无法抢占，从而实现对整个系统或部分 CPU 的“冻结”式同步操作。此机制常用于需要全局一致状态的关键内核操作，如 CPU 热插拔、模块加载、内核热补丁（livepatch）等。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct cpu_stop_done`**  \n  用于协调多个 CPU 上 stop 任务的完成状态，包含待完成任务计数（`nr_todo`）、返回值（`ret`）和完成信号量（`completion`）。\n\n- **`struct cpu_stopper`**  \n  每个 CPU 对应一个 stopper 实例，包含：\n  - `thread`：stopper 内核线程\n  - `lock`：保护 pending works 链表的自旋锁\n  - `enabled`：该 stopper 是否启用（对应 CPU 是否在线）\n  - `works`：待执行的 `cpu_stop_work` 链表\n  - `stop_work`、`caller`、`fn`：用于 `stop_cpus` 的临时字段\n\n- **`struct multi_stop_data`**  \n  用于多 CPU 同步执行的共享控制结构，包含：\n  - `fn` 和 `data`：要执行的函数及其参数\n  - `num_threads`：参与同步的线程数\n  - `active_cpus`：指定哪些 CPU 需要实际执行函数\n  - `state`：全局状态机（`MULTI_STOP_*` 枚举）\n  - `thread_ack`：用于状态同步的原子计数器\n\n- **`enum multi_stop_state`**  \n  多 CPU 同步执行的状态机，包括：\n  - `MULTI_STOP_NONE`\n  - `MULTI_STOP_PREPARE`\n  - `MULTI_STOP_DISABLE_IRQ`\n  - `MULTI_STOP_RUN`\n  - `MULTI_STOP_EXIT`\n\n### 主要函数\n\n- **`stop_one_cpu(cpu, fn, arg)`**  \n  在指定 CPU 上执行函数 `fn(arg)`，阻塞等待执行完成。若 CPU 离线则返回 `-ENOENT`。\n\n- **`cpu_stop_queue_work(cpu, work)`**  \n  将 stop 任务加入指定 CPU 的 stopper 队列，若 CPU 在线则唤醒其 stopper 线程。\n\n- **`multi_cpu_stop(data)`**  \n  stopper 线程的主函数，实现多 CPU 同步状态机，负责禁用中断、执行函数、状态同步等。\n\n- **`print_stop_info(log_lvl, task)`**  \n  调试辅助函数，若 `task` 是 stopper 线程，则打印其当前执行函数及调用者信息。\n\n- **`set_state()` / `ack_state()`**  \n  控制多 CPU 同步状态机的推进：`set_state` 设置新状态并重置 ack 计数器，`ack_state` 用于线程确认状态，最后一个确认者推进到下一状态。\n\n## 3. 关键实现\n\n### Stopper 线程模型\n- 每个可能的 CPU 都有一个 `cpu_stopper` 实例，其中包含一个专用内核线程。\n- 该线程运行 `multi_cpu_stop` 函数，处于高优先级实时调度策略（由 `smpboot` 框架设置），可抢占普通任务。\n- 当有 stop 任务时，通过 `wake_up_process` 唤醒对应 stopper 线程。\n\n### 多 CPU 同步状态机\n- 使用共享的 `multi_stop_data` 结构协调所有参与 CPU。\n- 状态转换通过 `set_state` 触发，所有线程通过轮询 `msdata->state` 检测状态变化。\n- 每个状态变更需所有线程调用 `ack_state` 确认，最后一个确认者推进到下一状态，确保严格同步。\n- 在 `MULTI_STOP_DISABLE_IRQ` 状态下，所有参与 CPU 禁用本地中断（包括硬中断），ARM64 还会屏蔽 SDEI 事件。\n- 仅 `active_cpus` 中的 CPU 在 `MULTI_STOP_RUN` 状态执行实际函数。\n\n### 中断与 NMI 安全\n- 执行期间禁用本地中断，防止中断处理程序干扰关键操作。\n- 在等待状态循环中调用 `touch_nmi_watchdog()` 防止 NMI watchdog 误报硬锁死。\n- 使用 `rcu_momentary_dyntick_idle()` 通知 RCU 系统当前 CPU 处于空闲状态，避免 RCU stall。\n\n### CPU 热插拔处理\n- `cpu_stopper.enabled` 标志反映 CPU 在线状态。\n- 若 CPU 离线时提交 stop 任务，则立即完成（调用 `cpu_stop_signal_done`），避免阻塞。\n- 支持从非活动 CPU（如 CPU hotplug 的 bringup 路径）调用 `stop_machine`，此时中断可能已禁用，需保存/恢复中断状态。\n\n### 死锁预防\n- `cpu_stop_queue_two_works` 函数通过嵌套锁（`SINGLE_DEPTH_NESTING`）和重试机制，确保两个 stopper 的入队操作原子性，避免与 `stop_cpus` 并发导致的死锁。\n- 使用 `preempt_disable()` 保证唤醒操作在不可抢占上下文中完成，防止唤醒丢失。\n\n## 4. 依赖关系\n\n- **调度子系统**：依赖 `kthread` 创建 stopper 线程，使用 `wake_up_process` 唤醒。\n- **SMP 子系统**：依赖 `smpboot.h` 的 CPU 热插拔通知机制来启用/禁用 stopper。\n- **中断子系统**：调用 `local_irq_disable/restore`、`hard_irq_disable` 控制中断。\n- **RCU 子系统**：通过 `rcu_momentary_dyntick_idle` 与 RCU 交互。\n- **NMI 子系统**：调用 `touch_nmi_watchdog` 避免 watchdog 误报。\n- **ARM64 架构**：条件编译包含 SDEI（Software Delegated Exception Interface）屏蔽/解除屏蔽。\n- **Per-CPU 基础设施**：使用 `DEFINE_PER_CPU` 和 `per_cpu_ptr` 管理 per-CPU stopper 实例。\n\n## 5. 使用场景\n\n- **CPU 热插拔**：在 CPU 上线/下线过程中执行需要全局同步的操作。\n- **内核模块加载/卸载**：某些架构或功能（如 ftrace）需要 stop_machine 来安全修改内核文本。\n- **内核热补丁（Livepatch）**：在应用补丁时冻结所有 CPU 以确保一致性。\n- **动态 tracing（如 ftrace）**：修改函数入口指令时需 stop_machine 保证原子性。\n- **内存热插拔**：某些内存操作需要全局同步。\n- **内核调试与诊断**：通过 `print_stop_info` 辅助分析 stopper 行为。\n- **架构特定操作**：如 ARM64 的 SDEI 事件处理需要在 stop_machine 上下文中屏蔽。",
      "similarity": 0.642629086971283,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/stop_machine.c",
          "start_line": 269,
          "end_line": 369,
          "content": [
            "static int cpu_stop_queue_two_works(int cpu1, struct cpu_stop_work *work1,",
            "\t\t\t\t    int cpu2, struct cpu_stop_work *work2)",
            "{",
            "\tstruct cpu_stopper *stopper1 = per_cpu_ptr(&cpu_stopper, cpu1);",
            "\tstruct cpu_stopper *stopper2 = per_cpu_ptr(&cpu_stopper, cpu2);",
            "\tint err;",
            "",
            "retry:",
            "\t/*",
            "\t * The waking up of stopper threads has to happen in the same",
            "\t * scheduling context as the queueing.  Otherwise, there is a",
            "\t * possibility of one of the above stoppers being woken up by another",
            "\t * CPU, and preempting us. This will cause us to not wake up the other",
            "\t * stopper forever.",
            "\t */",
            "\tpreempt_disable();",
            "\traw_spin_lock_irq(&stopper1->lock);",
            "\traw_spin_lock_nested(&stopper2->lock, SINGLE_DEPTH_NESTING);",
            "",
            "\tif (!stopper1->enabled || !stopper2->enabled) {",
            "\t\terr = -ENOENT;",
            "\t\tgoto unlock;",
            "\t}",
            "",
            "\t/*",
            "\t * Ensure that if we race with __stop_cpus() the stoppers won't get",
            "\t * queued up in reverse order leading to system deadlock.",
            "\t *",
            "\t * We can't miss stop_cpus_in_progress if queue_stop_cpus_work() has",
            "\t * queued a work on cpu1 but not on cpu2, we hold both locks.",
            "\t *",
            "\t * It can be falsely true but it is safe to spin until it is cleared,",
            "\t * queue_stop_cpus_work() does everything under preempt_disable().",
            "\t */",
            "\tif (unlikely(stop_cpus_in_progress)) {",
            "\t\terr = -EDEADLK;",
            "\t\tgoto unlock;",
            "\t}",
            "",
            "\terr = 0;",
            "\t__cpu_stop_queue_work(stopper1, work1);",
            "\t__cpu_stop_queue_work(stopper2, work2);",
            "",
            "unlock:",
            "\traw_spin_unlock(&stopper2->lock);",
            "\traw_spin_unlock_irq(&stopper1->lock);",
            "",
            "\tif (unlikely(err == -EDEADLK)) {",
            "\t\tpreempt_enable();",
            "",
            "\t\twhile (stop_cpus_in_progress)",
            "\t\t\tcpu_relax();",
            "",
            "\t\tgoto retry;",
            "\t}",
            "",
            "\tif (!err) {",
            "\t\twake_up_process(stopper1->thread);",
            "\t\twake_up_process(stopper2->thread);",
            "\t}",
            "\tpreempt_enable();",
            "",
            "\treturn err;",
            "}",
            "int stop_two_cpus(unsigned int cpu1, unsigned int cpu2, cpu_stop_fn_t fn, void *arg)",
            "{",
            "\tstruct cpu_stop_done done;",
            "\tstruct cpu_stop_work work1, work2;",
            "\tstruct multi_stop_data msdata;",
            "",
            "\tmsdata = (struct multi_stop_data){",
            "\t\t.fn = fn,",
            "\t\t.data = arg,",
            "\t\t.num_threads = 2,",
            "\t\t.active_cpus = cpumask_of(cpu1),",
            "\t};",
            "",
            "\twork1 = work2 = (struct cpu_stop_work){",
            "\t\t.fn = multi_cpu_stop,",
            "\t\t.arg = &msdata,",
            "\t\t.done = &done,",
            "\t\t.caller = _RET_IP_,",
            "\t};",
            "",
            "\tcpu_stop_init_done(&done, 2);",
            "\tset_state(&msdata, MULTI_STOP_PREPARE);",
            "",
            "\tif (cpu1 > cpu2)",
            "\t\tswap(cpu1, cpu2);",
            "\tif (cpu_stop_queue_two_works(cpu1, &work1, cpu2, &work2))",
            "\t\treturn -ENOENT;",
            "",
            "\twait_for_completion(&done.completion);",
            "\treturn done.ret;",
            "}",
            "bool stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,",
            "\t\t\tstruct cpu_stop_work *work_buf)",
            "{",
            "\t*work_buf = (struct cpu_stop_work){ .fn = fn, .arg = arg, .caller = _RET_IP_, };",
            "\treturn cpu_stop_queue_work(cpu, work_buf);",
            "}"
          ],
          "function_name": "cpu_stop_queue_two_works, stop_two_cpus, stop_one_cpu_nowait",
          "description": "实现双CPU停止操作的协同逻辑，通过原子操作防止死锁，确保两个CPU的停止工作被正确排队和唤醒。包含针对两个CPU的停止接口和非阻塞式单CPU停止标记功能。",
          "similarity": 0.5723315477371216
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/stop_machine.c",
          "start_line": 401,
          "end_line": 502,
          "content": [
            "static bool queue_stop_cpus_work(const struct cpumask *cpumask,",
            "\t\t\t\t cpu_stop_fn_t fn, void *arg,",
            "\t\t\t\t struct cpu_stop_done *done)",
            "{",
            "\tstruct cpu_stop_work *work;",
            "\tunsigned int cpu;",
            "\tbool queued = false;",
            "",
            "\t/*",
            "\t * Disable preemption while queueing to avoid getting",
            "\t * preempted by a stopper which might wait for other stoppers",
            "\t * to enter @fn which can lead to deadlock.",
            "\t */",
            "\tpreempt_disable();",
            "\tstop_cpus_in_progress = true;",
            "\tbarrier();",
            "\tfor_each_cpu(cpu, cpumask) {",
            "\t\twork = &per_cpu(cpu_stopper.stop_work, cpu);",
            "\t\twork->fn = fn;",
            "\t\twork->arg = arg;",
            "\t\twork->done = done;",
            "\t\twork->caller = _RET_IP_;",
            "\t\tif (cpu_stop_queue_work(cpu, work))",
            "\t\t\tqueued = true;",
            "\t}",
            "\tbarrier();",
            "\tstop_cpus_in_progress = false;",
            "\tpreempt_enable();",
            "",
            "\treturn queued;",
            "}",
            "static int __stop_cpus(const struct cpumask *cpumask,",
            "\t\t       cpu_stop_fn_t fn, void *arg)",
            "{",
            "\tstruct cpu_stop_done done;",
            "",
            "\tcpu_stop_init_done(&done, cpumask_weight(cpumask));",
            "\tif (!queue_stop_cpus_work(cpumask, fn, arg, &done))",
            "\t\treturn -ENOENT;",
            "\twait_for_completion(&done.completion);",
            "\treturn done.ret;",
            "}",
            "static int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg)",
            "{",
            "\tint ret;",
            "",
            "\t/* static works are used, process one request at a time */",
            "\tmutex_lock(&stop_cpus_mutex);",
            "\tret = __stop_cpus(cpumask, fn, arg);",
            "\tmutex_unlock(&stop_cpus_mutex);",
            "\treturn ret;",
            "}",
            "static int cpu_stop_should_run(unsigned int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "\tunsigned long flags;",
            "\tint run;",
            "",
            "\traw_spin_lock_irqsave(&stopper->lock, flags);",
            "\trun = !list_empty(&stopper->works);",
            "\traw_spin_unlock_irqrestore(&stopper->lock, flags);",
            "\treturn run;",
            "}",
            "static void cpu_stopper_thread(unsigned int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "\tstruct cpu_stop_work *work;",
            "",
            "repeat:",
            "\twork = NULL;",
            "\traw_spin_lock_irq(&stopper->lock);",
            "\tif (!list_empty(&stopper->works)) {",
            "\t\twork = list_first_entry(&stopper->works,",
            "\t\t\t\t\tstruct cpu_stop_work, list);",
            "\t\tlist_del_init(&work->list);",
            "\t}",
            "\traw_spin_unlock_irq(&stopper->lock);",
            "",
            "\tif (work) {",
            "\t\tcpu_stop_fn_t fn = work->fn;",
            "\t\tvoid *arg = work->arg;",
            "\t\tstruct cpu_stop_done *done = work->done;",
            "\t\tint ret;",
            "",
            "\t\t/* cpu stop callbacks must not sleep, make in_atomic() == T */",
            "\t\tstopper->caller = work->caller;",
            "\t\tstopper->fn = fn;",
            "\t\tpreempt_count_inc();",
            "\t\tret = fn(arg);",
            "\t\tif (done) {",
            "\t\t\tif (ret)",
            "\t\t\t\tdone->ret = ret;",
            "\t\t\tcpu_stop_signal_done(done);",
            "\t\t}",
            "\t\tpreempt_count_dec();",
            "\t\tstopper->fn = NULL;",
            "\t\tstopper->caller = 0;",
            "\t\tWARN_ONCE(preempt_count(),",
            "\t\t\t  \"cpu_stop: %ps(%p) leaked preempt count\\n\", fn, arg);",
            "\t\tgoto repeat;",
            "\t}",
            "}"
          ],
          "function_name": "queue_stop_cpus_work, __stop_cpus, stop_cpus, cpu_stop_should_run, cpu_stopper_thread",
          "description": "实现批量CPU停止的中枢逻辑，通过互斥锁保证串行化处理。包含工作分发、停止执行、状态追踪等功能，支持通用CPU掩码的停止操作，并提供预处理检查和结果收集机制。",
          "similarity": 0.564412534236908
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/stop_machine.c",
          "start_line": 56,
          "end_line": 201,
          "content": [
            "void print_stop_info(const char *log_lvl, struct task_struct *task)",
            "{",
            "\t/*",
            "\t * If @task is a stopper task, it cannot migrate and task_cpu() is",
            "\t * stable.",
            "\t */",
            "\tstruct cpu_stopper *stopper = per_cpu_ptr(&cpu_stopper, task_cpu(task));",
            "",
            "\tif (task != stopper->thread)",
            "\t\treturn;",
            "",
            "\tprintk(\"%sStopper: %pS <- %pS\\n\", log_lvl, stopper->fn, (void *)stopper->caller);",
            "}",
            "static void cpu_stop_init_done(struct cpu_stop_done *done, unsigned int nr_todo)",
            "{",
            "\tmemset(done, 0, sizeof(*done));",
            "\tatomic_set(&done->nr_todo, nr_todo);",
            "\tinit_completion(&done->completion);",
            "}",
            "static void cpu_stop_signal_done(struct cpu_stop_done *done)",
            "{",
            "\tif (atomic_dec_and_test(&done->nr_todo))",
            "\t\tcomplete(&done->completion);",
            "}",
            "static void __cpu_stop_queue_work(struct cpu_stopper *stopper,",
            "\t\t\t\t  struct cpu_stop_work *work)",
            "{",
            "\tlist_add_tail(&work->list, &stopper->works);",
            "}",
            "static bool cpu_stop_queue_work(unsigned int cpu, struct cpu_stop_work *work)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "\tunsigned long flags;",
            "\tbool enabled;",
            "",
            "\tpreempt_disable();",
            "\traw_spin_lock_irqsave(&stopper->lock, flags);",
            "\tenabled = stopper->enabled;",
            "\tif (enabled)",
            "\t\t__cpu_stop_queue_work(stopper, work);",
            "\telse if (work->done)",
            "\t\tcpu_stop_signal_done(work->done);",
            "\traw_spin_unlock_irqrestore(&stopper->lock, flags);",
            "",
            "\tif (enabled)",
            "\t\twake_up_process(stopper->thread);",
            "\tpreempt_enable();",
            "",
            "\treturn enabled;",
            "}",
            "int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg)",
            "{",
            "\tstruct cpu_stop_done done;",
            "\tstruct cpu_stop_work work = { .fn = fn, .arg = arg, .done = &done, .caller = _RET_IP_ };",
            "",
            "\tcpu_stop_init_done(&done, 1);",
            "\tif (!cpu_stop_queue_work(cpu, &work))",
            "\t\treturn -ENOENT;",
            "\t/*",
            "\t * In case @cpu == smp_proccessor_id() we can avoid a sleep+wakeup",
            "\t * cycle by doing a preemption:",
            "\t */",
            "\tcond_resched();",
            "\twait_for_completion(&done.completion);",
            "\treturn done.ret;",
            "}",
            "static void set_state(struct multi_stop_data *msdata,",
            "\t\t      enum multi_stop_state newstate)",
            "{",
            "\t/* Reset ack counter. */",
            "\tatomic_set(&msdata->thread_ack, msdata->num_threads);",
            "\tsmp_wmb();",
            "\tWRITE_ONCE(msdata->state, newstate);",
            "}",
            "static void ack_state(struct multi_stop_data *msdata)",
            "{",
            "\tif (atomic_dec_and_test(&msdata->thread_ack))",
            "\t\tset_state(msdata, msdata->state + 1);",
            "}",
            "notrace void __weak stop_machine_yield(const struct cpumask *cpumask)",
            "{",
            "\tcpu_relax();",
            "}",
            "static int multi_cpu_stop(void *data)",
            "{",
            "\tstruct multi_stop_data *msdata = data;",
            "\tenum multi_stop_state newstate, curstate = MULTI_STOP_NONE;",
            "\tint cpu = smp_processor_id(), err = 0;",
            "\tconst struct cpumask *cpumask;",
            "\tunsigned long flags;",
            "\tbool is_active;",
            "",
            "\t/*",
            "\t * When called from stop_machine_from_inactive_cpu(), irq might",
            "\t * already be disabled.  Save the state and restore it on exit.",
            "\t */",
            "\tlocal_save_flags(flags);",
            "",
            "\tif (!msdata->active_cpus) {",
            "\t\tcpumask = cpu_online_mask;",
            "\t\tis_active = cpu == cpumask_first(cpumask);",
            "\t} else {",
            "\t\tcpumask = msdata->active_cpus;",
            "\t\tis_active = cpumask_test_cpu(cpu, cpumask);",
            "\t}",
            "",
            "\t/* Simple state machine */",
            "\tdo {",
            "\t\t/* Chill out and ensure we re-read multi_stop_state. */",
            "\t\tstop_machine_yield(cpumask);",
            "\t\tnewstate = READ_ONCE(msdata->state);",
            "\t\tif (newstate != curstate) {",
            "\t\t\tcurstate = newstate;",
            "\t\t\tswitch (curstate) {",
            "\t\t\tcase MULTI_STOP_DISABLE_IRQ:",
            "\t\t\t\tlocal_irq_disable();",
            "\t\t\t\thard_irq_disable();",
            "#ifdef CONFIG_ARM64",
            "\t\t\t\tsdei_mask_local_cpu();",
            "#endif",
            "\t\t\t\tbreak;",
            "\t\t\tcase MULTI_STOP_RUN:",
            "\t\t\t\tif (is_active)",
            "\t\t\t\t\terr = msdata->fn(msdata->data);",
            "\t\t\t\tbreak;",
            "\t\t\tdefault:",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t\tack_state(msdata);",
            "\t\t} else if (curstate > MULTI_STOP_PREPARE) {",
            "\t\t\t/*",
            "\t\t\t * At this stage all other CPUs we depend on must spin",
            "\t\t\t * in the same loop. Any reason for hard-lockup should",
            "\t\t\t * be detected and reported on their side.",
            "\t\t\t */",
            "\t\t\ttouch_nmi_watchdog();",
            "\t\t}",
            "\t\trcu_momentary_dyntick_idle();",
            "\t} while (curstate != MULTI_STOP_EXIT);",
            "",
            "#ifdef CONFIG_ARM64",
            "\tsdei_unmask_local_cpu();",
            "#endif",
            "\tlocal_irq_restore(flags);",
            "\treturn err;",
            "}"
          ],
          "function_name": "print_stop_info, cpu_stop_init_done, cpu_stop_signal_done, __cpu_stop_queue_work, cpu_stop_queue_work, stop_one_cpu, set_state, ack_state, stop_machine_yield, multi_cpu_stop",
          "description": "实现了停止操作的核心控制逻辑，包括工作队列管理、状态同步、单CPU停止处理及多CPU状态机。提供打印停止信息、初始化完成状态、信号完成、排队工作、单CPU停止、状态切换等辅助函数。",
          "similarity": 0.5267167687416077
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/stop_machine.c",
          "start_line": 687,
          "end_line": 716,
          "content": [
            "int stop_machine_from_inactive_cpu(cpu_stop_fn_t fn, void *data,",
            "\t\t\t\t  const struct cpumask *cpus)",
            "{",
            "\tstruct multi_stop_data msdata = { .fn = fn, .data = data,",
            "\t\t\t\t\t    .active_cpus = cpus };",
            "\tstruct cpu_stop_done done;",
            "\tint ret;",
            "",
            "\t/* Local CPU must be inactive and CPU hotplug in progress. */",
            "\tBUG_ON(cpu_active(raw_smp_processor_id()));",
            "\tmsdata.num_threads = num_active_cpus() + 1;\t/* +1 for local */",
            "",
            "\t/* No proper task established and can't sleep - busy wait for lock. */",
            "\twhile (!mutex_trylock(&stop_cpus_mutex))",
            "\t\tcpu_relax();",
            "",
            "\t/* Schedule work on other CPUs and execute directly for local CPU */",
            "\tset_state(&msdata, MULTI_STOP_PREPARE);",
            "\tcpu_stop_init_done(&done, num_active_cpus());",
            "\tqueue_stop_cpus_work(cpu_active_mask, multi_cpu_stop, &msdata,",
            "\t\t\t     &done);",
            "\tret = multi_cpu_stop(&msdata);",
            "",
            "\t/* Busy wait for completion. */",
            "\twhile (!completion_done(&done.completion))",
            "\t\tcpu_relax();",
            "",
            "\tmutex_unlock(&stop_cpus_mutex);",
            "\treturn ret ?: done.ret;",
            "}"
          ],
          "function_name": "stop_machine_from_inactive_cpu",
          "description": "该函数用于在非活跃CPU上协调多CPU的停止操作，确保在CPU热插拔期间正确执行停止回调函数。  \n通过获取互斥锁、异步调度任务并在本地直接执行，最终阻塞等待所有停止操作完成。  \n依赖未显示的辅助函数（如`queue_stop_cpus_work`和`multi_cpu_stop`），上下文可能存在不完整情况。",
          "similarity": 0.5098245143890381
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/stop_machine.c",
          "start_line": 536,
          "end_line": 641,
          "content": [
            "void stop_machine_park(int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "\t/*",
            "\t * Lockless. cpu_stopper_thread() will take stopper->lock and flush",
            "\t * the pending works before it parks, until then it is fine to queue",
            "\t * the new works.",
            "\t */",
            "\tstopper->enabled = false;",
            "\tkthread_park(stopper->thread);",
            "}",
            "static void cpu_stop_create(unsigned int cpu)",
            "{",
            "\tsched_set_stop_task(cpu, per_cpu(cpu_stopper.thread, cpu));",
            "}",
            "static void cpu_stop_park(unsigned int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "",
            "\tWARN_ON(!list_empty(&stopper->works));",
            "}",
            "void stop_machine_unpark(int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "",
            "\tstopper->enabled = true;",
            "\tkthread_unpark(stopper->thread);",
            "}",
            "static int __init cpu_stop_init(void)",
            "{",
            "\tunsigned int cpu;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "",
            "\t\traw_spin_lock_init(&stopper->lock);",
            "\t\tINIT_LIST_HEAD(&stopper->works);",
            "\t}",
            "",
            "\tBUG_ON(smpboot_register_percpu_thread(&cpu_stop_threads));",
            "\tstop_machine_unpark(raw_smp_processor_id());",
            "\tstop_machine_initialized = true;",
            "\treturn 0;",
            "}",
            "int stop_machine_cpuslocked(cpu_stop_fn_t fn, void *data,",
            "\t\t\t    const struct cpumask *cpus)",
            "{",
            "\tstruct multi_stop_data msdata = {",
            "\t\t.fn = fn,",
            "\t\t.data = data,",
            "\t\t.num_threads = num_online_cpus(),",
            "\t\t.active_cpus = cpus,",
            "\t};",
            "",
            "\tlockdep_assert_cpus_held();",
            "",
            "\tif (!stop_machine_initialized) {",
            "\t\t/*",
            "\t\t * Handle the case where stop_machine() is called",
            "\t\t * early in boot before stop_machine() has been",
            "\t\t * initialized.",
            "\t\t */",
            "\t\tunsigned long flags;",
            "\t\tint ret;",
            "",
            "\t\tWARN_ON_ONCE(msdata.num_threads != 1);",
            "",
            "\t\tlocal_irq_save(flags);",
            "\t\thard_irq_disable();",
            "\t\tret = (*fn)(data);",
            "\t\tlocal_irq_restore(flags);",
            "",
            "\t\treturn ret;",
            "\t}",
            "",
            "\t/* Set the initial state and stop all online cpus. */",
            "\tset_state(&msdata, MULTI_STOP_PREPARE);",
            "\treturn stop_cpus(cpu_online_mask, multi_cpu_stop, &msdata);",
            "}",
            "int stop_machine(cpu_stop_fn_t fn, void *data, const struct cpumask *cpus)",
            "{",
            "\tint ret;",
            "",
            "\t/* No CPUs can come up or down during this. */",
            "\tcpus_read_lock();",
            "\tret = stop_machine_cpuslocked(fn, data, cpus);",
            "\tcpus_read_unlock();",
            "\treturn ret;",
            "}",
            "int stop_core_cpuslocked(unsigned int cpu, cpu_stop_fn_t fn, void *data)",
            "{",
            "\tconst struct cpumask *smt_mask = cpu_smt_mask(cpu);",
            "",
            "\tstruct multi_stop_data msdata = {",
            "\t\t.fn = fn,",
            "\t\t.data = data,",
            "\t\t.num_threads = cpumask_weight(smt_mask),",
            "\t\t.active_cpus = smt_mask,",
            "\t};",
            "",
            "\tlockdep_assert_cpus_held();",
            "",
            "\t/* Set the initial state and stop all online cpus. */",
            "\tset_state(&msdata, MULTI_STOP_PREPARE);",
            "\treturn stop_cpus(smt_mask, multi_cpu_stop, &msdata);",
            "}"
          ],
          "function_name": "stop_machine_park, cpu_stop_create, cpu_stop_park, stop_machine_unpark, cpu_stop_init, stop_machine_cpuslocked, stop_machine, stop_core_cpuslocked",
          "description": "负责停止器线程的生命周期管理和初始化。包含线程创建、挂起/恢复操作、核心初始化函数，以及带锁的CPU停止接口。提供针对特定CPU核心的停止功能和早期启动阶段的降级处理路径。",
          "similarity": 0.5017076730728149
        }
      ]
    }
  ]
}