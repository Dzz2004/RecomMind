{
  "query": "memory fragmentation",
  "timestamp": "2025-12-26 00:08:44",
  "retrieved_files": [
    {
      "source_file": "mm/compaction.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:44:52\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `compaction.c`\n\n---\n\n# compaction.c 技术文档\n\n## 1. 文件概述\n\n`compaction.c` 是 Linux 内核内存管理子系统中实现**内存压缩（Memory Compaction）**功能的核心文件。其主要目标是**减少外部碎片（external fragmentation）**，通过迁移可移动页面，将物理内存中的空闲页聚集形成连续的大块内存区域，从而满足高阶（high-order）内存分配请求（如透明大页 THP 或 HugeTLB）。该机制高度依赖页面迁移（page migration）来完成实际的页面移动工作。\n\n## 2. 核心功能\n\n### 主要函数\n- **`PageMovable()` / `__SetPageMovable()` / `__ClearPageMovable()`**: 管理页面的可移动性标记，用于标识页面是否可通过注册的 `movable_operations` 进行迁移。\n- **`defer_compaction()` / `compaction_deferred()` / `compaction_defer_reset()`**: 实现**压缩延迟（deferred compaction）**机制，避免在压缩失败后频繁重试，提升系统性能。\n- **`compaction_restarting()`**: 判断是否因多次失败后重新启动压缩流程。\n- **`isolation_suitable()`**: 检查指定 pageblock 是否适合进行页面隔离（用于迁移）。\n- **`reset_cached_positions()`**: 重置压缩控制结构中缓存的扫描位置（迁移源和空闲目标页的起始 PFN）。\n- **`release_free_list()`**: 将临时空闲页面列表中的页面释放回伙伴系统。\n- **`skip_offline_sections()` / `skip_offline_sections_reverse()`**: 在 SPARSEMEM 内存模型下跳过离线内存段。\n\n### 关键数据结构与宏\n- **`struct compact_control`**: 压缩操作的控制上下文（定义在 `internal.h` 中），包含扫描范围、迁移/空闲页面列表等。\n- **`COMPACTION_HPAGE_ORDER`**: 用于计算节点/区域“碎片分数（fragmentation score）”的参考阶数，通常为透明大页或 HugeTLB 的阶数。\n- **`COMPACT_MAX_DEFER_SHIFT`**: 压缩延迟的最大次数（64 次）。\n- **`zone->compact_*` 字段**: 包括 `compact_considered`, `compact_defer_shift`, `compact_order_failed`, `compact_cached_*_pfn` 等，用于跟踪压缩状态和优化扫描。\n\n## 3. 关键实现\n\n### 内存压缩流程\n1. **扫描阶段**：从区域两端向中间扫描：\n   - **迁移源扫描器（migrate scanner）**：从低地址向高地址扫描，寻找可迁移的页面。\n   - **空闲目标扫描器（free scanner）**：从高地址向低地址扫描，寻找空闲页面块。\n2. **页面隔离**：将找到的可迁移页面加入迁移列表，空闲页面加入空闲列表。\n3. **页面迁移**：调用 `migrate_pages()` 将迁移列表中的页面移动到空闲列表提供的目标位置。\n4. **结果处理**：迁移成功后，原位置变为空闲，可能形成更大的连续空闲块；失败则回滚。\n\n### 压缩延迟机制（Deferred Compaction）\n- 当压缩未能成功分配指定 `order` 的页面时，调用 `defer_compaction()` 增加延迟计数器 `compact_defer_shift`。\n- 后续分配请求会通过 `compaction_deferred()` 检查是否应跳过压缩（基于 `compact_considered` 计数和 `defer_limit = 1 << compact_defer_shift`）。\n- 若分配成功或预期成功，则通过 `compaction_defer_reset()` 重置延迟状态。\n- 当延迟达到最大值（`COMPACT_MAX_DEFER_SHIFT`）且考虑次数足够多时，`compaction_restarting()` 返回 true，强制重启完整压缩流程。\n\n### 碎片分数与主动压缩\n- 通过 `COMPACTION_HPAGE_ORDER` 定义的阶数评估区域的外部碎片程度。\n- 主动压缩（proactive compaction）定期（`HPAGE_FRAG_CHECK_INTERVAL_MSEC = 500ms`）检查碎片分数，并在需要时触发后台压缩。\n- `is_via_compact_memory()` 用于识别通过 `/proc/sys/vm/compact_memory` 等接口发起的全量压缩请求（`order = -1`）。\n\n### 页面可移动性管理\n- `__SetPageMovable()` 将 `movable_operations` 指针编码到 `page->mapping` 中，并设置 `PAGE_MAPPING_MOVABLE` 标志。\n- `PageMovable()` 验证页面是否被正确标记为可移动，并确保其操作集有效。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm.h>`, `internal.h`, `mm_inline.h` 提供的伙伴系统、页面分配/释放、zone 管理等基础功能。\n- **页面迁移**：紧密集成 `<linux/migrate.h>`，压缩的核心操作由 `migrate_pages()` 完成。\n- **内存模型**：针对 `CONFIG_SPARSEMEM` 提供离线内存段跳过逻辑。\n- **大页支持**：根据 `CONFIG_TRANSPARENT_HUGEPAGE` 或 `CONFIG_HUGETLBFS` 确定 `COMPACTION_HPAGE_ORDER`。\n- **调试与追踪**：使用 `kasan.h`, `page_owner.h` 进行调试；通过 `trace/events/compaction.h` 提供 ftrace 事件。\n- **系统调用与接口**：通过 sysctl (`/proc/sys/vm/`) 和 sysfs (`/sys/devices/system/node/`) 暴露用户空间控制接口。\n- **进程与调度**：使用 `kthread.h`, `freezer.h` 管理后台压缩线程；`psi.h` 用于压力状态监控。\n\n## 5. 使用场景\n\n1. **高阶内存分配失败时**：当 `alloc_pages()` 请求高阶页面（如 order ≥ 3）失败时，内核会尝试同步内存压缩以满足请求。\n2. **透明大页（THP）分配**：THP 需要连续的 2MB 物理内存，压缩是满足此类请求的关键机制。\n3. **主动后台压缩**：通过 `vm.compaction_proactiveness` sysctl 参数配置，内核定期评估内存碎片并主动压缩，预防分配延迟。\n4. **用户空间触发**：管理员可通过写入 `/proc/sys/vm/compact_memory` 或特定 NUMA 节点的 `compact` sysfs 文件，手动触发全量内存压缩。\n5. **CMA（Contiguous Memory Allocator）**：在 CMA 区域分配大块连续内存前，使用压缩机制迁移占用页面以腾出空间（需 `CONFIG_CMA`）。",
      "similarity": 0.5661789774894714,
      "chunks": [
        {
          "chunk_id": 12,
          "file_path": "mm/compaction.c",
          "start_line": 2200,
          "end_line": 2344,
          "content": [
            "static unsigned int fragmentation_score_zone(struct zone *zone)",
            "{",
            "\treturn extfrag_for_order(zone, COMPACTION_HPAGE_ORDER);",
            "}",
            "static unsigned int fragmentation_score_zone_weighted(struct zone *zone)",
            "{",
            "\tunsigned long score;",
            "",
            "\tscore = zone->present_pages * fragmentation_score_zone(zone);",
            "\treturn div64_ul(score, zone->zone_pgdat->node_present_pages + 1);",
            "}",
            "static unsigned int fragmentation_score_node(pg_data_t *pgdat)",
            "{",
            "\tunsigned int score = 0;",
            "\tint zoneid;",
            "",
            "\tfor (zoneid = 0; zoneid < MAX_NR_ZONES; zoneid++) {",
            "\t\tstruct zone *zone;",
            "",
            "\t\tzone = &pgdat->node_zones[zoneid];",
            "\t\tif (!populated_zone(zone))",
            "\t\t\tcontinue;",
            "\t\tscore += fragmentation_score_zone_weighted(zone);",
            "\t}",
            "",
            "\treturn score;",
            "}",
            "static unsigned int fragmentation_score_wmark(bool low)",
            "{",
            "\tunsigned int wmark_low;",
            "",
            "\t/*",
            "\t * Cap the low watermark to avoid excessive compaction",
            "\t * activity in case a user sets the proactiveness tunable",
            "\t * close to 100 (maximum).",
            "\t */",
            "\twmark_low = max(100U - sysctl_compaction_proactiveness, 5U);",
            "\treturn low ? wmark_low : min(wmark_low + 10, 100U);",
            "}",
            "static bool should_proactive_compact_node(pg_data_t *pgdat)",
            "{",
            "\tint wmark_high;",
            "",
            "\tif (!sysctl_compaction_proactiveness || kswapd_is_running(pgdat))",
            "\t\treturn false;",
            "",
            "\twmark_high = fragmentation_score_wmark(false);",
            "\treturn fragmentation_score_node(pgdat) > wmark_high;",
            "}",
            "static enum compact_result __compact_finished(struct compact_control *cc)",
            "{",
            "\tunsigned int order;",
            "\tconst int migratetype = cc->migratetype;",
            "\tint ret;",
            "",
            "\t/* Compaction run completes if the migrate and free scanner meet */",
            "\tif (compact_scanners_met(cc)) {",
            "\t\t/* Let the next compaction start anew. */",
            "\t\treset_cached_positions(cc->zone);",
            "",
            "\t\t/*",
            "\t\t * Mark that the PG_migrate_skip information should be cleared",
            "\t\t * by kswapd when it goes to sleep. kcompactd does not set the",
            "\t\t * flag itself as the decision to be clear should be directly",
            "\t\t * based on an allocation request.",
            "\t\t */",
            "\t\tif (cc->direct_compaction)",
            "\t\t\tcc->zone->compact_blockskip_flush = true;",
            "",
            "\t\tif (cc->whole_zone)",
            "\t\t\treturn COMPACT_COMPLETE;",
            "\t\telse",
            "\t\t\treturn COMPACT_PARTIAL_SKIPPED;",
            "\t}",
            "",
            "\tif (cc->proactive_compaction) {",
            "\t\tint score, wmark_low;",
            "\t\tpg_data_t *pgdat;",
            "",
            "\t\tpgdat = cc->zone->zone_pgdat;",
            "\t\tif (kswapd_is_running(pgdat))",
            "\t\t\treturn COMPACT_PARTIAL_SKIPPED;",
            "",
            "\t\tscore = fragmentation_score_zone(cc->zone);",
            "\t\twmark_low = fragmentation_score_wmark(true);",
            "",
            "\t\tif (score > wmark_low)",
            "\t\t\tret = COMPACT_CONTINUE;",
            "\t\telse",
            "\t\t\tret = COMPACT_SUCCESS;",
            "",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (is_via_compact_memory(cc->order))",
            "\t\treturn COMPACT_CONTINUE;",
            "",
            "\t/*",
            "\t * Always finish scanning a pageblock to reduce the possibility of",
            "\t * fallbacks in the future. This is particularly important when",
            "\t * migration source is unmovable/reclaimable but it's not worth",
            "\t * special casing.",
            "\t */",
            "\tif (!pageblock_aligned(cc->migrate_pfn))",
            "\t\treturn COMPACT_CONTINUE;",
            "",
            "\t/* Direct compactor: Is a suitable page free? */",
            "\tret = COMPACT_NO_SUITABLE_PAGE;",
            "\tfor (order = cc->order; order < NR_PAGE_ORDERS; order++) {",
            "\t\tstruct free_area *area = &cc->zone->free_area[order];",
            "\t\tbool can_steal;",
            "",
            "\t\t/* Job done if page is free of the right migratetype */",
            "\t\tif (!free_area_empty(area, migratetype))",
            "\t\t\treturn COMPACT_SUCCESS;",
            "",
            "#ifdef CONFIG_CMA",
            "\t\t/* MIGRATE_MOVABLE can fallback on MIGRATE_CMA */",
            "\t\tif (migratetype == MIGRATE_MOVABLE &&",
            "\t\t\t!free_area_empty(area, MIGRATE_CMA))",
            "\t\t\treturn COMPACT_SUCCESS;",
            "#endif",
            "\t\t/*",
            "\t\t * Job done if allocation would steal freepages from",
            "\t\t * other migratetype buddy lists.",
            "\t\t */",
            "\t\tif (find_suitable_fallback(area, order, migratetype,",
            "\t\t\t\t\t\ttrue, &can_steal) != -1)",
            "\t\t\t/*",
            "\t\t\t * Movable pages are OK in any pageblock. If we are",
            "\t\t\t * stealing for a non-movable allocation, make sure",
            "\t\t\t * we finish compacting the current pageblock first",
            "\t\t\t * (which is assured by the above migrate_pfn align",
            "\t\t\t * check) so it is as free as possible and we won't",
            "\t\t\t * have to steal another one soon.",
            "\t\t\t */",
            "\t\t\treturn COMPACT_SUCCESS;",
            "\t}",
            "",
            "out:",
            "\tif (cc->contended || fatal_signal_pending(current))",
            "\t\tret = COMPACT_CONTENDED;",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "fragmentation_score_zone, fragmentation_score_zone_weighted, fragmentation_score_node, fragmentation_score_wmark, should_proactive_compact_node, __compact_finished",
          "description": "fragmentation_score_zone计算区碎片评分，fragmentation_score_zone_weighted加权计算节点总分，fragmentation_score_wmark设置低水位阈值，should_proactive_compact_node根据评分判断是否需要主动压缩",
          "similarity": 0.5588366985321045
        },
        {
          "chunk_id": 0,
          "file_path": "mm/compaction.c",
          "start_line": 1,
          "end_line": 33,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * linux/mm/compaction.c",
            " *",
            " * Memory compaction for the reduction of external fragmentation. Note that",
            " * this heavily depends upon page migration to do all the real heavy",
            " * lifting",
            " *",
            " * Copyright IBM Corp. 2007-2010 Mel Gorman <mel@csn.ul.ie>",
            " */",
            "#include <linux/cpu.h>",
            "#include <linux/swap.h>",
            "#include <linux/migrate.h>",
            "#include <linux/compaction.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/page-isolation.h>",
            "#include <linux/kasan.h>",
            "#include <linux/kthread.h>",
            "#include <linux/freezer.h>",
            "#include <linux/page_owner.h>",
            "#include <linux/psi.h>",
            "#include \"internal.h\"",
            "",
            "#ifdef CONFIG_COMPACTION",
            "/*",
            " * Fragmentation score check interval for proactive compaction purposes.",
            " */",
            "#define HPAGE_FRAG_CHECK_INTERVAL_MSEC\t(500)",
            ""
          ],
          "function_name": null,
          "description": "声明内存压缩模块的头文件，包含相关依赖和定义，启用CONFIG_COMPACTION配置项，定义HPAGE_FRAG_CHECK_INTERVAL_MSEC常量用于主动压缩时间间隔",
          "similarity": 0.534339964389801
        },
        {
          "chunk_id": 10,
          "file_path": "mm/compaction.c",
          "start_line": 1888,
          "end_line": 2042,
          "content": [
            "static void compaction_free(struct folio *dst, unsigned long data)",
            "{",
            "\tstruct compact_control *cc = (struct compact_control *)data;",
            "\tint order = folio_order(dst);",
            "\tstruct page *page = &dst->page;",
            "",
            "\tif (folio_put_testzero(dst)) {",
            "\t\tfree_pages_prepare(page, order);",
            "\t\tlist_add(&dst->lru, &cc->freepages[order]);",
            "\t\tcc->nr_freepages += 1 << order;",
            "\t}",
            "\tcc->nr_migratepages += 1 << order;",
            "\t/*",
            "\t * someone else has referenced the page, we cannot take it back to our",
            "\t * free list.",
            "\t */",
            "}",
            "static inline void",
            "update_fast_start_pfn(struct compact_control *cc, unsigned long pfn)",
            "{",
            "\tif (cc->fast_start_pfn == ULONG_MAX)",
            "\t\treturn;",
            "",
            "\tif (!cc->fast_start_pfn)",
            "\t\tcc->fast_start_pfn = pfn;",
            "",
            "\tcc->fast_start_pfn = min(cc->fast_start_pfn, pfn);",
            "}",
            "static inline unsigned long",
            "reinit_migrate_pfn(struct compact_control *cc)",
            "{",
            "\tif (!cc->fast_start_pfn || cc->fast_start_pfn == ULONG_MAX)",
            "\t\treturn cc->migrate_pfn;",
            "",
            "\tcc->migrate_pfn = cc->fast_start_pfn;",
            "\tcc->fast_start_pfn = ULONG_MAX;",
            "",
            "\treturn cc->migrate_pfn;",
            "}",
            "static unsigned long fast_find_migrateblock(struct compact_control *cc)",
            "{",
            "\tunsigned int limit = freelist_scan_limit(cc);",
            "\tunsigned int nr_scanned = 0;",
            "\tunsigned long distance;",
            "\tunsigned long pfn = cc->migrate_pfn;",
            "\tunsigned long high_pfn;",
            "\tint order;",
            "\tbool found_block = false;",
            "",
            "\t/* Skip hints are relied on to avoid repeats on the fast search */",
            "\tif (cc->ignore_skip_hint)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * If the pageblock should be finished then do not select a different",
            "\t * pageblock.",
            "\t */",
            "\tif (cc->finish_pageblock)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * If the migrate_pfn is not at the start of a zone or the start",
            "\t * of a pageblock then assume this is a continuation of a previous",
            "\t * scan restarted due to COMPACT_CLUSTER_MAX.",
            "\t */",
            "\tif (pfn != cc->zone->zone_start_pfn && pfn != pageblock_start_pfn(pfn))",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * For smaller orders, just linearly scan as the number of pages",
            "\t * to migrate should be relatively small and does not necessarily",
            "\t * justify freeing up a large block for a small allocation.",
            "\t */",
            "\tif (cc->order <= PAGE_ALLOC_COSTLY_ORDER)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * Only allow kcompactd and direct requests for movable pages to",
            "\t * quickly clear out a MOVABLE pageblock for allocation. This",
            "\t * reduces the risk that a large movable pageblock is freed for",
            "\t * an unmovable/reclaimable small allocation.",
            "\t */",
            "\tif (cc->direct_compaction && cc->migratetype != MIGRATE_MOVABLE)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * When starting the migration scanner, pick any pageblock within the",
            "\t * first half of the search space. Otherwise try and pick a pageblock",
            "\t * within the first eighth to reduce the chances that a migration",
            "\t * target later becomes a source.",
            "\t */",
            "\tdistance = (cc->free_pfn - cc->migrate_pfn) >> 1;",
            "\tif (cc->migrate_pfn != cc->zone->zone_start_pfn)",
            "\t\tdistance >>= 2;",
            "\thigh_pfn = pageblock_start_pfn(cc->migrate_pfn + distance);",
            "",
            "\tfor (order = cc->order - 1;",
            "\t     order >= PAGE_ALLOC_COSTLY_ORDER && !found_block && nr_scanned < limit;",
            "\t     order--) {",
            "\t\tstruct free_area *area = &cc->zone->free_area[order];",
            "\t\tstruct list_head *freelist;",
            "\t\tunsigned long flags;",
            "\t\tstruct page *freepage;",
            "",
            "\t\tif (!area->nr_free)",
            "\t\t\tcontinue;",
            "",
            "\t\tspin_lock_irqsave(&cc->zone->lock, flags);",
            "\t\tfreelist = &area->free_list[MIGRATE_MOVABLE];",
            "\t\tlist_for_each_entry(freepage, freelist, buddy_list) {",
            "\t\t\tunsigned long free_pfn;",
            "",
            "\t\t\tif (nr_scanned++ >= limit) {",
            "\t\t\t\tmove_freelist_tail(freelist, freepage);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "",
            "\t\t\tfree_pfn = page_to_pfn(freepage);",
            "\t\t\tif (free_pfn < high_pfn) {",
            "\t\t\t\t/*",
            "\t\t\t\t * Avoid if skipped recently. Ideally it would",
            "\t\t\t\t * move to the tail but even safe iteration of",
            "\t\t\t\t * the list assumes an entry is deleted, not",
            "\t\t\t\t * reordered.",
            "\t\t\t\t */",
            "\t\t\t\tif (get_pageblock_skip(freepage))",
            "\t\t\t\t\tcontinue;",
            "",
            "\t\t\t\t/* Reorder to so a future search skips recent pages */",
            "\t\t\t\tmove_freelist_tail(freelist, freepage);",
            "",
            "\t\t\t\tupdate_fast_start_pfn(cc, free_pfn);",
            "\t\t\t\tpfn = pageblock_start_pfn(free_pfn);",
            "\t\t\t\tif (pfn < cc->zone->zone_start_pfn)",
            "\t\t\t\t\tpfn = cc->zone->zone_start_pfn;",
            "\t\t\t\tcc->fast_search_fail = 0;",
            "\t\t\t\tfound_block = true;",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t}",
            "\t\tspin_unlock_irqrestore(&cc->zone->lock, flags);",
            "\t}",
            "",
            "\tcc->total_migrate_scanned += nr_scanned;",
            "",
            "\t/*",
            "\t * If fast scanning failed then use a cached entry for a page block",
            "\t * that had free pages as the basis for starting a linear scan.",
            "\t */",
            "\tif (!found_block) {",
            "\t\tcc->fast_search_fail++;",
            "\t\tpfn = reinit_migrate_pfn(cc);",
            "\t}",
            "\treturn pfn;",
            "}"
          ],
          "function_name": "compaction_free, update_fast_start_pfn, reinit_migrate_pfn, fast_find_migrateblock",
          "description": "实现内存碎片整理中页面释放与迁移扫描逻辑，compaction_free处理页面回收，update_fast_start_pfn维护快速扫描起点，reinit_migrate_pfn重置迁移扫描位置，fast_find_migrateblock寻找适合迁移的页块，优先考虑可移动类型且未被跳过的页块",
          "similarity": 0.52850341796875
        },
        {
          "chunk_id": 1,
          "file_path": "mm/compaction.c",
          "start_line": 34,
          "end_line": 141,
          "content": [
            "static inline void count_compact_event(enum vm_event_item item)",
            "{",
            "\tcount_vm_event(item);",
            "}",
            "static inline void count_compact_events(enum vm_event_item item, long delta)",
            "{",
            "\tcount_vm_events(item, delta);",
            "}",
            "static inline bool is_via_compact_memory(int order)",
            "{",
            "\treturn order == -1;",
            "}",
            "static inline bool is_via_compact_memory(int order) { return false; }",
            "static unsigned long release_free_list(struct list_head *freepages)",
            "{",
            "\tint order;",
            "\tunsigned long high_pfn = 0;",
            "",
            "\tfor (order = 0; order < NR_PAGE_ORDERS; order++) {",
            "\t\tstruct page *page, *next;",
            "",
            "\t\tlist_for_each_entry_safe(page, next, &freepages[order], lru) {",
            "\t\t\tunsigned long pfn = page_to_pfn(page);",
            "",
            "\t\t\tlist_del(&page->lru);",
            "\t\t\t/*",
            "\t\t\t * Convert free pages into post allocation pages, so",
            "\t\t\t * that we can free them via __free_page.",
            "\t\t\t */",
            "\t\t\tmark_allocated(page, order, __GFP_MOVABLE);",
            "\t\t\t__free_pages(page, order);",
            "\t\t\tif (pfn > high_pfn)",
            "\t\t\t\thigh_pfn = pfn;",
            "\t\t}",
            "\t}",
            "\treturn high_pfn;",
            "}",
            "bool PageMovable(struct page *page)",
            "{",
            "\tconst struct movable_operations *mops;",
            "",
            "\tVM_BUG_ON_PAGE(!PageLocked(page), page);",
            "\tif (!__PageMovable(page))",
            "\t\treturn false;",
            "",
            "\tmops = page_movable_ops(page);",
            "\tif (mops)",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "void __SetPageMovable(struct page *page, const struct movable_operations *mops)",
            "{",
            "\tVM_BUG_ON_PAGE(!PageLocked(page), page);",
            "\tVM_BUG_ON_PAGE((unsigned long)mops & PAGE_MAPPING_MOVABLE, page);",
            "\tpage->mapping = (void *)((unsigned long)mops | PAGE_MAPPING_MOVABLE);",
            "}",
            "void __ClearPageMovable(struct page *page)",
            "{",
            "\tVM_BUG_ON_PAGE(!PageMovable(page), page);",
            "\t/*",
            "\t * This page still has the type of a movable page, but it's",
            "\t * actually not movable any more.",
            "\t */",
            "\tpage->mapping = (void *)PAGE_MAPPING_MOVABLE;",
            "}",
            "static void defer_compaction(struct zone *zone, int order)",
            "{",
            "\tzone->compact_considered = 0;",
            "\tzone->compact_defer_shift++;",
            "",
            "\tif (order < zone->compact_order_failed)",
            "\t\tzone->compact_order_failed = order;",
            "",
            "\tif (zone->compact_defer_shift > COMPACT_MAX_DEFER_SHIFT)",
            "\t\tzone->compact_defer_shift = COMPACT_MAX_DEFER_SHIFT;",
            "",
            "\ttrace_mm_compaction_defer_compaction(zone, order);",
            "}",
            "static bool compaction_deferred(struct zone *zone, int order)",
            "{",
            "\tunsigned long defer_limit = 1UL << zone->compact_defer_shift;",
            "",
            "\tif (order < zone->compact_order_failed)",
            "\t\treturn false;",
            "",
            "\t/* Avoid possible overflow */",
            "\tif (++zone->compact_considered >= defer_limit) {",
            "\t\tzone->compact_considered = defer_limit;",
            "\t\treturn false;",
            "\t}",
            "",
            "\ttrace_mm_compaction_deferred(zone, order);",
            "",
            "\treturn true;",
            "}",
            "void compaction_defer_reset(struct zone *zone, int order,",
            "\t\tbool alloc_success)",
            "{",
            "\tif (alloc_success) {",
            "\t\tzone->compact_considered = 0;",
            "\t\tzone->compact_defer_shift = 0;",
            "\t}",
            "\tif (order >= zone->compact_order_failed)",
            "\t\tzone->compact_order_failed = order + 1;",
            "",
            "\ttrace_mm_compaction_defer_reset(zone, order);",
            "}"
          ],
          "function_name": "count_compact_event, count_compact_events, is_via_compact_memory, is_via_compact_memory, release_free_list, PageMovable, __SetPageMovable, __ClearPageMovable, defer_compaction, compaction_deferred, compaction_defer_reset",
          "description": "提供内存压缩事件计数、页面可移动性检测、空闲列表释放、延迟压缩逻辑及页面块隔离辅助函数，包含重复定义可能导致冲突",
          "similarity": 0.5166202783584595
        },
        {
          "chunk_id": 14,
          "file_path": "mm/compaction.c",
          "start_line": 2489,
          "end_line": 2740,
          "content": [
            "static enum compact_result",
            "compaction_suit_allocation_order(struct zone *zone, unsigned int order,",
            "\t\t\t\t int highest_zoneidx, unsigned int alloc_flags)",
            "{",
            "\tunsigned long watermark;",
            "",
            "\twatermark = wmark_pages(zone, alloc_flags & ALLOC_WMARK_MASK);",
            "\tif (zone_watermark_ok(zone, order, watermark, highest_zoneidx,",
            "\t\t\t      alloc_flags))",
            "\t\treturn COMPACT_SUCCESS;",
            "",
            "\tif (!compaction_suitable(zone, order, highest_zoneidx))",
            "\t\treturn COMPACT_SKIPPED;",
            "",
            "\treturn COMPACT_CONTINUE;",
            "}",
            "static enum compact_result",
            "compact_zone(struct compact_control *cc, struct capture_control *capc)",
            "{",
            "\tenum compact_result ret;",
            "\tunsigned long start_pfn = cc->zone->zone_start_pfn;",
            "\tunsigned long end_pfn = zone_end_pfn(cc->zone);",
            "\tunsigned long last_migrated_pfn;",
            "\tconst bool sync = cc->mode != MIGRATE_ASYNC;",
            "\tbool update_cached;",
            "\tunsigned int nr_succeeded = 0, nr_migratepages;",
            "\tint order;",
            "",
            "\t/*",
            "\t * These counters track activities during zone compaction.  Initialize",
            "\t * them before compacting a new zone.",
            "\t */",
            "\tcc->total_migrate_scanned = 0;",
            "\tcc->total_free_scanned = 0;",
            "\tcc->nr_migratepages = 0;",
            "\tcc->nr_freepages = 0;",
            "\tfor (order = 0; order < NR_PAGE_ORDERS; order++)",
            "\t\tINIT_LIST_HEAD(&cc->freepages[order]);",
            "\tINIT_LIST_HEAD(&cc->migratepages);",
            "",
            "\tcc->migratetype = gfp_migratetype(cc->gfp_mask);",
            "",
            "\tif (!is_via_compact_memory(cc->order)) {",
            "\t\tret = compaction_suit_allocation_order(cc->zone, cc->order,",
            "\t\t\t\t\t\t       cc->highest_zoneidx,",
            "\t\t\t\t\t\t       cc->alloc_flags);",
            "\t\tif (ret != COMPACT_CONTINUE)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\t/*",
            "\t * Clear pageblock skip if there were failures recently and compaction",
            "\t * is about to be retried after being deferred.",
            "\t */",
            "\tif (compaction_restarting(cc->zone, cc->order))",
            "\t\t__reset_isolation_suitable(cc->zone);",
            "",
            "\t/*",
            "\t * Setup to move all movable pages to the end of the zone. Used cached",
            "\t * information on where the scanners should start (unless we explicitly",
            "\t * want to compact the whole zone), but check that it is initialised",
            "\t * by ensuring the values are within zone boundaries.",
            "\t */",
            "\tcc->fast_start_pfn = 0;",
            "\tif (cc->whole_zone) {",
            "\t\tcc->migrate_pfn = start_pfn;",
            "\t\tcc->free_pfn = pageblock_start_pfn(end_pfn - 1);",
            "\t} else {",
            "\t\tcc->migrate_pfn = cc->zone->compact_cached_migrate_pfn[sync];",
            "\t\tcc->free_pfn = cc->zone->compact_cached_free_pfn;",
            "\t\tif (cc->free_pfn < start_pfn || cc->free_pfn >= end_pfn) {",
            "\t\t\tcc->free_pfn = pageblock_start_pfn(end_pfn - 1);",
            "\t\t\tcc->zone->compact_cached_free_pfn = cc->free_pfn;",
            "\t\t}",
            "\t\tif (cc->migrate_pfn < start_pfn || cc->migrate_pfn >= end_pfn) {",
            "\t\t\tcc->migrate_pfn = start_pfn;",
            "\t\t\tcc->zone->compact_cached_migrate_pfn[0] = cc->migrate_pfn;",
            "\t\t\tcc->zone->compact_cached_migrate_pfn[1] = cc->migrate_pfn;",
            "\t\t}",
            "",
            "\t\tif (cc->migrate_pfn <= cc->zone->compact_init_migrate_pfn)",
            "\t\t\tcc->whole_zone = true;",
            "\t}",
            "",
            "\tlast_migrated_pfn = 0;",
            "",
            "\t/*",
            "\t * Migrate has separate cached PFNs for ASYNC and SYNC* migration on",
            "\t * the basis that some migrations will fail in ASYNC mode. However,",
            "\t * if the cached PFNs match and pageblocks are skipped due to having",
            "\t * no isolation candidates, then the sync state does not matter.",
            "\t * Until a pageblock with isolation candidates is found, keep the",
            "\t * cached PFNs in sync to avoid revisiting the same blocks.",
            "\t */",
            "\tupdate_cached = !sync &&",
            "\t\tcc->zone->compact_cached_migrate_pfn[0] == cc->zone->compact_cached_migrate_pfn[1];",
            "",
            "\ttrace_mm_compaction_begin(cc, start_pfn, end_pfn, sync);",
            "",
            "\t/* lru_add_drain_all could be expensive with involving other CPUs */",
            "\tlru_add_drain();",
            "",
            "\twhile ((ret = compact_finished(cc)) == COMPACT_CONTINUE) {",
            "\t\tint err;",
            "\t\tunsigned long iteration_start_pfn = cc->migrate_pfn;",
            "",
            "\t\t/*",
            "\t\t * Avoid multiple rescans of the same pageblock which can",
            "\t\t * happen if a page cannot be isolated (dirty/writeback in",
            "\t\t * async mode) or if the migrated pages are being allocated",
            "\t\t * before the pageblock is cleared.  The first rescan will",
            "\t\t * capture the entire pageblock for migration. If it fails,",
            "\t\t * it'll be marked skip and scanning will proceed as normal.",
            "\t\t */",
            "\t\tcc->finish_pageblock = false;",
            "\t\tif (pageblock_start_pfn(last_migrated_pfn) ==",
            "\t\t    pageblock_start_pfn(iteration_start_pfn)) {",
            "\t\t\tcc->finish_pageblock = true;",
            "\t\t}",
            "",
            "rescan:",
            "\t\tswitch (isolate_migratepages(cc)) {",
            "\t\tcase ISOLATE_ABORT:",
            "\t\t\tret = COMPACT_CONTENDED;",
            "\t\t\tputback_movable_pages(&cc->migratepages);",
            "\t\t\tcc->nr_migratepages = 0;",
            "\t\t\tgoto out;",
            "\t\tcase ISOLATE_NONE:",
            "\t\t\tif (update_cached) {",
            "\t\t\t\tcc->zone->compact_cached_migrate_pfn[1] =",
            "\t\t\t\t\tcc->zone->compact_cached_migrate_pfn[0];",
            "\t\t\t}",
            "",
            "\t\t\t/*",
            "\t\t\t * We haven't isolated and migrated anything, but",
            "\t\t\t * there might still be unflushed migrations from",
            "\t\t\t * previous cc->order aligned block.",
            "\t\t\t */",
            "\t\t\tgoto check_drain;",
            "\t\tcase ISOLATE_SUCCESS:",
            "\t\t\tupdate_cached = false;",
            "\t\t\tlast_migrated_pfn = max(cc->zone->zone_start_pfn,",
            "\t\t\t\tpageblock_start_pfn(cc->migrate_pfn - 1));",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Record the number of pages to migrate since the",
            "\t\t * compaction_alloc/free() will update cc->nr_migratepages",
            "\t\t * properly.",
            "\t\t */",
            "\t\tnr_migratepages = cc->nr_migratepages;",
            "\t\terr = migrate_pages(&cc->migratepages, compaction_alloc,",
            "\t\t\t\tcompaction_free, (unsigned long)cc, cc->mode,",
            "\t\t\t\tMR_COMPACTION, &nr_succeeded);",
            "",
            "\t\ttrace_mm_compaction_migratepages(nr_migratepages, nr_succeeded);",
            "",
            "\t\t/* All pages were either migrated or will be released */",
            "\t\tcc->nr_migratepages = 0;",
            "\t\tif (err) {",
            "\t\t\tputback_movable_pages(&cc->migratepages);",
            "\t\t\t/*",
            "\t\t\t * migrate_pages() may return -ENOMEM when scanners meet",
            "\t\t\t * and we want compact_finished() to detect it",
            "\t\t\t */",
            "\t\t\tif (err == -ENOMEM && !compact_scanners_met(cc)) {",
            "\t\t\t\tret = COMPACT_CONTENDED;",
            "\t\t\t\tgoto out;",
            "\t\t\t}",
            "\t\t\t/*",
            "\t\t\t * If an ASYNC or SYNC_LIGHT fails to migrate a page",
            "\t\t\t * within the pageblock_order-aligned block and",
            "\t\t\t * fast_find_migrateblock may be used then scan the",
            "\t\t\t * remainder of the pageblock. This will mark the",
            "\t\t\t * pageblock \"skip\" to avoid rescanning in the near",
            "\t\t\t * future. This will isolate more pages than necessary",
            "\t\t\t * for the request but avoid loops due to",
            "\t\t\t * fast_find_migrateblock revisiting blocks that were",
            "\t\t\t * recently partially scanned.",
            "\t\t\t */",
            "\t\t\tif (!pageblock_aligned(cc->migrate_pfn) &&",
            "\t\t\t    !cc->ignore_skip_hint && !cc->finish_pageblock &&",
            "\t\t\t    (cc->mode < MIGRATE_SYNC)) {",
            "\t\t\t\tcc->finish_pageblock = true;",
            "",
            "\t\t\t\t/*",
            "\t\t\t\t * Draining pcplists does not help THP if",
            "\t\t\t\t * any page failed to migrate. Even after",
            "\t\t\t\t * drain, the pageblock will not be free.",
            "\t\t\t\t */",
            "\t\t\t\tif (cc->order == COMPACTION_HPAGE_ORDER)",
            "\t\t\t\t\tlast_migrated_pfn = 0;",
            "",
            "\t\t\t\tgoto rescan;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\t/* Stop if a page has been captured */",
            "\t\tif (capc && capc->page) {",
            "\t\t\tret = COMPACT_SUCCESS;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "check_drain:",
            "\t\t/*",
            "\t\t * Has the migration scanner moved away from the previous",
            "\t\t * cc->order aligned block where we migrated from? If yes,",
            "\t\t * flush the pages that were freed, so that they can merge and",
            "\t\t * compact_finished() can detect immediately if allocation",
            "\t\t * would succeed.",
            "\t\t */",
            "\t\tif (cc->order > 0 && last_migrated_pfn) {",
            "\t\t\tunsigned long current_block_start =",
            "\t\t\t\tblock_start_pfn(cc->migrate_pfn, cc->order);",
            "",
            "\t\t\tif (last_migrated_pfn < current_block_start) {",
            "\t\t\t\tlru_add_drain_cpu_zone(cc->zone);",
            "\t\t\t\t/* No more flushing until we migrate again */",
            "\t\t\t\tlast_migrated_pfn = 0;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "out:",
            "\t/*",
            "\t * Release free pages and update where the free scanner should restart,",
            "\t * so we don't leave any returned pages behind in the next attempt.",
            "\t */",
            "\tif (cc->nr_freepages > 0) {",
            "\t\tunsigned long free_pfn = release_free_list(cc->freepages);",
            "",
            "\t\tcc->nr_freepages = 0;",
            "\t\tVM_BUG_ON(free_pfn == 0);",
            "\t\t/* The cached pfn is always the first in a pageblock */",
            "\t\tfree_pfn = pageblock_start_pfn(free_pfn);",
            "\t\t/*",
            "\t\t * Only go back, not forward. The cached pfn might have been",
            "\t\t * already reset to zone end in compact_finished()",
            "\t\t */",
            "\t\tif (free_pfn > cc->zone->compact_cached_free_pfn)",
            "\t\t\tcc->zone->compact_cached_free_pfn = free_pfn;",
            "\t}",
            "",
            "\tcount_compact_events(COMPACTMIGRATE_SCANNED, cc->total_migrate_scanned);",
            "\tcount_compact_events(COMPACTFREE_SCANNED, cc->total_free_scanned);",
            "",
            "\ttrace_mm_compaction_end(cc, start_pfn, end_pfn, sync, ret);",
            "",
            "\tVM_BUG_ON(!list_empty(&cc->migratepages));",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "compaction_suit_allocation_order, compact_zone",
          "description": "compaction_suit_allocation_order检查分配顺序兼容性，compact_zone执行核心压缩流程，迁移页面并调整缓存扫描起点，处理页块扫描和迁移结果",
          "similarity": 0.49879294633865356
        }
      ]
    },
    {
      "source_file": "mm/sparse.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:25:01\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sparse.c`\n\n---\n\n# sparse.c 技术文档\n\n## 1. 文件概述\n\n`sparse.c` 是 Linux 内核中实现 **SPARSEMEM（稀疏内存模型）** 的核心文件，用于管理物理内存的稀疏映射。该模型将整个物理地址空间划分为固定大小的“内存段”（memory sections），仅对实际存在的内存段分配 `mem_map`（页描述符数组），从而在支持大物理地址空间的同时节省内存开销。此文件负责内存段的初始化、节点关联、存在性标记以及与内存热插拔和 vmemmap 相关的功能。\n\n## 2. 核心功能\n\n### 主要数据结构\n- **`mem_section`**: 全局内存段数组，每个元素代表一个内存段，存储该段的 `mem_map` 指针及其他元数据。\n  - 在 `CONFIG_SPARSEMEM_EXTREME` 下为二级指针（动态分配根数组）\n  - 否则为静态二维数组 `[NR_SECTION_ROOTS][SECTIONS_PER_ROOT]`\n- **`section_to_node_table`**: （仅当 `NODE_NOT_IN_PAGE_FLAGS` 时）用于通过内存段号查找所属 NUMA 节点的查找表。\n- **`__highest_present_section_nr`**: 记录当前系统中编号最大的已存在内存段，用于优化遍历。\n\n### 主要函数\n- **`memory_present()`**: 标记指定 PFN 范围内的内存段为“存在”，并关联到指定 NUMA 节点。\n- **`memblocks_present()`**: 遍历所有 memblock 内存区域，调用 `memory_present()` 标记所有系统内存。\n- **`sparse_index_init()`**: （仅 `CONFIG_SPARSEMEM_EXTREME`）为指定内存段分配其所在的根数组项。\n- **`sparse_encode_mem_map()` / `sparse_decode_mem_map()`**: 编码/解码 `mem_map` 指针，使其能通过段内偏移计算出实际 PFN。\n- **`subsection_map_init()`**: （仅 `CONFIG_SPARSEMEM_VMEMMAP`）初始化子段（subsection）位图，用于更细粒度的内存管理。\n- **`page_to_nid()`**: （仅 `NODE_NOT_IN_PAGE_FLAGS`）通过页结构获取其所属 NUMA 节点。\n- **`mminit_validate_memmodel_limits()`**: 验证传入的 PFN 范围是否超出 SPARSEMEM 模型支持的最大地址。\n\n### 辅助宏与内联函数\n- **`for_each_present_section_nr()`**: 高效遍历所有已存在的内存段。\n- **`first_present_section_nr()`**: 获取第一个存在的内存段编号。\n- **`sparse_encode_early_nid()` / `sparse_early_nid()`**: 在早期启动阶段利用 `section_mem_map` 字段临时存储 NUMA 节点 ID。\n\n## 3. 关键实现\n\n### 内存段管理\n- 物理内存被划分为 `PAGES_PER_SECTION` 大小的段（通常 128MB）。\n- `mem_section` 数组索引即为段号（section number），通过 `__nr_to_section()` 宏访问。\n- 段的存在性通过 `SECTION_MARKED_PRESENT` 位标记，并维护 `__highest_present_section_nr` 以加速遍历。\n\n### NUMA 节点关联\n- 若页结构体（`struct page`）中未直接存储节点 ID（`NODE_NOT_IN_PAGE_FLAGS`），则使用 `section_to_node_table` 查找。\n- 在 `memory_present()` 中通过 `set_section_nid()` 建立段到节点的映射。\n\n### 动态内存段分配（SPARSEMEM_EXTREME）\n- 为减少静态内存占用，`mem_section` 采用二级结构：\n  - 一级：`mem_section[]` 指向多个二级数组\n  - 二级：每个 `mem_section[root]` 指向 `SECTIONS_PER_ROOT` 个 `struct mem_section`\n- `sparse_index_init()` 在需要时动态分配二级数组（使用 `kzalloc_node` 或 `memblock_alloc_node`）。\n\n### 早期启动阶段的优化\n- 在 `mem_map` 分配前，复用 `section_mem_map` 字段的高位存储 NUMA 节点 ID（`sparse_encode_early_nid()`）。\n- 此信息在分配真实 `mem_map` 前被清除。\n\n### vmemmap 子段支持\n- 当启用 `CONFIG_SPARSEMEM_VMEMMAP` 时，每个内存段进一步划分为子段（subsections）。\n- `subsection_map_init()` 初始化位图，标记哪些子段包含有效内存，支持更灵活的内存热插拔。\n\n### 地址空间验证\n- `mminit_validate_memmodel_limits()` 确保传入的 PFN 范围不超过 `PHYSMEM_END`（SPARSEMEM 模型最大支持地址），防止越界。\n\n## 4. 依赖关系\n\n- **头文件依赖**:\n  - `<linux/mm.h>`, `<linux/mmzone.h>`: 内存管理核心定义\n  - `<linux/memblock.h>`: 早期内存分配器\n  - `<linux/vmalloc.h>`: 用于 vmemmap 映射\n  - `<asm/dma.h>`: 架构相关 DMA 定义\n  - `\"internal.h\"`: MM 子系统内部头文件\n- **配置选项依赖**:\n  - `CONFIG_SPARSEMEM`: 基础稀疏内存模型\n  - `CONFIG_SPARSEMEM_EXTREME`: 动态内存段分配\n  - `CONFIG_SPARSEMEM_VMEMMAP`: 使用虚拟映射的 mem_map\n  - `CONFIG_MEMORY_HOTPLUG`: 内存热插拔支持\n  - `NODE_NOT_IN_PAGE_FLAGS`: 页结构体不包含节点 ID\n- **与其他模块交互**:\n  - **Memory Block (memblock)**: 通过 `for_each_mem_pfn_range()` 获取初始内存布局\n  - **Page Allocator**: 提供 `struct page` 数组（mem_map）\n  - **NUMA Subsystem**: 通过节点 ID 关联内存与 CPU 拓扑\n  - **Memory Hotplug**: 依赖本文件提供的段管理接口进行内存增删\n\n## 5. 使用场景\n\n- **系统启动初始化**:\n  - `memblocks_present()` 在 `mm_init()` 阶段被调用，标记所有固件报告的内存区域为“存在”。\n- **内存热插拔**:\n  - 热添加内存时，调用 `memory_present()` 标记新段；热移除时清理对应段。\n  - `sparse_index_init()` 支持动态扩展 `mem_section` 数组。\n- **页到节点转换**:\n  - 当 `page_to_nid()` 被调用时（如页面迁移、NUMA 调度），通过段查找节点。\n- **vmemmap 优化**:\n  - 在支持 `SPARSEMEM_VMEMMAP` 的架构（如 x86_64, ARM64）上，`subsection_map_init()` 使内核能按子段粒度映射 `struct page`，减少虚拟地址空间占用。\n- **调试与验证**:\n  - `mminit_validate_memmodel_limits()` 在开发阶段捕获内存模型配置错误。",
      "similarity": 0.5450947880744934,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/sparse.c",
          "start_line": 219,
          "end_line": 339,
          "content": [
            "void __init subsection_map_init(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "}",
            "static void __init memory_present(int nid, unsigned long start, unsigned long end)",
            "{",
            "\tunsigned long pfn;",
            "",
            "#ifdef CONFIG_SPARSEMEM_EXTREME",
            "\tif (unlikely(!mem_section)) {",
            "\t\tunsigned long size, align;",
            "",
            "\t\tsize = sizeof(struct mem_section *) * NR_SECTION_ROOTS;",
            "\t\talign = 1 << (INTERNODE_CACHE_SHIFT);",
            "\t\tmem_section = memblock_alloc(size, align);",
            "\t\tif (!mem_section)",
            "\t\t\tpanic(\"%s: Failed to allocate %lu bytes align=0x%lx\\n\",",
            "\t\t\t      __func__, size, align);",
            "\t}",
            "#endif",
            "",
            "\tstart &= PAGE_SECTION_MASK;",
            "\tmminit_validate_memmodel_limits(&start, &end);",
            "\tfor (pfn = start; pfn < end; pfn += PAGES_PER_SECTION) {",
            "\t\tunsigned long section = pfn_to_section_nr(pfn);",
            "\t\tstruct mem_section *ms;",
            "",
            "\t\tsparse_index_init(section, nid);",
            "\t\tset_section_nid(section, nid);",
            "",
            "\t\tms = __nr_to_section(section);",
            "\t\tif (!ms->section_mem_map) {",
            "\t\t\tms->section_mem_map = sparse_encode_early_nid(nid) |",
            "\t\t\t\t\t\t\tSECTION_IS_ONLINE;",
            "\t\t\t__section_mark_present(ms, section);",
            "\t\t}",
            "\t}",
            "}",
            "static void __init memblocks_present(void)",
            "{",
            "\tunsigned long start, end;",
            "\tint i, nid;",
            "",
            "\tfor_each_mem_pfn_range(i, MAX_NUMNODES, &start, &end, &nid)",
            "\t\tmemory_present(nid, start, end);",
            "}",
            "static unsigned long sparse_encode_mem_map(struct page *mem_map, unsigned long pnum)",
            "{",
            "\tunsigned long coded_mem_map =",
            "\t\t(unsigned long)(mem_map - (section_nr_to_pfn(pnum)));",
            "\tBUILD_BUG_ON(SECTION_MAP_LAST_BIT > PFN_SECTION_SHIFT);",
            "\tBUG_ON(coded_mem_map & ~SECTION_MAP_MASK);",
            "\treturn coded_mem_map;",
            "}",
            "static void __meminit sparse_init_one_section(struct mem_section *ms,",
            "\t\tunsigned long pnum, struct page *mem_map,",
            "\t\tstruct mem_section_usage *usage, unsigned long flags)",
            "{",
            "\tms->section_mem_map &= ~SECTION_MAP_MASK;",
            "\tms->section_mem_map |= sparse_encode_mem_map(mem_map, pnum)",
            "\t\t| SECTION_HAS_MEM_MAP | flags;",
            "\tms->usage = usage;",
            "}",
            "static unsigned long usemap_size(void)",
            "{",
            "\treturn BITS_TO_LONGS(SECTION_BLOCKFLAGS_BITS) * sizeof(unsigned long);",
            "}",
            "size_t mem_section_usage_size(void)",
            "{",
            "\treturn sizeof(struct mem_section_usage) + usemap_size();",
            "}",
            "static inline phys_addr_t pgdat_to_phys(struct pglist_data *pgdat)",
            "{",
            "#ifndef CONFIG_NUMA",
            "\tVM_BUG_ON(pgdat != &contig_page_data);",
            "\treturn __pa_symbol(&contig_page_data);",
            "#else",
            "\treturn __pa(pgdat);",
            "#endif",
            "}",
            "static void __init check_usemap_section_nr(int nid,",
            "\t\tstruct mem_section_usage *usage)",
            "{",
            "\tunsigned long usemap_snr, pgdat_snr;",
            "\tstatic unsigned long old_usemap_snr;",
            "\tstatic unsigned long old_pgdat_snr;",
            "\tstruct pglist_data *pgdat = NODE_DATA(nid);",
            "\tint usemap_nid;",
            "",
            "\t/* First call */",
            "\tif (!old_usemap_snr) {",
            "\t\told_usemap_snr = NR_MEM_SECTIONS;",
            "\t\told_pgdat_snr = NR_MEM_SECTIONS;",
            "\t}",
            "",
            "\tusemap_snr = pfn_to_section_nr(__pa(usage) >> PAGE_SHIFT);",
            "\tpgdat_snr = pfn_to_section_nr(pgdat_to_phys(pgdat) >> PAGE_SHIFT);",
            "\tif (usemap_snr == pgdat_snr)",
            "\t\treturn;",
            "",
            "\tif (old_usemap_snr == usemap_snr && old_pgdat_snr == pgdat_snr)",
            "\t\t/* skip redundant message */",
            "\t\treturn;",
            "",
            "\told_usemap_snr = usemap_snr;",
            "\told_pgdat_snr = pgdat_snr;",
            "",
            "\tusemap_nid = sparse_early_nid(__nr_to_section(usemap_snr));",
            "\tif (usemap_nid != nid) {",
            "\t\tpr_info(\"node %d must be removed before remove section %ld\\n\",",
            "\t\t\tnid, usemap_snr);",
            "\t\treturn;",
            "\t}",
            "\t/*",
            "\t * There is a circular dependency.",
            "\t * Some platforms allow un-removable section because they will just",
            "\t * gather other removable sections for dynamic partitioning.",
            "\t * Just notify un-removable section's number here.",
            "\t */",
            "\tpr_info(\"Section %ld and %ld (node %d) have a circular dependency on usemap and pgdat allocations\\n\",",
            "\t\tusemap_snr, pgdat_snr, nid);",
            "}"
          ],
          "function_name": "subsection_map_init, memory_present, memblocks_present, sparse_encode_mem_map, sparse_init_one_section, usemap_size, mem_section_usage_size, pgdat_to_phys, check_usemap_section_nr",
          "description": "实现memory_present标记内存区段为有效，memblocks_present遍历所有内存块执行此操作。提供sparse_encode_mem_map编码内存图，sparse_init_one_section初始化区段结构体。包含使用图大小计算、PGDAT物理地址转换及使用图与PGDAT的依赖检查功能。",
          "similarity": 0.5739966630935669
        },
        {
          "chunk_id": 3,
          "file_path": "mm/sparse.c",
          "start_line": 410,
          "end_line": 527,
          "content": [
            "static void __init check_usemap_section_nr(int nid,",
            "\t\tstruct mem_section_usage *usage)",
            "{",
            "}",
            "static unsigned long __init section_map_size(void)",
            "{",
            "\treturn ALIGN(sizeof(struct page) * PAGES_PER_SECTION, PMD_SIZE);",
            "}",
            "static unsigned long __init section_map_size(void)",
            "{",
            "\treturn PAGE_ALIGN(sizeof(struct page) * PAGES_PER_SECTION);",
            "}",
            "static inline void __meminit sparse_buffer_free(unsigned long size)",
            "{",
            "\tWARN_ON(!sparsemap_buf || size == 0);",
            "\tmemblock_free(sparsemap_buf, size);",
            "}",
            "static void __init sparse_buffer_init(unsigned long size, int nid)",
            "{",
            "\tphys_addr_t addr = __pa(MAX_DMA_ADDRESS);",
            "\tWARN_ON(sparsemap_buf);\t/* forgot to call sparse_buffer_fini()? */",
            "\t/*",
            "\t * Pre-allocated buffer is mainly used by __populate_section_memmap",
            "\t * and we want it to be properly aligned to the section size - this is",
            "\t * especially the case for VMEMMAP which maps memmap to PMDs",
            "\t */",
            "\tsparsemap_buf = memmap_alloc(size, section_map_size(), addr, nid, true);",
            "\tsparsemap_buf_end = sparsemap_buf + size;",
            "}",
            "static void __init sparse_buffer_fini(void)",
            "{",
            "\tunsigned long size = sparsemap_buf_end - sparsemap_buf;",
            "",
            "\tif (sparsemap_buf && size > 0)",
            "\t\tsparse_buffer_free(size);",
            "\tsparsemap_buf = NULL;",
            "}",
            "void __weak __meminit vmemmap_populate_print_last(void)",
            "{",
            "}",
            "static void __init sparse_init_nid(int nid, unsigned long pnum_begin,",
            "\t\t\t\t   unsigned long pnum_end,",
            "\t\t\t\t   unsigned long map_count)",
            "{",
            "\tstruct mem_section_usage *usage;",
            "\tunsigned long pnum;",
            "\tstruct page *map;",
            "",
            "\tusage = sparse_early_usemaps_alloc_pgdat_section(NODE_DATA(nid),",
            "\t\t\tmem_section_usage_size() * map_count);",
            "\tif (!usage) {",
            "\t\tpr_err(\"%s: node[%d] usemap allocation failed\", __func__, nid);",
            "\t\tgoto failed;",
            "\t}",
            "\tsparse_buffer_init(map_count * section_map_size(), nid);",
            "\tfor_each_present_section_nr(pnum_begin, pnum) {",
            "\t\tunsigned long pfn = section_nr_to_pfn(pnum);",
            "",
            "\t\tif (pnum >= pnum_end)",
            "\t\t\tbreak;",
            "",
            "\t\tmap = __populate_section_memmap(pfn, PAGES_PER_SECTION,",
            "\t\t\t\tnid, NULL, NULL);",
            "\t\tif (!map) {",
            "\t\t\tpr_err(\"%s: node[%d] memory map backing failed. Some memory will not be available.\",",
            "\t\t\t       __func__, nid);",
            "\t\t\tpnum_begin = pnum;",
            "\t\t\tsparse_buffer_fini();",
            "\t\t\tgoto failed;",
            "\t\t}",
            "\t\tcheck_usemap_section_nr(nid, usage);",
            "\t\tsparse_init_one_section(__nr_to_section(pnum), pnum, map, usage,",
            "\t\t\t\tSECTION_IS_EARLY);",
            "\t\tusage = (void *) usage + mem_section_usage_size();",
            "\t}",
            "\tsparse_buffer_fini();",
            "\treturn;",
            "failed:",
            "\t/* We failed to allocate, mark all the following pnums as not present */",
            "\tfor_each_present_section_nr(pnum_begin, pnum) {",
            "\t\tstruct mem_section *ms;",
            "",
            "\t\tif (pnum >= pnum_end)",
            "\t\t\tbreak;",
            "\t\tms = __nr_to_section(pnum);",
            "\t\tms->section_mem_map = 0;",
            "\t}",
            "}",
            "void __init sparse_init(void)",
            "{",
            "\tunsigned long pnum_end, pnum_begin, map_count = 1;",
            "\tint nid_begin;",
            "",
            "\tmemblocks_present();",
            "",
            "\tpnum_begin = first_present_section_nr();",
            "\tnid_begin = sparse_early_nid(__nr_to_section(pnum_begin));",
            "",
            "\t/* Setup pageblock_order for HUGETLB_PAGE_SIZE_VARIABLE */",
            "\tset_pageblock_order();",
            "",
            "\tfor_each_present_section_nr(pnum_begin + 1, pnum_end) {",
            "\t\tint nid = sparse_early_nid(__nr_to_section(pnum_end));",
            "",
            "\t\tif (nid == nid_begin) {",
            "\t\t\tmap_count++;",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\t/* Init node with sections in range [pnum_begin, pnum_end) */",
            "\t\tsparse_init_nid(nid_begin, pnum_begin, pnum_end, map_count);",
            "\t\tnid_begin = nid;",
            "\t\tpnum_begin = pnum_end;",
            "\t\tmap_count = 1;",
            "\t}",
            "\t/* cover the last node */",
            "\tsparse_init_nid(nid_begin, pnum_begin, pnum_end, map_count);",
            "\tvmemmap_populate_print_last();",
            "}"
          ],
          "function_name": "check_usemap_section_nr, section_map_size, section_map_size, sparse_buffer_free, sparse_buffer_init, sparse_buffer_fini, vmemmap_populate_print_last, sparse_init_nid, sparse_init",
          "description": "定义section_map_size计算区段映射大小，管理sparse_buffer缓冲区的分配释放。实现sparse_init_nid初始化节点区段，通过__populate_section_memmap填充内存图。包含错误处理逻辑，失败时清除已分配区段标识。",
          "similarity": 0.5427480936050415
        },
        {
          "chunk_id": 5,
          "file_path": "mm/sparse.c",
          "start_line": 717,
          "end_line": 839,
          "content": [
            "static void free_map_bootmem(struct page *memmap)",
            "{",
            "\tunsigned long maps_section_nr, removing_section_nr, i;",
            "\tunsigned long magic, nr_pages;",
            "\tstruct page *page = virt_to_page(memmap);",
            "",
            "\tnr_pages = PAGE_ALIGN(PAGES_PER_SECTION * sizeof(struct page))",
            "\t\t>> PAGE_SHIFT;",
            "",
            "\tfor (i = 0; i < nr_pages; i++, page++) {",
            "\t\tmagic = page->index;",
            "",
            "\t\tBUG_ON(magic == NODE_INFO);",
            "",
            "\t\tmaps_section_nr = pfn_to_section_nr(page_to_pfn(page));",
            "\t\tremoving_section_nr = page_private(page);",
            "",
            "\t\t/*",
            "\t\t * When this function is called, the removing section is",
            "\t\t * logical offlined state. This means all pages are isolated",
            "\t\t * from page allocator. If removing section's memmap is placed",
            "\t\t * on the same section, it must not be freed.",
            "\t\t * If it is freed, page allocator may allocate it which will",
            "\t\t * be removed physically soon.",
            "\t\t */",
            "\t\tif (maps_section_nr != removing_section_nr)",
            "\t\t\tput_page_bootmem(page);",
            "\t}",
            "}",
            "static int clear_subsection_map(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "\treturn 0;",
            "}",
            "static bool is_subsection_map_empty(struct mem_section *ms)",
            "{",
            "\treturn true;",
            "}",
            "static int fill_subsection_map(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "\treturn 0;",
            "}",
            "static void section_deactivate(unsigned long pfn, unsigned long nr_pages,",
            "\t\tstruct vmem_altmap *altmap)",
            "{",
            "\tstruct mem_section *ms = __pfn_to_section(pfn);",
            "\tbool section_is_early = early_section(ms);",
            "\tstruct page *memmap = NULL;",
            "\tbool empty;",
            "",
            "\tif (clear_subsection_map(pfn, nr_pages))",
            "\t\treturn;",
            "",
            "\tempty = is_subsection_map_empty(ms);",
            "\tif (empty) {",
            "\t\tunsigned long section_nr = pfn_to_section_nr(pfn);",
            "",
            "\t\t/*",
            "\t\t * Mark the section invalid so that valid_section()",
            "\t\t * return false. This prevents code from dereferencing",
            "\t\t * ms->usage array.",
            "\t\t */",
            "\t\tms->section_mem_map &= ~SECTION_HAS_MEM_MAP;",
            "",
            "\t\t/*",
            "\t\t * When removing an early section, the usage map is kept (as the",
            "\t\t * usage maps of other sections fall into the same page). It",
            "\t\t * will be re-used when re-adding the section - which is then no",
            "\t\t * longer an early section. If the usage map is PageReserved, it",
            "\t\t * was allocated during boot.",
            "\t\t */",
            "\t\tif (!PageReserved(virt_to_page(ms->usage))) {",
            "\t\t\tkfree_rcu(ms->usage, rcu);",
            "\t\t\tWRITE_ONCE(ms->usage, NULL);",
            "\t\t}",
            "\t\tmemmap = sparse_decode_mem_map(ms->section_mem_map, section_nr);",
            "\t}",
            "",
            "\t/*",
            "\t * The memmap of early sections is always fully populated. See",
            "\t * section_activate() and pfn_valid() .",
            "\t */",
            "\tif (!section_is_early)",
            "\t\tdepopulate_section_memmap(pfn, nr_pages, altmap);",
            "\telse if (memmap)",
            "\t\tfree_map_bootmem(memmap);",
            "",
            "\tif (empty)",
            "\t\tms->section_mem_map = (unsigned long)NULL;",
            "}",
            "int __meminit sparse_add_section(int nid, unsigned long start_pfn,",
            "\t\tunsigned long nr_pages, struct vmem_altmap *altmap,",
            "\t\tstruct dev_pagemap *pgmap)",
            "{",
            "\tunsigned long section_nr = pfn_to_section_nr(start_pfn);",
            "\tstruct mem_section *ms;",
            "\tstruct page *memmap;",
            "\tint ret;",
            "",
            "\tret = sparse_index_init(section_nr, nid);",
            "\tif (ret < 0)",
            "\t\treturn ret;",
            "",
            "\tmemmap = section_activate(nid, start_pfn, nr_pages, altmap, pgmap);",
            "\tif (IS_ERR(memmap))",
            "\t\treturn PTR_ERR(memmap);",
            "",
            "\t/*",
            "\t * Poison uninitialized struct pages in order to catch invalid flags",
            "\t * combinations.",
            "\t */",
            "\tpage_init_poison(memmap, sizeof(struct page) * nr_pages);",
            "",
            "\tms = __nr_to_section(section_nr);",
            "\tset_section_nid(section_nr, nid);",
            "\t__section_mark_present(ms, section_nr);",
            "",
            "\t/* Align memmap to section boundary in the subsection case */",
            "\tif (section_nr_to_pfn(section_nr) != start_pfn)",
            "\t\tmemmap = pfn_to_page(section_nr_to_pfn(section_nr));",
            "\tsparse_init_one_section(ms, section_nr, memmap, ms->usage, 0);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "free_map_bootmem, clear_subsection_map, is_subsection_map_empty, fill_subsection_map, section_deactivate, sparse_add_section",
          "description": "free_map_bootmem 函数遍历指定内存映射区域的 page 结构，跳过与当前移除节（section）相同的物理节号的页面，其余页面通过 put_page_bootmem 释放。clear_subsection_map、is_subsection_map_empty、fill_subsection_map 均为空实现。section_deactivate 处理内存节停用流程，清除子节映射标志，释放早期节的 usage 数据并调用 depopulate_section_memmap 或 free_map_bootmem。sparse_add_section 初始化新内存节，设置节点 ID，标记节为有效，并调整 memmap 地址对齐。",
          "similarity": 0.5286962985992432
        },
        {
          "chunk_id": 4,
          "file_path": "mm/sparse.c",
          "start_line": 592,
          "end_line": 692,
          "content": [
            "void online_mem_sections(unsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tunsigned long pfn;",
            "",
            "\tfor (pfn = start_pfn; pfn < end_pfn; pfn += PAGES_PER_SECTION) {",
            "\t\tunsigned long section_nr = pfn_to_section_nr(pfn);",
            "\t\tstruct mem_section *ms;",
            "",
            "\t\t/* onlining code should never touch invalid ranges */",
            "\t\tif (WARN_ON(!valid_section_nr(section_nr)))",
            "\t\t\tcontinue;",
            "",
            "\t\tms = __nr_to_section(section_nr);",
            "\t\tms->section_mem_map |= SECTION_IS_ONLINE;",
            "\t}",
            "}",
            "void offline_mem_sections(unsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tunsigned long pfn;",
            "",
            "\tfor (pfn = start_pfn; pfn < end_pfn; pfn += PAGES_PER_SECTION) {",
            "\t\tunsigned long section_nr = pfn_to_section_nr(pfn);",
            "\t\tstruct mem_section *ms;",
            "",
            "\t\t/*",
            "\t\t * TODO this needs some double checking. Offlining code makes",
            "\t\t * sure to check pfn_valid but those checks might be just bogus",
            "\t\t */",
            "\t\tif (WARN_ON(!valid_section_nr(section_nr)))",
            "\t\t\tcontinue;",
            "",
            "\t\tms = __nr_to_section(section_nr);",
            "\t\tms->section_mem_map &= ~SECTION_IS_ONLINE;",
            "\t}",
            "}",
            "static void depopulate_section_memmap(unsigned long pfn, unsigned long nr_pages,",
            "\t\tstruct vmem_altmap *altmap)",
            "{",
            "\tunsigned long start = (unsigned long) pfn_to_page(pfn);",
            "\tunsigned long end = start + nr_pages * sizeof(struct page);",
            "",
            "\tvmemmap_free(start, end, altmap);",
            "}",
            "static void free_map_bootmem(struct page *memmap)",
            "{",
            "\tunsigned long start = (unsigned long)memmap;",
            "\tunsigned long end = (unsigned long)(memmap + PAGES_PER_SECTION);",
            "",
            "\tvmemmap_free(start, end, NULL);",
            "}",
            "static int clear_subsection_map(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "\tDECLARE_BITMAP(map, SUBSECTIONS_PER_SECTION) = { 0 };",
            "\tDECLARE_BITMAP(tmp, SUBSECTIONS_PER_SECTION) = { 0 };",
            "\tstruct mem_section *ms = __pfn_to_section(pfn);",
            "\tunsigned long *subsection_map = ms->usage",
            "\t\t? &ms->usage->subsection_map[0] : NULL;",
            "",
            "\tsubsection_mask_set(map, pfn, nr_pages);",
            "\tif (subsection_map)",
            "\t\tbitmap_and(tmp, map, subsection_map, SUBSECTIONS_PER_SECTION);",
            "",
            "\tif (WARN(!subsection_map || !bitmap_equal(tmp, map, SUBSECTIONS_PER_SECTION),",
            "\t\t\t\t\"section already deactivated (%#lx + %ld)\\n\",",
            "\t\t\t\tpfn, nr_pages))",
            "\t\treturn -EINVAL;",
            "",
            "\tbitmap_xor(subsection_map, map, subsection_map, SUBSECTIONS_PER_SECTION);",
            "\treturn 0;",
            "}",
            "static bool is_subsection_map_empty(struct mem_section *ms)",
            "{",
            "\treturn bitmap_empty(&ms->usage->subsection_map[0],",
            "\t\t\t    SUBSECTIONS_PER_SECTION);",
            "}",
            "static int fill_subsection_map(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "\tstruct mem_section *ms = __pfn_to_section(pfn);",
            "\tDECLARE_BITMAP(map, SUBSECTIONS_PER_SECTION) = { 0 };",
            "\tunsigned long *subsection_map;",
            "\tint rc = 0;",
            "",
            "\tsubsection_mask_set(map, pfn, nr_pages);",
            "",
            "\tsubsection_map = &ms->usage->subsection_map[0];",
            "",
            "\tif (bitmap_empty(map, SUBSECTIONS_PER_SECTION))",
            "\t\trc = -EINVAL;",
            "\telse if (bitmap_intersects(map, subsection_map, SUBSECTIONS_PER_SECTION))",
            "\t\trc = -EEXIST;",
            "\telse",
            "\t\tbitmap_or(subsection_map, map, subsection_map,",
            "\t\t\t\tSUBSECTIONS_PER_SECTION);",
            "",
            "\treturn rc;",
            "}",
            "static void depopulate_section_memmap(unsigned long pfn, unsigned long nr_pages,",
            "\t\tstruct vmem_altmap *altmap)",
            "{",
            "\tkvfree(pfn_to_page(pfn));",
            "}"
          ],
          "function_name": "online_mem_sections, offline_mem_sections, depopulate_section_memmap, free_map_bootmem, clear_subsection_map, is_subsection_map_empty, fill_subsection_map, depopulate_section_memmap",
          "description": "提供区段在线/离线操作接口，修改区段在线状态标志。实现depopulate_section_memmap释放内存映射，free_map_bootmem释放启动内存。包含子部分掩码操作函数，用于跟踪和验证内存区域的有效性。",
          "similarity": 0.5184575915336609
        },
        {
          "chunk_id": 6,
          "file_path": "mm/sparse.c",
          "start_line": 925,
          "end_line": 934,
          "content": [
            "void sparse_remove_section(unsigned long pfn, unsigned long nr_pages,",
            "\t\t\t   struct vmem_altmap *altmap)",
            "{",
            "\tstruct mem_section *ms = __pfn_to_section(pfn);",
            "",
            "\tif (WARN_ON_ONCE(!valid_section(ms)))",
            "\t\treturn;",
            "",
            "\tsection_deactivate(pfn, nr_pages, altmap);",
            "}"
          ],
          "function_name": "sparse_remove_section",
          "description": "sparse_remove_section 调用 section_deactivate 停用指定 PFN 区间内存节，前提是目标节处于有效状态。",
          "similarity": 0.5034216642379761
        }
      ]
    },
    {
      "source_file": "mm/memory-failure.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:40:57\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memory-failure.c`\n\n---\n\n# memory-failure.c 技术文档\n\n## 1. 文件概述\n\n`memory-failure.c` 是 Linux 内核中用于处理硬件报告的内存故障（如多比特 ECC 错误）的核心模块。该文件实现了对已损坏物理页的检测、隔离和恢复机制，支持两种主要操作模式：\n- **硬离线（Hard Offline）**：处理已被硬件标记为损坏的页面，通常会导致使用该页的进程被终止\n- **软离线（Soft Offline）**：主动隔离可疑但尚未损坏的页面，避免潜在故障而不杀死进程\n\n该模块需要在不违反虚拟内存子系统正常锁定规则的前提下，异步安全地处理内存错误，确保系统稳定性。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `sysctl_memory_failure_early_kill`：控制是否立即杀死使用损坏页面的进程（0=延迟处理，1=立即杀死）\n- `sysctl_memory_failure_recovery`：启用/禁用内存故障恢复功能（默认启用）\n- `num_poisoned_pages`：原子计数器，记录已标记为有毒（poisoned）的页面数量\n- `hw_memory_failure`：标识是否由硬件直接报告的内存故障\n- `mf_mutex`：保护内存故障处理操作的互斥锁\n\n### 主要函数\n- `num_poisoned_pages_inc()` / `num_poisoned_pages_sub()`：管理有毒页面计数\n- `__page_handle_poison()`：处理大页或空闲页的溶解和从伙伴系统移除\n- `page_handle_poison()`：通用页面毒化处理函数，设置 HWPoison 标志并更新计数\n- `hwpoison_filter_dev()`：基于设备号过滤硬件毒化页面（用于测试）\n- `hwpoison_filter_flags()`：基于页面标志过滤硬件毒化页面（用于测试）\n\n### Sysfs 接口\n通过 `MF_ATTR_RO` 宏定义的只读属性，提供每个 NUMA 节点的内存故障统计信息：\n- `total`：总处理的内存故障数\n- `ignored`：被忽略的故障数\n- `failed`：处理失败的故障数  \n- `delayed`：延迟处理的故障数\n- `recovered`：成功恢复的故障数\n\n## 3. 关键实现\n\n### 页面毒化处理流程\n1. **页面状态识别**：区分大页（hugepage）、空闲页（freepage）和其他类型页面\n2. **大页处理**：调用 `dissolve_free_huge_page()` 溶解大页，然后通过 `drain_all_pages()` 和 `take_page_off_buddy()` 确保页面从伙伴系统移除\n3. **标志设置**：使用 `SetPageHWPoison()` 标记页面为硬件毒化状态\n4. **引用计数管理**：增加页面引用计数并更新全局有毒页面计数器\n\n### 锁定策略\n- 避免使用 `zone_pcp_disable()` 以防止与 CPU 热插拔锁产生死锁\n- 采用标准 VM 锁定规则，即使这意味着错误处理可能耗时较长\n- 使用 `mf_mutex` 保护关键的内存故障处理路径\n\n### 复杂度考量\n- 由于 VM 数据结构的限制，某些操作（如通过 RMAP 反向映射查找进程）具有非线性时间复杂度\n- 基于内存故障的稀有性，接受这种性能开销以避免影响核心 VM 性能\n\n### 开发约束\n新增处理逻辑必须满足：\n- 具备可测试性\n- 能够集成到 mce-test 测试套件\n- 在真实工作负载中属于常见页面状态（page-types 工具 top 10）\n\n## 4. 依赖关系\n\n### 内核头文件依赖\n- **内存管理**：`<linux/mm.h>`, `<linux/page-flags.h>`, `<linux/pagemap.h>`, `<linux/swap.h>`\n- **进程管理**：`<linux/sched/signal.h>`, `<linux/sched/task.h>`\n- **特殊内存类型**：`<linux/hugetlb.h>`, `<linux/dax.h>`, `<linux/ksm.h>`, `<linux/shmem_fs.h>`\n- **系统架构**：`<linux/ras/ras_event.h>`, `<linux/memremap.h>`\n- **内核内部**：`\"swap.h\"`, `\"internal.h\"`\n\n### 功能依赖\n- **RAS（Reliability, Availability, Serviceability）**：通过 ras_event 提供事件通知\n- **内存热插拔**：`memblk_nr_poison_inc/sub` 用于内存块级统计\n- **cgroup 内存控制**：CONFIG_MEMCG 支持基于 memcg 的故障页面过滤\n- **硬件毒化注入**：CONFIG_HWPOISON_INJECT 提供测试框架\n\n## 5. 使用场景\n\n### 硬件内存故障处理\n- 当硬件检测到多比特 ECC 内存错误时，通过 Machine Check Exception (MCE) 机制调用此模块\n- 自动隔离损坏页面，防止数据损坏扩散\n\n### 主动内存维护\n- 系统管理员可通过 `/sys` 接口触发软离线操作，主动替换可疑内存页\n- 用于内存压力测试和预防性维护\n\n### 故障注入测试\n- 通过 `hwpoison_inject` 模块模拟硬件内存故障\n- 支持基于设备号、页面标志和 memcg 的精细过滤，用于针对性测试\n\n### 系统监控和诊断\n- 通过 sysfs 接口提供详细的内存故障统计信息\n- 便于系统管理员监控内存健康状况和故障恢复效果\n\n### 企业级可靠性保障\n- 在高可用服务器环境中，确保单个内存故障不会导致整个系统崩溃\n- 通过可配置的策略（early_kill, recovery）平衡服务连续性和数据完整性",
      "similarity": 0.5411193370819092,
      "chunks": [
        {
          "chunk_id": 15,
          "file_path": "mm/memory-failure.c",
          "start_line": 2426,
          "end_line": 2586,
          "content": [
            "void memory_failure_queue(unsigned long pfn, int flags)",
            "{",
            "\tstruct memory_failure_cpu *mf_cpu;",
            "\tunsigned long proc_flags;",
            "\tbool buffer_overflow;",
            "\tstruct memory_failure_entry entry = {",
            "\t\t.pfn =\t\tpfn,",
            "\t\t.flags =\tflags,",
            "\t};",
            "",
            "\tmf_cpu = &get_cpu_var(memory_failure_cpu);",
            "\traw_spin_lock_irqsave(&mf_cpu->lock, proc_flags);",
            "\tbuffer_overflow = !kfifo_put(&mf_cpu->fifo, entry);",
            "\tif (!buffer_overflow)",
            "\t\tschedule_work_on(smp_processor_id(), &mf_cpu->work);",
            "\traw_spin_unlock_irqrestore(&mf_cpu->lock, proc_flags);",
            "\tput_cpu_var(memory_failure_cpu);",
            "\tif (buffer_overflow)",
            "\t\tpr_err(\"buffer overflow when queuing memory failure at %#lx\\n\",",
            "\t\t       pfn);",
            "}",
            "static void memory_failure_work_func(struct work_struct *work)",
            "{",
            "\tstruct memory_failure_cpu *mf_cpu;",
            "\tstruct memory_failure_entry entry = { 0, };",
            "\tunsigned long proc_flags;",
            "\tint gotten;",
            "",
            "\tmf_cpu = container_of(work, struct memory_failure_cpu, work);",
            "\tfor (;;) {",
            "\t\traw_spin_lock_irqsave(&mf_cpu->lock, proc_flags);",
            "\t\tgotten = kfifo_get(&mf_cpu->fifo, &entry);",
            "\t\traw_spin_unlock_irqrestore(&mf_cpu->lock, proc_flags);",
            "\t\tif (!gotten)",
            "\t\t\tbreak;",
            "\t\tif (entry.flags & MF_SOFT_OFFLINE)",
            "\t\t\tsoft_offline_page(entry.pfn, entry.flags);",
            "\t\telse",
            "\t\t\tmemory_failure(entry.pfn, entry.flags);",
            "\t}",
            "}",
            "static int __init memory_failure_init(void)",
            "{",
            "\tstruct memory_failure_cpu *mf_cpu;",
            "\tint cpu;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tmf_cpu = &per_cpu(memory_failure_cpu, cpu);",
            "\t\traw_spin_lock_init(&mf_cpu->lock);",
            "\t\tINIT_KFIFO(mf_cpu->fifo);",
            "\t\tINIT_WORK(&mf_cpu->work, memory_failure_work_func);",
            "\t}",
            "",
            "\tregister_sysctl_init(\"vm\", memory_failure_table);",
            "",
            "\treturn 0;",
            "}",
            "static int __unpoison_memory(unsigned long pfn, bool hw_mf_check)",
            "{",
            "\tstruct folio *folio;",
            "\tstruct page *p;",
            "\tint ret = -EBUSY, ghp;",
            "\tunsigned long count;",
            "\tbool huge = false;",
            "\tstatic DEFINE_RATELIMIT_STATE(unpoison_rs, DEFAULT_RATELIMIT_INTERVAL,",
            "\t\t\t\t\tDEFAULT_RATELIMIT_BURST);",
            "",
            "\tif (!pfn_valid(pfn))",
            "\t\treturn -ENXIO;",
            "",
            "\tp = pfn_to_page(pfn);",
            "\tfolio = page_folio(p);",
            "",
            "\tmutex_lock(&mf_mutex);",
            "",
            "\tif (hw_mf_check && hw_memory_failure) {",
            "\t\tunpoison_pr_info(\"Unpoison: Disabled after HW memory failure %#lx\\n\",",
            "\t\t\t\t pfn, &unpoison_rs);",
            "\t\tret = -EOPNOTSUPP;",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\tif (is_huge_zero_folio(folio)) {",
            "\t\tunpoison_pr_info(\"Unpoison: huge zero page is not supported %#lx\\n\",",
            "\t\t\t\t pfn, &unpoison_rs);",
            "\t\tret = -EOPNOTSUPP;",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\tif (!PageHWPoison(p)) {",
            "\t\tunpoison_pr_info(\"Unpoison: Page was already unpoisoned %#lx\\n\",",
            "\t\t\t\t pfn, &unpoison_rs);",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\tif (folio_ref_count(folio) > 1) {",
            "\t\tunpoison_pr_info(\"Unpoison: Someone grabs the hwpoison page %#lx\\n\",",
            "\t\t\t\t pfn, &unpoison_rs);",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\tif (folio_test_slab(folio) || folio_test_pgtable(folio) ||",
            "\t    folio_test_reserved(folio) || folio_test_offline(folio))",
            "\t\tgoto unlock_mutex;",
            "",
            "\tif (folio_mapped(folio)) {",
            "\t\tunpoison_pr_info(\"Unpoison: Someone maps the hwpoison page %#lx\\n\",",
            "\t\t\t\t pfn, &unpoison_rs);",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\tif (folio_mapping(folio)) {",
            "\t\tunpoison_pr_info(\"Unpoison: the hwpoison page has non-NULL mapping %#lx\\n\",",
            "\t\t\t\t pfn, &unpoison_rs);",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\tghp = get_hwpoison_page(p, MF_UNPOISON);",
            "\tif (!ghp) {",
            "\t\tif (folio_test_hugetlb(folio)) {",
            "\t\t\thuge = true;",
            "\t\t\tcount = folio_free_raw_hwp(folio, false);",
            "\t\t\tif (count == 0)",
            "\t\t\t\tgoto unlock_mutex;",
            "\t\t}",
            "\t\tret = folio_test_clear_hwpoison(folio) ? 0 : -EBUSY;",
            "\t} else if (ghp < 0) {",
            "\t\tif (ghp == -EHWPOISON) {",
            "\t\t\tret = put_page_back_buddy(p) ? 0 : -EBUSY;",
            "\t\t} else {",
            "\t\t\tret = ghp;",
            "\t\t\tunpoison_pr_info(\"Unpoison: failed to grab page %#lx\\n\",",
            "\t\t\t\t\t pfn, &unpoison_rs);",
            "\t\t}",
            "\t} else {",
            "\t\tif (folio_test_hugetlb(folio)) {",
            "\t\t\thuge = true;",
            "\t\t\tcount = folio_free_raw_hwp(folio, false);",
            "\t\t\tif (count == 0) {",
            "\t\t\t\tfolio_put(folio);",
            "\t\t\t\tgoto unlock_mutex;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tfolio_put(folio);",
            "\t\tif (TestClearPageHWPoison(p)) {",
            "\t\t\tfolio_put(folio);",
            "\t\t\tret = 0;",
            "\t\t}",
            "\t}",
            "",
            "unlock_mutex:",
            "\tmutex_unlock(&mf_mutex);",
            "\tif (!ret) {",
            "\t\tif (!huge)",
            "\t\t\tnum_poisoned_pages_sub(pfn, 1);",
            "\t\tunpoison_pr_info(\"Unpoison: Software-unpoisoned page %#lx\\n\",",
            "\t\t\t\t page_to_pfn(p), &unpoison_rs);",
            "\t}",
            "\treturn ret;",
            "}"
          ],
          "function_name": "memory_failure_queue, memory_failure_work_func, memory_failure_init, __unpoison_memory",
          "description": "memory_failure_queue将PFN和标志位加入当前CPU的内存故障队列，并触发工作队列处理；memory_failure_work_func从队列取出条目并根据MF_SOFT_OFFLINE标志选择soft_offline_page或memory_failure处理；memory_failure_init初始化每个CPU的内存故障结构体并注册sysctl接口；__unpoison_memory用于解除硬件内存故障标记，检查页面有效性及使用状态后清除HWPoison标志。",
          "similarity": 0.5513138771057129
        },
        {
          "chunk_id": 14,
          "file_path": "mm/memory-failure.c",
          "start_line": 2186,
          "end_line": 2390,
          "content": [
            "int memory_failure(unsigned long pfn, int flags)",
            "{",
            "\tstruct page *p;",
            "\tstruct folio *folio;",
            "\tstruct dev_pagemap *pgmap;",
            "\tint res = 0;",
            "\tunsigned long page_flags;",
            "\tbool retry = true;",
            "\tint hugetlb = 0;",
            "",
            "\tif (!sysctl_memory_failure_recovery)",
            "\t\tpanic(\"Memory failure on page %lx\", pfn);",
            "",
            "\tmutex_lock(&mf_mutex);",
            "",
            "\tif (!(flags & MF_SW_SIMULATED))",
            "\t\thw_memory_failure = true;",
            "",
            "\tp = pfn_to_online_page(pfn);",
            "\tif (!p) {",
            "\t\tres = arch_memory_failure(pfn, flags);",
            "\t\tif (res == 0)",
            "\t\t\tgoto unlock_mutex;",
            "",
            "\t\tif (pfn_valid(pfn)) {",
            "\t\t\tpgmap = get_dev_pagemap(pfn, NULL);",
            "\t\t\tput_ref_page(pfn, flags);",
            "\t\t\tif (pgmap) {",
            "\t\t\t\tres = memory_failure_dev_pagemap(pfn, flags,",
            "\t\t\t\t\t\t\t\t pgmap);",
            "\t\t\t\tgoto unlock_mutex;",
            "\t\t\t}",
            "\t\t}",
            "\t\tpr_err(\"%#lx: memory outside kernel control\\n\", pfn);",
            "\t\tres = -ENXIO;",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "try_again:",
            "\tres = try_memory_failure_hugetlb(pfn, flags, &hugetlb);",
            "\tif (hugetlb)",
            "\t\tgoto unlock_mutex;",
            "",
            "\tif (TestSetPageHWPoison(p)) {",
            "\t\tpr_err(\"%#lx: already hardware poisoned\\n\", pfn);",
            "\t\tres = -EHWPOISON;",
            "\t\tif (flags & MF_ACTION_REQUIRED)",
            "\t\t\tres = kill_accessing_process(current, pfn, flags);",
            "\t\tif (flags & MF_COUNT_INCREASED)",
            "\t\t\tput_page(p);",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\t/*",
            "\t * We need/can do nothing about count=0 pages.",
            "\t * 1) it's a free page, and therefore in safe hand:",
            "\t *    check_new_page() will be the gate keeper.",
            "\t * 2) it's part of a non-compound high order page.",
            "\t *    Implies some kernel user: cannot stop them from",
            "\t *    R/W the page; let's pray that the page has been",
            "\t *    used and will be freed some time later.",
            "\t * In fact it's dangerous to directly bump up page count from 0,",
            "\t * that may make page_ref_freeze()/page_ref_unfreeze() mismatch.",
            "\t */",
            "\tif (!(flags & MF_COUNT_INCREASED)) {",
            "\t\tres = get_hwpoison_page(p, flags);",
            "\t\tif (!res) {",
            "\t\t\tif (is_free_buddy_page(p)) {",
            "\t\t\t\tif (take_page_off_buddy(p)) {",
            "\t\t\t\t\tpage_ref_inc(p);",
            "\t\t\t\t\tres = MF_RECOVERED;",
            "\t\t\t\t} else {",
            "\t\t\t\t\t/* We lost the race, try again */",
            "\t\t\t\t\tif (retry) {",
            "\t\t\t\t\t\tClearPageHWPoison(p);",
            "\t\t\t\t\t\tretry = false;",
            "\t\t\t\t\t\tgoto try_again;",
            "\t\t\t\t\t}",
            "\t\t\t\t\tres = MF_FAILED;",
            "\t\t\t\t}",
            "\t\t\t\tres = action_result(pfn, MF_MSG_BUDDY, res);",
            "\t\t\t} else {",
            "\t\t\t\tres = action_result(pfn, MF_MSG_KERNEL_HIGH_ORDER, MF_IGNORED);",
            "\t\t\t}",
            "\t\t\tgoto unlock_mutex;",
            "\t\t} else if (res < 0) {",
            "\t\t\tres = action_result(pfn, MF_MSG_UNKNOWN, MF_IGNORED);",
            "\t\t\tgoto unlock_mutex;",
            "\t\t}",
            "\t}",
            "",
            "\tfolio = page_folio(p);",
            "\tif (folio_test_large(folio)) {",
            "\t\t/*",
            "\t\t * The flag must be set after the refcount is bumped",
            "\t\t * otherwise it may race with THP split.",
            "\t\t * And the flag can't be set in get_hwpoison_page() since",
            "\t\t * it is called by soft offline too and it is just called",
            "\t\t * for !MF_COUNT_INCREASED.  So here seems to be the best",
            "\t\t * place.",
            "\t\t *",
            "\t\t * Don't need care about the above error handling paths for",
            "\t\t * get_hwpoison_page() since they handle either free page",
            "\t\t * or unhandlable page.  The refcount is bumped iff the",
            "\t\t * page is a valid handlable page.",
            "\t\t */",
            "\t\tfolio_set_has_hwpoisoned(folio);",
            "\t\tif (try_to_split_thp_page(p) < 0) {",
            "\t\t\tres = action_result(pfn, MF_MSG_UNSPLIT_THP, MF_IGNORED);",
            "\t\t\tgoto unlock_mutex;",
            "\t\t}",
            "\t\tVM_BUG_ON_PAGE(!page_count(p), p);",
            "\t\tfolio = page_folio(p);",
            "\t}",
            "",
            "\t/*",
            "\t * We ignore non-LRU pages for good reasons.",
            "\t * - PG_locked is only well defined for LRU pages and a few others",
            "\t * - to avoid races with __SetPageLocked()",
            "\t * - to avoid races with __SetPageSlab*() (and more non-atomic ops)",
            "\t * The check (unnecessarily) ignores LRU pages being isolated and",
            "\t * walked by the page reclaim code, however that's not a big loss.",
            "\t */",
            "\tshake_folio(folio);",
            "",
            "\tfolio_lock(folio);",
            "",
            "\t/*",
            "\t * We're only intended to deal with the non-Compound page here.",
            "\t * However, the page could have changed compound pages due to",
            "\t * race window. If this happens, we could try again to hopefully",
            "\t * handle the page next round.",
            "\t */",
            "\tif (folio_test_large(folio)) {",
            "\t\tif (retry) {",
            "\t\t\tClearPageHWPoison(p);",
            "\t\t\tfolio_unlock(folio);",
            "\t\t\tfolio_put(folio);",
            "\t\t\tflags &= ~MF_COUNT_INCREASED;",
            "\t\t\tretry = false;",
            "\t\t\tgoto try_again;",
            "\t\t}",
            "\t\tres = action_result(pfn, MF_MSG_DIFFERENT_COMPOUND, MF_IGNORED);",
            "\t\tgoto unlock_page;",
            "\t}",
            "",
            "\t/*",
            "\t * We use page flags to determine what action should be taken, but",
            "\t * the flags can be modified by the error containment action.  One",
            "\t * example is an mlocked page, where PG_mlocked is cleared by",
            "\t * folio_remove_rmap_*() in try_to_unmap_one(). So to determine page",
            "\t * status correctly, we save a copy of the page flags at this time.",
            "\t */",
            "\tpage_flags = folio->flags;",
            "",
            "\tif (hwpoison_filter(p)) {",
            "\t\tClearPageHWPoison(p);",
            "\t\tfolio_unlock(folio);",
            "\t\tfolio_put(folio);",
            "\t\tres = -EOPNOTSUPP;",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\t/*",
            "\t * __munlock_folio() may clear a writeback folio's LRU flag without",
            "\t * the folio lock. We need to wait for writeback completion for this",
            "\t * folio or it may trigger a vfs BUG while evicting inode.",
            "\t */",
            "\tif (!folio_test_lru(folio) && !folio_test_writeback(folio))",
            "\t\tgoto identify_page_state;",
            "",
            "\t/*",
            "\t * It's very difficult to mess with pages currently under IO",
            "\t * and in many cases impossible, so we just avoid it here.",
            "\t */",
            "\tfolio_wait_writeback(folio);",
            "",
            "\t/*",
            "\t * Now take care of user space mappings.",
            "\t * Abort on fail: __filemap_remove_folio() assumes unmapped page.",
            "\t */",
            "\tif (!hwpoison_user_mappings(folio, p, pfn, flags)) {",
            "\t\tres = action_result(pfn, MF_MSG_UNMAP_FAILED, MF_IGNORED);",
            "\t\tgoto unlock_page;",
            "\t}",
            "",
            "\t/*",
            "\t * Torn down by someone else?",
            "\t */",
            "\tif (folio_test_lru(folio) && !folio_test_swapcache(folio) &&",
            "\t    folio->mapping == NULL) {",
            "\t\tres = action_result(pfn, MF_MSG_TRUNCATED_LRU, MF_IGNORED);",
            "\t\tgoto unlock_page;",
            "\t}",
            "",
            "identify_page_state:",
            "\tres = identify_page_state(pfn, p, page_flags);",
            "\tmutex_unlock(&mf_mutex);",
            "\treturn res;",
            "unlock_page:",
            "\tfolio_unlock(folio);",
            "unlock_mutex:",
            "\tmutex_unlock(&mf_mutex);",
            "\treturn res;",
            "}"
          ],
          "function_name": "memory_failure",
          "description": "memory_failure主函数处理内存故障，检查页面有效性，通过不同路径处理普通页、大页和设备页，调用相应处理函数并返回结果",
          "similarity": 0.5233527421951294
        },
        {
          "chunk_id": 6,
          "file_path": "mm/memory-failure.c",
          "start_line": 919,
          "end_line": 1050,
          "content": [
            "static int delete_from_lru_cache(struct page *p)",
            "{",
            "\tif (isolate_lru_page(p)) {",
            "\t\t/*",
            "\t\t * Clear sensible page flags, so that the buddy system won't",
            "\t\t * complain when the page is unpoison-and-freed.",
            "\t\t */",
            "\t\tClearPageActive(p);",
            "\t\tClearPageUnevictable(p);",
            "",
            "\t\t/*",
            "\t\t * Poisoned page might never drop its ref count to 0 so we have",
            "\t\t * to uncharge it manually from its memcg.",
            "\t\t */",
            "\t\tmem_cgroup_uncharge(page_folio(p));",
            "",
            "\t\t/*",
            "\t\t * drop the page count elevated by isolate_lru_page()",
            "\t\t */",
            "\t\tput_page(p);",
            "\t\treturn 0;",
            "\t}",
            "\treturn -EIO;",
            "}",
            "static int truncate_error_page(struct page *p, unsigned long pfn,",
            "\t\t\t\tstruct address_space *mapping)",
            "{",
            "\tstruct folio *folio = page_folio(p);",
            "\tint ret = MF_FAILED;",
            "",
            "\tif (mapping->a_ops->error_remove_page) {",
            "\t\tint err = mapping->a_ops->error_remove_page(mapping, p);",
            "",
            "\t\tif (err != 0)",
            "\t\t\tpr_info(\"%#lx: Failed to punch page: %d\\n\", pfn, err);",
            "\t\telse if (!filemap_release_folio(folio, GFP_NOIO))",
            "\t\t\tpr_info(\"%#lx: failed to release buffers\\n\", pfn);",
            "\t\telse",
            "\t\t\tret = MF_RECOVERED;",
            "\t} else {",
            "\t\t/*",
            "\t\t * If the file system doesn't support it just invalidate",
            "\t\t * This fails on dirty or anything with private pages",
            "\t\t */",
            "\t\tif (mapping_evict_folio(mapping, folio))",
            "\t\t\tret = MF_RECOVERED;",
            "\t\telse",
            "\t\t\tpr_info(\"%#lx: Failed to invalidate\\n\",\tpfn);",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "static bool has_extra_refcount(struct page_state *ps, struct page *p,",
            "\t\t\t       bool extra_pins)",
            "{",
            "\tint count = page_count(p) - 1;",
            "",
            "\tif (extra_pins)",
            "\t\tcount -= folio_nr_pages(page_folio(p));",
            "",
            "\tif (count > 0) {",
            "\t\tpr_err(\"%#lx: %s still referenced by %d users\\n\",",
            "\t\t       page_to_pfn(p), action_page_types[ps->type], count);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static int me_kernel(struct page_state *ps, struct page *p)",
            "{",
            "\tunlock_page(p);",
            "\treturn MF_IGNORED;",
            "}",
            "static int me_unknown(struct page_state *ps, struct page *p)",
            "{",
            "\tpr_err(\"%#lx: Unknown page state\\n\", page_to_pfn(p));",
            "\tunlock_page(p);",
            "\treturn MF_FAILED;",
            "}",
            "static int me_pagecache_clean(struct page_state *ps, struct page *p)",
            "{",
            "\tint ret;",
            "\tstruct address_space *mapping;",
            "\tbool extra_pins;",
            "",
            "\tdelete_from_lru_cache(p);",
            "",
            "\t/*",
            "\t * For anonymous pages we're done the only reference left",
            "\t * should be the one m_f() holds.",
            "\t */",
            "\tif (PageAnon(p)) {",
            "\t\tret = MF_RECOVERED;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * Now truncate the page in the page cache. This is really",
            "\t * more like a \"temporary hole punch\"",
            "\t * Don't do this for block devices when someone else",
            "\t * has a reference, because it could be file system metadata",
            "\t * and that's not safe to truncate.",
            "\t */",
            "\tmapping = page_mapping(p);",
            "\tif (!mapping) {",
            "\t\t/*",
            "\t\t * Page has been teared down in the meanwhile",
            "\t\t */",
            "\t\tret = MF_FAILED;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * The shmem page is kept in page cache instead of truncating",
            "\t * so is expected to have an extra refcount after error-handling.",
            "\t */",
            "\textra_pins = shmem_mapping(mapping);",
            "",
            "\t/*",
            "\t * Truncation is a bit tricky. Enable it per file system for now.",
            "\t *",
            "\t * Open: to take i_rwsem or not for this? Right now we don't.",
            "\t */",
            "\tret = truncate_error_page(p, page_to_pfn(p), mapping);",
            "\tif (has_extra_refcount(ps, p, extra_pins))",
            "\t\tret = MF_FAILED;",
            "",
            "out:",
            "\tunlock_page(p);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "delete_from_lru_cache, truncate_error_page, has_extra_refcount, me_kernel, me_unknown, me_pagecache_clean",
          "description": "提供内存故障页面清理流程，包括从LRU列表移除、截断页面缓存及检查引用计数的辅助函数",
          "similarity": 0.511276125907898
        },
        {
          "chunk_id": 2,
          "file_path": "mm/memory-failure.c",
          "start_line": 278,
          "end_line": 378,
          "content": [
            "static int hwpoison_filter_task(struct page *p) { return 0; }",
            "int hwpoison_filter(struct page *p)",
            "{",
            "\tif (!hwpoison_filter_enable)",
            "\t\treturn 0;",
            "",
            "\tif (hwpoison_filter_dev(p))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (hwpoison_filter_flags(p))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (hwpoison_filter_task(p))",
            "\t\treturn -EINVAL;",
            "",
            "\treturn 0;",
            "}",
            "int hwpoison_filter(struct page *p)",
            "{",
            "\treturn 0;",
            "}",
            "static int kill_proc(struct to_kill *tk, unsigned long pfn, int flags)",
            "{",
            "\tstruct task_struct *t = tk->tsk;",
            "\tshort addr_lsb = tk->size_shift;",
            "\tint ret = 0;",
            "",
            "\tpr_err(\"%#lx: Sending SIGBUS to %s:%d due to hardware memory corruption\\n\",",
            "\t\t\tpfn, t->comm, task_pid_nr(t));",
            "",
            "\tif ((flags & MF_ACTION_REQUIRED) && (t == current))",
            "\t\tret = force_sig_mceerr(BUS_MCEERR_AR,",
            "\t\t\t\t (void __user *)tk->addr, addr_lsb);",
            "\telse",
            "\t\t/*",
            "\t\t * Signal other processes sharing the page if they have",
            "\t\t * PF_MCE_EARLY set.",
            "\t\t * Don't use force here, it's convenient if the signal",
            "\t\t * can be temporarily blocked.",
            "\t\t */",
            "\t\tret = send_sig_mceerr(BUS_MCEERR_AO, (void __user *)tk->addr,",
            "\t\t\t\t      addr_lsb, t);",
            "\tif (ret < 0)",
            "\t\tpr_info(\"Error sending signal to %s:%d: %d\\n\",",
            "\t\t\tt->comm, task_pid_nr(t), ret);",
            "\treturn ret;",
            "}",
            "void shake_folio(struct folio *folio)",
            "{",
            "\tif (folio_test_hugetlb(folio))",
            "\t\treturn;",
            "\t/*",
            "\t * TODO: Could shrink slab caches here if a lightweight range-based",
            "\t * shrinker will be available.",
            "\t */",
            "\tif (folio_test_slab(folio))",
            "\t\treturn;",
            "",
            "\tlru_add_drain_all();",
            "}",
            "static void shake_page(struct page *page)",
            "{",
            "\tshake_folio(page_folio(page));",
            "}",
            "static unsigned long dev_pagemap_mapping_shift(struct vm_area_struct *vma,",
            "\t\tunsigned long address)",
            "{",
            "\tunsigned long ret = 0;",
            "\tpgd_t *pgd;",
            "\tp4d_t *p4d;",
            "\tpud_t *pud;",
            "\tpmd_t *pmd;",
            "\tpte_t *pte;",
            "\tpte_t ptent;",
            "",
            "\tVM_BUG_ON_VMA(address == -EFAULT, vma);",
            "\tpgd = pgd_offset(vma->vm_mm, address);",
            "\tif (!pgd_present(*pgd))",
            "\t\treturn 0;",
            "\tp4d = p4d_offset(pgd, address);",
            "\tif (!p4d_present(*p4d))",
            "\t\treturn 0;",
            "\tpud = pud_offset(p4d, address);",
            "\tif (!pud_present(*pud))",
            "\t\treturn 0;",
            "\tif (pud_devmap(*pud))",
            "\t\treturn PUD_SHIFT;",
            "\tpmd = pmd_offset(pud, address);",
            "\tif (!pmd_present(*pmd))",
            "\t\treturn 0;",
            "\tif (pmd_devmap(*pmd))",
            "\t\treturn PMD_SHIFT;",
            "\tpte = pte_offset_map(pmd, address);",
            "\tif (!pte)",
            "\t\treturn 0;",
            "\tptent = ptep_get(pte);",
            "\tif (pte_present(ptent) && pte_devmap(ptent))",
            "\t\tret = PAGE_SHIFT;",
            "\tpte_unmap(pte);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "hwpoison_filter_task, hwpoison_filter, hwpoison_filter, kill_proc, shake_folio, shake_page, dev_pagemap_mapping_shift",
          "description": "实现内存故障过滤和进程终止逻辑，包含验证页面映射有效性、向进程发送SIGBUS/SIGKILL信号的函数，以及用于页面抖动的辅助函数。",
          "similarity": 0.49882760643959045
        },
        {
          "chunk_id": 13,
          "file_path": "mm/memory-failure.c",
          "start_line": 2042,
          "end_line": 2153,
          "content": [
            "static int try_memory_failure_hugetlb(unsigned long pfn, int flags, int *hugetlb)",
            "{",
            "\tint res;",
            "\tstruct page *p = pfn_to_page(pfn);",
            "\tstruct folio *folio;",
            "\tunsigned long page_flags;",
            "\tbool migratable_cleared = false;",
            "",
            "\t*hugetlb = 1;",
            "retry:",
            "\tres = get_huge_page_for_hwpoison(pfn, flags, &migratable_cleared);",
            "\tif (res == 2) { /* fallback to normal page handling */",
            "\t\t*hugetlb = 0;",
            "\t\treturn 0;",
            "\t} else if (res == -EHWPOISON) {",
            "\t\tpr_err(\"%#lx: already hardware poisoned\\n\", pfn);",
            "\t\tif (flags & MF_ACTION_REQUIRED) {",
            "\t\t\tfolio = page_folio(p);",
            "\t\t\tres = kill_accessing_process(current, folio_pfn(folio), flags);",
            "\t\t}",
            "\t\treturn res;",
            "\t} else if (res == -EBUSY) {",
            "\t\tif (!(flags & MF_NO_RETRY)) {",
            "\t\t\tflags |= MF_NO_RETRY;",
            "\t\t\tgoto retry;",
            "\t\t}",
            "\t\treturn action_result(pfn, MF_MSG_UNKNOWN, MF_IGNORED);",
            "\t}",
            "",
            "\tfolio = page_folio(p);",
            "\tfolio_lock(folio);",
            "",
            "\tif (hwpoison_filter(p)) {",
            "\t\tfolio_clear_hugetlb_hwpoison(folio);",
            "\t\tif (migratable_cleared)",
            "\t\t\tfolio_set_hugetlb_migratable(folio);",
            "\t\tfolio_unlock(folio);",
            "\t\tif (res == 1)",
            "\t\t\tfolio_put(folio);",
            "\t\treturn -EOPNOTSUPP;",
            "\t}",
            "",
            "\t/*",
            "\t * Handling free hugepage.  The possible race with hugepage allocation",
            "\t * or demotion can be prevented by PageHWPoison flag.",
            "\t */",
            "\tif (res == 0) {",
            "\t\tfolio_unlock(folio);",
            "\t\tif (__page_handle_poison(p) > 0) {",
            "\t\t\tpage_ref_inc(p);",
            "\t\t\tres = MF_RECOVERED;",
            "\t\t} else {",
            "\t\t\tres = MF_FAILED;",
            "\t\t}",
            "\t\treturn action_result(pfn, MF_MSG_FREE_HUGE, res);",
            "\t}",
            "",
            "\tpage_flags = folio->flags;",
            "",
            "\tif (!hwpoison_user_mappings(folio, p, pfn, flags)) {",
            "\t\tfolio_unlock(folio);",
            "\t\treturn action_result(pfn, MF_MSG_UNMAP_FAILED, MF_IGNORED);",
            "\t}",
            "",
            "\treturn identify_page_state(pfn, p, page_flags);",
            "}",
            "static inline int try_memory_failure_hugetlb(unsigned long pfn, int flags, int *hugetlb)",
            "{",
            "\treturn 0;",
            "}",
            "static inline unsigned long folio_free_raw_hwp(struct folio *folio, bool flag)",
            "{",
            "\treturn 0;",
            "}",
            "static void put_ref_page(unsigned long pfn, int flags)",
            "{",
            "\tif (!(flags & MF_COUNT_INCREASED))",
            "\t\treturn;",
            "",
            "\tput_page(pfn_to_page(pfn));",
            "}",
            "static int memory_failure_dev_pagemap(unsigned long pfn, int flags,",
            "\t\tstruct dev_pagemap *pgmap)",
            "{",
            "\tint rc = -ENXIO;",
            "",
            "\t/* device metadata space is not recoverable */",
            "\tif (!pgmap_pfn_valid(pgmap, pfn))",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * Call driver's implementation to handle the memory failure, otherwise",
            "\t * fall back to generic handler.",
            "\t */",
            "\tif (pgmap_has_memory_failure(pgmap)) {",
            "\t\trc = pgmap->ops->memory_failure(pgmap, pfn, 1, flags);",
            "\t\t/*",
            "\t\t * Fall back to generic handler too if operation is not",
            "\t\t * supported inside the driver/device/filesystem.",
            "\t\t */",
            "\t\tif (rc != -EOPNOTSUPP)",
            "\t\t\tgoto out;",
            "\t}",
            "",
            "\trc = mf_generic_kill_procs(pfn, flags, pgmap);",
            "out:",
            "\t/* drop pgmap ref acquired in caller */",
            "\tput_dev_pagemap(pgmap);",
            "\tif (rc != -EOPNOTSUPP)",
            "\t\taction_result(pfn, MF_MSG_DAX, rc ? MF_FAILED : MF_RECOVERED);",
            "\treturn rc;",
            "}"
          ],
          "function_name": "try_memory_failure_hugetlb, try_memory_failure_hugetlb, folio_free_raw_hwp, put_ref_page, memory_failure_dev_pagemap",
          "description": "try_memory_failure_hugetlb尝试处理大页HWPOISON，跳转至通用处理；folio_free_raw_hwp空实现；put_ref_page释放引用计数；memory_failure_dev_pagemap调用设备驱动处理HWPOISON页，失败则回退至通用处理",
          "similarity": 0.4986128807067871
        }
      ]
    }
  ]
}