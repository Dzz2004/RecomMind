{
  "query": "KVM virtualization",
  "timestamp": "2025-12-26 01:48:40",
  "retrieved_files": [
    {
      "source_file": "kernel/entry/kvm.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:19:39\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `entry\\kvm.c`\n\n---\n\n# entry/kvm.c 技术文档\n\n## 1. 文件概述\n\n`entry/kvm.c` 是 Linux 内核中 KVM（Kernel-based Virtual Machine）子系统的关键入口处理文件，主要负责在从内核态切换回客户机（guest）模式之前，检查并处理需要在返回用户态（或客户机态）前完成的延迟工作项（deferred work）。该文件实现了通用的“传输到客户机模式前的工作处理”逻辑，确保在进入客户机执行前，所有必要的内核任务（如信号处理、调度请求、通知回调等）都已正确处理。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`xfer_to_guest_mode_handle_work(struct kvm_vcpu *vcpu)`**  \n  公共接口函数，供 KVM 调用，用于在进入客户机模式前检查并处理待办工作项。若无线程标志需要处理，则直接返回 0；否则调用内部处理函数。\n\n- **`xfer_to_guest_mode_work(struct kvm_vcpu *vcpu, unsigned long ti_work)`**  \n  静态内部函数，循环处理所有与客户机模式切换相关的线程标志（thread flags），包括信号挂起、调度请求、用户态恢复通知以及架构特定的工作项。\n\n### 关键宏与标志\n\n- `_TIF_SIGPENDING`：表示有挂起的信号需要处理。\n- `_TIF_NOTIFY_SIGNAL`：表示有信号相关的通知需要处理。\n- `_TIF_NEED_RESCHED`：表示需要重新调度。\n- `_TIF_NOTIFY_RESUME`：表示在恢复用户态前需要执行通知回调。\n- `XFER_TO_GUEST_MODE_WORK`：组合宏，包含所有在切换到客户机模式前需处理的线程标志位。\n\n## 3. 关键实现\n\n- **工作项处理循环**：  \n  `xfer_to_guest_mode_work()` 使用 `do-while` 循环持续检查线程标志，确保在处理完一批工作后，新产生的标志也能被及时处理。循环条件为 `ti_work & XFER_TO_GUEST_MODE_WORK || need_resched()`，保证即使在处理过程中产生新的调度请求也能被覆盖。\n\n- **信号处理**：  \n  若检测到 `_TIF_SIGPENDING` 或 `_TIF_NOTIFY_SIGNAL`，立即调用 `kvm_handle_signal_exit(vcpu)` 并返回 `-EINTR`，中断客户机执行流程，使 VCPU 退出到用户态处理信号。\n\n- **调度处理**：  \n  若存在 `_TIF_NEED_RESCHED` 标志，调用 `schedule()` 主动让出 CPU，进行任务切换。\n\n- **用户态恢复通知**：  \n  若存在 `_TIF_NOTIFY_RESUME`，调用 `resume_user_mode_work(NULL)` 执行注册的恢复回调（如 seccomp、audit 等机制的钩子）。\n\n- **架构扩展支持**：  \n  通过 `arch_xfer_to_guest_mode_handle_work()` 允许不同架构（如 x86、ARM64）插入自定义的客户机切换前处理逻辑。\n\n- **中断上下文安全**：  \n  注释明确指出，该函数在**中断和抢占使能**的上下文中被调用（来自外层客户机循环），而 KVM 内层循环在禁用中断时会通过 `xfer_to_guest_mode_work_pending()` 检查是否需要处理工作，因此此处无需额外关中断。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/entry-kvm.h>`：定义 `XFER_TO_GUEST_MODE_WORK` 宏及 `xfer_to_guest_mode_handle_work()` 的声明。\n  - `<linux/kvm_host.h>`：提供 `kvm_vcpu` 结构体定义及 `kvm_handle_signal_exit()` 等 KVM 核心接口。\n\n- **架构依赖**：\n  - 依赖各架构实现的 `arch_xfer_to_guest_mode_handle_work()` 函数（通常在 `arch/*/kvm/` 目录下）。\n\n- **内核子系统依赖**：\n  - 依赖调度子系统（`schedule()`）。\n  - 依赖信号处理机制（通过 `kvm_handle_signal_exit()` 触发）。\n  - 依赖用户态恢复通知机制（`resume_user_mode_work()`，与 `TIF_NOTIFY_RESUME` 相关）。\n\n## 5. 使用场景\n\n- **KVM VCPU 运行循环**：  \n  在 KVM 的主运行循环（如 `vcpu_run()`）中，每次从内核态准备重新进入客户机执行前，调用 `xfer_to_guest_mode_handle_work()` 检查是否有待处理工作。\n\n- **异步事件响应**：  \n  当外部事件（如发送信号、定时器触发调度、seccomp 策略更新等）设置线程标志后，KVM 在下次进入客户机前通过此机制响应，确保客户机不会无限期运行而忽略内核事件。\n\n- **安全与合规机制集成**：  \n  通过 `_TIF_NOTIFY_RESUME` 机制，允许 LSM（Linux Security Modules）、audit、seccomp 等子系统在每次返回客户机前执行策略检查或日志记录。\n\n- **跨架构统一入口**：  \n  为所有支持 KVM 的架构提供统一的“客户机入口前工作处理”框架，架构差异通过 `arch_xfer_to_guest_mode_handle_work()` 抽象。",
      "similarity": 0.5855922102928162,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/entry/kvm.c",
          "start_line": 1,
          "end_line": 5,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "",
            "#include <linux/entry-kvm.h>",
            "#include <linux/kvm_host.h>",
            ""
          ],
          "function_name": null,
          "description": "包含KVM模块的许可证声明及核心头文件，为KVM入口点实现提供架构无关声明和宿主环境定义",
          "similarity": 0.5778108239173889
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/entry/kvm.c",
          "start_line": 6,
          "end_line": 47,
          "content": [
            "static int xfer_to_guest_mode_work(struct kvm_vcpu *vcpu, unsigned long ti_work)",
            "{",
            "\tdo {",
            "\t\tint ret;",
            "",
            "\t\tif (ti_work & (_TIF_SIGPENDING | _TIF_NOTIFY_SIGNAL)) {",
            "\t\t\tkvm_handle_signal_exit(vcpu);",
            "\t\t\treturn -EINTR;",
            "\t\t}",
            "",
            "\t\tif (ti_work & _TIF_NEED_RESCHED)",
            "\t\t\tschedule();",
            "",
            "\t\tif (ti_work & _TIF_NOTIFY_RESUME)",
            "\t\t\tresume_user_mode_work(NULL);",
            "",
            "\t\tret = arch_xfer_to_guest_mode_handle_work(vcpu, ti_work);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "",
            "\t\tti_work = read_thread_flags();",
            "\t} while (ti_work & XFER_TO_GUEST_MODE_WORK || need_resched());",
            "\treturn 0;",
            "}",
            "int xfer_to_guest_mode_handle_work(struct kvm_vcpu *vcpu)",
            "{",
            "\tunsigned long ti_work;",
            "",
            "\t/*",
            "\t * This is invoked from the outer guest loop with interrupts and",
            "\t * preemption enabled.",
            "\t *",
            "\t * KVM invokes xfer_to_guest_mode_work_pending() with interrupts",
            "\t * disabled in the inner loop before going into guest mode. No need",
            "\t * to disable interrupts here.",
            "\t */",
            "\tti_work = read_thread_flags();",
            "\tif (!(ti_work & XFER_TO_GUEST_MODE_WORK))",
            "\t\treturn 0;",
            "",
            "\treturn xfer_to_guest_mode_work(vcpu, ti_work);",
            "}"
          ],
          "function_name": "xfer_to_guest_mode_work, xfer_to_guest_mode_handle_work",
          "description": "实现从用户态到来宾态转换时的辅助工作处理，通过循环检查并处理信号、调度等任务标志位，最终调用架构特定函数完成实际转移逻辑",
          "similarity": 0.49848073720932007
        }
      ]
    },
    {
      "source_file": "mm/ksm.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:34:25\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `ksm.c`\n\n---\n\n# ksm.c 技术文档\n\n## 1. 文件概述\n\n`ksm.c` 实现了内核同页合并（Kernel Samepage Merging, KSM）功能，该机制能够动态识别并合并内容完全相同的物理内存页，即使这些页属于不同的进程地址空间且未通过 `fork()` 共享。KSM 通过后台扫描线程周期性地遍历注册的内存区域，利用红黑树（rbtree）结构高效地比对页面内容，将重复页替换为只读的共享页，从而显著减少物理内存占用。此功能特别适用于虚拟化环境中多个相似虚拟机共存的场景。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct ksm_mm_slot`**  \n  表示一个被 KSM 扫描的内存描述符（`mm_struct`）的元数据，包含哈希槽位和反向映射项链表头。\n\n- **`struct ksm_scan`**  \n  全局扫描游标，记录当前扫描进度（包括当前 `mm_slot`、虚拟地址、反向映射项指针及完整扫描轮次计数）。\n\n- **`struct ksm_stable_node`**  \n  稳定红黑树中的节点，代表一个已合并的 KSM 页面。包含：\n  - 红黑树节点或迁移链表指针（联合体复用）\n  - 指向使用该 KSM 页的所有 `rmap_item` 的哈希链表头\n  - 物理页帧号（`kpfn`）或链修剪时间戳\n  - 反向映射项数量（支持链式扩展）\n  - NUMA 节点 ID（若启用 NUMA）\n\n- **`struct ksm_rmap_item`**  \n  反向映射项，跟踪一个虚拟地址到其物理页的映射关系。包含：\n  - 所属 `mm_struct` 和虚拟地址（低比特位用于标志）\n  - 匿名 VMA 指针（稳定状态）或 NUMA 节点 ID（不稳定状态）\n  - 校验和（不稳定状态）\n  - 红黑树节点（不稳定树）或指向 `stable_node` 的指针及哈希链表节点（稳定状态）\n\n### 关键宏定义\n\n- **`STABLE_NODE_CHAIN`**  \n  标识稳定节点为“链”类型（值为 -1024），用于高效管理大量相同内容的 KSM 页副本。\n  \n- **标志位**  \n  - `UNSTABLE_FLAG` (0x100)：标识 `rmap_item` 属于不稳定树\n  - `STABLE_FLAG` (0x200)：标识 `rmap_item` 已链接到稳定树\n  - `SEQNR_MASK` (0x0ff)：用于存储不稳定树序列号的低 8 位\n\n## 3. 关键实现\n\n### 双树架构设计\nKSM 采用**稳定树（stable tree）**与**不稳定树（unstable tree）**协同工作的机制：\n- **稳定树**：存储已确认可合并的只读 KSM 页，因写保护而内容恒定，支持高效精确匹配。\n- **不稳定树**：临时缓存近期未修改的普通页，因内容可能变化而需周期性重建。\n\n### 扫描与合并流程\n1. **增量扫描**：全局游标 `ksm_scan` 遍历所有注册的 `mm_slot` 及其内存区域。\n2. **校验和预筛**：计算页面内容的 `xxhash` 校验和，仅当与上次扫描一致时才尝试插入不稳定树。\n3. **双阶段匹配**：\n   - 优先在**稳定树**中查找完全匹配的 KSM 页\n   - 若未命中，则在**不稳定树**中查找潜在重复页\n4. **树维护策略**：\n   - 不稳定树在每轮全量扫描结束后**完全清空重建**\n   - 稳定树**持久保留**，通过反向映射（rmap）和链式节点优化大规模合并场景\n5. **NUMA 感知**：若 `merge_across_nodes=0`，则为每个 NUMA 节点维护独立的稳定/不稳定树，避免跨节点内存访问开销。\n\n### 内存安全机制\n- **写保护**：合并后的 KSM 页设为只读，任何写操作触发 COW（写时复制）并解除合并。\n- **RMAP 集成**：通过 `anon_vma` 和反向映射链表，在页解绑时高效更新所有相关虚拟地址。\n- **OOM 防护**：在内存压力下可释放 KSM 页以缓解系统压力。\n\n## 4. 依赖关系\n\n- **内存管理子系统**：深度依赖 `mm.h`、`rmap.h`、`pagemap.h` 实现页表操作、反向映射和页生命周期管理。\n- **调度与进程管理**：通过 `sched/mm.h` 获取进程内存上下文，利用 `kthread.h` 创建后台扫描线程。\n- **NUMA 支持**：条件编译依赖 `CONFIG_NUMA`，使用 `numa.h` 实现节点亲和性。\n- **调试与追踪**：集成 `trace/events/ksm.h` 提供运行时事件追踪能力。\n- **哈希算法**：使用 `xxhash.h` 提供高效的内容指纹计算。\n- **内部辅助模块**：依赖 `mm_slot.h` 管理内存描述符槽位，`internal.h` 提供内核 MM 内部接口。\n\n## 5. 使用场景\n\n- **虚拟化环境**：在 KVM/Xen 等 Hypervisor 中合并多个相似虚拟机的内存页（如相同操作系统镜像）。\n- **内存密集型应用**：合并大型应用（如数据库、Web 服务器）中重复的静态数据或零页。\n- **容器化平台**：在 Docker/LXC 等容器运行时中减少同镜像容器的内存占用。\n- **内存超分场景**：在物理内存有限但允许超额分配的系统中提升内存利用率。\n- **开发调试**：通过 `/sys/kernel/mm/ksm/` 接口动态控制扫描速率、合并阈值等参数。",
      "similarity": 0.5564841032028198,
      "chunks": [
        {
          "chunk_id": 12,
          "file_path": "mm/ksm.c",
          "start_line": 3034,
          "end_line": 3143,
          "content": [
            "static void ksm_check_stable_tree(unsigned long start_pfn,",
            "\t\t\t\t  unsigned long end_pfn)",
            "{",
            "\tstruct ksm_stable_node *stable_node, *next;",
            "\tstruct rb_node *node;",
            "\tint nid;",
            "",
            "\tfor (nid = 0; nid < ksm_nr_node_ids; nid++) {",
            "\t\tnode = rb_first(root_stable_tree + nid);",
            "\t\twhile (node) {",
            "\t\t\tstable_node = rb_entry(node, struct ksm_stable_node, node);",
            "\t\t\tif (stable_node_chain_remove_range(stable_node,",
            "\t\t\t\t\t\t\t   start_pfn, end_pfn,",
            "\t\t\t\t\t\t\t   root_stable_tree +",
            "\t\t\t\t\t\t\t   nid))",
            "\t\t\t\tnode = rb_first(root_stable_tree + nid);",
            "\t\t\telse",
            "\t\t\t\tnode = rb_next(node);",
            "\t\t\tcond_resched();",
            "\t\t}",
            "\t}",
            "\tlist_for_each_entry_safe(stable_node, next, &migrate_nodes, list) {",
            "\t\tif (stable_node->kpfn >= start_pfn &&",
            "\t\t    stable_node->kpfn < end_pfn)",
            "\t\t\tremove_node_from_stable_tree(stable_node);",
            "\t\tcond_resched();",
            "\t}",
            "}",
            "static int ksm_memory_callback(struct notifier_block *self,",
            "\t\t\t       unsigned long action, void *arg)",
            "{",
            "\tstruct memory_notify *mn = arg;",
            "",
            "\tswitch (action) {",
            "\tcase MEM_GOING_OFFLINE:",
            "\t\t/*",
            "\t\t * Prevent ksm_do_scan(), unmerge_and_remove_all_rmap_items()",
            "\t\t * and remove_all_stable_nodes() while memory is going offline:",
            "\t\t * it is unsafe for them to touch the stable tree at this time.",
            "\t\t * But unmerge_ksm_pages(), rmap lookups and other entry points",
            "\t\t * which do not need the ksm_thread_mutex are all safe.",
            "\t\t */",
            "\t\tmutex_lock(&ksm_thread_mutex);",
            "\t\tksm_run |= KSM_RUN_OFFLINE;",
            "\t\tmutex_unlock(&ksm_thread_mutex);",
            "\t\tbreak;",
            "",
            "\tcase MEM_OFFLINE:",
            "\t\t/*",
            "\t\t * Most of the work is done by page migration; but there might",
            "\t\t * be a few stable_nodes left over, still pointing to struct",
            "\t\t * pages which have been offlined: prune those from the tree,",
            "\t\t * otherwise get_ksm_page() might later try to access a",
            "\t\t * non-existent struct page.",
            "\t\t */",
            "\t\tksm_check_stable_tree(mn->start_pfn,",
            "\t\t\t\t      mn->start_pfn + mn->nr_pages);",
            "\t\tfallthrough;",
            "\tcase MEM_CANCEL_OFFLINE:",
            "\t\tmutex_lock(&ksm_thread_mutex);",
            "\t\tksm_run &= ~KSM_RUN_OFFLINE;",
            "\t\tmutex_unlock(&ksm_thread_mutex);",
            "",
            "\t\tsmp_mb();\t/* wake_up_bit advises this */",
            "\t\twake_up_bit(&ksm_run, ilog2(KSM_RUN_OFFLINE));",
            "\t\tbreak;",
            "\t}",
            "\treturn NOTIFY_OK;",
            "}",
            "static void wait_while_offlining(void)",
            "{",
            "}",
            "bool ksm_process_mergeable(struct mm_struct *mm)",
            "{",
            "\tstruct vm_area_struct *vma;",
            "",
            "\tmmap_assert_locked(mm);",
            "\tVMA_ITERATOR(vmi, mm, 0);",
            "\tfor_each_vma(vmi, vma)",
            "\t\tif (vma->vm_flags & VM_MERGEABLE)",
            "\t\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "long ksm_process_profit(struct mm_struct *mm)",
            "{",
            "\treturn (long)(mm->ksm_merging_pages + mm_ksm_zero_pages(mm)) * PAGE_SIZE -",
            "\t\tmm->ksm_rmap_items * sizeof(struct ksm_rmap_item);",
            "}",
            "static ssize_t sleep_millisecs_show(struct kobject *kobj,",
            "\t\t\t\t    struct kobj_attribute *attr, char *buf)",
            "{",
            "\treturn sysfs_emit(buf, \"%u\\n\", ksm_thread_sleep_millisecs);",
            "}",
            "static ssize_t sleep_millisecs_store(struct kobject *kobj,",
            "\t\t\t\t     struct kobj_attribute *attr,",
            "\t\t\t\t     const char *buf, size_t count)",
            "{",
            "\tunsigned int msecs;",
            "\tint err;",
            "",
            "\terr = kstrtouint(buf, 10, &msecs);",
            "\tif (err)",
            "\t\treturn -EINVAL;",
            "",
            "\tksm_thread_sleep_millisecs = msecs;",
            "\twake_up_interruptible(&ksm_iter_wait);",
            "",
            "\treturn count;",
            "}"
          ],
          "function_name": "ksm_check_stable_tree, ksm_memory_callback, wait_while_offlining, ksm_process_mergeable, ksm_process_profit, sleep_millisecs_show, sleep_millisecs_store",
          "description": "ksm_check_stable_tree扫描稳定树移除指定PFN范围节点；ksm_memory_callback处理内存离线/取消离线事件，同步KSMAPI状态；ksm_process_mergeable检测进程是否含可合并VMA；ksm_process_profit计算KSMAPI收益；sleep_millisecs_*控制KSMAPI线程休眠时间",
          "similarity": 0.5445411801338196
        },
        {
          "chunk_id": 9,
          "file_path": "mm/ksm.c",
          "start_line": 2608,
          "end_line": 2731,
          "content": [
            "int ksm_enable_merge_any(struct mm_struct *mm)",
            "{",
            "\tint err;",
            "",
            "\tif (test_bit(MMF_VM_MERGE_ANY, &mm->flags))",
            "\t\treturn 0;",
            "",
            "\tif (!test_bit(MMF_VM_MERGEABLE, &mm->flags)) {",
            "\t\terr = __ksm_enter(mm);",
            "\t\tif (err)",
            "\t\t\treturn err;",
            "\t}",
            "",
            "\tset_bit(MMF_VM_MERGE_ANY, &mm->flags);",
            "\tksm_add_vmas(mm);",
            "",
            "\treturn 0;",
            "}",
            "int ksm_disable_merge_any(struct mm_struct *mm)",
            "{",
            "\tint err;",
            "",
            "\tif (!test_bit(MMF_VM_MERGE_ANY, &mm->flags))",
            "\t\treturn 0;",
            "",
            "\terr = ksm_del_vmas(mm);",
            "\tif (err) {",
            "\t\tksm_add_vmas(mm);",
            "\t\treturn err;",
            "\t}",
            "",
            "\tclear_bit(MMF_VM_MERGE_ANY, &mm->flags);",
            "\treturn 0;",
            "}",
            "int ksm_disable(struct mm_struct *mm)",
            "{",
            "\tmmap_assert_write_locked(mm);",
            "",
            "\tif (!test_bit(MMF_VM_MERGEABLE, &mm->flags))",
            "\t\treturn 0;",
            "\tif (test_bit(MMF_VM_MERGE_ANY, &mm->flags))",
            "\t\treturn ksm_disable_merge_any(mm);",
            "\treturn ksm_del_vmas(mm);",
            "}",
            "int ksm_madvise(struct vm_area_struct *vma, unsigned long start,",
            "\t\tunsigned long end, int advice, unsigned long *vm_flags)",
            "{",
            "\tstruct mm_struct *mm = vma->vm_mm;",
            "\tint err;",
            "",
            "\tswitch (advice) {",
            "\tcase MADV_MERGEABLE:",
            "\t\tif (vma->vm_flags & VM_MERGEABLE)",
            "\t\t\treturn 0;",
            "\t\tif (!vma_ksm_compatible(vma))",
            "\t\t\treturn 0;",
            "",
            "\t\tif (!test_bit(MMF_VM_MERGEABLE, &mm->flags)) {",
            "\t\t\terr = __ksm_enter(mm);",
            "\t\t\tif (err)",
            "\t\t\t\treturn err;",
            "\t\t}",
            "",
            "\t\t*vm_flags |= VM_MERGEABLE;",
            "\t\tbreak;",
            "",
            "\tcase MADV_UNMERGEABLE:",
            "\t\tif (!(*vm_flags & VM_MERGEABLE))",
            "\t\t\treturn 0;\t\t/* just ignore the advice */",
            "",
            "\t\tif (vma->anon_vma) {",
            "\t\t\terr = unmerge_ksm_pages(vma, start, end, true);",
            "\t\t\tif (err)",
            "\t\t\t\treturn err;",
            "\t\t}",
            "",
            "\t\t*vm_flags &= ~VM_MERGEABLE;",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int __ksm_enter(struct mm_struct *mm)",
            "{",
            "\tstruct ksm_mm_slot *mm_slot;",
            "\tstruct mm_slot *slot;",
            "\tint needs_wakeup;",
            "",
            "\tmm_slot = mm_slot_alloc(mm_slot_cache);",
            "\tif (!mm_slot)",
            "\t\treturn -ENOMEM;",
            "",
            "\tslot = &mm_slot->slot;",
            "",
            "\t/* Check ksm_run too?  Would need tighter locking */",
            "\tneeds_wakeup = list_empty(&ksm_mm_head.slot.mm_node);",
            "",
            "\tspin_lock(&ksm_mmlist_lock);",
            "\tmm_slot_insert(mm_slots_hash, mm, slot);",
            "\t/*",
            "\t * When KSM_RUN_MERGE (or KSM_RUN_STOP),",
            "\t * insert just behind the scanning cursor, to let the area settle",
            "\t * down a little; when fork is followed by immediate exec, we don't",
            "\t * want ksmd to waste time setting up and tearing down an rmap_list.",
            "\t *",
            "\t * But when KSM_RUN_UNMERGE, it's important to insert ahead of its",
            "\t * scanning cursor, otherwise KSM pages in newly forked mms will be",
            "\t * missed: then we might as well insert at the end of the list.",
            "\t */",
            "\tif (ksm_run & KSM_RUN_UNMERGE)",
            "\t\tlist_add_tail(&slot->mm_node, &ksm_mm_head.slot.mm_node);",
            "\telse",
            "\t\tlist_add_tail(&slot->mm_node, &ksm_scan.mm_slot->slot.mm_node);",
            "\tspin_unlock(&ksm_mmlist_lock);",
            "",
            "\tset_bit(MMF_VM_MERGEABLE, &mm->flags);",
            "\tmmgrab(mm);",
            "",
            "\tif (needs_wakeup)",
            "\t\twake_up_interruptible(&ksm_thread_wait);",
            "",
            "\ttrace_ksm_enter(mm);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "ksm_enable_merge_any, ksm_disable_merge_any, ksm_disable, ksm_madvise, __ksm_enter",
          "description": "ksm_enable_merge_any 启用全局合并标志并注册内存区域。ksm_disable_merge_any 禁用合并并清理配置。ksm_disable 移除所有KSM配置。ksm_madvise 处理MADV_MERGEABLE/MADV_UNMERGEABLE建议，调整页面属性。__ksm_enter 注册内存区域到KSM管理系统。",
          "similarity": 0.5352988243103027
        },
        {
          "chunk_id": 2,
          "file_path": "mm/ksm.c",
          "start_line": 486,
          "end_line": 622,
          "content": [
            "static int break_ksm(struct vm_area_struct *vma, unsigned long addr, bool lock_vma)",
            "{",
            "\tvm_fault_t ret = 0;",
            "\tconst struct mm_walk_ops *ops = lock_vma ?",
            "\t\t\t\t&break_ksm_lock_vma_ops : &break_ksm_ops;",
            "",
            "\tdo {",
            "\t\tint ksm_page;",
            "",
            "\t\tcond_resched();",
            "\t\tksm_page = walk_page_range_vma(vma, addr, addr + 1, ops, NULL);",
            "\t\tif (WARN_ON_ONCE(ksm_page < 0))",
            "\t\t\treturn ksm_page;",
            "\t\tif (!ksm_page)",
            "\t\t\treturn 0;",
            "\t\tret = handle_mm_fault(vma, addr,",
            "\t\t\t\t      FAULT_FLAG_UNSHARE | FAULT_FLAG_REMOTE,",
            "\t\t\t\t      NULL);",
            "\t} while (!(ret & (VM_FAULT_SIGBUS | VM_FAULT_SIGSEGV | VM_FAULT_OOM)));",
            "\t/*",
            "\t * We must loop until we no longer find a KSM page because",
            "\t * handle_mm_fault() may back out if there's any difficulty e.g. if",
            "\t * pte accessed bit gets updated concurrently.",
            "\t *",
            "\t * VM_FAULT_SIGBUS could occur if we race with truncation of the",
            "\t * backing file, which also invalidates anonymous pages: that's",
            "\t * okay, that truncation will have unmapped the PageKsm for us.",
            "\t *",
            "\t * VM_FAULT_OOM: at the time of writing (late July 2009), setting",
            "\t * aside mem_cgroup limits, VM_FAULT_OOM would only be set if the",
            "\t * current task has TIF_MEMDIE set, and will be OOM killed on return",
            "\t * to user; and ksmd, having no mm, would never be chosen for that.",
            "\t *",
            "\t * But if the mm is in a limited mem_cgroup, then the fault may fail",
            "\t * with VM_FAULT_OOM even if the current task is not TIF_MEMDIE; and",
            "\t * even ksmd can fail in this way - though it's usually breaking ksm",
            "\t * just to undo a merge it made a moment before, so unlikely to oom.",
            "\t *",
            "\t * That's a pity: we might therefore have more kernel pages allocated",
            "\t * than we're counting as nodes in the stable tree; but ksm_do_scan",
            "\t * will retry to break_cow on each pass, so should recover the page",
            "\t * in due course.  The important thing is to not let VM_MERGEABLE",
            "\t * be cleared while any such pages might remain in the area.",
            "\t */",
            "\treturn (ret & VM_FAULT_OOM) ? -ENOMEM : 0;",
            "}",
            "static bool vma_ksm_compatible(struct vm_area_struct *vma)",
            "{",
            "\tif (vma->vm_flags & (VM_SHARED  | VM_MAYSHARE   | VM_PFNMAP  |",
            "\t\t\t     VM_IO      | VM_DONTEXPAND | VM_HUGETLB |",
            "\t\t\t     VM_MIXEDMAP))",
            "\t\treturn false;\t\t/* just ignore the advice */",
            "",
            "\tif (vma_is_dax(vma))",
            "\t\treturn false;",
            "",
            "#ifdef VM_SAO",
            "\tif (vma->vm_flags & VM_SAO)",
            "\t\treturn false;",
            "#endif",
            "#ifdef VM_SPARC_ADI",
            "\tif (vma->vm_flags & VM_SPARC_ADI)",
            "\t\treturn false;",
            "#endif",
            "",
            "\treturn true;",
            "}",
            "static void break_cow(struct ksm_rmap_item *rmap_item)",
            "{",
            "\tstruct mm_struct *mm = rmap_item->mm;",
            "\tunsigned long addr = rmap_item->address;",
            "\tstruct vm_area_struct *vma;",
            "",
            "\t/*",
            "\t * It is not an accident that whenever we want to break COW",
            "\t * to undo, we also need to drop a reference to the anon_vma.",
            "\t */",
            "\tput_anon_vma(rmap_item->anon_vma);",
            "",
            "\tmmap_read_lock(mm);",
            "\tvma = find_mergeable_vma(mm, addr);",
            "\tif (vma)",
            "\t\tbreak_ksm(vma, addr, false);",
            "\tmmap_read_unlock(mm);",
            "}",
            "static inline int get_kpfn_nid(unsigned long kpfn)",
            "{",
            "\treturn ksm_merge_across_nodes ? 0 : NUMA(pfn_to_nid(kpfn));",
            "}",
            "static inline void free_stable_node_chain(struct ksm_stable_node *chain,",
            "\t\t\t\t\t  struct rb_root *root)",
            "{",
            "\trb_erase(&chain->node, root);",
            "\tfree_stable_node(chain);",
            "\tksm_stable_node_chains--;",
            "}",
            "static void remove_node_from_stable_tree(struct ksm_stable_node *stable_node)",
            "{",
            "\tstruct ksm_rmap_item *rmap_item;",
            "",
            "\t/* check it's not STABLE_NODE_CHAIN or negative */",
            "\tBUG_ON(stable_node->rmap_hlist_len < 0);",
            "",
            "\thlist_for_each_entry(rmap_item, &stable_node->hlist, hlist) {",
            "\t\tif (rmap_item->hlist.next) {",
            "\t\t\tksm_pages_sharing--;",
            "\t\t\ttrace_ksm_remove_rmap_item(stable_node->kpfn, rmap_item, rmap_item->mm);",
            "\t\t} else {",
            "\t\t\tksm_pages_shared--;",
            "\t\t}",
            "",
            "\t\trmap_item->mm->ksm_merging_pages--;",
            "",
            "\t\tVM_BUG_ON(stable_node->rmap_hlist_len <= 0);",
            "\t\tstable_node->rmap_hlist_len--;",
            "\t\tput_anon_vma(rmap_item->anon_vma);",
            "\t\trmap_item->address &= PAGE_MASK;",
            "\t\tcond_resched();",
            "\t}",
            "",
            "\t/*",
            "\t * We need the second aligned pointer of the migrate_nodes",
            "\t * list_head to stay clear from the rb_parent_color union",
            "\t * (aligned and different than any node) and also different",
            "\t * from &migrate_nodes. This will verify that future list.h changes",
            "\t * don't break STABLE_NODE_DUP_HEAD. Only recent gcc can handle it.",
            "\t */",
            "\tBUILD_BUG_ON(STABLE_NODE_DUP_HEAD <= &migrate_nodes);",
            "\tBUILD_BUG_ON(STABLE_NODE_DUP_HEAD >= &migrate_nodes + 1);",
            "",
            "\ttrace_ksm_remove_ksm_page(stable_node->kpfn);",
            "\tif (stable_node->head == &migrate_nodes)",
            "\t\tlist_del(&stable_node->list);",
            "\telse",
            "\t\tstable_node_dup_del(stable_node);",
            "\tfree_stable_node(stable_node);",
            "}"
          ],
          "function_name": "break_ksm, vma_ksm_compatible, break_cow, get_kpfn_nid, free_stable_node_chain, remove_node_from_stable_tree",
          "description": "实现KSM页面分解逻辑，包含检查VMA是否兼容KSM、强制打破写时复制（COW）操作、获取KPFN NUMA节点ID以及稳定树节点链表清理等功能。核心作用是执行实际的KSM页面分离操作并维护稳定树结构。",
          "similarity": 0.5337348580360413
        },
        {
          "chunk_id": 4,
          "file_path": "mm/ksm.c",
          "start_line": 963,
          "end_line": 1081,
          "content": [
            "static int remove_stable_node_chain(struct ksm_stable_node *stable_node,",
            "\t\t\t\t    struct rb_root *root)",
            "{",
            "\tstruct ksm_stable_node *dup;",
            "\tstruct hlist_node *hlist_safe;",
            "",
            "\tif (!is_stable_node_chain(stable_node)) {",
            "\t\tVM_BUG_ON(is_stable_node_dup(stable_node));",
            "\t\tif (remove_stable_node(stable_node))",
            "\t\t\treturn true;",
            "\t\telse",
            "\t\t\treturn false;",
            "\t}",
            "",
            "\thlist_for_each_entry_safe(dup, hlist_safe,",
            "\t\t\t\t  &stable_node->hlist, hlist_dup) {",
            "\t\tVM_BUG_ON(!is_stable_node_dup(dup));",
            "\t\tif (remove_stable_node(dup))",
            "\t\t\treturn true;",
            "\t}",
            "\tBUG_ON(!hlist_empty(&stable_node->hlist));",
            "\tfree_stable_node_chain(stable_node, root);",
            "\treturn false;",
            "}",
            "static int remove_all_stable_nodes(void)",
            "{",
            "\tstruct ksm_stable_node *stable_node, *next;",
            "\tint nid;",
            "\tint err = 0;",
            "",
            "\tfor (nid = 0; nid < ksm_nr_node_ids; nid++) {",
            "\t\twhile (root_stable_tree[nid].rb_node) {",
            "\t\t\tstable_node = rb_entry(root_stable_tree[nid].rb_node,",
            "\t\t\t\t\t\tstruct ksm_stable_node, node);",
            "\t\t\tif (remove_stable_node_chain(stable_node,",
            "\t\t\t\t\t\t     root_stable_tree + nid)) {",
            "\t\t\t\terr = -EBUSY;",
            "\t\t\t\tbreak;\t/* proceed to next nid */",
            "\t\t\t}",
            "\t\t\tcond_resched();",
            "\t\t}",
            "\t}",
            "\tlist_for_each_entry_safe(stable_node, next, &migrate_nodes, list) {",
            "\t\tif (remove_stable_node(stable_node))",
            "\t\t\terr = -EBUSY;",
            "\t\tcond_resched();",
            "\t}",
            "\treturn err;",
            "}",
            "static int unmerge_and_remove_all_rmap_items(void)",
            "{",
            "\tstruct ksm_mm_slot *mm_slot;",
            "\tstruct mm_slot *slot;",
            "\tstruct mm_struct *mm;",
            "\tstruct vm_area_struct *vma;",
            "\tint err = 0;",
            "",
            "\tspin_lock(&ksm_mmlist_lock);",
            "\tslot = list_entry(ksm_mm_head.slot.mm_node.next,",
            "\t\t\t  struct mm_slot, mm_node);",
            "\tksm_scan.mm_slot = mm_slot_entry(slot, struct ksm_mm_slot, slot);",
            "\tspin_unlock(&ksm_mmlist_lock);",
            "",
            "\tfor (mm_slot = ksm_scan.mm_slot; mm_slot != &ksm_mm_head;",
            "\t     mm_slot = ksm_scan.mm_slot) {",
            "\t\tVMA_ITERATOR(vmi, mm_slot->slot.mm, 0);",
            "",
            "\t\tmm = mm_slot->slot.mm;",
            "\t\tmmap_read_lock(mm);",
            "",
            "\t\t/*",
            "\t\t * Exit right away if mm is exiting to avoid lockdep issue in",
            "\t\t * the maple tree",
            "\t\t */",
            "\t\tif (ksm_test_exit(mm))",
            "\t\t\tgoto mm_exiting;",
            "",
            "\t\tfor_each_vma(vmi, vma) {",
            "\t\t\tif (!(vma->vm_flags & VM_MERGEABLE) || !vma->anon_vma)",
            "\t\t\t\tcontinue;",
            "\t\t\terr = unmerge_ksm_pages(vma,",
            "\t\t\t\t\t\tvma->vm_start, vma->vm_end, false);",
            "\t\t\tif (err)",
            "\t\t\t\tgoto error;",
            "\t\t}",
            "",
            "mm_exiting:",
            "\t\tremove_trailing_rmap_items(&mm_slot->rmap_list);",
            "\t\tmmap_read_unlock(mm);",
            "",
            "\t\tspin_lock(&ksm_mmlist_lock);",
            "\t\tslot = list_entry(mm_slot->slot.mm_node.next,",
            "\t\t\t\t  struct mm_slot, mm_node);",
            "\t\tksm_scan.mm_slot = mm_slot_entry(slot, struct ksm_mm_slot, slot);",
            "\t\tif (ksm_test_exit(mm)) {",
            "\t\t\thash_del(&mm_slot->slot.hash);",
            "\t\t\tlist_del(&mm_slot->slot.mm_node);",
            "\t\t\tspin_unlock(&ksm_mmlist_lock);",
            "",
            "\t\t\tmm_slot_free(mm_slot_cache, mm_slot);",
            "\t\t\tclear_bit(MMF_VM_MERGEABLE, &mm->flags);",
            "\t\t\tclear_bit(MMF_VM_MERGE_ANY, &mm->flags);",
            "\t\t\tmmdrop(mm);",
            "\t\t} else",
            "\t\t\tspin_unlock(&ksm_mmlist_lock);",
            "\t}",
            "",
            "\t/* Clean up stable nodes, but don't worry if some are still busy */",
            "\tremove_all_stable_nodes();",
            "\tksm_scan.seqnr = 0;",
            "\treturn 0;",
            "",
            "error:",
            "\tmmap_read_unlock(mm);",
            "\tspin_lock(&ksm_mmlist_lock);",
            "\tksm_scan.mm_slot = &ksm_mm_head;",
            "\tspin_unlock(&ksm_mmlist_lock);",
            "\treturn err;",
            "}"
          ],
          "function_name": "remove_stable_node_chain, remove_all_stable_nodes, unmerge_and_remove_all_rmap_items",
          "description": "实现稳定节点链表深度清理、全部稳定节点移除及反向映射项完全卸载逻辑。核心作用是彻底释放KSM占用的所有资源，包括稳定树节点、反向映射项和相关内存结构，确保系统状态一致性。",
          "similarity": 0.5269331336021423
        },
        {
          "chunk_id": 10,
          "file_path": "mm/ksm.c",
          "start_line": 2750,
          "end_line": 2860,
          "content": [
            "void __ksm_exit(struct mm_struct *mm)",
            "{",
            "\tstruct ksm_mm_slot *mm_slot;",
            "\tstruct mm_slot *slot;",
            "\tint easy_to_free = 0;",
            "",
            "\t/*",
            "\t * This process is exiting: if it's straightforward (as is the",
            "\t * case when ksmd was never running), free mm_slot immediately.",
            "\t * But if it's at the cursor or has rmap_items linked to it, use",
            "\t * mmap_lock to synchronize with any break_cows before pagetables",
            "\t * are freed, and leave the mm_slot on the list for ksmd to free.",
            "\t * Beware: ksm may already have noticed it exiting and freed the slot.",
            "\t */",
            "",
            "\tspin_lock(&ksm_mmlist_lock);",
            "\tslot = mm_slot_lookup(mm_slots_hash, mm);",
            "\tmm_slot = mm_slot_entry(slot, struct ksm_mm_slot, slot);",
            "\tif (mm_slot && ksm_scan.mm_slot != mm_slot) {",
            "\t\tif (!mm_slot->rmap_list) {",
            "\t\t\thash_del(&slot->hash);",
            "\t\t\tlist_del(&slot->mm_node);",
            "\t\t\teasy_to_free = 1;",
            "\t\t} else {",
            "\t\t\tlist_move(&slot->mm_node,",
            "\t\t\t\t  &ksm_scan.mm_slot->slot.mm_node);",
            "\t\t}",
            "\t}",
            "\tspin_unlock(&ksm_mmlist_lock);",
            "",
            "\tif (easy_to_free) {",
            "\t\tmm_slot_free(mm_slot_cache, mm_slot);",
            "\t\tclear_bit(MMF_VM_MERGE_ANY, &mm->flags);",
            "\t\tclear_bit(MMF_VM_MERGEABLE, &mm->flags);",
            "\t\tmmdrop(mm);",
            "\t} else if (mm_slot) {",
            "\t\tmmap_write_lock(mm);",
            "\t\tmmap_write_unlock(mm);",
            "\t}",
            "",
            "\ttrace_ksm_exit(mm);",
            "}",
            "void rmap_walk_ksm(struct folio *folio, struct rmap_walk_control *rwc)",
            "{",
            "\tstruct ksm_stable_node *stable_node;",
            "\tstruct ksm_rmap_item *rmap_item;",
            "\tint search_new_forks = 0;",
            "",
            "\tVM_BUG_ON_FOLIO(!folio_test_ksm(folio), folio);",
            "",
            "\t/*",
            "\t * Rely on the page lock to protect against concurrent modifications",
            "\t * to that page's node of the stable tree.",
            "\t */",
            "\tVM_BUG_ON_FOLIO(!folio_test_locked(folio), folio);",
            "",
            "\tstable_node = folio_stable_node(folio);",
            "\tif (!stable_node)",
            "\t\treturn;",
            "again:",
            "\thlist_for_each_entry(rmap_item, &stable_node->hlist, hlist) {",
            "\t\tstruct anon_vma *anon_vma = rmap_item->anon_vma;",
            "\t\tstruct anon_vma_chain *vmac;",
            "\t\tstruct vm_area_struct *vma;",
            "",
            "\t\tcond_resched();",
            "\t\tif (!anon_vma_trylock_read(anon_vma)) {",
            "\t\t\tif (rwc->try_lock) {",
            "\t\t\t\trwc->contended = true;",
            "\t\t\t\treturn;",
            "\t\t\t}",
            "\t\t\tanon_vma_lock_read(anon_vma);",
            "\t\t}",
            "\t\tanon_vma_interval_tree_foreach(vmac, &anon_vma->rb_root,",
            "\t\t\t\t\t       0, ULONG_MAX) {",
            "\t\t\tunsigned long addr;",
            "",
            "\t\t\tcond_resched();",
            "\t\t\tvma = vmac->vma;",
            "",
            "\t\t\t/* Ignore the stable/unstable/sqnr flags */",
            "\t\t\taddr = rmap_item->address & PAGE_MASK;",
            "",
            "\t\t\tif (addr < vma->vm_start || addr >= vma->vm_end)",
            "\t\t\t\tcontinue;",
            "\t\t\t/*",
            "\t\t\t * Initially we examine only the vma which covers this",
            "\t\t\t * rmap_item; but later, if there is still work to do,",
            "\t\t\t * we examine covering vmas in other mms: in case they",
            "\t\t\t * were forked from the original since ksmd passed.",
            "\t\t\t */",
            "\t\t\tif ((rmap_item->mm == vma->vm_mm) == search_new_forks)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tif (rwc->invalid_vma && rwc->invalid_vma(vma, rwc->arg))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tif (!rwc->rmap_one(folio, vma, addr, rwc->arg)) {",
            "\t\t\t\tanon_vma_unlock_read(anon_vma);",
            "\t\t\t\treturn;",
            "\t\t\t}",
            "\t\t\tif (rwc->done && rwc->done(folio)) {",
            "\t\t\t\tanon_vma_unlock_read(anon_vma);",
            "\t\t\t\treturn;",
            "\t\t\t}",
            "\t\t}",
            "\t\tanon_vma_unlock_read(anon_vma);",
            "\t}",
            "\tif (!search_new_forks++)",
            "\t\tgoto again;",
            "}"
          ],
          "function_name": "__ksm_exit, rmap_walk_ksm",
          "description": "__ksm_exit清理进程退出时的KSMAPI结构，根据是否存在rmap链表决定立即释放或延迟释放mm_slot；rmap_walk_ksm遍历稳定树项，通过匿名VMA区间树查找匹配的VMA并调用rmap回调",
          "similarity": 0.5231180787086487
        }
      ]
    },
    {
      "source_file": "kernel/locking/qspinlock_paravirt.h",
      "md_summary": "> 自动生成时间: 2025-10-25 14:46:42\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\qspinlock_paravirt.h`\n\n---\n\n# `locking/qspinlock_paravirt.h` 技术文档\n\n## 1. 文件概述\n\n`qspinlock_paravirt.h` 是 Linux 内核中用于实现 **半虚拟化（paravirtualized, PV）队列自旋锁（qspinlock）** 的头文件。其核心目标是在虚拟化环境中优化自旋锁行为：当虚拟 CPU（vCPU）无法立即获取锁时，不进行忙等待（busy-waiting），而是通过 **挂起（halt）** 当前 vCPU 并等待被唤醒，从而显著降低在锁竞争激烈或宿主机过载（overcommitted）场景下的 CPU 资源浪费和延迟。\n\n该文件依赖架构层提供的两个关键半虚拟化超调用（hypercall）：\n- `pv_wait(u8 *ptr, u8 val)`：当 `*ptr == val` 时挂起当前 vCPU。\n- `pv_kick(cpu)`：唤醒指定的已挂起 vCPU。\n\n此文件 **不能直接包含**，必须通过定义 `_GEN_PV_LOCK_SLOWPATH` 宏后由其他文件（如 `qspinlock.c`）条件包含，以替换原生的慢路径锁实现。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`enum vcpu_state`**  \n  表示 vCPU 在锁等待队列中的状态：\n  - `vcpu_running`：正在运行（默认状态）。\n  - `vcpu_halted`：已挂起，等待被唤醒（仅用于 `pv_wait_node`）。\n  - `vcpu_hashed`：已挂起且其节点信息已加入哈希表（用于快速查找）。\n\n- **`struct pv_node`**  \n  扩展的 MCS 锁节点，包含：\n  - `mcs`：标准 MCS 自旋锁节点。\n  - `cpu`：关联的 CPU ID。\n  - `state`：当前 vCPU 状态（`vcpu_state` 枚举值）。\n\n- **`struct pv_hash_entry`**  \n  哈希表条目，用于快速映射锁地址到对应的 `pv_node`：\n  - `lock`：指向 `qspinlock` 的指针。\n  - `node`：指向 `pv_node` 的指针。\n\n### 主要函数与宏\n\n- **`pv_hybrid_queued_unfair_trylock()`**  \n  实现混合模式的锁尝试获取逻辑，结合了公平队列锁与非公平锁的优点。\n\n- **`set_pending()` / `trylock_clear_pending()`**  \n  操作锁的 `pending` 位，用于协调队列头 vCPU 与新到来的竞争者。\n\n- **`__pv_init_lock_hash()`**  \n  初始化 PV 锁哈希表，分配足够大的内存空间以支持所有可能的 CPU。\n\n- **`pv_hash()` / `pv_unhash()`**  \n  在哈希表中插入/删除锁与节点的映射关系，用于快速唤醒等待者。\n\n- **`pv_wait_early()`**  \n  （代码不完整）用于判断是否应提前检查前驱节点状态并挂起当前 vCPU。\n\n### 关键宏定义\n\n- **`PV_PREV_CHECK_MASK`**  \n  控制检查前驱节点状态的频率（每 256 次循环检查一次），避免缓存行抖动。\n\n- **`_Q_SLOW_VAL`**  \n  表示锁处于慢路径状态的值（`locked=1, pending=1`）。\n\n- **`queued_spin_trylock`**  \n  重定义为 `pv_hybrid_queued_unfair_trylock`，启用混合锁机制。\n\n## 3. 关键实现\n\n### 混合 PV 队列/非公平锁机制\n\n该实现采用 **混合策略**：\n- 当锁的 MCS 等待队列为空或 `pending` 位未设置时，新竞争者尝试 **非公平方式抢锁**（直接 CAS `locked` 位），提升低竞争场景性能。\n- 一旦有 vCPU 进入等待队列并成为队列头，它会设置 `pending` 位，**禁止后续抢锁**，强制新竞争者进入公平队列，避免锁饥饿。\n- 队列头 vCPU 在自旋等待锁释放时保持 `pending=1`，确保公平性。\n\n### 自适应挂起（Adaptive Spinning）\n\n- 等待队列中的 vCPU 会周期性（由 `PV_PREV_CHECK_MASK` 控制）检查 **前驱节点是否正在运行**。\n- 若前驱 **未运行**（如已挂起），当前 vCPU 也立即挂起，避免无意义的忙等。\n- 此机制在虚拟化过载环境中显著减少 CPU 浪费，同时在非过载场景下通过一次抢锁尝试维持性能。\n\n### 锁-节点哈希表\n\n- 为支持 `pv_kick()` 快速定位等待某锁的 vCPU，内核维护一个全局哈希表 `pv_lock_hash`。\n- 哈希表大小为 `4 * num_possible_cpus()`，确保即使在最大嵌套深度（4 层）下也有足够条目。\n- 使用 **开放寻址法**，每缓存行存放多个条目（`PV_HE_PER_LINE`），减少缓存未命中。\n- 锁持有者在释放锁前必须调用 `pv_unhash()` 移除映射，保证哈希表一致性。\n\n### Pending 位操作优化\n\n- 根据 `_Q_PENDING_BITS` 是否为 8（即 `pending` 字段是否独立字节），提供两种实现：\n  - **独立字节**：直接写 `pending` 字段，使用 `cmpxchg_acquire` 尝试获取锁。\n  - **共享字段**：使用原子位操作（`atomic_or` / `atomic_cmpxchg_acquire`）修改 `val`。\n\n## 4. 依赖关系\n\n- **架构依赖**：必须由底层架构（如 x86 KVM/Xen）提供 `pv_wait()` 和 `pv_kick()` 超调用。\n- **头文件依赖**：\n  - `<linux/hash.h>`：提供 `hash_ptr()` 哈希函数。\n  - `<linux/memblock.h>`：用于早期内存分配（`alloc_large_system_hash`）。\n  - `<linux/debug_locks.h>`：锁调试支持。\n- **锁核心依赖**：基于 `qspinlock` 和 `mcs_spinlock` 实现，需与 `locking/qspinlock.c` 协同工作。\n- **编译依赖**：必须由定义了 `_GEN_PV_LOCK_SLOWPATH` 的源文件包含，不能独立编译。\n\n## 5. 使用场景\n\n- **虚拟化环境**：主要在 KVM、Xen 等半虚拟化 Hypervisor 上启用，优化多 vCPU 虚拟机中的锁竞争。\n- **高竞争锁场景**：当多个 vCPU 频繁争用同一自旋锁时，避免忙等待导致的宿主机 CPU 资源耗尽。\n- **过载宿主机**：在物理 CPU 资源不足时，挂起等待锁的 vCPU 可减少调度开销和上下文切换延迟。\n- **混合工作负载**：通过混合锁机制，在低竞争时保持高性能，高竞争时保证公平性，适用于通用服务器场景。",
      "similarity": 0.5300443172454834,
      "chunks": []
    }
  ]
}