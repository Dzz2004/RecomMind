{
  "query": "内存故障处理中的页面隔离策略",
  "timestamp": "2025-12-26 01:28:21",
  "retrieved_files": [
    {
      "source_file": "mm/page_isolation.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:03:40\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `page_isolation.c`\n\n---\n\n# page_isolation.c 技术文档\n\n## 1. 文件概述\n\n`page_isolation.c` 是 Linux 内核内存管理子系统中的关键组件，主要负责**页面隔离（Page Isolation）**功能。该文件实现了将指定物理内存范围内的页面块（pageblock）标记为 `MIGRATE_ISOLATE` 迁移类型的能力，从而阻止分配器从此区域分配新页面。此机制主要用于**连续内存分配（CMA）**和**内存热插拔（Memory Hotplug）**场景，确保在执行内存迁移或离线操作前，目标区域不再被普通分配器使用。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`has_unmovable_pages()`**  \n  检查指定 PFN 范围 `[start_pfn, end_pfn)` 内是否存在不可移动页面。返回首个不可移动页面的指针（不持有引用），若全部可移动则返回 `NULL`。\n\n- **`set_migratetype_isolate()`**  \n  将包含指定页面的 pageblock 的迁移类型设置为 `MIGRATE_ISOLATE`。前提是该范围内无不可移动页面。成功时返回 0，否则返回 `-EBUSY`。\n\n- **`unset_migratetype_isolate()`**  \n  恢复 pageblock 的原始迁移类型，取消隔离状态，并将隔离期间产生的空闲页面归还到对应迁移类型的空闲链表中。\n\n- **`__first_valid_page()`**（代码片段未完整）  \n  辅助函数，用于在给定 PFN 范围内查找第一个有效的 struct page 实例。\n\n### 关键数据结构与宏\n\n- **`MIGRATE_ISOLATE`**: 特殊的迁移类型，表示该 pageblock 已被隔离，分配器应跳过。\n- **`pageblock_flags`**: 存储每个 pageblock 的迁移类型信息。\n- **`zone->nr_isolate_pageblock`**: 记录当前内存区域（zone）中被隔离的 pageblock 数量。\n\n## 3. 关键实现\n\n### 不可移动页面检测逻辑 (`has_unmovable_pages`)\n- **保留页面处理**: 所有 `PG_reserved` 页面（如 bootmem 分配、内存空洞）被视为不可移动。\n- **ZONE_MOVABLE 优化**: 若页面属于 `ZONE_MOVABLE`，则跳过详细检查（假设其内容可移动）。\n- **大页（Huge Page/THP）处理**: \n  - HugeTLB 页面需支持迁移才视为可移动。\n  - 透明大页（THP）若非 LRU 且非 `__PageMovable` 则视为不可移动。\n  - 跳过大页的尾页以避免重复检查。\n- **空闲页面处理**: Buddy 系统中的空闲页面（`PageBuddy`）可安全跳过。\n- **特殊标志处理**:\n  - 内存离线（`MEMORY_OFFLINE`）时，`PageHWPoison` 和 `PageOffline` 页面被临时视为可移动，允许驱动在离线回调中释放引用。\n- **可移动性判断**: 仅当页面属于 LRU 链表或具有 `__PageMovable` 属性时才视为可移动。\n\n### 隔离与取消隔离机制\n- **原子性保障**: 所有操作在 `zone->lock` 自旋锁保护下进行，确保并发安全。\n- **空闲页面迁移**: \n  - 隔离时调用 `move_freepages_block_isolate()` 将 pageblock 内空闲页面迁移到 `MIGRATE_ISOLATE` 链表。\n  - 取消隔离时，若存在高阶空闲页（≥ `pageblock_order`），先尝试隔离再归还，以触发 buddy 合并。\n- **错误报告**: 隔离失败时可通过 `REPORT_FAILURE` 标志触发 `dump_page()` 输出调试信息。\n\n### 限制与注意事项\n- **竞态条件**: 函数注释明确指出检测结果非精确（\"you can't expect this function should be exact\"），因未持有页面锁或 LRU 锁。\n- **范围约束**: 输入范围必须位于同一 pageblock 和同一内存区域（zone）内。\n- **CMA 特殊处理**: CMA 分配即使遇到实际不可移动页面，也强制视为可移动以支持隔离。\n\n## 4. 依赖关系\n\n- **内存管理核心**: 依赖 `<linux/mm.h>`、`internal.h` 提供的页面、区域（zone）、buddy 系统等基础功能。\n- **迁移框架**: 与 `<linux/migrate.h>` 协同工作，为页面迁移提供前置隔离能力。\n- **大页支持**: 通过 `<linux/hugetlb.h>` 处理 HugeTLB 页面的迁移属性。\n- **内存热插拔**: 服务于 `<linux/memory.h>` 中的内存离线（offline）流程。\n- **调试设施**: 使用 `<linux/page_owner.h>` 和 tracepoint（`<trace/events/page_isolation.h>`）辅助调试。\n\n## 5. 使用场景\n\n1. **连续内存分配（CMA）**  \n   在 `alloc_contig_range()` 中调用 `set_migratetype_isolate()` 隔离目标区域，确保后续迁移操作不受新分配干扰。\n\n2. **内存热插拔（Memory Hotplug）**  \n   - **内存离线**: 在 `offline_pages()` 流程中隔离待移除内存，确保无活跃分配后再迁移页面。\n   - **内存上线**: 通过 `unset_migratetype_isolate()` 恢复隔离区域，使其重新参与分配。\n\n3. **内存碎片整理（Compaction）**  \n   作为迁移前的准备步骤，隔离特定区域以进行定向碎片整理。\n\n4. **硬件错误处理**  \n   结合 `PageHWPoison` 机制，在隔离含错误页面的区域时提供特殊处理路径。",
      "similarity": 0.6875555515289307,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/page_isolation.c",
          "start_line": 305,
          "end_line": 447,
          "content": [
            "static int isolate_single_pageblock(unsigned long boundary_pfn, int flags,",
            "\t\t\tgfp_t gfp_flags, bool isolate_before, bool skip_isolation,",
            "\t\t\tint migratetype)",
            "{",
            "\tunsigned long start_pfn;",
            "\tunsigned long isolate_pageblock;",
            "\tunsigned long pfn;",
            "\tstruct zone *zone;",
            "\tint ret;",
            "",
            "\tVM_BUG_ON(!pageblock_aligned(boundary_pfn));",
            "",
            "\tif (isolate_before)",
            "\t\tisolate_pageblock = boundary_pfn - pageblock_nr_pages;",
            "\telse",
            "\t\tisolate_pageblock = boundary_pfn;",
            "",
            "\t/*",
            "\t * scan at the beginning of MAX_ORDER_NR_PAGES aligned range to avoid",
            "\t * only isolating a subset of pageblocks from a bigger than pageblock",
            "\t * free or in-use page. Also make sure all to-be-isolated pageblocks",
            "\t * are within the same zone.",
            "\t */",
            "\tzone  = page_zone(pfn_to_page(isolate_pageblock));",
            "\tstart_pfn  = max(ALIGN_DOWN(isolate_pageblock, MAX_ORDER_NR_PAGES),",
            "\t\t\t\t      zone->zone_start_pfn);",
            "",
            "\tif (skip_isolation) {",
            "\t\tint mt __maybe_unused = get_pageblock_migratetype(pfn_to_page(isolate_pageblock));",
            "",
            "\t\tVM_BUG_ON(!is_migrate_isolate(mt));",
            "\t} else {",
            "\t\tret = set_migratetype_isolate(pfn_to_page(isolate_pageblock), migratetype,",
            "\t\t\t\tflags, isolate_pageblock, isolate_pageblock + pageblock_nr_pages);",
            "",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\t/*",
            "\t * Bail out early when the to-be-isolated pageblock does not form",
            "\t * a free or in-use page across boundary_pfn:",
            "\t *",
            "\t * 1. isolate before boundary_pfn: the page after is not online",
            "\t * 2. isolate after boundary_pfn: the page before is not online",
            "\t *",
            "\t * This also ensures correctness. Without it, when isolate after",
            "\t * boundary_pfn and [start_pfn, boundary_pfn) are not online,",
            "\t * __first_valid_page() will return unexpected NULL in the for loop",
            "\t * below.",
            "\t */",
            "\tif (isolate_before) {",
            "\t\tif (!pfn_to_online_page(boundary_pfn))",
            "\t\t\treturn 0;",
            "\t} else {",
            "\t\tif (!pfn_to_online_page(boundary_pfn - 1))",
            "\t\t\treturn 0;",
            "\t}",
            "",
            "\tfor (pfn = start_pfn; pfn < boundary_pfn;) {",
            "\t\tstruct page *page = __first_valid_page(pfn, boundary_pfn - pfn);",
            "",
            "\t\tVM_BUG_ON(!page);",
            "\t\tpfn = page_to_pfn(page);",
            "",
            "\t\tif (PageBuddy(page)) {",
            "\t\t\tint order = buddy_order(page);",
            "",
            "\t\t\t/* move_freepages_block_isolate() handled this */",
            "\t\t\tVM_WARN_ON_ONCE(pfn + (1 << order) > boundary_pfn);",
            "",
            "\t\t\tpfn += 1UL << order;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * If a compound page is straddling our block, attempt",
            "\t\t * to migrate it out of the way.",
            "\t\t *",
            "\t\t * We don't have to worry about this creating a large",
            "\t\t * free page that straddles into our block: gigantic",
            "\t\t * pages are freed as order-0 chunks, and LRU pages",
            "\t\t * (currently) do not exceed pageblock_order.",
            "\t\t *",
            "\t\t * The block of interest has already been marked",
            "\t\t * MIGRATE_ISOLATE above, so when migration is done it",
            "\t\t * will free its pages onto the correct freelists.",
            "\t\t */",
            "\t\tif (PageCompound(page)) {",
            "\t\t\tstruct page *head = compound_head(page);",
            "\t\t\tunsigned long head_pfn = page_to_pfn(head);",
            "\t\t\tunsigned long nr_pages = compound_nr(head);",
            "",
            "\t\t\tif (head_pfn + nr_pages <= boundary_pfn) {",
            "\t\t\t\tpfn = head_pfn + nr_pages;",
            "\t\t\t\tcontinue;",
            "\t\t\t}",
            "",
            "#if defined CONFIG_COMPACTION || defined CONFIG_CMA",
            "\t\t\tif (PageHuge(page)) {",
            "\t\t\t\tint page_mt = get_pageblock_migratetype(page);",
            "\t\t\t\tstruct compact_control cc = {",
            "\t\t\t\t\t.nr_migratepages = 0,",
            "\t\t\t\t\t.order = -1,",
            "\t\t\t\t\t.zone = page_zone(pfn_to_page(head_pfn)),",
            "\t\t\t\t\t.mode = MIGRATE_SYNC,",
            "\t\t\t\t\t.ignore_skip_hint = true,",
            "\t\t\t\t\t.no_set_skip_hint = true,",
            "\t\t\t\t\t.gfp_mask = gfp_flags,",
            "\t\t\t\t\t.alloc_contig = true,",
            "\t\t\t\t};",
            "\t\t\t\tINIT_LIST_HEAD(&cc.migratepages);",
            "",
            "\t\t\t\tret = __alloc_contig_migrate_range(&cc, head_pfn,",
            "\t\t\t\t\t\t\thead_pfn + nr_pages, page_mt);",
            "\t\t\t\tif (ret)",
            "\t\t\t\t\tgoto failed;",
            "\t\t\t\tpfn = head_pfn + nr_pages;",
            "\t\t\t\tcontinue;",
            "\t\t\t}",
            "",
            "\t\t\t/*",
            "\t\t\t * These pages are movable too, but they're",
            "\t\t\t * not expected to exceed pageblock_order.",
            "\t\t\t *",
            "\t\t\t * Let us know when they do, so we can add",
            "\t\t\t * proper free and split handling for them.",
            "\t\t\t */",
            "\t\t\tVM_WARN_ON_ONCE_PAGE(PageLRU(page), page);",
            "\t\t\tVM_WARN_ON_ONCE_PAGE(__PageMovable(page), page);",
            "#endif",
            "\t\t\tgoto failed;",
            "\t\t}",
            "",
            "\t\tpfn++;",
            "\t}",
            "\treturn 0;",
            "failed:",
            "\t/* restore the original migratetype */",
            "\tif (!skip_isolation)",
            "\t\tunset_migratetype_isolate(pfn_to_page(isolate_pageblock), migratetype);",
            "\treturn -EBUSY;",
            "}"
          ],
          "function_name": "isolate_single_pageblock",
          "description": "`isolate_single_pageblock`隔离单个页面块，跳过自由页面并迁移复合/巨型页面，若失败则恢复原迁移类型，确保隔离区域不含不可移动页。",
          "similarity": 0.6502530574798584
        },
        {
          "chunk_id": 3,
          "file_path": "mm/page_isolation.c",
          "start_line": 494,
          "end_line": 623,
          "content": [
            "int start_isolate_page_range(unsigned long start_pfn, unsigned long end_pfn,",
            "\t\t\t     int migratetype, int flags, gfp_t gfp_flags)",
            "{",
            "\tunsigned long pfn;",
            "\tstruct page *page;",
            "\t/* isolation is done at page block granularity */",
            "\tunsigned long isolate_start = pageblock_start_pfn(start_pfn);",
            "\tunsigned long isolate_end = pageblock_align(end_pfn);",
            "\tint ret;",
            "\tbool skip_isolation = false;",
            "",
            "\t/* isolate [isolate_start, isolate_start + pageblock_nr_pages) pageblock */",
            "\tret = isolate_single_pageblock(isolate_start, flags, gfp_flags, false,",
            "\t\t\tskip_isolation, migratetype);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tif (isolate_start == isolate_end - pageblock_nr_pages)",
            "\t\tskip_isolation = true;",
            "",
            "\t/* isolate [isolate_end - pageblock_nr_pages, isolate_end) pageblock */",
            "\tret = isolate_single_pageblock(isolate_end, flags, gfp_flags, true,",
            "\t\t\tskip_isolation, migratetype);",
            "\tif (ret) {",
            "\t\tunset_migratetype_isolate(pfn_to_page(isolate_start), migratetype);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\t/* skip isolated pageblocks at the beginning and end */",
            "\tfor (pfn = isolate_start + pageblock_nr_pages;",
            "\t     pfn < isolate_end - pageblock_nr_pages;",
            "\t     pfn += pageblock_nr_pages) {",
            "\t\tpage = __first_valid_page(pfn, pageblock_nr_pages);",
            "\t\tif (page && set_migratetype_isolate(page, migratetype, flags,",
            "\t\t\t\t\tstart_pfn, end_pfn)) {",
            "\t\t\tundo_isolate_page_range(isolate_start, pfn, migratetype);",
            "\t\t\tunset_migratetype_isolate(",
            "\t\t\t\tpfn_to_page(isolate_end - pageblock_nr_pages),",
            "\t\t\t\tmigratetype);",
            "\t\t\treturn -EBUSY;",
            "\t\t}",
            "\t}",
            "\treturn 0;",
            "}",
            "void undo_isolate_page_range(unsigned long start_pfn, unsigned long end_pfn,",
            "\t\t\t    int migratetype)",
            "{",
            "\tunsigned long pfn;",
            "\tstruct page *page;",
            "\tunsigned long isolate_start = pageblock_start_pfn(start_pfn);",
            "\tunsigned long isolate_end = pageblock_align(end_pfn);",
            "",
            "\tfor (pfn = isolate_start;",
            "\t     pfn < isolate_end;",
            "\t     pfn += pageblock_nr_pages) {",
            "\t\tpage = __first_valid_page(pfn, pageblock_nr_pages);",
            "\t\tif (!page || !is_migrate_isolate_page(page))",
            "\t\t\tcontinue;",
            "\t\tunset_migratetype_isolate(page, migratetype);",
            "\t}",
            "}",
            "static unsigned long",
            "__test_page_isolated_in_pageblock(unsigned long pfn, unsigned long end_pfn,",
            "\t\t\t\t  int flags)",
            "{",
            "\tstruct page *page;",
            "",
            "\twhile (pfn < end_pfn) {",
            "\t\tpage = pfn_to_page(pfn);",
            "\t\tif (PageBuddy(page))",
            "\t\t\t/*",
            "\t\t\t * If the page is on a free list, it has to be on",
            "\t\t\t * the correct MIGRATE_ISOLATE freelist. There is no",
            "\t\t\t * simple way to verify that as VM_BUG_ON(), though.",
            "\t\t\t */",
            "\t\t\tpfn += 1 << buddy_order(page);",
            "\t\telse if ((flags & MEMORY_OFFLINE) && PageHWPoison(page))",
            "\t\t\t/* A HWPoisoned page cannot be also PageBuddy */",
            "\t\t\tpfn++;",
            "\t\telse if ((flags & MEMORY_OFFLINE) && PageOffline(page) &&",
            "\t\t\t !page_count(page))",
            "\t\t\t/*",
            "\t\t\t * The responsible driver agreed to skip PageOffline()",
            "\t\t\t * pages when offlining memory by dropping its",
            "\t\t\t * reference in MEM_GOING_OFFLINE.",
            "\t\t\t */",
            "\t\t\tpfn++;",
            "\t\telse",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\treturn pfn;",
            "}",
            "int test_pages_isolated(unsigned long start_pfn, unsigned long end_pfn,",
            "\t\t\tint isol_flags)",
            "{",
            "\tunsigned long pfn, flags;",
            "\tstruct page *page;",
            "\tstruct zone *zone;",
            "\tint ret;",
            "",
            "\t/*",
            "\t * Note: pageblock_nr_pages != MAX_PAGE_ORDER. Then, chunks of free",
            "\t * pages are not aligned to pageblock_nr_pages.",
            "\t * Then we just check migratetype first.",
            "\t */",
            "\tfor (pfn = start_pfn; pfn < end_pfn; pfn += pageblock_nr_pages) {",
            "\t\tpage = __first_valid_page(pfn, pageblock_nr_pages);",
            "\t\tif (page && !is_migrate_isolate_page(page))",
            "\t\t\tbreak;",
            "\t}",
            "\tpage = __first_valid_page(start_pfn, end_pfn - start_pfn);",
            "\tif ((pfn < end_pfn) || !page) {",
            "\t\tret = -EBUSY;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/* Check all pages are free or marked as ISOLATED */",
            "\tzone = page_zone(page);",
            "\tspin_lock_irqsave(&zone->lock, flags);",
            "\tpfn = __test_page_isolated_in_pageblock(start_pfn, end_pfn, isol_flags);",
            "\tspin_unlock_irqrestore(&zone->lock, flags);",
            "",
            "\tret = pfn < end_pfn ? -EBUSY : 0;",
            "",
            "out:",
            "\ttrace_test_pages_isolated(start_pfn, end_pfn, pfn);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "start_isolate_page_range, undo_isolate_page_range, __test_page_isolated_in_pageblock, test_pages_isolated",
          "description": "`start_isolate_page_range`分步隔离连续页面块范围，`undo_isolate_page_range`撤销隔离；`test_pages_isolated`验证隔离完整性，确保所有页面处于隔离或自由状态。",
          "similarity": 0.636143684387207
        },
        {
          "chunk_id": 1,
          "file_path": "mm/page_isolation.c",
          "start_line": 147,
          "end_line": 262,
          "content": [
            "static int set_migratetype_isolate(struct page *page, int migratetype, int isol_flags,",
            "\t\t\tunsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tstruct zone *zone = page_zone(page);",
            "\tstruct page *unmovable;",
            "\tunsigned long flags;",
            "\tunsigned long check_unmovable_start, check_unmovable_end;",
            "",
            "\tspin_lock_irqsave(&zone->lock, flags);",
            "",
            "\t/*",
            "\t * We assume the caller intended to SET migrate type to isolate.",
            "\t * If it is already set, then someone else must have raced and",
            "\t * set it before us.",
            "\t */",
            "\tif (is_migrate_isolate_page(page)) {",
            "\t\tspin_unlock_irqrestore(&zone->lock, flags);",
            "\t\treturn -EBUSY;",
            "\t}",
            "",
            "\t/*",
            "\t * FIXME: Now, memory hotplug doesn't call shrink_slab() by itself.",
            "\t * We just check MOVABLE pages.",
            "\t *",
            "\t * Pass the intersection of [start_pfn, end_pfn) and the page's pageblock",
            "\t * to avoid redundant checks.",
            "\t */",
            "\tcheck_unmovable_start = max(page_to_pfn(page), start_pfn);",
            "\tcheck_unmovable_end = min(pageblock_end_pfn(page_to_pfn(page)),",
            "\t\t\t\t  end_pfn);",
            "",
            "\tunmovable = has_unmovable_pages(check_unmovable_start, check_unmovable_end,",
            "\t\t\tmigratetype, isol_flags);",
            "\tif (!unmovable) {",
            "\t\tif (!move_freepages_block_isolate(zone, page, MIGRATE_ISOLATE)) {",
            "\t\t\tspin_unlock_irqrestore(&zone->lock, flags);",
            "\t\t\treturn -EBUSY;",
            "\t\t}",
            "\t\tzone->nr_isolate_pageblock++;",
            "\t\tspin_unlock_irqrestore(&zone->lock, flags);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tspin_unlock_irqrestore(&zone->lock, flags);",
            "\tif (isol_flags & REPORT_FAILURE) {",
            "\t\t/*",
            "\t\t * printk() with zone->lock held will likely trigger a",
            "\t\t * lockdep splat, so defer it here.",
            "\t\t */",
            "\t\tdump_page(unmovable, \"unmovable page\");",
            "\t}",
            "",
            "\treturn -EBUSY;",
            "}",
            "static void unset_migratetype_isolate(struct page *page, int migratetype)",
            "{",
            "\tstruct zone *zone;",
            "\tunsigned long flags;",
            "\tbool isolated_page = false;",
            "\tunsigned int order;",
            "\tstruct page *buddy;",
            "",
            "\tzone = page_zone(page);",
            "\tspin_lock_irqsave(&zone->lock, flags);",
            "\tif (!is_migrate_isolate_page(page))",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * Because freepage with more than pageblock_order on isolated",
            "\t * pageblock is restricted to merge due to freepage counting problem,",
            "\t * it is possible that there is free buddy page.",
            "\t * move_freepages_block() doesn't care of merge so we need other",
            "\t * approach in order to merge them. Isolation and free will make",
            "\t * these pages to be merged.",
            "\t */",
            "\tif (PageBuddy(page)) {",
            "\t\torder = buddy_order(page);",
            "\t\tif (order >= pageblock_order && order < MAX_PAGE_ORDER) {",
            "\t\t\tbuddy = find_buddy_page_pfn(page, page_to_pfn(page),",
            "\t\t\t\t\t\t    order, NULL);",
            "\t\t\tif (buddy && !is_migrate_isolate_page(buddy)) {",
            "\t\t\t\tisolated_page = !!__isolate_free_page(page, order);",
            "\t\t\t\t/*",
            "\t\t\t\t * Isolating a free page in an isolated pageblock",
            "\t\t\t\t * is expected to always work as watermarks don't",
            "\t\t\t\t * apply here.",
            "\t\t\t\t */",
            "\t\t\t\tVM_WARN_ON(!isolated_page);",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * If we isolate freepage with more than pageblock_order, there",
            "\t * should be no freepage in the range, so we could avoid costly",
            "\t * pageblock scanning for freepage moving.",
            "\t *",
            "\t * We didn't actually touch any of the isolated pages, so place them",
            "\t * to the tail of the freelist. This is an optimization for memory",
            "\t * onlining - just onlined memory won't immediately be considered for",
            "\t * allocation.",
            "\t */",
            "\tif (!isolated_page) {",
            "\t\t/*",
            "\t\t * Isolating this block already succeeded, so this",
            "\t\t * should not fail on zone boundaries.",
            "\t\t */",
            "\t\tWARN_ON_ONCE(!move_freepages_block_isolate(zone, page, migratetype));",
            "\t} else {",
            "\t\tset_pageblock_migratetype(page, migratetype);",
            "\t\t__putback_isolated_page(page, order, migratetype);",
            "\t}",
            "\tzone->nr_isolate_pageblock--;",
            "out:",
            "\tspin_unlock_irqrestore(&zone->lock, flags);",
            "}"
          ],
          "function_name": "set_migratetype_isolate, unset_migratetype_isolate",
          "description": "`set_migratetype_isolate`尝试设置页面块为隔离类型需先确认无不可移动页，成功则增加隔离计数；`unset_migratetype_isolate`移除隔离状态，处理自由页面合并与迁移异常情况。",
          "similarity": 0.5927551984786987
        },
        {
          "chunk_id": 0,
          "file_path": "mm/page_isolation.c",
          "start_line": 1,
          "end_line": 146,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * linux/mm/page_isolation.c",
            " */",
            "",
            "#include <linux/mm.h>",
            "#include <linux/page-isolation.h>",
            "#include <linux/pageblock-flags.h>",
            "#include <linux/memory.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/page_owner.h>",
            "#include <linux/migrate.h>",
            "#include \"internal.h\"",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/page_isolation.h>",
            "",
            "/*",
            " * This function checks whether the range [start_pfn, end_pfn) includes",
            " * unmovable pages or not. The range must fall into a single pageblock and",
            " * consequently belong to a single zone.",
            " *",
            " * PageLRU check without isolation or lru_lock could race so that",
            " * MIGRATE_MOVABLE block might include unmovable pages. And __PageMovable",
            " * check without lock_page also may miss some movable non-lru pages at",
            " * race condition. So you can't expect this function should be exact.",
            " *",
            " * Returns a page without holding a reference. If the caller wants to",
            " * dereference that page (e.g., dumping), it has to make sure that it",
            " * cannot get removed (e.g., via memory unplug) concurrently.",
            " *",
            " */",
            "static struct page *has_unmovable_pages(unsigned long start_pfn, unsigned long end_pfn,",
            "\t\t\t\tint migratetype, int flags)",
            "{",
            "\tstruct page *page = pfn_to_page(start_pfn);",
            "\tstruct zone *zone = page_zone(page);",
            "\tunsigned long pfn;",
            "",
            "\tVM_BUG_ON(pageblock_start_pfn(start_pfn) !=",
            "\t\t  pageblock_start_pfn(end_pfn - 1));",
            "",
            "\tif (is_migrate_cma_page(page)) {",
            "\t\t/*",
            "\t\t * CMA allocations (alloc_contig_range) really need to mark",
            "\t\t * isolate CMA pageblocks even when they are not movable in fact",
            "\t\t * so consider them movable here.",
            "\t\t */",
            "\t\tif (is_migrate_cma(migratetype))",
            "\t\t\treturn NULL;",
            "",
            "\t\treturn page;",
            "\t}",
            "",
            "\tfor (pfn = start_pfn; pfn < end_pfn; pfn++) {",
            "\t\tpage = pfn_to_page(pfn);",
            "",
            "\t\t/*",
            "\t\t * Both, bootmem allocations and memory holes are marked",
            "\t\t * PG_reserved and are unmovable. We can even have unmovable",
            "\t\t * allocations inside ZONE_MOVABLE, for example when",
            "\t\t * specifying \"movablecore\".",
            "\t\t */",
            "\t\tif (PageReserved(page))",
            "\t\t\treturn page;",
            "",
            "\t\t/*",
            "\t\t * If the zone is movable and we have ruled out all reserved",
            "\t\t * pages then it should be reasonably safe to assume the rest",
            "\t\t * is movable.",
            "\t\t */",
            "\t\tif (zone_idx(zone) == ZONE_MOVABLE)",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * Hugepages are not in LRU lists, but they're movable.",
            "\t\t * THPs are on the LRU, but need to be counted as #small pages.",
            "\t\t * We need not scan over tail pages because we don't",
            "\t\t * handle each tail page individually in migration.",
            "\t\t */",
            "\t\tif (PageHuge(page) || PageTransCompound(page)) {",
            "\t\t\tstruct folio *folio = page_folio(page);",
            "\t\t\tunsigned int skip_pages;",
            "",
            "\t\t\tif (PageHuge(page)) {",
            "\t\t\t\tif (!hugepage_migration_supported(folio_hstate(folio)))",
            "\t\t\t\t\treturn page;",
            "\t\t\t} else if (!folio_test_lru(folio) && !__folio_test_movable(folio)) {",
            "\t\t\t\treturn page;",
            "\t\t\t}",
            "",
            "\t\t\tskip_pages = folio_nr_pages(folio) - folio_page_idx(folio, page);",
            "\t\t\tpfn += skip_pages - 1;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * We can't use page_count without pin a page",
            "\t\t * because another CPU can free compound page.",
            "\t\t * This check already skips compound tails of THP",
            "\t\t * because their page->_refcount is zero at all time.",
            "\t\t */",
            "\t\tif (!page_ref_count(page)) {",
            "\t\t\tif (PageBuddy(page))",
            "\t\t\t\tpfn += (1 << buddy_order(page)) - 1;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * The HWPoisoned page may be not in buddy system, and",
            "\t\t * page_count() is not 0.",
            "\t\t */",
            "\t\tif ((flags & MEMORY_OFFLINE) && PageHWPoison(page))",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * We treat all PageOffline() pages as movable when offlining",
            "\t\t * to give drivers a chance to decrement their reference count",
            "\t\t * in MEM_GOING_OFFLINE in order to indicate that these pages",
            "\t\t * can be offlined as there are no direct references anymore.",
            "\t\t * For actually unmovable PageOffline() where the driver does",
            "\t\t * not support this, we will fail later when trying to actually",
            "\t\t * move these pages that still have a reference count > 0.",
            "\t\t * (false negatives in this function only)",
            "\t\t */",
            "\t\tif ((flags & MEMORY_OFFLINE) && PageOffline(page))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (__PageMovable(page) || PageLRU(page))",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * If there are RECLAIMABLE pages, we need to check",
            "\t\t * it.  But now, memory offline itself doesn't call",
            "\t\t * shrink_node_slabs() and it still to be fixed.",
            "\t\t */",
            "\t\treturn page;",
            "\t}",
            "\treturn NULL;",
            "}",
            "",
            "/*",
            " * This function set pageblock migratetype to isolate if no unmovable page is",
            " * present in [start_pfn, end_pfn). The pageblock must intersect with",
            " * [start_pfn, end_pfn).",
            " */"
          ],
          "function_name": null,
          "description": "函数`has_unmovable_pages`检查指定PFN范围是否存在不可移动页面，通过遍历并判断页面是否为保留、非MOVABLE或特殊类型（如HugeTLB），返回首个不可移动页面指针。结果可能因竞态存在误差。",
          "similarity": 0.5000823736190796
        }
      ]
    },
    {
      "source_file": "mm/memory-failure.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:40:57\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memory-failure.c`\n\n---\n\n# memory-failure.c 技术文档\n\n## 1. 文件概述\n\n`memory-failure.c` 是 Linux 内核中用于处理硬件报告的内存故障（如多比特 ECC 错误）的核心模块。该文件实现了对已损坏物理页的检测、隔离和恢复机制，支持两种主要操作模式：\n- **硬离线（Hard Offline）**：处理已被硬件标记为损坏的页面，通常会导致使用该页的进程被终止\n- **软离线（Soft Offline）**：主动隔离可疑但尚未损坏的页面，避免潜在故障而不杀死进程\n\n该模块需要在不违反虚拟内存子系统正常锁定规则的前提下，异步安全地处理内存错误，确保系统稳定性。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `sysctl_memory_failure_early_kill`：控制是否立即杀死使用损坏页面的进程（0=延迟处理，1=立即杀死）\n- `sysctl_memory_failure_recovery`：启用/禁用内存故障恢复功能（默认启用）\n- `num_poisoned_pages`：原子计数器，记录已标记为有毒（poisoned）的页面数量\n- `hw_memory_failure`：标识是否由硬件直接报告的内存故障\n- `mf_mutex`：保护内存故障处理操作的互斥锁\n\n### 主要函数\n- `num_poisoned_pages_inc()` / `num_poisoned_pages_sub()`：管理有毒页面计数\n- `__page_handle_poison()`：处理大页或空闲页的溶解和从伙伴系统移除\n- `page_handle_poison()`：通用页面毒化处理函数，设置 HWPoison 标志并更新计数\n- `hwpoison_filter_dev()`：基于设备号过滤硬件毒化页面（用于测试）\n- `hwpoison_filter_flags()`：基于页面标志过滤硬件毒化页面（用于测试）\n\n### Sysfs 接口\n通过 `MF_ATTR_RO` 宏定义的只读属性，提供每个 NUMA 节点的内存故障统计信息：\n- `total`：总处理的内存故障数\n- `ignored`：被忽略的故障数\n- `failed`：处理失败的故障数  \n- `delayed`：延迟处理的故障数\n- `recovered`：成功恢复的故障数\n\n## 3. 关键实现\n\n### 页面毒化处理流程\n1. **页面状态识别**：区分大页（hugepage）、空闲页（freepage）和其他类型页面\n2. **大页处理**：调用 `dissolve_free_huge_page()` 溶解大页，然后通过 `drain_all_pages()` 和 `take_page_off_buddy()` 确保页面从伙伴系统移除\n3. **标志设置**：使用 `SetPageHWPoison()` 标记页面为硬件毒化状态\n4. **引用计数管理**：增加页面引用计数并更新全局有毒页面计数器\n\n### 锁定策略\n- 避免使用 `zone_pcp_disable()` 以防止与 CPU 热插拔锁产生死锁\n- 采用标准 VM 锁定规则，即使这意味着错误处理可能耗时较长\n- 使用 `mf_mutex` 保护关键的内存故障处理路径\n\n### 复杂度考量\n- 由于 VM 数据结构的限制，某些操作（如通过 RMAP 反向映射查找进程）具有非线性时间复杂度\n- 基于内存故障的稀有性，接受这种性能开销以避免影响核心 VM 性能\n\n### 开发约束\n新增处理逻辑必须满足：\n- 具备可测试性\n- 能够集成到 mce-test 测试套件\n- 在真实工作负载中属于常见页面状态（page-types 工具 top 10）\n\n## 4. 依赖关系\n\n### 内核头文件依赖\n- **内存管理**：`<linux/mm.h>`, `<linux/page-flags.h>`, `<linux/pagemap.h>`, `<linux/swap.h>`\n- **进程管理**：`<linux/sched/signal.h>`, `<linux/sched/task.h>`\n- **特殊内存类型**：`<linux/hugetlb.h>`, `<linux/dax.h>`, `<linux/ksm.h>`, `<linux/shmem_fs.h>`\n- **系统架构**：`<linux/ras/ras_event.h>`, `<linux/memremap.h>`\n- **内核内部**：`\"swap.h\"`, `\"internal.h\"`\n\n### 功能依赖\n- **RAS（Reliability, Availability, Serviceability）**：通过 ras_event 提供事件通知\n- **内存热插拔**：`memblk_nr_poison_inc/sub` 用于内存块级统计\n- **cgroup 内存控制**：CONFIG_MEMCG 支持基于 memcg 的故障页面过滤\n- **硬件毒化注入**：CONFIG_HWPOISON_INJECT 提供测试框架\n\n## 5. 使用场景\n\n### 硬件内存故障处理\n- 当硬件检测到多比特 ECC 内存错误时，通过 Machine Check Exception (MCE) 机制调用此模块\n- 自动隔离损坏页面，防止数据损坏扩散\n\n### 主动内存维护\n- 系统管理员可通过 `/sys` 接口触发软离线操作，主动替换可疑内存页\n- 用于内存压力测试和预防性维护\n\n### 故障注入测试\n- 通过 `hwpoison_inject` 模块模拟硬件内存故障\n- 支持基于设备号、页面标志和 memcg 的精细过滤，用于针对性测试\n\n### 系统监控和诊断\n- 通过 sysfs 接口提供详细的内存故障统计信息\n- 便于系统管理员监控内存健康状况和故障恢复效果\n\n### 企业级可靠性保障\n- 在高可用服务器环境中，确保单个内存故障不会导致整个系统崩溃\n- 通过可配置的策略（early_kill, recovery）平衡服务连续性和数据完整性",
      "similarity": 0.6591424345970154,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "mm/memory-failure.c",
          "start_line": 919,
          "end_line": 1050,
          "content": [
            "static int delete_from_lru_cache(struct page *p)",
            "{",
            "\tif (isolate_lru_page(p)) {",
            "\t\t/*",
            "\t\t * Clear sensible page flags, so that the buddy system won't",
            "\t\t * complain when the page is unpoison-and-freed.",
            "\t\t */",
            "\t\tClearPageActive(p);",
            "\t\tClearPageUnevictable(p);",
            "",
            "\t\t/*",
            "\t\t * Poisoned page might never drop its ref count to 0 so we have",
            "\t\t * to uncharge it manually from its memcg.",
            "\t\t */",
            "\t\tmem_cgroup_uncharge(page_folio(p));",
            "",
            "\t\t/*",
            "\t\t * drop the page count elevated by isolate_lru_page()",
            "\t\t */",
            "\t\tput_page(p);",
            "\t\treturn 0;",
            "\t}",
            "\treturn -EIO;",
            "}",
            "static int truncate_error_page(struct page *p, unsigned long pfn,",
            "\t\t\t\tstruct address_space *mapping)",
            "{",
            "\tstruct folio *folio = page_folio(p);",
            "\tint ret = MF_FAILED;",
            "",
            "\tif (mapping->a_ops->error_remove_page) {",
            "\t\tint err = mapping->a_ops->error_remove_page(mapping, p);",
            "",
            "\t\tif (err != 0)",
            "\t\t\tpr_info(\"%#lx: Failed to punch page: %d\\n\", pfn, err);",
            "\t\telse if (!filemap_release_folio(folio, GFP_NOIO))",
            "\t\t\tpr_info(\"%#lx: failed to release buffers\\n\", pfn);",
            "\t\telse",
            "\t\t\tret = MF_RECOVERED;",
            "\t} else {",
            "\t\t/*",
            "\t\t * If the file system doesn't support it just invalidate",
            "\t\t * This fails on dirty or anything with private pages",
            "\t\t */",
            "\t\tif (mapping_evict_folio(mapping, folio))",
            "\t\t\tret = MF_RECOVERED;",
            "\t\telse",
            "\t\t\tpr_info(\"%#lx: Failed to invalidate\\n\",\tpfn);",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "static bool has_extra_refcount(struct page_state *ps, struct page *p,",
            "\t\t\t       bool extra_pins)",
            "{",
            "\tint count = page_count(p) - 1;",
            "",
            "\tif (extra_pins)",
            "\t\tcount -= folio_nr_pages(page_folio(p));",
            "",
            "\tif (count > 0) {",
            "\t\tpr_err(\"%#lx: %s still referenced by %d users\\n\",",
            "\t\t       page_to_pfn(p), action_page_types[ps->type], count);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static int me_kernel(struct page_state *ps, struct page *p)",
            "{",
            "\tunlock_page(p);",
            "\treturn MF_IGNORED;",
            "}",
            "static int me_unknown(struct page_state *ps, struct page *p)",
            "{",
            "\tpr_err(\"%#lx: Unknown page state\\n\", page_to_pfn(p));",
            "\tunlock_page(p);",
            "\treturn MF_FAILED;",
            "}",
            "static int me_pagecache_clean(struct page_state *ps, struct page *p)",
            "{",
            "\tint ret;",
            "\tstruct address_space *mapping;",
            "\tbool extra_pins;",
            "",
            "\tdelete_from_lru_cache(p);",
            "",
            "\t/*",
            "\t * For anonymous pages we're done the only reference left",
            "\t * should be the one m_f() holds.",
            "\t */",
            "\tif (PageAnon(p)) {",
            "\t\tret = MF_RECOVERED;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * Now truncate the page in the page cache. This is really",
            "\t * more like a \"temporary hole punch\"",
            "\t * Don't do this for block devices when someone else",
            "\t * has a reference, because it could be file system metadata",
            "\t * and that's not safe to truncate.",
            "\t */",
            "\tmapping = page_mapping(p);",
            "\tif (!mapping) {",
            "\t\t/*",
            "\t\t * Page has been teared down in the meanwhile",
            "\t\t */",
            "\t\tret = MF_FAILED;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * The shmem page is kept in page cache instead of truncating",
            "\t * so is expected to have an extra refcount after error-handling.",
            "\t */",
            "\textra_pins = shmem_mapping(mapping);",
            "",
            "\t/*",
            "\t * Truncation is a bit tricky. Enable it per file system for now.",
            "\t *",
            "\t * Open: to take i_rwsem or not for this? Right now we don't.",
            "\t */",
            "\tret = truncate_error_page(p, page_to_pfn(p), mapping);",
            "\tif (has_extra_refcount(ps, p, extra_pins))",
            "\t\tret = MF_FAILED;",
            "",
            "out:",
            "\tunlock_page(p);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "delete_from_lru_cache, truncate_error_page, has_extra_refcount, me_kernel, me_unknown, me_pagecache_clean",
          "description": "提供内存故障页面清理流程，包括从LRU列表移除、截断页面缓存及检查引用计数的辅助函数",
          "similarity": 0.7318708896636963
        },
        {
          "chunk_id": 7,
          "file_path": "mm/memory-failure.c",
          "start_line": 1088,
          "end_line": 1202,
          "content": [
            "static int me_pagecache_dirty(struct page_state *ps, struct page *p)",
            "{",
            "\tstruct address_space *mapping = page_mapping(p);",
            "",
            "\tSetPageError(p);",
            "\t/* TBD: print more information about the file. */",
            "\tif (mapping) {",
            "\t\t/*",
            "\t\t * IO error will be reported by write(), fsync(), etc.",
            "\t\t * who check the mapping.",
            "\t\t * This way the application knows that something went",
            "\t\t * wrong with its dirty file data.",
            "\t\t *",
            "\t\t * There's one open issue:",
            "\t\t *",
            "\t\t * The EIO will be only reported on the next IO",
            "\t\t * operation and then cleared through the IO map.",
            "\t\t * Normally Linux has two mechanisms to pass IO error",
            "\t\t * first through the AS_EIO flag in the address space",
            "\t\t * and then through the PageError flag in the page.",
            "\t\t * Since we drop pages on memory failure handling the",
            "\t\t * only mechanism open to use is through AS_AIO.",
            "\t\t *",
            "\t\t * This has the disadvantage that it gets cleared on",
            "\t\t * the first operation that returns an error, while",
            "\t\t * the PageError bit is more sticky and only cleared",
            "\t\t * when the page is reread or dropped.  If an",
            "\t\t * application assumes it will always get error on",
            "\t\t * fsync, but does other operations on the fd before",
            "\t\t * and the page is dropped between then the error",
            "\t\t * will not be properly reported.",
            "\t\t *",
            "\t\t * This can already happen even without hwpoisoned",
            "\t\t * pages: first on metadata IO errors (which only",
            "\t\t * report through AS_EIO) or when the page is dropped",
            "\t\t * at the wrong time.",
            "\t\t *",
            "\t\t * So right now we assume that the application DTRT on",
            "\t\t * the first EIO, but we're not worse than other parts",
            "\t\t * of the kernel.",
            "\t\t */",
            "\t\tmapping_set_error(mapping, -EIO);",
            "\t}",
            "",
            "\treturn me_pagecache_clean(ps, p);",
            "}",
            "static int me_swapcache_dirty(struct page_state *ps, struct page *p)",
            "{",
            "\tint ret;",
            "\tbool extra_pins = false;",
            "",
            "\tClearPageDirty(p);",
            "\t/* Trigger EIO in shmem: */",
            "\tClearPageUptodate(p);",
            "",
            "\tret = delete_from_lru_cache(p) ? MF_FAILED : MF_DELAYED;",
            "\tunlock_page(p);",
            "",
            "\tif (ret == MF_DELAYED)",
            "\t\textra_pins = true;",
            "",
            "\tif (has_extra_refcount(ps, p, extra_pins))",
            "\t\tret = MF_FAILED;",
            "",
            "\treturn ret;",
            "}",
            "static int me_swapcache_clean(struct page_state *ps, struct page *p)",
            "{",
            "\tstruct folio *folio = page_folio(p);",
            "\tint ret;",
            "",
            "\tdelete_from_swap_cache(folio);",
            "",
            "\tret = delete_from_lru_cache(p) ? MF_FAILED : MF_RECOVERED;",
            "\tfolio_unlock(folio);",
            "",
            "\tif (has_extra_refcount(ps, p, false))",
            "\t\tret = MF_FAILED;",
            "",
            "\treturn ret;",
            "}",
            "static int me_huge_page(struct page_state *ps, struct page *p)",
            "{",
            "\tstruct folio *folio = page_folio(p);",
            "\tint res;",
            "\tstruct address_space *mapping;",
            "\tbool extra_pins = false;",
            "",
            "\tmapping = folio_mapping(folio);",
            "\tif (mapping) {",
            "\t\tres = truncate_error_page(&folio->page, page_to_pfn(p), mapping);",
            "\t\t/* The page is kept in page cache. */",
            "\t\textra_pins = true;",
            "\t\tfolio_unlock(folio);",
            "\t} else {",
            "\t\tfolio_unlock(folio);",
            "\t\t/*",
            "\t\t * migration entry prevents later access on error hugepage,",
            "\t\t * so we can free and dissolve it into buddy to save healthy",
            "\t\t * subpages.",
            "\t\t */",
            "\t\tfolio_put(folio);",
            "\t\tif (__page_handle_poison(p) > 0) {",
            "\t\t\tpage_ref_inc(p);",
            "\t\t\tres = MF_RECOVERED;",
            "\t\t} else {",
            "\t\t\tres = MF_FAILED;",
            "\t\t}",
            "\t}",
            "",
            "\tif (has_extra_refcount(ps, p, extra_pins))",
            "\t\tres = MF_FAILED;",
            "",
            "\treturn res;",
            "}"
          ],
          "function_name": "me_pagecache_dirty, me_swapcache_dirty, me_swapcache_clean, me_huge_page",
          "description": "针对不同页面状态（脏页/交换缓存/大页）实施差异化处理，设置错误标志并触发生效I/O错误",
          "similarity": 0.7056461572647095
        },
        {
          "chunk_id": 8,
          "file_path": "mm/memory-failure.c",
          "start_line": 1288,
          "end_line": 1404,
          "content": [
            "static void update_per_node_mf_stats(unsigned long pfn,",
            "\t\t\t\t     enum mf_result result)",
            "{",
            "\tint nid = MAX_NUMNODES;",
            "\tstruct memory_failure_stats *mf_stats = NULL;",
            "",
            "\tnid = pfn_to_nid(pfn);",
            "\tif (unlikely(nid < 0 || nid >= MAX_NUMNODES)) {",
            "\t\tWARN_ONCE(1, \"Memory failure: pfn=%#lx, invalid nid=%d\", pfn, nid);",
            "\t\treturn;",
            "\t}",
            "",
            "\tmf_stats = &NODE_DATA(nid)->mf_stats;",
            "\tswitch (result) {",
            "\tcase MF_IGNORED:",
            "\t\t++mf_stats->ignored;",
            "\t\tbreak;",
            "\tcase MF_FAILED:",
            "\t\t++mf_stats->failed;",
            "\t\tbreak;",
            "\tcase MF_DELAYED:",
            "\t\t++mf_stats->delayed;",
            "\t\tbreak;",
            "\tcase MF_RECOVERED:",
            "\t\t++mf_stats->recovered;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tWARN_ONCE(1, \"Memory failure: mf_result=%d is not properly handled\", result);",
            "\t\tbreak;",
            "\t}",
            "\t++mf_stats->total;",
            "}",
            "static int action_result(unsigned long pfn, enum mf_action_page_type type,",
            "\t\t\t enum mf_result result)",
            "{",
            "\ttrace_memory_failure_event(pfn, type, result);",
            "",
            "\tnum_poisoned_pages_inc(pfn);",
            "",
            "\tupdate_per_node_mf_stats(pfn, result);",
            "",
            "\tpr_err(\"%#lx: recovery action for %s: %s\\n\",",
            "\t\tpfn, action_page_types[type], action_name[result]);",
            "",
            "\treturn (result == MF_RECOVERED || result == MF_DELAYED) ? 0 : -EBUSY;",
            "}",
            "static int page_action(struct page_state *ps, struct page *p,",
            "\t\t\tunsigned long pfn)",
            "{",
            "\tint result;",
            "",
            "\t/* page p should be unlocked after returning from ps->action().  */",
            "\tresult = ps->action(ps, p);",
            "",
            "\t/* Could do more checks here if page looks ok */",
            "\t/*",
            "\t * Could adjust zone counters here to correct for the missing page.",
            "\t */",
            "",
            "\treturn action_result(pfn, ps->type, result);",
            "}",
            "static inline bool PageHWPoisonTakenOff(struct page *page)",
            "{",
            "\treturn PageHWPoison(page) && page_private(page) == MAGIC_HWPOISON;",
            "}",
            "void SetPageHWPoisonTakenOff(struct page *page)",
            "{",
            "\tset_page_private(page, MAGIC_HWPOISON);",
            "}",
            "void ClearPageHWPoisonTakenOff(struct page *page)",
            "{",
            "\tif (PageHWPoison(page))",
            "\t\tset_page_private(page, 0);",
            "}",
            "static inline bool HWPoisonHandlable(struct page *page, unsigned long flags)",
            "{",
            "\t/* Soft offline could migrate non-LRU movable pages */",
            "\tif ((flags & MF_SOFT_OFFLINE) && __PageMovable(page))",
            "\t\treturn true;",
            "",
            "\treturn PageLRU(page) || is_free_buddy_page(page);",
            "}",
            "static int __get_hwpoison_page(struct page *page, unsigned long flags)",
            "{",
            "\tstruct folio *folio = page_folio(page);",
            "\tint ret = 0;",
            "\tbool hugetlb = false;",
            "",
            "\tret = get_hwpoison_hugetlb_folio(folio, &hugetlb, false);",
            "\tif (hugetlb) {",
            "\t\t/* Make sure hugetlb demotion did not happen from under us. */",
            "\t\tif (folio == page_folio(page))",
            "\t\t\treturn ret;",
            "\t\tif (ret > 0) {",
            "\t\t\tfolio_put(folio);",
            "\t\t\tfolio = page_folio(page);",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * This check prevents from calling folio_try_get() for any",
            "\t * unsupported type of folio in order to reduce the risk of unexpected",
            "\t * races caused by taking a folio refcount.",
            "\t */",
            "\tif (!HWPoisonHandlable(&folio->page, flags))",
            "\t\treturn -EBUSY;",
            "",
            "\tif (folio_try_get(folio)) {",
            "\t\tif (folio == page_folio(page))",
            "\t\t\treturn 1;",
            "",
            "\t\tpr_info(\"%#lx cannot catch tail\\n\", page_to_pfn(page));",
            "\t\tfolio_put(folio);",
            "\t}",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "update_per_node_mf_stats, action_result, page_action, PageHWPoisonTakenOff, SetPageHWPoisonTakenOff, ClearPageHWPoisonTakenOff, HWPoisonHandlable, __get_hwpoison_page",
          "description": "维护内存故障统计信息并处理页面操作结果，包含状态转换控制与硬件中毒标记管理",
          "similarity": 0.6854758262634277
        },
        {
          "chunk_id": 14,
          "file_path": "mm/memory-failure.c",
          "start_line": 2186,
          "end_line": 2390,
          "content": [
            "int memory_failure(unsigned long pfn, int flags)",
            "{",
            "\tstruct page *p;",
            "\tstruct folio *folio;",
            "\tstruct dev_pagemap *pgmap;",
            "\tint res = 0;",
            "\tunsigned long page_flags;",
            "\tbool retry = true;",
            "\tint hugetlb = 0;",
            "",
            "\tif (!sysctl_memory_failure_recovery)",
            "\t\tpanic(\"Memory failure on page %lx\", pfn);",
            "",
            "\tmutex_lock(&mf_mutex);",
            "",
            "\tif (!(flags & MF_SW_SIMULATED))",
            "\t\thw_memory_failure = true;",
            "",
            "\tp = pfn_to_online_page(pfn);",
            "\tif (!p) {",
            "\t\tres = arch_memory_failure(pfn, flags);",
            "\t\tif (res == 0)",
            "\t\t\tgoto unlock_mutex;",
            "",
            "\t\tif (pfn_valid(pfn)) {",
            "\t\t\tpgmap = get_dev_pagemap(pfn, NULL);",
            "\t\t\tput_ref_page(pfn, flags);",
            "\t\t\tif (pgmap) {",
            "\t\t\t\tres = memory_failure_dev_pagemap(pfn, flags,",
            "\t\t\t\t\t\t\t\t pgmap);",
            "\t\t\t\tgoto unlock_mutex;",
            "\t\t\t}",
            "\t\t}",
            "\t\tpr_err(\"%#lx: memory outside kernel control\\n\", pfn);",
            "\t\tres = -ENXIO;",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "try_again:",
            "\tres = try_memory_failure_hugetlb(pfn, flags, &hugetlb);",
            "\tif (hugetlb)",
            "\t\tgoto unlock_mutex;",
            "",
            "\tif (TestSetPageHWPoison(p)) {",
            "\t\tpr_err(\"%#lx: already hardware poisoned\\n\", pfn);",
            "\t\tres = -EHWPOISON;",
            "\t\tif (flags & MF_ACTION_REQUIRED)",
            "\t\t\tres = kill_accessing_process(current, pfn, flags);",
            "\t\tif (flags & MF_COUNT_INCREASED)",
            "\t\t\tput_page(p);",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\t/*",
            "\t * We need/can do nothing about count=0 pages.",
            "\t * 1) it's a free page, and therefore in safe hand:",
            "\t *    check_new_page() will be the gate keeper.",
            "\t * 2) it's part of a non-compound high order page.",
            "\t *    Implies some kernel user: cannot stop them from",
            "\t *    R/W the page; let's pray that the page has been",
            "\t *    used and will be freed some time later.",
            "\t * In fact it's dangerous to directly bump up page count from 0,",
            "\t * that may make page_ref_freeze()/page_ref_unfreeze() mismatch.",
            "\t */",
            "\tif (!(flags & MF_COUNT_INCREASED)) {",
            "\t\tres = get_hwpoison_page(p, flags);",
            "\t\tif (!res) {",
            "\t\t\tif (is_free_buddy_page(p)) {",
            "\t\t\t\tif (take_page_off_buddy(p)) {",
            "\t\t\t\t\tpage_ref_inc(p);",
            "\t\t\t\t\tres = MF_RECOVERED;",
            "\t\t\t\t} else {",
            "\t\t\t\t\t/* We lost the race, try again */",
            "\t\t\t\t\tif (retry) {",
            "\t\t\t\t\t\tClearPageHWPoison(p);",
            "\t\t\t\t\t\tretry = false;",
            "\t\t\t\t\t\tgoto try_again;",
            "\t\t\t\t\t}",
            "\t\t\t\t\tres = MF_FAILED;",
            "\t\t\t\t}",
            "\t\t\t\tres = action_result(pfn, MF_MSG_BUDDY, res);",
            "\t\t\t} else {",
            "\t\t\t\tres = action_result(pfn, MF_MSG_KERNEL_HIGH_ORDER, MF_IGNORED);",
            "\t\t\t}",
            "\t\t\tgoto unlock_mutex;",
            "\t\t} else if (res < 0) {",
            "\t\t\tres = action_result(pfn, MF_MSG_UNKNOWN, MF_IGNORED);",
            "\t\t\tgoto unlock_mutex;",
            "\t\t}",
            "\t}",
            "",
            "\tfolio = page_folio(p);",
            "\tif (folio_test_large(folio)) {",
            "\t\t/*",
            "\t\t * The flag must be set after the refcount is bumped",
            "\t\t * otherwise it may race with THP split.",
            "\t\t * And the flag can't be set in get_hwpoison_page() since",
            "\t\t * it is called by soft offline too and it is just called",
            "\t\t * for !MF_COUNT_INCREASED.  So here seems to be the best",
            "\t\t * place.",
            "\t\t *",
            "\t\t * Don't need care about the above error handling paths for",
            "\t\t * get_hwpoison_page() since they handle either free page",
            "\t\t * or unhandlable page.  The refcount is bumped iff the",
            "\t\t * page is a valid handlable page.",
            "\t\t */",
            "\t\tfolio_set_has_hwpoisoned(folio);",
            "\t\tif (try_to_split_thp_page(p) < 0) {",
            "\t\t\tres = action_result(pfn, MF_MSG_UNSPLIT_THP, MF_IGNORED);",
            "\t\t\tgoto unlock_mutex;",
            "\t\t}",
            "\t\tVM_BUG_ON_PAGE(!page_count(p), p);",
            "\t\tfolio = page_folio(p);",
            "\t}",
            "",
            "\t/*",
            "\t * We ignore non-LRU pages for good reasons.",
            "\t * - PG_locked is only well defined for LRU pages and a few others",
            "\t * - to avoid races with __SetPageLocked()",
            "\t * - to avoid races with __SetPageSlab*() (and more non-atomic ops)",
            "\t * The check (unnecessarily) ignores LRU pages being isolated and",
            "\t * walked by the page reclaim code, however that's not a big loss.",
            "\t */",
            "\tshake_folio(folio);",
            "",
            "\tfolio_lock(folio);",
            "",
            "\t/*",
            "\t * We're only intended to deal with the non-Compound page here.",
            "\t * However, the page could have changed compound pages due to",
            "\t * race window. If this happens, we could try again to hopefully",
            "\t * handle the page next round.",
            "\t */",
            "\tif (folio_test_large(folio)) {",
            "\t\tif (retry) {",
            "\t\t\tClearPageHWPoison(p);",
            "\t\t\tfolio_unlock(folio);",
            "\t\t\tfolio_put(folio);",
            "\t\t\tflags &= ~MF_COUNT_INCREASED;",
            "\t\t\tretry = false;",
            "\t\t\tgoto try_again;",
            "\t\t}",
            "\t\tres = action_result(pfn, MF_MSG_DIFFERENT_COMPOUND, MF_IGNORED);",
            "\t\tgoto unlock_page;",
            "\t}",
            "",
            "\t/*",
            "\t * We use page flags to determine what action should be taken, but",
            "\t * the flags can be modified by the error containment action.  One",
            "\t * example is an mlocked page, where PG_mlocked is cleared by",
            "\t * folio_remove_rmap_*() in try_to_unmap_one(). So to determine page",
            "\t * status correctly, we save a copy of the page flags at this time.",
            "\t */",
            "\tpage_flags = folio->flags;",
            "",
            "\tif (hwpoison_filter(p)) {",
            "\t\tClearPageHWPoison(p);",
            "\t\tfolio_unlock(folio);",
            "\t\tfolio_put(folio);",
            "\t\tres = -EOPNOTSUPP;",
            "\t\tgoto unlock_mutex;",
            "\t}",
            "",
            "\t/*",
            "\t * __munlock_folio() may clear a writeback folio's LRU flag without",
            "\t * the folio lock. We need to wait for writeback completion for this",
            "\t * folio or it may trigger a vfs BUG while evicting inode.",
            "\t */",
            "\tif (!folio_test_lru(folio) && !folio_test_writeback(folio))",
            "\t\tgoto identify_page_state;",
            "",
            "\t/*",
            "\t * It's very difficult to mess with pages currently under IO",
            "\t * and in many cases impossible, so we just avoid it here.",
            "\t */",
            "\tfolio_wait_writeback(folio);",
            "",
            "\t/*",
            "\t * Now take care of user space mappings.",
            "\t * Abort on fail: __filemap_remove_folio() assumes unmapped page.",
            "\t */",
            "\tif (!hwpoison_user_mappings(folio, p, pfn, flags)) {",
            "\t\tres = action_result(pfn, MF_MSG_UNMAP_FAILED, MF_IGNORED);",
            "\t\tgoto unlock_page;",
            "\t}",
            "",
            "\t/*",
            "\t * Torn down by someone else?",
            "\t */",
            "\tif (folio_test_lru(folio) && !folio_test_swapcache(folio) &&",
            "\t    folio->mapping == NULL) {",
            "\t\tres = action_result(pfn, MF_MSG_TRUNCATED_LRU, MF_IGNORED);",
            "\t\tgoto unlock_page;",
            "\t}",
            "",
            "identify_page_state:",
            "\tres = identify_page_state(pfn, p, page_flags);",
            "\tmutex_unlock(&mf_mutex);",
            "\treturn res;",
            "unlock_page:",
            "\tfolio_unlock(folio);",
            "unlock_mutex:",
            "\tmutex_unlock(&mf_mutex);",
            "\treturn res;",
            "}"
          ],
          "function_name": "memory_failure",
          "description": "memory_failure主函数处理内存故障，检查页面有效性，通过不同路径处理普通页、大页和设备页，调用相应处理函数并返回结果",
          "similarity": 0.6742947101593018
        },
        {
          "chunk_id": 16,
          "file_path": "mm/memory-failure.c",
          "start_line": 2613,
          "end_line": 2759,
          "content": [
            "int unpoison_memory(unsigned long pfn)",
            "{",
            "\treturn __unpoison_memory(pfn, true);",
            "}",
            "int soft_online_page(unsigned long pfn)",
            "{",
            "\treturn __unpoison_memory(pfn, IS_ENABLED(CONFIG_X86));",
            "}",
            "static int soft_offline_in_use_page(struct page *page)",
            "{",
            "\tlong ret = 0;",
            "\tunsigned long pfn = page_to_pfn(page);",
            "\tstruct folio *folio = page_folio(page);",
            "\tchar const *msg_page[] = {\"page\", \"hugepage\"};",
            "\tbool huge = folio_test_hugetlb(folio);",
            "\tbool isolated;",
            "\tLIST_HEAD(pagelist);",
            "\tstruct migration_target_control mtc = {",
            "\t\t.nid = NUMA_NO_NODE,",
            "\t\t.gfp_mask = GFP_USER | __GFP_MOVABLE | __GFP_RETRY_MAYFAIL,",
            "\t\t.reason = MR_MEMORY_FAILURE,",
            "\t};",
            "",
            "\tif (!huge && folio_test_large(folio)) {",
            "\t\tif (try_to_split_thp_page(page)) {",
            "\t\t\tpr_info(\"soft offline: %#lx: thp split failed\\n\", pfn);",
            "\t\t\treturn -EBUSY;",
            "\t\t}",
            "\t\tfolio = page_folio(page);",
            "\t}",
            "",
            "\tfolio_lock(folio);",
            "\tif (!huge)",
            "\t\tfolio_wait_writeback(folio);",
            "\tif (PageHWPoison(page)) {",
            "\t\tfolio_unlock(folio);",
            "\t\tfolio_put(folio);",
            "\t\tpr_info(\"soft offline: %#lx page already poisoned\\n\", pfn);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tif (!huge && folio_test_lru(folio) && !folio_test_swapcache(folio))",
            "\t\t/*",
            "\t\t * Try to invalidate first. This should work for",
            "\t\t * non dirty unmapped page cache pages.",
            "\t\t */",
            "\t\tret = mapping_evict_folio(folio_mapping(folio), folio);",
            "\tfolio_unlock(folio);",
            "",
            "\tif (ret) {",
            "\t\tpr_info(\"soft_offline: %#lx: invalidated\\n\", pfn);",
            "\t\tpage_handle_poison(page, false, true);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tisolated = isolate_folio_to_list(folio, &pagelist);",
            "",
            "\t/*",
            "\t * If we succeed to isolate the folio, we grabbed another refcount on",
            "\t * the folio, so we can safely drop the one we got from get_any_page().",
            "\t * If we failed to isolate the folio, it means that we cannot go further",
            "\t * and we will return an error, so drop the reference we got from",
            "\t * get_any_page() as well.",
            "\t */",
            "\tfolio_put(folio);",
            "",
            "\tif (isolated) {",
            "\t\tret = migrate_pages(&pagelist, alloc_migration_target, NULL,",
            "\t\t\t(unsigned long)&mtc, MIGRATE_SYNC, MR_MEMORY_FAILURE, NULL);",
            "\t\tif (!ret) {",
            "\t\t\tbool release = !huge;",
            "",
            "\t\t\tif (!page_handle_poison(page, huge, release))",
            "\t\t\t\tret = -EBUSY;",
            "\t\t} else {",
            "\t\t\tif (!list_empty(&pagelist))",
            "\t\t\t\tputback_movable_pages(&pagelist);",
            "",
            "\t\t\tpr_info(\"soft offline: %#lx: %s migration failed %ld, type %pGp\\n\",",
            "\t\t\t\tpfn, msg_page[huge], ret, &page->flags);",
            "\t\t\tif (ret > 0)",
            "\t\t\t\tret = -EBUSY;",
            "\t\t}",
            "\t} else {",
            "\t\tpr_info(\"soft offline: %#lx: %s isolation failed, page count %d, type %pGp\\n\",",
            "\t\t\tpfn, msg_page[huge], page_count(page), &page->flags);",
            "\t\tret = -EBUSY;",
            "\t}",
            "\treturn ret;",
            "}",
            "int soft_offline_page(unsigned long pfn, int flags)",
            "{",
            "\tint ret;",
            "\tbool try_again = true;",
            "\tstruct page *page;",
            "",
            "\tif (!pfn_valid(pfn)) {",
            "\t\tWARN_ON_ONCE(flags & MF_COUNT_INCREASED);",
            "\t\treturn -ENXIO;",
            "\t}",
            "",
            "\t/* Only online pages can be soft-offlined (esp., not ZONE_DEVICE). */",
            "\tpage = pfn_to_online_page(pfn);",
            "\tif (!page) {",
            "\t\tput_ref_page(pfn, flags);",
            "\t\treturn -EIO;",
            "\t}",
            "",
            "\tmutex_lock(&mf_mutex);",
            "",
            "\tif (PageHWPoison(page)) {",
            "\t\tpr_info(\"%s: %#lx page already poisoned\\n\", __func__, pfn);",
            "\t\tput_ref_page(pfn, flags);",
            "\t\tmutex_unlock(&mf_mutex);",
            "\t\treturn 0;",
            "\t}",
            "",
            "retry:",
            "\tget_online_mems();",
            "\tret = get_hwpoison_page(page, flags | MF_SOFT_OFFLINE);",
            "\tput_online_mems();",
            "",
            "\tif (hwpoison_filter(page)) {",
            "\t\tif (ret > 0)",
            "\t\t\tput_page(page);",
            "",
            "\t\tmutex_unlock(&mf_mutex);",
            "\t\treturn -EOPNOTSUPP;",
            "\t}",
            "",
            "\tif (ret > 0) {",
            "\t\tret = soft_offline_in_use_page(page);",
            "\t} else if (ret == 0) {",
            "\t\tif (!page_handle_poison(page, true, false)) {",
            "\t\t\tif (try_again) {",
            "\t\t\t\ttry_again = false;",
            "\t\t\t\tflags &= ~MF_COUNT_INCREASED;",
            "\t\t\t\tgoto retry;",
            "\t\t\t}",
            "\t\t\tret = -EBUSY;",
            "\t\t}",
            "\t}",
            "",
            "\tmutex_unlock(&mf_mutex);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "unpoison_memory, soft_online_page, soft_offline_in_use_page, soft_offline_page",
          "description": "unpoison_memory调用__unpoison_memory并强制启用硬件检查；soft_online_page调用__unpoison_memory用于软上线页面；soft_offline_in_use_page尝试隔离并迁移受内存故障影响的页面，处理Writeback和LRU列表；soft_offline_page获取页面并调用soft_offline_in_use_page，通过循环重试机制处理页面中毒状态。",
          "similarity": 0.6569955348968506
        }
      ]
    },
    {
      "source_file": "mm/kasan/quarantine.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:17:26\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kasan\\quarantine.c`\n\n---\n\n# kasan/quarantine.c 技术文档\n\n## 1. 文件概述\n\n`kasan/quarantine.c` 实现了 KASAN（Kernel Address Sanitizer）的隔离区（Quarantine）机制。该机制用于延迟释放已释放但可能仍被非法访问的内存对象，从而提高检测 Use-After-Free（UAF）错误的能力。通过将释放的对象暂时放入隔离队列而非立即归还给内存分配器，KASAN 能在后续访问这些“已释放”内存时捕获违规行为。\n\n隔离区由每个 CPU 的本地队列和一个全局循环批次队列组成，并支持动态调整大小以适应系统内存压力，防止因隔离区过大导致 OOM（Out-Of-Memory）。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct qlist_head`**  \n  表示一个单向链表队列，包含头指针、尾指针、总字节数和离线标志。\n  \n- **`cpu_quarantine`**（per-CPU）  \n  每个 CPU 的本地隔离队列，用于暂存刚释放的对象。\n\n- **`global_quarantine[QUARANTINE_BATCHES]`**  \n  全局隔离批次数组，采用循环 FIFO 结构，存储从各 CPU 队列转移过来的批量对象。\n\n- **`shrink_qlist`**（per-CPU）  \n  用于内存回收路径的辅助队列，带自旋锁保护。\n\n- **`remove_cache_srcu`**  \n  SRCU（Sleepable RCU）同步机制，用于安全地移除特定 slab 缓存的所有隔离对象。\n\n### 主要函数\n\n- **`kasan_quarantine_put()`**  \n  将指定对象放入当前 CPU 的隔离队列；若队列超过阈值，则批量转移到全局隔离区。\n\n- **`kasan_quarantine_reduce()`**  \n  当全局隔离区总大小超过限制时，释放最早一批对象以回收内存。\n\n- **`qlist_free_all()`**  \n  遍历并实际释放队列中所有对象回 slab 分配器。\n\n- **`qlink_free()`**  \n  执行单个隔离对象的实际释放操作，包括清除 KASAN 元数据和 shadow 内存标记。\n\n- **`qlist_move_cache()`**（未完成）  \n  （代码截断）预期用于将特定缓存类型的所有对象从一个队列迁移到另一个队列，通常用于缓存销毁时清理隔离对象。\n\n## 3. 关键实现\n\n### 隔离队列结构\n- 使用轻量级单向链表 `qlist_head` 管理对象，每个节点为 `struct qlist_node`（嵌入在 `kasan_free_meta` 中）。\n- 每个 CPU 维护一个本地队列（`cpu_quarantine`），避免锁竞争，提升性能。\n- 全局隔离区由 `QUARANTINE_BATCHES` 个批次组成环形缓冲区，通过 `quarantine_head` 和 `quarantine_tail` 实现 FIFO。\n\n### 内存管理策略\n- 单个 CPU 队列最大为 `QUARANTINE_PERCPU_SIZE`（1MB）。\n- 全局隔离区最大容量为系统物理内存的 `1/QUARANTINE_FRACTION`（即 1/32），再减去所有 CPU 队列的上限总和。\n- 批次大小 `quarantine_batch_size` 动态计算，至少为 `QUARANTINE_PERCPU_SIZE`，确保高效批量处理。\n\n### 并发与同步\n- CPU 本地操作使用 `local_irq_save/restore` 禁用中断，保证原子性。\n- 全局队列操作受 `quarantine_lock`（raw spinlock）保护。\n- 使用 `SRCU`（`remove_cache_srcu`）协调 `kasan_quarantine_remove_cache()` 与隔离对象释放之间的同步，确保在缓存销毁时不会遗漏隔离中的对象。\n\n### 安全释放机制\n- 对象释放前会将对应的 KASAN shadow 字节设为 `KASAN_SLAB_FREE`，使后续访问触发 KASAN 报告。\n- 若启用了 `init_on_free` 且 free metadata 存储在对象内部，则在释放前显式清零元数据，避免残留敏感信息。\n\n## 4. 依赖关系\n\n- **KASAN 核心模块**：依赖 `kasan.h` 中定义的元数据结构（如 `kasan_free_meta`）、shadow 内存操作和 `kasan_get_free_meta()` 等接口。\n- **Slab 分配器**：通过 `___cache_free()` 将对象归还给底层 slab（SLAB/SLUB）；使用 `virt_to_slab()` 和 `slab_want_init_on_free()` 等 slab 内部接口。\n- **内存管理子系统**：调用 `totalram_pages()` 获取系统内存总量，用于动态调整隔离区大小。\n- **CPU 热插拔**：通过 `num_online_cpus()` 适配 CPU 数量变化。\n- **同步原语**：使用 `percpu`、`raw_spinlock`、`SRCU` 和 `local_irq_*` 实现并发控制。\n- **内存回收**：虽未直接注册 shrinker（注释提及 SLAB 不支持），但 `kasan_quarantine_reduce()` 可被外部调用以响应内存压力。\n\n## 5. 使用场景\n\n- **Use-After-Free 检测增强**：当内核启用 KASAN（特别是 `CONFIG_KASAN_GENERIC` 或 `CONFIG_KASAN_SW_TAGS`）时，`kfree()` 或 `kmem_cache_free()` 调用会先将对象放入隔离区而非立即释放，延长 UAF 检测窗口。\n- **内存压力下的自动回收**：当系统内存紧张或隔离区超过阈值时，调用 `kasan_quarantine_reduce()` 释放最早隔离的一批对象，防止内存耗尽。\n- **Slab 缓存销毁**：当某个 `kmem_cache` 被销毁时，需调用未在本文件中完整实现的 `kasan_quarantine_remove_cache()`（依赖 `qlist_move_cache`），将该缓存的所有隔离对象立即释放，避免悬空引用。\n- **调试与测试**：在内核开发和测试阶段，隔离机制显著提升内存错误的可复现性和诊断能力。",
      "similarity": 0.6189047694206238,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/kasan/quarantine.c",
          "start_line": 238,
          "end_line": 375,
          "content": [
            "void kasan_quarantine_reduce(void)",
            "{",
            "\tsize_t total_size, new_quarantine_size, percpu_quarantines;",
            "\tunsigned long flags;",
            "\tint srcu_idx;",
            "\tstruct qlist_head to_free = QLIST_INIT;",
            "",
            "\tif (likely(READ_ONCE(quarantine_size) <=",
            "\t\t   READ_ONCE(quarantine_max_size)))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * srcu critical section ensures that kasan_quarantine_remove_cache()",
            "\t * will not miss objects belonging to the cache while they are in our",
            "\t * local to_free list. srcu is chosen because (1) it gives us private",
            "\t * grace period domain that does not interfere with anything else,",
            "\t * and (2) it allows synchronize_srcu() to return without waiting",
            "\t * if there are no pending read critical sections (which is the",
            "\t * expected case).",
            "\t */",
            "\tsrcu_idx = srcu_read_lock(&remove_cache_srcu);",
            "\traw_spin_lock_irqsave(&quarantine_lock, flags);",
            "",
            "\t/*",
            "\t * Update quarantine size in case of hotplug. Allocate a fraction of",
            "\t * the installed memory to quarantine minus per-cpu queue limits.",
            "\t */",
            "\ttotal_size = (totalram_pages() << PAGE_SHIFT) /",
            "\t\tQUARANTINE_FRACTION;",
            "\tpercpu_quarantines = QUARANTINE_PERCPU_SIZE * num_online_cpus();",
            "\tnew_quarantine_size = (total_size < percpu_quarantines) ?",
            "\t\t0 : total_size - percpu_quarantines;",
            "\tWRITE_ONCE(quarantine_max_size, new_quarantine_size);",
            "\t/* Aim at consuming at most 1/2 of slots in quarantine. */",
            "\tWRITE_ONCE(quarantine_batch_size, max((size_t)QUARANTINE_PERCPU_SIZE,",
            "\t\t2 * total_size / QUARANTINE_BATCHES));",
            "",
            "\tif (likely(quarantine_size > quarantine_max_size)) {",
            "\t\tqlist_move_all(&global_quarantine[quarantine_head], &to_free);",
            "\t\tWRITE_ONCE(quarantine_size, quarantine_size - to_free.bytes);",
            "\t\tquarantine_head++;",
            "\t\tif (quarantine_head == QUARANTINE_BATCHES)",
            "\t\t\tquarantine_head = 0;",
            "\t}",
            "",
            "\traw_spin_unlock_irqrestore(&quarantine_lock, flags);",
            "",
            "\tqlist_free_all(&to_free, NULL);",
            "\tsrcu_read_unlock(&remove_cache_srcu, srcu_idx);",
            "}",
            "static void qlist_move_cache(struct qlist_head *from,",
            "\t\t\t\t   struct qlist_head *to,",
            "\t\t\t\t   struct kmem_cache *cache)",
            "{",
            "\tstruct qlist_node *curr;",
            "",
            "\tif (unlikely(qlist_empty(from)))",
            "\t\treturn;",
            "",
            "\tcurr = from->head;",
            "\tqlist_init(from);",
            "\twhile (curr) {",
            "\t\tstruct qlist_node *next = curr->next;",
            "\t\tstruct kmem_cache *obj_cache = qlink_to_cache(curr);",
            "",
            "\t\tif (obj_cache == cache)",
            "\t\t\tqlist_put(to, curr, obj_cache->size);",
            "\t\telse",
            "\t\t\tqlist_put(from, curr, obj_cache->size);",
            "",
            "\t\tcurr = next;",
            "\t}",
            "}",
            "static void __per_cpu_remove_cache(struct qlist_head *q, void *arg)",
            "{",
            "\tstruct kmem_cache *cache = arg;",
            "\tunsigned long flags;",
            "\tstruct cpu_shrink_qlist *sq;",
            "",
            "\tsq = this_cpu_ptr(&shrink_qlist);",
            "\traw_spin_lock_irqsave(&sq->lock, flags);",
            "\tqlist_move_cache(q, &sq->qlist, cache);",
            "\traw_spin_unlock_irqrestore(&sq->lock, flags);",
            "}",
            "static void per_cpu_remove_cache(void *arg)",
            "{",
            "\tstruct qlist_head *q;",
            "",
            "\tq = this_cpu_ptr(&cpu_quarantine);",
            "\t/*",
            "\t * Ensure the ordering between the writing to q->offline and",
            "\t * per_cpu_remove_cache.  Prevent cpu_quarantine from being corrupted",
            "\t * by interrupt.",
            "\t */",
            "\tif (READ_ONCE(q->offline))",
            "\t\treturn;",
            "\t__per_cpu_remove_cache(q, arg);",
            "}",
            "void kasan_quarantine_remove_cache(struct kmem_cache *cache)",
            "{",
            "\tunsigned long flags, i;",
            "\tstruct qlist_head to_free = QLIST_INIT;",
            "\tint cpu;",
            "\tstruct cpu_shrink_qlist *sq;",
            "",
            "\t/*",
            "\t * Must be careful to not miss any objects that are being moved from",
            "\t * per-cpu list to the global quarantine in kasan_quarantine_put(),",
            "\t * nor objects being freed in kasan_quarantine_reduce(). on_each_cpu()",
            "\t * achieves the first goal, while synchronize_srcu() achieves the",
            "\t * second.",
            "\t */",
            "\ton_each_cpu(per_cpu_remove_cache, cache, 1);",
            "",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tsq = per_cpu_ptr(&shrink_qlist, cpu);",
            "\t\traw_spin_lock_irqsave(&sq->lock, flags);",
            "\t\tqlist_move_cache(&sq->qlist, &to_free, cache);",
            "\t\traw_spin_unlock_irqrestore(&sq->lock, flags);",
            "\t}",
            "\tqlist_free_all(&to_free, cache);",
            "",
            "\traw_spin_lock_irqsave(&quarantine_lock, flags);",
            "\tfor (i = 0; i < QUARANTINE_BATCHES; i++) {",
            "\t\tif (qlist_empty(&global_quarantine[i]))",
            "\t\t\tcontinue;",
            "\t\tqlist_move_cache(&global_quarantine[i], &to_free, cache);",
            "\t\t/* Scanning whole quarantine can take a while. */",
            "\t\traw_spin_unlock_irqrestore(&quarantine_lock, flags);",
            "\t\tcond_resched();",
            "\t\traw_spin_lock_irqsave(&quarantine_lock, flags);",
            "\t}",
            "\traw_spin_unlock_irqrestore(&quarantine_lock, flags);",
            "",
            "\tqlist_free_all(&to_free, cache);",
            "",
            "\tsynchronize_srcu(&remove_cache_srcu);",
            "}"
          ],
          "function_name": "kasan_quarantine_reduce, qlist_move_cache, __per_cpu_remove_cache, per_cpu_remove_cache, kasan_quarantine_remove_cache",
          "description": "提供隔离区缩减机制(kasan_quarantine_reduce)，通过srcu同步和跨CPU遍历清除指定缓存对象，利用qlist_move_cache实现基于缓存类型的对象转移与释放。",
          "similarity": 0.606938898563385
        },
        {
          "chunk_id": 3,
          "file_path": "mm/kasan/quarantine.c",
          "start_line": 382,
          "end_line": 410,
          "content": [
            "static int kasan_cpu_online(unsigned int cpu)",
            "{",
            "\tthis_cpu_ptr(&cpu_quarantine)->offline = false;",
            "\treturn 0;",
            "}",
            "static int kasan_cpu_offline(unsigned int cpu)",
            "{",
            "\tstruct qlist_head *q;",
            "",
            "\tq = this_cpu_ptr(&cpu_quarantine);",
            "\t/* Ensure the ordering between the writing to q->offline and",
            "\t * qlist_free_all. Otherwise, cpu_quarantine may be corrupted",
            "\t * by interrupt.",
            "\t */",
            "\tWRITE_ONCE(q->offline, true);",
            "\tbarrier();",
            "\tqlist_free_all(q, NULL);",
            "\treturn 0;",
            "}",
            "static int __init kasan_cpu_quarantine_init(void)",
            "{",
            "\tint ret = 0;",
            "",
            "\tret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, \"mm/kasan:online\",",
            "\t\t\t\tkasan_cpu_online, kasan_cpu_offline);",
            "\tif (ret < 0)",
            "\t\tpr_err(\"kasan cpu quarantine register failed [%d]\\n\", ret);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "kasan_cpu_online, kasan_cpu_offline, kasan_cpu_quarantine_init",
          "description": "实现CPU热插拔时隔离区状态管理，kasan_cpu_online/kasan_cpu_offline控制隔离区可用性，kasan_cpu_quarantine_init注册CPU状态回调接口。",
          "similarity": 0.5962210297584534
        },
        {
          "chunk_id": 1,
          "file_path": "mm/kasan/quarantine.c",
          "start_line": 42,
          "end_line": 172,
          "content": [
            "static bool qlist_empty(struct qlist_head *q)",
            "{",
            "\treturn !q->head;",
            "}",
            "static void qlist_init(struct qlist_head *q)",
            "{",
            "\tq->head = q->tail = NULL;",
            "\tq->bytes = 0;",
            "}",
            "static void qlist_put(struct qlist_head *q, struct qlist_node *qlink,",
            "\t\tsize_t size)",
            "{",
            "\tif (unlikely(qlist_empty(q)))",
            "\t\tq->head = qlink;",
            "\telse",
            "\t\tq->tail->next = qlink;",
            "\tq->tail = qlink;",
            "\tqlink->next = NULL;",
            "\tq->bytes += size;",
            "}",
            "static void qlist_move_all(struct qlist_head *from, struct qlist_head *to)",
            "{",
            "\tif (unlikely(qlist_empty(from)))",
            "\t\treturn;",
            "",
            "\tif (qlist_empty(to)) {",
            "\t\t*to = *from;",
            "\t\tqlist_init(from);",
            "\t\treturn;",
            "\t}",
            "",
            "\tto->tail->next = from->head;",
            "\tto->tail = from->tail;",
            "\tto->bytes += from->bytes;",
            "",
            "\tqlist_init(from);",
            "}",
            "static void qlink_free(struct qlist_node *qlink, struct kmem_cache *cache)",
            "{",
            "\tvoid *object = qlink_to_object(qlink, cache);",
            "\tstruct kasan_free_meta *meta = kasan_get_free_meta(cache, object);",
            "",
            "\t/*",
            "\t * If init_on_free is enabled and KASAN's free metadata is stored in",
            "\t * the object, zero the metadata. Otherwise, the object's memory will",
            "\t * not be properly zeroed, as KASAN saves the metadata after the slab",
            "\t * allocator zeroes the object.",
            "\t */",
            "\tif (slab_want_init_on_free(cache) &&",
            "\t    cache->kasan_info.free_meta_offset == 0)",
            "\t\tmemzero_explicit(meta, sizeof(*meta));",
            "",
            "\t/*",
            "\t * As the object now gets freed from the quarantine, assume that its",
            "\t * free track is no longer valid.",
            "\t */",
            "\t*(u8 *)kasan_mem_to_shadow(object) = KASAN_SLAB_FREE;",
            "",
            "\t___cache_free(cache, object, _THIS_IP_);",
            "}",
            "static void qlist_free_all(struct qlist_head *q, struct kmem_cache *cache)",
            "{",
            "\tstruct qlist_node *qlink;",
            "",
            "\tif (unlikely(qlist_empty(q)))",
            "\t\treturn;",
            "",
            "\tqlink = q->head;",
            "\twhile (qlink) {",
            "\t\tstruct kmem_cache *obj_cache =",
            "\t\t\tcache ? cache :\tqlink_to_cache(qlink);",
            "\t\tstruct qlist_node *next = qlink->next;",
            "",
            "\t\tqlink_free(qlink, obj_cache);",
            "\t\tqlink = next;",
            "\t}",
            "\tqlist_init(q);",
            "}",
            "bool kasan_quarantine_put(struct kmem_cache *cache, void *object)",
            "{",
            "\tunsigned long flags;",
            "\tstruct qlist_head *q;",
            "\tstruct qlist_head temp = QLIST_INIT;",
            "\tstruct kasan_free_meta *meta = kasan_get_free_meta(cache, object);",
            "",
            "\t/*",
            "\t * If there's no metadata for this object, don't put it into",
            "\t * quarantine.",
            "\t */",
            "\tif (!meta)",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Note: irq must be disabled until after we move the batch to the",
            "\t * global quarantine. Otherwise kasan_quarantine_remove_cache() can",
            "\t * miss some objects belonging to the cache if they are in our local",
            "\t * temp list. kasan_quarantine_remove_cache() executes on_each_cpu()",
            "\t * at the beginning which ensures that it either sees the objects in",
            "\t * per-cpu lists or in the global quarantine.",
            "\t */",
            "\tlocal_irq_save(flags);",
            "",
            "\tq = this_cpu_ptr(&cpu_quarantine);",
            "\tif (q->offline) {",
            "\t\tlocal_irq_restore(flags);",
            "\t\treturn false;",
            "\t}",
            "\tqlist_put(q, &meta->quarantine_link, cache->size);",
            "\tif (unlikely(q->bytes > QUARANTINE_PERCPU_SIZE)) {",
            "\t\tqlist_move_all(q, &temp);",
            "",
            "\t\traw_spin_lock(&quarantine_lock);",
            "\t\tWRITE_ONCE(quarantine_size, quarantine_size + temp.bytes);",
            "\t\tqlist_move_all(&temp, &global_quarantine[quarantine_tail]);",
            "\t\tif (global_quarantine[quarantine_tail].bytes >=",
            "\t\t\t\tREAD_ONCE(quarantine_batch_size)) {",
            "\t\t\tint new_tail;",
            "",
            "\t\t\tnew_tail = quarantine_tail + 1;",
            "\t\t\tif (new_tail == QUARANTINE_BATCHES)",
            "\t\t\t\tnew_tail = 0;",
            "\t\t\tif (new_tail != quarantine_head)",
            "\t\t\t\tquarantine_tail = new_tail;",
            "\t\t}",
            "\t\traw_spin_unlock(&quarantine_lock);",
            "\t}",
            "",
            "\tlocal_irq_restore(flags);",
            "",
            "\treturn true;",
            "}"
          ],
          "function_name": "qlist_empty, qlist_init, qlist_put, qlist_move_all, qlink_free, qlist_free_all, kasan_quarantine_put",
          "description": "实现了隔离区队列的基本操作（空判断、初始化、插入、转移和释放），kasan_quarantine_put将对象加入当前CPU隔离队列并触发全局隔离区迁移，通过中断屏蔽保证并发安全性。",
          "similarity": 0.5521301031112671
        },
        {
          "chunk_id": 0,
          "file_path": "mm/kasan/quarantine.c",
          "start_line": 1,
          "end_line": 41,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * KASAN quarantine.",
            " *",
            " * Author: Alexander Potapenko <glider@google.com>",
            " * Copyright (C) 2016 Google, Inc.",
            " *",
            " * Based on code by Dmitry Chernenkov.",
            " */",
            "",
            "#include <linux/gfp.h>",
            "#include <linux/hash.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mm.h>",
            "#include <linux/percpu.h>",
            "#include <linux/printk.h>",
            "#include <linux/shrinker.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/cpuhotplug.h>",
            "",
            "#include \"../slab.h\"",
            "#include \"kasan.h\"",
            "",
            "/* Data structure and operations for quarantine queues. */",
            "",
            "/*",
            " * Each queue is a single-linked list, which also stores the total size of",
            " * objects inside of it.",
            " */",
            "struct qlist_head {",
            "\tstruct qlist_node *head;",
            "\tstruct qlist_node *tail;",
            "\tsize_t bytes;",
            "\tbool offline;",
            "};",
            "",
            "#define QLIST_INIT { NULL, NULL, 0 }",
            ""
          ],
          "function_name": null,
          "description": "定义了KASAN隔离区队列的数据结构qlist_head，包含头尾指针、总字节数和离线标志位，用于管理隔离对象的链表队列。",
          "similarity": 0.5013296604156494
        }
      ]
    }
  ]
}