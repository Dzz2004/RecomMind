{
  "query": "用于跟踪中断的处理状态 软中断和硬中断",
  "timestamp": "2025-12-26 02:14:52",
  "retrieved_files": [
    {
      "source_file": "kernel/softirq.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:26:22\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `softirq.c`\n\n---\n\n# softirq.c 技术文档\n\n## 1. 文件概述\n\n`softirq.c` 是 Linux 内核中实现软中断（softirq）机制的核心文件。软中断是一种延迟执行中断处理下半部（bottom half）的机制，用于在中断上下文之外安全、高效地处理高频率、低延迟要求的任务。该文件负责软中断的注册、调度、执行以及与内核其他子系统（如调度器、RCU、SMP 等）的协同工作，并为每个 CPU 维护独立的软中断状态，确保无锁化和良好的 CPU 局部性。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `softirq_vec[NR_SOFTIRQS]`：全局数组，存储所有软中断类型的处理函数（`softirq_action`），每个软中断类型（如 `NET_RX`、`TIMER` 等）对应一个条目。\n- `ksoftirqd`：每 CPU 变量，指向该 CPU 上专用于处理软中断的内核线程（`ksoftirqd`）。\n- `softirq_to_name[NR_SOFTIRQS]`：软中断类型的名称字符串数组，用于调试和追踪。\n- `softirq_ctrl`（仅限 `CONFIG_PREEMPT_RT`）：每 CPU 结构体，包含本地锁（`local_lock_t`）和计数器（`cnt`），用于在实时内核中管理软中断禁用状态，支持抢占。\n- `irq_stat`：每 CPU 的中断统计结构体（若架构未提供）。\n\n### 主要函数\n\n- `wakeup_softirqd()`：唤醒当前 CPU 的 `ksoftirqd` 内核线程。\n- `__local_bh_disable_ip()` / `__local_bh_enable_ip()`：用于禁用/启用软中断（Bottom Half），并处理嵌套计数、RCU 锁、锁依赖追踪等。\n- `local_bh_blocked()`（仅限 RT）：检查当前 CPU 是否处于软中断被阻塞状态，用于 idle 任务避免误报。\n- `ksoftirqd_run_begin()` / `ksoftirqd_run_end()`：`ksoftirqd` 线程执行软中断前后的上下文管理。\n- `invoke_softirq()`：根据当前软中断状态决定是否唤醒 `ksoftirqd`。\n- `__do_softirq()`（声明在别处，但在此被调用）：实际执行挂起的软中断处理函数。\n\n## 3. 关键实现\n\n### 软中断执行模型\n- 软中断是 **CPU 本地** 的，无共享变量，天然支持 SMP。\n- 若软中断需要序列化（如 `TASKLET`），由其自身通过自旋锁实现。\n- 软中断执行具有 **弱 CPU 绑定**：仅在触发中断的 CPU 上标记为待执行，提升缓存局部性。\n\n### 实时内核（PREEMPT_RT）支持\n- 在 `CONFIG_PREEMPT_RT` 下，软中断禁用状态不再依赖抢占计数器，而是使用每任务（`task_struct::softirq_disable_cnt`）和每 CPU（`softirq_ctrl::cnt`）两个计数器。\n- 引入 `local_lock_t` 保护软中断临界区，允许在 BH 禁用期间被其他高优先级任务抢占。\n- `ksoftirqd` 线程通过 `ksoftirqd_run_begin/end` 获取本地锁，确保重入安全。\n\n### 软中断调度策略\n- 当软中断在原子上下文（不可抢占）中被启用且有待处理任务时，不直接执行，而是唤醒 `ksoftirqd` 线程处理，避免用户空间饥饿。\n- 在可抢占上下文中启用软中断时，若有待处理软中断，则立即调用 `__do_softirq()` 执行。\n\n### 调试与追踪\n- 集成 `lockdep` 锁依赖分析器，通过 `bh_lock_map` 跟踪软中断禁用区域。\n- 支持 `ftrace` 的 `irq` 事件追踪（通过 `trace/events/irq.h`）。\n- 提供 `in_softirq()`、`softirq_count()` 等宏用于上下文判断。\n\n## 4. 依赖关系\n\n- **中断子系统**：依赖 `irq.h`、`interrupt.h` 提供硬中断接口和状态管理。\n- **调度器**：与 `kthread.h` 协作创建和管理 `ksoftirqd` 内核线程；依赖 `sched.h` 相关机制进行唤醒和调度。\n- **RCU**：在 RT 模式下，软中断禁用区域需持有 `rcu_read_lock()`，确保 RCU 语义正确。\n- **SMP 支持**：使用 `smp.h`、`smpboot.h` 实现每 CPU 变量和 CPU 热插拔支持。\n- **内存管理**：依赖 `mm.h` 和 `percpu.h` 管理每 CPU 数据。\n- **调试设施**：集成 `lockdep`（`DEBUG_LOCK_ALLOC`）、`ftrace`、`irqflags tracing` 等调试框架。\n- **架构相关代码**：可能使用 `asm/softirq_stack.h` 提供的架构特定栈处理。\n\n## 5. 使用场景\n\n- **网络子系统**：`NET_RX` 和 `NET_TX` 软中断用于高效处理网络包接收和发送。\n- **块设备层**：`BLOCK` 软中断处理块 I/O 完成回调。\n- **定时器**：`TIMER` 和 `HRTIMER` 软中断用于执行高精度和普通定时器回调。\n- **RCU**：`RCU` 软中断用于执行宽限期（grace period）相关的回调。\n- **任务队列**：`TASKLET` 软中断提供轻量级、序列化的下半部机制。\n- **调度器事件**：`SCHED` 软中断用于处理调度相关的延迟任务（如负载均衡触发）。\n- **中断轮询**：`IRQ_POLL` 用于高吞吐场景下的中断合并与轮询。\n\n该机制广泛应用于需要在中断后快速、批量、低开销处理任务的内核子系统中，是 Linux 中断处理下半部的核心基础设施之一。",
      "similarity": 0.6723026037216187,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/softirq.c",
          "start_line": 417,
          "end_line": 572,
          "content": [
            "static inline void softirq_handle_begin(void)",
            "{",
            "\t__local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET);",
            "}",
            "static inline void softirq_handle_end(void)",
            "{",
            "\t__local_bh_enable(SOFTIRQ_OFFSET);",
            "\tWARN_ON_ONCE(in_interrupt());",
            "}",
            "static inline void ksoftirqd_run_begin(void)",
            "{",
            "\tlocal_irq_disable();",
            "}",
            "static inline void ksoftirqd_run_end(void)",
            "{",
            "\tlocal_irq_enable();",
            "}",
            "static inline bool should_wake_ksoftirqd(void)",
            "{",
            "\treturn true;",
            "}",
            "static inline void invoke_softirq(void)",
            "{",
            "\tif (!force_irqthreads() || !__this_cpu_read(ksoftirqd)) {",
            "#ifdef CONFIG_HAVE_IRQ_EXIT_ON_IRQ_STACK",
            "\t\t/*",
            "\t\t * We can safely execute softirq on the current stack if",
            "\t\t * it is the irq stack, because it should be near empty",
            "\t\t * at this stage.",
            "\t\t */",
            "\t\t__do_softirq();",
            "#else",
            "\t\t/*",
            "\t\t * Otherwise, irq_exit() is called on the task stack that can",
            "\t\t * be potentially deep already. So call softirq in its own stack",
            "\t\t * to prevent from any overrun.",
            "\t\t */",
            "\t\tdo_softirq_own_stack();",
            "#endif",
            "\t} else {",
            "\t\twakeup_softirqd();",
            "\t}",
            "}",
            "asmlinkage __visible void do_softirq(void)",
            "{",
            "\t__u32 pending;",
            "\tunsigned long flags;",
            "",
            "\tif (in_interrupt())",
            "\t\treturn;",
            "",
            "\tlocal_irq_save(flags);",
            "",
            "\tpending = local_softirq_pending();",
            "",
            "\tif (pending)",
            "\t\tdo_softirq_own_stack();",
            "",
            "\tlocal_irq_restore(flags);",
            "}",
            "static inline bool lockdep_softirq_start(void)",
            "{",
            "\tbool in_hardirq = false;",
            "",
            "\tif (lockdep_hardirq_context()) {",
            "\t\tin_hardirq = true;",
            "\t\tlockdep_hardirq_exit();",
            "\t}",
            "",
            "\tlockdep_softirq_enter();",
            "",
            "\treturn in_hardirq;",
            "}",
            "static inline void lockdep_softirq_end(bool in_hardirq)",
            "{",
            "\tlockdep_softirq_exit();",
            "",
            "\tif (in_hardirq)",
            "\t\tlockdep_hardirq_enter();",
            "}",
            "static inline bool lockdep_softirq_start(void) { return false; }",
            "static inline void lockdep_softirq_end(bool in_hardirq) { }",
            "static void handle_softirqs(bool ksirqd)",
            "{",
            "\tunsigned long end = jiffies + MAX_SOFTIRQ_TIME;",
            "\tunsigned long old_flags = current->flags;",
            "\tint max_restart = MAX_SOFTIRQ_RESTART;",
            "\tstruct softirq_action *h;",
            "\tbool in_hardirq;",
            "\t__u32 pending;",
            "\tint softirq_bit;",
            "",
            "\t/*",
            "\t * Mask out PF_MEMALLOC as the current task context is borrowed for the",
            "\t * softirq. A softirq handled, such as network RX, might set PF_MEMALLOC",
            "\t * again if the socket is related to swapping.",
            "\t */",
            "\tcurrent->flags &= ~PF_MEMALLOC;",
            "",
            "\tpending = local_softirq_pending();",
            "",
            "\tsoftirq_handle_begin();",
            "\tin_hardirq = lockdep_softirq_start();",
            "\taccount_softirq_enter(current);",
            "",
            "restart:",
            "\t/* Reset the pending bitmask before enabling irqs */",
            "\tset_softirq_pending(0);",
            "",
            "\tlocal_irq_enable();",
            "",
            "\th = softirq_vec;",
            "",
            "\twhile ((softirq_bit = ffs(pending))) {",
            "\t\tunsigned int vec_nr;",
            "\t\tint prev_count;",
            "",
            "\t\th += softirq_bit - 1;",
            "",
            "\t\tvec_nr = h - softirq_vec;",
            "\t\tprev_count = preempt_count();",
            "",
            "\t\tkstat_incr_softirqs_this_cpu(vec_nr);",
            "",
            "\t\ttrace_softirq_entry(vec_nr);",
            "\t\th->action(h);",
            "\t\ttrace_softirq_exit(vec_nr);",
            "\t\tif (unlikely(prev_count != preempt_count())) {",
            "\t\t\tpr_err(\"huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\\n\",",
            "\t\t\t       vec_nr, softirq_to_name[vec_nr], h->action,",
            "\t\t\t       prev_count, preempt_count());",
            "\t\t\tpreempt_count_set(prev_count);",
            "\t\t}",
            "\t\th++;",
            "\t\tpending >>= softirq_bit;",
            "\t}",
            "",
            "\tif (!IS_ENABLED(CONFIG_PREEMPT_RT) && ksirqd)",
            "\t\trcu_softirq_qs();",
            "",
            "\tlocal_irq_disable();",
            "",
            "\tpending = local_softirq_pending();",
            "\tif (pending) {",
            "\t\tif (time_before(jiffies, end) && !need_resched() &&",
            "\t\t    --max_restart)",
            "\t\t\tgoto restart;",
            "",
            "\t\twakeup_softirqd();",
            "\t}",
            "",
            "\taccount_softirq_exit(current);",
            "\tlockdep_softirq_end(in_hardirq);",
            "\tsoftirq_handle_end();",
            "\tcurrent_restore_flags(old_flags, PF_MEMALLOC);",
            "}"
          ],
          "function_name": "softirq_handle_begin, softirq_handle_end, ksoftirqd_run_begin, ksoftirqd_run_end, should_wake_ksoftirqd, invoke_softirq, do_softirq, lockdep_softirq_start, lockdep_softirq_end, lockdep_softirq_start, lockdep_softirq_end, handle_softirqs",
          "description": "实现软中断处理核心流程，包括pending位图扫描、动作执行、RCU状态更新及异常情况检测，包含硬中断上下文转换跟踪机制。",
          "similarity": 0.7771499156951904
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/softirq.c",
          "start_line": 618,
          "end_line": 732,
          "content": [
            "void irq_enter_rcu(void)",
            "{",
            "\t__irq_enter_raw();",
            "",
            "\tif (tick_nohz_full_cpu(smp_processor_id()) ||",
            "\t    (is_idle_task(current) && (irq_count() == HARDIRQ_OFFSET)))",
            "\t\ttick_irq_enter();",
            "",
            "\taccount_hardirq_enter(current);",
            "}",
            "void irq_enter(void)",
            "{",
            "\tct_irq_enter();",
            "\tirq_enter_rcu();",
            "}",
            "static inline void tick_irq_exit(void)",
            "{",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "\tint cpu = smp_processor_id();",
            "",
            "\t/* Make sure that timer wheel updates are propagated */",
            "\tif ((sched_core_idle_cpu(cpu) && !need_resched()) || tick_nohz_full_cpu(cpu)) {",
            "\t\tif (!in_hardirq())",
            "\t\t\ttick_nohz_irq_exit();",
            "\t}",
            "#endif",
            "}",
            "static void wake_timersd(void)",
            "{",
            "\tstruct task_struct *tsk = __this_cpu_read(ktimerd);",
            "",
            "\tif (tsk)",
            "\t\twake_up_process(tsk);",
            "}",
            "static inline void wake_timersd(void) { }",
            "static inline void __irq_exit_rcu(void)",
            "{",
            "#ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED",
            "\tlocal_irq_disable();",
            "#else",
            "\tlockdep_assert_irqs_disabled();",
            "#endif",
            "\taccount_hardirq_exit(current);",
            "\tpreempt_count_sub(HARDIRQ_OFFSET);",
            "\tif (!in_interrupt() && local_softirq_pending())",
            "\t\tinvoke_softirq();",
            "",
            "\tif (IS_ENABLED(CONFIG_IRQ_FORCED_THREADING) && force_irqthreads() &&",
            "\t    local_timers_pending_force_th() && !(in_nmi() | in_hardirq()))",
            "\t\twake_timersd();",
            "",
            "\ttick_irq_exit();",
            "}",
            "void irq_exit_rcu(void)",
            "{",
            "\t__irq_exit_rcu();",
            "\t /* must be last! */",
            "\tlockdep_hardirq_exit();",
            "}",
            "void irq_exit(void)",
            "{",
            "\t__irq_exit_rcu();",
            "\tct_irq_exit();",
            "\t /* must be last! */",
            "\tlockdep_hardirq_exit();",
            "}",
            "inline void raise_softirq_irqoff(unsigned int nr)",
            "{",
            "\t__raise_softirq_irqoff(nr);",
            "",
            "\t/*",
            "\t * If we're in an interrupt or softirq, we're done",
            "\t * (this also catches softirq-disabled code). We will",
            "\t * actually run the softirq once we return from",
            "\t * the irq or softirq.",
            "\t *",
            "\t * Otherwise we wake up ksoftirqd to make sure we",
            "\t * schedule the softirq soon.",
            "\t */",
            "\tif (!in_interrupt() && should_wake_ksoftirqd())",
            "\t\twakeup_softirqd();",
            "}",
            "void raise_softirq(unsigned int nr)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\traise_softirq_irqoff(nr);",
            "\tlocal_irq_restore(flags);",
            "}",
            "void __raise_softirq_irqoff(unsigned int nr)",
            "{",
            "\tlockdep_assert_irqs_disabled();",
            "\ttrace_softirq_raise(nr);",
            "\tor_softirq_pending(1UL << nr);",
            "}",
            "void open_softirq(int nr, void (*action)(struct softirq_action *))",
            "{",
            "\tsoftirq_vec[nr].action = action;",
            "}",
            "static void __tasklet_schedule_common(struct tasklet_struct *t,",
            "\t\t\t\t      struct tasklet_head __percpu *headp,",
            "\t\t\t\t      unsigned int softirq_nr)",
            "{",
            "\tstruct tasklet_head *head;",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\thead = this_cpu_ptr(headp);",
            "\tt->next = NULL;",
            "\t*head->tail = t;",
            "\thead->tail = &(t->next);",
            "\traise_softirq_irqoff(softirq_nr);",
            "\tlocal_irq_restore(flags);",
            "}"
          ],
          "function_name": "irq_enter_rcu, irq_enter, tick_irq_exit, wake_timersd, wake_timersd, __irq_exit_rcu, irq_exit_rcu, irq_exit, raise_softirq_irqoff, raise_softirq, __raise_softirq_irqoff, open_softirq, __tasklet_schedule_common",
          "description": "处理中断上下文切换相关操作，包含软中断触发接口、中断进入/退出时的统计更新和唤醒逻辑，以及任务队列调度辅助函数。",
          "similarity": 0.7615740299224854
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/softirq.c",
          "start_line": 1,
          "end_line": 73,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " *\tlinux/kernel/softirq.c",
            " *",
            " *\tCopyright (C) 1992 Linus Torvalds",
            " *",
            " *\tRewritten. Old one was good in 2.2, but in 2.3 it was immoral. --ANK (990903)",
            " */",
            "",
            "#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt",
            "",
            "#include <linux/export.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/init.h>",
            "#include <linux/local_lock.h>",
            "#include <linux/mm.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpu.h>",
            "#include <linux/freezer.h>",
            "#include <linux/kthread.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/smp.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/tick.h>",
            "#include <linux/irq.h>",
            "#include <linux/wait_bit.h>",
            "",
            "#include <asm/softirq_stack.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/irq.h>",
            "",
            "/*",
            "   - No shared variables, all the data are CPU local.",
            "   - If a softirq needs serialization, let it serialize itself",
            "     by its own spinlocks.",
            "   - Even if softirq is serialized, only local cpu is marked for",
            "     execution. Hence, we get something sort of weak cpu binding.",
            "     Though it is still not clear, will it result in better locality",
            "     or will not.",
            "",
            "   Examples:",
            "   - NET RX softirq. It is multithreaded and does not require",
            "     any global serialization.",
            "   - NET TX softirq. It kicks software netdevice queues, hence",
            "     it is logically serialized per device, but this serialization",
            "     is invisible to common code.",
            "   - Tasklets: serialized wrt itself.",
            " */",
            "",
            "#ifndef __ARCH_IRQ_STAT",
            "DEFINE_PER_CPU_ALIGNED(irq_cpustat_t, irq_stat);",
            "EXPORT_PER_CPU_SYMBOL(irq_stat);",
            "#endif",
            "",
            "static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;",
            "",
            "DEFINE_PER_CPU(struct task_struct *, ksoftirqd);",
            "",
            "const char * const softirq_to_name[NR_SOFTIRQS] = {",
            "\t\"HI\", \"TIMER\", \"NET_TX\", \"NET_RX\", \"BLOCK\", \"IRQ_POLL\",",
            "\t\"TASKLET\", \"SCHED\", \"HRTIMER\", \"RCU\"",
            "};",
            "",
            "/*",
            " * we cannot loop indefinitely here to avoid userspace starvation,",
            " * but we also don't want to introduce a worst case 1/HZ latency",
            " * to the pending events, so lets the scheduler to balance",
            " * the softirq load for us.",
            " */"
          ],
          "function_name": null,
          "description": "定义软中断相关数据结构和常量，包括每个CPU的中断统计信息、软中断动作数组及名称映射，描述软中断机制设计原则和示例场景。",
          "similarity": 0.7270932793617249
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/softirq.c",
          "start_line": 1059,
          "end_line": 1085,
          "content": [
            "static __init int spawn_ksoftirqd(void)",
            "{",
            "\tcpuhp_setup_state_nocalls(CPUHP_SOFTIRQ_DEAD, \"softirq:dead\", NULL,",
            "\t\t\t\t  takeover_tasklets);",
            "\tBUG_ON(smpboot_register_percpu_thread(&softirq_threads));",
            "#ifdef CONFIG_IRQ_FORCED_THREADING",
            "\tif (force_irqthreads())",
            "\t\tBUG_ON(smpboot_register_percpu_thread(&timer_thread));",
            "#endif",
            "\treturn 0;",
            "}",
            "int __init __weak early_irq_init(void)",
            "{",
            "\treturn 0;",
            "}",
            "int __init __weak arch_probe_nr_irqs(void)",
            "{",
            "\treturn NR_IRQS_LEGACY;",
            "}",
            "int __init __weak arch_early_irq_init(void)",
            "{",
            "\treturn 0;",
            "}",
            "unsigned int __weak arch_dynirq_lower_bound(unsigned int from)",
            "{",
            "\treturn from;",
            "}"
          ],
          "function_name": "spawn_ksoftirqd, early_irq_init, arch_probe_nr_irqs, arch_early_irq_init, arch_dynirq_lower_bound",
          "description": "实现软中断处理线程的注册与早期中断初始化，spawn_ksoftirqd注册软中断处理线程并绑定takeover_tasklets，arch_*系列弱符号接口处理不同架构的中断探测与动态中断范围计算",
          "similarity": 0.7227283716201782
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/softirq.c",
          "start_line": 74,
          "end_line": 191,
          "content": [
            "static void wakeup_softirqd(void)",
            "{",
            "\t/* Interrupts are disabled: no need to stop preemption */",
            "\tstruct task_struct *tsk = __this_cpu_read(ksoftirqd);",
            "",
            "\tif (tsk)",
            "\t\twake_up_process(tsk);",
            "}",
            "bool local_bh_blocked(void)",
            "{",
            "\treturn __this_cpu_read(softirq_ctrl.cnt) != 0;",
            "}",
            "void __local_bh_disable_ip(unsigned long ip, unsigned int cnt)",
            "{",
            "\tunsigned long flags;",
            "\tint newcnt;",
            "",
            "\tWARN_ON_ONCE(in_hardirq());",
            "",
            "\tlock_map_acquire_read(&bh_lock_map);",
            "",
            "\t/* First entry of a task into a BH disabled section? */",
            "\tif (!current->softirq_disable_cnt) {",
            "\t\tif (preemptible()) {",
            "\t\t\tlocal_lock(&softirq_ctrl.lock);",
            "\t\t\t/* Required to meet the RCU bottomhalf requirements. */",
            "\t\t\trcu_read_lock();",
            "\t\t} else {",
            "\t\t\tDEBUG_LOCKS_WARN_ON(this_cpu_read(softirq_ctrl.cnt));",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * Track the per CPU softirq disabled state. On RT this is per CPU",
            "\t * state to allow preemption of bottom half disabled sections.",
            "\t */",
            "\tnewcnt = __this_cpu_add_return(softirq_ctrl.cnt, cnt);",
            "\t/*",
            "\t * Reflect the result in the task state to prevent recursion on the",
            "\t * local lock and to make softirq_count() & al work.",
            "\t */",
            "\tcurrent->softirq_disable_cnt = newcnt;",
            "",
            "\tif (IS_ENABLED(CONFIG_TRACE_IRQFLAGS) && newcnt == cnt) {",
            "\t\traw_local_irq_save(flags);",
            "\t\tlockdep_softirqs_off(ip);",
            "\t\traw_local_irq_restore(flags);",
            "\t}",
            "}",
            "static void __local_bh_enable(unsigned int cnt, bool unlock)",
            "{",
            "\tunsigned long flags;",
            "\tint newcnt;",
            "",
            "\tDEBUG_LOCKS_WARN_ON(current->softirq_disable_cnt !=",
            "\t\t\t    this_cpu_read(softirq_ctrl.cnt));",
            "",
            "\tif (IS_ENABLED(CONFIG_TRACE_IRQFLAGS) && softirq_count() == cnt) {",
            "\t\traw_local_irq_save(flags);",
            "\t\tlockdep_softirqs_on(_RET_IP_);",
            "\t\traw_local_irq_restore(flags);",
            "\t}",
            "",
            "\tnewcnt = __this_cpu_sub_return(softirq_ctrl.cnt, cnt);",
            "\tcurrent->softirq_disable_cnt = newcnt;",
            "",
            "\tif (!newcnt && unlock) {",
            "\t\trcu_read_unlock();",
            "\t\tlocal_unlock(&softirq_ctrl.lock);",
            "\t}",
            "}",
            "void __local_bh_enable_ip(unsigned long ip, unsigned int cnt)",
            "{",
            "\tbool preempt_on = preemptible();",
            "\tunsigned long flags;",
            "\tu32 pending;",
            "\tint curcnt;",
            "",
            "\tWARN_ON_ONCE(in_hardirq());",
            "\tlockdep_assert_irqs_enabled();",
            "",
            "\tlock_map_release(&bh_lock_map);",
            "",
            "\tlocal_irq_save(flags);",
            "\tcurcnt = __this_cpu_read(softirq_ctrl.cnt);",
            "",
            "\t/*",
            "\t * If this is not reenabling soft interrupts, no point in trying to",
            "\t * run pending ones.",
            "\t */",
            "\tif (curcnt != cnt)",
            "\t\tgoto out;",
            "",
            "\tpending = local_softirq_pending();",
            "\tif (!pending)",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * If this was called from non preemptible context, wake up the",
            "\t * softirq daemon.",
            "\t */",
            "\tif (!preempt_on) {",
            "\t\twakeup_softirqd();",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * Adjust softirq count to SOFTIRQ_OFFSET which makes",
            "\t * in_serving_softirq() become true.",
            "\t */",
            "\tcnt = SOFTIRQ_OFFSET;",
            "\t__local_bh_enable(cnt, false);",
            "\t__do_softirq();",
            "",
            "out:",
            "\t__local_bh_enable(cnt, preempt_on);",
            "\tlocal_irq_restore(flags);",
            "}"
          ],
          "function_name": "wakeup_softirqd, local_bh_blocked, __local_bh_disable_ip, __local_bh_enable, __local_bh_enable_ip",
          "description": "实现软中断屏蔽/恢复逻辑，通过修改per-CPU计数器控制软中断状态，包含唤醒ksoftirqd线程的逻辑，处理抢占和锁依赖关系。",
          "similarity": 0.6875481605529785
        }
      ]
    },
    {
      "source_file": "kernel/irq/handle.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:55:29\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\handle.c`\n\n---\n\n# `irq/handle.c` 技术文档\n\n## 1. 文件概述\n\n`irq/handle.c` 是 Linux 内核通用中断子系统（Generic IRQ）的核心实现文件之一，负责中断事件的高层处理逻辑。该文件实现了中断处理流程中的关键函数，包括中断动作（`irqaction`）的调用、线程化中断的唤醒机制、未处理或异常中断的处理，以及架构无关的中断入口封装。其目标是为不同硬件架构提供统一、可扩展的中断处理框架。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`handle_bad_irq(struct irq_desc *desc)`**  \n  处理伪中断（spurious IRQ）或未注册处理函数的中断，记录统计信息并调用架构相关的 `ack_bad_irq()`。\n\n- **`no_action(int cpl, void *dev_id)`**  \n  空中断处理函数，返回 `IRQ_NONE`，常用于占位或测试。\n\n- **`__irq_wake_thread(struct irq_desc *desc, struct irqaction *action)`**  \n  唤醒与中断动作关联的内核线程（用于线程化中断），管理 `threads_oneshot` 和 `threads_active` 状态。\n\n- **`__handle_irq_event_percpu(struct irq_desc *desc)`**  \n  在当前 CPU 上遍历并执行该中断描述符关联的所有 `irqaction` 处理函数，支持 `IRQ_WAKE_THREAD` 返回值以触发线程化处理。\n\n- **`handle_irq_event_percpu(struct irq_desc *desc)`**  \n  对 `__handle_irq_event_percpu` 的封装，附加中断随机数注入（`add_interrupt_randomness`）和调试记录（`note_interrupt`）。\n\n- **`handle_irq_event(struct irq_desc *desc)`**  \n  中断事件处理的顶层入口，负责清除 `IRQS_PENDING` 状态、设置 `IRQD_IRQ_INPROGRESS` 标志，并在释放 `desc->lock` 后调用 per-CPU 处理函数，最后恢复锁和状态。\n\n- **`generic_handle_arch_irq(struct pt_regs *regs)`**（仅当 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 启用）  \n  架构无关的通用中断入口点，封装 `irq_enter()`/`irq_exit()` 和寄存器上下文切换。\n\n- **`set_handle_irq(void (*handle_irq)(struct pt_regs *))`**（仅当 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 启用）  \n  初始化架构特定的底层中断处理函数指针 `handle_arch_irq`。\n\n### 关键数据结构（引用）\n\n- `struct irq_desc`：中断描述符，包含中断状态、动作链表、锁等。\n- `struct irqaction`：中断动作，包含处理函数 `handler`、线程函数 `thread_fn`、设备 ID、标志等。\n- `handle_arch_irq`：函数指针，指向架构特定的底层中断分发函数（仅在 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 下定义）。\n\n## 3. 关键实现\n\n### 线程化中断唤醒机制\n\n当硬中断处理函数返回 `IRQ_WAKE_THREAD` 时，内核需唤醒对应的线程处理下半部。`__irq_wake_thread` 实现了以下关键逻辑：\n\n- 检查线程是否已退出（`PF_EXITING`），若是则忽略。\n- 使用原子位操作 `test_and_set_bit(IRQTF_RUNTHREAD, ...)` 避免重复唤醒。\n- 通过 `desc->threads_oneshot |= action->thread_mask` 标记需运行的线程。\n- 原子递增 `desc->threads_active`，供 `synchronize_irq()` 等同步原语使用。\n- 调用 `wake_up_process()` 唤醒内核线程。\n\n该机制通过 `IRQS_INPROGRESS` 状态和 `desc->lock` 实现硬中断上下文与中断线程之间的同步，确保 `threads_oneshot` 的读写安全。\n\n### 中断处理流程控制\n\n`handle_irq_event` 是中断流控的关键：\n\n1. 清除 `IRQS_PENDING`（表示中断已开始处理）。\n2. 设置 `IRQD_IRQ_INPROGRESS`（防止嵌套处理）。\n3. 释放 `desc->lock`，允许中断线程或其他 CPU 并发访问。\n4. 调用 `handle_irq_event_percpu` 执行实际处理。\n5. 重新获取锁，清除 `IRQD_IRQ_INPROGRESS`。\n\n此设计解耦了中断流控（如电平触发中断的 EOI）与具体处理逻辑，提高并发性。\n\n### 架构无关中断入口（`CONFIG_GENERIC_IRQ_MULTI_HANDLER`）\n\n该配置允许架构代码注册一个统一的中断入口函数 `handle_arch_irq`。`generic_handle_arch_irq` 作为通用包装器：\n\n- 调用 `irq_enter()` 进入中断上下文。\n- 使用 `set_irq_regs()` 切换当前 CPU 的中断寄存器上下文。\n- 调用注册的 `handle_arch_irq` 进行实际分发。\n- 恢复寄存器上下文并调用 `irq_exit()`。\n\n适用于不自行管理中断入口计数和上下文的架构（如 ARM64）。\n\n### 安全与调试\n\n- **中断使能检查**：在调用 `action->handler` 后，检查中断是否被意外使能（`WARN_ONCE(!irqs_disabled(), ...)`），若发现则强制禁用。\n- **伪中断处理**：`handle_bad_irq` 提供统一的异常中断处理路径，便于调试和统计。\n- **随机数注入**：通过 `add_interrupt_randomness()` 利用中断时间戳增强内核熵池。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/irq.h>`、`<linux/interrupt.h>`：中断核心 API 和数据结构。\n  - `<linux/kernel_stat.h>`：中断统计（`kstat_incr_irqs_this_cpu`）。\n  - `<linux/random.h>`：中断随机数注入。\n  - `<asm/irq_regs.h>`：架构相关的中断寄存器上下文管理。\n  - `\"internals.h\"`：中断子系统内部实现细节。\n  - `<trace/events/irq.h>`：中断事件跟踪点。\n\n- **模块依赖**：\n  - **Generic IRQ 子系统**：依赖 `irqdesc.c`、`irqchip.c` 等提供的 `irq_desc` 管理。\n  - **调度器**：`wake_up_process()` 依赖进程调度。\n  - **RCU 与同步原语**：`synchronize_irq()` 依赖 `threads_active` 计数。\n  - **架构代码**：`ack_bad_irq()`、`handle_arch_irq` 由具体架构实现。\n\n## 5. 使用场景\n\n- **设备驱动注册中断处理函数**：驱动通过 `request_irq()` 注册 `irqaction`，中断触发时由 `handle_irq_event_percpu` 调用其 `handler`。\n- **线程化中断处理**：驱动设置 `IRQF_ONESHOT` 并提供 `thread_fn`，硬中断返回 `IRQ_WAKE_THREAD` 后由 `__irq_wake_thread` 唤醒线程。\n- **伪中断或未处理中断**：硬件误触发或未注册处理函数的中断由 `handle_bad_irq` 统一处理。\n- **架构中断入口**：在 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 架构（如 ARM64）中，异常向量表直接跳转至 `generic_handle_arch_irq`。\n- **中断同步**：`synchronize_irq()` 等函数依赖 `threads_active` 计数等待线程化中断完成。\n- **内核调试与监控**：通过 `note_interrupt()` 记录异常中断，通过 ftrace 的 `irq_handler_entry/exit` 跟踪点监控中断处理性能。",
      "similarity": 0.6471443176269531,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/handle.c",
          "start_line": 33,
          "end_line": 178,
          "content": [
            "void handle_bad_irq(struct irq_desc *desc)",
            "{",
            "\tunsigned int irq = irq_desc_get_irq(desc);",
            "",
            "\tprint_irq_desc(irq, desc);",
            "\tkstat_incr_irqs_this_cpu(desc);",
            "\tack_bad_irq(irq);",
            "}",
            "irqreturn_t no_action(int cpl, void *dev_id)",
            "{",
            "\treturn IRQ_NONE;",
            "}",
            "static void warn_no_thread(unsigned int irq, struct irqaction *action)",
            "{",
            "\tif (test_and_set_bit(IRQTF_WARNED, &action->thread_flags))",
            "\t\treturn;",
            "",
            "\tprintk(KERN_WARNING \"IRQ %d device %s returned IRQ_WAKE_THREAD \"",
            "\t       \"but no thread function available.\", irq, action->name);",
            "}",
            "void __irq_wake_thread(struct irq_desc *desc, struct irqaction *action)",
            "{",
            "\t/*",
            "\t * In case the thread crashed and was killed we just pretend that",
            "\t * we handled the interrupt. The hardirq handler has disabled the",
            "\t * device interrupt, so no irq storm is lurking.",
            "\t */",
            "\tif (action->thread->flags & PF_EXITING)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Wake up the handler thread for this action. If the",
            "\t * RUNTHREAD bit is already set, nothing to do.",
            "\t */",
            "\tif (test_and_set_bit(IRQTF_RUNTHREAD, &action->thread_flags))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * It's safe to OR the mask lockless here. We have only two",
            "\t * places which write to threads_oneshot: This code and the",
            "\t * irq thread.",
            "\t *",
            "\t * This code is the hard irq context and can never run on two",
            "\t * cpus in parallel. If it ever does we have more serious",
            "\t * problems than this bitmask.",
            "\t *",
            "\t * The irq threads of this irq which clear their \"running\" bit",
            "\t * in threads_oneshot are serialized via desc->lock against",
            "\t * each other and they are serialized against this code by",
            "\t * IRQS_INPROGRESS.",
            "\t *",
            "\t * Hard irq handler:",
            "\t *",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tdesc->state |= IRQS_INPROGRESS;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *\tset_bit(IRQTF_RUNTHREAD, &action->thread_flags);",
            "\t *\tdesc->threads_oneshot |= mask;",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tdesc->state &= ~IRQS_INPROGRESS;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *",
            "\t * irq thread:",
            "\t *",
            "\t * again:",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tif (desc->state & IRQS_INPROGRESS) {",
            "\t *\t\tspin_unlock(desc->lock);",
            "\t *\t\twhile(desc->state & IRQS_INPROGRESS)",
            "\t *\t\t\tcpu_relax();",
            "\t *\t\tgoto again;",
            "\t *\t}",
            "\t *\tif (!test_bit(IRQTF_RUNTHREAD, &action->thread_flags))",
            "\t *\t\tdesc->threads_oneshot &= ~mask;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *",
            "\t * So either the thread waits for us to clear IRQS_INPROGRESS",
            "\t * or we are waiting in the flow handler for desc->lock to be",
            "\t * released before we reach this point. The thread also checks",
            "\t * IRQTF_RUNTHREAD under desc->lock. If set it leaves",
            "\t * threads_oneshot untouched and runs the thread another time.",
            "\t */",
            "\tdesc->threads_oneshot |= action->thread_mask;",
            "",
            "\t/*",
            "\t * We increment the threads_active counter in case we wake up",
            "\t * the irq thread. The irq thread decrements the counter when",
            "\t * it returns from the handler or in the exit path and wakes",
            "\t * up waiters which are stuck in synchronize_irq() when the",
            "\t * active count becomes zero. synchronize_irq() is serialized",
            "\t * against this code (hard irq handler) via IRQS_INPROGRESS",
            "\t * like the finalize_oneshot() code. See comment above.",
            "\t */",
            "\tatomic_inc(&desc->threads_active);",
            "",
            "\twake_up_process(action->thread);",
            "}",
            "irqreturn_t __handle_irq_event_percpu(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t retval = IRQ_NONE;",
            "\tunsigned int irq = desc->irq_data.irq;",
            "\tstruct irqaction *action;",
            "",
            "\trecord_irq_time(desc);",
            "",
            "\tfor_each_action_of_desc(desc, action) {",
            "\t\tirqreturn_t res;",
            "",
            "\t\t/*",
            "\t\t * If this IRQ would be threaded under force_irqthreads, mark it so.",
            "\t\t */",
            "\t\tif (irq_settings_can_thread(desc) &&",
            "\t\t    !(action->flags & (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT)))",
            "\t\t\tlockdep_hardirq_threaded();",
            "",
            "\t\ttrace_irq_handler_entry(irq, action);",
            "\t\tres = action->handler(irq, action->dev_id);",
            "\t\ttrace_irq_handler_exit(irq, action, res);",
            "",
            "\t\tif (WARN_ONCE(!irqs_disabled(),\"irq %u handler %pS enabled interrupts\\n\",",
            "\t\t\t      irq, action->handler))",
            "\t\t\tlocal_irq_disable();",
            "",
            "\t\tswitch (res) {",
            "\t\tcase IRQ_WAKE_THREAD:",
            "\t\t\t/*",
            "\t\t\t * Catch drivers which return WAKE_THREAD but",
            "\t\t\t * did not set up a thread function",
            "\t\t\t */",
            "\t\t\tif (unlikely(!action->thread_fn)) {",
            "\t\t\t\twarn_no_thread(irq, action);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "",
            "\t\t\t__irq_wake_thread(desc, action);",
            "\t\t\tbreak;",
            "",
            "\t\tdefault:",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tretval |= res;",
            "\t}",
            "",
            "\treturn retval;",
            "}"
          ],
          "function_name": "handle_bad_irq, no_action, warn_no_thread, __irq_wake_thread, __handle_irq_event_percpu",
          "description": "实现中断处理核心逻辑，包括错误中断处理、唤醒线程函数、事件分发及中断处理结果收集，包含中断线程唤醒与状态同步机制",
          "similarity": 0.7080581784248352
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/handle.c",
          "start_line": 1,
          "end_line": 32,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar",
            " * Copyright (C) 2005-2006, Thomas Gleixner, Russell King",
            " *",
            " * This file contains the core interrupt handling code. Detailed",
            " * information is available in Documentation/core-api/genericirq.rst",
            " *",
            " */",
            "",
            "#include <linux/irq.h>",
            "#include <linux/random.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "",
            "#include <asm/irq_regs.h>",
            "",
            "#include <trace/events/irq.h>",
            "",
            "#include \"internals.h\"",
            "",
            "#ifdef CONFIG_GENERIC_IRQ_MULTI_HANDLER",
            "void (*handle_arch_irq)(struct pt_regs *) __ro_after_init;",
            "#endif",
            "",
            "/**",
            " * handle_bad_irq - handle spurious and unhandled irqs",
            " * @desc:      description of the interrupt",
            " *",
            " * Handles spurious and unhandled IRQ's. It also prints a debugmessage.",
            " */"
          ],
          "function_name": null,
          "description": "定义了处理异常中断的函数handle_bad_irq，用于处理未处理或误触发的中断，打印调试信息并更新中断统计",
          "similarity": 0.6763118505477905
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/irq/handle.c",
          "start_line": 189,
          "end_line": 232,
          "content": [
            "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t retval;",
            "",
            "\tretval = __handle_irq_event_percpu(desc);",
            "",
            "\tadd_interrupt_randomness(desc->irq_data.irq);",
            "",
            "\tif (!irq_settings_no_debug(desc))",
            "\t\tnote_interrupt(desc, retval);",
            "\treturn retval;",
            "}",
            "irqreturn_t handle_irq_event(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t ret;",
            "",
            "\tdesc->istate &= ~IRQS_PENDING;",
            "\tirqd_set(&desc->irq_data, IRQD_IRQ_INPROGRESS);",
            "\traw_spin_unlock(&desc->lock);",
            "",
            "\tret = handle_irq_event_percpu(desc);",
            "",
            "\traw_spin_lock(&desc->lock);",
            "\tirqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);",
            "\treturn ret;",
            "}",
            "int __init set_handle_irq(void (*handle_irq)(struct pt_regs *))",
            "{",
            "\tif (handle_arch_irq)",
            "\t\treturn -EBUSY;",
            "",
            "\thandle_arch_irq = handle_irq;",
            "\treturn 0;",
            "}",
            "asmlinkage void noinstr generic_handle_arch_irq(struct pt_regs *regs)",
            "{",
            "\tstruct pt_regs *old_regs;",
            "",
            "\tirq_enter();",
            "\told_regs = set_irq_regs(regs);",
            "\thandle_arch_irq(regs);",
            "\tset_irq_regs(old_regs);",
            "\tirq_exit();",
            "}"
          ],
          "function_name": "handle_irq_event_percpu, handle_irq_event, set_handle_irq, generic_handle_arch_irq",
          "description": "提供中断事件处理接口，包含通用架构中断入口点generic_handle_arch_irq，管理中断处理流程并集成随机化干扰注入功能",
          "similarity": 0.6568790674209595
        }
      ]
    },
    {
      "source_file": "kernel/trace/trace_hwlat.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:26:17\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `trace\\trace_hwlat.c`\n\n---\n\n# trace_hwlat.c 技术文档\n\n## 1. 文件概述\n\n`trace_hwlat.c` 实现了一个硬件延迟检测器（Hardware Latency Detector），用于检测由底层硬件或固件（如 BIOS/UEFI）引起的系统延迟，这些延迟独立于 Linux 内核本身。该追踪器主要用于检测系统管理中断（SMI, System Management Interrupt）等不可见于操作系统的硬件事件。其核心原理是通过在 CPU 上持续运行高优先级线程，密集采样本地时间戳计数器（TSC 或等效时钟），并检测时间戳之间的异常跳变，从而推断硬件中断造成的延迟。\n\n> **警告**：该追踪器本身会显著干扰系统正常调度，引入可观测延迟，**严禁在对低延迟有要求的生产环境中启用**。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct hwlat_sample`**  \n  存储检测到的单次硬件延迟样本，包含：\n  - `seqnum`: 样本唯一序列号\n  - `duration`: 内层循环延迟（微秒）\n  - `outer_duration`: 外层循环延迟（微秒）\n  - `nmi_total_ts`: NMI 中断总耗时\n  - `timestamp`: 样本捕获的墙上时间\n  - `nmi_count`: 样本期间 NMI 中断次数\n  - `count`: 超过阈值的迭代次数\n\n- **`struct hwlat_data`**  \n  全局运行时状态，包含：\n  - `sample_window`: 采样窗口总时长（开启+关闭）\n  - `sample_width`: 窗口中实际采样时长\n  - `thread_mode`: 线程运行模式（轮询/每 CPU）\n  - `count`: 自重置以来的总样本数\n\n- **`struct hwlat_kthread_data`**  \n  每线程运行时数据，用于记录 NMI 相关时间戳和计数。\n\n### 主要函数\n\n- **`trace_hwlat_callback(bool enter)`**  \n  NMI 回调函数，由 NMI 处理程序调用，记录 NMI 进入/退出时间戳并累加耗时。\n\n- **`get_sample(void)`**  \n  核心采样函数，在关中断状态下密集读取本地时钟，计算连续时间戳差值，检测超过阈值的延迟。\n\n- **`trace_hwlat_sample(struct hwlat_sample *sample)`**  \n  将检测到的延迟样本写入 ftrace 环形缓冲区，供用户空间读取。\n\n- **`get_cpu_data(void)`**  \n  根据当前线程模式（`MODE_ROUND_ROBIN` 或 `MODE_PER_CPU`）返回对应的线程数据结构指针。\n\n### 全局变量\n\n- `trace_hwlat_callback_enabled`: 布尔标志，控制 NMI 是否调用回调函数。\n- `hwlat_data`: 全局配置和状态。\n- `hwlat_single_cpu_data` / `hwlat_per_cpu_data`: 线程数据存储。\n- `last_tracing_thresh`: 记录用户设置的延迟阈值（纳秒）。\n\n## 3. 关键实现\n\n### 延迟检测算法\n\n1. **密集时间采样**：在 `get_sample()` 中，通过连续两次调用 `time_get()`（即 `trace_clock_local()`）获取时间戳 `t1` 和 `t2`。\n2. **内层延迟计算**：`diff = t2 - t1` 表示单次读取操作间的延迟，理论上应极小（纳秒级）。\n3. **外层延迟计算**：`outer_diff = t1_next - t2_prev` 表示两次采样循环之间的间隔，可反映调度或中断延迟。\n4. **阈值比较**：若 `diff` 或 `outer_diff` 超过 `tracing_thresh`（默认 10 微秒），则视为潜在硬件延迟事件。\n5. **NMI 时间统计**：通过 `trace_hwlat_callback` 在 NMI 进入/退出时记录时间，累加 NMI 总耗时。\n\n### 线程模式\n\n- **`MODE_ROUND_ROBIN`（默认）**：单一线程在所有 CPU 间轮转执行采样。\n- **`MODE_PER_CPU`**：每个 CPU 启动独立采样线程，可检测 CPU 特定的硬件延迟。\n- **`MODE_NONE`**：禁用采样。\n\n### 时间基础设施\n\n- 使用 `trace_clock_local()` 获取高精度本地时间戳。\n- 通过 `time_to_us()` 将纳秒转换为微秒进行比较。\n- 依赖内存屏障（`barrier()`）确保 NMI 回调可见性。\n\n### 安全性考虑\n\n- 仅在 `!CONFIG_GENERIC_SCHED_CLOCK` 时记录 NMI 时间，因通用调度时钟在 NMI 上下文中不安全。\n- 采样过程全程关闭中断，防止调度干扰时间测量。\n\n## 4. 依赖关系\n\n- **内核子系统**：\n  - `ftrace`：通过 `trace.h` 接入追踪框架，使用环形缓冲区存储事件。\n  - `kthread`：创建内核线程执行采样任务。\n  - `tracefs`：提供用户空间配置接口（`sample_width`, `sample_window`, `thread_mode`）。\n  - `sched/clock.h`：获取高精度时间戳。\n- **配置选项**：\n  - 依赖 `CONFIG_GENERIC_SCHED_CLOCK` 判断 NMI 时间记录的安全性。\n- **头文件**：\n  - `linux/kthread.h`, `linux/tracefs.h`, `linux/uaccess.h`, `linux/cpumask.h`, `linux/delay.h`\n\n## 5. 使用场景\n\n- **SMI 检测**：在 Intel/AMD 系统上诊断由 BIOS/固件触发的系统管理中断导致的延迟毛刺。\n- **硬件延迟分析**：识别由南桥、热传感器、I/O 访问等硬件事件引发的不可预测延迟。\n- **实时系统调优**：在开发/测试阶段评估硬件对实时性能的影响，指导 BIOS 设置或硬件选型。\n- **固件问题排查**：当系统出现无法解释的延迟时，用于确认是否由底层固件行为导致。\n\n> **典型使用流程**：\n> 1. 挂载 `tracefs`\n> 2. 启用 `hwlat` tracer\n> 3. 配置 `sample_window`、`sample_width` 和 `latency_threshold`\n> 4. 读取 `trace` 文件获取延迟样本\n> 5. 分析样本中的 `duration`、`nmi_count` 等字段定位问题根源",
      "similarity": 0.6414668560028076,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/trace/trace_hwlat.c",
          "start_line": 130,
          "end_line": 284,
          "content": [
            "static void trace_hwlat_sample(struct hwlat_sample *sample)",
            "{",
            "\tstruct trace_array *tr = hwlat_trace;",
            "\tstruct trace_event_call *call = &event_hwlat;",
            "\tstruct trace_buffer *buffer = tr->array_buffer.buffer;",
            "\tstruct ring_buffer_event *event;",
            "\tstruct hwlat_entry *entry;",
            "",
            "\tevent = trace_buffer_lock_reserve(buffer, TRACE_HWLAT, sizeof(*entry),",
            "\t\t\t\t\t  tracing_gen_ctx());",
            "\tif (!event)",
            "\t\treturn;",
            "\tentry\t= ring_buffer_event_data(event);",
            "\tentry->seqnum\t\t\t= sample->seqnum;",
            "\tentry->duration\t\t\t= sample->duration;",
            "\tentry->outer_duration\t\t= sample->outer_duration;",
            "\tentry->timestamp\t\t= sample->timestamp;",
            "\tentry->nmi_total_ts\t\t= sample->nmi_total_ts;",
            "\tentry->nmi_count\t\t= sample->nmi_count;",
            "\tentry->count\t\t\t= sample->count;",
            "",
            "\tif (!call_filter_check_discard(call, entry, buffer, event))",
            "\t\ttrace_buffer_unlock_commit_nostack(buffer, event);",
            "}",
            "void trace_hwlat_callback(bool enter)",
            "{",
            "\tstruct hwlat_kthread_data *kdata = get_cpu_data();",
            "",
            "\tif (!kdata->kthread)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Currently trace_clock_local() calls sched_clock() and the",
            "\t * generic version is not NMI safe.",
            "\t */",
            "\tif (!IS_ENABLED(CONFIG_GENERIC_SCHED_CLOCK)) {",
            "\t\tif (enter)",
            "\t\t\tkdata->nmi_ts_start = time_get();",
            "\t\telse",
            "\t\t\tkdata->nmi_total_ts += time_get() - kdata->nmi_ts_start;",
            "\t}",
            "",
            "\tif (enter)",
            "\t\tkdata->nmi_count++;",
            "}",
            "static int get_sample(void)",
            "{",
            "\tstruct hwlat_kthread_data *kdata = get_cpu_data();",
            "\tstruct trace_array *tr = hwlat_trace;",
            "\tstruct hwlat_sample s;",
            "\ttime_type start, t1, t2, last_t2;",
            "\ts64 diff, outer_diff, total, last_total = 0;",
            "\tu64 sample = 0;",
            "\tu64 thresh = tracing_thresh;",
            "\tu64 outer_sample = 0;",
            "\tint ret = -1;",
            "\tunsigned int count = 0;",
            "",
            "\tdo_div(thresh, NSEC_PER_USEC); /* modifies interval value */",
            "",
            "\tkdata->nmi_total_ts = 0;",
            "\tkdata->nmi_count = 0;",
            "\t/* Make sure NMIs see this first */",
            "\tbarrier();",
            "",
            "\ttrace_hwlat_callback_enabled = true;",
            "",
            "\tinit_time(last_t2, 0);",
            "\tstart = time_get(); /* start timestamp */",
            "\touter_diff = 0;",
            "",
            "\tdo {",
            "",
            "\t\tt1 = time_get();\t/* we'll look for a discontinuity */",
            "\t\tt2 = time_get();",
            "",
            "\t\tif (time_u64(last_t2)) {",
            "\t\t\t/* Check the delta from outer loop (t2 to next t1) */",
            "\t\t\touter_diff = time_to_us(time_sub(t1, last_t2));",
            "\t\t\t/* This shouldn't happen */",
            "\t\t\tif (outer_diff < 0) {",
            "\t\t\t\thwlat_err(BANNER \"time running backwards\\n\");",
            "\t\t\t\tgoto out;",
            "\t\t\t}",
            "\t\t\tif (outer_diff > outer_sample)",
            "\t\t\t\touter_sample = outer_diff;",
            "\t\t}",
            "\t\tlast_t2 = t2;",
            "",
            "\t\ttotal = time_to_us(time_sub(t2, start)); /* sample width */",
            "",
            "\t\t/* Check for possible overflows */",
            "\t\tif (total < last_total) {",
            "\t\t\thwlat_err(\"Time total overflowed\\n\");",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tlast_total = total;",
            "",
            "\t\t/* This checks the inner loop (t1 to t2) */",
            "\t\tdiff = time_to_us(time_sub(t2, t1));     /* current diff */",
            "",
            "\t\tif (diff > thresh || outer_diff > thresh) {",
            "\t\t\tif (!count)",
            "\t\t\t\tktime_get_real_ts64(&s.timestamp);",
            "\t\t\tcount++;",
            "\t\t}",
            "",
            "\t\t/* This shouldn't happen */",
            "\t\tif (diff < 0) {",
            "\t\t\thwlat_err(BANNER \"time running backwards\\n\");",
            "\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\tif (diff > sample)",
            "\t\t\tsample = diff; /* only want highest value */",
            "",
            "\t} while (total <= hwlat_data.sample_width);",
            "",
            "\tbarrier(); /* finish the above in the view for NMIs */",
            "\ttrace_hwlat_callback_enabled = false;",
            "\tbarrier(); /* Make sure nmi_total_ts is no longer updated */",
            "",
            "\tret = 0;",
            "",
            "\t/* If we exceed the threshold value, we have found a hardware latency */",
            "\tif (sample > thresh || outer_sample > thresh) {",
            "\t\tu64 latency;",
            "",
            "\t\tret = 1;",
            "",
            "\t\t/* We read in microseconds */",
            "\t\tif (kdata->nmi_total_ts)",
            "\t\t\tdo_div(kdata->nmi_total_ts, NSEC_PER_USEC);",
            "",
            "\t\thwlat_data.count++;",
            "\t\ts.seqnum = hwlat_data.count;",
            "\t\ts.duration = sample;",
            "\t\ts.outer_duration = outer_sample;",
            "\t\ts.nmi_total_ts = kdata->nmi_total_ts;",
            "\t\ts.nmi_count = kdata->nmi_count;",
            "\t\ts.count = count;",
            "\t\ttrace_hwlat_sample(&s);",
            "",
            "\t\tlatency = max(sample, outer_sample);",
            "",
            "\t\t/* Keep a running maximum ever recorded hardware latency */",
            "\t\tif (latency > tr->max_latency) {",
            "\t\t\ttr->max_latency = latency;",
            "\t\t\tlatency_fsnotify(tr);",
            "\t\t}",
            "\t}",
            "",
            "out:",
            "\treturn ret;",
            "}"
          ],
          "function_name": "trace_hwlat_sample, trace_hwlat_callback, get_sample",
          "description": "实现硬件延迟检测的核心逻辑，包括时间采样、阈值判断、NMI回调处理及事件记录，用于识别由底层硬件引起的异常延迟。",
          "similarity": 0.6512531042098999
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/trace/trace_hwlat.c",
          "start_line": 1,
          "end_line": 129,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * trace_hwlat.c - A simple Hardware Latency detector.",
            " *",
            " * Use this tracer to detect large system latencies induced by the behavior of",
            " * certain underlying system hardware or firmware, independent of Linux itself.",
            " * The code was developed originally to detect the presence of SMIs on Intel",
            " * and AMD systems, although there is no dependency upon x86 herein.",
            " *",
            " * The classical example usage of this tracer is in detecting the presence of",
            " * SMIs or System Management Interrupts on Intel and AMD systems. An SMI is a",
            " * somewhat special form of hardware interrupt spawned from earlier CPU debug",
            " * modes in which the (BIOS/EFI/etc.) firmware arranges for the South Bridge",
            " * LPC (or other device) to generate a special interrupt under certain",
            " * circumstances, for example, upon expiration of a special SMI timer device,",
            " * due to certain external thermal readings, on certain I/O address accesses,",
            " * and other situations. An SMI hits a special CPU pin, triggers a special",
            " * SMI mode (complete with special memory map), and the OS is unaware.",
            " *",
            " * Although certain hardware-inducing latencies are necessary (for example,",
            " * a modern system often requires an SMI handler for correct thermal control",
            " * and remote management) they can wreak havoc upon any OS-level performance",
            " * guarantees toward low-latency, especially when the OS is not even made",
            " * aware of the presence of these interrupts. For this reason, we need a",
            " * somewhat brute force mechanism to detect these interrupts. In this case,",
            " * we do it by hogging all of the CPU(s) for configurable timer intervals,",
            " * sampling the built-in CPU timer, looking for discontiguous readings.",
            " *",
            " * WARNING: This implementation necessarily introduces latencies. Therefore,",
            " *          you should NEVER use this tracer while running in a production",
            " *          environment requiring any kind of low-latency performance",
            " *          guarantee(s).",
            " *",
            " * Copyright (C) 2008-2009 Jon Masters, Red Hat, Inc. <jcm@redhat.com>",
            " * Copyright (C) 2013-2016 Steven Rostedt, Red Hat, Inc. <srostedt@redhat.com>",
            " *",
            " * Includes useful feedback from Clark Williams <williams@redhat.com>",
            " *",
            " */",
            "#include <linux/kthread.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/clock.h>",
            "#include \"trace.h\"",
            "",
            "static struct trace_array\t*hwlat_trace;",
            "",
            "#define U64STR_SIZE\t\t22\t\t\t/* 20 digits max */",
            "",
            "#define BANNER\t\t\t\"hwlat_detector: \"",
            "#define DEFAULT_SAMPLE_WINDOW\t1000000\t\t\t/* 1s */",
            "#define DEFAULT_SAMPLE_WIDTH\t500000\t\t\t/* 0.5s */",
            "#define DEFAULT_LAT_THRESHOLD\t10\t\t\t/* 10us */",
            "",
            "static struct dentry *hwlat_sample_width;\t/* sample width us */",
            "static struct dentry *hwlat_sample_window;\t/* sample window us */",
            "static struct dentry *hwlat_thread_mode;\t/* hwlat thread mode */",
            "",
            "enum {",
            "\tMODE_NONE = 0,",
            "\tMODE_ROUND_ROBIN,",
            "\tMODE_PER_CPU,",
            "\tMODE_MAX",
            "};",
            "static char *thread_mode_str[] = { \"none\", \"round-robin\", \"per-cpu\" };",
            "",
            "/* Save the previous tracing_thresh value */",
            "static unsigned long save_tracing_thresh;",
            "",
            "/* runtime kthread data */",
            "struct hwlat_kthread_data {",
            "\tstruct task_struct\t*kthread;",
            "\t/* NMI timestamp counters */",
            "\tu64\t\t\tnmi_ts_start;",
            "\tu64\t\t\tnmi_total_ts;",
            "\tint\t\t\tnmi_count;",
            "\tint\t\t\tnmi_cpu;",
            "};",
            "",
            "static struct hwlat_kthread_data hwlat_single_cpu_data;",
            "static DEFINE_PER_CPU(struct hwlat_kthread_data, hwlat_per_cpu_data);",
            "",
            "/* Tells NMIs to call back to the hwlat tracer to record timestamps */",
            "bool trace_hwlat_callback_enabled;",
            "",
            "/* If the user changed threshold, remember it */",
            "static u64 last_tracing_thresh = DEFAULT_LAT_THRESHOLD * NSEC_PER_USEC;",
            "",
            "/* Individual latency samples are stored here when detected. */",
            "struct hwlat_sample {",
            "\tu64\t\t\tseqnum;\t\t/* unique sequence */",
            "\tu64\t\t\tduration;\t/* delta */",
            "\tu64\t\t\touter_duration;\t/* delta (outer loop) */",
            "\tu64\t\t\tnmi_total_ts;\t/* Total time spent in NMIs */",
            "\tstruct timespec64\ttimestamp;\t/* wall time */",
            "\tint\t\t\tnmi_count;\t/* # NMIs during this sample */",
            "\tint\t\t\tcount;\t\t/* # of iterations over thresh */",
            "};",
            "",
            "/* keep the global state somewhere. */",
            "static struct hwlat_data {",
            "",
            "\tstruct mutex lock;\t\t/* protect changes */",
            "",
            "\tu64\tcount;\t\t\t/* total since reset */",
            "",
            "\tu64\tsample_window;\t\t/* total sampling window (on+off) */",
            "\tu64\tsample_width;\t\t/* active sampling portion of window */",
            "",
            "\tint\tthread_mode;\t\t/* thread mode */",
            "",
            "} hwlat_data = {",
            "\t.sample_window\t\t= DEFAULT_SAMPLE_WINDOW,",
            "\t.sample_width\t\t= DEFAULT_SAMPLE_WIDTH,",
            "\t.thread_mode\t\t= MODE_ROUND_ROBIN",
            "};",
            "",
            "static struct hwlat_kthread_data *get_cpu_data(void)",
            "{",
            "\tif (hwlat_data.thread_mode == MODE_PER_CPU)",
            "\t\treturn this_cpu_ptr(&hwlat_per_cpu_data);",
            "\telse",
            "\t\treturn &hwlat_single_cpu_data;",
            "}",
            "",
            "static bool hwlat_busy;",
            ""
          ],
          "function_name": null,
          "description": "定义硬件延迟检测器的核心数据结构和配置参数，包括采样窗口、宽度、线程模式等全局变量及辅助函数，用于初始化和管理检测器状态。",
          "similarity": 0.6478887796401978
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/trace/trace_hwlat.c",
          "start_line": 462,
          "end_line": 572,
          "content": [
            "static void stop_cpu_kthread(unsigned int cpu)",
            "{",
            "\tstruct task_struct *kthread;",
            "",
            "\tkthread = per_cpu(hwlat_per_cpu_data, cpu).kthread;",
            "\tif (kthread)",
            "\t\tkthread_stop(kthread);",
            "\tper_cpu(hwlat_per_cpu_data, cpu).kthread = NULL;",
            "}",
            "static void stop_per_cpu_kthreads(void)",
            "{",
            "\tunsigned int cpu;",
            "",
            "\tcpus_read_lock();",
            "\tfor_each_online_cpu(cpu)",
            "\t\tstop_cpu_kthread(cpu);",
            "\tcpus_read_unlock();",
            "}",
            "static int start_cpu_kthread(unsigned int cpu)",
            "{",
            "\tstruct task_struct *kthread;",
            "",
            "\t/* Do not start a new hwlatd thread if it is already running */",
            "\tif (per_cpu(hwlat_per_cpu_data, cpu).kthread)",
            "\t\treturn 0;",
            "",
            "\tkthread = kthread_run_on_cpu(kthread_fn, NULL, cpu, \"hwlatd/%u\");",
            "\tif (IS_ERR(kthread)) {",
            "\t\tpr_err(BANNER \"could not start sampling thread\\n\");",
            "\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\tper_cpu(hwlat_per_cpu_data, cpu).kthread = kthread;",
            "",
            "\treturn 0;",
            "}",
            "static void hwlat_hotplug_workfn(struct work_struct *dummy)",
            "{",
            "\tstruct trace_array *tr = hwlat_trace;",
            "\tunsigned int cpu = smp_processor_id();",
            "",
            "\tmutex_lock(&trace_types_lock);",
            "\tmutex_lock(&hwlat_data.lock);",
            "\tcpus_read_lock();",
            "",
            "\tif (!hwlat_busy || hwlat_data.thread_mode != MODE_PER_CPU)",
            "\t\tgoto out_unlock;",
            "",
            "\tif (!cpu_online(cpu))",
            "\t\tgoto out_unlock;",
            "\tif (!cpumask_test_cpu(cpu, tr->tracing_cpumask))",
            "\t\tgoto out_unlock;",
            "",
            "\tstart_cpu_kthread(cpu);",
            "",
            "out_unlock:",
            "\tcpus_read_unlock();",
            "\tmutex_unlock(&hwlat_data.lock);",
            "\tmutex_unlock(&trace_types_lock);",
            "}",
            "static int hwlat_cpu_init(unsigned int cpu)",
            "{",
            "\tschedule_work_on(cpu, &hwlat_hotplug_work);",
            "\treturn 0;",
            "}",
            "static int hwlat_cpu_die(unsigned int cpu)",
            "{",
            "\tstop_cpu_kthread(cpu);",
            "\treturn 0;",
            "}",
            "static void hwlat_init_hotplug_support(void)",
            "{",
            "\tint ret;",
            "",
            "\tret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, \"trace/hwlat:online\",",
            "\t\t\t\thwlat_cpu_init, hwlat_cpu_die);",
            "\tif (ret < 0)",
            "\t\tpr_warn(BANNER \"Error to init cpu hotplug support\\n\");",
            "",
            "\treturn;",
            "}",
            "static void hwlat_init_hotplug_support(void)",
            "{",
            "\treturn;",
            "}",
            "static int start_per_cpu_kthreads(struct trace_array *tr)",
            "{",
            "\tstruct cpumask *current_mask = &save_cpumask;",
            "\tunsigned int cpu;",
            "\tint retval;",
            "",
            "\tcpus_read_lock();",
            "\t/*",
            "\t * Run only on CPUs in which hwlat is allowed to run.",
            "\t */",
            "\tcpumask_and(current_mask, cpu_online_mask, tr->tracing_cpumask);",
            "",
            "\tfor_each_cpu(cpu, current_mask) {",
            "\t\tretval = start_cpu_kthread(cpu);",
            "\t\tif (retval)",
            "\t\t\tgoto out_error;",
            "\t}",
            "\tcpus_read_unlock();",
            "",
            "\treturn 0;",
            "",
            "out_error:",
            "\tcpus_read_unlock();",
            "\tstop_per_cpu_kthreads();",
            "\treturn retval;",
            "}"
          ],
          "function_name": "stop_cpu_kthread, stop_per_cpu_kthreads, start_cpu_kthread, hwlat_hotplug_workfn, hwlat_cpu_init, hwlat_cpu_die, hwlat_init_hotplug_support, hwlat_init_hotplug_support, start_per_cpu_kthreads",
          "description": "实现CPU热插拔场景下的动态检测支持，在CPU在线/离线事件中自动启停对应检测线程，维护多核系统的实时监测能力。",
          "similarity": 0.6318466067314148
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/trace/trace_hwlat.c",
          "start_line": 812,
          "end_line": 878,
          "content": [
            "static void hwlat_tracer_start(struct trace_array *tr)",
            "{",
            "\tint err;",
            "",
            "\tif (hwlat_data.thread_mode == MODE_PER_CPU)",
            "\t\terr = start_per_cpu_kthreads(tr);",
            "\telse",
            "\t\terr = start_single_kthread(tr);",
            "\tif (err)",
            "\t\tpr_err(BANNER \"Cannot start hwlat kthread\\n\");",
            "}",
            "static void hwlat_tracer_stop(struct trace_array *tr)",
            "{",
            "\tif (hwlat_data.thread_mode == MODE_PER_CPU)",
            "\t\tstop_per_cpu_kthreads();",
            "\telse",
            "\t\tstop_single_kthread();",
            "}",
            "static int hwlat_tracer_init(struct trace_array *tr)",
            "{",
            "\t/* Only allow one instance to enable this */",
            "\tif (hwlat_busy)",
            "\t\treturn -EBUSY;",
            "",
            "\thwlat_trace = tr;",
            "",
            "\thwlat_data.count = 0;",
            "\ttr->max_latency = 0;",
            "\tsave_tracing_thresh = tracing_thresh;",
            "",
            "\t/* tracing_thresh is in nsecs, we speak in usecs */",
            "\tif (!tracing_thresh)",
            "\t\ttracing_thresh = last_tracing_thresh;",
            "",
            "\tif (tracer_tracing_is_on(tr))",
            "\t\thwlat_tracer_start(tr);",
            "",
            "\thwlat_busy = true;",
            "",
            "\treturn 0;",
            "}",
            "static void hwlat_tracer_reset(struct trace_array *tr)",
            "{",
            "\thwlat_tracer_stop(tr);",
            "",
            "\t/* the tracing threshold is static between runs */",
            "\tlast_tracing_thresh = tracing_thresh;",
            "",
            "\ttracing_thresh = save_tracing_thresh;",
            "\thwlat_busy = false;",
            "}",
            "__init static int init_hwlat_tracer(void)",
            "{",
            "\tint ret;",
            "",
            "\tmutex_init(&hwlat_data.lock);",
            "",
            "\tret = register_tracer(&hwlat_tracer);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\thwlat_init_hotplug_support();",
            "",
            "\tinit_tracefs();",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "hwlat_tracer_start, hwlat_tracer_stop, hwlat_tracer_init, hwlat_tracer_reset, init_hwlat_tracer",
          "description": "该代码实现了一种硬件延迟检测（HWLAT）的跟踪器模块，用于监控系统中因硬件资源竞争导致的延迟事件。  \n其核心函数根据`thread_mode`启动或停止多线程监控任务，并通过`hwlat_tracer_init`初始化跟踪器状态及阈值配置，确保仅允许单一实例运行。  \n`init_hwlat_tracer`负责注册跟踪器并初始化热插拔支持，构成整个HWLAT跟踪机制的基础框架。",
          "similarity": 0.6188614368438721
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/trace/trace_hwlat.c",
          "start_line": 630,
          "end_line": 742,
          "content": [
            "static int s_mode_show(struct seq_file *s, void *v)",
            "{",
            "\tloff_t *pos = v;",
            "\tint mode = *pos;",
            "",
            "\tif (mode == hwlat_data.thread_mode)",
            "\t\tseq_printf(s, \"[%s]\", thread_mode_str[mode]);",
            "\telse",
            "\t\tseq_printf(s, \"%s\", thread_mode_str[mode]);",
            "",
            "\tif (mode < MODE_MAX - 1) /* if mode is any but last */",
            "\t\tseq_puts(s, \" \");",
            "",
            "\treturn 0;",
            "}",
            "static void s_mode_stop(struct seq_file *s, void *v)",
            "{",
            "\tseq_puts(s, \"\\n\");",
            "\tmutex_unlock(&hwlat_data.lock);",
            "}",
            "static int hwlat_mode_open(struct inode *inode, struct file *file)",
            "{",
            "\treturn seq_open(file, &thread_mode_seq_ops);",
            "};",
            "static ssize_t hwlat_mode_write(struct file *filp, const char __user *ubuf,",
            "\t\t\t\t size_t cnt, loff_t *ppos)",
            "{",
            "\tstruct trace_array *tr = hwlat_trace;",
            "\tconst char *mode;",
            "\tchar buf[64];",
            "\tint ret, i;",
            "",
            "\tif (cnt >= sizeof(buf))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (copy_from_user(buf, ubuf, cnt))",
            "\t\treturn -EFAULT;",
            "",
            "\tbuf[cnt] = 0;",
            "",
            "\tmode = strstrip(buf);",
            "",
            "\tret = -EINVAL;",
            "",
            "\t/*",
            "\t * trace_types_lock is taken to avoid concurrency on start/stop",
            "\t * and hwlat_busy.",
            "\t */",
            "\tmutex_lock(&trace_types_lock);",
            "\tif (hwlat_busy)",
            "\t\thwlat_tracer_stop(tr);",
            "",
            "\tmutex_lock(&hwlat_data.lock);",
            "",
            "\tfor (i = 0; i < MODE_MAX; i++) {",
            "\t\tif (strcmp(mode, thread_mode_str[i]) == 0) {",
            "\t\t\thwlat_data.thread_mode = i;",
            "\t\t\tret = cnt;",
            "\t\t}",
            "\t}",
            "",
            "\tmutex_unlock(&hwlat_data.lock);",
            "",
            "\tif (hwlat_busy)",
            "\t\thwlat_tracer_start(tr);",
            "\tmutex_unlock(&trace_types_lock);",
            "",
            "\t*ppos += cnt;",
            "",
            "",
            "",
            "\treturn ret;",
            "}",
            "static int init_tracefs(void)",
            "{",
            "\tint ret;",
            "\tstruct dentry *top_dir;",
            "",
            "\tret = tracing_init_dentry();",
            "\tif (ret)",
            "\t\treturn -ENOMEM;",
            "",
            "\ttop_dir = tracefs_create_dir(\"hwlat_detector\", NULL);",
            "\tif (!top_dir)",
            "\t\treturn -ENOMEM;",
            "",
            "\thwlat_sample_window = tracefs_create_file(\"window\", TRACE_MODE_WRITE,",
            "\t\t\t\t\t\t  top_dir,",
            "\t\t\t\t\t\t  &hwlat_window,",
            "\t\t\t\t\t\t  &trace_min_max_fops);",
            "\tif (!hwlat_sample_window)",
            "\t\tgoto err;",
            "",
            "\thwlat_sample_width = tracefs_create_file(\"width\", TRACE_MODE_WRITE,",
            "\t\t\t\t\t\t top_dir,",
            "\t\t\t\t\t\t &hwlat_width,",
            "\t\t\t\t\t\t &trace_min_max_fops);",
            "\tif (!hwlat_sample_width)",
            "\t\tgoto err;",
            "",
            "\thwlat_thread_mode = trace_create_file(\"mode\", TRACE_MODE_WRITE,",
            "\t\t\t\t\t      top_dir,",
            "\t\t\t\t\t      NULL,",
            "\t\t\t\t\t      &thread_mode_fops);",
            "\tif (!hwlat_thread_mode)",
            "\t\tgoto err;",
            "",
            "\treturn 0;",
            "",
            " err:",
            "\ttracefs_remove(top_dir);",
            "\treturn -ENOMEM;",
            "}"
          ],
          "function_name": "s_mode_show, s_mode_stop, hwlat_mode_open, hwlat_mode_write, init_tracefs",
          "description": "提供TraceFS接口供用户配置检测模式及参数，包含模式读取/写入接口和TraceFS目录初始化逻辑，实现用户态对检测器的控制。",
          "similarity": 0.5523433089256287
        }
      ]
    }
  ]
}