{
  "query": "sys_call路径优化",
  "timestamp": "2025-12-26 02:10:23",
  "retrieved_files": [
    {
      "source_file": "kernel/entry/syscall_user_dispatch.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:20:47\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `entry\\syscall_user_dispatch.c`\n\n---\n\n# entry/syscall_user_dispatch.c 技术文档\n\n## 1. 文件概述\n\n`entry/syscall_user_dispatch.c` 实现了 **系统调用用户分发（Syscall User Dispatch, SUD）** 机制，该机制允许用户空间程序通过 `prctl()` 系统调用配置一个“选择器”（selector），用于在特定条件下拦截或允许系统调用的执行。当系统调用指令指针位于指定区域之外且选择器状态为“阻塞”时，内核会回滚该系统调用并向进程发送 `SIGSYS` 信号，从而实现对系统调用的细粒度控制。此功能常用于沙箱、安全监控或调试场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `trigger_sigsys(struct pt_regs *regs)`  \n  构造并强制发送 `SIGSYS` 信号，携带被拦截系统调用的详细信息（如地址、系统调用号、架构等）。\n\n- `syscall_user_dispatch(struct pt_regs *regs)`  \n  系统调用入口处的分发判断逻辑。根据当前指令指针位置和用户选择器状态决定是否拦截系统调用。\n\n- `task_set_syscall_user_dispatch(struct task_struct *task, ...)`  \n  为指定任务设置系统调用用户分发配置（开启/关闭、偏移、长度、选择器地址）。\n\n- `set_syscall_user_dispatch(...)`  \n  为当前任务设置系统调用用户分发配置的封装接口，供 `prctl()` 调用。\n\n- `syscall_user_dispatch_get_config(...)`  \n  通过 `ptrace` 获取指定任务的 SUD 配置。\n\n- `syscall_user_dispatch_set_config(...)`  \n  通过 `ptrace` 设置指定任务的 SUD 配置。\n\n### 关键数据结构\n\n- `struct syscall_user_dispatch`（定义在 `<linux/syscall_user_dispatch.h>`）  \n  存储每个任务的 SUD 配置：\n  - `selector`：指向用户空间选择器字节的指针\n  - `offset` / `len`：允许直接执行系统调用的代码区域（[offset, offset+len)）\n  - `on_dispatch`：标志位，表示当前是否处于分发拦截状态\n\n- `struct ptrace_sud_config`  \n  用于 `ptrace` 接口传递 SUD 配置的结构体，包含 `mode`、`offset`、`len` 和 `selector`。\n\n## 3. 关键实现\n\n### 系统调用拦截逻辑\n\n1. **区域检查**：若当前指令指针（`instruction_pointer(regs)`）落在 `[offset, offset + len)` 范围内，则**允许**系统调用直接执行，不进行拦截。\n2. **vdso 例外**：若系统调用来自 vDSO 中的 `sigreturn`（如 `arch_syscall_is_vdso_sigreturn()` 返回 true），则跳过拦截，避免干扰信号返回路径。\n3. **选择器读取**：若配置了 `selector`，则从用户空间读取一个字节的状态值：\n   - `SYSCALL_DISPATCH_FILTER_ALLOW`（0）：允许系统调用\n   - `SYSCALL_DISPATCH_FILTER_BLOCK`（1）：触发拦截\n   - 其他值：视为非法，发送 `SIGSYS`\n4. **拦截处理**：\n   - 设置 `on_dispatch = true`\n   - 调用 `syscall_rollback()` 回滚系统调用（恢复寄存器状态）\n   - 调用 `trigger_sigsys()` 发送 `SIGSYS` 信号\n\n### 安全与健壮性设计\n\n- **地址合法性校验**：在设置 `selector` 时使用 `access_ok(untagged_addr(selector), ...)`，确保地址可访问，并处理内存标记（如 ARM MTE）场景下调试器（tracer）与被调试进程（tracee）地址标记不一致的问题。\n- **溢出防护**：检查 `offset + len <= offset` 防止整数溢出导致无效区域。\n- **权限隔离**：`ptrace` 接口允许调试器配置其他进程的 SUD，但需具备相应权限。\n\n### 信号信息构造\n\n`trigger_sigsys()` 构造的 `siginfo_t` 包含：\n- `si_signo = SIGSYS`\n- `si_code = SYS_USER_DISPATCH`\n- `si_call_addr`：触发系统调用的用户空间地址\n- `si_syscall`：系统调用号\n- `si_arch`：系统调用架构（如 x86_64、AArch64）\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/prctl.h>`：定义 `PR_SYS_DISPATCH_*` 常量\n  - `<linux/syscall_user_dispatch.h>`：定义 `struct syscall_user_dispatch` 和相关常量\n  - `<asm/syscall.h>`：提供 `syscall_get_arch()`、`syscall_get_nr()` 等架构相关接口\n  - `\"common.h\"`：可能包含内核入口通用辅助函数\n- **内核子系统**：\n  - **调度器（sched）**：访问 `current` 任务结构\n  - **信号子系统（signal）**：发送 `SIGSYS` 信号\n  - **内存管理（uaccess）**：用户空间内存访问（`__get_user`, `access_ok`）\n  - **ptrace**：支持调试器配置 SUD\n  - **ELF**：可能用于架构识别（间接依赖）\n\n## 5. 使用场景\n\n- **沙箱环境**：限制应用只能在特定代码段发起系统调用，防止恶意代码绕过安全策略。\n- **动态二进制插桩（DBI）**：工具（如 Valgrind、Intel Pin）可拦截系统调用进行分析或重定向。\n- **安全监控**：监控程序可配置选择器为“阻塞”，在 `SIGSYS` 信号处理程序中记录或审查系统调用。\n- **调试与测试**：通过 `ptrace` 动态启用/禁用 SUD，用于测试系统调用拦截逻辑。\n- **W^X 策略增强**：结合代码段只读与 SUD，确保只有可信代码路径可发起系统调用。",
      "similarity": 0.6231281757354736,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/entry/syscall_user_dispatch.c",
          "start_line": 20,
          "end_line": 122,
          "content": [
            "static void trigger_sigsys(struct pt_regs *regs)",
            "{",
            "\tstruct kernel_siginfo info;",
            "",
            "\tclear_siginfo(&info);",
            "\tinfo.si_signo = SIGSYS;",
            "\tinfo.si_code = SYS_USER_DISPATCH;",
            "\tinfo.si_call_addr = (void __user *)KSTK_EIP(current);",
            "\tinfo.si_errno = 0;",
            "\tinfo.si_arch = syscall_get_arch(current);",
            "\tinfo.si_syscall = syscall_get_nr(current, regs);",
            "",
            "\tforce_sig_info(&info);",
            "}",
            "bool syscall_user_dispatch(struct pt_regs *regs)",
            "{",
            "\tstruct syscall_user_dispatch *sd = &current->syscall_dispatch;",
            "\tchar state;",
            "",
            "\tif (likely(instruction_pointer(regs) - sd->offset < sd->len))",
            "\t\treturn false;",
            "",
            "\tif (unlikely(arch_syscall_is_vdso_sigreturn(regs)))",
            "\t\treturn false;",
            "",
            "\tif (likely(sd->selector)) {",
            "\t\t/*",
            "\t\t * access_ok() is performed once, at prctl time, when",
            "\t\t * the selector is loaded by userspace.",
            "\t\t */",
            "\t\tif (unlikely(__get_user(state, sd->selector))) {",
            "\t\t\tforce_exit_sig(SIGSEGV);",
            "\t\t\treturn true;",
            "\t\t}",
            "",
            "\t\tif (likely(state == SYSCALL_DISPATCH_FILTER_ALLOW))",
            "\t\t\treturn false;",
            "",
            "\t\tif (state != SYSCALL_DISPATCH_FILTER_BLOCK) {",
            "\t\t\tforce_exit_sig(SIGSYS);",
            "\t\t\treturn true;",
            "\t\t}",
            "\t}",
            "",
            "\tsd->on_dispatch = true;",
            "\tsyscall_rollback(current, regs);",
            "\ttrigger_sigsys(regs);",
            "",
            "\treturn true;",
            "}",
            "static int task_set_syscall_user_dispatch(struct task_struct *task, unsigned long mode,",
            "\t\t\t\t\t  unsigned long offset, unsigned long len,",
            "\t\t\t\t\t  char __user *selector)",
            "{",
            "\tswitch (mode) {",
            "\tcase PR_SYS_DISPATCH_OFF:",
            "\t\tif (offset || len || selector)",
            "\t\t\treturn -EINVAL;",
            "\t\tbreak;",
            "\tcase PR_SYS_DISPATCH_ON:",
            "\t\t/*",
            "\t\t * Validate the direct dispatcher region just for basic",
            "\t\t * sanity against overflow and a 0-sized dispatcher",
            "\t\t * region.  If the user is able to submit a syscall from",
            "\t\t * an address, that address is obviously valid.",
            "\t\t */",
            "\t\tif (offset && offset + len <= offset)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * access_ok() will clear memory tags for tagged addresses",
            "\t\t * if current has memory tagging enabled.",
            "",
            "\t\t * To enable a tracer to set a tracees selector the",
            "\t\t * selector address must be untagged for access_ok(),",
            "\t\t * otherwise an untagged tracer will always fail to set a",
            "\t\t * tagged tracees selector.",
            "\t\t */",
            "\t\tif (selector && !access_ok(untagged_addr(selector), sizeof(*selector)))",
            "\t\t\treturn -EFAULT;",
            "",
            "\t\tbreak;",
            "\tdefault:",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\ttask->syscall_dispatch.selector = selector;",
            "\ttask->syscall_dispatch.offset = offset;",
            "\ttask->syscall_dispatch.len = len;",
            "\ttask->syscall_dispatch.on_dispatch = false;",
            "",
            "\tif (mode == PR_SYS_DISPATCH_ON)",
            "\t\tset_task_syscall_work(task, SYSCALL_USER_DISPATCH);",
            "\telse",
            "\t\tclear_task_syscall_work(task, SYSCALL_USER_DISPATCH);",
            "",
            "\treturn 0;",
            "}",
            "int set_syscall_user_dispatch(unsigned long mode, unsigned long offset,",
            "\t\t\t      unsigned long len, char __user *selector)",
            "{",
            "\treturn task_set_syscall_user_dispatch(current, mode, offset, len, selector);",
            "}"
          ],
          "function_name": "trigger_sigsys, syscall_user_dispatch, task_set_syscall_user_dispatch, set_syscall_user_dispatch",
          "description": "实现系统调用用户分发核心逻辑，包含触发SIGSYS信号处理、配置验证、拦截判断及模式切换功能",
          "similarity": 0.5609652996063232
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/entry/syscall_user_dispatch.c",
          "start_line": 127,
          "end_line": 163,
          "content": [
            "int syscall_user_dispatch_get_config(struct task_struct *task, unsigned long size,",
            "\t\t\t\t     void __user *data)",
            "{",
            "\tstruct syscall_user_dispatch *sd = &task->syscall_dispatch;",
            "\tstruct ptrace_sud_config cfg;",
            "",
            "\tif (size != sizeof(cfg))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (test_task_syscall_work(task, SYSCALL_USER_DISPATCH))",
            "\t\tcfg.mode = PR_SYS_DISPATCH_ON;",
            "\telse",
            "\t\tcfg.mode = PR_SYS_DISPATCH_OFF;",
            "",
            "\tcfg.offset = sd->offset;",
            "\tcfg.len = sd->len;",
            "\tcfg.selector = (__u64)(uintptr_t)sd->selector;",
            "",
            "\tif (copy_to_user(data, &cfg, sizeof(cfg)))",
            "\t\treturn -EFAULT;",
            "",
            "\treturn 0;",
            "}",
            "int syscall_user_dispatch_set_config(struct task_struct *task, unsigned long size,",
            "\t\t\t\t     void __user *data)",
            "{",
            "\tstruct ptrace_sud_config cfg;",
            "",
            "\tif (size != sizeof(cfg))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (copy_from_user(&cfg, data, sizeof(cfg)))",
            "\t\treturn -EFAULT;",
            "",
            "\treturn task_set_syscall_user_dispatch(task, cfg.mode, cfg.offset, cfg.len,",
            "\t\t\t\t\t      (char __user *)(uintptr_t)cfg.selector);",
            "}"
          ],
          "function_name": "syscall_user_dispatch_get_config, syscall_user_dispatch_set_config",
          "description": "提供系统调用分发配置的获取与设置接口，通过用户态指针操作实现配置参数的双向传递",
          "similarity": 0.4924231171607971
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/entry/syscall_user_dispatch.c",
          "start_line": 1,
          "end_line": 19,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 2020 Collabora Ltd.",
            " */",
            "#include <linux/sched.h>",
            "#include <linux/prctl.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/syscall_user_dispatch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/signal.h>",
            "#include <linux/elf.h>",
            "",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task_stack.h>",
            "",
            "#include <asm/syscall.h>",
            "",
            "#include \"common.h\"",
            ""
          ],
          "function_name": null,
          "description": "包含系统调用用户分发功能所需头文件及通用定义，提供架构相关接口和内核调度必要声明",
          "similarity": 0.4528947174549103
        }
      ]
    },
    {
      "source_file": "kernel/sched/syscalls.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:19:13\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\syscalls.c`\n\n---\n\n# `sched/syscalls.c` 技术文档\n\n## 1. 文件概述\n\n`sched/syscalls.c` 是 Linux 内核调度子系统的核心源文件之一，主要负责实现与调度相关的系统调用接口和优先级管理逻辑。该文件封装了任务优先级计算、nice 值设置、CPU 空闲状态判断等关键功能，为用户空间提供 `nice()` 等系统调用的内核支持，并为调度器内部模块提供优先级操作原语。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `__normal_prio()`：根据调度策略（SCHED_NORMAL/SCHED_BATCH/SCHED_IDLE、SCHED_FIFO/SCHED_RR、SCHED_DEADLINE）计算任务的“正常”优先级。\n- `normal_prio()`：基于任务当前策略、实时优先级和静态 nice 值计算其正常优先级。\n- `effective_prio()`：计算任务当前实际生效的调度优先级，考虑 RT 继承或提升。\n- `set_user_nice()`：安全地修改指定任务的 nice 值，更新其静态优先级和调度权重，并触发调度器重评估。\n- `is_nice_reduction()` / `can_nice()`：检查任务是否具备降低 nice 值（即提高优先级）的权限。\n- `sys_nice()`：实现 `nice(2)` 系统调用，允许当前进程调整自身优先级。\n- `task_prio()`：返回任务在 `/proc` 中对外暴露的用户可见优先级值。\n- `idle_cpu()` / `available_idle_cpu()`：判断指定 CPU 是否处于空闲状态。\n- `idle_task()`：获取指定 CPU 的 idle 任务结构体。\n- `update_other_load_avgs()`（SMP）：更新除 CFS 外其他调度类（RT、DL、IRQ）的负载平均值。\n- `effective_cpu_util()`（SMP）：计算 CPU 的有效利用率，用于频率调节（如 CPUFreq）。\n\n### 关键数据结构\n- 无独立定义的数据结构，主要操作 `struct task_struct` 和 `struct rq`（运行队列）。\n\n## 3. 关键实现\n\n### 优先级计算模型\n- **优先级映射**：\n  - 用户态 nice 值范围 `[-20, 19]` 映射到内核静态优先级 `[100, 139]`（通过 `NICE_TO_PRIO`）。\n  - 实时任务（RT/DL）使用 `[0, 99]` 的高优先级范围（`MAX_RT_PRIO = 100`）。\n  - `task_prio()` 返回值将内核优先级转换为用户可见格式：普通任务为 `[0,39]`，RT 任务为 `[-2,-100]`，DL 任务为 `-101`。\n- **有效优先级**：`effective_prio()` 区分“正常优先级”与“被提升的优先级”。若任务当前优先级为 RT/DL（即 `rt_or_dl_prio(p->prio)` 为真），则保留提升后的值；否则使用 `normal_prio`。\n\n### Nice 值修改安全机制\n- `set_user_nice()` 在修改 nice 值前：\n  1. 获取任务所在 CPU 的运行队列锁（`task_rq_lock`），防止并发调度。\n  2. 对 RT/DL 任务仅更新 `static_prio`（不影响调度行为）。\n  3. 对普通任务，先从运行队列中移除（若已入队或正在运行），更新 `static_prio` 和负载权重（`set_load_weight`），重新计算 `prio`，再重新入队。\n  4. 调用调度类的 `prio_changed` 回调，通知调度器优先级变更。\n\n### 权限控制\n- `can_nice()` 结合资源限制（`RLIMIT_NICE`）和特权（`CAP_SYS_NICE`）判断是否允许降低 nice 值（提高优先级）。\n- `nice_to_rlimit()` 将 nice 值 `[19,-20]` 转换为 rlimit 格式 `[1,40]` 以匹配 `RLIMIT_NICE` 的语义。\n\n### CPU 空闲判断\n- `idle_cpu()` 检查：\n  - 当前运行任务是否为 idle 任务。\n  - 运行队列中无其他可运行任务（`nr_running == 0`）。\n  - （SMP）无待处理的远程唤醒（`ttwu_pending == 0`）。\n- `available_idle_cpu()` 额外检查虚拟化场景下 CPU 是否被抢占（`vcpu_is_preempted`）。\n\n### 负载与利用率计算（SMP）\n- `update_other_load_avgs()` 周期性更新 RT、DL、IRQ 和硬件压力的负载平均值。\n- `effective_cpu_util()` 聚合 CFS、RT、DL、IRQ 的利用率，并考虑 DL 带宽预留，输出用于 CPU 频率调节的有效利用率。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/sched.h>`：核心调度数据结构和 API。\n  - `<linux/cpuset.h>`：CPU 亲和性相关（间接影响调度）。\n  - `\"sched.h\"`（本地）：调度器内部实现细节。\n  - `\"autogroup.h\"`：自动任务分组支持。\n- **调度类依赖**：\n  - 调用各调度类（CFS、RT、DL）的回调函数（如 `prio_changed`、`enqueue_task` 等）。\n- **安全模块**：调用 LSM 钩子 `security_task_setnice()`。\n- **架构相关**：\n  - `arch_scale_cpu_capacity()` / `arch_scale_hw_pressure()`：架构特定的 CPU 容量和硬件压力缩放。\n  - `__ARCH_WANT_SYS_NICE`：控制 `sys_nice` 是否编译进内核。\n\n## 5. 使用场景\n\n- **系统调用处理**：为 `nice(2)` 系统调用提供内核实现，允许用户进程动态调整自身优先级。\n- **调度器内部操作**：\n  - 在 `fork()`、`sched_setscheduler()` 等操作中计算任务优先级。\n  - 调度类在任务入队/出队时更新优先级和负载。\n- **资源监控与管理**：\n  - `/proc/[pid]/stat` 中的优先级字段通过 `task_prio()` 获取。\n  - 负载均衡器和 CPUFreq 驱动使用 `effective_cpu_util()` 获取 CPU 利用率。\n- **空闲检测**：\n  - 负载均衡、任务迁移、节能策略（如 cpuidle）依赖 `idle_cpu()` 和 `available_idle_cpu()` 判断 CPU 状态。\n- **权限控制**：在设置优先级时执行安全检查，防止非特权进程提升调度优先级。",
      "similarity": 0.5932570099830627,
      "chunks": [
        {
          "chunk_id": 8,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 1375,
          "end_line": 1517,
          "content": [
            "long sched_setaffinity(pid_t pid, const struct cpumask *in_mask)",
            "{",
            "\tstruct affinity_context ac;",
            "\tstruct cpumask *user_mask;",
            "\tint retval;",
            "",
            "\tCLASS(find_get_task, p)(pid);",
            "\tif (!p)",
            "\t\treturn -ESRCH;",
            "",
            "\tif (p->flags & PF_NO_SETAFFINITY)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (!check_same_owner(p)) {",
            "\t\tguard(rcu)();",
            "\t\tif (!ns_capable(__task_cred(p)->user_ns, CAP_SYS_NICE))",
            "\t\t\treturn -EPERM;",
            "\t}",
            "",
            "\tretval = security_task_setscheduler(p);",
            "\tif (retval)",
            "\t\treturn retval;",
            "",
            "\t/*",
            "\t * With non-SMP configs, user_cpus_ptr/user_mask isn't used and",
            "\t * alloc_user_cpus_ptr() returns NULL.",
            "\t */",
            "\tuser_mask = alloc_user_cpus_ptr(NUMA_NO_NODE);",
            "\tif (user_mask) {",
            "\t\tcpumask_copy(user_mask, in_mask);",
            "\t} else if (IS_ENABLED(CONFIG_SMP)) {",
            "\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\tac = (struct affinity_context){",
            "\t\t.new_mask  = in_mask,",
            "\t\t.user_mask = user_mask,",
            "\t\t.flags     = SCA_USER,",
            "\t};",
            "",
            "\tretval = __sched_setaffinity(p, &ac);",
            "\tkfree(ac.user_mask);",
            "",
            "\treturn retval;",
            "}",
            "static int get_user_cpu_mask(unsigned long __user *user_mask_ptr, unsigned len,",
            "\t\t\t     struct cpumask *new_mask)",
            "{",
            "\tif (len < cpumask_size())",
            "\t\tcpumask_clear(new_mask);",
            "\telse if (len > cpumask_size())",
            "\t\tlen = cpumask_size();",
            "",
            "\treturn copy_from_user(new_mask, user_mask_ptr, len) ? -EFAULT : 0;",
            "}",
            "long sched_getaffinity(pid_t pid, struct cpumask *mask)",
            "{",
            "\tstruct task_struct *p;",
            "\tint retval;",
            "",
            "\tguard(rcu)();",
            "\tp = find_process_by_pid(pid);",
            "\tif (!p)",
            "\t\treturn -ESRCH;",
            "",
            "\tretval = security_task_getscheduler(p);",
            "\tif (retval)",
            "\t\treturn retval;",
            "",
            "\tguard(raw_spinlock_irqsave)(&p->pi_lock);",
            "\tcpumask_and(mask, &p->cpus_mask, cpu_active_mask);",
            "",
            "\treturn 0;",
            "}",
            "static void do_sched_yield(void)",
            "{",
            "\tstruct rq_flags rf;",
            "\tstruct rq *rq;",
            "",
            "\trq = this_rq_lock_irq(&rf);",
            "",
            "\tschedstat_inc(rq->yld_count);",
            "\tcurrent->sched_class->yield_task(rq);",
            "",
            "\tpreempt_disable();",
            "\trq_unlock_irq(rq, &rf);",
            "\tsched_preempt_enable_no_resched();",
            "",
            "\tschedule();",
            "}",
            "void __sched yield(void)",
            "{",
            "\tset_current_state(TASK_RUNNING);",
            "\tdo_sched_yield();",
            "}",
            "int __sched yield_to(struct task_struct *p, bool preempt)",
            "{",
            "\tstruct task_struct *curr = current;",
            "\tstruct rq *rq, *p_rq;",
            "\tint yielded = 0;",
            "",
            "\tscoped_guard (irqsave) {",
            "\t\trq = this_rq();",
            "",
            "again:",
            "\t\tp_rq = task_rq(p);",
            "\t\t/*",
            "\t\t * If we're the only runnable task on the rq and target rq also",
            "\t\t * has only one task, there's absolutely no point in yielding.",
            "\t\t */",
            "\t\tif (rq->nr_running == 1 && p_rq->nr_running == 1)",
            "\t\t\treturn -ESRCH;",
            "",
            "\t\tguard(double_rq_lock)(rq, p_rq);",
            "\t\tif (task_rq(p) != p_rq)",
            "\t\t\tgoto again;",
            "",
            "\t\tif (!curr->sched_class->yield_to_task)",
            "\t\t\treturn 0;",
            "",
            "\t\tif (curr->sched_class != p->sched_class)",
            "\t\t\treturn 0;",
            "",
            "\t\tif (task_on_cpu(p_rq, p) || !task_is_running(p))",
            "\t\t\treturn 0;",
            "",
            "\t\tyielded = curr->sched_class->yield_to_task(rq, p);",
            "\t\tif (yielded) {",
            "\t\t\tschedstat_inc(rq->yld_count);",
            "\t\t\t/*",
            "\t\t\t * Make p's CPU reschedule; pick_next_entity",
            "\t\t\t * takes care of fairness.",
            "\t\t\t */",
            "\t\t\tif (preempt && rq != p_rq)",
            "\t\t\t\tresched_curr(p_rq);",
            "\t\t}",
            "\t}",
            "",
            "\tif (yielded)",
            "\t\tschedule();",
            "",
            "\treturn yielded;",
            "}"
          ],
          "function_name": "sched_setaffinity, get_user_cpu_mask, sched_getaffinity, do_sched_yield, yield, yield_to",
          "description": "实现CPU亲和性设置/获取及调度让步功能。sched_setaffinity设置进程CPU亲和性掩码并进行权限检查，sched_getaffinity获取当前亲和性掩码。yield/yield_to实现调度器让步操作，do_sched_yield触发当前进程主动让出CPU。",
          "similarity": 0.5317782163619995
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 889,
          "end_line": 1002,
          "content": [
            "static int _sched_setscheduler(struct task_struct *p, int policy,",
            "\t\t\t       const struct sched_param *param, bool check)",
            "{",
            "\tstruct sched_attr attr = {",
            "\t\t.sched_policy   = policy,",
            "\t\t.sched_priority = param->sched_priority,",
            "\t\t.sched_nice\t= PRIO_TO_NICE(p->static_prio),",
            "\t};",
            "",
            "\tif (p->se.custom_slice)",
            "\t\tattr.sched_runtime = p->se.slice;",
            "",
            "\t/* Fixup the legacy SCHED_RESET_ON_FORK hack. */",
            "\tif ((policy != SETPARAM_POLICY) && (policy & SCHED_RESET_ON_FORK)) {",
            "\t\tattr.sched_flags |= SCHED_FLAG_RESET_ON_FORK;",
            "\t\tpolicy &= ~SCHED_RESET_ON_FORK;",
            "\t\tattr.sched_policy = policy;",
            "\t}",
            "",
            "\treturn __sched_setscheduler(p, &attr, check, true);",
            "}",
            "int sched_setscheduler(struct task_struct *p, int policy,",
            "\t\t       const struct sched_param *param)",
            "{",
            "\treturn _sched_setscheduler(p, policy, param, true);",
            "}",
            "int sched_setattr(struct task_struct *p, const struct sched_attr *attr)",
            "{",
            "\treturn __sched_setscheduler(p, attr, true, true);",
            "}",
            "int sched_setattr_nocheck(struct task_struct *p, const struct sched_attr *attr)",
            "{",
            "\treturn __sched_setscheduler(p, attr, false, true);",
            "}",
            "int sched_setscheduler_nocheck(struct task_struct *p, int policy,",
            "\t\t\t       const struct sched_param *param)",
            "{",
            "\treturn _sched_setscheduler(p, policy, param, false);",
            "}",
            "void sched_set_fifo(struct task_struct *p)",
            "{",
            "\tstruct sched_param sp = { .sched_priority = MAX_RT_PRIO / 2 };",
            "\tWARN_ON_ONCE(sched_setscheduler_nocheck(p, SCHED_FIFO, &sp) != 0);",
            "}",
            "void sched_set_fifo_low(struct task_struct *p)",
            "{",
            "\tstruct sched_param sp = { .sched_priority = 1 };",
            "\tWARN_ON_ONCE(sched_setscheduler_nocheck(p, SCHED_FIFO, &sp) != 0);",
            "}",
            "void sched_set_normal(struct task_struct *p, int nice)",
            "{",
            "\tstruct sched_attr attr = {",
            "\t\t.sched_policy = SCHED_NORMAL,",
            "\t\t.sched_nice = nice,",
            "\t};",
            "\tWARN_ON_ONCE(sched_setattr_nocheck(p, &attr) != 0);",
            "}",
            "static int",
            "do_sched_setscheduler(pid_t pid, int policy, struct sched_param __user *param)",
            "{",
            "\tstruct sched_param lparam;",
            "",
            "\tif (!param || pid < 0)",
            "\t\treturn -EINVAL;",
            "\tif (copy_from_user(&lparam, param, sizeof(struct sched_param)))",
            "\t\treturn -EFAULT;",
            "",
            "\tCLASS(find_get_task, p)(pid);",
            "\tif (!p)",
            "\t\treturn -ESRCH;",
            "",
            "\treturn sched_setscheduler(p, policy, &lparam);",
            "}",
            "static int sched_copy_attr(struct sched_attr __user *uattr, struct sched_attr *attr)",
            "{",
            "\tu32 size;",
            "\tint ret;",
            "",
            "\t/* Zero the full structure, so that a short copy will be nice: */",
            "\tmemset(attr, 0, sizeof(*attr));",
            "",
            "\tret = get_user(size, &uattr->size);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\t/* ABI compatibility quirk: */",
            "\tif (!size)",
            "\t\tsize = SCHED_ATTR_SIZE_VER0;",
            "\tif (size < SCHED_ATTR_SIZE_VER0 || size > PAGE_SIZE)",
            "\t\tgoto err_size;",
            "",
            "\tret = copy_struct_from_user(attr, sizeof(*attr), uattr, size);",
            "\tif (ret) {",
            "\t\tif (ret == -E2BIG)",
            "\t\t\tgoto err_size;",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tif ((attr->sched_flags & SCHED_FLAG_UTIL_CLAMP) &&",
            "\t    size < SCHED_ATTR_SIZE_VER1)",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * XXX: Do we want to be lenient like existing syscalls; or do we want",
            "\t * to be strict and return an error on out-of-bounds values?",
            "\t */",
            "\tattr->sched_nice = clamp(attr->sched_nice, MIN_NICE, MAX_NICE);",
            "",
            "\treturn 0;",
            "",
            "err_size:",
            "\tput_user(sizeof(*attr), &uattr->size);",
            "\treturn -E2BIG;",
            "}"
          ],
          "function_name": "_sched_setscheduler, sched_setscheduler, sched_setattr, sched_setattr_nocheck, sched_setscheduler_nocheck, sched_set_fifo, sched_set_fifo_low, sched_set_normal, do_sched_setscheduler, sched_copy_attr",
          "description": "提供多种调度参数设置接口，包括_sched_setscheduler及其变种函数。通过封装将用户参数转化为sched_attr结构，调用底层__sched_setscheduler实现。包含针对特定调度策略（FIFO/NORMAL）的专用接口，以及参数复制和校验逻辑。",
          "similarity": 0.5184146165847778
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 646,
          "end_line": 887,
          "content": [
            "int __sched_setscheduler(struct task_struct *p,",
            "\t\t\t const struct sched_attr *attr,",
            "\t\t\t bool user, bool pi)",
            "{",
            "\tint oldpolicy = -1, policy = attr->sched_policy;",
            "\tint retval, oldprio, newprio, queued, running;",
            "\tconst struct sched_class *prev_class, *next_class;",
            "\tstruct balance_callback *head;",
            "\tstruct rq_flags rf;",
            "\tint reset_on_fork;",
            "\tint queue_flags = DEQUEUE_SAVE | DEQUEUE_MOVE | DEQUEUE_NOCLOCK;",
            "\tstruct rq *rq;",
            "\tbool cpuset_locked = false;",
            "",
            "\t/* The pi code expects interrupts enabled */",
            "\tBUG_ON(pi && in_interrupt());",
            "recheck:",
            "\t/* Double check policy once rq lock held: */",
            "\tif (policy < 0) {",
            "\t\treset_on_fork = p->sched_reset_on_fork;",
            "\t\tpolicy = oldpolicy = p->policy;",
            "\t} else {",
            "\t\treset_on_fork = !!(attr->sched_flags & SCHED_FLAG_RESET_ON_FORK);",
            "",
            "\t\tif (!valid_policy(policy))",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tif (attr->sched_flags & ~(SCHED_FLAG_ALL | SCHED_FLAG_SUGOV))",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * Valid priorities for SCHED_FIFO and SCHED_RR are",
            "\t * 1..MAX_RT_PRIO-1, valid priority for SCHED_NORMAL,",
            "\t * SCHED_BATCH and SCHED_IDLE is 0.",
            "\t */",
            "\tif (attr->sched_priority > MAX_RT_PRIO-1)",
            "\t\treturn -EINVAL;",
            "\tif ((dl_policy(policy) && !__checkparam_dl(attr)) ||",
            "\t    (rt_policy(policy) != (attr->sched_priority != 0)))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (user) {",
            "\t\tretval = user_check_sched_setscheduler(p, attr, policy, reset_on_fork);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "",
            "\t\tif (attr->sched_flags & SCHED_FLAG_SUGOV)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\tretval = security_task_setscheduler(p);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "\t}",
            "",
            "\t/* Update task specific \"requested\" clamps */",
            "\tif (attr->sched_flags & SCHED_FLAG_UTIL_CLAMP) {",
            "\t\tretval = uclamp_validate(p, attr);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "\t}",
            "",
            "\t/*",
            "\t * SCHED_DEADLINE bandwidth accounting relies on stable cpusets",
            "\t * information.",
            "\t */",
            "\tif (dl_policy(policy) || dl_policy(p->policy)) {",
            "\t\tcpuset_locked = true;",
            "\t\tcpuset_lock();",
            "\t}",
            "",
            "\t/*",
            "\t * Make sure no PI-waiters arrive (or leave) while we are",
            "\t * changing the priority of the task:",
            "\t *",
            "\t * To be able to change p->policy safely, the appropriate",
            "\t * runqueue lock must be held.",
            "\t */",
            "\trq = task_rq_lock(p, &rf);",
            "\tupdate_rq_clock(rq);",
            "",
            "\t/*",
            "\t * Changing the policy of the stop threads its a very bad idea:",
            "\t */",
            "\tif (p == rq->stop) {",
            "\t\tretval = -EINVAL;",
            "\t\tgoto unlock;",
            "\t}",
            "",
            "\tretval = scx_check_setscheduler(p, policy);",
            "\tif (retval)",
            "\t\tgoto unlock;",
            "",
            "\t/*",
            "\t * If not changing anything there's no need to proceed further,",
            "\t * but store a possible modification of reset_on_fork.",
            "\t */",
            "\tif (unlikely(policy == p->policy)) {",
            "\t\tif (fair_policy(policy) &&",
            "\t\t    (attr->sched_nice != task_nice(p) ||",
            "\t\t     (attr->sched_runtime != p->se.slice)))",
            "\t\t\tgoto change;",
            "\t\tif (rt_policy(policy) && attr->sched_priority != p->rt_priority)",
            "\t\t\tgoto change;",
            "\t\tif (dl_policy(policy) && dl_param_changed(p, attr))",
            "\t\t\tgoto change;",
            "\t\tif (attr->sched_flags & SCHED_FLAG_UTIL_CLAMP)",
            "\t\t\tgoto change;",
            "",
            "\t\tp->sched_reset_on_fork = reset_on_fork;",
            "\t\tretval = 0;",
            "\t\tgoto unlock;",
            "\t}",
            "change:",
            "",
            "\tif (user) {",
            "#ifdef CONFIG_RT_GROUP_SCHED",
            "\t\t/*",
            "\t\t * Do not allow realtime tasks into groups that have no runtime",
            "\t\t * assigned.",
            "\t\t */",
            "\t\tif (rt_bandwidth_enabled() && rt_policy(policy) &&",
            "\t\t\t\ttask_group(p)->rt_bandwidth.rt_runtime == 0 &&",
            "\t\t\t\t!task_group_is_autogroup(task_group(p))) {",
            "\t\t\tretval = -EPERM;",
            "\t\t\tgoto unlock;",
            "\t\t}",
            "#endif",
            "#ifdef CONFIG_SMP",
            "\t\tif (dl_bandwidth_enabled() && dl_policy(policy) &&",
            "\t\t\t\t!(attr->sched_flags & SCHED_FLAG_SUGOV)) {",
            "\t\t\tcpumask_t *span = rq->rd->span;",
            "",
            "\t\t\t/*",
            "\t\t\t * Don't allow tasks with an affinity mask smaller than",
            "\t\t\t * the entire root_domain to become SCHED_DEADLINE. We",
            "\t\t\t * will also fail if there's no bandwidth available.",
            "\t\t\t */",
            "\t\t\tif (!cpumask_subset(span, p->cpus_ptr) ||",
            "\t\t\t    rq->rd->dl_bw.bw == 0) {",
            "\t\t\t\tretval = -EPERM;",
            "\t\t\t\tgoto unlock;",
            "\t\t\t}",
            "\t\t}",
            "#endif",
            "\t}",
            "",
            "\t/* Re-check policy now with rq lock held: */",
            "\tif (unlikely(oldpolicy != -1 && oldpolicy != p->policy)) {",
            "\t\tpolicy = oldpolicy = -1;",
            "\t\ttask_rq_unlock(rq, p, &rf);",
            "\t\tif (cpuset_locked)",
            "\t\t\tcpuset_unlock();",
            "\t\tgoto recheck;",
            "\t}",
            "",
            "\t/*",
            "\t * If setscheduling to SCHED_DEADLINE (or changing the parameters",
            "\t * of a SCHED_DEADLINE task) we need to check if enough bandwidth",
            "\t * is available.",
            "\t */",
            "\tif ((dl_policy(policy) || dl_task(p)) && sched_dl_overflow(p, policy, attr)) {",
            "\t\tretval = -EBUSY;",
            "\t\tgoto unlock;",
            "\t}",
            "",
            "\tp->sched_reset_on_fork = reset_on_fork;",
            "\toldprio = p->prio;",
            "",
            "\tnewprio = __normal_prio(policy, attr->sched_priority, attr->sched_nice);",
            "\tif (pi) {",
            "\t\t/*",
            "\t\t * Take priority boosted tasks into account. If the new",
            "\t\t * effective priority is unchanged, we just store the new",
            "\t\t * normal parameters and do not touch the scheduler class and",
            "\t\t * the runqueue. This will be done when the task deboost",
            "\t\t * itself.",
            "\t\t */",
            "\t\tnewprio = rt_effective_prio(p, newprio);",
            "\t\tif (newprio == oldprio)",
            "\t\t\tqueue_flags &= ~DEQUEUE_MOVE;",
            "\t}",
            "",
            "\tprev_class = p->sched_class;",
            "\tnext_class = __setscheduler_class(policy, newprio);",
            "",
            "\tif (prev_class != next_class && p->se.sched_delayed)",
            "\t\tdequeue_task(rq, p, DEQUEUE_SLEEP | DEQUEUE_DELAYED | DEQUEUE_NOCLOCK);",
            "",
            "\tqueued = task_on_rq_queued(p);",
            "\trunning = task_current(rq, p);",
            "\tif (queued)",
            "\t\tdequeue_task(rq, p, queue_flags);",
            "\tif (running)",
            "\t\tput_prev_task(rq, p);",
            "",
            "\tif (!(attr->sched_flags & SCHED_FLAG_KEEP_PARAMS)) {",
            "\t\t__setscheduler_params(p, attr);",
            "\t\tp->sched_class = next_class;",
            "\t\tp->prio = newprio;",
            "\t}",
            "\t__setscheduler_uclamp(p, attr);",
            "\tcheck_class_changing(rq, p, prev_class);",
            "",
            "\tif (queued) {",
            "\t\t/*",
            "\t\t * We enqueue to tail when the priority of a task is",
            "\t\t * increased (user space view).",
            "\t\t */",
            "\t\tif (oldprio < p->prio)",
            "\t\t\tqueue_flags |= ENQUEUE_HEAD;",
            "",
            "\t\tenqueue_task(rq, p, queue_flags);",
            "\t}",
            "\tif (running)",
            "\t\tset_next_task(rq, p);",
            "",
            "\tcheck_class_changed(rq, p, prev_class, oldprio);",
            "",
            "\t/* Avoid rq from going away on us: */",
            "\tpreempt_disable();",
            "\thead = splice_balance_callbacks(rq);",
            "\ttask_rq_unlock(rq, p, &rf);",
            "",
            "\tif (pi) {",
            "\t\tif (cpuset_locked)",
            "\t\t\tcpuset_unlock();",
            "\t\trt_mutex_adjust_pi(p);",
            "\t}",
            "",
            "\t/* Run balance callbacks after we've adjusted the PI chain: */",
            "\tbalance_callbacks(rq, head);",
            "\tpreempt_enable();",
            "",
            "\treturn 0;",
            "",
            "unlock:",
            "\ttask_rq_unlock(rq, p, &rf);",
            "\tif (cpuset_locked)",
            "\t\tcpuset_unlock();",
            "\treturn retval;",
            "}"
          ],
          "function_name": "__sched_setscheduler",
          "description": "实现__sched_setscheduler函数，用于修改任务的调度策略及参数。该函数验证新策略有效性，更新任务优先级，切换调度类并调整运行队列状态，处理PI互斥锁及负载均衡回调。核心功能是安全地变更任务调度参数并维护调度器一致性。",
          "similarity": 0.5131968259811401
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 1065,
          "end_line": 1186,
          "content": [
            "static void get_params(struct task_struct *p, struct sched_attr *attr)",
            "{",
            "\tif (task_has_dl_policy(p)) {",
            "\t\t__getparam_dl(p, attr);",
            "\t} else if (task_has_rt_policy(p)) {",
            "\t\tattr->sched_priority = p->rt_priority;",
            "\t} else {",
            "\t\tattr->sched_nice = task_nice(p);",
            "\t\tattr->sched_runtime = p->se.slice;",
            "\t}",
            "}",
            "static int",
            "sched_attr_copy_to_user(struct sched_attr __user *uattr,",
            "\t\t\tstruct sched_attr *kattr,",
            "\t\t\tunsigned int usize)",
            "{",
            "\tunsigned int ksize = sizeof(*kattr);",
            "",
            "\tif (!access_ok(uattr, usize))",
            "\t\treturn -EFAULT;",
            "",
            "\t/*",
            "\t * sched_getattr() ABI forwards and backwards compatibility:",
            "\t *",
            "\t * If usize == ksize then we just copy everything to user-space and all is good.",
            "\t *",
            "\t * If usize < ksize then we only copy as much as user-space has space for,",
            "\t * this keeps ABI compatibility as well. We skip the rest.",
            "\t *",
            "\t * If usize > ksize then user-space is using a newer version of the ABI,",
            "\t * which part the kernel doesn't know about. Just ignore it - tooling can",
            "\t * detect the kernel's knowledge of attributes from the attr->size value",
            "\t * which is set to ksize in this case.",
            "\t */",
            "\tkattr->size = min(usize, ksize);",
            "",
            "\tif (copy_to_user(uattr, kattr, kattr->size))",
            "\t\treturn -EFAULT;",
            "",
            "\treturn 0;",
            "}",
            "int dl_task_check_affinity(struct task_struct *p, const struct cpumask *mask)",
            "{",
            "\t/*",
            "\t * If the task isn't a deadline task or admission control is",
            "\t * disabled then we don't care about affinity changes.",
            "\t */",
            "\tif (!task_has_dl_policy(p) || !dl_bandwidth_enabled())",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * Since bandwidth control happens on root_domain basis,",
            "\t * if admission test is enabled, we only admit -deadline",
            "\t * tasks allowed to run on all the CPUs in the task's",
            "\t * root_domain.",
            "\t */",
            "\tguard(rcu)();",
            "\tif (!cpumask_subset(task_rq(p)->rd->span, mask))",
            "\t\treturn -EBUSY;",
            "",
            "\treturn 0;",
            "}",
            "int __sched_setaffinity(struct task_struct *p, struct affinity_context *ctx)",
            "{",
            "\tint retval;",
            "\tcpumask_var_t cpus_allowed, new_mask;",
            "",
            "\tif (!alloc_cpumask_var(&cpus_allowed, GFP_KERNEL))",
            "\t\treturn -ENOMEM;",
            "",
            "\tif (!alloc_cpumask_var(&new_mask, GFP_KERNEL)) {",
            "\t\tretval = -ENOMEM;",
            "\t\tgoto out_free_cpus_allowed;",
            "\t}",
            "",
            "\tcpuset_cpus_allowed(p, cpus_allowed);",
            "\tcpumask_and(new_mask, ctx->new_mask, cpus_allowed);",
            "",
            "\tctx->new_mask = new_mask;",
            "\tctx->flags |= SCA_CHECK;",
            "",
            "\tretval = dl_task_check_affinity(p, new_mask);",
            "\tif (retval)",
            "\t\tgoto out_free_new_mask;",
            "",
            "\tretval = __set_cpus_allowed_ptr(p, ctx);",
            "\tif (retval)",
            "\t\tgoto out_free_new_mask;",
            "",
            "\tcpuset_cpus_allowed(p, cpus_allowed);",
            "\tif (!cpumask_subset(new_mask, cpus_allowed)) {",
            "\t\t/*",
            "\t\t * We must have raced with a concurrent cpuset update.",
            "\t\t * Just reset the cpumask to the cpuset's cpus_allowed.",
            "\t\t */",
            "\t\tcpumask_copy(new_mask, cpus_allowed);",
            "",
            "\t\t/*",
            "\t\t * If SCA_USER is set, a 2nd call to __set_cpus_allowed_ptr()",
            "\t\t * will restore the previous user_cpus_ptr value.",
            "\t\t *",
            "\t\t * In the unlikely event a previous user_cpus_ptr exists,",
            "\t\t * we need to further restrict the mask to what is allowed",
            "\t\t * by that old user_cpus_ptr.",
            "\t\t */",
            "\t\tif (unlikely((ctx->flags & SCA_USER) && ctx->user_mask)) {",
            "\t\t\tbool empty = !cpumask_and(new_mask, new_mask,",
            "\t\t\t\t\t\t  ctx->user_mask);",
            "",
            "\t\t\tif (empty)",
            "\t\t\t\tcpumask_copy(new_mask, cpus_allowed);",
            "\t\t}",
            "\t\t__set_cpus_allowed_ptr(p, ctx);",
            "\t\tretval = -EINVAL;",
            "\t}",
            "",
            "out_free_new_mask:",
            "\tfree_cpumask_var(new_mask);",
            "out_free_cpus_allowed:",
            "\tfree_cpumask_var(cpus_allowed);",
            "\treturn retval;",
            "}"
          ],
          "function_name": "get_params, sched_attr_copy_to_user, dl_task_check_affinity, __sched_setaffinity",
          "description": "实现调度参数获取与亲和性检查功能。get_params提取任务调度参数，sched_attr_copy_to_user完成内核参数向用户空间复制。dl_task_check_affinity验证截止时间任务的CPU亲和性有效性，__sched_setaffinity处理任务CPU亲和性设置及约束检查。",
          "similarity": 0.4966122806072235
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 19,
          "end_line": 130,
          "content": [
            "static inline int __normal_prio(int policy, int rt_prio, int nice)",
            "{",
            "\tint prio;",
            "",
            "\tif (dl_policy(policy))",
            "\t\tprio = MAX_DL_PRIO - 1;",
            "\telse if (rt_policy(policy))",
            "\t\tprio = MAX_RT_PRIO - 1 - rt_prio;",
            "\telse",
            "\t\tprio = NICE_TO_PRIO(nice);",
            "",
            "\treturn prio;",
            "}",
            "static inline int normal_prio(struct task_struct *p)",
            "{",
            "\treturn __normal_prio(p->policy, p->rt_priority, PRIO_TO_NICE(p->static_prio));",
            "}",
            "static int effective_prio(struct task_struct *p)",
            "{",
            "\tp->normal_prio = normal_prio(p);",
            "\t/*",
            "\t * If we are RT tasks or we were boosted to RT priority,",
            "\t * keep the priority unchanged. Otherwise, update priority",
            "\t * to the normal priority:",
            "\t */",
            "\tif (!rt_or_dl_prio(p->prio))",
            "\t\treturn p->normal_prio;",
            "\treturn p->prio;",
            "}",
            "void set_user_nice(struct task_struct *p, long nice)",
            "{",
            "\tbool queued, running;",
            "\tstruct rq *rq;",
            "\tint old_prio;",
            "",
            "\tif (task_nice(p) == nice || nice < MIN_NICE || nice > MAX_NICE)",
            "\t\treturn;",
            "\t/*",
            "\t * We have to be careful, if called from sys_setpriority(),",
            "\t * the task might be in the middle of scheduling on another CPU.",
            "\t */",
            "\tCLASS(task_rq_lock, rq_guard)(p);",
            "\trq = rq_guard.rq;",
            "",
            "\tupdate_rq_clock(rq);",
            "",
            "\t/*",
            "\t * The RT priorities are set via sched_setscheduler(), but we still",
            "\t * allow the 'normal' nice value to be set - but as expected",
            "\t * it won't have any effect on scheduling until the task is",
            "\t * SCHED_DEADLINE, SCHED_FIFO or SCHED_RR:",
            "\t */",
            "\tif (task_has_dl_policy(p) || task_has_rt_policy(p)) {",
            "\t\tp->static_prio = NICE_TO_PRIO(nice);",
            "\t\treturn;",
            "\t}",
            "",
            "\tqueued = task_on_rq_queued(p);",
            "\trunning = task_current(rq, p);",
            "\tif (queued)",
            "\t\tdequeue_task(rq, p, DEQUEUE_SAVE | DEQUEUE_NOCLOCK);",
            "\tif (running)",
            "\t\tput_prev_task(rq, p);",
            "",
            "\tp->static_prio = NICE_TO_PRIO(nice);",
            "\tset_load_weight(p, true);",
            "\told_prio = p->prio;",
            "\tp->prio = effective_prio(p);",
            "",
            "\tif (queued)",
            "\t\tenqueue_task(rq, p, ENQUEUE_RESTORE | ENQUEUE_NOCLOCK);",
            "\tif (running)",
            "\t\tset_next_task(rq, p);",
            "",
            "\t/*",
            "\t * If the task increased its priority or is running and",
            "\t * lowered its priority, then reschedule its CPU:",
            "\t */",
            "\tp->sched_class->prio_changed(rq, p, old_prio);",
            "}",
            "static bool is_nice_reduction(const struct task_struct *p, const int nice)",
            "{",
            "\t/* Convert nice value [19,-20] to rlimit style value [1,40]: */",
            "\tint nice_rlim = nice_to_rlimit(nice);",
            "",
            "\treturn (nice_rlim <= task_rlimit(p, RLIMIT_NICE));",
            "}",
            "int can_nice(const struct task_struct *p, const int nice)",
            "{",
            "\treturn is_nice_reduction(p, nice) || capable(CAP_SYS_NICE);",
            "}",
            "int task_prio(const struct task_struct *p)",
            "{",
            "\treturn p->prio - MAX_RT_PRIO;",
            "}",
            "int idle_cpu(int cpu)",
            "{",
            "\tstruct rq *rq = cpu_rq(cpu);",
            "",
            "\tif (rq->curr != rq->idle)",
            "\t\treturn 0;",
            "",
            "\tif (rq->nr_running)",
            "\t\treturn 0;",
            "",
            "#ifdef CONFIG_SMP",
            "\tif (rq->ttwu_pending)",
            "\t\treturn 0;",
            "#endif",
            "",
            "\treturn 1;",
            "}"
          ],
          "function_name": "__normal_prio, normal_prio, effective_prio, set_user_nice, is_nice_reduction, can_nice, task_prio, idle_cpu",
          "description": "实现优先级计算与调整逻辑，包含正常优先级计算、有效优先级判定、用户nice值修改、优先级变化检测及实时任务优先级处理等功能",
          "similarity": 0.48702818155288696
        }
      ]
    },
    {
      "source_file": "kernel/static_call_inline.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:29:06\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `static_call_inline.c`\n\n---\n\n# static_call_inline.c 技术文档\n\n## 1. 文件概述\n\n`static_call_inline.c` 是 Linux 内核中实现 **静态调用（Static Call）** 机制的核心文件之一。静态调用是一种运行时可动态更新的函数调用优化技术，它在编译时将函数调用点内联为对跳板（trampoline）的直接跳转，而在运行时可通过 `__static_call_update()` 动态修改所有调用点，使其跳转到新的目标函数，从而避免传统函数指针调用的间接开销。该机制常用于性能敏感路径（如调度、RCU、tracepoint 等），同时支持模块热插拔和初始化阶段的特殊处理。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `static_call_force_reinit(void)`  \n  强制重新初始化静态调用机制，用于调试或特殊场景，必须在 `early_initcall()` 之前调用。\n\n- `__static_call_update(struct static_call_key *key, void *tramp, void *func)`  \n  核心更新函数：将指定 `key` 对应的所有静态调用点更新为调用 `func`，并更新跳板 `tramp`。支持内核和模块中的调用点。\n\n- `__static_call_init(struct module *mod, struct static_call_site *start, struct static_call_site *stop)`  \n  初始化静态调用站点，对站点按 `key` 排序，并建立 `key` 到站点的映射关系，同时执行首次 `arch_static_call_transform`。\n\n- `__static_call_text_reserved(...)`  \n  检查指定代码区间是否与活跃的静态调用站点冲突，用于内存热插拔或代码修改前的安全校验。\n\n### 主要数据结构\n\n- `struct static_call_site`  \n  描述一个静态调用点的位置（`addr`）和关联的 `key`（带标志位）。\n\n- `struct static_call_key`  \n  静态调用的“键”，用于将多个调用点分组。包含当前函数指针 `func` 和类型/模块信息。\n\n- `struct static_call_mod`  \n  用于模块场景下，将模块与该模块中属于某 `key` 的调用点列表关联。\n\n- 全局符号：\n  - `__start_static_call_sites[]` / `__stop_static_call_sites[]`：内核镜像中所有静态调用点的链接器生成数组。\n  - `__start_static_call_tramp_key[]` / `__stop_static_call_tramp_key[]`：跳板与 key 的映射。\n\n### 辅助函数与宏\n\n- `static_call_addr(site)`：计算调用点的实际地址（处理重定位）。\n- `static_call_key(site)`：从站点中提取 `static_call_key*`（忽略标志位）。\n- `static_call_is_init(site)` / `static_call_is_tail(site)`：检查站点是否位于 `__init` 段或是否为尾调用。\n- `static_call_sort_entries()`：对站点按 `key` 排序，便于批量处理。\n- `static_call_key_has_mods()` / `static_call_key_sites()`：判断 key 是否关联模块或直接站点。\n\n## 3. 关键实现\n\n### 地址重定位处理\n由于静态调用站点在编译时使用相对地址存储，`static_call_addr()` 和 `__static_call_key()` 通过 `(long)field + (long)&field` 的方式计算出运行时绝对地址，这是处理位置无关代码（PIC）和内核重定位的关键技巧。\n\n### 站点组织与模块支持\n- **内核（vmlinux）场景**：为节省内存和避免早期内存分配，将首个站点指针直接编码到 `key->type` 的低有效位中（通过 `| 1` 标记）。\n- **模块场景**：使用 `static_call_mod` 链表管理不同模块中属于同一 `key` 的站点，支持模块加载/卸载时的动态注册。\n\n### 初始化与更新流程\n1. **初始化**（`__static_call_init`）：\n   - 对站点按 `key` 排序。\n   - 标记位于 `__init` 段的站点（后续更新可跳过）。\n   - 建立 `key` 到站点的映射。\n   - 调用架构相关 `arch_static_call_transform` 执行首次转换（通常设为跳板）。\n\n2. **更新**（`__static_call_update`）：\n   - 更新 `key->func`。\n   - 更新跳板 `tramp` 指向新函数。\n   - 遍历所有关联站点（包括模块），调用 `arch_static_call_transform` 修改调用点指令（如 x86 的 `jmp` 目标）。\n   - 跳过 `__init` 段中已初始化的站点（因不会被执行）。\n\n### 安全与并发控制\n- 使用 `cpus_read_lock()` 防止 CPU 热插拔期间的并发问题。\n- 使用 `static_call_mutex` 保护 `key` 和站点数据结构的修改。\n- 通过 `kernel_text_address()` 验证调用点是否在可执行内核文本段，避免修改无效地址。\n\n## 4. 依赖关系\n\n- **架构依赖**：依赖 `asm/sections.h` 和 `arch_static_call_transform()`（由各架构实现，如 x86、ARM64）。\n- **内核子系统**：\n  - `linux/module.h`：模块加载/卸载时的静态调用站点管理。\n  - `linux/cpu.h` / `linux/smp.h`：CPU 热插拔和并发控制。\n  - `linux/sort.h`：站点排序。\n  - `linux/slab.h`：模块场景下的动态内存分配。\n- **链接器脚本**：依赖链接器生成的 `__start/stop_static_call_sites` 等符号，这些在 `vmlinux.lds` 中定义。\n\n## 5. 使用场景\n\n- **内核核心优化**：在调度器、RCU、中断处理等高频路径中替代函数指针，减少间接调用开销。\n- **动态追踪（ftrace）**：作为 tracepoint 或 kprobe 的底层机制，实现零开销探针。\n- **模块热插拔**：模块加载时注册其静态调用站点，卸载时自动清理，确保调用点始终有效。\n- **初始化优化**：`__init` 段的调用点在初始化完成后可被安全忽略，减少运行时开销。\n- **安全代码修改**：在 livepatch 或内核热补丁中，安全地替换函数实现而不影响运行中的调用。",
      "similarity": 0.5929683446884155,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 220,
          "end_line": 340,
          "content": [
            "static int __static_call_init(struct module *mod,",
            "\t\t\t      struct static_call_site *start,",
            "\t\t\t      struct static_call_site *stop)",
            "{",
            "\tstruct static_call_site *site;",
            "\tstruct static_call_key *key, *prev_key = NULL;",
            "\tstruct static_call_mod *site_mod;",
            "",
            "\tif (start == stop)",
            "\t\treturn 0;",
            "",
            "\tstatic_call_sort_entries(start, stop);",
            "",
            "\tfor (site = start; site < stop; site++) {",
            "\t\tvoid *site_addr = static_call_addr(site);",
            "",
            "\t\tif ((mod && within_module_init((unsigned long)site_addr, mod)) ||",
            "\t\t    (!mod && init_section_contains(site_addr, 1)))",
            "\t\t\tstatic_call_set_init(site);",
            "",
            "\t\tkey = static_call_key(site);",
            "\t\tif (key != prev_key) {",
            "\t\t\tprev_key = key;",
            "",
            "\t\t\t/*",
            "\t\t\t * For vmlinux (!mod) avoid the allocation by storing",
            "\t\t\t * the sites pointer in the key itself. Also see",
            "\t\t\t * __static_call_update()'s @first.",
            "\t\t\t *",
            "\t\t\t * This allows architectures (eg. x86) to call",
            "\t\t\t * static_call_init() before memory allocation works.",
            "\t\t\t */",
            "\t\t\tif (!mod) {",
            "\t\t\t\tkey->sites = site;",
            "\t\t\t\tkey->type |= 1;",
            "\t\t\t\tgoto do_transform;",
            "\t\t\t}",
            "",
            "\t\t\tsite_mod = kzalloc(sizeof(*site_mod), GFP_KERNEL);",
            "\t\t\tif (!site_mod)",
            "\t\t\t\treturn -ENOMEM;",
            "",
            "\t\t\t/*",
            "\t\t\t * When the key has a direct sites pointer, extract",
            "\t\t\t * that into an explicit struct static_call_mod, so we",
            "\t\t\t * can have a list of modules.",
            "\t\t\t */",
            "\t\t\tif (static_call_key_sites(key)) {",
            "\t\t\t\tsite_mod->mod = NULL;",
            "\t\t\t\tsite_mod->next = NULL;",
            "\t\t\t\tsite_mod->sites = static_call_key_sites(key);",
            "",
            "\t\t\t\tkey->mods = site_mod;",
            "",
            "\t\t\t\tsite_mod = kzalloc(sizeof(*site_mod), GFP_KERNEL);",
            "\t\t\t\tif (!site_mod)",
            "\t\t\t\t\treturn -ENOMEM;",
            "\t\t\t}",
            "",
            "\t\t\tsite_mod->mod = mod;",
            "\t\t\tsite_mod->sites = site;",
            "\t\t\tsite_mod->next = static_call_key_next(key);",
            "\t\t\tkey->mods = site_mod;",
            "\t\t}",
            "",
            "do_transform:",
            "\t\tarch_static_call_transform(site_addr, NULL, key->func,",
            "\t\t\t\tstatic_call_is_tail(site));",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int addr_conflict(struct static_call_site *site, void *start, void *end)",
            "{",
            "\tunsigned long addr = (unsigned long)static_call_addr(site);",
            "",
            "\tif (addr <= (unsigned long)end &&",
            "\t    addr + CALL_INSN_SIZE > (unsigned long)start)",
            "\t\treturn 1;",
            "",
            "\treturn 0;",
            "}",
            "static int __static_call_text_reserved(struct static_call_site *iter_start,",
            "\t\t\t\t       struct static_call_site *iter_stop,",
            "\t\t\t\t       void *start, void *end, bool init)",
            "{",
            "\tstruct static_call_site *iter = iter_start;",
            "",
            "\twhile (iter < iter_stop) {",
            "\t\tif (init || !static_call_is_init(iter)) {",
            "\t\t\tif (addr_conflict(iter, start, end))",
            "\t\t\t\treturn 1;",
            "\t\t}",
            "\t\titer++;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int __static_call_mod_text_reserved(void *start, void *end)",
            "{",
            "\tstruct module *mod;",
            "\tint ret;",
            "",
            "\tpreempt_disable();",
            "\tmod = __module_text_address((unsigned long)start);",
            "\tWARN_ON_ONCE(__module_text_address((unsigned long)end) != mod);",
            "\tif (!try_module_get(mod))",
            "\t\tmod = NULL;",
            "\tpreempt_enable();",
            "",
            "\tif (!mod)",
            "\t\treturn 0;",
            "",
            "\tret = __static_call_text_reserved(mod->static_call_sites,",
            "\t\t\tmod->static_call_sites + mod->num_static_call_sites,",
            "\t\t\tstart, end, mod->state == MODULE_STATE_COMING);",
            "",
            "\tmodule_put(mod);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__static_call_init, addr_conflict, __static_call_text_reserved, __static_call_mod_text_reserved",
          "description": "执行静态调用初始化流程，分配模块关联结构体并进行地址转换，实现文本区域预留检查以避免内存覆盖。",
          "similarity": 0.5305767059326172
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 347,
          "end_line": 449,
          "content": [
            "static unsigned long tramp_key_lookup(unsigned long addr)",
            "{",
            "\tstruct static_call_tramp_key *start = __start_static_call_tramp_key;",
            "\tstruct static_call_tramp_key *stop = __stop_static_call_tramp_key;",
            "\tstruct static_call_tramp_key *tramp_key;",
            "",
            "\tfor (tramp_key = start; tramp_key != stop; tramp_key++) {",
            "\t\tunsigned long tramp;",
            "",
            "\t\ttramp = (long)tramp_key->tramp + (long)&tramp_key->tramp;",
            "\t\tif (tramp == addr)",
            "\t\t\treturn (long)tramp_key->key + (long)&tramp_key->key;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int static_call_add_module(struct module *mod)",
            "{",
            "\tstruct static_call_site *start = mod->static_call_sites;",
            "\tstruct static_call_site *stop = start + mod->num_static_call_sites;",
            "\tstruct static_call_site *site;",
            "",
            "#ifdef CONFIG_LIVEPATCH_WO_FTRACE",
            "\tif (unlikely(!mod_klp_rel_completed(mod)))",
            "\t\treturn 0;",
            "#endif",
            "",
            "\tfor (site = start; site != stop; site++) {",
            "\t\tunsigned long s_key = __static_call_key(site);",
            "\t\tunsigned long addr = s_key & ~STATIC_CALL_SITE_FLAGS;",
            "\t\tunsigned long key;",
            "",
            "\t\t/*",
            "\t\t * Is the key is exported, 'addr' points to the key, which",
            "\t\t * means modules are allowed to call static_call_update() on",
            "\t\t * it.",
            "\t\t *",
            "\t\t * Otherwise, the key isn't exported, and 'addr' points to the",
            "\t\t * trampoline so we need to lookup the key.",
            "\t\t *",
            "\t\t * We go through this dance to prevent crazy modules from",
            "\t\t * abusing sensitive static calls.",
            "\t\t */",
            "\t\tif (!kernel_text_address(addr))",
            "\t\t\tcontinue;",
            "",
            "\t\tkey = tramp_key_lookup(addr);",
            "\t\tif (!key) {",
            "\t\t\tpr_warn(\"Failed to fixup __raw_static_call() usage at: %ps\\n\",",
            "\t\t\t\tstatic_call_addr(site));",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\tkey |= s_key & STATIC_CALL_SITE_FLAGS;",
            "\t\tsite->key = key - (long)&site->key;",
            "\t}",
            "",
            "\treturn __static_call_init(mod, start, stop);",
            "}",
            "static void static_call_del_module(struct module *mod)",
            "{",
            "\tstruct static_call_site *start = mod->static_call_sites;",
            "\tstruct static_call_site *stop = mod->static_call_sites +",
            "\t\t\t\t\tmod->num_static_call_sites;",
            "\tstruct static_call_key *key, *prev_key = NULL;",
            "\tstruct static_call_mod *site_mod, **prev;",
            "\tstruct static_call_site *site;",
            "",
            "#ifdef CONFIG_LIVEPATCH_WO_FTRACE",
            "\tif (unlikely(!mod_klp_rel_completed(mod)))",
            "\t\treturn;",
            "#endif",
            "",
            "\tfor (site = start; site < stop; site++) {",
            "\t\tkey = static_call_key(site);",
            "",
            "\t\t/*",
            "\t\t * If the key was not updated due to a memory allocation",
            "\t\t * failure in __static_call_init() then treating key::sites",
            "\t\t * as key::mods in the code below would cause random memory",
            "\t\t * access and #GP. In that case all subsequent sites have",
            "\t\t * not been touched either, so stop iterating.",
            "\t\t */",
            "\t\tif (!static_call_key_has_mods(key))",
            "\t\t\tbreak;",
            "",
            "\t\tif (key == prev_key)",
            "\t\t\tcontinue;",
            "",
            "\t\tprev_key = key;",
            "",
            "\t\tfor (prev = &key->mods, site_mod = key->mods;",
            "\t\t     site_mod && site_mod->mod != mod;",
            "\t\t     prev = &site_mod->next, site_mod = site_mod->next)",
            "\t\t\t;",
            "",
            "\t\tif (!site_mod)",
            "\t\t\tcontinue;",
            "",
            "\t\t*prev = site_mod->next;",
            "\t\tkfree(site_mod);",
            "\t}",
            "}"
          ],
          "function_name": "tramp_key_lookup, static_call_add_module, static_call_del_module",
          "description": "处理模块动态加载/卸载时的静态调用更新，通过键查找机制确保跨模块调用正确性，并维护静态调用站点的模块绑定关系。",
          "similarity": 0.49566468596458435
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 23,
          "end_line": 176,
          "content": [
            "void static_call_force_reinit(void)",
            "{",
            "\tif (WARN_ON_ONCE(!static_call_initialized))",
            "\t\treturn;",
            "",
            "\tstatic_call_initialized++;",
            "}",
            "static void static_call_lock(void)",
            "{",
            "\tmutex_lock(&static_call_mutex);",
            "}",
            "static void static_call_unlock(void)",
            "{",
            "\tmutex_unlock(&static_call_mutex);",
            "}",
            "static inline unsigned long __static_call_key(const struct static_call_site *site)",
            "{",
            "\treturn (long)site->key + (long)&site->key;",
            "}",
            "static inline bool static_call_is_init(struct static_call_site *site)",
            "{",
            "\treturn __static_call_key(site) & STATIC_CALL_SITE_INIT;",
            "}",
            "static inline bool static_call_is_tail(struct static_call_site *site)",
            "{",
            "\treturn __static_call_key(site) & STATIC_CALL_SITE_TAIL;",
            "}",
            "static inline void static_call_set_init(struct static_call_site *site)",
            "{",
            "\tsite->key = (__static_call_key(site) | STATIC_CALL_SITE_INIT) -",
            "\t\t    (long)&site->key;",
            "}",
            "static int static_call_site_cmp(const void *_a, const void *_b)",
            "{",
            "\tconst struct static_call_site *a = _a;",
            "\tconst struct static_call_site *b = _b;",
            "\tconst struct static_call_key *key_a = static_call_key(a);",
            "\tconst struct static_call_key *key_b = static_call_key(b);",
            "",
            "\tif (key_a < key_b)",
            "\t\treturn -1;",
            "",
            "\tif (key_a > key_b)",
            "\t\treturn 1;",
            "",
            "\treturn 0;",
            "}",
            "static void static_call_site_swap(void *_a, void *_b, int size)",
            "{",
            "\tlong delta = (unsigned long)_a - (unsigned long)_b;",
            "\tstruct static_call_site *a = _a;",
            "\tstruct static_call_site *b = _b;",
            "\tstruct static_call_site tmp = *a;",
            "",
            "\ta->addr = b->addr  - delta;",
            "\ta->key  = b->key   - delta;",
            "",
            "\tb->addr = tmp.addr + delta;",
            "\tb->key  = tmp.key  + delta;",
            "}",
            "static inline void static_call_sort_entries(struct static_call_site *start,",
            "\t\t\t\t\t    struct static_call_site *stop)",
            "{",
            "\tsort(start, stop - start, sizeof(struct static_call_site),",
            "\t     static_call_site_cmp, static_call_site_swap);",
            "}",
            "static inline bool static_call_key_has_mods(struct static_call_key *key)",
            "{",
            "\treturn !(key->type & 1);",
            "}",
            "void __static_call_update(struct static_call_key *key, void *tramp, void *func)",
            "{",
            "\tstruct static_call_site *site, *stop;",
            "\tstruct static_call_mod *site_mod, first;",
            "",
            "\tcpus_read_lock();",
            "\tstatic_call_lock();",
            "",
            "\tif (key->func == func)",
            "\t\tgoto done;",
            "",
            "\tkey->func = func;",
            "",
            "\tarch_static_call_transform(NULL, tramp, func, false);",
            "",
            "\t/*",
            "\t * If uninitialized, we'll not update the callsites, but they still",
            "\t * point to the trampoline and we just patched that.",
            "\t */",
            "\tif (WARN_ON_ONCE(!static_call_initialized))",
            "\t\tgoto done;",
            "",
            "\tfirst = (struct static_call_mod){",
            "\t\t.next = static_call_key_next(key),",
            "\t\t.mod = NULL,",
            "\t\t.sites = static_call_key_sites(key),",
            "\t};",
            "",
            "\tfor (site_mod = &first; site_mod; site_mod = site_mod->next) {",
            "\t\tbool init = system_state < SYSTEM_RUNNING;",
            "\t\tstruct module *mod = site_mod->mod;",
            "",
            "\t\tif (!site_mod->sites) {",
            "\t\t\t/*",
            "\t\t\t * This can happen if the static call key is defined in",
            "\t\t\t * a module which doesn't use it.",
            "\t\t\t *",
            "\t\t\t * It also happens in the has_mods case, where the",
            "\t\t\t * 'first' entry has no sites associated with it.",
            "\t\t\t */",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tstop = __stop_static_call_sites;",
            "",
            "\t\tif (mod) {",
            "#ifdef CONFIG_MODULES",
            "\t\t\tstop = mod->static_call_sites +",
            "\t\t\t       mod->num_static_call_sites;",
            "\t\t\tinit = mod->state == MODULE_STATE_COMING;",
            "#endif",
            "\t\t}",
            "",
            "\t\tfor (site = site_mod->sites;",
            "\t\t     site < stop && static_call_key(site) == key; site++) {",
            "\t\t\tvoid *site_addr = static_call_addr(site);",
            "",
            "\t\t\tif (!init && static_call_is_init(site))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tif (!kernel_text_address((unsigned long)site_addr)) {",
            "\t\t\t\t/*",
            "\t\t\t\t * This skips patching built-in __exit, which",
            "\t\t\t\t * is part of init_section_contains() but is",
            "\t\t\t\t * not part of kernel_text_address().",
            "\t\t\t\t *",
            "\t\t\t\t * Skipping built-in __exit is fine since it",
            "\t\t\t\t * will never be executed.",
            "\t\t\t\t */",
            "\t\t\t\tWARN_ONCE(!static_call_is_init(site),",
            "\t\t\t\t\t  \"can't patch static call site at %pS\",",
            "\t\t\t\t\t  site_addr);",
            "\t\t\t\tcontinue;",
            "\t\t\t}",
            "",
            "\t\t\tarch_static_call_transform(site_addr, NULL, func,",
            "\t\t\t\t\t\t   static_call_is_tail(site));",
            "\t\t}",
            "\t}",
            "",
            "done:",
            "\tstatic_call_unlock();",
            "\tcpus_read_unlock();",
            "}"
          ],
          "function_name": "static_call_force_reinit, static_call_lock, static_call_unlock, __static_call_key, static_call_is_init, static_call_is_tail, static_call_set_init, static_call_site_cmp, static_call_site_swap, static_call_sort_entries, static_call_key_has_mods, __static_call_update",
          "description": "实现静态调用的互斥锁控制、键值计算、站点排序及更新逻辑，包含地址冲突检测和模块间调用关系维护功能。",
          "similarity": 0.4896518290042877
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 453,
          "end_line": 552,
          "content": [
            "static int static_call_module_notify(struct notifier_block *nb,",
            "\t\t\t\t     unsigned long val, void *data)",
            "{",
            "\tstruct module *mod = data;",
            "\tint ret = 0;",
            "",
            "\tcpus_read_lock();",
            "\tstatic_call_lock();",
            "",
            "\tswitch (val) {",
            "\tcase MODULE_STATE_COMING:",
            "\t\tret = static_call_add_module(mod);",
            "\t\tif (ret) {",
            "\t\t\tpr_warn(\"Failed to allocate memory for static calls\\n\");",
            "\t\t\tstatic_call_del_module(mod);",
            "\t\t}",
            "\t\tbreak;",
            "\tcase MODULE_STATE_GOING:",
            "\t\tstatic_call_del_module(mod);",
            "\t\tbreak;",
            "\t}",
            "",
            "\tstatic_call_unlock();",
            "\tcpus_read_unlock();",
            "",
            "\treturn notifier_from_errno(ret);",
            "}",
            "int klp_static_call_register(struct module *mod)",
            "{",
            "\tint ret;",
            "",
            "\tret = static_call_module_notify(&static_call_module_nb, MODULE_STATE_COMING, mod);",
            "\treturn notifier_to_errno(ret);",
            "}",
            "static inline int __static_call_mod_text_reserved(void *start, void *end)",
            "{",
            "\treturn 0;",
            "}",
            "int static_call_text_reserved(void *start, void *end)",
            "{",
            "\tbool init = system_state < SYSTEM_RUNNING;",
            "\tint ret = __static_call_text_reserved(__start_static_call_sites,",
            "\t\t\t__stop_static_call_sites, start, end, init);",
            "",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\treturn __static_call_mod_text_reserved(start, end);",
            "}",
            "int __init static_call_init(void)",
            "{",
            "\tint ret;",
            "",
            "\t/* See static_call_force_reinit(). */",
            "\tif (static_call_initialized == 1)",
            "\t\treturn 0;",
            "",
            "\tcpus_read_lock();",
            "\tstatic_call_lock();",
            "\tret = __static_call_init(NULL, __start_static_call_sites,",
            "\t\t\t\t __stop_static_call_sites);",
            "\tstatic_call_unlock();",
            "\tcpus_read_unlock();",
            "",
            "\tif (ret) {",
            "\t\tpr_err(\"Failed to allocate memory for static_call!\\n\");",
            "\t\tBUG();",
            "\t}",
            "",
            "#ifdef CONFIG_MODULES",
            "\tif (!static_call_initialized)",
            "\t\tregister_module_notifier(&static_call_module_nb);",
            "#endif",
            "",
            "\tstatic_call_initialized = 1;",
            "\treturn 0;",
            "}",
            "static int func_a(int x)",
            "{",
            "\treturn x+1;",
            "}",
            "static int func_b(int x)",
            "{",
            "\treturn x+2;",
            "}",
            "static int __init test_static_call_init(void)",
            "{",
            "      int i;",
            "",
            "      for (i = 0; i < ARRAY_SIZE(static_call_data); i++ ) {",
            "\t      struct static_call_data *scd = &static_call_data[i];",
            "",
            "              if (scd->func)",
            "                      static_call_update(sc_selftest, scd->func);",
            "",
            "              WARN_ON(static_call(sc_selftest)(scd->val) != scd->expect);",
            "      }",
            "",
            "      return 0;",
            "}"
          ],
          "function_name": "static_call_module_notify, klp_static_call_register, __static_call_mod_text_reserved, static_call_text_reserved, static_call_init, func_a, func_b, test_static_call_init",
          "description": "实现模块状态变更通知机制，完成静态调用系统的初始化注册，包含测试函数用于验证静态调用逻辑的正确性。",
          "similarity": 0.4804297685623169
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 1,
          "end_line": 22,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/init.h>",
            "#include <linux/static_call.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>",
            "#include <linux/sort.h>",
            "#include <linux/slab.h>",
            "#include <linux/module.h>",
            "#include <linux/cpu.h>",
            "#include <linux/processor.h>",
            "#include <asm/sections.h>",
            "",
            "extern struct static_call_site __start_static_call_sites[],",
            "\t\t\t       __stop_static_call_sites[];",
            "extern struct static_call_tramp_key __start_static_call_tramp_key[],",
            "\t\t\t\t    __stop_static_call_tramp_key[];",
            "",
            "int static_call_initialized;",
            "",
            "/*",
            " * Must be called before early_initcall() to be effective.",
            " */"
          ],
          "function_name": null,
          "description": "声明静态调用相关的全局变量和外部符号，定义静态调用初始化标志位，为后续静态调用站点管理和地址转换提供基础结构。",
          "similarity": 0.462082177400589
        }
      ]
    }
  ]
}