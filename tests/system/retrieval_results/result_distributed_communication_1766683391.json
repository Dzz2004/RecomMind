{
  "query": "distributed communication",
  "timestamp": "2025-12-26 01:23:11",
  "retrieved_files": [
    {
      "source_file": "kernel/gcov/gcc_4_7.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:40:20\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `gcov\\gcc_4_7.c`\n\n---\n\n# gcov/gcc_4_7.c 技术文档\n\n## 文件概述\n\n`gcov/gcc_4_7.c` 是 Linux 内核中用于支持 GCC 4.7 及更高版本生成的代码覆盖率（gcov）数据格式的实现文件。该文件提供了一套内核态的接口，用于管理、操作和聚合由 GCC 编译器在编译时插入的覆盖率计数器数据。它基于早期 `gcc_3_4.c` 的实现，并针对 GCC 4.7+ 的数据结构和语义进行了适配，同时兼容 GCC 5 至 GCC 14 的多个版本差异（如计数器数量、数据单位大小、校验和字段等）。\n\n## 核心功能\n\n### 主要数据结构\n\n- **`struct gcov_ctr_info`**  \n  表示单个函数中某一类计数器的信息，包含计数器值的数量（`num`）和指向实际计数器值数组的指针（`values`）。\n\n- **`struct gcov_fn_info`**  \n  描述单个被插桩函数的元数据，包括唯一标识符（`ident`）、行号校验和（`lineno_checksum`）、控制流图校验和（`cfg_checksum`），以及一个变长的 `gcov_ctr_info` 数组（`ctrs[]`），用于存储该函数的所有活跃计数器。\n\n- **`struct gcov_info`**  \n  表示一个目标文件（object file）的完整覆盖率数据集合，包含版本号（`version`）、时间戳（`stamp`）、文件名（`filename`）、合并函数指针数组（`merge`）、函数数量（`n_functions`）以及指向各函数信息的指针数组（`functions`）。从 GCC 12.1 起，还包含一个 `checksum` 字段。\n\n### 主要函数接口\n\n- `const char *gcov_info_filename(struct gcov_info *info)`  \n  返回覆盖率数据关联的 `.gcda` 文件路径。\n\n- `unsigned int gcov_info_version(struct gcov_info *info)`  \n  返回生成该数据的 GCC 版本标识。\n\n- `struct gcov_info *gcov_info_next(struct gcov_info *info)`  \n  遍历全局 `gcov_info` 链表。\n\n- `void gcov_info_link(struct gcov_info *info)`  \n  将新的 `gcov_info` 节点插入全局链表头部。\n\n- `void gcov_info_unlink(struct gcov_info *prev, struct gcov_info *info)`  \n  从全局链表中移除指定节点。\n\n- `bool gcov_info_within_module(struct gcov_info *info, struct module *mod)`  \n  判断覆盖率数据是否属于指定内核模块。\n\n- `void gcov_info_reset(struct gcov_info *info)`  \n  将所有计数器值清零。\n\n- `int gcov_info_is_compatible(struct gcov_info *info1, struct gcov_info *info2)`  \n  检查两个覆盖率数据集是否可合并（基于 `stamp` 字段）。\n\n- `void gcov_info_add(struct gcov_info *dst, struct gcov_info *src)`  \n  将 `src` 的计数器值累加到 `dst` 中。\n\n- `struct gcov_info *gcov_info_dup(struct gcov_info *info)`  \n  深拷贝一个 `gcov_info` 结构（实现未完整展示，但已分配内存并准备复制函数和计数器数据）。\n\n### 全局符号\n\n- `gcov_link[]`  \n  定义了在 `/sys/kernel/debug/gcov/` 下为每个覆盖率数据文件创建的符号链接规则，例如链接到源码树中的 `.gcno` 文件。\n\n## 关键实现\n\n1. **GCC 版本适配**  \n   通过预处理器条件判断（`__GNUC__` 和 `__GNUC_MINOR__`）动态设置 `GCOV_COUNTERS`（计数器类型数量）和 `GCOV_UNIT_SIZE`（数据单位大小）。例如：\n   - GCC ≥ 12.1：计数器数量为 9，数据单位为字节（`GCOV_UNIT_SIZE = 4` 表示以 4 字节为单位）。\n   - GCC 5.1–11：计数器数量为 10。\n   - 其他版本：计数器数量为 9。\n\n2. **活跃计数器检测**  \n   通过检查 `gcov_info->merge[type]` 是否为非空函数指针，判断某类计数器是否在编译时被启用（`counter_active()`）。\n\n3. **动态内存管理**  \n   `gcov_info_dup()` 使用 `kmemdup()`、`kstrdup()` 和 `kcalloc()` 安全地复制结构体、字符串和指针数组，并为每个函数的计数器信息分配连续内存（利用 trailing array idiom）。\n\n4. **数据兼容性校验**  \n   使用 `stamp` 字段（由 GCC 在编译时生成）确保只有来自同一编译单元的覆盖率数据才能被合并，防止数据错位。\n\n5. **链表管理**  \n   全局变量 `gcov_info_head` 维护所有已注册的覆盖率数据结构，支持动态加载/卸载模块时的注册与注销。\n\n## 依赖关系\n\n- **头文件依赖**：\n  - `<linux/errno.h>`：错误码定义。\n  - `<linux/slab.h>`：内存分配接口（`kmalloc`/`kfree` 等）。\n  - `<linux/string.h>`：内存操作函数（`memset`）。\n  - `<linux/mm.h>`：内存管理相关（间接支持 `within_module`）。\n  - `\"gcov.h\"`：内核 GCOV 子系统的公共接口和类型定义。\n\n- **内核子系统**：\n  - **GCOV 子系统**：作为内核代码覆盖率基础设施的一部分，与 `gcov-core.c`、`gcov-fs.c` 等协同工作。\n  - **模块系统**：通过 `within_module()` 与内核模块加载机制集成，支持模块级覆盖率收集。\n  - **DebugFS**：通过 `gcov_link` 提供用户空间访问接口。\n\n## 使用场景\n\n1. **内核代码覆盖率分析**  \n   当内核以 `CONFIG_GCOV_KERNEL=y` 编译时，该文件提供的接口用于收集内核各部分（包括可加载模块）的执行路径覆盖信息。\n\n2. **模块覆盖率支持**  \n   在模块加载时，其内嵌的 `gcov_info` 结构被注册到全局链表；卸载时被移除，确保覆盖率数据与模块生命周期一致。\n\n3. **运行时数据重置与聚合**  \n   支持在测试过程中动态清零计数器（`gcov_info_reset`）或合并多次运行的结果（`gcov_info_add`），适用于回归测试和持续集成。\n\n4. **用户空间工具集成**  \n   通过 DebugFS 暴露的 `.gcda` 数据可被 `gcov` 工具读取，生成人类可读的覆盖率报告，用于内核开发和质量保证。",
      "similarity": 0.5014992356300354,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/gcov/gcc_4_7.c",
          "start_line": 1,
          "end_line": 122,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " *  This code provides functions to handle gcc's profiling data format",
            " *  introduced with gcc 4.7.",
            " *",
            " *  This file is based heavily on gcc_3_4.c file.",
            " *",
            " *  For a better understanding, refer to gcc source:",
            " *  gcc/gcov-io.h",
            " *  libgcc/libgcov.c",
            " *",
            " *  Uses gcc-internal data definitions.",
            " */",
            "",
            "#include <linux/errno.h>",
            "#include <linux/slab.h>",
            "#include <linux/string.h>",
            "#include <linux/mm.h>",
            "#include \"gcov.h\"",
            "",
            "#if (__GNUC__ >= 14)",
            "#define GCOV_COUNTERS\t\t\t9",
            "#elif (__GNUC__ >= 10)",
            "#define GCOV_COUNTERS\t\t\t8",
            "#elif (__GNUC__ >= 7)",
            "#define GCOV_COUNTERS\t\t\t9",
            "#elif (__GNUC__ > 5) || (__GNUC__ == 5 && __GNUC_MINOR__ >= 1)",
            "#define GCOV_COUNTERS\t\t\t10",
            "#else",
            "#define GCOV_COUNTERS\t\t\t9",
            "#endif",
            "",
            "#define GCOV_TAG_FUNCTION_LENGTH\t3",
            "",
            "/* Since GCC 12.1 sizes are in BYTES and not in WORDS (4B). */",
            "#if (__GNUC__ >= 12)",
            "#define GCOV_UNIT_SIZE\t\t\t\t4",
            "#else",
            "#define GCOV_UNIT_SIZE\t\t\t\t1",
            "#endif",
            "",
            "static struct gcov_info *gcov_info_head;",
            "",
            "/**",
            " * struct gcov_ctr_info - information about counters for a single function",
            " * @num: number of counter values for this type",
            " * @values: array of counter values for this type",
            " *",
            " * This data is generated by gcc during compilation and doesn't change",
            " * at run-time with the exception of the values array.",
            " */",
            "struct gcov_ctr_info {",
            "\tunsigned int num;",
            "\tgcov_type *values;",
            "};",
            "",
            "/**",
            " * struct gcov_fn_info - profiling meta data per function",
            " * @key: comdat key",
            " * @ident: unique ident of function",
            " * @lineno_checksum: function lineo_checksum",
            " * @cfg_checksum: function cfg checksum",
            " * @ctrs: instrumented counters",
            " *",
            " * This data is generated by gcc during compilation and doesn't change",
            " * at run-time.",
            " *",
            " * Information about a single function.  This uses the trailing array",
            " * idiom. The number of counters is determined from the merge pointer",
            " * array in gcov_info.  The key is used to detect which of a set of",
            " * comdat functions was selected -- it points to the gcov_info object",
            " * of the object file containing the selected comdat function.",
            " */",
            "struct gcov_fn_info {",
            "\tconst struct gcov_info *key;",
            "\tunsigned int ident;",
            "\tunsigned int lineno_checksum;",
            "\tunsigned int cfg_checksum;",
            "\tstruct gcov_ctr_info ctrs[];",
            "};",
            "",
            "/**",
            " * struct gcov_info - profiling data per object file",
            " * @version: gcov version magic indicating the gcc version used for compilation",
            " * @next: list head for a singly-linked list",
            " * @stamp: uniquifying time stamp",
            " * @checksum: unique object checksum",
            " * @filename: name of the associated gcov data file",
            " * @merge: merge functions (null for unused counter type)",
            " * @n_functions: number of instrumented functions",
            " * @functions: pointer to pointers to function information",
            " *",
            " * This data is generated by gcc during compilation and doesn't change",
            " * at run-time with the exception of the next pointer.",
            " */",
            "struct gcov_info {",
            "\tunsigned int version;",
            "\tstruct gcov_info *next;",
            "\tunsigned int stamp;",
            " /* Since GCC 12.1 a checksum field is added. */",
            "#if (__GNUC__ >= 12)",
            "\tunsigned int checksum;",
            "#endif",
            "\tconst char *filename;",
            "\tvoid (*merge[GCOV_COUNTERS])(gcov_type *, unsigned int);",
            "\tunsigned int n_functions;",
            "\tstruct gcov_fn_info **functions;",
            "};",
            "",
            "/**",
            " * gcov_info_filename - return info filename",
            " * @info: profiling data set",
            " */",
            "const char *gcov_info_filename(struct gcov_info *info)",
            "{",
            "\treturn info->filename;",
            "}",
            "",
            "/**",
            " * gcov_info_version - return info version",
            " * @info: profiling data set",
            " */"
          ],
          "function_name": null,
          "description": "定义GCC 4.7及以上版本的覆盖率数据结构和宏，包含gcov_info、gcov_fn_info、gcov_ctr_info结构体，用于存储函数元数据和计数器信息，并设置版本号、合并函数指针等字段。上下文不完整。",
          "similarity": 0.4642520546913147
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/gcov/gcc_4_7.c",
          "start_line": 386,
          "end_line": 438,
          "content": [
            "size_t convert_to_gcda(char *buffer, struct gcov_info *info)",
            "{",
            "\tstruct gcov_fn_info *fi_ptr;",
            "\tstruct gcov_ctr_info *ci_ptr;",
            "\tunsigned int fi_idx;",
            "\tunsigned int ct_idx;",
            "\tunsigned int cv_idx;",
            "\tsize_t pos = 0;",
            "",
            "\t/* File header. */",
            "\tpos += store_gcov_u32(buffer, pos, GCOV_DATA_MAGIC);",
            "\tpos += store_gcov_u32(buffer, pos, info->version);",
            "\tpos += store_gcov_u32(buffer, pos, info->stamp);",
            "",
            "#if (__GNUC__ >= 12)",
            "\t/* Use zero as checksum of the compilation unit. */",
            "\tpos += store_gcov_u32(buffer, pos, 0);",
            "#endif",
            "",
            "\tfor (fi_idx = 0; fi_idx < info->n_functions; fi_idx++) {",
            "\t\tfi_ptr = info->functions[fi_idx];",
            "",
            "\t\t/* Function record. */",
            "\t\tpos += store_gcov_u32(buffer, pos, GCOV_TAG_FUNCTION);",
            "\t\tpos += store_gcov_u32(buffer, pos,",
            "\t\t\tGCOV_TAG_FUNCTION_LENGTH * GCOV_UNIT_SIZE);",
            "\t\tpos += store_gcov_u32(buffer, pos, fi_ptr->ident);",
            "\t\tpos += store_gcov_u32(buffer, pos, fi_ptr->lineno_checksum);",
            "\t\tpos += store_gcov_u32(buffer, pos, fi_ptr->cfg_checksum);",
            "",
            "\t\tci_ptr = fi_ptr->ctrs;",
            "",
            "\t\tfor (ct_idx = 0; ct_idx < GCOV_COUNTERS; ct_idx++) {",
            "\t\t\tif (!counter_active(info, ct_idx))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\t/* Counter record. */",
            "\t\t\tpos += store_gcov_u32(buffer, pos,",
            "\t\t\t\t\t      GCOV_TAG_FOR_COUNTER(ct_idx));",
            "\t\t\tpos += store_gcov_u32(buffer, pos,",
            "\t\t\t\tci_ptr->num * 2 * GCOV_UNIT_SIZE);",
            "",
            "\t\t\tfor (cv_idx = 0; cv_idx < ci_ptr->num; cv_idx++) {",
            "\t\t\t\tpos += store_gcov_u64(buffer, pos,",
            "\t\t\t\t\t\t      ci_ptr->values[cv_idx]);",
            "\t\t\t}",
            "",
            "\t\t\tci_ptr++;",
            "\t\t}",
            "\t}",
            "",
            "\treturn pos;",
            "}"
          ],
          "function_name": "convert_to_gcda",
          "description": "将gcov_info结构序列化为GCDA文件格式的二进制缓冲区，按文件头、函数记录、计数器数据顺序写入，包含魔数、版本号、时间戳、校验和及各函数的标识符、校验码和计数器值。",
          "similarity": 0.4292227625846863
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/gcov/gcc_4_7.c",
          "start_line": 123,
          "end_line": 234,
          "content": [
            "unsigned int gcov_info_version(struct gcov_info *info)",
            "{",
            "\treturn info->version;",
            "}",
            "void gcov_info_link(struct gcov_info *info)",
            "{",
            "\tinfo->next = gcov_info_head;",
            "\tgcov_info_head = info;",
            "}",
            "void gcov_info_unlink(struct gcov_info *prev, struct gcov_info *info)",
            "{",
            "\tif (prev)",
            "\t\tprev->next = info->next;",
            "\telse",
            "\t\tgcov_info_head = info->next;",
            "}",
            "bool gcov_info_within_module(struct gcov_info *info, struct module *mod)",
            "{",
            "\treturn within_module((unsigned long)info, mod);",
            "}",
            "static int counter_active(struct gcov_info *info, unsigned int type)",
            "{",
            "\treturn info->merge[type] ? 1 : 0;",
            "}",
            "static unsigned int num_counter_active(struct gcov_info *info)",
            "{",
            "\tunsigned int i;",
            "\tunsigned int result = 0;",
            "",
            "\tfor (i = 0; i < GCOV_COUNTERS; i++) {",
            "\t\tif (counter_active(info, i))",
            "\t\t\tresult++;",
            "\t}",
            "\treturn result;",
            "}",
            "void gcov_info_reset(struct gcov_info *info)",
            "{",
            "\tstruct gcov_ctr_info *ci_ptr;",
            "\tunsigned int fi_idx;",
            "\tunsigned int ct_idx;",
            "",
            "\tfor (fi_idx = 0; fi_idx < info->n_functions; fi_idx++) {",
            "\t\tci_ptr = info->functions[fi_idx]->ctrs;",
            "",
            "\t\tfor (ct_idx = 0; ct_idx < GCOV_COUNTERS; ct_idx++) {",
            "\t\t\tif (!counter_active(info, ct_idx))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tmemset(ci_ptr->values, 0,",
            "\t\t\t\t\tsizeof(gcov_type) * ci_ptr->num);",
            "\t\t\tci_ptr++;",
            "\t\t}",
            "\t}",
            "}",
            "int gcov_info_is_compatible(struct gcov_info *info1, struct gcov_info *info2)",
            "{",
            "\treturn (info1->stamp == info2->stamp);",
            "}",
            "void gcov_info_add(struct gcov_info *dst, struct gcov_info *src)",
            "{",
            "\tstruct gcov_ctr_info *dci_ptr;",
            "\tstruct gcov_ctr_info *sci_ptr;",
            "\tunsigned int fi_idx;",
            "\tunsigned int ct_idx;",
            "\tunsigned int val_idx;",
            "",
            "\tfor (fi_idx = 0; fi_idx < src->n_functions; fi_idx++) {",
            "\t\tdci_ptr = dst->functions[fi_idx]->ctrs;",
            "\t\tsci_ptr = src->functions[fi_idx]->ctrs;",
            "",
            "\t\tfor (ct_idx = 0; ct_idx < GCOV_COUNTERS; ct_idx++) {",
            "\t\t\tif (!counter_active(src, ct_idx))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tfor (val_idx = 0; val_idx < sci_ptr->num; val_idx++)",
            "\t\t\t\tdci_ptr->values[val_idx] +=",
            "\t\t\t\t\tsci_ptr->values[val_idx];",
            "",
            "\t\t\tdci_ptr++;",
            "\t\t\tsci_ptr++;",
            "\t\t}",
            "\t}",
            "}",
            "void gcov_info_free(struct gcov_info *info)",
            "{",
            "\tunsigned int active;",
            "\tunsigned int fi_idx;",
            "\tunsigned int ct_idx;",
            "\tstruct gcov_ctr_info *ci_ptr;",
            "",
            "\tif (!info->functions)",
            "\t\tgoto free_info;",
            "",
            "\tactive = num_counter_active(info);",
            "",
            "\tfor (fi_idx = 0; fi_idx < info->n_functions; fi_idx++) {",
            "\t\tif (!info->functions[fi_idx])",
            "\t\t\tcontinue;",
            "",
            "\t\tci_ptr = info->functions[fi_idx]->ctrs;",
            "",
            "\t\tfor (ct_idx = 0; ct_idx < active; ct_idx++, ci_ptr++)",
            "\t\t\tkvfree(ci_ptr->values);",
            "",
            "\t\tkfree(info->functions[fi_idx]);",
            "\t}",
            "",
            "free_info:",
            "\tkfree(info->functions);",
            "\tkfree(info->filename);",
            "\tkfree(info);",
            "}"
          ],
          "function_name": "gcov_info_version, gcov_info_link, gcov_info_unlink, gcov_info_within_module, counter_active, num_counter_active, gcov_info_reset, gcov_info_is_compatible, gcov_info_add, gcov_info_free",
          "description": "实现gcov_info链表操作（链接/断链）、模块范围检查、计数器激活状态查询、计数器重置、兼容性检测、数据合并及释放函数，通过遍历函数和计数器完成数据操作与内存管理。",
          "similarity": 0.42312273383140564
        }
      ]
    },
    {
      "source_file": "kernel/sched/deadline.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:06:40\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\deadline.c`\n\n---\n\n# `sched/deadline.c` 技术文档\n\n## 1. 文件概述\n\n`sched/deadline.c` 是 Linux 内核调度器中 **SCHED_DEADLINE** 调度类的核心实现文件。该调度类基于 **最早截止时间优先（Earliest Deadline First, EDF）** 算法，并结合 **恒定带宽服务器（Constant Bandwidth Server, CBS）** 机制，为具有严格实时性要求的任务提供可预测的调度保障。\n\n其核心目标是：  \n- 对于周期性任务，若其实际运行时间不超过所申请的运行时间（runtime），则保证不会错过任何截止时间（deadline）；  \n- 对于非周期性任务、突发任务或试图超出其预留带宽的任务，系统会对其进行节流（throttling），防止其影响其他任务的实时性保障。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct sched_dl_entity`：表示一个 deadline 调度实体，包含任务的运行时间（runtime）、截止期限（deadline）、周期（period）、带宽（dl_bw）等关键参数。\n- `struct dl_rq`：每个 CPU 的 deadline 运行队列，维护该 CPU 上所有 deadline 任务的红黑树、当前带宽使用情况（`this_bw`、`running_bw`）等。\n- `struct dl_bw`：deadline 带宽管理结构，用于跟踪系统或调度域中已分配的总带宽（`total_bw`）。\n\n### 主要函数与辅助宏\n\n#### 调度实体与运行队列关联\n- `dl_task_of(dl_se)`：从 `sched_dl_entity` 获取对应的 `task_struct`（仅适用于普通任务，不适用于服务器实体）。\n- `rq_of_dl_rq(dl_rq)` / `rq_of_dl_se(dl_se)`：获取与 deadline 运行队列或调度实体关联的 `rq`（runqueue）。\n- `dl_rq_of_se(dl_se)`：获取调度实体所属的 `dl_rq`。\n- `on_dl_rq(dl_se)`：判断调度实体是否已在 deadline 运行队列中（通过红黑树节点是否为空判断）。\n\n#### 优先级继承（PI）支持（`CONFIG_RT_MUTEXES`）\n- `pi_of(dl_se)`：获取当前调度实体因优先级继承而提升后的“代理”实体。\n- `is_dl_boosted(dl_se)`：判断该 deadline 实体是否因优先级继承被提升。\n\n#### 带宽管理（SMP 与 UP 差异处理）\n- `dl_bw_of(cpu)`：获取指定 CPU 所属调度域（或本地）的 `dl_bw` 结构。\n- `dl_bw_cpus(cpu)`：返回该 CPU 所在调度域中活跃 CPU 的数量。\n- `dl_bw_capacity(cpu)`：计算调度域的总 CPU 容量（考虑异构 CPU 的 `arch_scale_cpu_capacity`）。\n- `__dl_add()` / `__dl_sub()`：向带宽池中添加或移除任务带宽，并更新 `extra_bw`（用于负载均衡）。\n- `__dl_overflow()`：检查新增带宽是否超出系统/调度域的可用带宽上限。\n\n#### 运行时带宽跟踪\n- `__add_running_bw()` / `__sub_running_bw()`：更新 `dl_rq->running_bw`（当前正在运行的 deadline 任务所消耗的带宽）。\n- `__add_rq_bw()` / `__sub_rq_bw()`：更新 `dl_rq->this_bw`（该运行队列上所有 deadline 任务的总预留带宽）。\n- `add_running_bw()` / `sub_running_bw()` / `add_rq_bw()` / `sub_rq_bw()`：带宽操作的封装，跳过“特殊”调度实体（如服务器）。\n\n#### 其他\n- `dl_server(dl_se)`：判断调度实体是否为 CBS 服务器（而非普通任务）。\n- `dl_bw_visited(cpu, gen)`：用于带宽遍历去重（SMP 场景）。\n\n### 系统控制接口（`CONFIG_SYSCTL`）\n- `sched_deadline_period_max_us`：deadline 任务周期上限（默认 ~4 秒）。\n- `sched_deadline_period_min_us`：deadline 任务周期下限（默认 100 微秒），防止定时器 DoS。\n\n## 3. 关键实现\n\n### EDF + CBS 调度模型\n- 每个 deadline 任务通过 `runtime`、`deadline`、`period` 三个参数定义其资源需求。\n- 调度器按 **绝对截止时间（absolute deadline）** 对任务排序，使用红黑树实现 O(log n) 的调度决策。\n- CBS 机制确保任务即使突发执行，也不会长期占用超过其 `runtime/period` 的 CPU 带宽，超限任务会被 throttled。\n\n### 带宽隔离与全局限制\n- 在 SMP 系统中，deadline 带宽按 **调度域（root domain）** 进行管理，防止跨 CPU 的带宽滥用。\n- 总带宽限制默认为 CPU 总容量的 95%（由 `sysctl_sched_util_clamp_min` 等机制间接控制，具体限制逻辑在带宽分配函数中体现）。\n- `dl_bw->total_bw` 跟踪已分配带宽，`__dl_overflow()` 用于在任务加入时检查是否超限。\n\n### 异构 CPU 支持\n- 通过 `arch_scale_cpu_capacity()` 获取每个 CPU 的相对性能权重。\n- `dl_bw_capacity()` 在异构系统中返回调度域内所有活跃 CPU 的容量总和，用于带宽比例计算（`cap_scale()`）。\n\n### 与 cpufreq 集成\n- 每次 `running_bw` 变化时调用 `cpufreq_update_util()`，通知 CPU 频率调节器当前 deadline 负载，确保满足实时性能需求。\n\n### 优先级继承（PI）\n- 当 deadline 任务因持有 mutex 而阻塞高优先级任务时，通过 `pi_se` 字段临时提升其调度参数，避免优先级反转。\n\n## 4. 依赖关系\n\n- **核心调度框架**：依赖 `kernel/sched/sched.h` 中定义的通用调度结构（如 `rq`、`task_struct`）和宏（如 `SCHED_CAPACITY_SCALE`）。\n- **CPU 拓扑与容量**：依赖 `arch_scale_cpu_capacity()`（由各架构实现）获取 CPU 性能信息。\n- **RCU 机制**：在 SMP 路径中大量使用 `rcu_read_lock_sched_held()` 进行锁依赖检查。\n- **cpufreq 子系统**：通过 `cpufreq_update_util()` 与 CPU 频率调节器交互。\n- **实时互斥锁**：`CONFIG_RT_MUTEXES` 启用时，支持 deadline 任务的优先级继承。\n- **Sysctl 接口**：`CONFIG_SYSCTL` 启用时，提供用户空间可调的 deadline 参数。\n\n## 5. 使用场景\n\n- **工业实时控制**：如机器人控制、数控机床等需要严格周期性和低延迟响应的场景。\n- **音视频处理**：专业音视频采集、编码、播放等对 jitter 敏感的应用。\n- **电信基础设施**：5G 基站、核心网网元中的高优先级信令处理。\n- **汽车电子**：ADAS、自动驾驶系统中的关键任务调度。\n- **科研与高性能计算**：需要确定性执行时间的实验或仿真任务。\n\n用户通过 `sched_setattr(2)` 系统调用设置任务的 `SCHED_DEADLINE` 策略及对应的 `runtime`、`deadline`、`period` 参数，内核则通过本文件实现的调度逻辑确保其满足实时性约束。",
      "similarity": 0.5010366439819336,
      "chunks": [
        {
          "chunk_id": 18,
          "file_path": "kernel/sched/deadline.c",
          "start_line": 3051,
          "end_line": 3166,
          "content": [
            "static void switched_to_dl(struct rq *rq, struct task_struct *p)",
            "{",
            "\tif (hrtimer_try_to_cancel(&p->dl.inactive_timer) == 1)",
            "\t\tput_task_struct(p);",
            "",
            "\t/*",
            "\t * In case a task is setscheduled to SCHED_DEADLINE we need to keep",
            "\t * track of that on its cpuset (for correct bandwidth tracking).",
            "\t */",
            "\tinc_dl_tasks_cs(p);",
            "",
            "\t/* If p is not queued we will update its parameters at next wakeup. */",
            "\tif (!task_on_rq_queued(p)) {",
            "\t\tadd_rq_bw(&p->dl, &rq->dl);",
            "",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (rq->curr != p) {",
            "#ifdef CONFIG_SMP",
            "\t\tif (p->nr_cpus_allowed > 1 && rq->dl.overloaded)",
            "\t\t\tdeadline_queue_push_tasks(rq);",
            "#endif",
            "\t\tif (dl_task(rq->curr))",
            "\t\t\twakeup_preempt_dl(rq, p, 0);",
            "\t\telse",
            "\t\t\tresched_curr(rq);",
            "\t} else {",
            "\t\tupdate_dl_rq_load_avg(rq_clock_pelt(rq), rq, 0);",
            "\t}",
            "}",
            "static void prio_changed_dl(struct rq *rq, struct task_struct *p,",
            "\t\t\t    int oldprio)",
            "{",
            "\tif (!task_on_rq_queued(p))",
            "\t\treturn;",
            "",
            "#ifdef CONFIG_SMP",
            "\t/*",
            "\t * This might be too much, but unfortunately",
            "\t * we don't have the old deadline value, and",
            "\t * we can't argue if the task is increasing",
            "\t * or lowering its prio, so...",
            "\t */",
            "\tif (!rq->dl.overloaded)",
            "\t\tdeadline_queue_pull_task(rq);",
            "",
            "\tif (task_current(rq, p)) {",
            "\t\t/*",
            "\t\t * If we now have a earlier deadline task than p,",
            "\t\t * then reschedule, provided p is still on this",
            "\t\t * runqueue.",
            "\t\t */",
            "\t\tif (dl_time_before(rq->dl.earliest_dl.curr, p->dl.deadline))",
            "\t\t\tresched_curr(rq);",
            "\t} else {",
            "\t\t/*",
            "\t\t * Current may not be deadline in case p was throttled but we",
            "\t\t * have just replenished it (e.g. rt_mutex_setprio()).",
            "\t\t *",
            "\t\t * Otherwise, if p was given an earlier deadline, reschedule.",
            "\t\t */",
            "\t\tif (!dl_task(rq->curr) ||",
            "\t\t    dl_time_before(p->dl.deadline, rq->curr->dl.deadline))",
            "\t\t\tresched_curr(rq);",
            "\t}",
            "#else",
            "\t/*",
            "\t * We don't know if p has a earlier or later deadline, so let's blindly",
            "\t * set a (maybe not needed) rescheduling point.",
            "\t */",
            "\tresched_curr(rq);",
            "#endif",
            "}",
            "static int task_is_throttled_dl(struct task_struct *p, int cpu)",
            "{",
            "\treturn p->dl.dl_throttled;",
            "}",
            "int sched_dl_global_validate(void)",
            "{",
            "\tu64 runtime = global_rt_runtime();",
            "\tu64 period = global_rt_period();",
            "\tu64 new_bw = to_ratio(period, runtime);",
            "\tu64 gen = ++dl_generation;",
            "\tstruct dl_bw *dl_b;",
            "\tint cpu, cpus, ret = 0;",
            "\tunsigned long flags;",
            "",
            "\t/*",
            "\t * Here we want to check the bandwidth not being set to some",
            "\t * value smaller than the currently allocated bandwidth in",
            "\t * any of the root_domains.",
            "\t */",
            "\tfor_each_online_cpu(cpu) {",
            "\t\trcu_read_lock_sched();",
            "",
            "\t\tif (dl_bw_visited(cpu, gen))",
            "\t\t\tgoto next;",
            "",
            "\t\tdl_b = dl_bw_of(cpu);",
            "\t\tcpus = dl_bw_cpus(cpu);",
            "",
            "\t\traw_spin_lock_irqsave(&dl_b->lock, flags);",
            "\t\tif (new_bw * cpus < dl_b->total_bw)",
            "\t\t\tret = -EBUSY;",
            "\t\traw_spin_unlock_irqrestore(&dl_b->lock, flags);",
            "",
            "next:",
            "\t\trcu_read_unlock_sched();",
            "",
            "\t\tif (ret)",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "switched_to_dl, prio_changed_dl, task_is_throttled_dl, sched_dl_global_validate",
          "description": "处理SCHED_DEADLINE任务策略切换、优先级变更、节流状态检测及全局带宽验证，确保系统范围内的带宽约束有效性",
          "similarity": 0.5162321329116821
        },
        {
          "chunk_id": 21,
          "file_path": "kernel/sched/deadline.c",
          "start_line": 3482,
          "end_line": 3530,
          "content": [
            "static int dl_bw_manage(enum dl_bw_request req, int cpu, u64 dl_bw)",
            "{",
            "\tunsigned long flags;",
            "\tstruct dl_bw *dl_b;",
            "\tbool overflow = 0;",
            "",
            "\trcu_read_lock_sched();",
            "\tdl_b = dl_bw_of(cpu);",
            "\traw_spin_lock_irqsave(&dl_b->lock, flags);",
            "",
            "\tif (req == dl_bw_req_free) {",
            "\t\t__dl_sub(dl_b, dl_bw, dl_bw_cpus(cpu));",
            "\t} else {",
            "\t\tunsigned long cap = dl_bw_capacity(cpu);",
            "",
            "\t\toverflow = __dl_overflow(dl_b, cap, 0, dl_bw);",
            "",
            "\t\tif (req == dl_bw_req_alloc && !overflow) {",
            "\t\t\t/*",
            "\t\t\t * We reserve space in the destination",
            "\t\t\t * root_domain, as we can't fail after this point.",
            "\t\t\t * We will free resources in the source root_domain",
            "\t\t\t * later on (see set_cpus_allowed_dl()).",
            "\t\t\t */",
            "\t\t\t__dl_add(dl_b, dl_bw, dl_bw_cpus(cpu));",
            "\t\t}",
            "\t}",
            "",
            "\traw_spin_unlock_irqrestore(&dl_b->lock, flags);",
            "\trcu_read_unlock_sched();",
            "",
            "\treturn overflow ? -EBUSY : 0;",
            "}",
            "int dl_bw_check_overflow(int cpu)",
            "{",
            "\treturn dl_bw_manage(dl_bw_req_check_overflow, cpu, 0);",
            "}",
            "int dl_bw_alloc(int cpu, u64 dl_bw)",
            "{",
            "\treturn dl_bw_manage(dl_bw_req_alloc, cpu, dl_bw);",
            "}",
            "void dl_bw_free(int cpu, u64 dl_bw)",
            "{",
            "\tdl_bw_manage(dl_bw_req_free, cpu, dl_bw);",
            "}",
            "void print_dl_stats(struct seq_file *m, int cpu)",
            "{",
            "\tprint_dl_rq(m, cpu, &cpu_rq(cpu)->dl);",
            "}"
          ],
          "function_name": "dl_bw_manage, dl_bw_check_overflow, dl_bw_alloc, dl_bw_free, print_dl_stats",
          "description": "该代码段实现了截止时间调度器（Deadline Scheduler）中带宽管理的核心逻辑，通过`dl_bw_manage`统一处理带宽分配、释放及溢出检测。其中`dl_bw_alloc/free`用于资源申请与回收，`dl_bw_check_overflow`检查带宽是否超限，`print_dl_stats`输出统计信息。因依赖未展示的辅助函数（如`__dl_add/sub`、`dl_bw_of`等），上下文存在缺失。",
          "similarity": 0.5109387636184692
        },
        {
          "chunk_id": 16,
          "file_path": "kernel/sched/deadline.c",
          "start_line": 2709,
          "end_line": 2879,
          "content": [
            "static int push_dl_task(struct rq *rq)",
            "{",
            "\tstruct task_struct *next_task;",
            "\tstruct rq *later_rq;",
            "\tint ret = 0;",
            "",
            "\tnext_task = pick_next_pushable_dl_task(rq);",
            "\tif (!next_task)",
            "\t\treturn 0;",
            "",
            "retry:",
            "\t/*",
            "\t * If next_task preempts rq->curr, and rq->curr",
            "\t * can move away, it makes sense to just reschedule",
            "\t * without going further in pushing next_task.",
            "\t */",
            "\tif (dl_task(rq->curr) &&",
            "\t    dl_time_before(next_task->dl.deadline, rq->curr->dl.deadline) &&",
            "\t    rq->curr->nr_cpus_allowed > 1) {",
            "\t\tresched_curr(rq);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tif (is_migration_disabled(next_task))",
            "\t\treturn 0;",
            "",
            "\tif (WARN_ON(next_task == rq->curr))",
            "\t\treturn 0;",
            "",
            "\t/* We might release rq lock */",
            "\tget_task_struct(next_task);",
            "",
            "\t/* Will lock the rq it'll find */",
            "\tlater_rq = find_lock_later_rq(next_task, rq);",
            "\tif (!later_rq) {",
            "\t\tstruct task_struct *task;",
            "",
            "\t\t/*",
            "\t\t * We must check all this again, since",
            "\t\t * find_lock_later_rq releases rq->lock and it is",
            "\t\t * then possible that next_task has migrated.",
            "\t\t */",
            "\t\ttask = pick_next_pushable_dl_task(rq);",
            "\t\tif (task == next_task) {",
            "\t\t\t/*",
            "\t\t\t * The task is still there. We don't try",
            "\t\t\t * again, some other CPU will pull it when ready.",
            "\t\t\t */",
            "\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\tif (!task)",
            "\t\t\t/* No more tasks */",
            "\t\t\tgoto out;",
            "",
            "\t\tput_task_struct(next_task);",
            "\t\tnext_task = task;",
            "\t\tgoto retry;",
            "\t}",
            "",
            "\tdeactivate_task(rq, next_task, 0);",
            "\tset_task_cpu(next_task, later_rq->cpu);",
            "\tactivate_task(later_rq, next_task, 0);",
            "\tret = 1;",
            "",
            "\tresched_curr(later_rq);",
            "",
            "\tdouble_unlock_balance(rq, later_rq);",
            "",
            "out:",
            "\tput_task_struct(next_task);",
            "",
            "\treturn ret;",
            "}",
            "static void push_dl_tasks(struct rq *rq)",
            "{",
            "\t/* push_dl_task() will return true if it moved a -deadline task */",
            "\twhile (push_dl_task(rq))",
            "\t\t;",
            "}",
            "static void pull_dl_task(struct rq *this_rq)",
            "{",
            "\tint this_cpu = this_rq->cpu, cpu;",
            "\tstruct task_struct *p, *push_task;",
            "\tbool resched = false;",
            "\tstruct rq *src_rq;",
            "\tu64 dmin = LONG_MAX;",
            "",
            "\tif (likely(!dl_overloaded(this_rq)))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Match the barrier from dl_set_overloaded; this guarantees that if we",
            "\t * see overloaded we must also see the dlo_mask bit.",
            "\t */",
            "\tsmp_rmb();",
            "",
            "\tfor_each_cpu(cpu, this_rq->rd->dlo_mask) {",
            "\t\tif (this_cpu == cpu)",
            "\t\t\tcontinue;",
            "",
            "\t\tsrc_rq = cpu_rq(cpu);",
            "",
            "\t\t/*",
            "\t\t * It looks racy, abd it is! However, as in sched_rt.c,",
            "\t\t * we are fine with this.",
            "\t\t */",
            "\t\tif (this_rq->dl.dl_nr_running &&",
            "\t\t    dl_time_before(this_rq->dl.earliest_dl.curr,",
            "\t\t\t\t   src_rq->dl.earliest_dl.next))",
            "\t\t\tcontinue;",
            "",
            "\t\t/* Might drop this_rq->lock */",
            "\t\tpush_task = NULL;",
            "\t\tdouble_lock_balance(this_rq, src_rq);",
            "",
            "\t\t/*",
            "\t\t * If there are no more pullable tasks on the",
            "\t\t * rq, we're done with it.",
            "\t\t */",
            "\t\tif (src_rq->dl.dl_nr_running <= 1)",
            "\t\t\tgoto skip;",
            "",
            "\t\tp = pick_earliest_pushable_dl_task(src_rq, this_cpu);",
            "",
            "\t\t/*",
            "\t\t * We found a task to be pulled if:",
            "\t\t *  - it preempts our current (if there's one),",
            "\t\t *  - it will preempt the last one we pulled (if any).",
            "\t\t */",
            "\t\tif (p && dl_time_before(p->dl.deadline, dmin) &&",
            "\t\t    dl_task_is_earliest_deadline(p, this_rq)) {",
            "\t\t\tWARN_ON(p == src_rq->curr);",
            "\t\t\tWARN_ON(!task_on_rq_queued(p));",
            "",
            "\t\t\t/*",
            "\t\t\t * Then we pull iff p has actually an earlier",
            "\t\t\t * deadline than the current task of its runqueue.",
            "\t\t\t */",
            "\t\t\tif (dl_time_before(p->dl.deadline,",
            "\t\t\t\t\t   src_rq->curr->dl.deadline))",
            "\t\t\t\tgoto skip;",
            "",
            "\t\t\tif (is_migration_disabled(p)) {",
            "\t\t\t\tpush_task = get_push_task(src_rq);",
            "\t\t\t} else {",
            "\t\t\t\tdeactivate_task(src_rq, p, 0);",
            "\t\t\t\tset_task_cpu(p, this_cpu);",
            "\t\t\t\tactivate_task(this_rq, p, 0);",
            "\t\t\t\tdmin = p->dl.deadline;",
            "\t\t\t\tresched = true;",
            "\t\t\t}",
            "",
            "\t\t\t/* Is there any other task even earlier? */",
            "\t\t}",
            "skip:",
            "\t\tdouble_unlock_balance(this_rq, src_rq);",
            "",
            "\t\tif (push_task) {",
            "\t\t\tpreempt_disable();",
            "\t\t\traw_spin_rq_unlock(this_rq);",
            "\t\t\tstop_one_cpu_nowait(src_rq->cpu, push_cpu_stop,",
            "\t\t\t\t\t    push_task, &src_rq->push_work);",
            "\t\t\tpreempt_enable();",
            "\t\t\traw_spin_rq_lock(this_rq);",
            "\t\t}",
            "\t}",
            "",
            "\tif (resched)",
            "\t\tresched_curr(this_rq);",
            "}"
          ],
          "function_name": "push_dl_task, push_dl_tasks, pull_dl_task",
          "description": "实现SCHED_DEADLINE任务的迁移逻辑，通过push_dl_task尝试将任务推送到更晚截止时间的CPU，pull_dl_task从过载CPU拉取任务以平衡负载",
          "similarity": 0.499131441116333
        },
        {
          "chunk_id": 17,
          "file_path": "kernel/sched/deadline.c",
          "start_line": 2887,
          "end_line": 3034,
          "content": [
            "static void task_woken_dl(struct rq *rq, struct task_struct *p)",
            "{",
            "\tif (!task_on_cpu(rq, p) &&",
            "\t    !test_tsk_need_resched(rq->curr) &&",
            "\t    p->nr_cpus_allowed > 1 &&",
            "\t    dl_task(rq->curr) &&",
            "\t    (rq->curr->nr_cpus_allowed < 2 ||",
            "\t     !dl_entity_preempt(&p->dl, &rq->curr->dl))) {",
            "\t\tpush_dl_tasks(rq);",
            "\t}",
            "}",
            "static void set_cpus_allowed_dl(struct task_struct *p,",
            "\t\t\t\tstruct affinity_context *ctx)",
            "{",
            "\tstruct root_domain *src_rd;",
            "\tstruct rq *rq;",
            "",
            "\tWARN_ON_ONCE(!dl_task(p));",
            "",
            "\trq = task_rq(p);",
            "\tsrc_rd = rq->rd;",
            "\t/*",
            "\t * Migrating a SCHED_DEADLINE task between exclusive",
            "\t * cpusets (different root_domains) entails a bandwidth",
            "\t * update. We already made space for us in the destination",
            "\t * domain (see cpuset_can_attach()).",
            "\t */",
            "\tif (!cpumask_intersects(src_rd->span, ctx->new_mask)) {",
            "\t\tstruct dl_bw *src_dl_b;",
            "",
            "\t\tsrc_dl_b = dl_bw_of(cpu_of(rq));",
            "\t\t/*",
            "\t\t * We now free resources of the root_domain we are migrating",
            "\t\t * off. In the worst case, sched_setattr() may temporary fail",
            "\t\t * until we complete the update.",
            "\t\t */",
            "\t\traw_spin_lock(&src_dl_b->lock);",
            "\t\t__dl_sub(src_dl_b, p->dl.dl_bw, dl_bw_cpus(task_cpu(p)));",
            "\t\traw_spin_unlock(&src_dl_b->lock);",
            "\t}",
            "",
            "\tset_cpus_allowed_common(p, ctx);",
            "}",
            "static void rq_online_dl(struct rq *rq)",
            "{",
            "\tif (rq->dl.overloaded)",
            "\t\tdl_set_overload(rq);",
            "",
            "\tcpudl_set_freecpu(&rq->rd->cpudl, rq->cpu);",
            "\tif (rq->dl.dl_nr_running > 0)",
            "\t\tcpudl_set(&rq->rd->cpudl, rq->cpu, rq->dl.earliest_dl.curr);",
            "}",
            "static void rq_offline_dl(struct rq *rq)",
            "{",
            "\tif (rq->dl.overloaded)",
            "\t\tdl_clear_overload(rq);",
            "",
            "\tcpudl_clear(&rq->rd->cpudl, rq->cpu);",
            "\tcpudl_clear_freecpu(&rq->rd->cpudl, rq->cpu);",
            "}",
            "void __init init_sched_dl_class(void)",
            "{",
            "\tunsigned int i;",
            "",
            "\tfor_each_possible_cpu(i)",
            "\t\tzalloc_cpumask_var_node(&per_cpu(local_cpu_mask_dl, i),",
            "\t\t\t\t\tGFP_KERNEL, cpu_to_node(i));",
            "}",
            "void dl_add_task_root_domain(struct task_struct *p)",
            "{",
            "\tstruct rq_flags rf;",
            "\tstruct rq *rq;",
            "\tstruct dl_bw *dl_b;",
            "",
            "\traw_spin_lock_irqsave(&p->pi_lock, rf.flags);",
            "\tif (!dl_task(p)) {",
            "\t\traw_spin_unlock_irqrestore(&p->pi_lock, rf.flags);",
            "\t\treturn;",
            "\t}",
            "",
            "\trq = __task_rq_lock(p, &rf);",
            "",
            "\tdl_b = &rq->rd->dl_bw;",
            "\traw_spin_lock(&dl_b->lock);",
            "",
            "\t__dl_add(dl_b, p->dl.dl_bw, cpumask_weight(rq->rd->span));",
            "",
            "\traw_spin_unlock(&dl_b->lock);",
            "",
            "\ttask_rq_unlock(rq, p, &rf);",
            "}",
            "void dl_clear_root_domain(struct root_domain *rd)",
            "{",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&rd->dl_bw.lock, flags);",
            "\trd->dl_bw.total_bw = 0;",
            "\traw_spin_unlock_irqrestore(&rd->dl_bw.lock, flags);",
            "}",
            "static void switched_from_dl(struct rq *rq, struct task_struct *p)",
            "{",
            "\t/*",
            "\t * task_non_contending() can start the \"inactive timer\" (if the 0-lag",
            "\t * time is in the future). If the task switches back to dl before",
            "\t * the \"inactive timer\" fires, it can continue to consume its current",
            "\t * runtime using its current deadline. If it stays outside of",
            "\t * SCHED_DEADLINE until the 0-lag time passes, inactive_task_timer()",
            "\t * will reset the task parameters.",
            "\t */",
            "\tif (task_on_rq_queued(p) && p->dl.dl_runtime)",
            "\t\ttask_non_contending(&p->dl);",
            "",
            "\t/*",
            "\t * In case a task is setscheduled out from SCHED_DEADLINE we need to",
            "\t * keep track of that on its cpuset (for correct bandwidth tracking).",
            "\t */",
            "\tdec_dl_tasks_cs(p);",
            "",
            "\tif (!task_on_rq_queued(p)) {",
            "\t\t/*",
            "\t\t * Inactive timer is armed. However, p is leaving DEADLINE and",
            "\t\t * might migrate away from this rq while continuing to run on",
            "\t\t * some other class. We need to remove its contribution from",
            "\t\t * this rq running_bw now, or sub_rq_bw (below) will complain.",
            "\t\t */",
            "\t\tif (p->dl.dl_non_contending)",
            "\t\t\tsub_running_bw(&p->dl, &rq->dl);",
            "\t\tsub_rq_bw(&p->dl, &rq->dl);",
            "\t}",
            "",
            "\t/*",
            "\t * We cannot use inactive_task_timer() to invoke sub_running_bw()",
            "\t * at the 0-lag time, because the task could have been migrated",
            "\t * while SCHED_OTHER in the meanwhile.",
            "\t */",
            "\tif (p->dl.dl_non_contending)",
            "\t\tp->dl.dl_non_contending = 0;",
            "",
            "\t/*",
            "\t * Since this might be the only -deadline task on the rq,",
            "\t * this is the right place to try to pull some other one",
            "\t * from an overloaded CPU, if any.",
            "\t */",
            "\tif (!task_on_rq_queued(p) || rq->dl.dl_nr_running)",
            "\t\treturn;",
            "",
            "\tdeadline_queue_pull_task(rq);",
            "}"
          ],
          "function_name": "task_woken_dl, set_cpus_allowed_dl, rq_online_dl, rq_offline_dl, init_sched_dl_class, dl_add_task_root_domain, dl_clear_root_domain, switched_from_dl",
          "description": "管理SCHED_DEADLINE任务唤醒后的处理、CPU亲和性变更、根域带宽分配及任务状态切换时的资源回收与重新计算",
          "similarity": 0.4925793409347534
        },
        {
          "chunk_id": 13,
          "file_path": "kernel/sched/deadline.c",
          "start_line": 2104,
          "end_line": 2251,
          "content": [
            "static void enqueue_task_dl(struct rq *rq, struct task_struct *p, int flags)",
            "{",
            "\tif (is_dl_boosted(&p->dl)) {",
            "\t\t/*",
            "\t\t * Because of delays in the detection of the overrun of a",
            "\t\t * thread's runtime, it might be the case that a thread",
            "\t\t * goes to sleep in a rt mutex with negative runtime. As",
            "\t\t * a consequence, the thread will be throttled.",
            "\t\t *",
            "\t\t * While waiting for the mutex, this thread can also be",
            "\t\t * boosted via PI, resulting in a thread that is throttled",
            "\t\t * and boosted at the same time.",
            "\t\t *",
            "\t\t * In this case, the boost overrides the throttle.",
            "\t\t */",
            "\t\tif (p->dl.dl_throttled) {",
            "\t\t\t/*",
            "\t\t\t * The replenish timer needs to be canceled. No",
            "\t\t\t * problem if it fires concurrently: boosted threads",
            "\t\t\t * are ignored in dl_task_timer().",
            "\t\t\t *",
            "\t\t\t * If the timer callback was running (hrtimer_try_to_cancel == -1),",
            "\t\t\t * it will eventually call put_task_struct().",
            "\t\t\t */",
            "\t\t\tif (hrtimer_try_to_cancel(&p->dl.dl_timer) == 1 &&",
            "\t\t\t    !dl_server(&p->dl))",
            "\t\t\t\tput_task_struct(p);",
            "\t\t\tp->dl.dl_throttled = 0;",
            "\t\t}",
            "\t} else if (!dl_prio(p->normal_prio)) {",
            "\t\t/*",
            "\t\t * Special case in which we have a !SCHED_DEADLINE task that is going",
            "\t\t * to be deboosted, but exceeds its runtime while doing so. No point in",
            "\t\t * replenishing it, as it's going to return back to its original",
            "\t\t * scheduling class after this. If it has been throttled, we need to",
            "\t\t * clear the flag, otherwise the task may wake up as throttled after",
            "\t\t * being boosted again with no means to replenish the runtime and clear",
            "\t\t * the throttle.",
            "\t\t */",
            "\t\tp->dl.dl_throttled = 0;",
            "\t\tif (!(flags & ENQUEUE_REPLENISH))",
            "\t\t\tprintk_deferred_once(\"sched: DL de-boosted task PID %d: REPLENISH flag missing\\n\",",
            "\t\t\t\t\t     task_pid_nr(p));",
            "",
            "\t\treturn;",
            "\t}",
            "",
            "\tcheck_schedstat_required();",
            "\tupdate_stats_wait_start_dl(dl_rq_of_se(&p->dl), &p->dl);",
            "",
            "\tif (p->on_rq == TASK_ON_RQ_MIGRATING)",
            "\t\tflags |= ENQUEUE_MIGRATING;",
            "",
            "\tenqueue_dl_entity(&p->dl, flags);",
            "",
            "\tif (dl_server(&p->dl))",
            "\t\treturn;",
            "",
            "\tif (!task_current(rq, p) && !p->dl.dl_throttled && p->nr_cpus_allowed > 1)",
            "\t\tenqueue_pushable_dl_task(rq, p);",
            "}",
            "static bool dequeue_task_dl(struct rq *rq, struct task_struct *p, int flags)",
            "{",
            "\tupdate_curr_dl(rq);",
            "",
            "\tif (p->on_rq == TASK_ON_RQ_MIGRATING)",
            "\t\tflags |= DEQUEUE_MIGRATING;",
            "",
            "\tdequeue_dl_entity(&p->dl, flags);",
            "\tif (!p->dl.dl_throttled && !dl_server(&p->dl))",
            "\t\tdequeue_pushable_dl_task(rq, p);",
            "",
            "\treturn true;",
            "}",
            "static void yield_task_dl(struct rq *rq)",
            "{",
            "\t/*",
            "\t * We make the task go to sleep until its current deadline by",
            "\t * forcing its runtime to zero. This way, update_curr_dl() stops",
            "\t * it and the bandwidth timer will wake it up and will give it",
            "\t * new scheduling parameters (thanks to dl_yielded=1).",
            "\t */",
            "\trq->curr->dl.dl_yielded = 1;",
            "",
            "\tupdate_rq_clock(rq);",
            "\tupdate_curr_dl(rq);",
            "\t/*",
            "\t * Tell update_rq_clock() that we've just updated,",
            "\t * so we don't do microscopic update in schedule()",
            "\t * and double the fastpath cost.",
            "\t */",
            "\trq_clock_skip_update(rq);",
            "}",
            "static inline bool dl_task_is_earliest_deadline(struct task_struct *p,",
            "\t\t\t\t\t\t struct rq *rq)",
            "{",
            "\treturn (!rq->dl.dl_nr_running ||",
            "\t\tdl_time_before(p->dl.deadline,",
            "\t\t\t       rq->dl.earliest_dl.curr));",
            "}",
            "static int",
            "select_task_rq_dl(struct task_struct *p, int cpu, int flags)",
            "{",
            "\tstruct task_struct *curr;",
            "\tbool select_rq;",
            "\tstruct rq *rq;",
            "",
            "\tif (!(flags & WF_TTWU))",
            "\t\tgoto out;",
            "",
            "\trq = cpu_rq(cpu);",
            "",
            "\trcu_read_lock();",
            "\tcurr = READ_ONCE(rq->curr); /* unlocked access */",
            "",
            "\t/*",
            "\t * If we are dealing with a -deadline task, we must",
            "\t * decide where to wake it up.",
            "\t * If it has a later deadline and the current task",
            "\t * on this rq can't move (provided the waking task",
            "\t * can!) we prefer to send it somewhere else. On the",
            "\t * other hand, if it has a shorter deadline, we",
            "\t * try to make it stay here, it might be important.",
            "\t */",
            "\tselect_rq = unlikely(dl_task(curr)) &&",
            "\t\t    (curr->nr_cpus_allowed < 2 ||",
            "\t\t     !dl_entity_preempt(&p->dl, &curr->dl)) &&",
            "\t\t    p->nr_cpus_allowed > 1;",
            "",
            "\t/*",
            "\t * Take the capacity of the CPU into account to",
            "\t * ensure it fits the requirement of the task.",
            "\t */",
            "\tif (sched_asym_cpucap_active())",
            "\t\tselect_rq |= !dl_task_fits_capacity(p, cpu);",
            "",
            "\tif (select_rq) {",
            "\t\tint target = find_later_rq(p);",
            "",
            "\t\tif (target != -1 &&",
            "\t\t    dl_task_is_earliest_deadline(p, cpu_rq(target)))",
            "\t\t\tcpu = target;",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "out:",
            "\treturn cpu;",
            "}"
          ],
          "function_name": "enqueue_task_dl, dequeue_task_dl, yield_task_dl, dl_task_is_earliest_deadline, select_task_rq_dl",
          "description": "处理截止时间任务的调度决策，包含任务入队出队、抢占检查、CPU选择及负载均衡逻辑，通过dl_task_is_earliest_deadline判断任务截止时间优先级并选择合适CPU",
          "similarity": 0.48900026082992554
        }
      ]
    },
    {
      "source_file": "kernel/bpf/dispatcher.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:10:06\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\dispatcher.c`\n\n---\n\n# `bpf/dispatcher.c` 技术文档\n\n## 1. 文件概述\n\n`bpf/dispatcher.c` 实现了 BPF（Berkeley Packet Filter）调度器（dispatcher）机制，其核心目标是通过生成多路分支的直接调用代码，避免在启用 retpoline（用于缓解 Spectre v2 攻击的间接跳转防护机制）时因间接调用带来的性能开销。该调度器通过劫持一个 trampoline 函数的 `__fentry__` 入口，动态生成包含多个 BPF 程序直接调用的跳转逻辑，从而将原本的间接调用转换为高效的直接调用。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct bpf_dispatcher`：BPF 调度器主结构体，包含：\n  - `progs[BPF_DISPATCHER_MAX]`：最多支持 `BPF_DISPATCHER_MAX` 个 BPF 程序的注册项\n  - `num_progs`：当前注册的程序数量\n  - `image` 和 `rw_image`：分别指向只读可执行（RO+X）和可读写（RW）的代码页\n  - `image_off`：用于双缓冲机制的偏移量\n  - `mutex`：保护调度器状态的互斥锁\n  - `ksym`：用于内核符号管理的 ksym 结构\n- `struct bpf_dispatcher_prog`：调度器中每个 BPF 程序的注册项，包含：\n  - `prog`：指向注册的 `struct bpf_prog`\n  - `users`：引用计数\n\n### 主要函数\n- `bpf_dispatcher_find_prog()`：在调度器中查找指定 BPF 程序的注册项\n- `bpf_dispatcher_find_free()`：查找空闲的注册槽位\n- `bpf_dispatcher_add_prog()`：向调度器注册一个 BPF 程序（带引用计数）\n- `bpf_dispatcher_remove_prog()`：从调度器注销一个 BPF 程序（引用计数减一，若为零则真正移除）\n- `arch_prepare_bpf_dispatcher()`（弱符号）：架构相关函数，用于生成实际的多路分支机器码\n- `bpf_dispatcher_prepare()`：准备调度器代码镜像，收集所有已注册 BPF 程序的入口地址\n- `bpf_dispatcher_update()`：更新调度器的可执行代码，使用双缓冲机制避免执行时修改代码\n- `bpf_dispatcher_change_prog()`：主入口函数，用于将一个 BPF 程序替换为另一个，并触发调度器代码更新\n\n## 3. 关键实现\n\n### 调度器工作原理\n调度器维护一个最多包含 `BPF_DISPATCHER_MAX` 个 BPF 程序的列表。当有程序注册或注销时，调度器会重新生成一段包含所有有效程序直接调用的机器码（多路分支），并通过 trampoline 机制被调用。\n\n### 双缓冲代码更新机制\n为避免在 CPU 执行调度器代码时修改代码页导致崩溃，采用双缓冲策略：\n- 调度器分配两个半页（共一页）的内存：`image`（RO+X）和 `rw_image`（RW）\n- `image_off` 在 `0` 和 `PAGE_SIZE/2` 之间切换，指示当前活跃的半页\n- 新代码先在 `rw_image` 的非活跃半页中生成，再通过 `bpf_arch_text_copy` 原子复制到 `image` 的对应位置\n- 调用 `synchronize_rcu()` 确保所有 CPU 退出旧代码后再切换活跃半页\n\n### 引用计数管理\n每个注册的 BPF 程序通过 `refcount_t users` 管理引用计数，允许多次注册同一程序（仅增加引用计数），只有当引用归零时才真正从调度器中移除并释放程序。\n\n### 架构无关与相关分离\n- 架构无关逻辑（如程序管理、缓冲区切换）在本文件实现\n- 架构相关代码生成由 `arch_prepare_bpf_dispatcher()` 实现（通常在 `arch/xxx/net/bpf_dispatcher.c` 中），若未实现则返回 `-ENOTSUPP`\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/hash.h>`：哈希辅助（虽未直接使用，但可能为未来扩展预留）\n  - `<linux/bpf.h>` 和 `<linux/filter.h>`：BPF 核心数据结构（`bpf_prog`、`bpf_insn` 等）\n  - `<linux/static_call.h>`：静态调用优化支持（用于 `__BPF_DISPATCHER_UPDATE` 宏）\n- **内核模块依赖**：\n  - BPF JIT 子系统：通过 `bpf_prog_pack_alloc()`、`bpf_jit_alloc_exec()` 分配可执行内存\n  - 内存管理：使用 `bpf_prog_inc()`/`bpf_prog_put()` 管理 BPF 程序生命周期\n  - RCU 机制：通过 `synchronize_rcu()` 实现安全的代码更新\n  - 架构特定代码复制：依赖 `bpf_arch_text_copy()`（通常基于 `text_poke()`）\n\n## 5. 使用场景\n\n- **BPF 程序热替换**：当 attach 到 tracepoint、kprobe、perf event 等的 BPF 程序被替换时，通过 `bpf_dispatcher_change_prog()` 更新调度器，避免间接调用开销。\n- **高性能 BPF 执行路径**：在需要极致性能的场景（如网络数据包处理、系统调用跟踪），调度器可显著提升 BPF 程序调用效率，尤其在启用 retpoline 的系统上。\n- **多程序共享调度器**：多个相同类型的 BPF 程序（如多个 socket filter）可共享同一个调度器实例，统一管理直接调用入口。",
      "similarity": 0.49775052070617676,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/bpf/dispatcher.c",
          "start_line": 43,
          "end_line": 166,
          "content": [
            "static bool bpf_dispatcher_add_prog(struct bpf_dispatcher *d,",
            "\t\t\t\t    struct bpf_prog *prog)",
            "{",
            "\tstruct bpf_dispatcher_prog *entry;",
            "",
            "\tif (!prog)",
            "\t\treturn false;",
            "",
            "\tentry = bpf_dispatcher_find_prog(d, prog);",
            "\tif (entry) {",
            "\t\trefcount_inc(&entry->users);",
            "\t\treturn false;",
            "\t}",
            "",
            "\tentry = bpf_dispatcher_find_free(d);",
            "\tif (!entry)",
            "\t\treturn false;",
            "",
            "\tbpf_prog_inc(prog);",
            "\tentry->prog = prog;",
            "\trefcount_set(&entry->users, 1);",
            "\td->num_progs++;",
            "\treturn true;",
            "}",
            "static bool bpf_dispatcher_remove_prog(struct bpf_dispatcher *d,",
            "\t\t\t\t       struct bpf_prog *prog)",
            "{",
            "\tstruct bpf_dispatcher_prog *entry;",
            "",
            "\tif (!prog)",
            "\t\treturn false;",
            "",
            "\tentry = bpf_dispatcher_find_prog(d, prog);",
            "\tif (!entry)",
            "\t\treturn false;",
            "",
            "\tif (refcount_dec_and_test(&entry->users)) {",
            "\t\tentry->prog = NULL;",
            "\t\tbpf_prog_put(prog);",
            "\t\td->num_progs--;",
            "\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "int __weak arch_prepare_bpf_dispatcher(void *image, void *buf, s64 *funcs, int num_funcs)",
            "{",
            "\treturn -ENOTSUPP;",
            "}",
            "static int bpf_dispatcher_prepare(struct bpf_dispatcher *d, void *image, void *buf)",
            "{",
            "\ts64 ips[BPF_DISPATCHER_MAX] = {}, *ipsp = &ips[0];",
            "\tint i;",
            "",
            "\tfor (i = 0; i < BPF_DISPATCHER_MAX; i++) {",
            "\t\tif (d->progs[i].prog)",
            "\t\t\t*ipsp++ = (s64)(uintptr_t)d->progs[i].prog->bpf_func;",
            "\t}",
            "\treturn arch_prepare_bpf_dispatcher(image, buf, &ips[0], d->num_progs);",
            "}",
            "static void bpf_dispatcher_update(struct bpf_dispatcher *d, int prev_num_progs)",
            "{",
            "\tvoid *new, *tmp;",
            "\tu32 noff = 0;",
            "",
            "\tif (prev_num_progs)",
            "\t\tnoff = d->image_off ^ (PAGE_SIZE / 2);",
            "",
            "\tnew = d->num_progs ? d->image + noff : NULL;",
            "\ttmp = d->num_progs ? d->rw_image + noff : NULL;",
            "\tif (new) {",
            "\t\t/* Prepare the dispatcher in d->rw_image. Then use",
            "\t\t * bpf_arch_text_copy to update d->image, which is RO+X.",
            "\t\t */",
            "\t\tif (bpf_dispatcher_prepare(d, new, tmp))",
            "\t\t\treturn;",
            "\t\tif (IS_ERR(bpf_arch_text_copy(new, tmp, PAGE_SIZE / 2)))",
            "\t\t\treturn;",
            "\t}",
            "",
            "\t__BPF_DISPATCHER_UPDATE(d, new ?: (void *)&bpf_dispatcher_nop_func);",
            "",
            "\t/* Make sure all the callers executing the previous/old half of the",
            "\t * image leave it, so following update call can modify it safely.",
            "\t */",
            "\tsynchronize_rcu();",
            "",
            "\tif (new)",
            "\t\td->image_off = noff;",
            "}",
            "void bpf_dispatcher_change_prog(struct bpf_dispatcher *d, struct bpf_prog *from,",
            "\t\t\t\tstruct bpf_prog *to)",
            "{",
            "\tbool changed = false;",
            "\tint prev_num_progs;",
            "",
            "\tif (from == to)",
            "\t\treturn;",
            "",
            "\tmutex_lock(&d->mutex);",
            "\tif (!d->image) {",
            "\t\td->image = bpf_prog_pack_alloc(PAGE_SIZE, bpf_jit_fill_hole_with_zero);",
            "\t\tif (!d->image)",
            "\t\t\tgoto out;",
            "\t\td->rw_image = bpf_jit_alloc_exec(PAGE_SIZE);",
            "\t\tif (!d->rw_image) {",
            "\t\t\tbpf_prog_pack_free(d->image, PAGE_SIZE);",
            "\t\t\td->image = NULL;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t\tbpf_image_ksym_init(d->image, PAGE_SIZE, &d->ksym);",
            "\t\tbpf_image_ksym_add(&d->ksym);",
            "\t}",
            "",
            "\tprev_num_progs = d->num_progs;",
            "\tchanged |= bpf_dispatcher_remove_prog(d, from);",
            "\tchanged |= bpf_dispatcher_add_prog(d, to);",
            "",
            "\tif (!changed)",
            "\t\tgoto out;",
            "",
            "\tbpf_dispatcher_update(d, prev_num_progs);",
            "out:",
            "\tmutex_unlock(&d->mutex);",
            "}"
          ],
          "function_name": "bpf_dispatcher_add_prog, bpf_dispatcher_remove_prog, arch_prepare_bpf_dispatcher, bpf_dispatcher_prepare, bpf_dispatcher_update, bpf_dispatcher_change_prog",
          "description": "该代码块实现了BPF调度器的增删改逻辑及图像更新。bpf_dispatcher_add_prog/bpf_dispatcher_remove_prog管理程序注册与解注册，arch_prepare_bpf_dispatcher为架构弱符号接口，bpf_dispatcher_prepare收集程序函数地址，bpf_dispatcher_update执行安全的图像更新，bpf_dispatcher_change_prog协调程序替换流程并触发更新操作。",
          "similarity": 0.45332396030426025
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/dispatcher.c",
          "start_line": 1,
          "end_line": 42,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/* Copyright(c) 2019 Intel Corporation. */",
            "",
            "#include <linux/hash.h>",
            "#include <linux/bpf.h>",
            "#include <linux/filter.h>",
            "#include <linux/static_call.h>",
            "",
            "/* The BPF dispatcher is a multiway branch code generator. The",
            " * dispatcher is a mechanism to avoid the performance penalty of an",
            " * indirect call, which is expensive when retpolines are enabled. A",
            " * dispatch client registers a BPF program into the dispatcher, and if",
            " * there is available room in the dispatcher a direct call to the BPF",
            " * program will be generated. All calls to the BPF programs called via",
            " * the dispatcher will then be a direct call, instead of an",
            " * indirect. The dispatcher hijacks a trampoline function it via the",
            " * __fentry__ of the trampoline. The trampoline function has the",
            " * following signature:",
            " *",
            " * unsigned int trampoline(const void *ctx, const struct bpf_insn *insnsi,",
            " *                         unsigned int (*bpf_func)(const void *,",
            " *                                                  const struct bpf_insn *));",
            " */",
            "",
            "static struct bpf_dispatcher_prog *bpf_dispatcher_find_prog(",
            "\tstruct bpf_dispatcher *d, struct bpf_prog *prog)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < BPF_DISPATCHER_MAX; i++) {",
            "\t\tif (prog == d->progs[i].prog)",
            "\t\t\treturn &d->progs[i];",
            "\t}",
            "\treturn NULL;",
            "}",
            "",
            "static struct bpf_dispatcher_prog *bpf_dispatcher_find_free(",
            "\tstruct bpf_dispatcher *d)",
            "{",
            "\treturn bpf_dispatcher_find_prog(d, NULL);",
            "}",
            ""
          ],
          "function_name": null,
          "description": "该代码块定义了BPF调度器的辅助函数，用于查找已注册的BPF程序或空闲槽位。bpf_dispatcher_find_prog遍历调度器槽位以匹配指定程序，返回对应项指针；bpf_dispatcher_find_free用于定位未占用的槽位，为后续程序注册做准备。",
          "similarity": 0.40678077936172485
        }
      ]
    }
  ]
}