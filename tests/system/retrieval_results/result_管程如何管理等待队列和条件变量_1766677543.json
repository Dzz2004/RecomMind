{
  "query": "管程如何管理等待队列和条件变量",
  "timestamp": "2025-12-25 23:45:43",
  "retrieved_files": [
    {
      "source_file": "kernel/watch_queue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:50:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `watch_queue.c`\n\n---\n\n# watch_queue.c 技术文档\n\n## 文件概述\n\n`watch_queue.c` 实现了 Linux 内核中的**监视队列**（Watch Queue）机制，这是一种基于管道（pipe）构建的通用事件通知系统。该机制允许内核子系统（如文件系统、密钥管理、设备驱动等）向用户空间异步发送结构化通知。用户空间通过创建特殊类型的管道并关联监视队列，即可接收来自内核的各类事件通知。该文件定义了通知的投递、过滤、缓冲管理及与管道集成的核心逻辑。\n\n## 核心功能\n\n### 主要函数\n\n- **`__post_watch_notification()`**  \n  核心通知投递函数。遍历指定 `watch_list` 中所有匹配 `id` 的监视器（`watch`），对每个关联的 `watch_queue` 应用过滤规则、安全检查，并将通知写入底层管道。\n\n- **`post_one_notification()`**  \n  将单个通知写入指定 `watch_queue` 的底层管道缓冲区。负责从预分配的通知页中获取空闲槽位、填充数据、更新管道头指针并唤醒等待读取的进程。\n\n- **`filter_watch_notification()`**  \n  根据 `watch_filter` 中的类型、子类型和信息掩码规则，判断是否允许特定通知通过。\n\n- **`watch_queue_set_size()`**  \n  为监视队列分配预分配的通知缓冲区（页数组和位图），并调整底层管道的环形缓冲区大小。\n\n- **`watch_queue_pipe_buf_release()`**  \n  管道缓冲区释放回调。当用户空间读取完通知后，将对应的通知槽位在位图中标记为空闲，供后续复用。\n\n### 关键数据结构\n\n- **`struct watch_queue`**  \n  表示一个监视队列，包含：\n  - 指向底层 `pipe_inode_info` 的指针\n  - 预分配的通知页数组（`notes`）\n  - 通知槽位空闲位图（`notes_bitmap`）\n  - 通知过滤器（`filter`）\n  - 保护锁（`lock`）\n\n- **`struct watch_notification`**  \n  通用通知记录格式，包含类型（`type`）、子类型（`subtype`）、信息字段（`info`，含长度和ID）及可变负载。\n\n- **`struct watch_filter` / `struct watch_type_filter`**  \n  定义通知过滤规则，支持按类型、子类型及信息字段的位掩码进行精确过滤。\n\n- **`watch_queue_pipe_buf_ops`**  \n  自定义的 `pipe_buf_operations`，用于管理监视队列专用管道缓冲区的生命周期。\n\n## 关键实现\n\n### 基于管道的通知传输\n- 监视队列复用内核管道（`pipe_inode_info`）作为通知传输通道，利用其成熟的读写、轮询、异步通知机制。\n- 通过自定义 `pipe_buf_operations`（`watch_queue_pipe_buf_ops`）实现通知槽位的回收：当用户读取通知后，`release` 回调将对应槽位在 `notes_bitmap` 中置位，标记为空闲。\n\n### 预分配通知缓冲区\n- 通知数据存储在预分配的内核页（`notes`）中，每页划分为多个固定大小（128字节）的槽位（`WATCH_QUEUE_NOTE_SIZE`）。\n- 使用位图（`notes_bitmap`）跟踪槽位使用状态，1 表示空闲。投递通知时通过 `find_first_bit()` 快速查找空闲槽位。\n- 缓冲区大小由用户通过 `watch_queue_set_size()` 设置（1-512个通知），并受管道缓冲区配额限制。\n\n### 通知投递流程\n1. **匹配监视器**：遍历 `watch_list`，查找 `id` 匹配的 `watch`。\n2. **应用过滤**：若队列配置了过滤器，调用 `filter_watch_notification()` 决定是否丢弃。\n3. **安全检查**：调用 LSM 钩子 `security_post_notification()` 进行权限验证。\n4. **写入管道**：\n   - 获取空闲通知槽位，复制通知数据。\n   - 构造 `pipe_buffer` 指向该槽位，设置自定义操作集。\n   - 更新管道 `head` 指针，唤醒等待读取的进程。\n   - 若缓冲区满，标记前一个缓冲区为 `PIPE_BUF_FLAG_LOSS` 表示丢包。\n\n### 并发与同步\n- **RCU 保护**：`watch_list` 和 `watch_queue` 的访问通过 RCU 机制保护，确保遍历时结构体不被释放。\n- **自旋锁**：\n  - `wqueue->lock`：保护 `wqueue` 状态（如 `pipe` 指针有效性）。\n  - `pipe->rd_wait.lock`：保护管道环形缓冲区的读写操作。\n- **原子操作**：管道 `head` 指针使用 `smp_store_release()` 更新，确保与 `pipe_read()` 的同步。\n\n## 依赖关系\n\n- **管道子系统**（`fs/pipe.c`）  \n  依赖管道的核心数据结构（`pipe_inode_info`、`pipe_buffer`）和操作接口（`pipe_buf()`、`pipe_full()`、`generic_pipe_buf_*`）。\n\n- **内存管理**  \n  使用 `alloc_page()`、`kmap_atomic()` 管理通知缓冲区页，`bitmap_alloc()` 管理槽位位图。\n\n- **安全模块**（LSM）  \n  通过 `security_post_notification()` 钩子集成安全策略。\n\n- **用户空间接口**  \n  与 `fs/watch_queue.c` 中的系统调用（如 `watch_queue_set_size()`）协同工作，后者负责创建监视队列并与管道关联。\n\n- **头文件依赖**  \n  `linux/watch_queue.h`（核心数据结构定义）、`linux/pipe_fs_i.h`（管道内部接口）。\n\n## 使用场景\n\n- **文件系统事件监控**  \n  如 `fsnotify` 子系统可通过监视队列向用户空间报告文件访问、修改等事件。\n\n- **密钥管理通知**  \n  内核密钥环（`KEYS`）子系统使用该机制通知密钥状态变更（如过期、撤销）。\n\n- **设备事件上报**  \n  设备驱动可利用监视队列异步上报硬件状态变化或错误事件。\n\n- **通用内核事件分发**  \n  任何需要向特权用户空间守护进程（如 `systemd`）发送结构化事件的内核子系统均可集成此机制。\n\n- **用户空间消费**  \n  应用程序通过 `open(\"/dev/watch_queue\")` 获取监视队列文件描述符，调用 `ioctl()` 设置缓冲区大小和过滤器，然后像读取普通管道一样接收通知。",
      "similarity": 0.6097899675369263,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/watch_queue.c",
          "start_line": 42,
          "end_line": 154,
          "content": [
            "static inline bool lock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_lock_bh(&wqueue->lock);",
            "\tif (unlikely(!wqueue->pipe)) {",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "\t\treturn false;",
            "\t}",
            "\treturn true;",
            "}",
            "static inline void unlock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_unlock_bh(&wqueue->lock);",
            "}",
            "static void watch_queue_pipe_buf_release(struct pipe_inode_info *pipe,",
            "\t\t\t\t\t struct pipe_buffer *buf)",
            "{",
            "\tstruct watch_queue *wqueue = (struct watch_queue *)buf->private;",
            "\tstruct page *page;",
            "\tunsigned int bit;",
            "",
            "\t/* We need to work out which note within the page this refers to, but",
            "\t * the note might have been maximum size, so merely ANDing the offset",
            "\t * off doesn't work.  OTOH, the note must've been more than zero size.",
            "\t */",
            "\tbit = buf->offset + buf->len;",
            "\tif ((bit & (WATCH_QUEUE_NOTE_SIZE - 1)) == 0)",
            "\t\tbit -= WATCH_QUEUE_NOTE_SIZE;",
            "\tbit /= WATCH_QUEUE_NOTE_SIZE;",
            "",
            "\tpage = buf->page;",
            "\tbit += page->index;",
            "",
            "\tset_bit(bit, wqueue->notes_bitmap);",
            "\tgeneric_pipe_buf_release(pipe, buf);",
            "}",
            "static bool post_one_notification(struct watch_queue *wqueue,",
            "\t\t\t\t  struct watch_notification *n)",
            "{",
            "\tvoid *p;",
            "\tstruct pipe_inode_info *pipe = wqueue->pipe;",
            "\tstruct pipe_buffer *buf;",
            "\tstruct page *page;",
            "\tunsigned int head, tail, note, offset, len;",
            "\tbool done = false;",
            "",
            "\tspin_lock_irq(&pipe->rd_wait.lock);",
            "",
            "\thead = pipe->head;",
            "\ttail = pipe->tail;",
            "\tif (pipe_full(head, tail, pipe->ring_size))",
            "\t\tgoto lost;",
            "",
            "\tnote = find_first_bit(wqueue->notes_bitmap, wqueue->nr_notes);",
            "\tif (note >= wqueue->nr_notes)",
            "\t\tgoto lost;",
            "",
            "\tpage = wqueue->notes[note / WATCH_QUEUE_NOTES_PER_PAGE];",
            "\toffset = note % WATCH_QUEUE_NOTES_PER_PAGE * WATCH_QUEUE_NOTE_SIZE;",
            "\tget_page(page);",
            "\tlen = n->info & WATCH_INFO_LENGTH;",
            "\tp = kmap_atomic(page);",
            "\tmemcpy(p + offset, n, len);",
            "\tkunmap_atomic(p);",
            "",
            "\tbuf = pipe_buf(pipe, head);",
            "\tbuf->page = page;",
            "\tbuf->private = (unsigned long)wqueue;",
            "\tbuf->ops = &watch_queue_pipe_buf_ops;",
            "\tbuf->offset = offset;",
            "\tbuf->len = len;",
            "\tbuf->flags = PIPE_BUF_FLAG_WHOLE;",
            "\tsmp_store_release(&pipe->head, head + 1); /* vs pipe_read() */",
            "",
            "\tif (!test_and_clear_bit(note, wqueue->notes_bitmap)) {",
            "\t\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\t\tBUG();",
            "\t}",
            "\twake_up_interruptible_sync_poll_locked(&pipe->rd_wait, EPOLLIN | EPOLLRDNORM);",
            "\tdone = true;",
            "",
            "out:",
            "\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\tif (done)",
            "\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);",
            "\treturn done;",
            "",
            "lost:",
            "\tbuf = pipe_buf(pipe, head - 1);",
            "\tbuf->flags |= PIPE_BUF_FLAG_LOSS;",
            "\tgoto out;",
            "}",
            "static bool filter_watch_notification(const struct watch_filter *wf,",
            "\t\t\t\t      const struct watch_notification *n)",
            "{",
            "\tconst struct watch_type_filter *wt;",
            "\tunsigned int st_bits = sizeof(wt->subtype_filter[0]) * 8;",
            "\tunsigned int st_index = n->subtype / st_bits;",
            "\tunsigned int st_bit = 1U << (n->subtype % st_bits);",
            "\tint i;",
            "",
            "\tif (!test_bit(n->type, wf->type_filter))",
            "\t\treturn false;",
            "",
            "\tfor (i = 0; i < wf->nr_filters; i++) {",
            "\t\twt = &wf->filters[i];",
            "\t\tif (n->type == wt->type &&",
            "\t\t    (wt->subtype_filter[st_index] & st_bit) &&",
            "\t\t    (n->info & wt->info_mask) == wt->info_filter)",
            "\t\t\treturn true;",
            "\t}",
            "",
            "\treturn false; /* If there is a filter, the default is to reject. */",
            "}"
          ],
          "function_name": "lock_wqueue, unlock_wqueue, watch_queue_pipe_buf_release, post_one_notification, filter_watch_notification",
          "description": "实现了watch_queue的锁操作、缓冲区释放、通知提交及过滤逻辑。lock_wqueue/unlock_wqueue用于保护队列访问，watch_queue_pipe_buf_release处理缓冲区回收并更新位图，post_one_notification将通知数据写入管道，filter_watch_notification进行类型和子类型的匹配判断。",
          "similarity": 0.5940708518028259
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/watch_queue.c",
          "start_line": 602,
          "end_line": 680,
          "content": [
            "void watch_queue_clear(struct watch_queue *wqueue)",
            "{",
            "\tstruct watch_list *wlist;",
            "\tstruct watch *watch;",
            "\tbool release;",
            "",
            "\trcu_read_lock();",
            "\tspin_lock_bh(&wqueue->lock);",
            "",
            "\t/*",
            "\t * This pipe can be freed by callers like free_pipe_info().",
            "\t * Removing this reference also prevents new notifications.",
            "\t */",
            "\twqueue->pipe = NULL;",
            "",
            "\twhile (!hlist_empty(&wqueue->watches)) {",
            "\t\twatch = hlist_entry(wqueue->watches.first, struct watch, queue_node);",
            "\t\thlist_del_init_rcu(&watch->queue_node);",
            "\t\t/* We now own a ref on the watch. */",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "",
            "\t\t/* We can't do the next bit under the queue lock as we need to",
            "\t\t * get the list lock - which would cause a deadlock if someone",
            "\t\t * was removing from the opposite direction at the same time or",
            "\t\t * posting a notification.",
            "\t\t */",
            "\t\twlist = rcu_dereference(watch->watch_list);",
            "\t\tif (wlist) {",
            "\t\t\tvoid (*release_watch)(struct watch *);",
            "",
            "\t\t\tspin_lock(&wlist->lock);",
            "",
            "\t\t\trelease = !hlist_unhashed(&watch->list_node);",
            "\t\t\tif (release) {",
            "\t\t\t\thlist_del_init_rcu(&watch->list_node);",
            "\t\t\t\trcu_assign_pointer(watch->watch_list, NULL);",
            "",
            "\t\t\t\t/* We now own a second ref on the watch. */",
            "\t\t\t}",
            "",
            "\t\t\trelease_watch = wlist->release_watch;",
            "\t\t\tspin_unlock(&wlist->lock);",
            "",
            "\t\t\tif (release) {",
            "\t\t\t\tif (release_watch) {",
            "\t\t\t\t\trcu_read_unlock();",
            "\t\t\t\t\t/* This might need to call dput(), so",
            "\t\t\t\t\t * we have to drop all the locks.",
            "\t\t\t\t\t */",
            "\t\t\t\t\t(*release_watch)(watch);",
            "\t\t\t\t\trcu_read_lock();",
            "\t\t\t\t}",
            "\t\t\t\tput_watch(watch);",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tput_watch(watch);",
            "\t\tspin_lock_bh(&wqueue->lock);",
            "\t}",
            "",
            "\tspin_unlock_bh(&wqueue->lock);",
            "\trcu_read_unlock();",
            "}",
            "int watch_queue_init(struct pipe_inode_info *pipe)",
            "{",
            "\tstruct watch_queue *wqueue;",
            "",
            "\twqueue = kzalloc(sizeof(*wqueue), GFP_KERNEL);",
            "\tif (!wqueue)",
            "\t\treturn -ENOMEM;",
            "",
            "\twqueue->pipe = pipe;",
            "\tkref_init(&wqueue->usage);",
            "\tspin_lock_init(&wqueue->lock);",
            "\tINIT_HLIST_HEAD(&wqueue->watches);",
            "",
            "\tpipe->watch_queue = wqueue;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "watch_queue_clear, watch_queue_init",
          "description": "该代码实现了监视队列的初始化与清理功能。  \n`watch_queue_clear`通过RCU和自旋锁机制安全地移除所有监视项并释放资源，`watch_queue_init`初始化监视队列结构并绑定至管道对象。  \n上下文不完整：`release_watch`等关键函数依赖外部定义，部分RCU回调逻辑未完全展示。",
          "similarity": 0.5723839402198792
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/watch_queue.c",
          "start_line": 315,
          "end_line": 422,
          "content": [
            "long watch_queue_set_filter(struct pipe_inode_info *pipe,",
            "\t\t\t    struct watch_notification_filter __user *_filter)",
            "{",
            "\tstruct watch_notification_type_filter *tf;",
            "\tstruct watch_notification_filter filter;",
            "\tstruct watch_type_filter *q;",
            "\tstruct watch_filter *wfilter;",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tint ret, nr_filter = 0, i;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "",
            "\tif (!_filter) {",
            "\t\t/* Remove the old filter */",
            "\t\twfilter = NULL;",
            "\t\tgoto set;",
            "\t}",
            "",
            "\t/* Grab the user's filter specification */",
            "\tif (copy_from_user(&filter, _filter, sizeof(filter)) != 0)",
            "\t\treturn -EFAULT;",
            "\tif (filter.nr_filters == 0 ||",
            "\t    filter.nr_filters > 16 ||",
            "\t    filter.__reserved != 0)",
            "\t\treturn -EINVAL;",
            "",
            "\ttf = memdup_array_user(_filter->filters, filter.nr_filters, sizeof(*tf));",
            "\tif (IS_ERR(tf))",
            "\t\treturn PTR_ERR(tf);",
            "",
            "\tret = -EINVAL;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif ((tf[i].info_filter & ~tf[i].info_mask) ||",
            "\t\t    tf[i].info_mask & WATCH_INFO_LENGTH)",
            "\t\t\tgoto err_filter;",
            "\t\t/* Ignore any unknown types */",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "\t\tnr_filter++;",
            "\t}",
            "",
            "\t/* Now we need to build the internal filter from only the relevant",
            "\t * user-specified filters.",
            "\t */",
            "\tret = -ENOMEM;",
            "\twfilter = kzalloc(struct_size(wfilter, filters, nr_filter), GFP_KERNEL);",
            "\tif (!wfilter)",
            "\t\tgoto err_filter;",
            "\twfilter->nr_filters = nr_filter;",
            "",
            "\tq = wfilter->filters;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "",
            "\t\tq->type\t\t\t= tf[i].type;",
            "\t\tq->info_filter\t\t= tf[i].info_filter;",
            "\t\tq->info_mask\t\t= tf[i].info_mask;",
            "\t\tq->subtype_filter[0]\t= tf[i].subtype_filter[0];",
            "\t\t__set_bit(q->type, wfilter->type_filter);",
            "\t\tq++;",
            "\t}",
            "",
            "\tkfree(tf);",
            "set:",
            "\tpipe_lock(pipe);",
            "\twfilter = rcu_replace_pointer(wqueue->filter, wfilter,",
            "\t\t\t\t      lockdep_is_held(&pipe->mutex));",
            "\tpipe_unlock(pipe);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\treturn 0;",
            "",
            "err_filter:",
            "\tkfree(tf);",
            "\treturn ret;",
            "}",
            "static void __put_watch_queue(struct kref *kref)",
            "{",
            "\tstruct watch_queue *wqueue =",
            "\t\tcontainer_of(kref, struct watch_queue, usage);",
            "\tstruct watch_filter *wfilter;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < wqueue->nr_pages; i++)",
            "\t\t__free_page(wqueue->notes[i]);",
            "\tkfree(wqueue->notes);",
            "\tbitmap_free(wqueue->notes_bitmap);",
            "",
            "\twfilter = rcu_access_pointer(wqueue->filter);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\tkfree_rcu(wqueue, rcu);",
            "}",
            "void put_watch_queue(struct watch_queue *wqueue)",
            "{",
            "\tkref_put(&wqueue->usage, __put_watch_queue);",
            "}",
            "static void free_watch(struct rcu_head *rcu)",
            "{",
            "\tstruct watch *watch = container_of(rcu, struct watch, rcu);",
            "",
            "\tput_watch_queue(rcu_access_pointer(watch->queue));",
            "\tatomic_dec(&watch->cred->user->nr_watches);",
            "\tput_cred(watch->cred);",
            "\tkfree(watch);",
            "}"
          ],
          "function_name": "watch_queue_set_filter, __put_watch_queue, put_watch_queue, free_watch",
          "description": "watch_queue_set_filter设置过滤规则并转换为内核内部结构，__put_watch_queue释放watch_queue相关资源包括页面、位图和过滤器，put_watch_queue通过引用计数管理watch_queue生命周期，free_watch执行RCU回调完成最终释放。",
          "similarity": 0.5594894886016846
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/watch_queue.c",
          "start_line": 193,
          "end_line": 304,
          "content": [
            "void __post_watch_notification(struct watch_list *wlist,",
            "\t\t\t       struct watch_notification *n,",
            "\t\t\t       const struct cred *cred,",
            "\t\t\t       u64 id)",
            "{",
            "\tconst struct watch_filter *wf;",
            "\tstruct watch_queue *wqueue;",
            "\tstruct watch *watch;",
            "",
            "\tif (((n->info & WATCH_INFO_LENGTH) >> WATCH_INFO_LENGTH__SHIFT) == 0) {",
            "\t\tWARN_ON(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\trcu_read_lock();",
            "",
            "\thlist_for_each_entry_rcu(watch, &wlist->watchers, list_node) {",
            "\t\tif (watch->id != id)",
            "\t\t\tcontinue;",
            "\t\tn->info &= ~WATCH_INFO_ID;",
            "\t\tn->info |= watch->info_id;",
            "",
            "\t\twqueue = rcu_dereference(watch->queue);",
            "\t\twf = rcu_dereference(wqueue->filter);",
            "\t\tif (wf && !filter_watch_notification(wf, n))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (security_post_notification(watch->cred, cred, n) < 0)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (lock_wqueue(wqueue)) {",
            "\t\t\tpost_one_notification(wqueue, n);",
            "\t\t\tunlock_wqueue(wqueue);",
            "\t\t}",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "}",
            "long watch_queue_set_size(struct pipe_inode_info *pipe, unsigned int nr_notes)",
            "{",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tstruct page **pages;",
            "\tunsigned long *bitmap;",
            "\tunsigned long user_bufs;",
            "\tint ret, i, nr_pages;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "\tif (wqueue->notes)",
            "\t\treturn -EBUSY;",
            "",
            "\tif (nr_notes < 1 ||",
            "\t    nr_notes > 512) /* TODO: choose a better hard limit */",
            "\t\treturn -EINVAL;",
            "",
            "\tnr_pages = (nr_notes + WATCH_QUEUE_NOTES_PER_PAGE - 1);",
            "\tnr_pages /= WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tuser_bufs = account_pipe_buffers(pipe->user, pipe->nr_accounted, nr_pages);",
            "",
            "\tif (nr_pages > pipe->max_usage &&",
            "\t    (too_many_pipe_buffers_hard(user_bufs) ||",
            "\t     too_many_pipe_buffers_soft(user_bufs)) &&",
            "\t    pipe_is_unprivileged_user()) {",
            "\t\tret = -EPERM;",
            "\t\tgoto error;",
            "\t}",
            "",
            "\tnr_notes = nr_pages * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tret = pipe_resize_ring(pipe, roundup_pow_of_two(nr_notes));",
            "\tif (ret < 0)",
            "\t\tgoto error;",
            "",
            "\t/*",
            "\t * pipe_resize_ring() does not update nr_accounted for watch_queue",
            "\t * pipes, because the above vastly overprovisions. Set nr_accounted on",
            "\t * and max_usage this pipe to the number that was actually charged to",
            "\t * the user above via account_pipe_buffers.",
            "\t */",
            "\tpipe->max_usage = nr_pages;",
            "\tpipe->nr_accounted = nr_pages;",
            "",
            "\tret = -ENOMEM;",
            "\tpages = kcalloc(sizeof(struct page *), nr_pages, GFP_KERNEL);",
            "\tif (!pages)",
            "\t\tgoto error;",
            "",
            "\tfor (i = 0; i < nr_pages; i++) {",
            "\t\tpages[i] = alloc_page(GFP_KERNEL);",
            "\t\tif (!pages[i])",
            "\t\t\tgoto error_p;",
            "\t\tpages[i]->index = i * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\t}",
            "",
            "\tbitmap = bitmap_alloc(nr_notes, GFP_KERNEL);",
            "\tif (!bitmap)",
            "\t\tgoto error_p;",
            "",
            "\tbitmap_fill(bitmap, nr_notes);",
            "\twqueue->notes = pages;",
            "\twqueue->notes_bitmap = bitmap;",
            "\twqueue->nr_pages = nr_pages;",
            "\twqueue->nr_notes = nr_notes;",
            "\treturn 0;",
            "",
            "error_p:",
            "\twhile (--i >= 0)",
            "\t\t__free_page(pages[i]);",
            "\tkfree(pages);",
            "error:",
            "\t(void) account_pipe_buffers(pipe->user, nr_pages, pipe->nr_accounted);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__post_watch_notification, watch_queue_set_size",
          "description": "__post_watch_notification遍历watch列表并应用过滤器后提交通知，watch_queue_set_size动态调整管道容量，通过计算所需页数和位图分配，限制最大容量为512个笔记，支持扩展性需求。",
          "similarity": 0.5333130359649658
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/watch_queue.c",
          "start_line": 1,
          "end_line": 41,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/* Watch queue and general notification mechanism, built on pipes",
            " *",
            " * Copyright (C) 2020 Red Hat, Inc. All Rights Reserved.",
            " * Written by David Howells (dhowells@redhat.com)",
            " *",
            " * See Documentation/core-api/watch_queue.rst",
            " */",
            "",
            "#define pr_fmt(fmt) \"watchq: \" fmt",
            "#include <linux/module.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/printk.h>",
            "#include <linux/miscdevice.h>",
            "#include <linux/fs.h>",
            "#include <linux/mm.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/poll.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <linux/security.h>",
            "#include <linux/cred.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/watch_queue.h>",
            "#include <linux/pipe_fs_i.h>",
            "",
            "MODULE_DESCRIPTION(\"Watch queue\");",
            "MODULE_AUTHOR(\"Red Hat, Inc.\");",
            "",
            "#define WATCH_QUEUE_NOTE_SIZE 128",
            "#define WATCH_QUEUE_NOTES_PER_PAGE (PAGE_SIZE / WATCH_QUEUE_NOTE_SIZE)",
            "",
            "/*",
            " * This must be called under the RCU read-lock, which makes",
            " * sure that the wqueue still exists. It can then take the lock,",
            " * and check that the wqueue hasn't been destroyed, which in",
            " * turn makes sure that the notification pipe still exists.",
            " */"
          ],
          "function_name": null,
          "description": "定义了watch_queue模块的头部信息，包含常量WATCH_QUEUE_NOTE_SIZE和NOTES_PER_PAGE，声明模块许可证及作者信息，并引入相关内核头文件，为后续实现提供基础框架。",
          "similarity": 0.5315037965774536
        }
      ]
    },
    {
      "source_file": "kernel/sched/wait.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:20:46\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\wait.c`\n\n---\n\n# `sched/wait.c` 技术文档\n\n## 1. 文件概述\n\n`sched/wait.c` 是 Linux 内核中实现通用等待队列（wait queue）机制的核心文件。该机制用于线程在特定条件满足前进入睡眠状态，并在条件就绪时被唤醒。文件提供了等待队列的初始化、添加/移除等待项、以及多种唤醒策略（包括普通唤醒、独占唤醒、优先级唤醒、同步唤醒等）的实现，是内核同步与调度子系统的重要组成部分。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`__init_waitqueue_head`**  \n  初始化一个等待队列头，设置自旋锁、锁类信息和空链表。\n\n- **`add_wait_queue`**  \n  将一个非独占等待项添加到等待队列头部。\n\n- **`add_wait_queue_exclusive`**  \n  将一个独占等待项添加到等待队列尾部（用于避免“惊群”问题）。\n\n- **`add_wait_queue_priority`**  \n  添加具有独占性和优先级标志的等待项，插入到队列头部。\n\n- **`remove_wait_queue`**  \n  从等待队列中安全移除指定的等待项。\n\n- **`__wake_up` / `__wake_up_common`**  \n  核心唤醒函数，支持唤醒非独占任务和指定数量的独占任务。\n\n- **`__wake_up_sync_key` / `__wake_up_locked_sync_key`**  \n  同步唤醒函数，避免目标任务被迁移到其他 CPU，减少缓存颠簸。\n\n- **`__wake_up_on_current_cpu`**  \n  仅在当前 CPU 上唤醒一个任务。\n\n- **`__wake_up_pollfree`**  \n  专用于 poll 机制的唤醒，发送 `POLLFREE` 事件并验证队列已清空。\n\n- **`prepare_to_wait` / `prepare_to_wait_exclusive`**  \n  将当前任务加入等待队列并设置其睡眠状态，后者返回是否为队列中首个等待者。\n\n### 关键数据结构\n\n- **`struct wait_queue_head`**  \n  等待队列头，包含自旋锁 `lock` 和双向链表 `head`。\n\n- **`struct wait_queue_entry`**  \n  等待队列项，包含回调函数 `func`、任务指针、标志位（如 `WQ_FLAG_EXCLUSIVE`、`WQ_FLAG_PRIORITY`）及链表节点。\n\n## 3. 关键实现\n\n### 等待队列组织策略\n\n- **非独占任务**：通过 `add_wait_queue` 添加至队列**头部**，唤醒时优先处理。\n- **独占任务**：通过 `add_wait_queue_exclusive` 添加至队列**尾部**，确保在非独占任务之后唤醒，避免多个独占任务同时被唤醒（解决“惊群”问题）。\n- **优先级任务**：通过 `add_wait_queue_priority` 添加至**头部**，并标记为独占+优先级，可在唤醒时优先消费事件。\n\n### 唤醒逻辑（`__wake_up_common`）\n\n1. 遍历等待队列中的每个等待项。\n2. 调用其回调函数 `func`（通常为 `default_wake_function`），尝试唤醒对应任务。\n3. 若回调返回正值且该项为独占任务，则减少 `nr_exclusive` 计数；当计数归零时停止唤醒。\n4. 非独占任务始终被唤醒（除非回调返回负值中断流程）。\n\n### 内存屏障与 SMP 安全\n\n- 在 `prepare_to_wait` 中，**先加锁添加等待项，再调用 `set_current_state()`**，确保 SMP 系统下唤醒者能看到完整的等待状态，避免竞态。\n- 所有对外接口均使用 `spin_lock_irqsave`/`restore` 保证中断上下文安全。\n\n### 同步唤醒优化\n\n- `WF_SYNC` 标志告知调度器：唤醒者即将主动调度（如调用 `schedule()`），因此被唤醒任务应尽量留在当前 CPU，减少迁移开销。\n- 在单处理器（UP）系统上可避免不必要的抢占。\n\n## 4. 依赖关系\n\n- **调度子系统**：依赖 `try_to_wake_up()` 等底层唤醒函数（定义于 `kernel/sched/core.c`）。\n- **锁调试机制**：使用 `lockdep_set_class_and_name` 进行锁类跟踪（`kernel/locking/lockdep.c`）。\n- **内存屏障原语**：依赖架构相关的内存屏障实现（如 `smp_mb()`）。\n- **poll 机制**：`__wake_up_pollfree` 与 `fs/select.c` 中的 poll 实现紧密耦合。\n- **EXPORT_SYMBOL**：向内核其他模块（如驱动、文件系统）导出通用等待/唤醒接口。\n\n## 5. 使用场景\n\n- **设备驱动**：驱动程序在无数据可读/写时将进程加入等待队列，硬件就绪时唤醒。\n- **文件系统**：如 inode 锁、页缓存 I/O 等待。\n- **IPC 机制**：信号量、互斥锁、完成量（completion）等同步原语的底层实现。\n- **网络子系统**：socket 接收/发送缓冲区满或空时的阻塞等待。\n- **内核线程同步**：工作者线程等待工作项到达。\n- **poll/epoll**：通过 `poll_wait()` 注册等待队列，事件触发时唤醒用户进程。",
      "similarity": 0.5890638828277588,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/wait.c",
          "start_line": 8,
          "end_line": 111,
          "content": [
            "void __init_waitqueue_head(struct wait_queue_head *wq_head, const char *name, struct lock_class_key *key)",
            "{",
            "\tspin_lock_init(&wq_head->lock);",
            "\tlockdep_set_class_and_name(&wq_head->lock, key, name);",
            "\tINIT_LIST_HEAD(&wq_head->head);",
            "}",
            "void add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)",
            "{",
            "\tunsigned long flags;",
            "",
            "\twq_entry->flags &= ~WQ_FLAG_EXCLUSIVE;",
            "\tspin_lock_irqsave(&wq_head->lock, flags);",
            "\t__add_wait_queue(wq_head, wq_entry);",
            "\tspin_unlock_irqrestore(&wq_head->lock, flags);",
            "}",
            "void add_wait_queue_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)",
            "{",
            "\tunsigned long flags;",
            "",
            "\twq_entry->flags |= WQ_FLAG_EXCLUSIVE;",
            "\tspin_lock_irqsave(&wq_head->lock, flags);",
            "\t__add_wait_queue_entry_tail(wq_head, wq_entry);",
            "\tspin_unlock_irqrestore(&wq_head->lock, flags);",
            "}",
            "void add_wait_queue_priority(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)",
            "{",
            "\tunsigned long flags;",
            "",
            "\twq_entry->flags |= WQ_FLAG_EXCLUSIVE | WQ_FLAG_PRIORITY;",
            "\tspin_lock_irqsave(&wq_head->lock, flags);",
            "\t__add_wait_queue(wq_head, wq_entry);",
            "\tspin_unlock_irqrestore(&wq_head->lock, flags);",
            "}",
            "void remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tspin_lock_irqsave(&wq_head->lock, flags);",
            "\t__remove_wait_queue(wq_head, wq_entry);",
            "\tspin_unlock_irqrestore(&wq_head->lock, flags);",
            "}",
            "static int __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode,",
            "\t\t\tint nr_exclusive, int wake_flags, void *key)",
            "{",
            "\twait_queue_entry_t *curr, *next;",
            "",
            "\tlockdep_assert_held(&wq_head->lock);",
            "",
            "\tcurr = list_first_entry(&wq_head->head, wait_queue_entry_t, entry);",
            "",
            "\tif (&curr->entry == &wq_head->head)",
            "\t\treturn nr_exclusive;",
            "",
            "\tlist_for_each_entry_safe_from(curr, next, &wq_head->head, entry) {",
            "\t\tunsigned flags = curr->flags;",
            "\t\tint ret;",
            "",
            "\t\tret = curr->func(curr, mode, wake_flags, key);",
            "\t\tif (ret < 0)",
            "\t\t\tbreak;",
            "\t\tif (ret && (flags & WQ_FLAG_EXCLUSIVE) && !--nr_exclusive)",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\treturn nr_exclusive;",
            "}",
            "static int __wake_up_common_lock(struct wait_queue_head *wq_head, unsigned int mode,",
            "\t\t\tint nr_exclusive, int wake_flags, void *key)",
            "{",
            "\tunsigned long flags;",
            "\tint remaining;",
            "",
            "\tspin_lock_irqsave(&wq_head->lock, flags);",
            "\tremaining = __wake_up_common(wq_head, mode, nr_exclusive, wake_flags,",
            "\t\t\tkey);",
            "\tspin_unlock_irqrestore(&wq_head->lock, flags);",
            "",
            "\treturn nr_exclusive - remaining;",
            "}",
            "int __wake_up(struct wait_queue_head *wq_head, unsigned int mode,",
            "\t      int nr_exclusive, void *key)",
            "{",
            "\treturn __wake_up_common_lock(wq_head, mode, nr_exclusive, 0, key);",
            "}",
            "void __wake_up_on_current_cpu(struct wait_queue_head *wq_head, unsigned int mode, void *key)",
            "{",
            "\t__wake_up_common_lock(wq_head, mode, 1, WF_CURRENT_CPU, key);",
            "}",
            "void __wake_up_locked(struct wait_queue_head *wq_head, unsigned int mode, int nr)",
            "{",
            "\t__wake_up_common(wq_head, mode, nr, 0, NULL);",
            "}",
            "void __wake_up_locked_key(struct wait_queue_head *wq_head, unsigned int mode, void *key)",
            "{",
            "\t__wake_up_common(wq_head, mode, 1, 0, key);",
            "}",
            "void __wake_up_sync_key(struct wait_queue_head *wq_head, unsigned int mode,",
            "\t\t\tvoid *key)",
            "{",
            "\tif (unlikely(!wq_head))",
            "\t\treturn;",
            "",
            "\t__wake_up_common_lock(wq_head, mode, 1, WF_SYNC, key);",
            "}"
          ],
          "function_name": "__init_waitqueue_head, add_wait_queue, add_wait_queue_exclusive, add_wait_queue_priority, remove_wait_queue, __wake_up_common, __wake_up_common_lock, __wake_up, __wake_up_on_current_cpu, __wake_up_locked, __wake_up_locked_key, __wake_up_sync_key",
          "description": "实现等待队列核心管理函数，包含初始化头结构、添加/移除等待项、唤醒逻辑及多种唤醒变体，通过自旋锁保护并发访问",
          "similarity": 0.6861589550971985
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/wait.c",
          "start_line": 193,
          "end_line": 306,
          "content": [
            "void __wake_up_locked_sync_key(struct wait_queue_head *wq_head,",
            "\t\t\t       unsigned int mode, void *key)",
            "{",
            "        __wake_up_common(wq_head, mode, 1, WF_SYNC, key);",
            "}",
            "void __wake_up_sync(struct wait_queue_head *wq_head, unsigned int mode)",
            "{",
            "\t__wake_up_sync_key(wq_head, mode, NULL);",
            "}",
            "void __wake_up_pollfree(struct wait_queue_head *wq_head)",
            "{",
            "\t__wake_up(wq_head, TASK_NORMAL, 0, poll_to_key(EPOLLHUP | POLLFREE));",
            "\t/* POLLFREE must have cleared the queue. */",
            "\tWARN_ON_ONCE(waitqueue_active(wq_head));",
            "}",
            "void",
            "prepare_to_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)",
            "{",
            "\tunsigned long flags;",
            "",
            "\twq_entry->flags &= ~WQ_FLAG_EXCLUSIVE;",
            "\tspin_lock_irqsave(&wq_head->lock, flags);",
            "\tif (list_empty(&wq_entry->entry))",
            "\t\t__add_wait_queue(wq_head, wq_entry);",
            "\tset_current_state(state);",
            "\tspin_unlock_irqrestore(&wq_head->lock, flags);",
            "}",
            "bool",
            "prepare_to_wait_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)",
            "{",
            "\tunsigned long flags;",
            "\tbool was_empty = false;",
            "",
            "\twq_entry->flags |= WQ_FLAG_EXCLUSIVE;",
            "\tspin_lock_irqsave(&wq_head->lock, flags);",
            "\tif (list_empty(&wq_entry->entry)) {",
            "\t\twas_empty = list_empty(&wq_head->head);",
            "\t\t__add_wait_queue_entry_tail(wq_head, wq_entry);",
            "\t}",
            "\tset_current_state(state);",
            "\tspin_unlock_irqrestore(&wq_head->lock, flags);",
            "\treturn was_empty;",
            "}",
            "void init_wait_entry(struct wait_queue_entry *wq_entry, int flags)",
            "{",
            "\twq_entry->flags = flags;",
            "\twq_entry->private = current;",
            "\twq_entry->func = autoremove_wake_function;",
            "\tINIT_LIST_HEAD(&wq_entry->entry);",
            "}",
            "long prepare_to_wait_event(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)",
            "{",
            "\tunsigned long flags;",
            "\tlong ret = 0;",
            "",
            "\tspin_lock_irqsave(&wq_head->lock, flags);",
            "\tif (signal_pending_state(state, current)) {",
            "\t\t/*",
            "\t\t * Exclusive waiter must not fail if it was selected by wakeup,",
            "\t\t * it should \"consume\" the condition we were waiting for.",
            "\t\t *",
            "\t\t * The caller will recheck the condition and return success if",
            "\t\t * we were already woken up, we can not miss the event because",
            "\t\t * wakeup locks/unlocks the same wq_head->lock.",
            "\t\t *",
            "\t\t * But we need to ensure that set-condition + wakeup after that",
            "\t\t * can't see us, it should wake up another exclusive waiter if",
            "\t\t * we fail.",
            "\t\t */",
            "\t\tlist_del_init(&wq_entry->entry);",
            "\t\tret = -ERESTARTSYS;",
            "\t} else {",
            "\t\tif (list_empty(&wq_entry->entry)) {",
            "\t\t\tif (wq_entry->flags & WQ_FLAG_EXCLUSIVE)",
            "\t\t\t\t__add_wait_queue_entry_tail(wq_head, wq_entry);",
            "\t\t\telse",
            "\t\t\t\t__add_wait_queue(wq_head, wq_entry);",
            "\t\t}",
            "\t\tset_current_state(state);",
            "\t}",
            "\tspin_unlock_irqrestore(&wq_head->lock, flags);",
            "",
            "\treturn ret;",
            "}",
            "int do_wait_intr(wait_queue_head_t *wq, wait_queue_entry_t *wait)",
            "{",
            "\tif (likely(list_empty(&wait->entry)))",
            "\t\t__add_wait_queue_entry_tail(wq, wait);",
            "",
            "\tset_current_state(TASK_INTERRUPTIBLE);",
            "\tif (signal_pending(current))",
            "\t\treturn -ERESTARTSYS;",
            "",
            "\tspin_unlock(&wq->lock);",
            "\tschedule();",
            "\tspin_lock(&wq->lock);",
            "",
            "\treturn 0;",
            "}",
            "int do_wait_intr_irq(wait_queue_head_t *wq, wait_queue_entry_t *wait)",
            "{",
            "\tif (likely(list_empty(&wait->entry)))",
            "\t\t__add_wait_queue_entry_tail(wq, wait);",
            "",
            "\tset_current_state(TASK_INTERRUPTIBLE);",
            "\tif (signal_pending(current))",
            "\t\treturn -ERESTARTSYS;",
            "",
            "\tspin_unlock_irq(&wq->lock);",
            "\tschedule();",
            "\tspin_lock_irq(&wq->lock);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "__wake_up_locked_sync_key, __wake_up_sync, __wake_up_pollfree, prepare_to_wait, prepare_to_wait_exclusive, init_wait_entry, prepare_to_wait_event, do_wait_intr, do_wait_intr_irq",
          "description": "提供等待状态准备、事件等待及中断处理辅助函数，支持独占等待、信号检测和任务调度，处理等待队列插入与状态切换",
          "similarity": 0.6805229187011719
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/sched/wait.c",
          "start_line": 356,
          "end_line": 419,
          "content": [
            "void finish_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)",
            "{",
            "\tunsigned long flags;",
            "",
            "\t__set_current_state(TASK_RUNNING);",
            "\t/*",
            "\t * We can check for list emptiness outside the lock",
            "\t * IFF:",
            "\t *  - we use the \"careful\" check that verifies both",
            "\t *    the next and prev pointers, so that there cannot",
            "\t *    be any half-pending updates in progress on other",
            "\t *    CPU's that we haven't seen yet (and that might",
            "\t *    still change the stack area.",
            "\t * and",
            "\t *  - all other users take the lock (ie we can only",
            "\t *    have _one_ other CPU that looks at or modifies",
            "\t *    the list).",
            "\t */",
            "\tif (!list_empty_careful(&wq_entry->entry)) {",
            "\t\tspin_lock_irqsave(&wq_head->lock, flags);",
            "\t\tlist_del_init(&wq_entry->entry);",
            "\t\tspin_unlock_irqrestore(&wq_head->lock, flags);",
            "\t}",
            "}",
            "int autoremove_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, int sync, void *key)",
            "{",
            "\tint ret = default_wake_function(wq_entry, mode, sync, key);",
            "",
            "\tif (ret)",
            "\t\tlist_del_init_careful(&wq_entry->entry);",
            "",
            "\treturn ret;",
            "}",
            "long wait_woken(struct wait_queue_entry *wq_entry, unsigned mode, long timeout)",
            "{",
            "\t/*",
            "\t * The below executes an smp_mb(), which matches with the full barrier",
            "\t * executed by the try_to_wake_up() in woken_wake_function() such that",
            "\t * either we see the store to wq_entry->flags in woken_wake_function()",
            "\t * or woken_wake_function() sees our store to current->state.",
            "\t */",
            "\tset_current_state(mode); /* A */",
            "\tif (!(wq_entry->flags & WQ_FLAG_WOKEN) && !kthread_should_stop_or_park())",
            "\t\ttimeout = schedule_timeout(timeout);",
            "\t__set_current_state(TASK_RUNNING);",
            "",
            "\t/*",
            "\t * The below executes an smp_mb(), which matches with the smp_mb() (C)",
            "\t * in woken_wake_function() such that either we see the wait condition",
            "\t * being true or the store to wq_entry->flags in woken_wake_function()",
            "\t * follows ours in the coherence order.",
            "\t */",
            "\tsmp_store_mb(wq_entry->flags, wq_entry->flags & ~WQ_FLAG_WOKEN); /* B */",
            "",
            "\treturn timeout;",
            "}",
            "int woken_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, int sync, void *key)",
            "{",
            "\t/* Pairs with the smp_store_mb() in wait_woken(). */",
            "\tsmp_mb(); /* C */",
            "\twq_entry->flags |= WQ_FLAG_WOKEN;",
            "",
            "\treturn default_wake_function(wq_entry, mode, sync, key);",
            "}"
          ],
          "function_name": "finish_wait, autoremove_wake_function, wait_woken, woken_wake_function",
          "description": "实现等待结束清理与自动移除唤醒回调，包含状态转换屏障、唤醒标记更新及条件判断逻辑，确保内存顺序一致性",
          "similarity": 0.5911954641342163
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/wait.c",
          "start_line": 1,
          "end_line": 7,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Generic waiting primitives.",
            " *",
            " * (C) 2004 Nadia Yvette Chambers, Oracle",
            " */",
            ""
          ],
          "function_name": null,
          "description": "定义等待队列通用原语的头部注释，声明GPL许可及原始作者信息",
          "similarity": 0.5593518614768982
        }
      ]
    },
    {
      "source_file": "kernel/futex/requeue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:34:56\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `futex\\requeue.c`\n\n---\n\n# futex/requeue.c 技术文档\n\n## 1. 文件概述\n\n`futex/requeue.c` 是 Linux 内核 FUTEX（Fast Userspace muTEX）子系统中的关键实现文件，专门负责 **FUTEX_REQUEUE** 和 **FUTEX_CMP_REQUEUE_PI** 等操作中涉及的 **futex 等待队列重排队（requeue）逻辑**，尤其针对 **PI（Priority Inheritance，优先级继承）futex** 的复杂场景。该文件的核心目标是在保证正确性和避免死锁的前提下，高效地将等待在源 futex（uaddr1）上的任务迁移到目标 futex（uaddr2）上，并处理 PI 相关的状态同步与唤醒机制。特别地，它解决了在 **PREEMPT_RT** 实时内核配置下，由于底层使用 rtmutex 实现自旋锁而引发的潜在状态冲突问题。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`enum requeue_pi_state`**: 定义 PI futex 重排队过程中的状态机，用于协调重排队操作者（requeue side）与被重排队任务（waiter side）之间的同步。\n  - `Q_REQUEUE_PI_NONE`: 初始状态。\n  - `Q_REQUEUE_PI_IGNORE`: 等待者已提前唤醒，应忽略此次重排队。\n  - `Q_REQUEUE_PI_IN_PROGRESS`: 重排队操作正在进行中。\n  - `Q_REQUEUE_PI_WAIT`: 等待者在重排队过程中被唤醒，需等待操作完成。\n  - `Q_REQUEUE_PI_DONE`: 重排队成功，任务在目标 futex 上等待。\n  - `Q_REQUEUE_PI_LOCKED`: 重排队成功，且任务已原子地获取了目标 futex 锁。\n- **`futex_q_init`**: `futex_q` 结构体的初始化模板，将 `requeue_state` 初始化为 `Q_REQUEUE_PI_NONE`。\n\n### 主要函数\n\n- **`requeue_futex()`**: 将一个 `futex_q` 从源哈希桶 (`hb1`) 移动到目标哈希桶 (`hb2`)，并更新其关联的 futex key。如果源和目标哈希桶相同，则跳过移动操作。\n- **`futex_requeue_pi_prepare()`**: 为 PI 重排队操作做准备。尝试将等待者的 `requeue_state` 从 `NONE` 设置为 `IN_PROGRESS`。如果状态已是 `IGNORE`，则返回 `false` 表示应跳过此等待者。\n- **`futex_requeue_pi_complete()`**: 完成 PI 重排队操作。根据操作结果（成功/失败/死锁）和当前状态，将 `requeue_state` 更新为 `DONE`、`LOCKED`、`NONE` 或 `IGNORE`。在 `PREEMPT_RT` 下，若存在状态交错（`WAIT`），会唤醒等待者。\n- **`futex_requeue_pi_wakeup_sync()`**: 由被重排队的等待者调用，用于处理在重排队过程中发生的提前唤醒（如超时或信号）。它会根据当前重排队状态，设置自身状态为 `IGNORE` 或 `WAIT`，并在必要时阻塞等待重排队操作完成。\n- **`requeue_pi_wake_futex()`**: 在重排队过程中，如果目标 futex 锁可以被原子获取（无竞争或通过锁窃取），则直接唤醒该等待者。此函数负责更新 `futex_q` 的状态（key、rt_waiter、lock_ptr），完成重排队状态机，并最终唤醒任务。\n- **`futex_proxy_trylock_atomic()`**: （声明未在片段中完整给出，但为关键函数）尝试为重排队目标 futex 的 top waiter 原子地获取锁，并建立 PI 状态（`pi_state`）。这是实现 `FUTEX_CMP_REQUEUE_PI` 无竞争快速路径的核心。\n\n## 3. 关键实现\n\n### PI 重排队状态机\n文件的核心是一个精心设计的无锁状态机，通过 `atomic_t requeue_state` 字段在重排队操作者和被操作的等待者之间进行同步。该状态机定义了双方允许的状态转换，确保了在并发唤醒（如信号、超时）和重排队操作交错发生时，系统状态的一致性和正确性。\n\n### PREEMPT_RT 兼容性\n在 `PREEMPT_RT` 内核中，哈希桶锁（`hb->lock`）底层是 `rtmutex`。一个任务不能同时阻塞在两个 `rtmutex` 上。如果一个刚被唤醒的任务（因信号/超时）试图获取源 futex 的哈希桶锁，而该锁正被重排队代码持有，就会与重排队过程中可能涉及的代理锁（proxy lock）操作冲突。本文件通过状态机机制，让提前唤醒的任务能“通知”重排队代码忽略它，从而避免了这种冲突和潜在的状态损坏。\n\n### 原子锁获取与唤醒\n`requeue_pi_wake_futex()` 函数实现了在重排队过程中直接获取目标 futex 锁并唤醒任务的优化路径。这避免了任务先被加入目标等待队列再被唤醒的开销，提高了性能。该函数必须在持有源和目标哈希桶锁的情况下调用，以保证操作的原子性。\n\n### 同步原语\n- **`atomic_try_cmpxchg`**: 用于无锁地更新 `requeue_state`，实现状态机的原子转换。\n- **`rcuwait`**: 在 `PREEMPT_RT` 下，当等待者需要等待重排队完成时，使用 `rcuwait` 机制进行高效等待。\n- **`atomic_cond_read_relaxed`**: 在非 `PREEMPT_RT` 下，用于自旋等待状态改变。\n\n## 4. 依赖关系\n\n- **`<linux/plist.h>`**: 提供优先级链表（`plist`）的实现，用于管理 futex 等待队列。\n- **`<linux/sched/signal.h>`**: 提供任务唤醒（`wake_up_state`）和信号处理相关的功能。\n- **`\"futex.h\"`**: 包含 FUTEX 子系统的核心定义，如 `futex_q`, `futex_hash_bucket`, `futex_key` 等。\n- **`../locking/rtmutex_common.h`**: 提供实时互斥锁（`rtmutex`）的通用接口，`PREEMPT_RT` 的关键依赖。\n- **内核调度器**: 依赖 `wake_up_state` 等函数与内核调度器交互，唤醒被阻塞的任务。\n- **内存屏障原语**: 代码中隐含使用了 `acquire`/`release` 语义的原子操作来保证内存访问顺序。\n\n## 5. 使用场景\n\n- **`FUTEX_REQUEUE` 系统调用**: 当用户空间调用 `futex(uaddr1, FUTEX_REQUEUE, ...)` 时，内核会调用此文件中的逻辑，将等待在 `uaddr1` 上的指定数量的任务移动到 `uaddr2` 的等待队列上。\n- **`FUTEX_CMP_REQUEUE_PI` 系统调用**: 这是 PI futex 的关键操作。它首先检查 `uaddr1` 的值，如果匹配，则尝试将 `uaddr1` 上的等待者重排队到 `uaddr2`。在此过程中，会尝试为 `uaddr2` 的 top waiter 原子地获取锁（通过 `futex_proxy_trylock_atomic`）。如果成功，则直接唤醒该任务（通过 `requeue_pi_wake_futex`）；如果失败，则将其加入 `uaddr2` 的等待队列。整个过程需要本文件提供的状态机来处理并发唤醒。\n- **PI futex 的唤醒与超时处理**: 当一个正在被重排队的 PI futex 等待者收到信号或发生超时时，会调用 `futex_requeue_pi_wakeup_sync` 来安全地退出等待，并与正在进行的重排队操作进行协调。",
      "similarity": 0.5815715789794922,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/futex/requeue.c",
          "start_line": 74,
          "end_line": 190,
          "content": [
            "static inline",
            "void requeue_futex(struct futex_q *q, struct futex_hash_bucket *hb1,",
            "\t\t   struct futex_hash_bucket *hb2, union futex_key *key2)",
            "{",
            "",
            "\t/*",
            "\t * If key1 and key2 hash to the same bucket, no need to",
            "\t * requeue.",
            "\t */",
            "\tif (likely(&hb1->chain != &hb2->chain)) {",
            "\t\tplist_del(&q->list, &hb1->chain);",
            "\t\tfutex_hb_waiters_dec(hb1);",
            "\t\tfutex_hb_waiters_inc(hb2);",
            "\t\tplist_add(&q->list, &hb2->chain);",
            "\t\tq->lock_ptr = &hb2->lock;",
            "\t}",
            "\tq->key = *key2;",
            "}",
            "static inline bool futex_requeue_pi_prepare(struct futex_q *q,",
            "\t\t\t\t\t    struct futex_pi_state *pi_state)",
            "{",
            "\tint old, new;",
            "",
            "\t/*",
            "\t * Set state to Q_REQUEUE_PI_IN_PROGRESS unless an early wakeup has",
            "\t * already set Q_REQUEUE_PI_IGNORE to signal that requeue should",
            "\t * ignore the waiter.",
            "\t */",
            "\told = atomic_read_acquire(&q->requeue_state);",
            "\tdo {",
            "\t\tif (old == Q_REQUEUE_PI_IGNORE)",
            "\t\t\treturn false;",
            "",
            "\t\t/*",
            "\t\t * futex_proxy_trylock_atomic() might have set it to",
            "\t\t * IN_PROGRESS and a interleaved early wake to WAIT.",
            "\t\t *",
            "\t\t * It was considered to have an extra state for that",
            "\t\t * trylock, but that would just add more conditionals",
            "\t\t * all over the place for a dubious value.",
            "\t\t */",
            "\t\tif (old != Q_REQUEUE_PI_NONE)",
            "\t\t\tbreak;",
            "",
            "\t\tnew = Q_REQUEUE_PI_IN_PROGRESS;",
            "\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));",
            "",
            "\tq->pi_state = pi_state;",
            "\treturn true;",
            "}",
            "static inline void futex_requeue_pi_complete(struct futex_q *q, int locked)",
            "{",
            "\tint old, new;",
            "",
            "\told = atomic_read_acquire(&q->requeue_state);",
            "\tdo {",
            "\t\tif (old == Q_REQUEUE_PI_IGNORE)",
            "\t\t\treturn;",
            "",
            "\t\tif (locked >= 0) {",
            "\t\t\t/* Requeue succeeded. Set DONE or LOCKED */",
            "\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_IN_PROGRESS &&",
            "\t\t\t\t     old != Q_REQUEUE_PI_WAIT);",
            "\t\t\tnew = Q_REQUEUE_PI_DONE + locked;",
            "\t\t} else if (old == Q_REQUEUE_PI_IN_PROGRESS) {",
            "\t\t\t/* Deadlock, no early wakeup interleave */",
            "\t\t\tnew = Q_REQUEUE_PI_NONE;",
            "\t\t} else {",
            "\t\t\t/* Deadlock, early wakeup interleave. */",
            "\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_WAIT);",
            "\t\t\tnew = Q_REQUEUE_PI_IGNORE;",
            "\t\t}",
            "\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));",
            "",
            "#ifdef CONFIG_PREEMPT_RT",
            "\t/* If the waiter interleaved with the requeue let it know */",
            "\tif (unlikely(old == Q_REQUEUE_PI_WAIT))",
            "\t\trcuwait_wake_up(&q->requeue_wait);",
            "#endif",
            "}",
            "static inline int futex_requeue_pi_wakeup_sync(struct futex_q *q)",
            "{",
            "\tint old, new;",
            "",
            "\told = atomic_read_acquire(&q->requeue_state);",
            "\tdo {",
            "\t\t/* Is requeue done already? */",
            "\t\tif (old >= Q_REQUEUE_PI_DONE)",
            "\t\t\treturn old;",
            "",
            "\t\t/*",
            "\t\t * If not done, then tell the requeue code to either ignore",
            "\t\t * the waiter or to wake it up once the requeue is done.",
            "\t\t */",
            "\t\tnew = Q_REQUEUE_PI_WAIT;",
            "\t\tif (old == Q_REQUEUE_PI_NONE)",
            "\t\t\tnew = Q_REQUEUE_PI_IGNORE;",
            "\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));",
            "",
            "\t/* If the requeue was in progress, wait for it to complete */",
            "\tif (old == Q_REQUEUE_PI_IN_PROGRESS) {",
            "#ifdef CONFIG_PREEMPT_RT",
            "\t\trcuwait_wait_event(&q->requeue_wait,",
            "\t\t\t\t   atomic_read(&q->requeue_state) != Q_REQUEUE_PI_WAIT,",
            "\t\t\t\t   TASK_UNINTERRUPTIBLE);",
            "#else",
            "\t\t(void)atomic_cond_read_relaxed(&q->requeue_state, VAL != Q_REQUEUE_PI_WAIT);",
            "#endif",
            "\t}",
            "",
            "\t/*",
            "\t * Requeue is now either prohibited or complete. Reread state",
            "\t * because during the wait above it might have changed. Nothing",
            "\t * will modify q->requeue_state after this point.",
            "\t */",
            "\treturn atomic_read(&q->requeue_state);",
            "}"
          ],
          "function_name": "requeue_futex, futex_requeue_pi_prepare, futex_requeue_pi_complete, futex_requeue_pi_wakeup_sync",
          "description": "实现futex重新排队的核心逻辑，通过原子操作管理状态转换，处理等待队列迁移、锁竞争检测及状态同步问题。",
          "similarity": 0.6532182097434998
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/futex/requeue.c",
          "start_line": 223,
          "end_line": 635,
          "content": [
            "static inline",
            "void requeue_pi_wake_futex(struct futex_q *q, union futex_key *key,",
            "\t\t\t   struct futex_hash_bucket *hb)",
            "{",
            "\tstruct task_struct *task;",
            "",
            "\tq->key = *key;",
            "\t__futex_unqueue(q);",
            "",
            "\tWARN_ON(!q->rt_waiter);",
            "\tq->rt_waiter = NULL;",
            "",
            "\tq->lock_ptr = &hb->lock;",
            "\ttask = READ_ONCE(q->task);",
            "",
            "\t/* Signal locked state to the waiter */",
            "\tfutex_requeue_pi_complete(q, 1);",
            "\twake_up_state(task, TASK_NORMAL);",
            "}",
            "static int",
            "futex_proxy_trylock_atomic(u32 __user *pifutex, struct futex_hash_bucket *hb1,",
            "\t\t\t   struct futex_hash_bucket *hb2, union futex_key *key1,",
            "\t\t\t   union futex_key *key2, struct futex_pi_state **ps,",
            "\t\t\t   struct task_struct **exiting, int set_waiters)",
            "{",
            "\tstruct futex_q *top_waiter = NULL;",
            "\tu32 curval;",
            "\tint ret;",
            "",
            "\tif (futex_get_value_locked(&curval, pifutex))",
            "\t\treturn -EFAULT;",
            "",
            "\tif (unlikely(should_fail_futex(true)))",
            "\t\treturn -EFAULT;",
            "",
            "\t/*",
            "\t * Find the top_waiter and determine if there are additional waiters.",
            "\t * If the caller intends to requeue more than 1 waiter to pifutex,",
            "\t * force futex_lock_pi_atomic() to set the FUTEX_WAITERS bit now,",
            "\t * as we have means to handle the possible fault.  If not, don't set",
            "\t * the bit unnecessarily as it will force the subsequent unlock to enter",
            "\t * the kernel.",
            "\t */",
            "\ttop_waiter = futex_top_waiter(hb1, key1);",
            "",
            "\t/* There are no waiters, nothing for us to do. */",
            "\tif (!top_waiter)",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * Ensure that this is a waiter sitting in futex_wait_requeue_pi()",
            "\t * and waiting on the 'waitqueue' futex which is always !PI.",
            "\t */",
            "\tif (!top_waiter->rt_waiter || top_waiter->pi_state)",
            "\t\treturn -EINVAL;",
            "",
            "\t/* Ensure we requeue to the expected futex. */",
            "\tif (!futex_match(top_waiter->requeue_pi_key, key2))",
            "\t\treturn -EINVAL;",
            "",
            "\t/* Ensure that this does not race against an early wakeup */",
            "\tif (!futex_requeue_pi_prepare(top_waiter, NULL))",
            "\t\treturn -EAGAIN;",
            "",
            "\t/*",
            "\t * Try to take the lock for top_waiter and set the FUTEX_WAITERS bit",
            "\t * in the contended case or if @set_waiters is true.",
            "\t *",
            "\t * In the contended case PI state is attached to the lock owner. If",
            "\t * the user space lock can be acquired then PI state is attached to",
            "\t * the new owner (@top_waiter->task) when @set_waiters is true.",
            "\t */",
            "\tret = futex_lock_pi_atomic(pifutex, hb2, key2, ps, top_waiter->task,",
            "\t\t\t\t   exiting, set_waiters);",
            "\tif (ret == 1) {",
            "\t\t/*",
            "\t\t * Lock was acquired in user space and PI state was",
            "\t\t * attached to @top_waiter->task. That means state is fully",
            "\t\t * consistent and the waiter can return to user space",
            "\t\t * immediately after the wakeup.",
            "\t\t */",
            "\t\trequeue_pi_wake_futex(top_waiter, key2, hb2);",
            "\t} else if (ret < 0) {",
            "\t\t/* Rewind top_waiter::requeue_state */",
            "\t\tfutex_requeue_pi_complete(top_waiter, ret);",
            "\t} else {",
            "\t\t/*",
            "\t\t * futex_lock_pi_atomic() did not acquire the user space",
            "\t\t * futex, but managed to establish the proxy lock and pi",
            "\t\t * state. top_waiter::requeue_state cannot be fixed up here",
            "\t\t * because the waiter is not enqueued on the rtmutex",
            "\t\t * yet. This is handled at the callsite depending on the",
            "\t\t * result of rt_mutex_start_proxy_lock() which is",
            "\t\t * guaranteed to be reached with this function returning 0.",
            "\t\t */",
            "\t}",
            "\treturn ret;",
            "}",
            "int futex_requeue(u32 __user *uaddr1, unsigned int flags1,",
            "\t\t  u32 __user *uaddr2, unsigned int flags2,",
            "\t\t  int nr_wake, int nr_requeue, u32 *cmpval, int requeue_pi)",
            "{",
            "\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;",
            "\tint task_count = 0, ret;",
            "\tstruct futex_pi_state *pi_state = NULL;",
            "\tstruct futex_hash_bucket *hb1, *hb2;",
            "\tstruct futex_q *this, *next;",
            "\tDEFINE_WAKE_Q(wake_q);",
            "",
            "\tif (nr_wake < 0 || nr_requeue < 0)",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * When PI not supported: return -ENOSYS if requeue_pi is true,",
            "\t * consequently the compiler knows requeue_pi is always false past",
            "\t * this point which will optimize away all the conditional code",
            "\t * further down.",
            "\t */",
            "\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)",
            "\t\treturn -ENOSYS;",
            "",
            "\tif (requeue_pi) {",
            "\t\t/*",
            "\t\t * Requeue PI only works on two distinct uaddrs. This",
            "\t\t * check is only valid for private futexes. See below.",
            "\t\t */",
            "\t\tif (uaddr1 == uaddr2)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * futex_requeue() allows the caller to define the number",
            "\t\t * of waiters to wake up via the @nr_wake argument. With",
            "\t\t * REQUEUE_PI, waking up more than one waiter is creating",
            "\t\t * more problems than it solves. Waking up a waiter makes",
            "\t\t * only sense if the PI futex @uaddr2 is uncontended as",
            "\t\t * this allows the requeue code to acquire the futex",
            "\t\t * @uaddr2 before waking the waiter. The waiter can then",
            "\t\t * return to user space without further action. A secondary",
            "\t\t * wakeup would just make the futex_wait_requeue_pi()",
            "\t\t * handling more complex, because that code would have to",
            "\t\t * look up pi_state and do more or less all the handling",
            "\t\t * which the requeue code has to do for the to be requeued",
            "\t\t * waiters. So restrict the number of waiters to wake to",
            "\t\t * one, and only wake it up when the PI futex is",
            "\t\t * uncontended. Otherwise requeue it and let the unlock of",
            "\t\t * the PI futex handle the wakeup.",
            "\t\t *",
            "\t\t * All REQUEUE_PI users, e.g. pthread_cond_signal() and",
            "\t\t * pthread_cond_broadcast() must use nr_wake=1.",
            "\t\t */",
            "\t\tif (nr_wake != 1)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * requeue_pi requires a pi_state, try to allocate it now",
            "\t\t * without any locks in case it fails.",
            "\t\t */",
            "\t\tif (refill_pi_state_cache())",
            "\t\t\treturn -ENOMEM;",
            "\t}",
            "",
            "retry:",
            "\tret = get_futex_key(uaddr1, flags1, &key1, FUTEX_READ);",
            "\tif (unlikely(ret != 0))",
            "\t\treturn ret;",
            "\tret = get_futex_key(uaddr2, flags2, &key2,",
            "\t\t\t    requeue_pi ? FUTEX_WRITE : FUTEX_READ);",
            "\tif (unlikely(ret != 0))",
            "\t\treturn ret;",
            "",
            "\t/*",
            "\t * The check above which compares uaddrs is not sufficient for",
            "\t * shared futexes. We need to compare the keys:",
            "\t */",
            "\tif (requeue_pi && futex_match(&key1, &key2))",
            "\t\treturn -EINVAL;",
            "",
            "\thb1 = futex_hash(&key1);",
            "\thb2 = futex_hash(&key2);",
            "",
            "retry_private:",
            "\tfutex_hb_waiters_inc(hb2);",
            "\tdouble_lock_hb(hb1, hb2);",
            "",
            "\tif (likely(cmpval != NULL)) {",
            "\t\tu32 curval;",
            "",
            "\t\tret = futex_get_value_locked(&curval, uaddr1);",
            "",
            "\t\tif (unlikely(ret)) {",
            "\t\t\tdouble_unlock_hb(hb1, hb2);",
            "\t\t\tfutex_hb_waiters_dec(hb2);",
            "",
            "\t\t\tret = get_user(curval, uaddr1);",
            "\t\t\tif (ret)",
            "\t\t\t\treturn ret;",
            "",
            "\t\t\tif (!(flags1 & FLAGS_SHARED))",
            "\t\t\t\tgoto retry_private;",
            "",
            "\t\t\tgoto retry;",
            "\t\t}",
            "\t\tif (curval != *cmpval) {",
            "\t\t\tret = -EAGAIN;",
            "\t\t\tgoto out_unlock;",
            "\t\t}",
            "\t}",
            "",
            "\tif (requeue_pi) {",
            "\t\tstruct task_struct *exiting = NULL;",
            "",
            "\t\t/*",
            "\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we",
            "\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS",
            "\t\t * bit.  We force this here where we are able to easily handle",
            "\t\t * faults rather in the requeue loop below.",
            "\t\t *",
            "\t\t * Updates topwaiter::requeue_state if a top waiter exists.",
            "\t\t */",
            "\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,",
            "\t\t\t\t\t\t &key2, &pi_state,",
            "\t\t\t\t\t\t &exiting, nr_requeue);",
            "",
            "\t\t/*",
            "\t\t * At this point the top_waiter has either taken uaddr2 or",
            "\t\t * is waiting on it. In both cases pi_state has been",
            "\t\t * established and an initial refcount on it. In case of an",
            "\t\t * error there's nothing.",
            "\t\t *",
            "\t\t * The top waiter's requeue_state is up to date:",
            "\t\t *",
            "\t\t *  - If the lock was acquired atomically (ret == 1), then",
            "\t\t *    the state is Q_REQUEUE_PI_LOCKED.",
            "\t\t *",
            "\t\t *    The top waiter has been dequeued and woken up and can",
            "\t\t *    return to user space immediately. The kernel/user",
            "\t\t *    space state is consistent. In case that there must be",
            "\t\t *    more waiters requeued the WAITERS bit in the user",
            "\t\t *    space futex is set so the top waiter task has to go",
            "\t\t *    into the syscall slowpath to unlock the futex. This",
            "\t\t *    will block until this requeue operation has been",
            "\t\t *    completed and the hash bucket locks have been",
            "\t\t *    dropped.",
            "\t\t *",
            "\t\t *  - If the trylock failed with an error (ret < 0) then",
            "\t\t *    the state is either Q_REQUEUE_PI_NONE, i.e. \"nothing",
            "\t\t *    happened\", or Q_REQUEUE_PI_IGNORE when there was an",
            "\t\t *    interleaved early wakeup.",
            "\t\t *",
            "\t\t *  - If the trylock did not succeed (ret == 0) then the",
            "\t\t *    state is either Q_REQUEUE_PI_IN_PROGRESS or",
            "\t\t *    Q_REQUEUE_PI_WAIT if an early wakeup interleaved.",
            "\t\t *    This will be cleaned up in the loop below, which",
            "\t\t *    cannot fail because futex_proxy_trylock_atomic() did",
            "\t\t *    the same sanity checks for requeue_pi as the loop",
            "\t\t *    below does.",
            "\t\t */",
            "\t\tswitch (ret) {",
            "\t\tcase 0:",
            "\t\t\t/* We hold a reference on the pi state. */",
            "\t\t\tbreak;",
            "",
            "\t\tcase 1:",
            "\t\t\t/*",
            "\t\t\t * futex_proxy_trylock_atomic() acquired the user space",
            "\t\t\t * futex. Adjust task_count.",
            "\t\t\t */",
            "\t\t\ttask_count++;",
            "\t\t\tret = 0;",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * If the above failed, then pi_state is NULL and",
            "\t\t * waiter::requeue_state is correct.",
            "\t\t */",
            "\t\tcase -EFAULT:",
            "\t\t\tdouble_unlock_hb(hb1, hb2);",
            "\t\t\tfutex_hb_waiters_dec(hb2);",
            "\t\t\tret = fault_in_user_writeable(uaddr2);",
            "\t\t\tif (!ret)",
            "\t\t\t\tgoto retry;",
            "\t\t\treturn ret;",
            "\t\tcase -EBUSY:",
            "\t\tcase -EAGAIN:",
            "\t\t\t/*",
            "\t\t\t * Two reasons for this:",
            "\t\t\t * - EBUSY: Owner is exiting and we just wait for the",
            "\t\t\t *   exit to complete.",
            "\t\t\t * - EAGAIN: The user space value changed.",
            "\t\t\t */",
            "\t\t\tdouble_unlock_hb(hb1, hb2);",
            "\t\t\tfutex_hb_waiters_dec(hb2);",
            "\t\t\t/*",
            "\t\t\t * Handle the case where the owner is in the middle of",
            "\t\t\t * exiting. Wait for the exit to complete otherwise",
            "\t\t\t * this task might loop forever, aka. live lock.",
            "\t\t\t */",
            "\t\t\twait_for_owner_exiting(ret, exiting);",
            "\t\t\tcond_resched();",
            "\t\t\tgoto retry;",
            "\t\tdefault:",
            "\t\t\tgoto out_unlock;",
            "\t\t}",
            "\t}",
            "",
            "\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {",
            "\t\tif (task_count - nr_wake >= nr_requeue)",
            "\t\t\tbreak;",
            "",
            "\t\tif (!futex_match(&this->key, &key1))",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * FUTEX_WAIT_REQUEUE_PI and FUTEX_CMP_REQUEUE_PI should always",
            "\t\t * be paired with each other and no other futex ops.",
            "\t\t *",
            "\t\t * We should never be requeueing a futex_q with a pi_state,",
            "\t\t * which is awaiting a futex_unlock_pi().",
            "\t\t */",
            "\t\tif ((requeue_pi && !this->rt_waiter) ||",
            "\t\t    (!requeue_pi && this->rt_waiter) ||",
            "\t\t    this->pi_state) {",
            "\t\t\tret = -EINVAL;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\t/* Plain futexes just wake or requeue and are done */",
            "\t\tif (!requeue_pi) {",
            "\t\t\tif (++task_count <= nr_wake)",
            "\t\t\t\tfutex_wake_mark(&wake_q, this);",
            "\t\t\telse",
            "\t\t\t\trequeue_futex(this, hb1, hb2, &key2);",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\t/* Ensure we requeue to the expected futex for requeue_pi. */",
            "\t\tif (!futex_match(this->requeue_pi_key, &key2)) {",
            "\t\t\tret = -EINVAL;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Requeue nr_requeue waiters and possibly one more in the case",
            "\t\t * of requeue_pi if we couldn't acquire the lock atomically.",
            "\t\t *",
            "\t\t * Prepare the waiter to take the rt_mutex. Take a refcount",
            "\t\t * on the pi_state and store the pointer in the futex_q",
            "\t\t * object of the waiter.",
            "\t\t */",
            "\t\tget_pi_state(pi_state);",
            "",
            "\t\t/* Don't requeue when the waiter is already on the way out. */",
            "\t\tif (!futex_requeue_pi_prepare(this, pi_state)) {",
            "\t\t\t/*",
            "\t\t\t * Early woken waiter signaled that it is on the",
            "\t\t\t * way out. Drop the pi_state reference and try the",
            "\t\t\t * next waiter. @this->pi_state is still NULL.",
            "\t\t\t */",
            "\t\t\tput_pi_state(pi_state);",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,",
            "\t\t\t\t\t\tthis->rt_waiter,",
            "\t\t\t\t\t\tthis->task);",
            "",
            "\t\tif (ret == 1) {",
            "\t\t\t/*",
            "\t\t\t * We got the lock. We do neither drop the refcount",
            "\t\t\t * on pi_state nor clear this->pi_state because the",
            "\t\t\t * waiter needs the pi_state for cleaning up the",
            "\t\t\t * user space value. It will drop the refcount",
            "\t\t\t * after doing so. this::requeue_state is updated",
            "\t\t\t * in the wakeup as well.",
            "\t\t\t */",
            "\t\t\trequeue_pi_wake_futex(this, &key2, hb2);",
            "\t\t\ttask_count++;",
            "\t\t} else if (!ret) {",
            "\t\t\t/* Waiter is queued, move it to hb2 */",
            "\t\t\trequeue_futex(this, hb1, hb2, &key2);",
            "\t\t\tfutex_requeue_pi_complete(this, 0);",
            "\t\t\ttask_count++;",
            "\t\t} else {",
            "\t\t\t/*",
            "\t\t\t * rt_mutex_start_proxy_lock() detected a potential",
            "\t\t\t * deadlock when we tried to queue that waiter.",
            "\t\t\t * Drop the pi_state reference which we took above",
            "\t\t\t * and remove the pointer to the state from the",
            "\t\t\t * waiters futex_q object.",
            "\t\t\t */",
            "\t\t\tthis->pi_state = NULL;",
            "\t\t\tput_pi_state(pi_state);",
            "\t\t\tfutex_requeue_pi_complete(this, ret);",
            "\t\t\t/*",
            "\t\t\t * We stop queueing more waiters and let user space",
            "\t\t\t * deal with the mess.",
            "\t\t\t */",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * We took an extra initial reference to the pi_state in",
            "\t * futex_proxy_trylock_atomic(). We need to drop it here again.",
            "\t */",
            "\tput_pi_state(pi_state);",
            "",
            "out_unlock:",
            "\tdouble_unlock_hb(hb1, hb2);",
            "\twake_up_q(&wake_q);",
            "\tfutex_hb_waiters_dec(hb2);",
            "\treturn ret ? ret : task_count;",
            "}"
          ],
          "function_name": "requeue_pi_wake_futex, futex_proxy_trylock_atomic, futex_requeue",
          "description": "实现futex_requeue函数，负责将等待队列从源哈希桶迁移到目标哈希桶，支持PI模式下的锁抢占与状态一致性维护。",
          "similarity": 0.6208422183990479
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/futex/requeue.c",
          "start_line": 1,
          "end_line": 73,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-or-later",
            "",
            "#include <linux/plist.h>",
            "#include <linux/sched/signal.h>",
            "",
            "#include \"futex.h\"",
            "#include \"../locking/rtmutex_common.h\"",
            "",
            "/*",
            " * On PREEMPT_RT, the hash bucket lock is a 'sleeping' spinlock with an",
            " * underlying rtmutex. The task which is about to be requeued could have",
            " * just woken up (timeout, signal). After the wake up the task has to",
            " * acquire hash bucket lock, which is held by the requeue code.  As a task",
            " * can only be blocked on _ONE_ rtmutex at a time, the proxy lock blocking",
            " * and the hash bucket lock blocking would collide and corrupt state.",
            " *",
            " * On !PREEMPT_RT this is not a problem and everything could be serialized",
            " * on hash bucket lock, but aside of having the benefit of common code,",
            " * this allows to avoid doing the requeue when the task is already on the",
            " * way out and taking the hash bucket lock of the original uaddr1 when the",
            " * requeue has been completed.",
            " *",
            " * The following state transitions are valid:",
            " *",
            " * On the waiter side:",
            " *   Q_REQUEUE_PI_NONE\t\t-> Q_REQUEUE_PI_IGNORE",
            " *   Q_REQUEUE_PI_IN_PROGRESS\t-> Q_REQUEUE_PI_WAIT",
            " *",
            " * On the requeue side:",
            " *   Q_REQUEUE_PI_NONE\t\t-> Q_REQUEUE_PI_INPROGRESS",
            " *   Q_REQUEUE_PI_IN_PROGRESS\t-> Q_REQUEUE_PI_DONE/LOCKED",
            " *   Q_REQUEUE_PI_IN_PROGRESS\t-> Q_REQUEUE_PI_NONE (requeue failed)",
            " *   Q_REQUEUE_PI_WAIT\t\t-> Q_REQUEUE_PI_DONE/LOCKED",
            " *   Q_REQUEUE_PI_WAIT\t\t-> Q_REQUEUE_PI_IGNORE (requeue failed)",
            " *",
            " * The requeue side ignores a waiter with state Q_REQUEUE_PI_IGNORE as this",
            " * signals that the waiter is already on the way out. It also means that",
            " * the waiter is still on the 'wait' futex, i.e. uaddr1.",
            " *",
            " * The waiter side signals early wakeup to the requeue side either through",
            " * setting state to Q_REQUEUE_PI_IGNORE or to Q_REQUEUE_PI_WAIT depending",
            " * on the current state. In case of Q_REQUEUE_PI_IGNORE it can immediately",
            " * proceed to take the hash bucket lock of uaddr1. If it set state to WAIT,",
            " * which means the wakeup is interleaving with a requeue in progress it has",
            " * to wait for the requeue side to change the state. Either to DONE/LOCKED",
            " * or to IGNORE. DONE/LOCKED means the waiter q is now on the uaddr2 futex",
            " * and either blocked (DONE) or has acquired it (LOCKED). IGNORE is set by",
            " * the requeue side when the requeue attempt failed via deadlock detection",
            " * and therefore the waiter q is still on the uaddr1 futex.",
            " */",
            "enum {",
            "\tQ_REQUEUE_PI_NONE\t\t=  0,",
            "\tQ_REQUEUE_PI_IGNORE,",
            "\tQ_REQUEUE_PI_IN_PROGRESS,",
            "\tQ_REQUEUE_PI_WAIT,",
            "\tQ_REQUEUE_PI_DONE,",
            "\tQ_REQUEUE_PI_LOCKED,",
            "};",
            "",
            "const struct futex_q futex_q_init = {",
            "\t/* list gets initialized in futex_queue()*/",
            "\t.key\t\t= FUTEX_KEY_INIT,",
            "\t.bitset\t\t= FUTEX_BITSET_MATCH_ANY,",
            "\t.requeue_state\t= ATOMIC_INIT(Q_REQUEUE_PI_NONE),",
            "};",
            "",
            "/**",
            " * requeue_futex() - Requeue a futex_q from one hb to another",
            " * @q:\t\tthe futex_q to requeue",
            " * @hb1:\tthe source hash_bucket",
            " * @hb2:\tthe target hash_bucket",
            " * @key2:\tthe new key for the requeued futex_q",
            " */"
          ],
          "function_name": null,
          "description": "定义FUTEX_REQUEUE_PI状态常量并初始化futex_q结构体，用于管理基于优先级继承的futex重新排队操作的状态机。",
          "similarity": 0.557669997215271
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/futex/requeue.c",
          "start_line": 695,
          "end_line": 862,
          "content": [
            "static inline",
            "int handle_early_requeue_pi_wakeup(struct futex_hash_bucket *hb,",
            "\t\t\t\t   struct futex_q *q,",
            "\t\t\t\t   struct hrtimer_sleeper *timeout)",
            "{",
            "\tint ret;",
            "",
            "\t/*",
            "\t * With the hb lock held, we avoid races while we process the wakeup.",
            "\t * We only need to hold hb (and not hb2) to ensure atomicity as the",
            "\t * wakeup code can't change q.key from uaddr to uaddr2 if we hold hb.",
            "\t * It can't be requeued from uaddr2 to something else since we don't",
            "\t * support a PI aware source futex for requeue.",
            "\t */",
            "\tWARN_ON_ONCE(&hb->lock != q->lock_ptr);",
            "",
            "\t/*",
            "\t * We were woken prior to requeue by a timeout or a signal.",
            "\t * Unqueue the futex_q and determine which it was.",
            "\t */",
            "\tplist_del(&q->list, &hb->chain);",
            "\tfutex_hb_waiters_dec(hb);",
            "",
            "\t/* Handle spurious wakeups gracefully */",
            "\tret = -EWOULDBLOCK;",
            "\tif (timeout && !timeout->task)",
            "\t\tret = -ETIMEDOUT;",
            "\telse if (signal_pending(current))",
            "\t\tret = -ERESTARTNOINTR;",
            "\treturn ret;",
            "}",
            "int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,",
            "\t\t\t  u32 val, ktime_t *abs_time, u32 bitset,",
            "\t\t\t  u32 __user *uaddr2)",
            "{",
            "\tstruct hrtimer_sleeper timeout, *to;",
            "\tstruct rt_mutex_waiter rt_waiter;",
            "\tstruct futex_hash_bucket *hb;",
            "\tunion futex_key key2 = FUTEX_KEY_INIT;",
            "\tstruct futex_q q = futex_q_init;",
            "\tstruct rt_mutex_base *pi_mutex;",
            "\tint res, ret;",
            "",
            "\tif (!IS_ENABLED(CONFIG_FUTEX_PI))",
            "\t\treturn -ENOSYS;",
            "",
            "\tif (uaddr == uaddr2)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (!bitset)",
            "\t\treturn -EINVAL;",
            "",
            "\tto = futex_setup_timer(abs_time, &timeout, flags,",
            "\t\t\t       current->timer_slack_ns);",
            "",
            "\t/*",
            "\t * The waiter is allocated on our stack, manipulated by the requeue",
            "\t * code while we sleep on uaddr.",
            "\t */",
            "\trt_mutex_init_waiter(&rt_waiter);",
            "",
            "\tret = get_futex_key(uaddr2, flags, &key2, FUTEX_WRITE);",
            "\tif (unlikely(ret != 0))",
            "\t\tgoto out;",
            "",
            "\tq.bitset = bitset;",
            "\tq.rt_waiter = &rt_waiter;",
            "\tq.requeue_pi_key = &key2;",
            "",
            "\t/*",
            "\t * Prepare to wait on uaddr. On success, it holds hb->lock and q",
            "\t * is initialized.",
            "\t */",
            "\tret = futex_wait_setup(uaddr, val, flags, &q, &hb);",
            "\tif (ret)",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * The check above which compares uaddrs is not sufficient for",
            "\t * shared futexes. We need to compare the keys:",
            "\t */",
            "\tif (futex_match(&q.key, &key2)) {",
            "\t\tfutex_q_unlock(hb);",
            "\t\tret = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/* Queue the futex_q, drop the hb lock, wait for wakeup. */",
            "\tfutex_wait_queue(hb, &q, to);",
            "",
            "\tswitch (futex_requeue_pi_wakeup_sync(&q)) {",
            "\tcase Q_REQUEUE_PI_IGNORE:",
            "\t\t/* The waiter is still on uaddr1 */",
            "\t\tspin_lock(&hb->lock);",
            "\t\tret = handle_early_requeue_pi_wakeup(hb, &q, to);",
            "\t\tspin_unlock(&hb->lock);",
            "\t\tbreak;",
            "",
            "\tcase Q_REQUEUE_PI_LOCKED:",
            "\t\t/* The requeue acquired the lock */",
            "\t\tif (q.pi_state && (q.pi_state->owner != current)) {",
            "\t\t\tspin_lock(q.lock_ptr);",
            "\t\t\tret = fixup_pi_owner(uaddr2, &q, true);",
            "\t\t\t/*",
            "\t\t\t * Drop the reference to the pi state which the",
            "\t\t\t * requeue_pi() code acquired for us.",
            "\t\t\t */",
            "\t\t\tput_pi_state(q.pi_state);",
            "\t\t\tspin_unlock(q.lock_ptr);",
            "\t\t\t/*",
            "\t\t\t * Adjust the return value. It's either -EFAULT or",
            "\t\t\t * success (1) but the caller expects 0 for success.",
            "\t\t\t */",
            "\t\t\tret = ret < 0 ? ret : 0;",
            "\t\t}",
            "\t\tbreak;",
            "",
            "\tcase Q_REQUEUE_PI_DONE:",
            "\t\t/* Requeue completed. Current is 'pi_blocked_on' the rtmutex */",
            "\t\tpi_mutex = &q.pi_state->pi_mutex;",
            "\t\tret = rt_mutex_wait_proxy_lock(pi_mutex, to, &rt_waiter);",
            "",
            "\t\t/*",
            "\t\t * See futex_unlock_pi()'s cleanup: comment.",
            "\t\t */",
            "\t\tif (ret && !rt_mutex_cleanup_proxy_lock(pi_mutex, &rt_waiter))",
            "\t\t\tret = 0;",
            "",
            "\t\tspin_lock(q.lock_ptr);",
            "\t\tdebug_rt_mutex_free_waiter(&rt_waiter);",
            "\t\t/*",
            "\t\t * Fixup the pi_state owner and possibly acquire the lock if we",
            "\t\t * haven't already.",
            "\t\t */",
            "\t\tres = fixup_pi_owner(uaddr2, &q, !ret);",
            "\t\t/*",
            "\t\t * If fixup_pi_owner() returned an error, propagate that.  If it",
            "\t\t * acquired the lock, clear -ETIMEDOUT or -EINTR.",
            "\t\t */",
            "\t\tif (res)",
            "\t\t\tret = (res < 0) ? res : 0;",
            "",
            "\t\tfutex_unqueue_pi(&q);",
            "\t\tspin_unlock(q.lock_ptr);",
            "",
            "\t\tif (ret == -EINTR) {",
            "\t\t\t/*",
            "\t\t\t * We've already been requeued, but cannot restart",
            "\t\t\t * by calling futex_lock_pi() directly. We could",
            "\t\t\t * restart this syscall, but it would detect that",
            "\t\t\t * the user space \"val\" changed and return",
            "\t\t\t * -EWOULDBLOCK.  Save the overhead of the restart",
            "\t\t\t * and return -EWOULDBLOCK directly.",
            "\t\t\t */",
            "\t\t\tret = -EWOULDBLOCK;",
            "\t\t}",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "",
            "out:",
            "\tif (to) {",
            "\t\thrtimer_cancel(&to->timer);",
            "\t\tdestroy_hrtimer_on_stack(&to->timer);",
            "\t}",
            "\treturn ret;",
            "}"
          ],
          "function_name": "handle_early_requeue_pi_wakeup, futex_wait_requeue_pi",
          "description": "处理基于优先级继承的等待超时或信号唤醒场景，通过锁保护确保状态转换正确性，并执行必要的清理和错误恢复操作。",
          "similarity": 0.5324760675430298
        }
      ]
    }
  ]
}