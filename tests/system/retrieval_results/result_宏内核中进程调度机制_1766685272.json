{
  "query": "宏内核中进程调度机制",
  "timestamp": "2025-12-26 01:54:32",
  "retrieved_files": [
    {
      "source_file": "kernel/sched/sched.h",
      "md_summary": "> 自动生成时间: 2025-10-25 16:16:13\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\sched.h`\n\n---\n\n# `sched/sched.h` 技术文档\n\n## 1. 文件概述\n\n`sched/sched.h` 是 Linux 内核调度器（Scheduler）的核心内部头文件，定义了调度子系统内部使用的类型、宏、辅助函数和全局变量。该文件不对外暴露给其他子系统直接使用，而是作为调度器各组件（如 CFS、RT、Deadline 调度类）之间的内部接口和共享基础设施。它整合了任务状态管理、负载计算、策略判断、CPU 能力建模、cgroup 权重转换等关键调度逻辑，并为调试、性能追踪和平台适配提供支持。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct asym_cap_data`：用于描述非对称 CPU 架构中不同 CPU 集合的计算能力（capacity），支持异构多核系统（如 big.LITTLE）的调度优化。\n- `struct rq`（前向声明）：运行队列（runqueue）结构体，每个 CPU 对应一个，是调度器管理可运行任务的核心数据结构。\n- `struct cpuidle_state`（前向声明）：CPU 空闲状态信息，用于与调度器协同进行能效管理。\n\n### 关键全局变量\n- `scheduler_running`：标志调度器是否已启动。\n- `calc_load_update` / `calc_load_tasks`：用于全局负载（load average）计算的时间戳和任务计数。\n- `sysctl_sched_rt_period` / `sysctl_sched_rt_runtime`：实时任务带宽控制参数。\n- `sched_rr_timeslice`：SCHED_RR 策略的时间片长度。\n- `asym_cap_list`：非对称 CPU 能力数据的全局链表。\n\n### 核心辅助函数与宏\n- **任务策略判断函数**：\n  - `idle_policy()` / `task_has_idle_policy()`\n  - `normal_policy()` / `fair_policy()`\n  - `rt_policy()` / `task_has_rt_policy()`\n  - `dl_policy()` / `task_has_dl_policy()`\n  - `valid_policy()`\n- **负载与权重转换**：\n  - `scale_load()` / `scale_load_down()`：在内部高精度负载值与用户可见权重间转换。\n  - `sched_weight_from_cgroup()` / `sched_weight_to_cgroup()`：cgroup 权重与调度器内部权重的映射。\n- **时间与精度处理**：\n  - `NS_TO_JIFFIES()`：纳秒转 jiffies。\n  - `update_avg()`：指数移动平均（EMA）更新。\n  - `shr_bound()`：安全右移，避免未定义行为。\n- **特殊调度标志**：\n  - `SCHED_FLAG_SUGOV`：用于 schedutil 频率调节器的特殊标志，使相关 kworker 临时获得高于 SCHED_DEADLINE 的优先级。\n  - `dl_entity_is_special()`：判断 Deadline 实体是否为 SUGOV 特殊任务。\n\n### 重要宏定义\n- `TASK_ON_RQ_QUEUED` / `TASK_ON_RQ_MIGRATING`：`task_struct::on_rq` 字段的状态值。\n- `NICE_0_LOAD`：nice 值为 0 的任务对应的内部负载基准值。\n- `DL_SCALE`：SCHED_DEADLINE 内部计算的精度因子。\n- `RUNTIME_INF`：表示无限运行时间的常量。\n- `SCHED_WARN_ON()`：调度器专用的条件警告宏（仅在 `CONFIG_SCHED_DEBUG` 时生效）。\n\n## 3. 关键实现\n\n### 高精度负载计算（64 位优化）\n在 64 位架构上，通过 `NICE_0_LOAD_SHIFT = 2 * SCHED_FIXEDPOINT_SHIFT` 提升内部负载计算的精度，改善低权重任务组（如 nice +19）和深层 cgroup 层级的负载均衡效果。`scale_load()` 和 `scale_load_down()` 实现了用户权重与内部高精度负载值之间的无损转换。\n\n### 非对称 CPU 能力建模\n`asym_cap_data` 结构体结合 `cpu_capacity_span()` 宏，将具有相同计算能力的 CPU 归为一组，并通过全局链表 `asym_cap_list` 管理。这为调度器在异构系统中进行负载均衡和任务迁移提供关键拓扑信息。\n\n### cgroup 权重标准化\n通过 `sched_weight_from_cgroup()` 和 `sched_weight_to_cgroup()`，将 cgroup 接口的权重范围（1–10000，默认 100）映射到调度器内部使用的权重值（基于 1024 基准），确保用户配置与调度行为的一致性。\n\n### SCHED_DEADLINE 与频率调节协同\n引入 `SCHED_FLAG_SUGOV` 标志，允许 `schedutil` 频率调节器的工作线程在需要时临时突破 SCHED_DEADLINE 的优先级限制，以解决某些平台无法原子切换 CPU 频率的问题。这是一种临时性 workaround，依赖于 `dl_entity_is_special()` 进行识别。\n\n### 安全位运算\n`shr_bound()` 宏确保右移操作不会因移位数过大而触发未定义行为（UB），通过 `min_t()` 将移位数限制在 `BITS_PER_TYPE(val) - 1` 以内。\n\n## 4. 依赖关系\n\n### 内核头文件依赖\n- **调度子系统内部**：包含多个调度相关子模块头文件（如 `affinity.h`, `deadline.h`, `topology.h`, `cpupri.h` 等）。\n- **核心内核设施**：依赖 `atomic.h`, `rcupdate.h`, `cpumask_api.h`, `ktime_api.h`, `trace/events/sched.h` 等。\n- **平台与虚拟化**：条件包含 `asm/paravirt.h`（半虚拟化支持）和 `asm/barrier.h`（内存屏障）。\n- **工作队列**：包含 `../workqueue_internal.h`，用于与工作队列子系统交互。\n\n### 配置选项依赖\n- `CONFIG_64BIT`：启用高精度负载计算。\n- `CONFIG_SCHED_DEBUG`：启用 `SCHED_WARN_ON()` 调试检查。\n- `CONFIG_CPU_FREQ_GOV_SCHEDUTIL`：启用 `SCHED_FLAG_SUGOV` 相关逻辑。\n- `CONFIG_SCHED_CLASS_EXT`：扩展调度类支持（影响 `normal_policy()` 判断）。\n- `CONFIG_PARAVIRT`：半虚拟化支持。\n\n## 5. 使用场景\n\n- **调度器初始化与运行**：`scheduler_running` 和负载计算变量在调度器启动和周期性负载更新中使用。\n- **任务调度策略处理**：所有调度类（CFS、RT、Deadline、Idle）在入队、出队、选择下一个任务时，通过策略判断函数确定任务类型。\n- **负载均衡与迁移**：`asym_cap_data` 和 CPU 拓扑信息用于跨 CPU 的任务迁移决策，尤其在异构系统中。\n- **cgroup 资源控制**：在设置或读取 cgroup 的 CPU 权重时，通过权重转换函数确保调度器内部表示与用户接口一致。\n- **实时带宽管理**：`sysctl_sched_rt_*` 参数用于限制 SCHED_FIFO/SCHED_RR 任务的 CPU 使用率。\n- **能效调度协同**：`SCHED_FLAG_SUGOV` 机制使频率调节器能及时响应 Deadline 任务的性能需求。\n- **内核调试与追踪**：`SCHED_WARN_ON()` 用于捕获调度器内部异常状态；tracepoint 定义支持调度事件追踪。",
      "similarity": 0.6292101740837097,
      "chunks": []
    },
    {
      "source_file": "kernel/workqueue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:53:20\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `workqueue.c`\n\n---\n\n# workqueue.c 技术文档\n\n## 1. 文件概述\n\n`workqueue.c` 是 Linux 内核中实现通用异步执行机制的核心文件，提供基于共享工作线程池（worker pool）的延迟任务调度功能。工作项（work items）在进程上下文中执行，支持 CPU 绑定和非绑定两种模式。每个 CPU 默认拥有两个标准工作池（普通优先级和高优先级），同时支持动态创建非绑定工作池以满足不同工作队列的需求。该机制替代了早期的 taskqueue/keventd 实现，具有更高的可扩展性和资源利用率。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct worker_pool`**  \n  工作线程池结构体，管理一组工作线程（workers），包含：\n  - `lock`：保护池状态的自旋锁\n  - `cpu` / `node`：关联的 CPU 和 NUMA 节点（绑定池）\n  - `worklist`：待处理工作项队列\n  - `idle_list` / `busy_hash`：空闲和忙碌工作线程的管理结构\n  - `nr_workers` / `nr_idle`：工作线程数量统计\n  - `attrs`：工作线程属性（如优先级、CPU 亲和性）\n  - `mayday_timer`：紧急情况下的救援请求定时器\n\n- **`struct pool_workqueue`**  \n  工作队列与工作池之间的关联结构，每个工作队列在每个池中都有一个对应的 `pool_workqueue` 实例，用于：\n  - 管理工作项的入队和执行\n  - 实现 `max_active` 限制（控制并发执行数）\n  - 支持 flush 操作（等待所有工作完成）\n  - 统计性能指标（如启动/完成次数、CPU 时间等）\n\n- **`struct worker`**（定义在 `workqueue_internal.h`）  \n  工作线程的运行时上下文，包含状态标志（如 `WORKER_IDLE`, `WORKER_UNBOUND`）、当前执行的工作项等。\n\n### 关键枚举与常量\n\n- **池/工作线程标志**：\n  - `POOL_DISASSOCIATED`：CPU 离线时池进入非绑定状态\n  - `WORKER_UNBOUND`：工作线程可在任意 CPU 上运行\n  - `WORKER_CPU_INTENSIVE`：标记 CPU 密集型任务，影响并发控制\n\n- **配置参数**：\n  - `NR_STD_WORKER_POOLS = 2`：每 CPU 标准池数量（普通 + 高优先级）\n  - `IDLE_WORKER_TIMEOUT = 300 * HZ`：空闲线程保留时间（5 分钟）\n  - `MAYDAY_INITIAL_TIMEOUT`：工作积压时触发救援的延迟（10ms）\n\n- **统计指标**（`pool_workqueue_stats`）：\n  - `PWQ_STAT_STARTED` / `PWQ_STAT_COMPLETED`：工作项执行统计\n  - `PWQ_STAT_MAYDAY` / `PWQ_STAT_RESCUED`：紧急救援事件计数\n\n## 3. 关键实现\n\n### 工作池管理\n- **绑定池（Bound Pool）**：与特定 CPU 关联，工作线程默认绑定到该 CPU。当 CPU 离线时，池进入 `DISASSOCIATED` 状态，工作线程转为非绑定模式。\n- **非绑定池（Unbound Pool）**：动态创建，通过哈希表（`unbound_pool_hash`）按属性（`workqueue_attrs`）去重，支持跨 CPU 调度。\n- **并发控制**：通过 `nr_running` 计数器和 `max_active` 限制，防止工作项过度并发执行。\n\n### 工作线程生命周期\n- **空闲管理**：空闲线程加入 `idle_list`，超时（`IDLE_WORKER_TIMEOUT`）后被回收。\n- **动态伸缩**：当工作积压时，通过 `mayday_timer` 触发新线程创建；若创建失败，向全局救援线程（rescuer）求助。\n- **状态标志**：使用位标志（如 `WORKER_IDLE`, `WORKER_PREP`）高效管理线程状态，避免锁竞争。\n\n### 内存与同步\n- **RCU 保护**：工作池销毁通过 RCU 延迟释放，确保 `get_work_pool()` 等读取路径无锁安全。\n- **锁分层**：\n  - `pool->lock`（自旋锁）：保护池内部状态\n  - `wq_pool_mutex`：全局池管理互斥锁\n  - `wq_pool_attach_mutex`：防止 CPU 绑定状态变更冲突\n\n### 工作项调度\n- **数据指针复用**：`work_struct->data` 的高有效位存储 `pool_workqueue` 指针，低有效位用于标志位（如 `WORK_STRUCT_INACTIVE`）。\n- **优先级支持**：高优先级工作池使用 `HIGHPRI_NICE_LEVEL = MIN_NICE` 提升调度优先级。\n\n## 4. 依赖关系\n\n- **内核子系统**：\n  - **调度器**（`<linux/sched.h>`）：创建工作线程（kworker），管理 CPU 亲和性\n  - **内存管理**（`<linux/slab.h>`）：分配工作池、工作队列等结构\n  - **CPU 热插拔**（`<linux/cpu.h>`）：处理 CPU 上下线时的池绑定状态切换\n  - **RCU**（`<linux/rculist.h>`）：实现无锁读取路径\n  - **定时器**（`<linux/timer.h>`）：实现空闲超时和救援机制\n\n- **内部依赖**：\n  - `workqueue_internal.h`：定义 `struct worker` 等内部结构\n  - `Documentation/core-api/workqueue.rst`：详细设计文档\n\n## 5. 使用场景\n\n- **驱动程序延迟操作**：硬件中断后调度下半部处理（如网络包处理、磁盘 I/O 完成回调）。\n- **内核子系统异步任务**：文件系统元数据更新、内存回收、电源管理状态切换。\n- **高优先级任务**：使用 `WQ_HIGHPRI` 标志创建工作队列，确保关键任务及时执行（如死锁恢复）。\n- **CPU 密集型任务**：标记 `WQ_CPU_INTENSIVE` 避免占用过多并发槽位，提升系统响应性。\n- **NUMA 感知调度**：非绑定工作队列可指定 NUMA 节点，优化内存访问延迟。",
      "similarity": 0.606261670589447,
      "chunks": [
        {
          "chunk_id": 33,
          "file_path": "kernel/workqueue.c",
          "start_line": 6492,
          "end_line": 6592,
          "content": [
            "static void panic_on_wq_watchdog(void)",
            "{",
            "\tstatic unsigned int wq_stall;",
            "",
            "\tif (wq_panic_on_stall) {",
            "\t\twq_stall++;",
            "\t\tBUG_ON(wq_stall >= wq_panic_on_stall);",
            "\t}",
            "}",
            "static void wq_watchdog_reset_touched(void)",
            "{",
            "\tint cpu;",
            "",
            "\twq_watchdog_touched = jiffies;",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tper_cpu(wq_watchdog_touched_cpu, cpu) = jiffies;",
            "}",
            "static void wq_watchdog_timer_fn(struct timer_list *unused)",
            "{",
            "\tunsigned long thresh = READ_ONCE(wq_watchdog_thresh) * HZ;",
            "\tbool lockup_detected = false;",
            "\tbool cpu_pool_stall = false;",
            "\tunsigned long now = jiffies;",
            "\tstruct worker_pool *pool;",
            "\tint pi;",
            "",
            "\tif (!thresh)",
            "\t\treturn;",
            "",
            "\trcu_read_lock();",
            "",
            "\tfor_each_pool(pool, pi) {",
            "\t\tunsigned long pool_ts, touched, ts;",
            "",
            "\t\tpool->cpu_stall = false;",
            "\t\tif (list_empty(&pool->worklist))",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * If a virtual machine is stopped by the host it can look to",
            "\t\t * the watchdog like a stall.",
            "\t\t */",
            "\t\tkvm_check_and_clear_guest_paused();",
            "",
            "\t\t/* get the latest of pool and touched timestamps */",
            "\t\tif (pool->cpu >= 0)",
            "\t\t\ttouched = READ_ONCE(per_cpu(wq_watchdog_touched_cpu, pool->cpu));",
            "\t\telse",
            "\t\t\ttouched = READ_ONCE(wq_watchdog_touched);",
            "\t\tpool_ts = READ_ONCE(pool->watchdog_ts);",
            "",
            "\t\tif (time_after(pool_ts, touched))",
            "\t\t\tts = pool_ts;",
            "\t\telse",
            "\t\t\tts = touched;",
            "",
            "\t\t/* did we stall? */",
            "\t\tif (time_after(now, ts + thresh)) {",
            "\t\t\tlockup_detected = true;",
            "\t\t\tif (pool->cpu >= 0) {",
            "\t\t\t\tpool->cpu_stall = true;",
            "\t\t\t\tcpu_pool_stall = true;",
            "\t\t\t}",
            "\t\t\tpr_emerg(\"BUG: workqueue lockup - pool\");",
            "\t\t\tpr_cont_pool_info(pool);",
            "\t\t\tpr_cont(\" stuck for %us!\\n\",",
            "\t\t\t\tjiffies_to_msecs(now - pool_ts) / 1000);",
            "\t\t}",
            "",
            "",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "",
            "\tif (lockup_detected)",
            "\t\tshow_all_workqueues();",
            "",
            "\tif (cpu_pool_stall)",
            "\t\tshow_cpu_pools_hogs();",
            "",
            "\tif (lockup_detected)",
            "\t\tpanic_on_wq_watchdog();",
            "",
            "\twq_watchdog_reset_touched();",
            "\tmod_timer(&wq_watchdog_timer, jiffies + thresh);",
            "}",
            "notrace void wq_watchdog_touch(int cpu)",
            "{",
            "\tunsigned long thresh = READ_ONCE(wq_watchdog_thresh) * HZ;",
            "\tunsigned long touch_ts = READ_ONCE(wq_watchdog_touched);",
            "\tunsigned long now = jiffies;",
            "",
            "\tif (cpu >= 0)",
            "\t\tper_cpu(wq_watchdog_touched_cpu, cpu) = now;",
            "\telse",
            "\t\tWARN_ONCE(1, \"%s should be called with valid CPU\", __func__);",
            "",
            "\t/* Don't unnecessarily store to global cacheline */",
            "\tif (time_after(now, touch_ts + thresh / 4))",
            "\t\tWRITE_ONCE(wq_watchdog_touched, jiffies);",
            "}"
          ],
          "function_name": "panic_on_wq_watchdog, wq_watchdog_reset_touched, wq_watchdog_timer_fn, wq_watchdog_touch",
          "description": "实现工作队列看门狗机制，通过定时器周期性检测任务阻塞状态，当检测到CPU池超时时触发警告日志和panic，包含超时阈值管理、时间戳更新及阻塞状态标识逻辑。",
          "similarity": 0.5889946222305298
        },
        {
          "chunk_id": 27,
          "file_path": "kernel/workqueue.c",
          "start_line": 5563,
          "end_line": 5664,
          "content": [
            "int workqueue_prepare_cpu(unsigned int cpu)",
            "{",
            "\tstruct worker_pool *pool;",
            "",
            "\tfor_each_cpu_worker_pool(pool, cpu) {",
            "\t\tif (pool->nr_workers)",
            "\t\t\tcontinue;",
            "\t\tif (!create_worker(pool))",
            "\t\t\treturn -ENOMEM;",
            "\t}",
            "\treturn 0;",
            "}",
            "int workqueue_online_cpu(unsigned int cpu)",
            "{",
            "\tstruct worker_pool *pool;",
            "\tstruct workqueue_struct *wq;",
            "\tint pi;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tfor_each_pool(pool, pi) {",
            "\t\tmutex_lock(&wq_pool_attach_mutex);",
            "",
            "\t\tif (pool->cpu == cpu)",
            "\t\t\trebind_workers(pool);",
            "\t\telse if (pool->cpu < 0)",
            "\t\t\trestore_unbound_workers_cpumask(pool, cpu);",
            "",
            "\t\tmutex_unlock(&wq_pool_attach_mutex);",
            "\t}",
            "",
            "\t/* update pod affinity of unbound workqueues */",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tstruct workqueue_attrs *attrs = wq->unbound_attrs;",
            "",
            "\t\tif (attrs) {",
            "\t\t\tconst struct wq_pod_type *pt = wqattrs_pod_type(attrs);",
            "\t\t\tint tcpu;",
            "",
            "\t\t\tfor_each_cpu(tcpu, pt->pod_cpus[pt->cpu_pod[cpu]])",
            "\t\t\t\twq_update_pod(wq, tcpu, cpu, true);",
            "\t\t}",
            "\t}",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\treturn 0;",
            "}",
            "int workqueue_offline_cpu(unsigned int cpu)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "",
            "\t/* unbinding per-cpu workers should happen on the local CPU */",
            "\tif (WARN_ON(cpu != smp_processor_id()))",
            "\t\treturn -1;",
            "",
            "\tunbind_workers(cpu);",
            "",
            "\t/* update pod affinity of unbound workqueues */",
            "\tmutex_lock(&wq_pool_mutex);",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tstruct workqueue_attrs *attrs = wq->unbound_attrs;",
            "",
            "\t\tif (attrs) {",
            "\t\t\tconst struct wq_pod_type *pt = wqattrs_pod_type(attrs);",
            "\t\t\tint tcpu;",
            "",
            "\t\t\tfor_each_cpu(tcpu, pt->pod_cpus[pt->cpu_pod[cpu]])",
            "\t\t\t\twq_update_pod(wq, tcpu, cpu, false);",
            "\t\t}",
            "\t}",
            "\tmutex_unlock(&wq_pool_mutex);",
            "",
            "\treturn 0;",
            "}",
            "static void work_for_cpu_fn(struct work_struct *work)",
            "{",
            "\tstruct work_for_cpu *wfc = container_of(work, struct work_for_cpu, work);",
            "",
            "\twfc->ret = wfc->fn(wfc->arg);",
            "}",
            "long work_on_cpu_key(int cpu, long (*fn)(void *),",
            "\t\t     void *arg, struct lock_class_key *key)",
            "{",
            "\tstruct work_for_cpu wfc = { .fn = fn, .arg = arg };",
            "",
            "\tINIT_WORK_ONSTACK_KEY(&wfc.work, work_for_cpu_fn, key);",
            "\tschedule_work_on(cpu, &wfc.work);",
            "\tflush_work(&wfc.work);",
            "\tdestroy_work_on_stack(&wfc.work);",
            "\treturn wfc.ret;",
            "}",
            "long work_on_cpu_safe_key(int cpu, long (*fn)(void *),",
            "\t\t\t  void *arg, struct lock_class_key *key)",
            "{",
            "\tlong ret = -ENODEV;",
            "",
            "\tcpus_read_lock();",
            "\tif (cpu_online(cpu))",
            "\t\tret = work_on_cpu_key(cpu, fn, arg, key);",
            "\tcpus_read_unlock();",
            "\treturn ret;",
            "}"
          ],
          "function_name": "workqueue_prepare_cpu, workqueue_online_cpu, workqueue_offline_cpu, work_for_cpu_fn, work_on_cpu_key, work_on_cpu_safe_key",
          "description": "处理CPU事件生命周期，准备工作者、更新工作者池状态，并提供跨CPU任务执行接口以保证调度一致性",
          "similarity": 0.5772678852081299
        },
        {
          "chunk_id": 29,
          "file_path": "kernel/workqueue.c",
          "start_line": 5864,
          "end_line": 5966,
          "content": [
            "int workqueue_unbound_exclude_cpumask(cpumask_var_t exclude_cpumask)",
            "{",
            "\tcpumask_var_t cpumask;",
            "\tint ret = 0;",
            "",
            "\tif (!zalloc_cpumask_var(&cpumask, GFP_KERNEL))",
            "\t\treturn -ENOMEM;",
            "",
            "\tlockdep_assert_cpus_held();",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\t/* Save the current isolated cpumask & export it via sysfs */",
            "\tcpumask_copy(wq_isolated_cpumask, exclude_cpumask);",
            "",
            "\t/*",
            "\t * If the operation fails, it will fall back to",
            "\t * wq_requested_unbound_cpumask which is initially set to",
            "\t * (HK_TYPE_WQ ∩ HK_TYPE_DOMAIN) house keeping mask and rewritten",
            "\t * by any subsequent write to workqueue/cpumask sysfs file.",
            "\t */",
            "\tif (!cpumask_andnot(cpumask, wq_requested_unbound_cpumask, exclude_cpumask))",
            "\t\tcpumask_copy(cpumask, wq_requested_unbound_cpumask);",
            "\tif (!cpumask_equal(cpumask, wq_unbound_cpumask))",
            "\t\tret = workqueue_apply_unbound_cpumask(cpumask);",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tfree_cpumask_var(cpumask);",
            "\treturn ret;",
            "}",
            "static int parse_affn_scope(const char *val)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < ARRAY_SIZE(wq_affn_names); i++) {",
            "\t\tif (!strncasecmp(val, wq_affn_names[i], strlen(wq_affn_names[i])))",
            "\t\t\treturn i;",
            "\t}",
            "\treturn -EINVAL;",
            "}",
            "static int wq_affn_dfl_set(const char *val, const struct kernel_param *kp)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tint affn, cpu;",
            "",
            "\taffn = parse_affn_scope(val);",
            "\tif (affn < 0)",
            "\t\treturn affn;",
            "\tif (affn == WQ_AFFN_DFL)",
            "\t\treturn -EINVAL;",
            "",
            "\tcpus_read_lock();",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\twq_affn_dfl = affn;",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tfor_each_online_cpu(cpu) {",
            "\t\t\twq_update_pod(wq, cpu, cpu, true);",
            "\t\t}",
            "\t}",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tcpus_read_unlock();",
            "",
            "\treturn 0;",
            "}",
            "static int wq_affn_dfl_get(char *buffer, const struct kernel_param *kp)",
            "{",
            "\treturn scnprintf(buffer, PAGE_SIZE, \"%s\\n\", wq_affn_names[wq_affn_dfl]);",
            "}",
            "static ssize_t per_cpu_show(struct device *dev, struct device_attribute *attr,",
            "\t\t\t    char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "",
            "\treturn scnprintf(buf, PAGE_SIZE, \"%d\\n\", (bool)!(wq->flags & WQ_UNBOUND));",
            "}",
            "static ssize_t max_active_show(struct device *dev,",
            "\t\t\t       struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "",
            "\treturn scnprintf(buf, PAGE_SIZE, \"%d\\n\", wq->saved_max_active);",
            "}",
            "static ssize_t max_active_store(struct device *dev,",
            "\t\t\t\tstruct device_attribute *attr, const char *buf,",
            "\t\t\t\tsize_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint val;",
            "",
            "\tif (sscanf(buf, \"%d\", &val) != 1 || val <= 0)",
            "\t\treturn -EINVAL;",
            "",
            "\tworkqueue_set_max_active(wq, val);",
            "\treturn count;",
            "}",
            "static void apply_wqattrs_lock(void)",
            "{",
            "\t/* CPUs should stay stable across pwq creations and installations */",
            "\tcpus_read_lock();",
            "\tmutex_lock(&wq_pool_mutex);",
            "}"
          ],
          "function_name": "workqueue_unbound_exclude_cpumask, parse_affn_scope, wq_affn_dfl_set, wq_affn_dfl_get, per_cpu_show, max_active_show, max_active_store, apply_wqattrs_lock",
          "description": "配置非绑定工作者的CPU排除掩码和默认亲和性策略，暴露工作队列属性供sysfs访问并管理最大并发数参数",
          "similarity": 0.5730841159820557
        },
        {
          "chunk_id": 28,
          "file_path": "kernel/workqueue.c",
          "start_line": 5717,
          "end_line": 5828,
          "content": [
            "void freeze_workqueues_begin(void)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tstruct pool_workqueue *pwq;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tWARN_ON_ONCE(workqueue_freezing);",
            "\tworkqueue_freezing = true;",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tmutex_lock(&wq->mutex);",
            "\t\tfor_each_pwq(pwq, wq)",
            "\t\t\tpwq_adjust_max_active(pwq);",
            "\t\tmutex_unlock(&wq->mutex);",
            "\t}",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "}",
            "bool freeze_workqueues_busy(void)",
            "{",
            "\tbool busy = false;",
            "\tstruct workqueue_struct *wq;",
            "\tstruct pool_workqueue *pwq;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tWARN_ON_ONCE(!workqueue_freezing);",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tif (!(wq->flags & WQ_FREEZABLE))",
            "\t\t\tcontinue;",
            "\t\t/*",
            "\t\t * nr_active is monotonically decreasing.  It's safe",
            "\t\t * to peek without lock.",
            "\t\t */",
            "\t\trcu_read_lock();",
            "\t\tfor_each_pwq(pwq, wq) {",
            "\t\t\tWARN_ON_ONCE(pwq->nr_active < 0);",
            "\t\t\tif (pwq->nr_active) {",
            "\t\t\t\tbusy = true;",
            "\t\t\t\trcu_read_unlock();",
            "\t\t\t\tgoto out_unlock;",
            "\t\t\t}",
            "\t\t}",
            "\t\trcu_read_unlock();",
            "\t}",
            "out_unlock:",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\treturn busy;",
            "}",
            "void thaw_workqueues(void)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tstruct pool_workqueue *pwq;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tif (!workqueue_freezing)",
            "\t\tgoto out_unlock;",
            "",
            "\tworkqueue_freezing = false;",
            "",
            "\t/* restore max_active and repopulate worklist */",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tmutex_lock(&wq->mutex);",
            "\t\tfor_each_pwq(pwq, wq)",
            "\t\t\tpwq_adjust_max_active(pwq);",
            "\t\tmutex_unlock(&wq->mutex);",
            "\t}",
            "",
            "out_unlock:",
            "\tmutex_unlock(&wq_pool_mutex);",
            "}",
            "static int workqueue_apply_unbound_cpumask(const cpumask_var_t unbound_cpumask)",
            "{",
            "\tLIST_HEAD(ctxs);",
            "\tint ret = 0;",
            "\tstruct workqueue_struct *wq;",
            "\tstruct apply_wqattrs_ctx *ctx, *n;",
            "",
            "\tlockdep_assert_held(&wq_pool_mutex);",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tif (!(wq->flags & WQ_UNBOUND))",
            "\t\t\tcontinue;",
            "\t\t/* creating multiple pwqs breaks ordering guarantee */",
            "\t\tif (wq->flags & __WQ_ORDERED)",
            "\t\t\tcontinue;",
            "",
            "\t\tctx = apply_wqattrs_prepare(wq, wq->unbound_attrs, unbound_cpumask);",
            "\t\tif (IS_ERR(ctx)) {",
            "\t\t\tret = PTR_ERR(ctx);",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tlist_add_tail(&ctx->list, &ctxs);",
            "\t}",
            "",
            "\tlist_for_each_entry_safe(ctx, n, &ctxs, list) {",
            "\t\tif (!ret)",
            "\t\t\tapply_wqattrs_commit(ctx);",
            "\t\tapply_wqattrs_cleanup(ctx);",
            "\t}",
            "",
            "\tif (!ret) {",
            "\t\tmutex_lock(&wq_pool_attach_mutex);",
            "\t\tcpumask_copy(wq_unbound_cpumask, unbound_cpumask);",
            "\t\tmutex_unlock(&wq_pool_attach_mutex);",
            "\t}",
            "\treturn ret;",
            "}"
          ],
          "function_name": "freeze_workqueues_begin, freeze_workqueues_busy, thaw_workqueues, workqueue_apply_unbound_cpumask",
          "description": "实现工作队列冻结/解冻逻辑，检查是否存在活跃任务并调整最大并发数，动态修改非绑定工作者的CPU掩码配置",
          "similarity": 0.5719221234321594
        },
        {
          "chunk_id": 8,
          "file_path": "kernel/workqueue.c",
          "start_line": 1832,
          "end_line": 1933,
          "content": [
            "bool queue_work_on(int cpu, struct workqueue_struct *wq,",
            "\t\t   struct work_struct *work)",
            "{",
            "\tbool ret = false;",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "",
            "\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {",
            "\t\t__queue_work(cpu, wq, work);",
            "\t\tret = true;",
            "\t}",
            "",
            "\tlocal_irq_restore(flags);",
            "\treturn ret;",
            "}",
            "static int select_numa_node_cpu(int node)",
            "{",
            "\tint cpu;",
            "",
            "\t/* Delay binding to CPU if node is not valid or online */",
            "\tif (node < 0 || node >= MAX_NUMNODES || !node_online(node))",
            "\t\treturn WORK_CPU_UNBOUND;",
            "",
            "\t/* Use local node/cpu if we are already there */",
            "\tcpu = raw_smp_processor_id();",
            "\tif (node == cpu_to_node(cpu))",
            "\t\treturn cpu;",
            "",
            "\t/* Use \"random\" otherwise know as \"first\" online CPU of node */",
            "\tcpu = cpumask_any_and(cpumask_of_node(node), cpu_online_mask);",
            "",
            "\t/* If CPU is valid return that, otherwise just defer */",
            "\treturn cpu < nr_cpu_ids ? cpu : WORK_CPU_UNBOUND;",
            "}",
            "bool queue_work_node(int node, struct workqueue_struct *wq,",
            "\t\t     struct work_struct *work)",
            "{",
            "\tunsigned long flags;",
            "\tbool ret = false;",
            "",
            "\t/*",
            "\t * This current implementation is specific to unbound workqueues.",
            "\t * Specifically we only return the first available CPU for a given",
            "\t * node instead of cycling through individual CPUs within the node.",
            "\t *",
            "\t * If this is used with a per-cpu workqueue then the logic in",
            "\t * workqueue_select_cpu_near would need to be updated to allow for",
            "\t * some round robin type logic.",
            "\t */",
            "\tWARN_ON_ONCE(!(wq->flags & WQ_UNBOUND));",
            "",
            "\tlocal_irq_save(flags);",
            "",
            "\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {",
            "\t\tint cpu = select_numa_node_cpu(node);",
            "",
            "\t\t__queue_work(cpu, wq, work);",
            "\t\tret = true;",
            "\t}",
            "",
            "\tlocal_irq_restore(flags);",
            "\treturn ret;",
            "}",
            "void delayed_work_timer_fn(struct timer_list *t)",
            "{",
            "\tstruct delayed_work *dwork = from_timer(dwork, t, timer);",
            "",
            "\t/* should have been called from irqsafe timer with irq already off */",
            "\t__queue_work(dwork->cpu, dwork->wq, &dwork->work);",
            "}",
            "static void __queue_delayed_work(int cpu, struct workqueue_struct *wq,",
            "\t\t\t\tstruct delayed_work *dwork, unsigned long delay)",
            "{",
            "\tstruct timer_list *timer = &dwork->timer;",
            "\tstruct work_struct *work = &dwork->work;",
            "",
            "\tWARN_ON_ONCE(!wq);",
            "\tWARN_ON_ONCE(timer->function != delayed_work_timer_fn);",
            "\tWARN_ON_ONCE(timer_pending(timer));",
            "\tWARN_ON_ONCE(!list_empty(&work->entry));",
            "",
            "\t/*",
            "\t * If @delay is 0, queue @dwork->work immediately.  This is for",
            "\t * both optimization and correctness.  The earliest @timer can",
            "\t * expire is on the closest next tick and delayed_work users depend",
            "\t * on that there's no such delay when @delay is 0.",
            "\t */",
            "\tif (!delay) {",
            "\t\t__queue_work(cpu, wq, &dwork->work);",
            "\t\treturn;",
            "\t}",
            "",
            "\tdwork->wq = wq;",
            "\tdwork->cpu = cpu;",
            "\ttimer->expires = jiffies + delay;",
            "",
            "\tif (unlikely(cpu != WORK_CPU_UNBOUND))",
            "\t\tadd_timer_on(timer, cpu);",
            "\telse",
            "\t\tadd_timer(timer);",
            "}"
          ],
          "function_name": "queue_work_on, select_numa_node_cpu, queue_work_node, delayed_work_timer_fn, __queue_delayed_work",
          "description": "该代码块实现基于NUMA节点的延迟工作调度。queue_work_on指定CPU提交工作；select_numa_node_cpu选择节点对应的CPU；delayed_work_timer_fn作为延迟工作超时时的回调；__queue_delayed_work设置定时器并安排工作项执行。",
          "similarity": 0.5704951286315918
        }
      ]
    },
    {
      "source_file": "kernel/rcu/tree_plugin.h",
      "md_summary": "> 自动生成时间: 2025-10-25 15:48:59\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `rcu\\tree_plugin.h`\n\n---\n\n# `rcu/tree_plugin.h` 技术文档\n\n## 1. 文件概述\n\n`rcu/tree_plugin.h` 是 Linux 内核中 **树形 RCU（Read-Copy Update）机制** 的内部头文件，用于实现基于分层树结构的 RCU 互斥机制。该文件定义了适用于 **经典 RCU** 或 **可抢占 RCU（PREEMPT_RCU）** 的内部非公开接口和辅助函数，主要服务于 `kernel/rcu/tree.c` 等核心 RCU 实现模块。其核心目标是在大规模 CPU 系统中高效管理宽限期（Grace Period）的检测与回调处理，同时支持 NOCB（No-CBs，即回调卸载）等高级特性。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`rcu_rdp_is_offloaded(struct rcu_data *rdp)`**  \n  安全地判断指定 CPU 的 `rcu_data` 是否启用了 NOCB（回调卸载）模式。该函数包含严格的锁依赖检查（通过 `RCU_LOCKDEP_WARN`），确保在读取 `offloaded` 状态时不会因并发修改导致数据不一致。\n\n- **`rcu_bootup_announce_oddness(void)`**  \n  在内核启动阶段检测并打印所有非默认或调试相关的 RCU 配置参数，用于诊断和性能调优。涵盖内容包括：扇出（fanout）设置、回调水位线、FQS（Force Quiescent State）延迟、软中断处理方式、调试选项等。\n\n- **`rcu_bootup_announce(void)`**（仅 `CONFIG_PREEMPT_RCU`）  \n  启动时声明当前使用的是“可抢占的分层 RCU 实现”，并调用 `rcu_bootup_announce_oddness()` 输出配置异常信息。\n\n- **`rcu_preempt_ctxt_queue(struct rcu_node *rnp, struct rcu_data *rdp)`**（仅 `CONFIG_PREEMPT_RCU`）  \n  将当前被抢占且处于 RCU 读侧临界区的任务插入到 `rcu_node` 的阻塞任务链表（`blkd_tasks`）中的合适位置。其插入策略基于当前是否存在普通或加速宽限期（GP/EXP GP），以及当前 CPU 是否被这些宽限期阻塞，以最小化对已有宽限期的不必要阻塞。\n\n### 关键宏定义（仅 `CONFIG_PREEMPT_RCU`）\n\n- **`RCU_GP_TASKS` / `RCU_EXP_TASKS` / `RCU_GP_BLKD` / `RCU_EXP_BLKD`**  \n  用于构建决策表，表示 `rcu_node` 中普通/加速宽限期的等待状态及当前 CPU 的阻塞状态，指导 `rcu_preempt_ctxt_queue()` 的任务插入逻辑。\n\n## 3. 关键实现\n\n### 安全读取 NOCB 状态\n`rcu_rdp_is_offloaded()` 通过 `RCU_LOCKDEP_WARN` 强制要求调用者必须持有以下任一同步原语：\n- `rcu_state.barrier_mutex`\n- CPU 热插拔锁（读/写）\n- 对应 `rdp` 的 NOCB 锁\n- 在本地 CPU 且不可抢占（非 `CONFIG_PREEMPT_COUNT` 或不可抢占上下文）\n- 当前为 NOCB 内核线程  \n这确保了在读取 `rdp->cblist` 的 `offloaded` 标志时，其值不会被并发修改。\n\n### 可抢占 RCU 的任务阻塞队列策略\n在 `CONFIG_PREEMPT_RCU` 下，当任务在 RCU 读侧临界区内被抢占时，需将其加入 `rcu_node->blkd_tasks` 链表。`rcu_preempt_ctxt_queue()` 使用 **状态决策表**（基于 `blkd_state` 的 4 位组合）决定插入位置：\n- **插入链表头部**：当任务不会阻塞任何**已存在的**宽限期（尤其是加速宽限期）时，避免延长已有宽限期。\n- **插入链表尾部**（代码未完整显示，但逻辑隐含）：当任务会阻塞已有宽限期时，需排在末尾以确保正确性。  \n该策略优先保护**加速宽限期**的低延迟特性，即使可能轻微延长普通宽限期。\n\n### 启动配置诊断\n`rcu_bootup_announce_oddness()` 系统性地检查数十个编译时和运行时 RCU 参数，对任何非默认值或启用的调试功能输出 `pr_info` 日志。这为系统管理员和开发者提供了 RCU 行为的透明视图，便于性能分析和问题排查。\n\n## 4. 依赖关系\n\n- **内部依赖**：\n  - `../locking/rtmutex_common.h`：提供 `lockdep_is_cpus_held()` 等锁依赖检查宏。\n  - `rcu_segcblist_is_offloaded()`：来自 RCU 回调段管理模块，用于查询 NOCB 状态。\n  - `rcu_lockdep_is_held_nocb()`、`rcu_current_is_nocb_kthread()`：NOCB 相关的锁依赖和上下文检查函数。\n  - `rcupdate_announce_bootup_oddness()`：来自 `kernel/rcu/update.c`，用于打印通用 RCU 启动信息。\n\n- **配置依赖**：\n  - `CONFIG_PREEMPT_RCU`：启用可抢占 RCU 的特定逻辑（如任务阻塞队列）。\n  - `CONFIG_RCU_TRACE`、`CONFIG_PROVE_RCU`、`CONFIG_RCU_BOOST` 等：控制启动诊断信息的输出。\n  - `CONFIG_HOTPLUG_CPU`：影响 CPU 热插拔锁的检查逻辑。\n\n- **数据结构依赖**：\n  - `struct rcu_data`、`struct rcu_node`：RCU 核心数据结构，定义在 `kernel/rcu/tree.h`。\n  - `rcu_state`：全局 RCU 状态结构体。\n\n## 5. 使用场景\n\n- **内核启动阶段**：  \n  `rcu_bootup_announce()` 和 `rcu_bootup_announce_oddness()` 在 RCU 初始化时被调用，输出配置诊断信息，帮助确认 RCU 子系统按预期配置。\n\n- **NOCB（回调卸载）模式运行时**：  \n  当系统启用 `CONFIG_RCU_NOCB_CPU` 时，`rcu_rdp_is_offloaded()` 被频繁调用（如在回调处理、宽限期推进路径中），以安全判断当前 CPU 的回调是否由专用内核线程处理。\n\n- **可抢占内核中的任务调度**：  \n  在 `CONFIG_PREEMPT_RCU` 系统中，当任务在 RCU 读侧临界区内被抢占时，调度器路径会调用 `rcu_preempt_ctxt_queue()`，将任务加入阻塞链表，确保宽限期能正确等待该任务退出临界区。\n\n- **调试与性能分析**：  \n  启动时的“oddness”日志为 RCU 调优提供依据；`RCU_LOCKDEP_WARN` 等检查帮助开发者发现 RCU 状态访问的同步错误。",
      "similarity": 0.6054452061653137,
      "chunks": []
    }
  ]
}