{
  "query": "条件变量如何解决生产者消费者竞争",
  "timestamp": "2025-12-26 00:58:41",
  "retrieved_files": [
    {
      "source_file": "kernel/kcsan/core.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:17:10\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kcsan\\core.c`\n\n---\n\n# kcsan/core.c 技术文档\n\n## 文件概述\n\n`kcsan/core.c` 是内核竞争条件检测器（KCSAN, Kernel Concurrency Sanitizer）的核心运行时实现文件。该文件负责管理观察点（watchpoints）的设置、查找与清除，实现对并发内存访问冲突的动态检测。KCSAN 通过概率性地监视内存访问，无需对所有内存访问进行插桩，从而在较低性能开销下检测数据竞争。\n\n## 核心功能\n\n### 主要全局变量\n- `kcsan_enabled`：控制 KCSAN 是否启用的全局开关。\n- `watchpoints[]`：原子长整型数组，用于存储编码后的观察点信息。\n- `kcsan_cpu_ctx`：每个 CPU 的上下文结构，用于中断上下文中的 KCSAN 状态管理。\n- 模块参数（可通过 `/sys/module/kcsan/parameters/` 调整）：\n  - `early_enable`：是否在早期启动阶段启用 KCSAN。\n  - `udelay_task` / `udelay_interrupt`：任务/中断上下文中检测前的延迟微秒数。\n  - `skip_watch`：跳过监视的指令计数器。\n  - `interrupt_watcher`：是否监视中断上下文中的访问。\n  - `weak_memory`（仅当 `CONFIG_KCSAN_WEAK_MEMORY` 启用）：是否启用弱内存序检测。\n\n### 主要函数\n- `find_watchpoint()`：在观察点表中查找与给定地址范围匹配的观察点。\n- `insert_watchpoint()`：尝试将新的观察点插入观察点表。\n- `try_consume_watchpoint()` / `consume_watchpoint()` / `remove_watchpoint()`：管理观察点的消费与移除。\n- `get_ctx()`：获取当前执行上下文（任务或中断）的 KCSAN 上下文。\n- `kcsan_check_scoped_accesses()`：检查当前上下文中注册的作用域访问（scoped accesses）。\n\n### 核心数据结构\n- `struct kcsan_ctx`：KCSAN 执行上下文，包含作用域访问链表、禁用标志等。\n- `struct kcsan_scoped_access`：表示一个作用域内的内存访问，用于延迟检查。\n\n## 关键实现\n\n### 观察点管理\n- **编码存储**：每个观察点通过 `encode_watchpoint()` 编码为单个 `atomic_long_t`，包含地址、大小和访问类型（读/写），避免使用锁。\n- **槽位索引策略**：\n  - 使用 `watchpoint_slot(addr)` 将地址映射到主槽位。\n  - 通过 `SLOT_IDX` 和 `SLOT_IDX_FAST` 宏支持检查相邻槽位（由 `KCSAN_CHECK_ADJACENT` 控制），以处理跨槽访问和槽位冲突。\n  - 数组大小为 `CONFIG_KCSAN_NUM_WATCHPOINTS + NUM_SLOTS - 1`，避免快速路径中的取模运算。\n- **无锁操作**：使用 `atomic_long_try_cmpxchg_relaxed()` 实现观察点的原子插入和消费。\n\n### 上下文管理\n- **双上下文支持**：任务上下文使用 `current->kcsan_ctx`，中断上下文使用 per-CPU 变量 `kcsan_cpu_ctx`。\n- **作用域访问**：通过链表管理延迟检查的访问（如 `kcsan_check_scoped_accesses()`），避免在禁用区域内重复检查。\n\n### 检测逻辑\n- **概率性检测**：通过 `kcsan_skip` 计数器和随机延迟（`kcsan_udelay_*`）控制检测频率，平衡开销与覆盖率。\n- **原子访问识别**：根据访问类型标志（`KCSAN_ACCESS_ATOMIC`、`KCSAN_ACCESS_ASSERT`）和配置（`CONFIG_KCSAN_ASSUME_PLAIN_WRITES_ATOMIC`）判断访问是否为原子操作，避免误报。\n\n## 依赖关系\n\n- **内部依赖**：\n  - `encoding.h`：提供观察点的编码/解码函数。\n  - `kcsan.h`：定义核心数据结构和常量。\n  - `permissive.h`：提供宽松模式下的行为控制。\n- **内核子系统**：\n  - 调度器（`linux/sched.h`）：用于获取当前任务上下文。\n  - 原子操作（`linux/atomic.h`）：实现无锁观察点管理。\n  - Per-CPU 变量（`linux/percpu.h`）：管理中断上下文状态。\n  - 内存访问（`linux/uaccess.h`）：处理用户空间访问区域。\n\n## 使用场景\n\n- **数据竞争检测**：在 SMP 系统中检测未同步的并发内存访问（如未加锁的共享变量读写）。\n- **开发与调试**：内核开发者启用 KCSAN 后，可在运行时捕获竞争条件，通过报告定位问题代码。\n- **中断与任务交互**：通过 `kcsan_interrupt_watcher` 参数控制是否检测中断与任务之间的竞争。\n- **弱内存序系统**：在启用 `CONFIG_KCSAN_WEAK_MEMORY` 的架构（如 ARM、RISC-V）上检测内存重排序导致的竞争。",
      "similarity": 0.4609726667404175,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/kcsan/core.c",
          "start_line": 182,
          "end_line": 286,
          "content": [
            "static __always_inline bool",
            "try_consume_watchpoint(atomic_long_t *watchpoint, long encoded_watchpoint)",
            "{",
            "\treturn atomic_long_try_cmpxchg_relaxed(watchpoint, &encoded_watchpoint, CONSUMED_WATCHPOINT);",
            "}",
            "static inline bool consume_watchpoint(atomic_long_t *watchpoint)",
            "{",
            "\treturn atomic_long_xchg_relaxed(watchpoint, CONSUMED_WATCHPOINT) != CONSUMED_WATCHPOINT;",
            "}",
            "static inline void remove_watchpoint(atomic_long_t *watchpoint)",
            "{",
            "\tatomic_long_set(watchpoint, INVALID_WATCHPOINT);",
            "}",
            "static noinline void kcsan_check_scoped_accesses(void)",
            "{",
            "\tstruct kcsan_ctx *ctx = get_ctx();",
            "\tstruct kcsan_scoped_access *scoped_access;",
            "",
            "\tif (ctx->disable_scoped)",
            "\t\treturn;",
            "",
            "\tctx->disable_scoped++;",
            "\tlist_for_each_entry(scoped_access, &ctx->scoped_accesses, list) {",
            "\t\tcheck_access(scoped_access->ptr, scoped_access->size,",
            "\t\t\t     scoped_access->type, scoped_access->ip);",
            "\t}",
            "\tctx->disable_scoped--;",
            "}",
            "static __always_inline bool",
            "is_atomic(struct kcsan_ctx *ctx, const volatile void *ptr, size_t size, int type)",
            "{",
            "\tif (type & KCSAN_ACCESS_ATOMIC)",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * Unless explicitly declared atomic, never consider an assertion access",
            "\t * as atomic. This allows using them also in atomic regions, such as",
            "\t * seqlocks, without implicitly changing their semantics.",
            "\t */",
            "\tif (type & KCSAN_ACCESS_ASSERT)",
            "\t\treturn false;",
            "",
            "\tif (IS_ENABLED(CONFIG_KCSAN_ASSUME_PLAIN_WRITES_ATOMIC) &&",
            "\t    (type & KCSAN_ACCESS_WRITE) && size <= sizeof(long) &&",
            "\t    !(type & KCSAN_ACCESS_COMPOUND) && IS_ALIGNED((unsigned long)ptr, size))",
            "\t\treturn true; /* Assume aligned writes up to word size are atomic. */",
            "",
            "\tif (ctx->atomic_next > 0) {",
            "\t\t/*",
            "\t\t * Because we do not have separate contexts for nested",
            "\t\t * interrupts, in case atomic_next is set, we simply assume that",
            "\t\t * the outer interrupt set atomic_next. In the worst case, we",
            "\t\t * will conservatively consider operations as atomic. This is a",
            "\t\t * reasonable trade-off to make, since this case should be",
            "\t\t * extremely rare; however, even if extremely rare, it could",
            "\t\t * lead to false positives otherwise.",
            "\t\t */",
            "\t\tif ((hardirq_count() >> HARDIRQ_SHIFT) < 2)",
            "\t\t\t--ctx->atomic_next; /* in task, or outer interrupt */",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn ctx->atomic_nest_count > 0 || ctx->in_flat_atomic;",
            "}",
            "static __always_inline bool",
            "should_watch(struct kcsan_ctx *ctx, const volatile void *ptr, size_t size, int type)",
            "{",
            "\t/*",
            "\t * Never set up watchpoints when memory operations are atomic.",
            "\t *",
            "\t * Need to check this first, before kcsan_skip check below: (1) atomics",
            "\t * should not count towards skipped instructions, and (2) to actually",
            "\t * decrement kcsan_atomic_next for consecutive instruction stream.",
            "\t */",
            "\tif (is_atomic(ctx, ptr, size, type))",
            "\t\treturn false;",
            "",
            "\tif (this_cpu_dec_return(kcsan_skip) >= 0)",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * NOTE: If we get here, kcsan_skip must always be reset in slow path",
            "\t * via reset_kcsan_skip() to avoid underflow.",
            "\t */",
            "",
            "\t/* this operation should be watched */",
            "\treturn true;",
            "}",
            "static u32 kcsan_prandom_u32_max(u32 ep_ro)",
            "{",
            "\tu32 state = this_cpu_read(kcsan_rand_state);",
            "",
            "\tstate = 1664525 * state + 1013904223;",
            "\tthis_cpu_write(kcsan_rand_state, state);",
            "",
            "\treturn state % ep_ro;",
            "}",
            "static inline void reset_kcsan_skip(void)",
            "{",
            "\tlong skip_count = kcsan_skip_watch -",
            "\t\t\t  (IS_ENABLED(CONFIG_KCSAN_SKIP_WATCH_RANDOMIZE) ?",
            "\t\t\t\t   kcsan_prandom_u32_max(kcsan_skip_watch) :",
            "\t\t\t\t   0);",
            "\tthis_cpu_write(kcsan_skip, skip_count);",
            "}"
          ],
          "function_name": "try_consume_watchpoint, consume_watchpoint, remove_watchpoint, kcsan_check_scoped_accesses, is_atomic, should_watch, kcsan_prandom_u32_max, reset_kcsan_skip",
          "description": "实现了监视点状态管理相关函数（try_consume_watchpoint、consume_watchpoint等），提供原子性判断、跳过指令计数控制及随机数生成功能，用于动态决策是否需设置监视点。",
          "similarity": 0.46094828844070435
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/kcsan/core.c",
          "start_line": 455,
          "end_line": 715,
          "content": [
            "static noinline void kcsan_found_watchpoint(const volatile void *ptr,",
            "\t\t\t\t\t    size_t size,",
            "\t\t\t\t\t    int type,",
            "\t\t\t\t\t    unsigned long ip,",
            "\t\t\t\t\t    atomic_long_t *watchpoint,",
            "\t\t\t\t\t    long encoded_watchpoint)",
            "{",
            "\tconst bool is_assert = (type & KCSAN_ACCESS_ASSERT) != 0;",
            "\tstruct kcsan_ctx *ctx = get_ctx();",
            "\tunsigned long flags;",
            "\tbool consumed;",
            "",
            "\t/*",
            "\t * We know a watchpoint exists. Let's try to keep the race-window",
            "\t * between here and finally consuming the watchpoint below as small as",
            "\t * possible -- avoid unneccessarily complex code until consumed.",
            "\t */",
            "",
            "\tif (!kcsan_is_enabled(ctx))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * The access_mask check relies on value-change comparison. To avoid",
            "\t * reporting a race where e.g. the writer set up the watchpoint, but the",
            "\t * reader has access_mask!=0, we have to ignore the found watchpoint.",
            "\t *",
            "\t * reorder_access is never created from an access with access_mask set.",
            "\t */",
            "\tif (ctx->access_mask && !find_reorder_access(ctx, ptr, size, type, ip))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If the other thread does not want to ignore the access, and there was",
            "\t * a value change as a result of this thread's operation, we will still",
            "\t * generate a report of unknown origin.",
            "\t *",
            "\t * Use CONFIG_KCSAN_REPORT_RACE_UNKNOWN_ORIGIN=n to filter.",
            "\t */",
            "\tif (!is_assert && kcsan_ignore_address(ptr))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Consuming the watchpoint must be guarded by kcsan_is_enabled() to",
            "\t * avoid erroneously triggering reports if the context is disabled.",
            "\t */",
            "\tconsumed = try_consume_watchpoint(watchpoint, encoded_watchpoint);",
            "",
            "\t/* keep this after try_consume_watchpoint */",
            "\tflags = user_access_save();",
            "",
            "\tif (consumed) {",
            "\t\tkcsan_save_irqtrace(current);",
            "\t\tkcsan_report_set_info(ptr, size, type, ip, watchpoint - watchpoints);",
            "\t\tkcsan_restore_irqtrace(current);",
            "\t} else {",
            "\t\t/*",
            "\t\t * The other thread may not print any diagnostics, as it has",
            "\t\t * already removed the watchpoint, or another thread consumed",
            "\t\t * the watchpoint before this thread.",
            "\t\t */",
            "\t\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_REPORT_RACES]);",
            "\t}",
            "",
            "\tif (is_assert)",
            "\t\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_ASSERT_FAILURES]);",
            "\telse",
            "\t\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_DATA_RACES]);",
            "",
            "\tuser_access_restore(flags);",
            "}",
            "static noinline void",
            "kcsan_setup_watchpoint(const volatile void *ptr, size_t size, int type, unsigned long ip)",
            "{",
            "\tconst bool is_write = (type & KCSAN_ACCESS_WRITE) != 0;",
            "\tconst bool is_assert = (type & KCSAN_ACCESS_ASSERT) != 0;",
            "\tatomic_long_t *watchpoint;",
            "\tu64 old, new, diff;",
            "\tenum kcsan_value_change value_change = KCSAN_VALUE_CHANGE_MAYBE;",
            "\tbool interrupt_watcher = kcsan_interrupt_watcher;",
            "\tunsigned long ua_flags = user_access_save();",
            "\tstruct kcsan_ctx *ctx = get_ctx();",
            "\tunsigned long access_mask = ctx->access_mask;",
            "\tunsigned long irq_flags = 0;",
            "\tbool is_reorder_access;",
            "",
            "\t/*",
            "\t * Always reset kcsan_skip counter in slow-path to avoid underflow; see",
            "\t * should_watch().",
            "\t */",
            "\treset_kcsan_skip();",
            "",
            "\tif (!kcsan_is_enabled(ctx))",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * Check to-ignore addresses after kcsan_is_enabled(), as we may access",
            "\t * memory that is not yet initialized during early boot.",
            "\t */",
            "\tif (!is_assert && kcsan_ignore_address(ptr))",
            "\t\tgoto out;",
            "",
            "\tif (!check_encodable((unsigned long)ptr, size)) {",
            "\t\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_UNENCODABLE_ACCESSES]);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * The local CPU cannot observe reordering of its own accesses, and",
            "\t * therefore we need to take care of 2 cases to avoid false positives:",
            "\t *",
            "\t *\t1. Races of the reordered access with interrupts. To avoid, if",
            "\t *\t   the current access is reorder_access, disable interrupts.",
            "\t *\t2. Avoid races of scoped accesses from nested interrupts (below).",
            "\t */",
            "\tis_reorder_access = find_reorder_access(ctx, ptr, size, type, ip);",
            "\tif (is_reorder_access)",
            "\t\tinterrupt_watcher = false;",
            "\t/*",
            "\t * Avoid races of scoped accesses from nested interrupts (or scheduler).",
            "\t * Assume setting up a watchpoint for a non-scoped (normal) access that",
            "\t * also conflicts with a current scoped access. In a nested interrupt,",
            "\t * which shares the context, it would check a conflicting scoped access.",
            "\t * To avoid, disable scoped access checking.",
            "\t */",
            "\tctx->disable_scoped++;",
            "",
            "\t/*",
            "\t * Save and restore the IRQ state trace touched by KCSAN, since KCSAN's",
            "\t * runtime is entered for every memory access, and potentially useful",
            "\t * information is lost if dirtied by KCSAN.",
            "\t */",
            "\tkcsan_save_irqtrace(current);",
            "\tif (!interrupt_watcher)",
            "\t\tlocal_irq_save(irq_flags);",
            "",
            "\twatchpoint = insert_watchpoint((unsigned long)ptr, size, is_write);",
            "\tif (watchpoint == NULL) {",
            "\t\t/*",
            "\t\t * Out of capacity: the size of 'watchpoints', and the frequency",
            "\t\t * with which should_watch() returns true should be tweaked so",
            "\t\t * that this case happens very rarely.",
            "\t\t */",
            "\t\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_NO_CAPACITY]);",
            "\t\tgoto out_unlock;",
            "\t}",
            "",
            "\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_SETUP_WATCHPOINTS]);",
            "\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_USED_WATCHPOINTS]);",
            "",
            "\t/*",
            "\t * Read the current value, to later check and infer a race if the data",
            "\t * was modified via a non-instrumented access, e.g. from a device.",
            "\t */",
            "\told = is_reorder_access ? 0 : read_instrumented_memory(ptr, size);",
            "",
            "\t/*",
            "\t * Delay this thread, to increase probability of observing a racy",
            "\t * conflicting access.",
            "\t */",
            "\tdelay_access(type);",
            "",
            "\t/*",
            "\t * Re-read value, and check if it is as expected; if not, we infer a",
            "\t * racy access.",
            "\t */",
            "\tif (!is_reorder_access) {",
            "\t\tnew = read_instrumented_memory(ptr, size);",
            "\t} else {",
            "\t\t/*",
            "\t\t * Reordered accesses cannot be used for value change detection,",
            "\t\t * because the memory location may no longer be accessible and",
            "\t\t * could result in a fault.",
            "\t\t */",
            "\t\tnew = 0;",
            "\t\taccess_mask = 0;",
            "\t}",
            "",
            "\tdiff = old ^ new;",
            "\tif (access_mask)",
            "\t\tdiff &= access_mask;",
            "",
            "\t/*",
            "\t * Check if we observed a value change.",
            "\t *",
            "\t * Also check if the data race should be ignored (the rules depend on",
            "\t * non-zero diff); if it is to be ignored, the below rules for",
            "\t * KCSAN_VALUE_CHANGE_MAYBE apply.",
            "\t */",
            "\tif (diff && !kcsan_ignore_data_race(size, type, old, new, diff))",
            "\t\tvalue_change = KCSAN_VALUE_CHANGE_TRUE;",
            "",
            "\t/* Check if this access raced with another. */",
            "\tif (!consume_watchpoint(watchpoint)) {",
            "\t\t/*",
            "\t\t * Depending on the access type, map a value_change of MAYBE to",
            "\t\t * TRUE (always report) or FALSE (never report).",
            "\t\t */",
            "\t\tif (value_change == KCSAN_VALUE_CHANGE_MAYBE) {",
            "\t\t\tif (access_mask != 0) {",
            "\t\t\t\t/*",
            "\t\t\t\t * For access with access_mask, we require a",
            "\t\t\t\t * value-change, as it is likely that races on",
            "\t\t\t\t * ~access_mask bits are expected.",
            "\t\t\t\t */",
            "\t\t\t\tvalue_change = KCSAN_VALUE_CHANGE_FALSE;",
            "\t\t\t} else if (size > 8 || is_assert) {",
            "\t\t\t\t/* Always assume a value-change. */",
            "\t\t\t\tvalue_change = KCSAN_VALUE_CHANGE_TRUE;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * No need to increment 'data_races' counter, as the racing",
            "\t\t * thread already did.",
            "\t\t *",
            "\t\t * Count 'assert_failures' for each failed ASSERT access,",
            "\t\t * therefore both this thread and the racing thread may",
            "\t\t * increment this counter.",
            "\t\t */",
            "\t\tif (is_assert && value_change == KCSAN_VALUE_CHANGE_TRUE)",
            "\t\t\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_ASSERT_FAILURES]);",
            "",
            "\t\tkcsan_report_known_origin(ptr, size, type, ip,",
            "\t\t\t\t\t  value_change, watchpoint - watchpoints,",
            "\t\t\t\t\t  old, new, access_mask);",
            "\t} else if (value_change == KCSAN_VALUE_CHANGE_TRUE) {",
            "\t\t/* Inferring a race, since the value should not have changed. */",
            "",
            "\t\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_RACES_UNKNOWN_ORIGIN]);",
            "\t\tif (is_assert)",
            "\t\t\tatomic_long_inc(&kcsan_counters[KCSAN_COUNTER_ASSERT_FAILURES]);",
            "",
            "\t\tif (IS_ENABLED(CONFIG_KCSAN_REPORT_RACE_UNKNOWN_ORIGIN) || is_assert) {",
            "\t\t\tkcsan_report_unknown_origin(ptr, size, type, ip,",
            "\t\t\t\t\t\t    old, new, access_mask);",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * Remove watchpoint; must be after reporting, since the slot may be",
            "\t * reused after this point.",
            "\t */",
            "\tremove_watchpoint(watchpoint);",
            "\tatomic_long_dec(&kcsan_counters[KCSAN_COUNTER_USED_WATCHPOINTS]);",
            "",
            "out_unlock:",
            "\tif (!interrupt_watcher)",
            "\t\tlocal_irq_restore(irq_flags);",
            "\tkcsan_restore_irqtrace(current);",
            "\tctx->disable_scoped--;",
            "",
            "\t/*",
            "\t * Reordered accesses cannot be used for value change detection,",
            "\t * therefore never consider for reordering if access_mask is set.",
            "\t * ASSERT_EXCLUSIVE are not real accesses, ignore them as well.",
            "\t */",
            "\tif (!access_mask && !is_assert)",
            "\t\tset_reorder_access(ctx, ptr, size, type, ip);",
            "out:",
            "\tuser_access_restore(ua_flags);",
            "}"
          ],
          "function_name": "kcsan_found_watchpoint, kcsan_setup_watchpoint",
          "description": "处理监视点命中后的竞态分析流程，通过值变化检测区分真实竞态与预期变更，根据配置策略生成不同类型的报告，并维护各类统计计数器以评估检测效果。",
          "similarity": 0.458797812461853
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/kcsan/core.c",
          "start_line": 1,
          "end_line": 181,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * KCSAN core runtime.",
            " *",
            " * Copyright (C) 2019, Google LLC.",
            " */",
            "",
            "#define pr_fmt(fmt) \"kcsan: \" fmt",
            "",
            "#include <linux/atomic.h>",
            "#include <linux/bug.h>",
            "#include <linux/delay.h>",
            "#include <linux/export.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/list.h>",
            "#include <linux/minmax.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/percpu.h>",
            "#include <linux/preempt.h>",
            "#include <linux/sched.h>",
            "#include <linux/string.h>",
            "#include <linux/uaccess.h>",
            "",
            "#include \"encoding.h\"",
            "#include \"kcsan.h\"",
            "#include \"permissive.h\"",
            "",
            "static bool kcsan_early_enable = IS_ENABLED(CONFIG_KCSAN_EARLY_ENABLE);",
            "unsigned int kcsan_udelay_task = CONFIG_KCSAN_UDELAY_TASK;",
            "unsigned int kcsan_udelay_interrupt = CONFIG_KCSAN_UDELAY_INTERRUPT;",
            "static long kcsan_skip_watch = CONFIG_KCSAN_SKIP_WATCH;",
            "static bool kcsan_interrupt_watcher = IS_ENABLED(CONFIG_KCSAN_INTERRUPT_WATCHER);",
            "",
            "#ifdef MODULE_PARAM_PREFIX",
            "#undef MODULE_PARAM_PREFIX",
            "#endif",
            "#define MODULE_PARAM_PREFIX \"kcsan.\"",
            "module_param_named(early_enable, kcsan_early_enable, bool, 0);",
            "module_param_named(udelay_task, kcsan_udelay_task, uint, 0644);",
            "module_param_named(udelay_interrupt, kcsan_udelay_interrupt, uint, 0644);",
            "module_param_named(skip_watch, kcsan_skip_watch, long, 0644);",
            "module_param_named(interrupt_watcher, kcsan_interrupt_watcher, bool, 0444);",
            "",
            "#ifdef CONFIG_KCSAN_WEAK_MEMORY",
            "static bool kcsan_weak_memory = true;",
            "module_param_named(weak_memory, kcsan_weak_memory, bool, 0644);",
            "#else",
            "#define kcsan_weak_memory false",
            "#endif",
            "",
            "bool kcsan_enabled;",
            "",
            "/* Per-CPU kcsan_ctx for interrupts */",
            "static DEFINE_PER_CPU(struct kcsan_ctx, kcsan_cpu_ctx) = {",
            "\t.scoped_accesses\t= {LIST_POISON1, NULL},",
            "};",
            "",
            "/*",
            " * Helper macros to index into adjacent slots, starting from address slot",
            " * itself, followed by the right and left slots.",
            " *",
            " * The purpose is 2-fold:",
            " *",
            " *\t1. if during insertion the address slot is already occupied, check if",
            " *\t   any adjacent slots are free;",
            " *\t2. accesses that straddle a slot boundary due to size that exceeds a",
            " *\t   slot's range may check adjacent slots if any watchpoint matches.",
            " *",
            " * Note that accesses with very large size may still miss a watchpoint; however,",
            " * given this should be rare, this is a reasonable trade-off to make, since this",
            " * will avoid:",
            " *",
            " *\t1. excessive contention between watchpoint checks and setup;",
            " *\t2. larger number of simultaneous watchpoints without sacrificing",
            " *\t   performance.",
            " *",
            " * Example: SLOT_IDX values for KCSAN_CHECK_ADJACENT=1, where i is [0, 1, 2]:",
            " *",
            " *   slot=0:  [ 1,  2,  0]",
            " *   slot=9:  [10, 11,  9]",
            " *   slot=63: [64, 65, 63]",
            " */",
            "#define SLOT_IDX(slot, i) (slot + ((i + KCSAN_CHECK_ADJACENT) % NUM_SLOTS))",
            "",
            "/*",
            " * SLOT_IDX_FAST is used in the fast-path. Not first checking the address's primary",
            " * slot (middle) is fine if we assume that races occur rarely. The set of",
            " * indices {SLOT_IDX(slot, i) | i in [0, NUM_SLOTS)} is equivalent to",
            " * {SLOT_IDX_FAST(slot, i) | i in [0, NUM_SLOTS)}.",
            " */",
            "#define SLOT_IDX_FAST(slot, i) (slot + i)",
            "",
            "/*",
            " * Watchpoints, with each entry encoded as defined in encoding.h: in order to be",
            " * able to safely update and access a watchpoint without introducing locking",
            " * overhead, we encode each watchpoint as a single atomic long. The initial",
            " * zero-initialized state matches INVALID_WATCHPOINT.",
            " *",
            " * Add NUM_SLOTS-1 entries to account for overflow; this helps avoid having to",
            " * use more complicated SLOT_IDX_FAST calculation with modulo in the fast-path.",
            " */",
            "static atomic_long_t watchpoints[CONFIG_KCSAN_NUM_WATCHPOINTS + NUM_SLOTS-1];",
            "",
            "/*",
            " * Instructions to skip watching counter, used in should_watch(). We use a",
            " * per-CPU counter to avoid excessive contention.",
            " */",
            "static DEFINE_PER_CPU(long, kcsan_skip);",
            "",
            "/* For kcsan_prandom_u32_max(). */",
            "static DEFINE_PER_CPU(u32, kcsan_rand_state);",
            "",
            "static __always_inline atomic_long_t *find_watchpoint(unsigned long addr,",
            "\t\t\t\t\t\t      size_t size,",
            "\t\t\t\t\t\t      bool expect_write,",
            "\t\t\t\t\t\t      long *encoded_watchpoint)",
            "{",
            "\tconst int slot = watchpoint_slot(addr);",
            "\tconst unsigned long addr_masked = addr & WATCHPOINT_ADDR_MASK;",
            "\tatomic_long_t *watchpoint;",
            "\tunsigned long wp_addr_masked;",
            "\tsize_t wp_size;",
            "\tbool is_write;",
            "\tint i;",
            "",
            "\tBUILD_BUG_ON(CONFIG_KCSAN_NUM_WATCHPOINTS < NUM_SLOTS);",
            "",
            "\tfor (i = 0; i < NUM_SLOTS; ++i) {",
            "\t\twatchpoint = &watchpoints[SLOT_IDX_FAST(slot, i)];",
            "\t\t*encoded_watchpoint = atomic_long_read(watchpoint);",
            "\t\tif (!decode_watchpoint(*encoded_watchpoint, &wp_addr_masked,",
            "\t\t\t\t       &wp_size, &is_write))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (expect_write && !is_write)",
            "\t\t\tcontinue;",
            "",
            "\t\t/* Check if the watchpoint matches the access. */",
            "\t\tif (matching_access(wp_addr_masked, wp_size, addr_masked, size))",
            "\t\t\treturn watchpoint;",
            "\t}",
            "",
            "\treturn NULL;",
            "}",
            "",
            "static inline atomic_long_t *",
            "insert_watchpoint(unsigned long addr, size_t size, bool is_write)",
            "{",
            "\tconst int slot = watchpoint_slot(addr);",
            "\tconst long encoded_watchpoint = encode_watchpoint(addr, size, is_write);",
            "\tatomic_long_t *watchpoint;",
            "\tint i;",
            "",
            "\t/* Check slot index logic, ensuring we stay within array bounds. */",
            "\tBUILD_BUG_ON(SLOT_IDX(0, 0) != KCSAN_CHECK_ADJACENT);",
            "\tBUILD_BUG_ON(SLOT_IDX(0, KCSAN_CHECK_ADJACENT+1) != 0);",
            "\tBUILD_BUG_ON(SLOT_IDX(CONFIG_KCSAN_NUM_WATCHPOINTS-1, KCSAN_CHECK_ADJACENT) != ARRAY_SIZE(watchpoints)-1);",
            "\tBUILD_BUG_ON(SLOT_IDX(CONFIG_KCSAN_NUM_WATCHPOINTS-1, KCSAN_CHECK_ADJACENT+1) != ARRAY_SIZE(watchpoints) - NUM_SLOTS);",
            "",
            "\tfor (i = 0; i < NUM_SLOTS; ++i) {",
            "\t\tlong expect_val = INVALID_WATCHPOINT;",
            "",
            "\t\t/* Try to acquire this slot. */",
            "\t\twatchpoint = &watchpoints[SLOT_IDX(slot, i)];",
            "\t\tif (atomic_long_try_cmpxchg_relaxed(watchpoint, &expect_val, encoded_watchpoint))",
            "\t\t\treturn watchpoint;",
            "\t}",
            "",
            "\treturn NULL;",
            "}",
            "",
            "/*",
            " * Return true if watchpoint was successfully consumed, false otherwise.",
            " *",
            " * This may return false if:",
            " *",
            " *\t1. another thread already consumed the watchpoint;",
            " *\t2. the thread that set up the watchpoint already removed it;",
            " *\t3. the watchpoint was removed and then re-used.",
            " */"
          ],
          "function_name": null,
          "description": "定义了KCSAN的核心运行时变量和参数，包含监视点数组、上下文结构体及辅助宏，用于管理内存访问检查的槽位计算和监视点插入逻辑，但代码上下文不完整。",
          "similarity": 0.4046398997306824
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/kcsan/core.c",
          "start_line": 830,
          "end_line": 931,
          "content": [
            "void kcsan_enable_current(void)",
            "{",
            "\tif (get_ctx()->disable_count-- == 0) {",
            "\t\t/*",
            "\t\t * Warn if kcsan_enable_current() calls are unbalanced with",
            "\t\t * kcsan_disable_current() calls, which causes disable_count to",
            "\t\t * become negative and should not happen.",
            "\t\t */",
            "\t\tkcsan_disable_current(); /* restore to 0, KCSAN still enabled */",
            "\t\tkcsan_disable_current(); /* disable to generate warning */",
            "\t\tWARN(1, \"Unbalanced %s()\", __func__);",
            "\t\tkcsan_enable_current();",
            "\t}",
            "}",
            "void kcsan_enable_current_nowarn(void)",
            "{",
            "\tif (get_ctx()->disable_count-- == 0)",
            "\t\tkcsan_disable_current();",
            "}",
            "void kcsan_nestable_atomic_begin(void)",
            "{",
            "\t/*",
            "\t * Do *not* check and warn if we are in a flat atomic region: nestable",
            "\t * and flat atomic regions are independent from each other.",
            "\t * See include/linux/kcsan.h: struct kcsan_ctx comments for more",
            "\t * comments.",
            "\t */",
            "",
            "\t++get_ctx()->atomic_nest_count;",
            "}",
            "void kcsan_nestable_atomic_end(void)",
            "{",
            "\tif (get_ctx()->atomic_nest_count-- == 0) {",
            "\t\t/*",
            "\t\t * Warn if kcsan_nestable_atomic_end() calls are unbalanced with",
            "\t\t * kcsan_nestable_atomic_begin() calls, which causes",
            "\t\t * atomic_nest_count to become negative and should not happen.",
            "\t\t */",
            "\t\tkcsan_nestable_atomic_begin(); /* restore to 0 */",
            "\t\tkcsan_disable_current(); /* disable to generate warning */",
            "\t\tWARN(1, \"Unbalanced %s()\", __func__);",
            "\t\tkcsan_enable_current();",
            "\t}",
            "}",
            "void kcsan_flat_atomic_begin(void)",
            "{",
            "\tget_ctx()->in_flat_atomic = true;",
            "}",
            "void kcsan_flat_atomic_end(void)",
            "{",
            "\tget_ctx()->in_flat_atomic = false;",
            "}",
            "void kcsan_atomic_next(int n)",
            "{",
            "\tget_ctx()->atomic_next = n;",
            "}",
            "void kcsan_set_access_mask(unsigned long mask)",
            "{",
            "\tget_ctx()->access_mask = mask;",
            "}",
            "void kcsan_end_scoped_access(struct kcsan_scoped_access *sa)",
            "{",
            "\tstruct kcsan_ctx *ctx = get_ctx();",
            "",
            "\tif (WARN(!ctx->scoped_accesses.prev, \"Unbalanced %s()?\", __func__))",
            "\t\treturn;",
            "",
            "\tctx->disable_count++; /* Disable KCSAN, in case list debugging is on. */",
            "",
            "\tlist_del(&sa->list);",
            "\tif (list_empty(&ctx->scoped_accesses))",
            "\t\t/*",
            "\t\t * Ensure we do not enter kcsan_check_scoped_accesses()",
            "\t\t * slow-path if unnecessary, and avoids requiring list_empty()",
            "\t\t * in the fast-path (to avoid a READ_ONCE() and potential",
            "\t\t * uaccess warning).",
            "\t\t */",
            "\t\tctx->scoped_accesses.prev = NULL;",
            "",
            "\tctx->disable_count--;",
            "",
            "\tcheck_access(sa->ptr, sa->size, sa->type, sa->ip);",
            "}",
            "void __kcsan_check_access(const volatile void *ptr, size_t size, int type)",
            "{",
            "\tcheck_access(ptr, size, type, _RET_IP_);",
            "}",
            "void __tsan_read_range(void *ptr, size_t size)",
            "{",
            "\tcheck_access(ptr, size, 0, _RET_IP_);",
            "}",
            "void __tsan_write_range(void *ptr, size_t size)",
            "{",
            "\tcheck_access(ptr, size, KCSAN_ACCESS_WRITE, _RET_IP_);",
            "}",
            "noinline void __tsan_func_entry(void *call_pc)",
            "{",
            "\tif (!IS_ENABLED(CONFIG_KCSAN_WEAK_MEMORY))",
            "\t\treturn;",
            "",
            "\tadd_kcsan_stack_depth(1);",
            "}"
          ],
          "function_name": "kcsan_enable_current, kcsan_enable_current_nowarn, kcsan_nestable_atomic_begin, kcsan_nestable_atomic_end, kcsan_flat_atomic_begin, kcsan_flat_atomic_end, kcsan_atomic_next, kcsan_set_access_mask, kcsan_end_scoped_access, __kcsan_check_access, __tsan_read_range, __tsan_write_range, __tsan_func_entry",
          "description": "该代码块定义了KCSAN工具的启用/禁用控制逻辑及原子操作追踪接口。kcsan_enable_current系列函数通过递减disable_count实现线程级启用状态管理，当计数归零时触发警告以检测未平衡的enable/disable调用。nestable_atomic_*系列函数跟踪嵌套原子操作层级，flat_atomic_*用于标记平坦原子区域状态。set_access_mask配置访问掩码，end_scoped_access处理作用域访问结束时的检查与清理，各内存访问检查函数（__tsan_read/write_range）调用通用check_access实现数据竞争检测。",
          "similarity": 0.37874069809913635
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/kcsan/core.c",
          "start_line": 1111,
          "end_line": 1171,
          "content": [
            "noinline void __tsan_func_exit(void)",
            "{",
            "\tstruct kcsan_scoped_access *reorder_access;",
            "",
            "\tif (!IS_ENABLED(CONFIG_KCSAN_WEAK_MEMORY))",
            "\t\treturn;",
            "",
            "\treorder_access = get_reorder_access(get_ctx());",
            "\tif (!reorder_access)",
            "\t\tgoto out;",
            "",
            "\tif (get_kcsan_stack_depth() <= reorder_access->stack_depth) {",
            "\t\t/*",
            "\t\t * Access check to catch cases where write without a barrier",
            "\t\t * (supposed release) was last access in function: because",
            "\t\t * instrumentation is inserted before the real access, a data",
            "\t\t * race due to the write giving up a c-s would only be caught if",
            "\t\t * we do the conflicting access after.",
            "\t\t */",
            "\t\tcheck_access(reorder_access->ptr, reorder_access->size,",
            "\t\t\t     reorder_access->type, reorder_access->ip);",
            "\t\treorder_access->size = 0;",
            "\t\treorder_access->stack_depth = INT_MIN;",
            "\t}",
            "out:",
            "\tadd_kcsan_stack_depth(-1);",
            "}",
            "void __tsan_init(void)",
            "{",
            "}",
            "static __always_inline void kcsan_atomic_builtin_memorder(int memorder)",
            "{",
            "\tif (memorder == __ATOMIC_RELEASE ||",
            "\t    memorder == __ATOMIC_SEQ_CST ||",
            "\t    memorder == __ATOMIC_ACQ_REL)",
            "\t\t__kcsan_release();",
            "}",
            "void __tsan_atomic_thread_fence(int memorder)",
            "{",
            "\tkcsan_atomic_builtin_memorder(memorder);",
            "\t__atomic_thread_fence(memorder);",
            "}",
            "noinline void __tsan_atomic_signal_fence(int memorder)",
            "{",
            "\tswitch (memorder) {",
            "\tcase __KCSAN_BARRIER_TO_SIGNAL_FENCE_mb:",
            "\t\t__kcsan_mb();",
            "\t\tbreak;",
            "\tcase __KCSAN_BARRIER_TO_SIGNAL_FENCE_wmb:",
            "\t\t__kcsan_wmb();",
            "\t\tbreak;",
            "\tcase __KCSAN_BARRIER_TO_SIGNAL_FENCE_rmb:",
            "\t\t__kcsan_rmb();",
            "\t\tbreak;",
            "\tcase __KCSAN_BARRIER_TO_SIGNAL_FENCE_release:",
            "\t\t__kcsan_release();",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tbreak;",
            "\t}",
            "}"
          ],
          "function_name": "__tsan_func_exit, __tsan_init, kcsan_atomic_builtin_memorder, __tsan_atomic_thread_fence, __tsan_atomic_signal_fence",
          "description": "该代码块实现KCSAN的内存序处理与函数边界检查逻辑。__tsan_func_exit在函数退出时检查潜在的数据竞争，通过比较堆栈深度判断是否需执行访问检查。__tsan_init为空实现。kcsan_atomic_builtin_memorder根据内存序类型注入对应的KCSAN释放屏障。__tsan_atomic_*系列函数封装了对原子内存屏障（thread_fence/signal_fence）的插桩处理，通过条件分支选择不同类型的内存屏障指令以满足不同的同步需求。",
          "similarity": 0.3562309741973877
        }
      ]
    },
    {
      "source_file": "kernel/kcsan/kcsan.h",
      "md_summary": "> 自动生成时间: 2025-10-25 14:19:29\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kcsan\\kcsan.h`\n\n---\n\n# `kcsan/kcsan.h` 技术文档\n\n## 1. 文件概述\n\n`kcsan/kcsan.h` 是 Linux 内核中 **Kernel Concurrency Sanitizer (KCSAN)** 动态数据竞争检测器的核心头文件。该文件定义了 KCSAN 的全局控制变量、统计计数器、报告接口以及与中断上下文和任务上下文交互所需的辅助函数。KCSAN 用于在运行时检测内核中的数据竞争（data races），帮助开发者发现并发访问中的潜在问题。\n\n## 2. 核心功能\n\n### 全局变量\n- `kcsan_enabled`：布尔值，用于全局启用或禁用 KCSAN 检测。\n- `kcsan_udelay_task` / `kcsan_udelay_interrupt`：分别指定在任务上下文和中断上下文中检测时引入的延迟时间（微秒），用于增加竞争暴露概率。\n- `kcsan_counters[KCSAN_COUNTER_COUNT]`：原子长整型数组，用于记录 KCSAN 运行时的各类统计信息。\n\n### 枚举类型\n- `enum kcsan_counter_id`：定义 KCSAN 统计计数器的种类，包括：\n  - `KCSAN_COUNTER_USED_WATCHPOINTS`：当前使用的观察点数量\n  - `KCSAN_COUNTER_SETUP_WATCHPOINTS`：设置的观察点总数\n  - `KCSAN_COUNTER_DATA_RACES`：检测到的数据竞争总数\n  - `KCSAN_COUNTER_ASSERT_FAILURES`：因竞争导致的 ASSERT 失败次数\n  - `KCSAN_COUNTER_NO_CAPACITY`：因无可用观察点槽位而跳过的次数\n  - `KCSAN_COUNTER_REPORT_RACES`：因多个线程同时检查同一观察点而仅报告一次的次数\n  - `KCSAN_COUNTER_RACES_UNKNOWN_ORIGIN`：值变化但无法确定写入者来源的竞争\n  - `KCSAN_COUNTER_UNENCODABLE_ACCESSES`：无法编码为有效观察点的访问\n  - `KCSAN_COUNTER_ENCODING_FALSE_POSITIVES`：因编码导致误报的次数\n- `enum kcsan_value_change`：描述观察到的值是否发生变化，用于决定是否报告竞争：\n  - `KCSAN_VALUE_CHANGE_MAYBE`：未观察到变化，但可报告（取决于配置）\n  - `KCSAN_VALUE_CHANGE_FALSE`：未变化，不应报告\n  - `KCSAN_VALUE_CHANGE_TRUE`：值已变化，应报告\n\n### 函数接口\n- `kcsan_save_irqtrace(struct task_struct *task)`  \n  保存当前任务的中断标志状态（IRQ trace），防止 KCSAN 自身操作污染原始状态。\n- `kcsan_restore_irqtrace(struct task_struct *task)`  \n  恢复之前保存的中断标志状态。\n- `kcsan_skip_report_debugfs(unsigned long func_addr)`  \n  根据 debugfs 配置判断是否应跳过对指定函数地址所在函数的数据竞争报告。\n- `kcsan_report_set_info(...)`  \n  当前线程命中并消费了一个观察点，设置报告所需的基本访问信息（由竞争线程调用）。\n- `kcsan_report_known_origin(...)`  \n  当前线程发现其设置的观察点被另一线程命中，基于对方设置的信息生成完整竞争报告。\n- `kcsan_report_unknown_origin(...)`  \n  在无明确竞争线程的情况下（如值在延迟后发生变化），报告“来源未知”的数据竞争。\n\n### 宏定义\n- `KCSAN_CHECK_ADJACENT`：定义在检查观察点时需同时检查的相邻内存地址数量（默认为 1）。\n- `NUM_SLOTS`：计算观察点槽位总数，公式为 `1 + 2 * KCSAN_CHECK_ADJACENT`，用于支持对齐和邻近访问的检测。\n\n## 3. 关键实现\n\n- **观察点机制**：KCSAN 使用有限数量的“观察点”（watchpoints）来监控内存访问。每个观察点记录地址、大小、访问类型等信息。当另一线程访问该地址时，可能触发竞争检测。\n- **邻近访问检查**：通过 `KCSAN_CHECK_ADJACENT` 支持检测与观察点地址相邻的访问，提升对非对齐或跨缓存行访问的覆盖能力。\n- **双阶段报告**：\n  1. 竞争线程调用 `kcsan_report_set_info()` 设置冲突信息；\n  2. 原始设置观察点的线程调用 `kcsan_report_known_origin()` 生成完整报告。\n- **未知来源竞争**：当启用延迟检测（通过 `udelay`）后，若值发生变化但未捕获到明确的竞争线程，则调用 `kcsan_report_unknown_origin()` 报告。\n- **统计计数**：所有计数器通过 `atomic_long_t` 实现，确保在慢路径（如报告生成）中安全更新，供 debugfs 导出分析。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/atomic.h>`：用于原子操作（统计计数器）\n  - `<linux/kcsan.h>`：用户态或架构无关的 KCSAN 接口定义\n  - `<linux/sched.h>`：依赖 `struct task_struct`，用于保存/恢复任务的 IRQ 状态\n- **模块依赖**：\n  - 依赖 KCSAN 核心实现（如 `kcsan.c`）提供观察点管理、竞争检测逻辑\n  - 与 debugfs 集成，用于动态控制报告过滤（`kcsan_skip_report_debugfs`）\n  - 与内核调度器和中断子系统交互，确保在不同上下文（任务/中断）中正确运行\n\n## 5. 使用场景\n\n- **内核开发与调试**：在启用 `CONFIG_KCSAN` 的内核中，该头文件被 KCSAN 核心代码、内存访问插桩（instrumentation）逻辑以及报告模块包含，用于实现运行时数据竞争检测。\n- **竞争报告生成**：当两个线程并发访问同一内存区域且至少一个是写操作时，KCSAN 通过本文件定义的接口收集信息并生成详细竞争报告。\n- **性能调优与分析**：通过 `kcsan_counters` 提供的统计数据，开发者可评估 KCSAN 覆盖率、误报率及系统开销。\n- **动态控制**：通过 `kcsan_enabled` 和 debugfs 接口，可在运行时开启/关闭检测或过滤特定函数的竞争报告，适用于生产环境调试或性能敏感场景。",
      "similarity": 0.4427844285964966,
      "chunks": []
    },
    {
      "source_file": "kernel/kcsan/permissive.h",
      "md_summary": "> 自动生成时间: 2025-10-25 14:20:57\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kcsan\\permissive.h`\n\n---\n\n# kcsan/permissive.h 技术文档\n\n## 文件概述\n\n`kcsan/permissive.h` 是 Linux 内核 KCSAN（Kernel Concurrency Sanitizer）动态数据竞争检测器的一部分，用于定义**宽容模式**（permissive mode）下的特殊忽略规则。该文件提供了一组条件判断函数，用于在特定场景下**有选择地忽略某些数据竞争报告**，以减少误报或因历史代码难以大规模重构而产生的噪音。需要注意的是，这些规则**并不表示被忽略的数据竞争本质上是安全的**，而是出于工程实践的权衡。\n\n该文件的内容仅在启用 `CONFIG_KCSAN_PERMISSIVE` 配置选项时生效，且被刻意与 KCSAN 核心逻辑分离，便于审计和维护。\n\n## 核心功能\n\n### 函数列表\n\n1. **`kcsan_ignore_address`**\n   - **原型**：`static __always_inline bool kcsan_ignore_address(const volatile void *ptr)`\n   - **功能**：根据内存地址判断是否应忽略对该地址的访问所引发的数据竞争。\n   - **返回值**：若应忽略，返回 `true`；否则返回 `false`。\n\n2. **`kcsan_ignore_data_race`**\n   - **原型**：`static bool kcsan_ignore_data_race(size_t size, int type, u64 old, u64 new, u64 diff)`\n   - **功能**：根据访问类型、操作数大小及值的变化模式，判断是否应忽略特定的数据竞争。\n   - **参数说明**：\n     - `size`：访问的字节数\n     - `type`：访问类型（0 表示 plain read，非 0 表示 write 或 atomic 等）\n     - `old`：旧值\n     - `new`：新值\n     - `diff`：`old ^ new` 的异或结果，表示变化的位\n   - **返回值**：若应忽略，返回 `true`；否则返回 `false`。\n\n## 关键实现\n\n### 地址忽略规则（`kcsan_ignore_address`）\n\n- **忽略 `current->flags` 的所有访问**：\n  - 内核中对 `current->flags`（当前任务的标志位）使用非原子位操作（如 `set_bit`, `clear_bit`）非常普遍，且常与 plain load 混合使用。\n  - 这类数据竞争在现有代码中极为常见，短期内难以全部修复或标注。\n  - 因此，在宽容模式下，**完全忽略对 `&current->flags` 地址的所有数据竞争报告**。\n\n### 值变化模式忽略规则（`kcsan_ignore_data_race`）\n\n该函数仅在以下条件下尝试忽略数据竞争：\n\n1. **仅适用于 plain read 访问**：\n   - 要求 `type == 0`（即读操作）且 `size <= sizeof(long)`。\n   - 目的是**仍报告 plain read 与 write 之间的竞争**，但对某些“良性”读操作放宽限制。\n\n2. **单比特变化忽略策略**：\n   - 若 `diff`（即 `old ^ new`）的汉明权重（`hweight64(diff)`）为 1，说明仅有**一个比特位发生变化**。\n   - 此类模式常见于标志位检查（如 `if (flags & FLAG)`）与并发的单比特设置（如 `flags |= OTHER_FLAG`）。\n   - 假设：在现代编译器和 CPU 下，单比特变化的 plain 访问即使存在数据竞争，通常也不会导致未定义行为（如撕裂访问仍可接受）。\n\n3. **布尔值例外**：\n   - 若变化涉及**0 与 1 之间的切换**（即 `(!old || !new) && diff == 1`），则**不忽略**。\n   - 原因：布尔标志常伴随内存序要求（如状态机、完成通知），此类竞争更可能反映真实问题，应保留报告。\n\n## 依赖关系\n\n- **头文件依赖**：\n  - `<linux/bitops.h>`：提供 `hweight64()` 等位操作函数。\n  - `<linux/sched.h>`：定义 `current` 宏及 `task_struct`，用于访问 `current->flags`。\n  - `<linux/types.h>`：提供 `u64` 等基本类型定义。\n- **配置依赖**：\n  - 依赖 `CONFIG_KCSAN_PERMISSIVE` 内核配置选项。若未启用，所有忽略函数直接返回 `false`，不产生任何忽略行为。\n- **模块依赖**：\n  - 被 KCSAN 核心检测逻辑（如 `kcsan.c`）调用，作为数据竞争过滤的回调判断依据。\n\n## 使用场景\n\n- **KCSAN 动态检测过程中的过滤阶段**：\n  - 当 KCSAN 检测到潜在数据竞争时，会调用 `kcsan_ignore_address()` 判断是否因地址特殊而忽略。\n  - 对于 plain read 类型的竞争，还会调用 `kcsan_ignore_data_race()` 基于值变化模式决定是否忽略。\n- **内核开发与调试**：\n  - 在启用 `CONFIG_KCSAN_PERMISSIVE=y` 的测试或调试内核中，减少因历史代码中广泛存在的“良性”标志位竞争导致的报告噪音。\n  - 允许开发者聚焦于更可能引发问题的复杂数据竞争，而非大量单比特标志操作。\n- **维护兼容性**：\n  - 在无法立即修复或标注所有非原子标志位访问的子系统中，提供临时的宽容策略，避免 KCSAN 报告淹没真实问题。",
      "similarity": 0.44234609603881836,
      "chunks": []
    }
  ]
}