{
  "query": "保护环机制与操作系统安全",
  "timestamp": "2025-12-25 23:59:13",
  "retrieved_files": [
    {
      "source_file": "kernel/printk/printk_ringbuffer.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:34:17\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `printk\\printk_ringbuffer.c`\n\n---\n\n# printk_ringbuffer.c 技术文档\n\n## 文件概述\n\n`printk_ringbuffer.c` 实现了 Linux 内核中用于日志记录的无锁环形缓冲区（printk ringbuffer）核心逻辑。该缓冲区用于高效、并发安全地存储内核日志消息（printk 输出），支持多写者-多读者模型，无需使用传统锁机制，从而在高并发或中断上下文中也能安全使用。该实现是现代 printk 子系统的基础组件，用于替代旧的 log_buf。\n\n## 核心功能\n\n### 主要数据结构\n\n- **`printk_ringbuffer`**：顶层环形缓冲区结构，包含三个内部环形缓冲区：\n  - **`desc_ring`**：描述符环，存储每条日志记录的元数据（序列号、时间戳、日志级别、状态等）及指向文本数据的逻辑位置。\n  - **`text_data_ring`**：文本数据环，以字节为单位存储日志文本内容，每个数据块以描述符 ID 开头，后接实际文本。\n  - **`info` 数组**：与描述符一一对应的 `printk_info` 结构数组，存储日志记录的详细元数据。\n\n- **描述符状态（`state_var`）**：\n  - `reserved`：写者正在修改记录。\n  - `committed`：记录已提交，数据一致，但可被原写者重新打开修改。\n  - `finalized`：记录已最终确定，对读者可见，不可再修改。\n  - `reusable`：记录可被回收复用。\n  - `miss`（伪状态）：查询时发现描述符 ID 不匹配。\n\n- **`blk_lpos`**：逻辑位置结构，用于在数据环中定位数据块的起始和结束位置。\n\n### 主要函数（接口）\n\n- `prb_reserve()`：为新日志记录预留空间，返回保留条目。\n- `prb_commit()`：提交当前记录（可后续重新打开）。\n- `prb_final_commit()`：提交并最终确定记录，使其对读者可见。\n- `prb_read_valid()` / `prb_read_valid_info()`：安全读取指定序列号的日志记录及其元数据。\n- `prb_first_valid_seq()` / `prb_next_seq()`：获取有效日志序列范围。\n\n## 关键实现\n\n### 无锁同步机制\n\n通过原子操作更新描述符的 `state_var` 字段（将 ID 与状态位打包），实现写者与读者之间的无锁同步。状态转换遵循严格顺序：`reserved → committed → finalized → reusable`。\n\n### 描述符生命周期管理\n\n- **预留（Reserve）**：分配新描述符，状态设为 `reserved`。\n- **提交（Commit）**：写入完成后设为 `committed`，数据一致但可重入。\n- **最终确定（Finalize）**：在以下任一情况下自动或显式触发：\n  1. 调用 `prb_final_commit()`；\n  2. 下一条记录被预留且当前记录已 `committed`；\n  3. 提交一条记录时已有更新记录存在。\n- **回收（Reuse）**：缓冲区满时，将最旧的 `finalized` 或 `reusable` 记录状态转为 `reusable`，并推进 `tail_id`。\n\n### 数据环的环绕处理\n\n当日志文本跨越缓冲区末尾时，仅在末尾存储描述符 ID，完整数据块（ID + 文本）从缓冲区起始位置存储。`blk_lpos` 正确指向环绕前的 ID 位置，保证逻辑连续性。\n\n### 尾部推进安全约束\n\n`tail_id` 和 `tail_lpos` 仅在对应记录处于 `committed` 或 `reusable` 状态时才可推进，确保始终保留至少一条有效日志的序列号，避免读者读取到无效数据。\n\n### 元数据一致性保障\n\n读取 `printk_info` 时，需在读取前后两次检查对应描述符状态，确保元数据未在读取过程中被覆盖或修改（ABA 问题防护）。\n\n## 依赖关系\n\n- **内部依赖**：\n  - `printk_ringbuffer.h`：定义核心数据结构和 API。\n  - `internal.h`：包含 printk 子系统内部辅助函数和定义。\n- **内核头文件**：\n  - `<linux/kernel.h>`、`<linux/irqflags.h>`、`<linux/string.h>`、`<linux/bug.h>`：提供基础内核功能、原子操作、内存操作及调试支持。\n- **被 printk.c 调用**：作为 printk 日志后端，由 `printk.c` 中的 `vprintk_store()` 等函数调用其预留/提交接口。\n\n## 使用场景\n\n- **内核日志记录**：所有 `printk()` 调用最终通过此环形缓冲区存储日志消息。\n- **高并发环境**：在中断上下文、NMI、SMP 系统中安全记录日志，无需睡眠或持有自旋锁。\n- **日志读取**：`/dev/kmsg`、`dmesg` 命令及内核日志守护进程通过此缓冲区读取日志。\n- **崩溃转储**：在系统崩溃（如 panic）时，确保关键日志能被可靠记录和后续分析。\n- **动态日志扩展**：支持在提交后、最终确定前扩展日志内容（如追加堆栈信息），适用于延迟格式化场景。",
      "similarity": 0.5632604360580444,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/printk/printk_ringbuffer.c",
          "start_line": 771,
          "end_line": 876,
          "content": [
            "static bool desc_push_tail(struct printk_ringbuffer *rb,",
            "\t\t\t   unsigned long tail_id)",
            "{",
            "\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;",
            "\tenum desc_state d_state;",
            "\tstruct prb_desc desc;",
            "",
            "\td_state = desc_read(desc_ring, tail_id, &desc, NULL, NULL);",
            "",
            "\tswitch (d_state) {",
            "\tcase desc_miss:",
            "\t\t/*",
            "\t\t * If the ID is exactly 1 wrap behind the expected, it is",
            "\t\t * in the process of being reserved by another writer and",
            "\t\t * must be considered reserved.",
            "\t\t */",
            "\t\tif (DESC_ID(atomic_long_read(&desc.state_var)) ==",
            "\t\t    DESC_ID_PREV_WRAP(desc_ring, tail_id)) {",
            "\t\t\treturn false;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * The ID has changed. Another writer must have pushed the",
            "\t\t * tail and recycled the descriptor already. Success is",
            "\t\t * returned because the caller is only interested in the",
            "\t\t * specified tail being pushed, which it was.",
            "\t\t */",
            "\t\treturn true;",
            "\tcase desc_reserved:",
            "\tcase desc_committed:",
            "\t\treturn false;",
            "\tcase desc_finalized:",
            "\t\tdesc_make_reusable(desc_ring, tail_id);",
            "\t\tbreak;",
            "\tcase desc_reusable:",
            "\t\tbreak;",
            "\t}",
            "",
            "\t/*",
            "\t * Data blocks must be invalidated before their associated",
            "\t * descriptor can be made available for recycling. Invalidating",
            "\t * them later is not possible because there is no way to trust",
            "\t * data blocks once their associated descriptor is gone.",
            "\t */",
            "",
            "\tif (!data_push_tail(rb, desc.text_blk_lpos.next))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Check the next descriptor after @tail_id before pushing the tail",
            "\t * to it because the tail must always be in a finalized or reusable",
            "\t * state. The implementation of prb_first_seq() relies on this.",
            "\t *",
            "\t * A successful read implies that the next descriptor is less than or",
            "\t * equal to @head_id so there is no risk of pushing the tail past the",
            "\t * head.",
            "\t */",
            "\td_state = desc_read(desc_ring, DESC_ID(tail_id + 1), &desc,",
            "\t\t\t    NULL, NULL); /* LMM(desc_push_tail:A) */",
            "",
            "\tif (d_state == desc_finalized || d_state == desc_reusable) {",
            "\t\t/*",
            "\t\t * Guarantee any descriptor states that have transitioned to",
            "\t\t * reusable are stored before pushing the tail ID. This allows",
            "\t\t * verifying the recycled descriptor state. A full memory",
            "\t\t * barrier is needed since other CPUs may have made the",
            "\t\t * descriptor states reusable. This pairs with desc_reserve:D.",
            "\t\t */",
            "\t\tatomic_long_cmpxchg(&desc_ring->tail_id, tail_id,",
            "\t\t\t\t    DESC_ID(tail_id + 1)); /* LMM(desc_push_tail:B) */",
            "\t} else {",
            "\t\t/*",
            "\t\t * Guarantee the last state load from desc_read() is before",
            "\t\t * reloading @tail_id in order to see a new tail ID in the",
            "\t\t * case that the descriptor has been recycled. This pairs",
            "\t\t * with desc_reserve:D.",
            "\t\t *",
            "\t\t * Memory barrier involvement:",
            "\t\t *",
            "\t\t * If desc_push_tail:A reads from desc_reserve:F, then",
            "\t\t * desc_push_tail:D reads from desc_push_tail:B.",
            "\t\t *",
            "\t\t * Relies on:",
            "\t\t *",
            "\t\t * MB from desc_push_tail:B to desc_reserve:F",
            "\t\t *    matching",
            "\t\t * RMB from desc_push_tail:A to desc_push_tail:D",
            "\t\t *",
            "\t\t * Note: desc_push_tail:B and desc_reserve:F can be different",
            "\t\t *       CPUs. However, the desc_reserve:F CPU (which performs",
            "\t\t *       the full memory barrier) must have previously seen",
            "\t\t *       desc_push_tail:B.",
            "\t\t */",
            "\t\tsmp_rmb(); /* LMM(desc_push_tail:C) */",
            "",
            "\t\t/*",
            "\t\t * Re-check the tail ID. The descriptor following @tail_id is",
            "\t\t * not in an allowed tail state. But if the tail has since",
            "\t\t * been moved by another CPU, then it does not matter.",
            "\t\t */",
            "\t\tif (atomic_long_read(&desc_ring->tail_id) == tail_id) /* LMM(desc_push_tail:D) */",
            "\t\t\treturn false;",
            "\t}",
            "",
            "\treturn true;",
            "}"
          ],
          "function_name": "desc_push_tail",
          "description": "推进描述符环尾指针，检查后续描述符状态合法性，通过内存屏障保障状态变更顺序以避免非法尾指针推进",
          "similarity": 0.571247398853302
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/printk/printk_ringbuffer.c",
          "start_line": 1,
          "end_line": 382,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "",
            "#include <linux/kernel.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/string.h>",
            "#include <linux/errno.h>",
            "#include <linux/bug.h>",
            "#include \"printk_ringbuffer.h\"",
            "#include \"internal.h\"",
            "",
            "/**",
            " * DOC: printk_ringbuffer overview",
            " *",
            " * Data Structure",
            " * --------------",
            " * The printk_ringbuffer is made up of 3 internal ringbuffers:",
            " *",
            " *   desc_ring",
            " *     A ring of descriptors and their meta data (such as sequence number,",
            " *     timestamp, loglevel, etc.) as well as internal state information about",
            " *     the record and logical positions specifying where in the other",
            " *     ringbuffer the text strings are located.",
            " *",
            " *   text_data_ring",
            " *     A ring of data blocks. A data block consists of an unsigned long",
            " *     integer (ID) that maps to a desc_ring index followed by the text",
            " *     string of the record.",
            " *",
            " * The internal state information of a descriptor is the key element to allow",
            " * readers and writers to locklessly synchronize access to the data.",
            " *",
            " * Implementation",
            " * --------------",
            " *",
            " * Descriptor Ring",
            " * ~~~~~~~~~~~~~~~",
            " * The descriptor ring is an array of descriptors. A descriptor contains",
            " * essential meta data to track the data of a printk record using",
            " * blk_lpos structs pointing to associated text data blocks (see",
            " * \"Data Rings\" below). Each descriptor is assigned an ID that maps",
            " * directly to index values of the descriptor array and has a state. The ID",
            " * and the state are bitwise combined into a single descriptor field named",
            " * @state_var, allowing ID and state to be synchronously and atomically",
            " * updated.",
            " *",
            " * Descriptors have four states:",
            " *",
            " *   reserved",
            " *     A writer is modifying the record.",
            " *",
            " *   committed",
            " *     The record and all its data are written. A writer can reopen the",
            " *     descriptor (transitioning it back to reserved), but in the committed",
            " *     state the data is consistent.",
            " *",
            " *   finalized",
            " *     The record and all its data are complete and available for reading. A",
            " *     writer cannot reopen the descriptor.",
            " *",
            " *   reusable",
            " *     The record exists, but its text and/or meta data may no longer be",
            " *     available.",
            " *",
            " * Querying the @state_var of a record requires providing the ID of the",
            " * descriptor to query. This can yield a possible fifth (pseudo) state:",
            " *",
            " *   miss",
            " *     The descriptor being queried has an unexpected ID.",
            " *",
            " * The descriptor ring has a @tail_id that contains the ID of the oldest",
            " * descriptor and @head_id that contains the ID of the newest descriptor.",
            " *",
            " * When a new descriptor should be created (and the ring is full), the tail",
            " * descriptor is invalidated by first transitioning to the reusable state and",
            " * then invalidating all tail data blocks up to and including the data blocks",
            " * associated with the tail descriptor (for the text ring). Then",
            " * @tail_id is advanced, followed by advancing @head_id. And finally the",
            " * @state_var of the new descriptor is initialized to the new ID and reserved",
            " * state.",
            " *",
            " * The @tail_id can only be advanced if the new @tail_id would be in the",
            " * committed or reusable queried state. This makes it possible that a valid",
            " * sequence number of the tail is always available.",
            " *",
            " * Descriptor Finalization",
            " * ~~~~~~~~~~~~~~~~~~~~~~~",
            " * When a writer calls the commit function prb_commit(), record data is",
            " * fully stored and is consistent within the ringbuffer. However, a writer can",
            " * reopen that record, claiming exclusive access (as with prb_reserve()), and",
            " * modify that record. When finished, the writer must again commit the record.",
            " *",
            " * In order for a record to be made available to readers (and also become",
            " * recyclable for writers), it must be finalized. A finalized record cannot be",
            " * reopened and can never become \"unfinalized\". Record finalization can occur",
            " * in three different scenarios:",
            " *",
            " *   1) A writer can simultaneously commit and finalize its record by calling",
            " *      prb_final_commit() instead of prb_commit().",
            " *",
            " *   2) When a new record is reserved and the previous record has been",
            " *      committed via prb_commit(), that previous record is automatically",
            " *      finalized.",
            " *",
            " *   3) When a record is committed via prb_commit() and a newer record",
            " *      already exists, the record being committed is automatically finalized.",
            " *",
            " * Data Ring",
            " * ~~~~~~~~~",
            " * The text data ring is a byte array composed of data blocks. Data blocks are",
            " * referenced by blk_lpos structs that point to the logical position of the",
            " * beginning of a data block and the beginning of the next adjacent data",
            " * block. Logical positions are mapped directly to index values of the byte",
            " * array ringbuffer.",
            " *",
            " * Each data block consists of an ID followed by the writer data. The ID is",
            " * the identifier of a descriptor that is associated with the data block. A",
            " * given data block is considered valid if all of the following conditions",
            " * are met:",
            " *",
            " *   1) The descriptor associated with the data block is in the committed",
            " *      or finalized queried state.",
            " *",
            " *   2) The blk_lpos struct within the descriptor associated with the data",
            " *      block references back to the same data block.",
            " *",
            " *   3) The data block is within the head/tail logical position range.",
            " *",
            " * If the writer data of a data block would extend beyond the end of the",
            " * byte array, only the ID of the data block is stored at the logical",
            " * position and the full data block (ID and writer data) is stored at the",
            " * beginning of the byte array. The referencing blk_lpos will point to the",
            " * ID before the wrap and the next data block will be at the logical",
            " * position adjacent the full data block after the wrap.",
            " *",
            " * Data rings have a @tail_lpos that points to the beginning of the oldest",
            " * data block and a @head_lpos that points to the logical position of the",
            " * next (not yet existing) data block.",
            " *",
            " * When a new data block should be created (and the ring is full), tail data",
            " * blocks will first be invalidated by putting their associated descriptors",
            " * into the reusable state and then pushing the @tail_lpos forward beyond",
            " * them. Then the @head_lpos is pushed forward and is associated with a new",
            " * descriptor. If a data block is not valid, the @tail_lpos cannot be",
            " * advanced beyond it.",
            " *",
            " * Info Array",
            " * ~~~~~~~~~~",
            " * The general meta data of printk records are stored in printk_info structs,",
            " * stored in an array with the same number of elements as the descriptor ring.",
            " * Each info corresponds to the descriptor of the same index in the",
            " * descriptor ring. Info validity is confirmed by evaluating the corresponding",
            " * descriptor before and after loading the info.",
            " *",
            " * Usage",
            " * -----",
            " * Here are some simple examples demonstrating writers and readers. For the",
            " * examples a global ringbuffer (test_rb) is available (which is not the",
            " * actual ringbuffer used by printk)::",
            " *",
            " *\tDEFINE_PRINTKRB(test_rb, 15, 5);",
            " *",
            " * This ringbuffer allows up to 32768 records (2 ^ 15) and has a size of",
            " * 1 MiB (2 ^ (15 + 5)) for text data.",
            " *",
            " * Sample writer code::",
            " *",
            " *\tconst char *textstr = \"message text\";",
            " *\tstruct prb_reserved_entry e;",
            " *\tstruct printk_record r;",
            " *",
            " *\t// specify how much to allocate",
            " *\tprb_rec_init_wr(&r, strlen(textstr) + 1);",
            " *",
            " *\tif (prb_reserve(&e, &test_rb, &r)) {",
            " *\t\tsnprintf(r.text_buf, r.text_buf_size, \"%s\", textstr);",
            " *",
            " *\t\tr.info->text_len = strlen(textstr);",
            " *\t\tr.info->ts_nsec = local_clock();",
            " *\t\tr.info->caller_id = printk_caller_id();",
            " *",
            " *\t\t// commit and finalize the record",
            " *\t\tprb_final_commit(&e);",
            " *\t}",
            " *",
            " * Note that additional writer functions are available to extend a record",
            " * after it has been committed but not yet finalized. This can be done as",
            " * long as no new records have been reserved and the caller is the same.",
            " *",
            " * Sample writer code (record extending)::",
            " *",
            " *\t\t// alternate rest of previous example",
            " *",
            " *\t\tr.info->text_len = strlen(textstr);",
            " *\t\tr.info->ts_nsec = local_clock();",
            " *\t\tr.info->caller_id = printk_caller_id();",
            " *",
            " *\t\t// commit the record (but do not finalize yet)",
            " *\t\tprb_commit(&e);",
            " *\t}",
            " *",
            " *\t...",
            " *",
            " *\t// specify additional 5 bytes text space to extend",
            " *\tprb_rec_init_wr(&r, 5);",
            " *",
            " *\t// try to extend, but only if it does not exceed 32 bytes",
            " *\tif (prb_reserve_in_last(&e, &test_rb, &r, printk_caller_id(), 32)) {",
            " *\t\tsnprintf(&r.text_buf[r.info->text_len],",
            " *\t\t\t r.text_buf_size - r.info->text_len, \"hello\");",
            " *",
            " *\t\tr.info->text_len += 5;",
            " *",
            " *\t\t// commit and finalize the record",
            " *\t\tprb_final_commit(&e);",
            " *\t}",
            " *",
            " * Sample reader code::",
            " *",
            " *\tstruct printk_info info;",
            " *\tstruct printk_record r;",
            " *\tchar text_buf[32];",
            " *\tu64 seq;",
            " *",
            " *\tprb_rec_init_rd(&r, &info, &text_buf[0], sizeof(text_buf));",
            " *",
            " *\tprb_for_each_record(0, &test_rb, &seq, &r) {",
            " *\t\tif (info.seq != seq)",
            " *\t\t\tpr_warn(\"lost %llu records\\n\", info.seq - seq);",
            " *",
            " *\t\tif (info.text_len > r.text_buf_size) {",
            " *\t\t\tpr_warn(\"record %llu text truncated\\n\", info.seq);",
            " *\t\t\ttext_buf[r.text_buf_size - 1] = 0;",
            " *\t\t}",
            " *",
            " *\t\tpr_info(\"%llu: %llu: %s\\n\", info.seq, info.ts_nsec,",
            " *\t\t\t&text_buf[0]);",
            " *\t}",
            " *",
            " * Note that additional less convenient reader functions are available to",
            " * allow complex record access.",
            " *",
            " * ABA Issues",
            " * ~~~~~~~~~~",
            " * To help avoid ABA issues, descriptors are referenced by IDs (array index",
            " * values combined with tagged bits counting array wraps) and data blocks are",
            " * referenced by logical positions (array index values combined with tagged",
            " * bits counting array wraps). However, on 32-bit systems the number of",
            " * tagged bits is relatively small such that an ABA incident is (at least",
            " * theoretically) possible. For example, if 4 million maximally sized (1KiB)",
            " * printk messages were to occur in NMI context on a 32-bit system, the",
            " * interrupted context would not be able to recognize that the 32-bit integer",
            " * completely wrapped and thus represents a different data block than the one",
            " * the interrupted context expects.",
            " *",
            " * To help combat this possibility, additional state checking is performed",
            " * (such as using cmpxchg() even though set() would suffice). These extra",
            " * checks are commented as such and will hopefully catch any ABA issue that",
            " * a 32-bit system might experience.",
            " *",
            " * Memory Barriers",
            " * ~~~~~~~~~~~~~~~",
            " * Multiple memory barriers are used. To simplify proving correctness and",
            " * generating litmus tests, lines of code related to memory barriers",
            " * (loads, stores, and the associated memory barriers) are labeled::",
            " *",
            " *\tLMM(function:letter)",
            " *",
            " * Comments reference the labels using only the \"function:letter\" part.",
            " *",
            " * The memory barrier pairs and their ordering are:",
            " *",
            " *   desc_reserve:D / desc_reserve:B",
            " *     push descriptor tail (id), then push descriptor head (id)",
            " *",
            " *   desc_reserve:D / data_push_tail:B",
            " *     push data tail (lpos), then set new descriptor reserved (state)",
            " *",
            " *   desc_reserve:D / desc_push_tail:C",
            " *     push descriptor tail (id), then set new descriptor reserved (state)",
            " *",
            " *   desc_reserve:D / prb_first_seq:C",
            " *     push descriptor tail (id), then set new descriptor reserved (state)",
            " *",
            " *   desc_reserve:F / desc_read:D",
            " *     set new descriptor id and reserved (state), then allow writer changes",
            " *",
            " *   data_alloc:A (or data_realloc:A) / desc_read:D",
            " *     set old descriptor reusable (state), then modify new data block area",
            " *",
            " *   data_alloc:A (or data_realloc:A) / data_push_tail:B",
            " *     push data tail (lpos), then modify new data block area",
            " *",
            " *   _prb_commit:B / desc_read:B",
            " *     store writer changes, then set new descriptor committed (state)",
            " *",
            " *   desc_reopen_last:A / _prb_commit:B",
            " *     set descriptor reserved (state), then read descriptor data",
            " *",
            " *   _prb_commit:B / desc_reserve:D",
            " *     set new descriptor committed (state), then check descriptor head (id)",
            " *",
            " *   data_push_tail:D / data_push_tail:A",
            " *     set descriptor reusable (state), then push data tail (lpos)",
            " *",
            " *   desc_push_tail:B / desc_reserve:D",
            " *     set descriptor reusable (state), then push descriptor tail (id)",
            " *",
            " *   desc_update_last_finalized:A / desc_last_finalized_seq:A",
            " *     store finalized record, then set new highest finalized sequence number",
            " */",
            "",
            "#define DATA_SIZE(data_ring)\t\t_DATA_SIZE((data_ring)->size_bits)",
            "#define DATA_SIZE_MASK(data_ring)\t(DATA_SIZE(data_ring) - 1)",
            "",
            "#define DESCS_COUNT(desc_ring)\t\t_DESCS_COUNT((desc_ring)->count_bits)",
            "#define DESCS_COUNT_MASK(desc_ring)\t(DESCS_COUNT(desc_ring) - 1)",
            "",
            "/* Determine the data array index from a logical position. */",
            "#define DATA_INDEX(data_ring, lpos)\t((lpos) & DATA_SIZE_MASK(data_ring))",
            "",
            "/* Determine the desc array index from an ID or sequence number. */",
            "#define DESC_INDEX(desc_ring, n)\t((n) & DESCS_COUNT_MASK(desc_ring))",
            "",
            "/* Determine how many times the data array has wrapped. */",
            "#define DATA_WRAPS(data_ring, lpos)\t((lpos) >> (data_ring)->size_bits)",
            "",
            "/* Determine if a logical position refers to a data-less block. */",
            "#define LPOS_DATALESS(lpos)\t\t((lpos) & 1UL)",
            "#define BLK_DATALESS(blk)\t\t(LPOS_DATALESS((blk)->begin) && \\",
            "\t\t\t\t\t LPOS_DATALESS((blk)->next))",
            "",
            "/* Get the logical position at index 0 of the current wrap. */",
            "#define DATA_THIS_WRAP_START_LPOS(data_ring, lpos) \\",
            "((lpos) & ~DATA_SIZE_MASK(data_ring))",
            "",
            "/* Get the ID for the same index of the previous wrap as the given ID. */",
            "#define DESC_ID_PREV_WRAP(desc_ring, id) \\",
            "DESC_ID((id) - DESCS_COUNT(desc_ring))",
            "",
            "/*",
            " * A data block: mapped directly to the beginning of the data block area",
            " * specified as a logical position within the data ring.",
            " *",
            " * @id:   the ID of the associated descriptor",
            " * @data: the writer data",
            " *",
            " * Note that the size of a data block is only known by its associated",
            " * descriptor.",
            " */",
            "struct prb_data_block {",
            "\tunsigned long\tid;",
            "\tchar\t\tdata[];",
            "};",
            "",
            "/*",
            " * Return the descriptor associated with @n. @n can be either a",
            " * descriptor ID or a sequence number.",
            " */",
            "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)",
            "{",
            "\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];",
            "}",
            "",
            "/*",
            " * Return the printk_info associated with @n. @n can be either a",
            " * descriptor ID or a sequence number.",
            " */",
            "static struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)",
            "{",
            "\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];",
            "}",
            "",
            "static struct prb_data_block *to_block(struct prb_data_ring *data_ring,",
            "\t\t\t\t       unsigned long begin_lpos)",
            "{",
            "\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];",
            "}",
            "",
            "/*",
            " * Increase the data size to account for data block meta data plus any",
            " * padding so that the adjacent data block is aligned on the ID size.",
            " */"
          ],
          "function_name": null,
          "description": "定义printk_ringbuffer的数据结构和宏，用于管理描述符环与文本数据环，包含内存屏障标注和ABAA问题处理说明",
          "similarity": 0.5659058094024658
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/printk/printk_ringbuffer.c",
          "start_line": 2179,
          "end_line": 2259,
          "content": [
            "bool prb_read_valid(struct printk_ringbuffer *rb, u64 seq,",
            "\t\t    struct printk_record *r)",
            "{",
            "\treturn _prb_read_valid(rb, &seq, r, NULL);",
            "}",
            "bool prb_read_valid_info(struct printk_ringbuffer *rb, u64 seq,",
            "\t\t\t struct printk_info *info, unsigned int *line_count)",
            "{",
            "\tstruct printk_record r;",
            "",
            "\tprb_rec_init_rd(&r, info, NULL, 0);",
            "",
            "\treturn _prb_read_valid(rb, &seq, &r, line_count);",
            "}",
            "u64 prb_first_valid_seq(struct printk_ringbuffer *rb)",
            "{",
            "\tu64 seq = 0;",
            "",
            "\tif (!_prb_read_valid(rb, &seq, NULL, NULL))",
            "\t\treturn 0;",
            "",
            "\treturn seq;",
            "}",
            "u64 prb_next_seq(struct printk_ringbuffer *rb)",
            "{",
            "\tu64 seq;",
            "",
            "\tseq = desc_last_finalized_seq(rb);",
            "",
            "\t/*",
            "\t * Begin searching after the last finalized record.",
            "\t *",
            "\t * On 0, the search must begin at 0 because of hack#2",
            "\t * of the bootstrapping phase it is not known if a",
            "\t * record at index 0 exists.",
            "\t */",
            "\tif (seq != 0)",
            "\t\tseq++;",
            "",
            "\t/*",
            "\t * The information about the last finalized @seq might be inaccurate.",
            "\t * Search forward to find the current one.",
            "\t */",
            "\twhile (_prb_read_valid(rb, &seq, NULL, NULL))",
            "\t\tseq++;",
            "",
            "\treturn seq;",
            "}",
            "void prb_init(struct printk_ringbuffer *rb,",
            "\t      char *text_buf, unsigned int textbits,",
            "\t      struct prb_desc *descs, unsigned int descbits,",
            "\t      struct printk_info *infos)",
            "{",
            "\tmemset(descs, 0, _DESCS_COUNT(descbits) * sizeof(descs[0]));",
            "\tmemset(infos, 0, _DESCS_COUNT(descbits) * sizeof(infos[0]));",
            "",
            "\trb->desc_ring.count_bits = descbits;",
            "\trb->desc_ring.descs = descs;",
            "\trb->desc_ring.infos = infos;",
            "\tatomic_long_set(&rb->desc_ring.head_id, DESC0_ID(descbits));",
            "\tatomic_long_set(&rb->desc_ring.tail_id, DESC0_ID(descbits));",
            "\tatomic_long_set(&rb->desc_ring.last_finalized_seq, 0);",
            "",
            "\trb->text_data_ring.size_bits = textbits;",
            "\trb->text_data_ring.data = text_buf;",
            "\tatomic_long_set(&rb->text_data_ring.head_lpos, BLK0_LPOS(textbits));",
            "\tatomic_long_set(&rb->text_data_ring.tail_lpos, BLK0_LPOS(textbits));",
            "",
            "\tatomic_long_set(&rb->fail, 0);",
            "",
            "\tatomic_long_set(&(descs[_DESCS_COUNT(descbits) - 1].state_var), DESC0_SV(descbits));",
            "\tdescs[_DESCS_COUNT(descbits) - 1].text_blk_lpos.begin = FAILED_LPOS;",
            "\tdescs[_DESCS_COUNT(descbits) - 1].text_blk_lpos.next = FAILED_LPOS;",
            "",
            "\tinfos[0].seq = -(u64)_DESCS_COUNT(descbits);",
            "\tinfos[_DESCS_COUNT(descbits) - 1].seq = 0;",
            "}",
            "unsigned int prb_record_text_space(struct prb_reserved_entry *e)",
            "{",
            "\treturn e->text_space;",
            "}"
          ],
          "function_name": "prb_read_valid, prb_read_valid_info, prb_first_valid_seq, prb_next_seq, prb_init, prb_record_text_space",
          "description": "该代码段实现了 printk 环形缓冲区的读写控制逻辑，主要包含以下内容：  \n1. `prb_read_valid` 系列函数通过 `_prb_read_valid` 检查序列号有效性并填充记录信息，用于日志读取校验；  \n2. `prb_first_valid_seq` 和 `prb_next_seq` 用于定位首个有效序列号与后续序列号，解决缓冲区初始状态不确定的问题；  \n3. `prb_init` 初始化缓冲区结构，配置描述符环和文本数据环的元数据，`prb_record_text_space` 返回记录文本空间大小。注：`_prb_read_valid` 实现未完整展示，需结合上下文理解其核心逻辑。",
          "similarity": 0.5529941916465759
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/printk/printk_ringbuffer.c",
          "start_line": 879,
          "end_line": 1003,
          "content": [
            "static bool desc_reserve(struct printk_ringbuffer *rb, unsigned long *id_out)",
            "{",
            "\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;",
            "\tunsigned long prev_state_val;",
            "\tunsigned long id_prev_wrap;",
            "\tstruct prb_desc *desc;",
            "\tunsigned long head_id;",
            "\tunsigned long id;",
            "",
            "\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(desc_reserve:A) */",
            "",
            "\tdo {",
            "\t\tid = DESC_ID(head_id + 1);",
            "\t\tid_prev_wrap = DESC_ID_PREV_WRAP(desc_ring, id);",
            "",
            "\t\t/*",
            "\t\t * Guarantee the head ID is read before reading the tail ID.",
            "\t\t * Since the tail ID is updated before the head ID, this",
            "\t\t * guarantees that @id_prev_wrap is never ahead of the tail",
            "\t\t * ID. This pairs with desc_reserve:D.",
            "\t\t *",
            "\t\t * Memory barrier involvement:",
            "\t\t *",
            "\t\t * If desc_reserve:A reads from desc_reserve:D, then",
            "\t\t * desc_reserve:C reads from desc_push_tail:B.",
            "\t\t *",
            "\t\t * Relies on:",
            "\t\t *",
            "\t\t * MB from desc_push_tail:B to desc_reserve:D",
            "\t\t *    matching",
            "\t\t * RMB from desc_reserve:A to desc_reserve:C",
            "\t\t *",
            "\t\t * Note: desc_push_tail:B and desc_reserve:D can be different",
            "\t\t *       CPUs. However, the desc_reserve:D CPU (which performs",
            "\t\t *       the full memory barrier) must have previously seen",
            "\t\t *       desc_push_tail:B.",
            "\t\t */",
            "\t\tsmp_rmb(); /* LMM(desc_reserve:B) */",
            "",
            "\t\tif (id_prev_wrap == atomic_long_read(&desc_ring->tail_id",
            "\t\t\t\t\t\t    )) { /* LMM(desc_reserve:C) */",
            "\t\t\t/*",
            "\t\t\t * Make space for the new descriptor by",
            "\t\t\t * advancing the tail.",
            "\t\t\t */",
            "\t\t\tif (!desc_push_tail(rb, id_prev_wrap))",
            "\t\t\t\treturn false;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * 1. Guarantee the tail ID is read before validating the",
            "\t\t *    recycled descriptor state. A read memory barrier is",
            "\t\t *    sufficient for this. This pairs with desc_push_tail:B.",
            "\t\t *",
            "\t\t *    Memory barrier involvement:",
            "\t\t *",
            "\t\t *    If desc_reserve:C reads from desc_push_tail:B, then",
            "\t\t *    desc_reserve:E reads from desc_make_reusable:A.",
            "\t\t *",
            "\t\t *    Relies on:",
            "\t\t *",
            "\t\t *    MB from desc_make_reusable:A to desc_push_tail:B",
            "\t\t *       matching",
            "\t\t *    RMB from desc_reserve:C to desc_reserve:E",
            "\t\t *",
            "\t\t *    Note: desc_make_reusable:A and desc_push_tail:B can be",
            "\t\t *          different CPUs. However, the desc_push_tail:B CPU",
            "\t\t *          (which performs the full memory barrier) must have",
            "\t\t *          previously seen desc_make_reusable:A.",
            "\t\t *",
            "\t\t * 2. Guarantee the tail ID is stored before storing the head",
            "\t\t *    ID. This pairs with desc_reserve:B.",
            "\t\t *",
            "\t\t * 3. Guarantee any data ring tail changes are stored before",
            "\t\t *    recycling the descriptor. Data ring tail changes can",
            "\t\t *    happen via desc_push_tail()->data_push_tail(). A full",
            "\t\t *    memory barrier is needed since another CPU may have",
            "\t\t *    pushed the data ring tails. This pairs with",
            "\t\t *    data_push_tail:B.",
            "\t\t *",
            "\t\t * 4. Guarantee a new tail ID is stored before recycling the",
            "\t\t *    descriptor. A full memory barrier is needed since",
            "\t\t *    another CPU may have pushed the tail ID. This pairs",
            "\t\t *    with desc_push_tail:C and this also pairs with",
            "\t\t *    prb_first_seq:C.",
            "\t\t *",
            "\t\t * 5. Guarantee the head ID is stored before trying to",
            "\t\t *    finalize the previous descriptor. This pairs with",
            "\t\t *    _prb_commit:B.",
            "\t\t */",
            "\t} while (!atomic_long_try_cmpxchg(&desc_ring->head_id, &head_id,",
            "\t\t\t\t\t  id)); /* LMM(desc_reserve:D) */",
            "",
            "\tdesc = to_desc(desc_ring, id);",
            "",
            "\t/*",
            "\t * If the descriptor has been recycled, verify the old state val.",
            "\t * See \"ABA Issues\" about why this verification is performed.",
            "\t */",
            "\tprev_state_val = atomic_long_read(&desc->state_var); /* LMM(desc_reserve:E) */",
            "\tif (prev_state_val &&",
            "\t    get_desc_state(id_prev_wrap, prev_state_val) != desc_reusable) {",
            "\t\tWARN_ON_ONCE(1);",
            "\t\treturn false;",
            "\t}",
            "",
            "\t/*",
            "\t * Assign the descriptor a new ID and set its state to reserved.",
            "\t * See \"ABA Issues\" about why cmpxchg() instead of set() is used.",
            "\t *",
            "\t * Guarantee the new descriptor ID and state is stored before making",
            "\t * any other changes. A write memory barrier is sufficient for this.",
            "\t * This pairs with desc_read:D.",
            "\t */",
            "\tif (!atomic_long_try_cmpxchg(&desc->state_var, &prev_state_val,",
            "\t\t\tDESC_SV(id, desc_reserved))) { /* LMM(desc_reserve:F) */",
            "\t\tWARN_ON_ONCE(1);",
            "\t\treturn false;",
            "\t}",
            "",
            "\t/* Now data in @desc can be modified: LMM(desc_reserve:G) */",
            "",
            "\t*id_out = id;",
            "\treturn true;",
            "}"
          ],
          "function_name": "desc_reserve",
          "description": "实现描述符保留逻辑，通过CAS操作获取新ID并设置保留状态，含多重内存屏障保障状态变更顺序与数据一致性",
          "similarity": 0.5511641502380371
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/printk/printk_ringbuffer.c",
          "start_line": 383,
          "end_line": 521,
          "content": [
            "static unsigned int to_blk_size(unsigned int size)",
            "{",
            "\tstruct prb_data_block *db = NULL;",
            "",
            "\tsize += sizeof(*db);",
            "\tsize = ALIGN(size, sizeof(db->id));",
            "\treturn size;",
            "}",
            "static bool data_check_size(struct prb_data_ring *data_ring, unsigned int size)",
            "{",
            "\tstruct prb_data_block *db = NULL;",
            "",
            "\tif (size == 0)",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * Ensure the alignment padded size could possibly fit in the data",
            "\t * array. The largest possible data block must still leave room for",
            "\t * at least the ID of the next block.",
            "\t */",
            "\tsize = to_blk_size(size);",
            "\tif (size > DATA_SIZE(data_ring) - sizeof(db->id))",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}",
            "static enum desc_state get_desc_state(unsigned long id,",
            "\t\t\t\t      unsigned long state_val)",
            "{",
            "\tif (id != DESC_ID(state_val))",
            "\t\treturn desc_miss;",
            "",
            "\treturn DESC_STATE(state_val);",
            "}",
            "static enum desc_state desc_read(struct prb_desc_ring *desc_ring,",
            "\t\t\t\t unsigned long id, struct prb_desc *desc_out,",
            "\t\t\t\t u64 *seq_out, u32 *caller_id_out)",
            "{",
            "\tstruct printk_info *info = to_info(desc_ring, id);",
            "\tstruct prb_desc *desc = to_desc(desc_ring, id);",
            "\tatomic_long_t *state_var = &desc->state_var;",
            "\tenum desc_state d_state;",
            "\tunsigned long state_val;",
            "",
            "\t/* Check the descriptor state. */",
            "\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */",
            "\td_state = get_desc_state(id, state_val);",
            "\tif (d_state == desc_miss || d_state == desc_reserved) {",
            "\t\t/*",
            "\t\t * The descriptor is in an inconsistent state. Set at least",
            "\t\t * @state_var so that the caller can see the details of",
            "\t\t * the inconsistent state.",
            "\t\t */",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * Guarantee the state is loaded before copying the descriptor",
            "\t * content. This avoids copying obsolete descriptor content that might",
            "\t * not apply to the descriptor state. This pairs with _prb_commit:B.",
            "\t *",
            "\t * Memory barrier involvement:",
            "\t *",
            "\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads",
            "\t * from _prb_commit:A.",
            "\t *",
            "\t * Relies on:",
            "\t *",
            "\t * WMB from _prb_commit:A to _prb_commit:B",
            "\t *    matching",
            "\t * RMB from desc_read:A to desc_read:C",
            "\t */",
            "\tsmp_rmb(); /* LMM(desc_read:B) */",
            "",
            "\t/*",
            "\t * Copy the descriptor data. The data is not valid until the",
            "\t * state has been re-checked. A memcpy() for all of @desc",
            "\t * cannot be used because of the atomic_t @state_var field.",
            "\t */",
            "\tif (desc_out) {",
            "\t\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,",
            "\t\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */",
            "\t}",
            "\tif (seq_out)",
            "\t\t*seq_out = info->seq; /* also part of desc_read:C */",
            "\tif (caller_id_out)",
            "\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */",
            "",
            "\t/*",
            "\t * 1. Guarantee the descriptor content is loaded before re-checking",
            "\t *    the state. This avoids reading an obsolete descriptor state",
            "\t *    that may not apply to the copied content. This pairs with",
            "\t *    desc_reserve:F.",
            "\t *",
            "\t *    Memory barrier involvement:",
            "\t *",
            "\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E",
            "\t *    reads from desc_reserve:F.",
            "\t *",
            "\t *    Relies on:",
            "\t *",
            "\t *    WMB from desc_reserve:F to desc_reserve:G",
            "\t *       matching",
            "\t *    RMB from desc_read:C to desc_read:E",
            "\t *",
            "\t * 2. Guarantee the record data is loaded before re-checking the",
            "\t *    state. This avoids reading an obsolete descriptor state that may",
            "\t *    not apply to the copied data. This pairs with data_alloc:A and",
            "\t *    data_realloc:A.",
            "\t *",
            "\t *    Memory barrier involvement:",
            "\t *",
            "\t *    If copy_data:A reads from data_alloc:B, then desc_read:E",
            "\t *    reads from desc_make_reusable:A.",
            "\t *",
            "\t *    Relies on:",
            "\t *",
            "\t *    MB from desc_make_reusable:A to data_alloc:B",
            "\t *       matching",
            "\t *    RMB from desc_read:C to desc_read:E",
            "\t *",
            "\t *    Note: desc_make_reusable:A and data_alloc:B can be different",
            "\t *          CPUs. However, the data_alloc:B CPU (which performs the",
            "\t *          full memory barrier) must have previously seen",
            "\t *          desc_make_reusable:A.",
            "\t */",
            "\tsmp_rmb(); /* LMM(desc_read:D) */",
            "",
            "\t/*",
            "\t * The data has been copied. Return the current descriptor state,",
            "\t * which may have changed since the load above.",
            "\t */",
            "\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */",
            "\td_state = get_desc_state(id, state_val);",
            "out:",
            "\tif (desc_out)",
            "\t\tatomic_long_set(&desc_out->state_var, state_val);",
            "\treturn d_state;",
            "}"
          ],
          "function_name": "to_blk_size, data_check_size, get_desc_state, desc_read",
          "description": "实现数据块大小计算、数据大小验证、描述符状态获取及描述符读取逻辑，含多处内存屏障保障状态一致性",
          "similarity": 0.5252209901809692
        }
      ]
    },
    {
      "source_file": "kernel/events/ring_buffer.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:25:08\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `events\\ring_buffer.c`\n\n---\n\n# `events/ring_buffer.c` 技术文档\n\n## 1. 文件概述\n\n`events/ring_buffer.c` 是 Linux 内核性能事件（perf events）子系统中用于实现高性能、无锁环形缓冲区（ring buffer）的核心文件。该文件提供了在内核态向用户态高效传递性能采样数据的机制，支持前向（forward）和后向（backward）两种写入模式，并确保在中断（IRQ）和不可屏蔽中断（NMI）上下文中安全使用。其设计重点在于高并发场景下的数据一致性、内存屏障语义以及与用户空间 mmap 映射的协同工作。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `perf_output_wakeup(struct perf_output_handle *handle)`  \n  触发事件唤醒机制，设置 poll 状态并调度 IRQ work 以通知用户空间有新数据可读。\n\n- `perf_output_get_handle(struct perf_output_handle *handle)`  \n  获取输出句柄，增加嵌套计数（`nest`），用于支持嵌套写入（如 NMI 中再次写入）。\n\n- `perf_output_put_handle(struct perf_output_handle *handle)`  \n  释放输出句柄，仅在最外层嵌套结束时更新用户页中的 `data_head`，并根据需要触发唤醒。\n\n- `__perf_output_begin(..., bool backward)`  \n  通用的输出开始函数，尝试为指定大小的数据在环形缓冲区中预留空间，支持前向/后向写入模式。\n\n- `perf_output_begin_forward(...)` / `perf_output_begin_backward(...)` / `perf_output_begin(...)`  \n  封装函数，分别用于前向写入、后向写入和根据事件属性自动选择方向的写入初始化。\n\n- `perf_output_copy(...)` / `perf_output_skip(...)`  \n  分别用于将数据拷贝到缓冲区或跳过指定字节数（预留空间）。\n\n- `perf_output_end(...)`  \n  结束一次输出操作，调用 `perf_output_put_handle` 并释放 RCU 锁。\n\n- `ring_buffer_init(...)`（未完整展示）  \n  初始化 `perf_buffer` 结构体，设置水位线等参数。\n\n### 关键数据结构（隐含）\n\n- `struct perf_buffer`：环形缓冲区的内核表示，包含 `head`、`tail`、`nest`、`lost`、`user_page` 等字段。\n- `struct perf_output_handle`：一次输出操作的上下文句柄，包含缓冲区页、地址、大小等信息。\n- `struct perf_event`：性能事件对象，关联其输出缓冲区。\n\n## 3. 关键实现\n\n### 嵌套写入与 NMI 安全性\n- 使用 `rb->nest` 计数器跟踪嵌套层数（如普通上下文写入过程中被 NMI 中断并再次写入）。\n- 仅当 `nest == 1`（最外层）退出时才更新用户可见的 `data_head`，防止中间状态暴露给用户空间。\n- 通过 `barrier()` 和 `volatile` 访问确保嵌套计数与 head 更新的顺序性。\n\n### 内存屏障与用户空间同步\n- 采用经典的 **生产者-消费者内存模型**：\n  - 内核（生产者）：先写数据，`smp_wmb()`，再更新 `data_head`。\n  - 用户空间（消费者）：先读 `data_head`，`smp_rmb()`，再读数据，最后写 `data_tail`。\n- 代码注释中明确标出屏障配对关系（A-D），确保跨 CPU 的数据一致性。\n\n### 环形缓冲区空间管理\n- 使用 `CIRC_SPACE` 宏计算可用空间，区分前向（`head >= tail`）和后向（`tail >= head`）模式。\n- 非覆盖模式（`!overwrite`）下，若空间不足则返回 `-ENOSPC` 并增加 `lost` 计数。\n- 使用 `local_try_cmpxchg` 原子地推进 `rb->head`，避免锁竞争。\n\n### 丢失事件处理\n- 若检测到 `rb->lost > 0`，自动在用户数据前插入 `PERF_RECORD_LOST` 记录，报告丢失样本数。\n- 通过 `perf_event_header__init_id` 和 `perf_event__output_id_sample` 确保 ID 信息正确。\n\n### 水位线与唤醒机制\n- 当 `head - wakeup > watermark` 时，推进 `wakeup` 指针并触发 `perf_output_wakeup`。\n- 唤醒通过设置 `poll` 事件位和调度 `irq_work` 实现，避免在原子上下文中直接唤醒。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/perf_event.h>`：perf 事件核心定义。\n  - `<linux/circ_buf.h>`：提供 `CIRC_SPACE` 等环形缓冲区宏。\n  - `<linux/nospec.h>`：防范推测执行漏洞。\n  - `\"internal.h\"`：perf 子系统内部头文件，包含 `__output_copy` 等辅助函数。\n- **内核子系统**：\n  - RCU（Read-Copy-Update）：用于安全访问 `event->rb`。\n  - IRQ Work：用于延迟执行唤醒操作。\n  - Slab/Vmalloc：用于分配缓冲区内存（虽未在片段中体现，但 `perf_buffer` 初始化时使用）。\n- **用户空间接口**：通过 `mmap()` 映射 `user_page` 和数据页，依赖约定的内存屏障语义。\n\n## 5. 使用场景\n\n- **性能监控工具**：如 `perf record`、`perf stat` 等通过此机制接收内核采样数据。\n- **动态追踪**：eBPF 程序或 kprobe 事件通过 perf ring buffer 向用户空间传递追踪信息。\n- **硬件性能计数器溢出处理**：当 PMU 计数器溢出时，中断处理程序使用此接口记录样本。\n- **NMI 上下文采样**：支持在不可屏蔽中断中安全写入（如 NMI watchdog 触发的栈回溯）。\n- **前向/后向缓冲区**：前向用于常规流式输出；后向用于“最后 N 个事件”场景（如崩溃前状态捕获）。",
      "similarity": 0.5345695614814758,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 20,
          "end_line": 125,
          "content": [
            "static void perf_output_wakeup(struct perf_output_handle *handle)",
            "{",
            "\tatomic_set(&handle->rb->poll, EPOLLIN | EPOLLRDNORM);",
            "",
            "\thandle->event->pending_wakeup = 1;",
            "\tirq_work_queue(&handle->event->pending_irq);",
            "}",
            "static void perf_output_get_handle(struct perf_output_handle *handle)",
            "{",
            "\tstruct perf_buffer *rb = handle->rb;",
            "",
            "\tpreempt_disable();",
            "",
            "\t/*",
            "\t * Avoid an explicit LOAD/STORE such that architectures with memops",
            "\t * can use them.",
            "\t */",
            "\t(*(volatile unsigned int *)&rb->nest)++;",
            "\thandle->wakeup = local_read(&rb->wakeup);",
            "}",
            "static void perf_output_put_handle(struct perf_output_handle *handle)",
            "{",
            "\tstruct perf_buffer *rb = handle->rb;",
            "\tunsigned long head;",
            "\tunsigned int nest;",
            "",
            "\t/*",
            "\t * If this isn't the outermost nesting, we don't have to update",
            "\t * @rb->user_page->data_head.",
            "\t */",
            "\tnest = READ_ONCE(rb->nest);",
            "\tif (nest > 1) {",
            "\t\tWRITE_ONCE(rb->nest, nest - 1);",
            "\t\tgoto out;",
            "\t}",
            "",
            "again:",
            "\t/*",
            "\t * In order to avoid publishing a head value that goes backwards,",
            "\t * we must ensure the load of @rb->head happens after we've",
            "\t * incremented @rb->nest.",
            "\t *",
            "\t * Otherwise we can observe a @rb->head value before one published",
            "\t * by an IRQ/NMI happening between the load and the increment.",
            "\t */",
            "\tbarrier();",
            "\thead = local_read(&rb->head);",
            "",
            "\t/*",
            "\t * IRQ/NMI can happen here and advance @rb->head, causing our",
            "\t * load above to be stale.",
            "\t */",
            "",
            "\t/*",
            "\t * Since the mmap() consumer (userspace) can run on a different CPU:",
            "\t *",
            "\t *   kernel\t\t\t\tuser",
            "\t *",
            "\t *   if (LOAD ->data_tail) {\t\tLOAD ->data_head",
            "\t *\t\t\t(A)\t\tsmp_rmb()\t(C)",
            "\t *\tSTORE $data\t\t\tLOAD $data",
            "\t *\tsmp_wmb()\t(B)\t\tsmp_mb()\t(D)",
            "\t *\tSTORE ->data_head\t\tSTORE ->data_tail",
            "\t *   }",
            "\t *",
            "\t * Where A pairs with D, and B pairs with C.",
            "\t *",
            "\t * In our case (A) is a control dependency that separates the load of",
            "\t * the ->data_tail and the stores of $data. In case ->data_tail",
            "\t * indicates there is no room in the buffer to store $data we do not.",
            "\t *",
            "\t * D needs to be a full barrier since it separates the data READ",
            "\t * from the tail WRITE.",
            "\t *",
            "\t * For B a WMB is sufficient since it separates two WRITEs, and for C",
            "\t * an RMB is sufficient since it separates two READs.",
            "\t *",
            "\t * See perf_output_begin().",
            "\t */",
            "\tsmp_wmb(); /* B, matches C */",
            "\tWRITE_ONCE(rb->user_page->data_head, head);",
            "",
            "\t/*",
            "\t * We must publish the head before decrementing the nest count,",
            "\t * otherwise an IRQ/NMI can publish a more recent head value and our",
            "\t * write will (temporarily) publish a stale value.",
            "\t */",
            "\tbarrier();",
            "\tWRITE_ONCE(rb->nest, 0);",
            "",
            "\t/*",
            "\t * Ensure we decrement @rb->nest before we validate the @rb->head.",
            "\t * Otherwise we cannot be sure we caught the 'last' nested update.",
            "\t */",
            "\tbarrier();",
            "\tif (unlikely(head != local_read(&rb->head))) {",
            "\t\tWRITE_ONCE(rb->nest, 1);",
            "\t\tgoto again;",
            "\t}",
            "",
            "\tif (handle->wakeup != local_read(&rb->wakeup))",
            "\t\tperf_output_wakeup(handle);",
            "",
            "out:",
            "\tpreempt_enable();",
            "}"
          ],
          "function_name": "perf_output_wakeup, perf_output_get_handle, perf_output_put_handle",
          "description": "实现环形缓冲区的唤醒机制和嵌套计数管理，通过原子操作和内存屏障保证多线程下的数据一致性，维护缓冲区状态转换过程中的竞态防护。",
          "similarity": 0.5838512182235718
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 1,
          "end_line": 19,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Performance events ring-buffer code:",
            " *",
            " *  Copyright (C) 2008 Thomas Gleixner <tglx@linutronix.de>",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Ingo Molnar",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Peter Zijlstra",
            " *  Copyright  ©  2009 Paul Mackerras, IBM Corp. <paulus@au1.ibm.com>",
            " */",
            "",
            "#include <linux/perf_event.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/circ_buf.h>",
            "#include <linux/poll.h>",
            "#include <linux/nospec.h>",
            "",
            "#include \"internal.h\"",
            ""
          ],
          "function_name": null,
          "description": "该代码块为性能事件环形缓冲区的头文件，包含许可证声明和核心依赖头文件，定义了环形缓冲区模块的基础结构和接口。",
          "similarity": 0.5228610038757324
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 269,
          "end_line": 408,
          "content": [
            "int perf_output_begin_forward(struct perf_output_handle *handle,",
            "\t\t\t      struct perf_sample_data *data,",
            "\t\t\t      struct perf_event *event, unsigned int size)",
            "{",
            "\treturn __perf_output_begin(handle, data, event, size, false);",
            "}",
            "int perf_output_begin_backward(struct perf_output_handle *handle,",
            "\t\t\t       struct perf_sample_data *data,",
            "\t\t\t       struct perf_event *event, unsigned int size)",
            "{",
            "\treturn __perf_output_begin(handle, data, event, size, true);",
            "}",
            "int perf_output_begin(struct perf_output_handle *handle,",
            "\t\t      struct perf_sample_data *data,",
            "\t\t      struct perf_event *event, unsigned int size)",
            "{",
            "",
            "\treturn __perf_output_begin(handle, data, event, size,",
            "\t\t\t\t   unlikely(is_write_backward(event)));",
            "}",
            "unsigned int perf_output_copy(struct perf_output_handle *handle,",
            "\t\t      const void *buf, unsigned int len)",
            "{",
            "\treturn __output_copy(handle, buf, len);",
            "}",
            "unsigned int perf_output_skip(struct perf_output_handle *handle,",
            "\t\t\t      unsigned int len)",
            "{",
            "\treturn __output_skip(handle, NULL, len);",
            "}",
            "void perf_output_end(struct perf_output_handle *handle)",
            "{",
            "\tperf_output_put_handle(handle);",
            "\trcu_read_unlock();",
            "}",
            "static void",
            "ring_buffer_init(struct perf_buffer *rb, long watermark, int flags)",
            "{",
            "\tlong max_size = perf_data_size(rb);",
            "",
            "\tif (watermark)",
            "\t\trb->watermark = min(max_size, watermark);",
            "",
            "\tif (!rb->watermark)",
            "\t\trb->watermark = max_size / 2;",
            "",
            "\tif (flags & RING_BUFFER_WRITABLE)",
            "\t\trb->overwrite = 0;",
            "\telse",
            "\t\trb->overwrite = 1;",
            "",
            "\trefcount_set(&rb->refcount, 1);",
            "",
            "\tINIT_LIST_HEAD(&rb->event_list);",
            "\tspin_lock_init(&rb->event_lock);",
            "",
            "\t/*",
            "\t * perf_output_begin() only checks rb->paused, therefore",
            "\t * rb->paused must be true if we have no pages for output.",
            "\t */",
            "\tif (!rb->nr_pages)",
            "\t\trb->paused = 1;",
            "",
            "\tmutex_init(&rb->aux_mutex);",
            "}",
            "void perf_aux_output_flag(struct perf_output_handle *handle, u64 flags)",
            "{",
            "\t/*",
            "\t * OVERWRITE is determined by perf_aux_output_end() and can't",
            "\t * be passed in directly.",
            "\t */",
            "\tif (WARN_ON_ONCE(flags & PERF_AUX_FLAG_OVERWRITE))",
            "\t\treturn;",
            "",
            "\thandle->aux_flags |= flags;",
            "}",
            "static __always_inline bool rb_need_aux_wakeup(struct perf_buffer *rb)",
            "{",
            "\tif (rb->aux_overwrite)",
            "\t\treturn false;",
            "",
            "\tif (rb->aux_head - rb->aux_wakeup >= rb->aux_watermark) {",
            "\t\trb->aux_wakeup = rounddown(rb->aux_head, rb->aux_watermark);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "void perf_aux_output_end(struct perf_output_handle *handle, unsigned long size)",
            "{",
            "\tbool wakeup = !!(handle->aux_flags & PERF_AUX_FLAG_TRUNCATED);",
            "\tstruct perf_buffer *rb = handle->rb;",
            "\tunsigned long aux_head;",
            "",
            "\t/* in overwrite mode, driver provides aux_head via handle */",
            "\tif (rb->aux_overwrite) {",
            "\t\thandle->aux_flags |= PERF_AUX_FLAG_OVERWRITE;",
            "",
            "\t\taux_head = handle->head;",
            "\t\trb->aux_head = aux_head;",
            "\t} else {",
            "\t\thandle->aux_flags &= ~PERF_AUX_FLAG_OVERWRITE;",
            "",
            "\t\taux_head = rb->aux_head;",
            "\t\trb->aux_head += size;",
            "\t}",
            "",
            "\t/*",
            "\t * Only send RECORD_AUX if we have something useful to communicate",
            "\t *",
            "\t * Note: the OVERWRITE records by themselves are not considered",
            "\t * useful, as they don't communicate any *new* information,",
            "\t * aside from the short-lived offset, that becomes history at",
            "\t * the next event sched-in and therefore isn't useful.",
            "\t * The userspace that needs to copy out AUX data in overwrite",
            "\t * mode should know to use user_page::aux_head for the actual",
            "\t * offset. So, from now on we don't output AUX records that",
            "\t * have *only* OVERWRITE flag set.",
            "\t */",
            "\tif (size || (handle->aux_flags & ~(u64)PERF_AUX_FLAG_OVERWRITE))",
            "\t\tperf_event_aux_event(handle->event, aux_head, size,",
            "\t\t\t\t     handle->aux_flags);",
            "",
            "\tWRITE_ONCE(rb->user_page->aux_head, rb->aux_head);",
            "\tif (rb_need_aux_wakeup(rb))",
            "\t\twakeup = true;",
            "",
            "\tif (wakeup) {",
            "\t\tif (handle->aux_flags & PERF_AUX_FLAG_TRUNCATED)",
            "\t\t\tperf_event_disable_inatomic(handle->event);",
            "\t\tperf_output_wakeup(handle);",
            "\t}",
            "",
            "\thandle->event = NULL;",
            "",
            "\tWRITE_ONCE(rb->aux_nest, 0);",
            "\t/* can't be last */",
            "\trb_free_aux(rb);",
            "\tring_buffer_put(rb);",
            "}"
          ],
          "function_name": "perf_output_begin_forward, perf_output_begin_backward, perf_output_begin, perf_output_copy, perf_output_skip, perf_output_end, ring_buffer_init, perf_aux_output_flag, rb_need_aux_wakeup, perf_aux_output_end",
          "description": "封装数据写入接口并实现缓冲区初始化逻辑，管理覆盖模式切换、水位线监控及辅助输出标志位，支持双向写入模式选择和资源引用计数控制。",
          "similarity": 0.5153067111968994
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 137,
          "end_line": 266,
          "content": [
            "static __always_inline bool",
            "ring_buffer_has_space(unsigned long head, unsigned long tail,",
            "\t\t      unsigned long data_size, unsigned int size,",
            "\t\t      bool backward)",
            "{",
            "\tif (!backward)",
            "\t\treturn CIRC_SPACE(head, tail, data_size) >= size;",
            "\telse",
            "\t\treturn CIRC_SPACE(tail, head, data_size) >= size;",
            "}",
            "static __always_inline int",
            "__perf_output_begin(struct perf_output_handle *handle,",
            "\t\t    struct perf_sample_data *data,",
            "\t\t    struct perf_event *event, unsigned int size,",
            "\t\t    bool backward)",
            "{",
            "\tstruct perf_buffer *rb;",
            "\tunsigned long tail, offset, head;",
            "\tint have_lost, page_shift;",
            "\tstruct {",
            "\t\tstruct perf_event_header header;",
            "\t\tu64\t\t\t id;",
            "\t\tu64\t\t\t lost;",
            "\t} lost_event;",
            "",
            "\trcu_read_lock();",
            "\t/*",
            "\t * For inherited events we send all the output towards the parent.",
            "\t */",
            "\tif (event->parent)",
            "\t\tevent = event->parent;",
            "",
            "\trb = rcu_dereference(event->rb);",
            "\tif (unlikely(!rb))",
            "\t\tgoto out;",
            "",
            "\tif (unlikely(rb->paused)) {",
            "\t\tif (rb->nr_pages) {",
            "\t\t\tlocal_inc(&rb->lost);",
            "\t\t\tatomic64_inc(&event->lost_samples);",
            "\t\t}",
            "\t\tgoto out;",
            "\t}",
            "",
            "\thandle->rb    = rb;",
            "\thandle->event = event;",
            "\thandle->flags = 0;",
            "",
            "\thave_lost = local_read(&rb->lost);",
            "\tif (unlikely(have_lost)) {",
            "\t\tsize += sizeof(lost_event);",
            "\t\tif (event->attr.sample_id_all)",
            "\t\t\tsize += event->id_header_size;",
            "\t}",
            "",
            "\tperf_output_get_handle(handle);",
            "",
            "\toffset = local_read(&rb->head);",
            "\tdo {",
            "\t\thead = offset;",
            "\t\ttail = READ_ONCE(rb->user_page->data_tail);",
            "\t\tif (!rb->overwrite) {",
            "\t\t\tif (unlikely(!ring_buffer_has_space(head, tail,",
            "\t\t\t\t\t\t\t    perf_data_size(rb),",
            "\t\t\t\t\t\t\t    size, backward)))",
            "\t\t\t\tgoto fail;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * The above forms a control dependency barrier separating the",
            "\t\t * @tail load above from the data stores below. Since the @tail",
            "\t\t * load is required to compute the branch to fail below.",
            "\t\t *",
            "\t\t * A, matches D; the full memory barrier userspace SHOULD issue",
            "\t\t * after reading the data and before storing the new tail",
            "\t\t * position.",
            "\t\t *",
            "\t\t * See perf_output_put_handle().",
            "\t\t */",
            "",
            "\t\tif (!backward)",
            "\t\t\thead += size;",
            "\t\telse",
            "\t\t\thead -= size;",
            "\t} while (!local_try_cmpxchg(&rb->head, &offset, head));",
            "",
            "\tif (backward) {",
            "\t\toffset = head;",
            "\t\thead = (u64)(-head);",
            "\t}",
            "",
            "\t/*",
            "\t * We rely on the implied barrier() by local_cmpxchg() to ensure",
            "\t * none of the data stores below can be lifted up by the compiler.",
            "\t */",
            "",
            "\tif (unlikely(head - local_read(&rb->wakeup) > rb->watermark))",
            "\t\tlocal_add(rb->watermark, &rb->wakeup);",
            "",
            "\tpage_shift = PAGE_SHIFT + page_order(rb);",
            "",
            "\thandle->page = (offset >> page_shift) & (rb->nr_pages - 1);",
            "\toffset &= (1UL << page_shift) - 1;",
            "\thandle->addr = rb->data_pages[handle->page] + offset;",
            "\thandle->size = (1UL << page_shift) - offset;",
            "",
            "\tif (unlikely(have_lost)) {",
            "\t\tlost_event.header.size = sizeof(lost_event);",
            "\t\tlost_event.header.type = PERF_RECORD_LOST;",
            "\t\tlost_event.header.misc = 0;",
            "\t\tlost_event.id          = event->id;",
            "\t\tlost_event.lost        = local_xchg(&rb->lost, 0);",
            "",
            "\t\t/* XXX mostly redundant; @data is already fully initializes */",
            "\t\tperf_event_header__init_id(&lost_event.header, data, event);",
            "\t\tperf_output_put(handle, lost_event);",
            "\t\tperf_event__output_id_sample(event, handle, data);",
            "\t}",
            "",
            "\treturn 0;",
            "",
            "fail:",
            "\tlocal_inc(&rb->lost);",
            "\tatomic64_inc(&event->lost_samples);",
            "\tperf_output_put_handle(handle);",
            "out:",
            "\trcu_read_unlock();",
            "",
            "\treturn -ENOSPC;",
            "}"
          ],
          "function_name": "ring_buffer_has_space, __perf_output_begin",
          "description": "提供空间检测算法和数据写入入口点，通过循环缓冲区计算公式判断可用容量，在成功获取写入位置后进行实际数据填充并更新缓冲区状态。",
          "similarity": 0.481118768453598
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 542,
          "end_line": 727,
          "content": [
            "int perf_aux_output_skip(struct perf_output_handle *handle, unsigned long size)",
            "{",
            "\tstruct perf_buffer *rb = handle->rb;",
            "",
            "\tif (size > handle->size)",
            "\t\treturn -ENOSPC;",
            "",
            "\trb->aux_head += size;",
            "",
            "\tWRITE_ONCE(rb->user_page->aux_head, rb->aux_head);",
            "\tif (rb_need_aux_wakeup(rb)) {",
            "\t\tperf_output_wakeup(handle);",
            "\t\thandle->wakeup = rb->aux_wakeup + rb->aux_watermark;",
            "\t}",
            "",
            "\thandle->head = rb->aux_head;",
            "\thandle->size -= size;",
            "",
            "\treturn 0;",
            "}",
            "long perf_output_copy_aux(struct perf_output_handle *aux_handle,",
            "\t\t\t  struct perf_output_handle *handle,",
            "\t\t\t  unsigned long from, unsigned long to)",
            "{",
            "\tstruct perf_buffer *rb = aux_handle->rb;",
            "\tunsigned long tocopy, remainder, len = 0;",
            "\tvoid *addr;",
            "",
            "\tfrom &= (rb->aux_nr_pages << PAGE_SHIFT) - 1;",
            "\tto &= (rb->aux_nr_pages << PAGE_SHIFT) - 1;",
            "",
            "\tdo {",
            "\t\ttocopy = PAGE_SIZE - offset_in_page(from);",
            "\t\tif (to > from)",
            "\t\t\ttocopy = min(tocopy, to - from);",
            "\t\tif (!tocopy)",
            "\t\t\tbreak;",
            "",
            "\t\taddr = rb->aux_pages[from >> PAGE_SHIFT];",
            "\t\taddr += offset_in_page(from);",
            "",
            "\t\tremainder = perf_output_copy(handle, addr, tocopy);",
            "\t\tif (remainder)",
            "\t\t\treturn -EFAULT;",
            "",
            "\t\tlen += tocopy;",
            "\t\tfrom += tocopy;",
            "\t\tfrom &= (rb->aux_nr_pages << PAGE_SHIFT) - 1;",
            "\t} while (to != from);",
            "",
            "\treturn len;",
            "}",
            "static void rb_free_aux_page(struct perf_buffer *rb, int idx)",
            "{",
            "\tstruct page *page = virt_to_page(rb->aux_pages[idx]);",
            "",
            "\tClearPagePrivate(page);",
            "\tpage->mapping = NULL;",
            "\t__free_page(page);",
            "}",
            "static void __rb_free_aux(struct perf_buffer *rb)",
            "{",
            "\tint pg;",
            "",
            "\t/*",
            "\t * Should never happen, the last reference should be dropped from",
            "\t * perf_mmap_close() path, which first stops aux transactions (which",
            "\t * in turn are the atomic holders of aux_refcount) and then does the",
            "\t * last rb_free_aux().",
            "\t */",
            "\tWARN_ON_ONCE(in_atomic());",
            "",
            "\tif (rb->aux_priv) {",
            "\t\trb->free_aux(rb->aux_priv);",
            "\t\trb->free_aux = NULL;",
            "\t\trb->aux_priv = NULL;",
            "\t}",
            "",
            "\tif (rb->aux_nr_pages) {",
            "\t\tfor (pg = 0; pg < rb->aux_nr_pages; pg++)",
            "\t\t\trb_free_aux_page(rb, pg);",
            "",
            "\t\tkfree(rb->aux_pages);",
            "\t\trb->aux_nr_pages = 0;",
            "\t}",
            "}",
            "int rb_alloc_aux(struct perf_buffer *rb, struct perf_event *event,",
            "\t\t pgoff_t pgoff, int nr_pages, long watermark, int flags)",
            "{",
            "\tbool overwrite = !(flags & RING_BUFFER_WRITABLE);",
            "\tint node = (event->cpu == -1) ? -1 : cpu_to_node(event->cpu);",
            "\tint ret = -ENOMEM, max_order;",
            "",
            "\tif (!has_aux(event))",
            "\t\treturn -EOPNOTSUPP;",
            "",
            "\tif (!overwrite) {",
            "\t\t/*",
            "\t\t * Watermark defaults to half the buffer, and so does the",
            "\t\t * max_order, to aid PMU drivers in double buffering.",
            "\t\t */",
            "\t\tif (!watermark)",
            "\t\t\twatermark = min_t(unsigned long,",
            "\t\t\t\t\t  U32_MAX,",
            "\t\t\t\t\t  (unsigned long)nr_pages << (PAGE_SHIFT - 1));",
            "",
            "\t\t/*",
            "\t\t * Use aux_watermark as the basis for chunking to",
            "\t\t * help PMU drivers honor the watermark.",
            "\t\t */",
            "\t\tmax_order = get_order(watermark);",
            "\t} else {",
            "\t\t/*",
            "\t\t * We need to start with the max_order that fits in nr_pages,",
            "\t\t * not the other way around, hence ilog2() and not get_order.",
            "\t\t */",
            "\t\tmax_order = ilog2(nr_pages);",
            "\t\twatermark = 0;",
            "\t}",
            "",
            "\t/*",
            "\t * kcalloc_node() is unable to allocate buffer if the size is larger",
            "\t * than: PAGE_SIZE << MAX_PAGE_ORDER; directly bail out in this case.",
            "\t */",
            "\tif (get_order((unsigned long)nr_pages * sizeof(void *)) > MAX_PAGE_ORDER)",
            "\t\treturn -ENOMEM;",
            "\trb->aux_pages = kcalloc_node(nr_pages, sizeof(void *), GFP_KERNEL,",
            "\t\t\t\t     node);",
            "\tif (!rb->aux_pages)",
            "\t\treturn -ENOMEM;",
            "",
            "\trb->free_aux = event->pmu->free_aux;",
            "\tfor (rb->aux_nr_pages = 0; rb->aux_nr_pages < nr_pages;) {",
            "\t\tstruct page *page;",
            "\t\tint last, order;",
            "",
            "\t\torder = min(max_order, ilog2(nr_pages - rb->aux_nr_pages));",
            "\t\tpage = rb_alloc_aux_page(node, order);",
            "\t\tif (!page)",
            "\t\t\tgoto out;",
            "",
            "\t\tfor (last = rb->aux_nr_pages + (1 << page_private(page));",
            "\t\t     last > rb->aux_nr_pages; rb->aux_nr_pages++)",
            "\t\t\trb->aux_pages[rb->aux_nr_pages] = page_address(page++);",
            "\t}",
            "",
            "\t/*",
            "\t * In overwrite mode, PMUs that don't support SG may not handle more",
            "\t * than one contiguous allocation, since they rely on PMI to do double",
            "\t * buffering. In this case, the entire buffer has to be one contiguous",
            "\t * chunk.",
            "\t */",
            "\tif ((event->pmu->capabilities & PERF_PMU_CAP_AUX_NO_SG) &&",
            "\t    overwrite) {",
            "\t\tstruct page *page = virt_to_page(rb->aux_pages[0]);",
            "",
            "\t\tif (page_private(page) != max_order)",
            "\t\t\tgoto out;",
            "\t}",
            "",
            "\trb->aux_priv = event->pmu->setup_aux(event, rb->aux_pages, nr_pages,",
            "\t\t\t\t\t     overwrite);",
            "\tif (!rb->aux_priv)",
            "\t\tgoto out;",
            "",
            "\tret = 0;",
            "",
            "\t/*",
            "\t * aux_pages (and pmu driver's private data, aux_priv) will be",
            "\t * referenced in both producer's and consumer's contexts, thus",
            "\t * we keep a refcount here to make sure either of the two can",
            "\t * reference them safely.",
            "\t */",
            "\trefcount_set(&rb->aux_refcount, 1);",
            "",
            "\trb->aux_overwrite = overwrite;",
            "\trb->aux_watermark = watermark;",
            "",
            "out:",
            "\tif (!ret)",
            "\t\trb->aux_pgoff = pgoff;",
            "\telse",
            "\t\t__rb_free_aux(rb);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "perf_aux_output_skip, perf_output_copy_aux, rb_free_aux_page, __rb_free_aux, rb_alloc_aux",
          "description": "实现辅助数据通道的管理函数，包含数据跳过、页框回收及辅助内存分配逻辑，处理非覆盖模式下的数据迁移和资源释放操作。",
          "similarity": 0.46153244376182556
        }
      ]
    },
    {
      "source_file": "kernel/printk/nbcon.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:32:39\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `printk\\nbcon.c`\n\n---\n\n# printk/nbcon.c 技术文档\n\n## 文件概述\n\n`printk/nbcon.c` 实现了新一代的 printk 控制台（nbcon，即 \"new console\"）打印机制，该机制不依赖传统的 `console_lock` 互斥锁，而是采用基于原子操作的状态机模型来管理控制台访问。其核心目标是支持高优先级上下文（如中断、NMI、panic）安全、高效地抢占低优先级上下文对控制台的使用权，同时避免死锁和优先级反转问题。该机制特别适用于实时系统和 panic 场景下的可靠日志输出。\n\n## 核心功能\n\n### 主要数据结构\n- **`struct nbcon_state`**：封装控制台状态的原子变量，包含以下关键字段：\n  - `prio`：当前持有控制台的上下文优先级（0 表示未锁定）\n  - `cpu`：当前持有控制台的 CPU 编号\n  - `req_prio`：请求友好移交的更高优先级上下文的优先级\n  - `unsafe`：标志当前是否处于不安全状态（如正在操作共享资源）\n  - `unsafe_takeover`：标志是否发生过不安全的强制接管\n\n### 主要函数\n- **`nbcon_state_set()`**：初始化或重置控制台状态（仅限未注册或初始化阶段使用）\n- **`nbcon_state_read()`**：原子读取当前控制台状态\n- **`nbcon_state_try_cmpxchg()`**：原子比较并交换控制台状态\n- **`nbcon_seq_read()`**：读取控制台当前应打印的 printk 记录序列号\n- **`nbcon_seq_force()`**：强制设置控制台序列号（用于初始化或 panic 场景）\n- **`nbcon_seq_try_update()`**：尝试原子更新控制台序列号\n- **`nbcon_context_try_acquire_direct()`**：尝试直接获取控制台所有权（核心获取逻辑之一）\n\n## 关键实现\n\n### 控制台状态管理机制\n控制台状态通过 `nbcon_state` 原子变量管理，支持三种获取策略：\n1. **直接获取**：当控制台未被占用，或当前持有者优先级更低且处于安全状态时，直接抢占。\n2. **友好移交**：当持有者优先级更低但处于不安全状态时，请求者设置 `req_prio`，持有者在退出不安全状态后主动释放。\n3. **强制接管**：仅在 `panic()` 的最后尝试中使用，无视不安全状态强制接管（标记 `unsafe_takeover`）。\n\n### 安全状态标记\n- **`unsafe` 字段**：在操作共享资源或控制台设备时置位，操作完成后清除。确保高优先级上下文不会在设备不一致状态下接管。\n- **`unsafe_takeover` 字段**：记录强制接管事件，后续需重新初始化控制台状态。\n\n### 序列号管理\n- 使用 64 位序列号跟踪下一条待打印的 printk 记录。\n- 在 32 位系统上，仅存储低 32 位，高 32 位通过 ringbuffer 中的有效序列号推导。\n- `nbcon_seq_force()` 确保设置的序列号不低于 ringbuffer 中最早的有效记录。\n\n### 优先级与 CPU 绑定\n- 优先级数值越大表示优先级越高（`NBCON_PRIO_NONE = 0` 表示无持有者）。\n- `cpu` 字段防止同 CPU 上的忙等待，并处理复杂场景下优先级相同但 CPU 切换的情况。\n\n## 依赖关系\n\n- **内部依赖**：\n  - `printk_ringbuffer.h`：提供 printk 环形缓冲区操作接口（如 `prb_first_valid_seq()`）\n  - `internal.h`：包含 nbcon 内部定义的辅助宏和类型（如 `ACCESS_PRIVATE`、`__ulseq_to_u64seq`）\n- **内核核心模块**：\n  - `linux/atomic.h`：提供原子操作支持\n  - `linux/console.h`：定义 `struct console` 及相关常量\n  - `linux/irqflags.h`：用于中断上下文判断\n  - `linux/smp.h`：SMP 相关支持（如 `smp_processor_id()`）\n- **关键子系统**：\n  - **Printk 子系统**：作为 printk 输出后端，与 ringbuffer 紧密集成\n  - **调度器/中断子系统**：依赖上下文优先级模型（如 NMI > IRQ > 进程）\n\n## 使用场景\n\n1. **常规 printk 输出**：\n   - 高优先级中断/NMI 日志可安全抢占低优先级进程的控制台输出。\n   - 每条 printk 记录独立输出，被抢占时由新持有者重试整条记录。\n\n2. **Panic 处理**：\n   - 在 `panic()` 流程中，通过强制接管机制确保最后的日志能输出。\n   - 使用独立的 panic 记录缓冲区，避免因不安全状态导致数据损坏。\n\n3. **实时系统**：\n   - 避免传统 `console_lock` 导致的优先级反转问题。\n   - 保证高优先级任务/中断的日志能及时输出。\n\n4. **控制台驱动实现**：\n   - 控制台驱动需在关键操作（如设备寄存器访问）前后标记 `unsafe` 状态。\n   - 驱动需在每次输出字符后检查移交请求（`req_prio`），及时释放控制台。",
      "similarity": 0.5283252596855164,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/printk/nbcon.c",
          "start_line": 651,
          "end_line": 757,
          "content": [
            "static void nbcon_context_release(struct nbcon_context *ctxt)",
            "{",
            "\tunsigned int cpu = smp_processor_id();",
            "\tstruct console *con = ctxt->console;",
            "\tstruct nbcon_state cur;",
            "\tstruct nbcon_state new;",
            "",
            "\tnbcon_state_read(con, &cur);",
            "",
            "\tdo {",
            "\t\tif (!nbcon_owner_matches(&cur, cpu, ctxt->prio))",
            "\t\t\tbreak;",
            "",
            "\t\tnew.atom = cur.atom;",
            "\t\tnew.prio = NBCON_PRIO_NONE;",
            "",
            "\t\t/*",
            "\t\t * If @unsafe_takeover is set, it is kept set so that",
            "\t\t * the state remains permanently unsafe.",
            "\t\t */",
            "\t\tnew.unsafe |= cur.unsafe_takeover;",
            "",
            "\t} while (!nbcon_state_try_cmpxchg(con, &cur, &new));",
            "",
            "\tctxt->pbufs = NULL;",
            "}",
            "static bool nbcon_context_can_proceed(struct nbcon_context *ctxt, struct nbcon_state *cur)",
            "{",
            "\tunsigned int cpu = smp_processor_id();",
            "",
            "\t/* Make sure this context still owns the console. */",
            "\tif (!nbcon_owner_matches(cur, cpu, ctxt->prio))",
            "\t\treturn false;",
            "",
            "\t/* The console owner can proceed if there is no waiter. */",
            "\tif (cur->req_prio == NBCON_PRIO_NONE)",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * A console owner within an unsafe region is always allowed to",
            "\t * proceed, even if there are waiters. It can perform a handover",
            "\t * when exiting the unsafe region. Otherwise the waiter will",
            "\t * need to perform an unsafe hostile takeover.",
            "\t */",
            "\tif (cur->unsafe)",
            "\t\treturn true;",
            "",
            "\t/* Waiters always have higher priorities than owners. */",
            "\tWARN_ON_ONCE(cur->req_prio <= cur->prio);",
            "",
            "\t/*",
            "\t * Having a safe point for take over and eventually a few",
            "\t * duplicated characters or a full line is way better than a",
            "\t * hostile takeover. Post processing can take care of the garbage.",
            "\t * Release and hand over.",
            "\t */",
            "\tnbcon_context_release(ctxt);",
            "",
            "\t/*",
            "\t * It is not clear whether the waiter really took over ownership. The",
            "\t * outermost callsite must make the final decision whether console",
            "\t * ownership is needed for it to proceed. If yes, it must reacquire",
            "\t * ownership (possibly hostile) before carefully proceeding.",
            "\t *",
            "\t * The calling context no longer owns the console so go back all the",
            "\t * way instead of trying to implement reacquire heuristics in tons of",
            "\t * places.",
            "\t */",
            "\treturn false;",
            "}",
            "bool nbcon_can_proceed(struct nbcon_write_context *wctxt)",
            "{",
            "\tstruct nbcon_context *ctxt = &ACCESS_PRIVATE(wctxt, ctxt);",
            "\tstruct console *con = ctxt->console;",
            "\tstruct nbcon_state cur;",
            "",
            "\tnbcon_state_read(con, &cur);",
            "",
            "\treturn nbcon_context_can_proceed(ctxt, &cur);",
            "}",
            "static bool __nbcon_context_update_unsafe(struct nbcon_context *ctxt, bool unsafe)",
            "{",
            "\tstruct console *con = ctxt->console;",
            "\tstruct nbcon_state cur;",
            "\tstruct nbcon_state new;",
            "",
            "\tnbcon_state_read(con, &cur);",
            "",
            "\tdo {",
            "\t\t/*",
            "\t\t * The unsafe bit must not be cleared if an",
            "\t\t * unsafe hostile takeover has occurred.",
            "\t\t */",
            "\t\tif (!unsafe && cur.unsafe_takeover)",
            "\t\t\tgoto out;",
            "",
            "\t\tif (!nbcon_context_can_proceed(ctxt, &cur))",
            "\t\t\treturn false;",
            "",
            "\t\tnew.atom = cur.atom;",
            "\t\tnew.unsafe = unsafe;",
            "\t} while (!nbcon_state_try_cmpxchg(con, &cur, &new));",
            "",
            "\tcur.atom = new.atom;",
            "out:",
            "\treturn nbcon_context_can_proceed(ctxt, &cur);",
            "}"
          ],
          "function_name": "nbcon_context_release, nbcon_context_can_proceed, nbcon_can_proceed, __nbcon_context_update_unsafe",
          "description": "实现控制台释放与状态检查逻辑，包含安全状态维护、所有权验证和异常处理，通过循环CAS更新状态并在不安全状态下阻止进一步操作。",
          "similarity": 0.5876905918121338
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/printk/nbcon.c",
          "start_line": 128,
          "end_line": 242,
          "content": [
            "static inline void nbcon_state_set(struct console *con, struct nbcon_state *new)",
            "{",
            "\tatomic_set(&ACCESS_PRIVATE(con, nbcon_state), new->atom);",
            "}",
            "static inline void nbcon_state_read(struct console *con, struct nbcon_state *state)",
            "{",
            "\tstate->atom = atomic_read(&ACCESS_PRIVATE(con, nbcon_state));",
            "}",
            "static inline bool nbcon_state_try_cmpxchg(struct console *con, struct nbcon_state *cur,",
            "\t\t\t\t\t   struct nbcon_state *new)",
            "{",
            "\treturn atomic_try_cmpxchg(&ACCESS_PRIVATE(con, nbcon_state), &cur->atom, new->atom);",
            "}",
            "u64 nbcon_seq_read(struct console *con)",
            "{",
            "\tunsigned long nbcon_seq = atomic_long_read(&ACCESS_PRIVATE(con, nbcon_seq));",
            "",
            "\treturn __ulseq_to_u64seq(prb, nbcon_seq);",
            "}",
            "void nbcon_seq_force(struct console *con, u64 seq)",
            "{",
            "\t/*",
            "\t * If the specified record no longer exists, the oldest available record",
            "\t * is chosen. This is especially important on 32bit systems because only",
            "\t * the lower 32 bits of the sequence number are stored. The upper 32 bits",
            "\t * are derived from the sequence numbers available in the ringbuffer.",
            "\t */",
            "\tu64 valid_seq = max_t(u64, seq, prb_first_valid_seq(prb));",
            "",
            "\tatomic_long_set(&ACCESS_PRIVATE(con, nbcon_seq), __u64seq_to_ulseq(valid_seq));",
            "}",
            "static void nbcon_seq_try_update(struct nbcon_context *ctxt, u64 new_seq)",
            "{",
            "\tunsigned long nbcon_seq = __u64seq_to_ulseq(ctxt->seq);",
            "\tstruct console *con = ctxt->console;",
            "",
            "\tif (atomic_long_try_cmpxchg(&ACCESS_PRIVATE(con, nbcon_seq), &nbcon_seq,",
            "\t\t\t\t    __u64seq_to_ulseq(new_seq))) {",
            "\t\tctxt->seq = new_seq;",
            "\t} else {",
            "\t\tctxt->seq = nbcon_seq_read(con);",
            "\t}",
            "}",
            "static int nbcon_context_try_acquire_direct(struct nbcon_context *ctxt,",
            "\t\t\t\t\t    struct nbcon_state *cur)",
            "{",
            "\tunsigned int cpu = smp_processor_id();",
            "\tstruct console *con = ctxt->console;",
            "\tstruct nbcon_state new;",
            "",
            "\tdo {",
            "\t\t/*",
            "\t\t * Panic does not imply that the console is owned. However, it",
            "\t\t * is critical that non-panic CPUs during panic are unable to",
            "\t\t * acquire ownership in order to satisfy the assumptions of",
            "\t\t * nbcon_waiter_matches(). In particular, the assumption that",
            "\t\t * lower priorities are ignored during panic.",
            "\t\t */",
            "\t\tif (other_cpu_in_panic())",
            "\t\t\treturn -EPERM;",
            "",
            "\t\tif (ctxt->prio <= cur->prio || ctxt->prio <= cur->req_prio)",
            "\t\t\treturn -EPERM;",
            "",
            "\t\tif (cur->unsafe)",
            "\t\t\treturn -EBUSY;",
            "",
            "\t\t/*",
            "\t\t * The console should never be safe for a direct acquire",
            "\t\t * if an unsafe hostile takeover has ever happened.",
            "\t\t */",
            "\t\tWARN_ON_ONCE(cur->unsafe_takeover);",
            "",
            "\t\tnew.atom = cur->atom;",
            "\t\tnew.prio\t= ctxt->prio;",
            "\t\tnew.req_prio\t= NBCON_PRIO_NONE;",
            "\t\tnew.unsafe\t= cur->unsafe_takeover;",
            "\t\tnew.cpu\t\t= cpu;",
            "",
            "\t} while (!nbcon_state_try_cmpxchg(con, cur, &new));",
            "",
            "\treturn 0;",
            "}",
            "static bool nbcon_waiter_matches(struct nbcon_state *cur, int expected_prio)",
            "{",
            "\t/*",
            "\t * The request context is well defined by the @req_prio because:",
            "\t *",
            "\t * - Only a context with a priority higher than the owner can become",
            "\t *   a waiter.",
            "\t * - Only a context with a priority higher than the waiter can",
            "\t *   directly take over the request.",
            "\t * - There are only three priorities.",
            "\t * - Only one CPU is allowed to request PANIC priority.",
            "\t * - Lower priorities are ignored during panic() until reboot.",
            "\t *",
            "\t * As a result, the following scenario is *not* possible:",
            "\t *",
            "\t * 1. This context is currently a waiter.",
            "\t * 2. Another context with a higher priority than this context",
            "\t *    directly takes ownership.",
            "\t * 3. The higher priority context releases the ownership.",
            "\t * 4. Another lower priority context takes the ownership.",
            "\t * 5. Another context with the same priority as this context",
            "\t *    creates a request and starts waiting.",
            "\t *",
            "\t * Event #1 implies this context is EMERGENCY.",
            "\t * Event #2 implies the new context is PANIC.",
            "\t * Event #3 occurs when panic() has flushed the console.",
            "\t * Events #4 and #5 are not possible due to the other_cpu_in_panic()",
            "\t * check in nbcon_context_try_acquire_direct().",
            "\t */",
            "",
            "\treturn (cur->req_prio == expected_prio);",
            "}"
          ],
          "function_name": "nbcon_state_set, nbcon_state_read, nbcon_state_try_cmpxchg, nbcon_seq_read, nbcon_seq_force, nbcon_seq_try_update, nbcon_context_try_acquire_direct, nbcon_waiter_matches",
          "description": "实现直接获取控制台的逻辑，包含优先级检查、安全状态验证和状态原子更新，通过cmpxchg保证并发安全性，处理跨CPU和panic场景下的所有权转移规则。",
          "similarity": 0.5465762615203857
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/printk/nbcon.c",
          "start_line": 524,
          "end_line": 629,
          "content": [
            "static int nbcon_context_try_acquire_hostile(struct nbcon_context *ctxt,",
            "\t\t\t\t\t     struct nbcon_state *cur)",
            "{",
            "\tunsigned int cpu = smp_processor_id();",
            "\tstruct console *con = ctxt->console;",
            "\tstruct nbcon_state new;",
            "",
            "\tif (!ctxt->allow_unsafe_takeover)",
            "\t\treturn -EPERM;",
            "",
            "\t/* Ensure caller is allowed to perform unsafe hostile takeovers. */",
            "\tif (WARN_ON_ONCE(ctxt->prio != NBCON_PRIO_PANIC))",
            "\t\treturn -EPERM;",
            "",
            "\t/*",
            "\t * Check that try_acquire_direct() and try_acquire_handover() returned",
            "\t * -EBUSY in the right situation.",
            "\t */",
            "\tWARN_ON_ONCE(ctxt->prio <= cur->prio || ctxt->prio <= cur->req_prio);",
            "\tWARN_ON_ONCE(cur->unsafe != true);",
            "",
            "\tdo {",
            "\t\tnew.atom = cur->atom;",
            "\t\tnew.cpu\t\t\t= cpu;",
            "\t\tnew.prio\t\t= ctxt->prio;",
            "\t\tnew.unsafe\t\t|= cur->unsafe_takeover;",
            "\t\tnew.unsafe_takeover\t|= cur->unsafe;",
            "",
            "\t} while (!nbcon_state_try_cmpxchg(con, cur, &new));",
            "",
            "\treturn 0;",
            "}",
            "static bool nbcon_context_try_acquire(struct nbcon_context *ctxt)",
            "{",
            "\tunsigned int cpu = smp_processor_id();",
            "\tstruct console *con = ctxt->console;",
            "\tstruct nbcon_state cur;",
            "\tint err;",
            "",
            "\tnbcon_state_read(con, &cur);",
            "try_again:",
            "\terr = nbcon_context_try_acquire_direct(ctxt, &cur);",
            "\tif (err != -EBUSY)",
            "\t\tgoto out;",
            "",
            "\terr = nbcon_context_try_acquire_handover(ctxt, &cur);",
            "\tif (err == -EAGAIN)",
            "\t\tgoto try_again;",
            "\tif (err != -EBUSY)",
            "\t\tgoto out;",
            "",
            "\terr = nbcon_context_try_acquire_hostile(ctxt, &cur);",
            "out:",
            "\tif (err)",
            "\t\treturn false;",
            "",
            "\t/* Acquire succeeded. */",
            "",
            "\t/* Assign the appropriate buffer for this context. */",
            "\tif (atomic_read(&panic_cpu) == cpu)",
            "\t\tctxt->pbufs = &panic_nbcon_pbufs;",
            "\telse",
            "\t\tctxt->pbufs = con->pbufs;",
            "",
            "\t/* Set the record sequence for this context to print. */",
            "\tctxt->seq = nbcon_seq_read(ctxt->console);",
            "",
            "\treturn true;",
            "}",
            "static bool nbcon_owner_matches(struct nbcon_state *cur, int expected_cpu,",
            "\t\t\t\tint expected_prio)",
            "{",
            "\t/*",
            "\t * A similar function, nbcon_waiter_matches(), only deals with",
            "\t * EMERGENCY and PANIC priorities. However, this function must also",
            "\t * deal with the NORMAL priority, which requires additional checks",
            "\t * and constraints.",
            "\t *",
            "\t * For the case where preemption and interrupts are disabled, it is",
            "\t * enough to also verify that the owning CPU has not changed.",
            "\t *",
            "\t * For the case where preemption or interrupts are enabled, an",
            "\t * external synchronization method *must* be used. In particular,",
            "\t * the driver-specific locking mechanism used in device_lock()",
            "\t * (including disabling migration) should be used. It prevents",
            "\t * scenarios such as:",
            "\t *",
            "\t * 1. [Task A] owns a context with NBCON_PRIO_NORMAL on [CPU X] and",
            "\t *    is scheduled out.",
            "\t * 2. Another context takes over the lock with NBCON_PRIO_EMERGENCY",
            "\t *    and releases it.",
            "\t * 3. [Task B] acquires a context with NBCON_PRIO_NORMAL on [CPU X]",
            "\t *    and is scheduled out.",
            "\t * 4. [Task A] gets running on [CPU X] and sees that the console is",
            "\t *    still owned by a task on [CPU X] with NBON_PRIO_NORMAL. Thus",
            "\t *    [Task A] thinks it is the owner when it is not.",
            "\t */",
            "",
            "\tif (cur->prio != expected_prio)",
            "\t\treturn false;",
            "",
            "\tif (cur->cpu != expected_cpu)",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}"
          ],
          "function_name": "nbcon_context_try_acquire_hostile, nbcon_context_try_acquire, nbcon_owner_matches",
          "description": "处理强制接管（hostile takeover）逻辑，仅限panic优先级使用，标记控制台为永久不安全状态，提供统一的获取入口函数并关联缓冲区选择。",
          "similarity": 0.5435399413108826
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/printk/nbcon.c",
          "start_line": 1,
          "end_line": 127,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "// Copyright (C) 2022 Linutronix GmbH, John Ogness",
            "// Copyright (C) 2022 Intel, Thomas Gleixner",
            "",
            "#include <linux/atomic.h>",
            "#include <linux/bug.h>",
            "#include <linux/console.h>",
            "#include <linux/delay.h>",
            "#include <linux/errno.h>",
            "#include <linux/export.h>",
            "#include <linux/init.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kthread.h>",
            "#include <linux/minmax.h>",
            "#include <linux/percpu.h>",
            "#include <linux/preempt.h>",
            "#include <linux/slab.h>",
            "#include <linux/smp.h>",
            "#include <linux/stddef.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include \"internal.h\"",
            "#include \"printk_ringbuffer.h\"",
            "/*",
            " * Printk console printing implementation for consoles which does not depend",
            " * on the legacy style console_lock mechanism.",
            " *",
            " * The state of the console is maintained in the \"nbcon_state\" atomic",
            " * variable.",
            " *",
            " * The console is locked when:",
            " *",
            " *   - The 'prio' field contains the priority of the context that owns the",
            " *     console. Only higher priority contexts are allowed to take over the",
            " *     lock. A value of 0 (NBCON_PRIO_NONE) means the console is not locked.",
            " *",
            " *   - The 'cpu' field denotes on which CPU the console is locked. It is used",
            " *     to prevent busy waiting on the same CPU. Also it informs the lock owner",
            " *     that it has lost the lock in a more complex scenario when the lock was",
            " *     taken over by a higher priority context, released, and taken on another",
            " *     CPU with the same priority as the interrupted owner.",
            " *",
            " * The acquire mechanism uses a few more fields:",
            " *",
            " *   - The 'req_prio' field is used by the handover approach to make the",
            " *     current owner aware that there is a context with a higher priority",
            " *     waiting for the friendly handover.",
            " *",
            " *   - The 'unsafe' field allows to take over the console in a safe way in the",
            " *     middle of emitting a message. The field is set only when accessing some",
            " *     shared resources or when the console device is manipulated. It can be",
            " *     cleared, for example, after emitting one character when the console",
            " *     device is in a consistent state.",
            " *",
            " *   - The 'unsafe_takeover' field is set when a hostile takeover took the",
            " *     console in an unsafe state. The console will stay in the unsafe state",
            " *     until re-initialized.",
            " *",
            " * The acquire mechanism uses three approaches:",
            " *",
            " *   1) Direct acquire when the console is not owned or is owned by a lower",
            " *      priority context and is in a safe state.",
            " *",
            " *   2) Friendly handover mechanism uses a request/grant handshake. It is used",
            " *      when the current owner has lower priority and the console is in an",
            " *      unsafe state.",
            " *",
            " *      The requesting context:",
            " *",
            " *        a) Sets its priority into the 'req_prio' field.",
            " *",
            " *        b) Waits (with a timeout) for the owning context to unlock the",
            " *           console.",
            " *",
            " *        c) Takes the lock and clears the 'req_prio' field.",
            " *",
            " *      The owning context:",
            " *",
            " *        a) Observes the 'req_prio' field set on exit from the unsafe",
            " *           console state.",
            " *",
            " *        b) Gives up console ownership by clearing the 'prio' field.",
            " *",
            " *   3) Unsafe hostile takeover allows to take over the lock even when the",
            " *      console is an unsafe state. It is used only in panic() by the final",
            " *      attempt to flush consoles in a try and hope mode.",
            " *",
            " *      Note that separate record buffers are used in panic(). As a result,",
            " *      the messages can be read and formatted without any risk even after",
            " *      using the hostile takeover in unsafe state.",
            " *",
            " * The release function simply clears the 'prio' field.",
            " *",
            " * All operations on @console::nbcon_state are atomic cmpxchg based to",
            " * handle concurrency.",
            " *",
            " * The acquire/release functions implement only minimal policies:",
            " *",
            " *   - Preference for higher priority contexts.",
            " *   - Protection of the panic CPU.",
            " *",
            " * All other policy decisions must be made at the call sites:",
            " *",
            " *   - What is marked as an unsafe section.",
            " *   - Whether to spin-wait if there is already an owner and the console is",
            " *     in an unsafe state.",
            " *   - Whether to attempt an unsafe hostile takeover.",
            " *",
            " * The design allows to implement the well known:",
            " *",
            " *     acquire()",
            " *     output_one_printk_record()",
            " *     release()",
            " *",
            " * The output of one printk record might be interrupted with a higher priority",
            " * context. The new owner is supposed to reprint the entire interrupted record",
            " * from scratch.",
            " */",
            "",
            "/**",
            " * nbcon_state_set - Helper function to set the console state",
            " * @con:\tConsole to update",
            " * @new:\tThe new state to write",
            " *",
            " * Only to be used when the console is not yet or no longer visible in the",
            " * system. Otherwise use nbcon_state_try_cmpxchg().",
            " */"
          ],
          "function_name": null,
          "description": "定义了非阻塞控制台（nbcon）的状态管理和序列号操作函数，提供设置、读取和原子比较交换操作，用于维护控制台锁状态及记录序列号，支持多优先级抢占式控制台访问策略。",
          "similarity": 0.5327815413475037
        },
        {
          "chunk_id": 9,
          "file_path": "kernel/printk/nbcon.c",
          "start_line": 1619,
          "end_line": 1720,
          "content": [
            "void nbcon_atomic_flush_unsafe(void)",
            "{",
            "\t__nbcon_atomic_flush_pending(prb_next_reserve_seq(prb), true);",
            "}",
            "void nbcon_cpu_emergency_enter(void)",
            "{",
            "\tunsigned int *cpu_emergency_nesting;",
            "",
            "\tpreempt_disable();",
            "",
            "\tcpu_emergency_nesting = nbcon_get_cpu_emergency_nesting();",
            "\t(*cpu_emergency_nesting)++;",
            "}",
            "void nbcon_cpu_emergency_exit(void)",
            "{",
            "\tunsigned int *cpu_emergency_nesting;",
            "",
            "\tcpu_emergency_nesting = nbcon_get_cpu_emergency_nesting();",
            "",
            "\tif (!WARN_ON_ONCE(*cpu_emergency_nesting == 0))",
            "\t\t(*cpu_emergency_nesting)--;",
            "",
            "\tpreempt_enable();",
            "}",
            "bool nbcon_alloc(struct console *con)",
            "{",
            "\tstruct nbcon_state state = { };",
            "",
            "\t/* The write_thread() callback is mandatory. */",
            "\tif (WARN_ON(!con->write_thread))",
            "\t\treturn false;",
            "",
            "\trcuwait_init(&con->rcuwait);",
            "\tinit_irq_work(&con->irq_work, nbcon_irq_work);",
            "\tatomic_long_set(&ACCESS_PRIVATE(con, nbcon_prev_seq), -1UL);",
            "\tnbcon_state_set(con, &state);",
            "",
            "\t/*",
            "\t * Initialize @nbcon_seq to the highest possible sequence number so",
            "\t * that practically speaking it will have nothing to print until a",
            "\t * desired initial sequence number has been set via nbcon_seq_force().",
            "\t */",
            "\tatomic_long_set(&ACCESS_PRIVATE(con, nbcon_seq), ULSEQ_MAX(prb));",
            "",
            "\tif (con->flags & CON_BOOT) {",
            "\t\t/*",
            "\t\t * Boot console printing is synchronized with legacy console",
            "\t\t * printing, so boot consoles can share the same global printk",
            "\t\t * buffers.",
            "\t\t */",
            "\t\tcon->pbufs = &printk_shared_pbufs;",
            "\t} else {",
            "\t\tcon->pbufs = kmalloc(sizeof(*con->pbufs), GFP_KERNEL);",
            "\t\tif (!con->pbufs) {",
            "\t\t\tcon_printk(KERN_ERR, con, \"failed to allocate printing buffer\\n\");",
            "\t\t\treturn false;",
            "\t\t}",
            "",
            "\t\tif (printk_kthreads_running) {",
            "\t\t\tif (!nbcon_kthread_create(con)) {",
            "\t\t\t\tkfree(con->pbufs);",
            "\t\t\t\tcon->pbufs = NULL;",
            "\t\t\t\treturn false;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "\treturn true;",
            "}",
            "void nbcon_free(struct console *con)",
            "{",
            "\tstruct nbcon_state state = { };",
            "",
            "\tif (printk_kthreads_running)",
            "\t\tnbcon_kthread_stop(con);",
            "",
            "\tnbcon_state_set(con, &state);",
            "",
            "\t/* Boot consoles share global printk buffers. */",
            "\tif (!(con->flags & CON_BOOT))",
            "\t\tkfree(con->pbufs);",
            "",
            "\tcon->pbufs = NULL;",
            "}",
            "bool nbcon_device_try_acquire(struct console *con)",
            "{",
            "\tstruct nbcon_context *ctxt = &ACCESS_PRIVATE(con, nbcon_device_ctxt);",
            "",
            "\tcant_migrate();",
            "",
            "\tmemset(ctxt, 0, sizeof(*ctxt));",
            "\tctxt->console\t= con;",
            "\tctxt->prio\t= NBCON_PRIO_NORMAL;",
            "",
            "\tif (!nbcon_context_try_acquire(ctxt))",
            "\t\treturn false;",
            "",
            "\tif (!nbcon_context_enter_unsafe(ctxt))",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}"
          ],
          "function_name": "nbcon_atomic_flush_unsafe, nbcon_cpu_emergency_enter, nbcon_cpu_emergency_exit, nbcon_alloc, nbcon_free, nbcon_device_try_acquire",
          "description": "包含CPU紧急模式的嵌套计数器增减接口，控制台资源分配释放逻辑(nbcon_alloc/free)，以及设备抢占尝试函数nbcon_device_try_acquire，用于协调控制台设备的并发访问。",
          "similarity": 0.5184999108314514
        }
      ]
    }
  ]
}