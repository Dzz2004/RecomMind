{
  "query": "Linux内核Hypervisor模块与写回策略的交互",
  "timestamp": "2025-12-26 01:48:29",
  "retrieved_files": [
    {
      "source_file": "mm/mempolicy.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:44:01\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `mempolicy.c`\n\n---\n\n# mempolicy.c 技术文档\n\n## 1. 文件概述\n\n`mempolicy.c` 实现了 Linux 内核中的 NUMA（Non-Uniform Memory Access）内存策略机制，允许用户通过系统调用为进程或虚拟内存区域（VMA）指定内存分配偏好。该机制支持多种内存分配策略，包括本地优先、绑定节点、轮询交错和基于权重的交错分配等，以优化多节点 NUMA 系统上的内存访问性能。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct mempolicy`：表示内存策略的核心结构，包含策略模式（如 MPOL_INTERLEAVE、MPOL_BIND、MPOL_PREFERRED 等）、节点掩码（nodemask）和引用计数。\n- `struct weighted_interleave_state`：用于实现加权交错分配策略，包含每个节点的权重表（iw_table）和自动模式标志。\n- `default_policy`：全局默认内存策略，初始为 MPOL_LOCAL（本地节点优先）。\n- `preferred_node_policy[MAX_NUMNODES]`：为每个节点预定义的首选策略数组。\n\n### 主要函数与接口\n- `get_il_weight(int node)`：获取指定节点在加权交错策略中的权重。\n- `reduce_interleave_weights(unsigned int *bw, u8 *new_iw)`：将带宽值转换为归一化的交错权重。\n- `mempolicy_set_node_perf(unsigned int node, struct access_coordinate *coords)`：根据节点性能坐标（读/写带宽）动态更新加权交错策略。\n- 多个辅助函数用于策略创建、复制、合并、验证及与 VMA 和进程上下文的集成。\n\n### 全局变量\n- `policy_cache` / `sn_cache`：用于高效分配 mempolicy 和相关子结构的 slab 缓存。\n- `policy_zone`：标识受策略控制的最高内存区域类型（zone_type），低区域（如 GFP_DMA）不应用策略。\n- `wi_state`：RCU 保护的加权交错状态指针。\n- `node_bw_table`：存储各节点带宽信息，用于动态权重计算。\n- `weightiness`：权重归一化常量（值为 32），平衡权重精度与分配公平性。\n\n## 3. 关键实现\n\n### 策略优先级与作用域\n- **VMA 策略优先于进程策略**：页错误处理时，若 VMA 有策略则使用 VMA 策略，否则回退到当前进程的策略。\n- **中断上下文忽略策略**：所有中断相关的内存分配始终尝试在本地 CPU 节点分配。\n- **策略不跨 swap 保留**：进程策略在页面换出/换入时不被保留。\n\n### 加权交错分配（Weighted Interleave）\n- 基于各 NUMA 节点的读/写带宽动态计算分配权重。\n- 使用 `weightiness=32` 对带宽进行缩放，并通过 GCD（最大公约数）约简权重以减少分配周期长度。\n- 权重状态通过 RCU 机制安全更新，读路径无锁，写路径由 `wi_state_lock` 互斥锁保护。\n\n### 策略类型详解\n- **interleave**：按偏移量（VMA）或进程计数器（进程）在节点集上轮询分配。\n- **weighted interleave**：按节点权重比例分配（如权重 [2,1] 表示节点0:节点1 = 2:1）。\n- **bind**：严格限制在指定节点集分配，无回退（当前实现按节点顺序分配，非最优）。\n- **preferred / preferred many**：优先在指定单个/多个节点分配，失败后回退到默认策略。\n- **default / local**：优先本地节点分配，VMA 中则继承进程策略。\n\n### 内存区域限制\n- 仅对 **最高 zone 层级**（如 NORMAL 或 MOVABLE）应用策略，GFP_DMA、HIGHMEM 等低层级分配忽略策略。\n\n### 特殊共享内存处理\n- **shmem/tmpfs**：策略在所有映射进程间共享，即使无活跃映射也持久保存。\n\n## 4. 依赖关系\n\n- **内存管理子系统**：依赖 `<linux/mm.h>`、`<linux/vm_area_struct.h>`、`<linux/page-flags.h>` 等进行页分配、VMA 操作和页表遍历。\n- **NUMA 感知调度**：与 `<linux/sched/numa_balancing.h>` 协同，支持自动 NUMA 迁移。\n- **CPUSET 子系统**：通过 `<linux/cpuset.h>` 集成节点可用性约束。\n- **Slab 分配器**：使用 kmem_cache 管理 mempolicy 对象生命周期。\n- **RCU 机制**：用于加权交错状态的无锁读取。\n- **系统调用接口**：通过 `sys_mbind()`、`sys_set_mempolicy()` 等提供用户空间配置入口。\n- **安全模块**：调用 LSM hooks（`security_task_movememory()`）进行权限检查。\n\n## 5. 使用场景\n\n- **高性能计算（HPC）应用**：通过 `mbind()` 将关键数据结构绑定到特定 NUMA 节点，减少远程内存访问延迟。\n- **数据库系统**：使用交错策略均衡多节点内存带宽，提升吞吐量。\n- **虚拟化环境**：VMM 可为不同虚拟机设置独立内存策略，隔离资源并优化性能。\n- **自动 NUMA 优化**：内核 NUMA balancing 机制结合默认策略，自动迁移热点页面至访问 CPU 所在节点。\n- **实时系统**：通过 `MPOL_BIND` 严格限制内存位置，确保确定性访问延迟。\n- **大页（HugeTLB）分配**：策略同样适用于透明大页和显式 HugeTLB 页面分配。",
      "similarity": 0.6013049483299255,
      "chunks": [
        {
          "chunk_id": 12,
          "file_path": "mm/mempolicy.c",
          "start_line": 2024,
          "end_line": 2135,
          "content": [
            "static unsigned int interleave_nodes(struct mempolicy *policy)",
            "{",
            "\tunsigned int nid;",
            "\tunsigned int cpuset_mems_cookie;",
            "",
            "\t/* to prevent miscount, use tsk->mems_allowed_seq to detect rebind */",
            "\tdo {",
            "\t\tcpuset_mems_cookie = read_mems_allowed_begin();",
            "\t\tnid = next_node_in(current->il_prev, policy->nodes);",
            "\t} while (read_mems_allowed_retry(cpuset_mems_cookie));",
            "",
            "\tif (nid < MAX_NUMNODES)",
            "\t\tcurrent->il_prev = nid;",
            "\treturn nid;",
            "}",
            "unsigned int mempolicy_slab_node(void)",
            "{",
            "\tstruct mempolicy *policy;",
            "\tint node = numa_mem_id();",
            "",
            "\tif (!in_task())",
            "\t\treturn node;",
            "",
            "\tpolicy = current->mempolicy;",
            "\tif (!policy)",
            "\t\treturn node;",
            "",
            "\tswitch (policy->mode) {",
            "\tcase MPOL_PREFERRED:",
            "\t\treturn first_node(policy->nodes);",
            "",
            "\tcase MPOL_INTERLEAVE:",
            "\t\treturn interleave_nodes(policy);",
            "",
            "\tcase MPOL_WEIGHTED_INTERLEAVE:",
            "\t\treturn weighted_interleave_nodes(policy);",
            "",
            "\tcase MPOL_BIND:",
            "\tcase MPOL_PREFERRED_MANY:",
            "\t{",
            "\t\tstruct zoneref *z;",
            "",
            "\t\t/*",
            "\t\t * Follow bind policy behavior and start allocation at the",
            "\t\t * first node.",
            "\t\t */",
            "\t\tstruct zonelist *zonelist;",
            "\t\tenum zone_type highest_zoneidx = gfp_zone(GFP_KERNEL);",
            "\t\tzonelist = &NODE_DATA(node)->node_zonelists[ZONELIST_FALLBACK];",
            "\t\tz = first_zones_zonelist(zonelist, highest_zoneidx,",
            "\t\t\t\t\t\t\t&policy->nodes);",
            "\t\treturn z->zone ? zone_to_nid(z->zone) : node;",
            "\t}",
            "\tcase MPOL_LOCAL:",
            "\t\treturn node;",
            "",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "}",
            "static unsigned int read_once_policy_nodemask(struct mempolicy *pol,",
            "\t\t\t\t\t      nodemask_t *mask)",
            "{",
            "\t/*",
            "\t * barrier stabilizes the nodemask locally so that it can be iterated",
            "\t * over safely without concern for changes. Allocators validate node",
            "\t * selection does not violate mems_allowed, so this is safe.",
            "\t */",
            "\tbarrier();",
            "\tmemcpy(mask, &pol->nodes, sizeof(nodemask_t));",
            "\tbarrier();",
            "\treturn nodes_weight(*mask);",
            "}",
            "static unsigned int weighted_interleave_nid(struct mempolicy *pol, pgoff_t ilx)",
            "{",
            "\tstruct weighted_interleave_state *state;",
            "\tnodemask_t nodemask;",
            "\tunsigned int target, nr_nodes;",
            "\tu8 *table = NULL;",
            "\tunsigned int weight_total = 0;",
            "\tu8 weight;",
            "\tint nid = 0;",
            "",
            "\tnr_nodes = read_once_policy_nodemask(pol, &nodemask);",
            "\tif (!nr_nodes)",
            "\t\treturn numa_node_id();",
            "",
            "\trcu_read_lock();",
            "",
            "\tstate = rcu_dereference(wi_state);",
            "\t/* Uninitialized wi_state means we should assume all weights are 1 */",
            "\tif (state)",
            "\t\ttable = state->iw_table;",
            "",
            "\t/* calculate the total weight */",
            "\tfor_each_node_mask(nid, nodemask)",
            "\t\tweight_total += table ? table[nid] : 1;",
            "",
            "\t/* Calculate the node offset based on totals */",
            "\ttarget = ilx % weight_total;",
            "\tnid = first_node(nodemask);",
            "\twhile (target) {",
            "\t\t/* detect system default usage */",
            "\t\tweight = table ? table[nid] : 1;",
            "\t\tif (target < weight)",
            "\t\t\tbreak;",
            "\t\ttarget -= weight;",
            "\t\tnid = next_node_in(nid, nodemask);",
            "\t}",
            "\trcu_read_unlock();",
            "\treturn nid;",
            "}"
          ],
          "function_name": "interleave_nodes, mempolicy_slab_node, read_once_policy_nodemask, weighted_interleave_nid",
          "description": "interleave_nodes 计算交错分配的下一个节点；mempolicy_slab_node 根据内存策略返回Slab分配的节点；read_once_policy_nodemask 安全读取策略节点掩码；weighted_interleave_nid 基于权重计算加权交错分配的目标节点。",
          "similarity": 0.5747257471084595
        },
        {
          "chunk_id": 1,
          "file_path": "mm/mempolicy.c",
          "start_line": 168,
          "end_line": 268,
          "content": [
            "static u8 get_il_weight(int node)",
            "{",
            "\tstruct weighted_interleave_state *state;",
            "\tu8 weight = 1;",
            "",
            "\trcu_read_lock();",
            "\tstate = rcu_dereference(wi_state);",
            "\tif (state)",
            "\t\tweight = state->iw_table[node];",
            "\trcu_read_unlock();",
            "\treturn weight;",
            "}",
            "static void reduce_interleave_weights(unsigned int *bw, u8 *new_iw)",
            "{",
            "\tu64 sum_bw = 0;",
            "\tunsigned int cast_sum_bw, scaling_factor = 1, iw_gcd = 0;",
            "\tint nid;",
            "",
            "\tfor_each_node_state(nid, N_MEMORY)",
            "\t\tsum_bw += bw[nid];",
            "",
            "\t/* Scale bandwidths to whole numbers in the range [1, weightiness] */",
            "\tfor_each_node_state(nid, N_MEMORY) {",
            "\t\t/*",
            "\t\t * Try not to perform 64-bit division.",
            "\t\t * If sum_bw < scaling_factor, then sum_bw < U32_MAX.",
            "\t\t * If sum_bw > scaling_factor, then round the weight up to 1.",
            "\t\t */",
            "\t\tscaling_factor = weightiness * bw[nid];",
            "\t\tif (bw[nid] && sum_bw < scaling_factor) {",
            "\t\t\tcast_sum_bw = (unsigned int)sum_bw;",
            "\t\t\tnew_iw[nid] = scaling_factor / cast_sum_bw;",
            "\t\t} else {",
            "\t\t\tnew_iw[nid] = 1;",
            "\t\t}",
            "\t\tif (!iw_gcd)",
            "\t\t\tiw_gcd = new_iw[nid];",
            "\t\tiw_gcd = gcd(iw_gcd, new_iw[nid]);",
            "\t}",
            "",
            "\t/* 1:2 is strictly better than 16:32. Reduce by the weights' GCD. */",
            "\tfor_each_node_state(nid, N_MEMORY)",
            "\t\tnew_iw[nid] /= iw_gcd;",
            "}",
            "int mempolicy_set_node_perf(unsigned int node, struct access_coordinate *coords)",
            "{",
            "\tstruct weighted_interleave_state *new_wi_state, *old_wi_state = NULL;",
            "\tunsigned int *old_bw, *new_bw;",
            "\tunsigned int bw_val;",
            "\tint i;",
            "",
            "\tbw_val = min(coords->read_bandwidth, coords->write_bandwidth);",
            "\tnew_bw = kcalloc(nr_node_ids, sizeof(unsigned int), GFP_KERNEL);",
            "\tif (!new_bw)",
            "\t\treturn -ENOMEM;",
            "",
            "\tnew_wi_state = kmalloc(struct_size(new_wi_state, iw_table, nr_node_ids),",
            "\t\t\t       GFP_KERNEL);",
            "\tif (!new_wi_state) {",
            "\t\tkfree(new_bw);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "\tnew_wi_state->mode_auto = true;",
            "\tfor (i = 0; i < nr_node_ids; i++)",
            "\t\tnew_wi_state->iw_table[i] = 1;",
            "",
            "\t/*",
            "\t * Update bandwidth info, even in manual mode. That way, when switching",
            "\t * to auto mode in the future, iw_table can be overwritten using",
            "\t * accurate bw data.",
            "\t */",
            "\tmutex_lock(&wi_state_lock);",
            "",
            "\told_bw = node_bw_table;",
            "\tif (old_bw)",
            "\t\tmemcpy(new_bw, old_bw, nr_node_ids * sizeof(*old_bw));",
            "\tnew_bw[node] = bw_val;",
            "\tnode_bw_table = new_bw;",
            "",
            "\told_wi_state = rcu_dereference_protected(wi_state,",
            "\t\t\t\t\tlockdep_is_held(&wi_state_lock));",
            "\tif (old_wi_state && !old_wi_state->mode_auto) {",
            "\t\t/* Manual mode; skip reducing weights and updating wi_state */",
            "\t\tmutex_unlock(&wi_state_lock);",
            "\t\tkfree(new_wi_state);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/* NULL wi_state assumes auto=true; reduce weights and update wi_state*/",
            "\treduce_interleave_weights(new_bw, new_wi_state->iw_table);",
            "\trcu_assign_pointer(wi_state, new_wi_state);",
            "",
            "\tmutex_unlock(&wi_state_lock);",
            "\tif (old_wi_state) {",
            "\t\tsynchronize_rcu();",
            "\t\tkfree(old_wi_state);",
            "\t}",
            "out:",
            "\tkfree(old_bw);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "get_il_weight, reduce_interleave_weights, mempolicy_set_node_perf",
          "description": "实现带权交错策略的权重计算与调整逻辑，通过获取节点带宽数据动态修改权重比例，支持根据性能参数更新节点间内存分配优先级。",
          "similarity": 0.5740642547607422
        },
        {
          "chunk_id": 13,
          "file_path": "mm/mempolicy.c",
          "start_line": 2149,
          "end_line": 2255,
          "content": [
            "static unsigned int interleave_nid(struct mempolicy *pol, pgoff_t ilx)",
            "{",
            "\tnodemask_t nodemask;",
            "\tunsigned int target, nnodes;",
            "\tint i;",
            "\tint nid;",
            "",
            "\tnnodes = read_once_policy_nodemask(pol, &nodemask);",
            "\tif (!nnodes)",
            "\t\treturn numa_node_id();",
            "\ttarget = ilx % nnodes;",
            "\tnid = first_node(nodemask);",
            "\tfor (i = 0; i < target; i++)",
            "\t\tnid = next_node(nid, nodemask);",
            "\treturn nid;",
            "}",
            "int huge_node(struct vm_area_struct *vma, unsigned long addr, gfp_t gfp_flags,",
            "\t\tstruct mempolicy **mpol, nodemask_t **nodemask)",
            "{",
            "\tpgoff_t ilx;",
            "\tint nid;",
            "",
            "\tnid = numa_node_id();",
            "\t*mpol = get_vma_policy(vma, addr, hstate_vma(vma)->order, &ilx);",
            "\t*nodemask = policy_nodemask(gfp_flags, *mpol, ilx, &nid);",
            "\treturn nid;",
            "}",
            "bool init_nodemask_of_mempolicy(nodemask_t *mask)",
            "{",
            "\tstruct mempolicy *mempolicy;",
            "",
            "\tif (!(mask && current->mempolicy))",
            "\t\treturn false;",
            "",
            "\ttask_lock(current);",
            "\tmempolicy = current->mempolicy;",
            "\tswitch (mempolicy->mode) {",
            "\tcase MPOL_PREFERRED:",
            "\tcase MPOL_PREFERRED_MANY:",
            "\tcase MPOL_BIND:",
            "\tcase MPOL_INTERLEAVE:",
            "\tcase MPOL_WEIGHTED_INTERLEAVE:",
            "\t\t*mask = mempolicy->nodes;",
            "\t\tbreak;",
            "",
            "\tcase MPOL_LOCAL:",
            "\t\tinit_nodemask_of_node(mask, numa_node_id());",
            "\t\tbreak;",
            "",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "\ttask_unlock(current);",
            "",
            "\treturn true;",
            "}",
            "bool mempolicy_in_oom_domain(struct task_struct *tsk,",
            "\t\t\t\t\tconst nodemask_t *mask)",
            "{",
            "\tstruct mempolicy *mempolicy;",
            "\tbool ret = true;",
            "",
            "\tif (!mask)",
            "\t\treturn ret;",
            "",
            "\ttask_lock(tsk);",
            "\tmempolicy = tsk->mempolicy;",
            "\tif (mempolicy && mempolicy->mode == MPOL_BIND)",
            "\t\tret = nodes_intersects(mempolicy->nodes, *mask);",
            "\ttask_unlock(tsk);",
            "",
            "\treturn ret;",
            "}",
            "static unsigned long alloc_pages_bulk_array_interleave(gfp_t gfp,",
            "\t\tstruct mempolicy *pol, unsigned long nr_pages,",
            "\t\tstruct page **page_array)",
            "{",
            "\tint nodes;",
            "\tunsigned long nr_pages_per_node;",
            "\tint delta;",
            "\tint i;",
            "\tunsigned long nr_allocated;",
            "\tunsigned long total_allocated = 0;",
            "",
            "\tnodes = nodes_weight(pol->nodes);",
            "\tnr_pages_per_node = nr_pages / nodes;",
            "\tdelta = nr_pages - nodes * nr_pages_per_node;",
            "",
            "\tfor (i = 0; i < nodes; i++) {",
            "\t\tif (delta) {",
            "\t\t\tnr_allocated = alloc_pages_bulk_noprof(gfp,",
            "\t\t\t\t\tinterleave_nodes(pol), NULL,",
            "\t\t\t\t\tnr_pages_per_node + 1, NULL,",
            "\t\t\t\t\tpage_array);",
            "\t\t\tdelta--;",
            "\t\t} else {",
            "\t\t\tnr_allocated = alloc_pages_bulk_noprof(gfp,",
            "\t\t\t\t\tinterleave_nodes(pol), NULL,",
            "\t\t\t\t\tnr_pages_per_node, NULL, page_array);",
            "\t\t}",
            "",
            "\t\tpage_array += nr_allocated;",
            "\t\ttotal_allocated += nr_allocated;",
            "\t}",
            "",
            "\treturn total_allocated;",
            "}"
          ],
          "function_name": "interleave_nid, huge_node, init_nodemask_of_mempolicy, mempolicy_in_oom_domain, alloc_pages_bulk_array_interleave",
          "description": "interleave_nid 计算简单交错分配的目标节点；huge_node 结合HugeTLB策略确定大页分配节点；init_nodemask_of_mempolicy 初始化当前进程的内存策略节点掩码；mempolicy_in_oom_domain 检查策略节点是否与OOM域重叠；alloc_pages_bulk_array_interleave 执行批量交错分配。",
          "similarity": 0.5604425072669983
        },
        {
          "chunk_id": 11,
          "file_path": "mm/mempolicy.c",
          "start_line": 1855,
          "end_line": 1971,
          "content": [
            "static int kernel_get_mempolicy(int __user *policy,",
            "\t\t\t\tunsigned long __user *nmask,",
            "\t\t\t\tunsigned long maxnode,",
            "\t\t\t\tunsigned long addr,",
            "\t\t\t\tunsigned long flags)",
            "{",
            "\tint err;",
            "\tint pval;",
            "\tnodemask_t nodes;",
            "",
            "\tif (nmask != NULL && maxnode < nr_node_ids)",
            "\t\treturn -EINVAL;",
            "",
            "\taddr = untagged_addr(addr);",
            "",
            "\terr = do_get_mempolicy(&pval, &nodes, addr, flags);",
            "",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tif (policy && put_user(pval, policy))",
            "\t\treturn -EFAULT;",
            "",
            "\tif (nmask)",
            "\t\terr = copy_nodes_to_user(nmask, maxnode, &nodes);",
            "",
            "\treturn err;",
            "}",
            "bool vma_migratable(struct vm_area_struct *vma)",
            "{",
            "\tif (vma->vm_flags & (VM_IO | VM_PFNMAP))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * DAX device mappings require predictable access latency, so avoid",
            "\t * incurring periodic faults.",
            "\t */",
            "\tif (vma_is_dax(vma))",
            "\t\treturn false;",
            "",
            "\tif (is_vm_hugetlb_page(vma) &&",
            "\t\t!hugepage_migration_supported(hstate_vma(vma)))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Migration allocates pages in the highest zone. If we cannot",
            "\t * do so then migration (at least from node to node) is not",
            "\t * possible.",
            "\t */",
            "\tif (vma->vm_file &&",
            "\t\tgfp_zone(mapping_gfp_mask(vma->vm_file->f_mapping))",
            "\t\t\t< policy_zone)",
            "\t\treturn false;",
            "\treturn true;",
            "}",
            "bool vma_policy_mof(struct vm_area_struct *vma)",
            "{",
            "\tstruct mempolicy *pol;",
            "",
            "\tif (vma->vm_ops && vma->vm_ops->get_policy) {",
            "\t\tbool ret = false;",
            "\t\tpgoff_t ilx;\t\t/* ignored here */",
            "",
            "\t\tpol = vma->vm_ops->get_policy(vma, vma->vm_start, &ilx);",
            "\t\tif (pol && (pol->flags & MPOL_F_MOF))",
            "\t\t\tret = true;",
            "\t\tmpol_cond_put(pol);",
            "",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tpol = vma->vm_policy;",
            "\tif (!pol)",
            "\t\tpol = get_task_policy(current);",
            "",
            "\treturn pol->flags & MPOL_F_MOF;",
            "}",
            "bool apply_policy_zone(struct mempolicy *policy, enum zone_type zone)",
            "{",
            "\tenum zone_type dynamic_policy_zone = policy_zone;",
            "",
            "\tBUG_ON(dynamic_policy_zone == ZONE_MOVABLE);",
            "",
            "\t/*",
            "\t * if policy->nodes has movable memory only,",
            "\t * we apply policy when gfp_zone(gfp) = ZONE_MOVABLE only.",
            "\t *",
            "\t * policy->nodes is intersect with node_states[N_MEMORY].",
            "\t * so if the following test fails, it implies",
            "\t * policy->nodes has movable memory only.",
            "\t */",
            "\tif (!nodes_intersects(policy->nodes, node_states[N_HIGH_MEMORY]))",
            "\t\tdynamic_policy_zone = ZONE_MOVABLE;",
            "",
            "\treturn zone >= dynamic_policy_zone;",
            "}",
            "static unsigned int weighted_interleave_nodes(struct mempolicy *policy)",
            "{",
            "\tunsigned int node;",
            "\tunsigned int cpuset_mems_cookie;",
            "",
            "retry:",
            "\t/* to prevent miscount use tsk->mems_allowed_seq to detect rebind */",
            "\tcpuset_mems_cookie = read_mems_allowed_begin();",
            "\tnode = current->il_prev;",
            "\tif (!current->il_weight || !node_isset(node, policy->nodes)) {",
            "\t\tnode = next_node_in(node, policy->nodes);",
            "\t\tif (read_mems_allowed_retry(cpuset_mems_cookie))",
            "\t\t\tgoto retry;",
            "\t\tif (node == MAX_NUMNODES)",
            "\t\t\treturn node;",
            "\t\tcurrent->il_prev = node;",
            "\t\tcurrent->il_weight = get_il_weight(node);",
            "\t}",
            "\tcurrent->il_weight--;",
            "\treturn node;",
            "}"
          ],
          "function_name": "kernel_get_mempolicy, vma_migratable, vma_policy_mof, apply_policy_zone, weighted_interleave_nodes",
          "description": "kernel_get_mempolicy 获取当前内存策略参数并复制到用户空间；vma_migratable 判断虚拟内存区域是否支持迁移；vma_policy_mof 检查VMA是否启用了MOF（Migration On Fault）策略；apply_policy_zone 确定当前zone是否满足策略要求；weighted_interleave_nodes 计算加权交错分配的目标节点。",
          "similarity": 0.5575867891311646
        },
        {
          "chunk_id": 20,
          "file_path": "mm/mempolicy.c",
          "start_line": 3434,
          "end_line": 3538,
          "content": [
            "void mpol_to_str(char *buffer, int maxlen, struct mempolicy *pol)",
            "{",
            "\tchar *p = buffer;",
            "\tnodemask_t nodes = NODE_MASK_NONE;",
            "\tunsigned short mode = MPOL_DEFAULT;",
            "\tunsigned short flags = 0;",
            "",
            "\tif (pol &&",
            "\t    pol != &default_policy &&",
            "\t    !(pol >= &preferred_node_policy[0] &&",
            "\t      pol <= &preferred_node_policy[ARRAY_SIZE(preferred_node_policy) - 1])) {",
            "\t\tmode = pol->mode;",
            "\t\tflags = pol->flags;",
            "\t}",
            "",
            "\tswitch (mode) {",
            "\tcase MPOL_DEFAULT:",
            "\tcase MPOL_LOCAL:",
            "\t\tbreak;",
            "\tcase MPOL_PREFERRED:",
            "\tcase MPOL_PREFERRED_MANY:",
            "\tcase MPOL_BIND:",
            "\tcase MPOL_INTERLEAVE:",
            "\tcase MPOL_WEIGHTED_INTERLEAVE:",
            "\t\tnodes = pol->nodes;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tWARN_ON_ONCE(1);",
            "\t\tsnprintf(p, maxlen, \"unknown\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tp += snprintf(p, maxlen, \"%s\", policy_modes[mode]);",
            "",
            "\tif (flags & MPOL_MODE_FLAGS) {",
            "\t\tp += snprintf(p, buffer + maxlen - p, \"=\");",
            "",
            "\t\t/*",
            "\t\t * Static and relative are mutually exclusive.",
            "\t\t */",
            "\t\tif (flags & MPOL_F_STATIC_NODES)",
            "\t\t\tp += snprintf(p, buffer + maxlen - p, \"static\");",
            "\t\telse if (flags & MPOL_F_RELATIVE_NODES)",
            "\t\t\tp += snprintf(p, buffer + maxlen - p, \"relative\");",
            "",
            "\t\tif (flags & MPOL_F_NUMA_BALANCING) {",
            "\t\t\tif (!is_power_of_2(flags & MPOL_MODE_FLAGS))",
            "\t\t\t\tp += snprintf(p, buffer + maxlen - p, \"|\");",
            "\t\t\tp += snprintf(p, buffer + maxlen - p, \"balancing\");",
            "\t\t}",
            "\t}",
            "",
            "\tif (!nodes_empty(nodes))",
            "\t\tp += scnprintf(p, buffer + maxlen - p, \":%*pbl\",",
            "\t\t\t       nodemask_pr_args(&nodes));",
            "}",
            "static ssize_t node_show(struct kobject *kobj, struct kobj_attribute *attr,",
            "\t\t\t char *buf)",
            "{",
            "\tstruct iw_node_attr *node_attr;",
            "\tu8 weight;",
            "",
            "\tnode_attr = container_of(attr, struct iw_node_attr, kobj_attr);",
            "\tweight = get_il_weight(node_attr->nid);",
            "\treturn sysfs_emit(buf, \"%d\\n\", weight);",
            "}",
            "static ssize_t node_store(struct kobject *kobj, struct kobj_attribute *attr,",
            "\t\t\t  const char *buf, size_t count)",
            "{",
            "\tstruct weighted_interleave_state *new_wi_state, *old_wi_state = NULL;",
            "\tstruct iw_node_attr *node_attr;",
            "\tu8 weight = 0;",
            "\tint i;",
            "",
            "\tnode_attr = container_of(attr, struct iw_node_attr, kobj_attr);",
            "\tif (count == 0 || sysfs_streq(buf, \"\") ||",
            "\t    kstrtou8(buf, 0, &weight) || weight == 0)",
            "\t\treturn -EINVAL;",
            "",
            "\tnew_wi_state = kzalloc(struct_size(new_wi_state, iw_table, nr_node_ids),",
            "\t\t\t       GFP_KERNEL);",
            "\tif (!new_wi_state)",
            "\t\treturn -ENOMEM;",
            "",
            "\tmutex_lock(&wi_state_lock);",
            "\told_wi_state = rcu_dereference_protected(wi_state,",
            "\t\t\t\t\tlockdep_is_held(&wi_state_lock));",
            "\tif (old_wi_state) {",
            "\t\tmemcpy(new_wi_state->iw_table, old_wi_state->iw_table,",
            "\t\t\t\t\tnr_node_ids * sizeof(u8));",
            "\t} else {",
            "\t\tfor (i = 0; i < nr_node_ids; i++)",
            "\t\t\tnew_wi_state->iw_table[i] = 1;",
            "\t}",
            "\tnew_wi_state->iw_table[node_attr->nid] = weight;",
            "\tnew_wi_state->mode_auto = false;",
            "",
            "\trcu_assign_pointer(wi_state, new_wi_state);",
            "\tmutex_unlock(&wi_state_lock);",
            "\tif (old_wi_state) {",
            "\t\tsynchronize_rcu();",
            "\t\tkfree(old_wi_state);",
            "\t}",
            "\treturn count;",
            "}"
          ],
          "function_name": "mpol_to_str, node_show, node_store",
          "description": "mpol_to_str 将内存策略结构体转换为可打印字符串，识别策略模式和节点掩码信息。node_show 和 node_store 分别实现 sysfs 属性的读取和写入逻辑，用于动态配置加权交错节点权重。",
          "similarity": 0.5536090135574341
        }
      ]
    },
    {
      "source_file": "kernel/pid_sysctl.h",
      "md_summary": "> 自动生成时间: 2025-10-25 15:17:36\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `pid_sysctl.h`\n\n---\n\n# `pid_sysctl.h` 技术文档\n\n## 1. 文件概述\n\n`pid_sysctl.h` 是 Linux 内核中用于定义与 PID 命名空间（`pid_namespace`）相关的系统控制（sysctl）接口的头文件。其核心功能是提供对 `memfd_noexec` 系统策略的运行时配置支持，该策略用于控制通过 `memfd_create()` 创建的内存文件是否允许执行代码。该配置具有层级继承语义：子 PID 命名空间的策略不能比其父命名空间更宽松，以确保安全策略的向下兼容性和强制性。\n\n## 2. 核心功能\n\n### 函数\n\n- **`pid_mfd_noexec_dointvec_minmax`**  \n  自定义的 sysctl 处理函数，用于读写 `memfd_noexec` 策略值。在写入时执行权限检查和策略继承约束验证。\n\n- **`register_pid_ns_sysctl_table_vm`**  \n  内联函数，用于向内核 sysctl 子系统注册 `vm.memfd_noexec` 控制项（仅在 `CONFIG_SYSCTL` 和 `CONFIG_MEMFD_CREATE` 同时启用时有效）。\n\n### 数据结构\n\n- **`pid_ns_ctl_table_vm`**  \n  `ctl_table` 类型的静态数组，定义了 `vm.memfd_noexec` sysctl 条目，包括其名称、数据指针、访问权限、处理函数及取值范围（0 到 2）。\n\n## 3. 关键实现\n\n- **权限控制**：  \n  在写入 `memfd_noexec` 值时，调用 `ns_capable(ns->user_ns, CAP_SYS_ADMIN)` 检查当前任务是否在对应用户命名空间中拥有 `CAP_SYS_ADMIN` 能力，防止非特权用户修改安全策略。\n\n- **策略继承约束**：  \n  通过 `pidns_memfd_noexec_scope(ns->parent)` 获取父 PID 命名空间的策略值 `parent_scope`，并确保当前命名空间的策略值 `scope` 不小于父策略（即不能更宽松）。实际写入前使用 `max(READ_ONCE(ns->memfd_noexec_scope), parent_scope)` 保证该约束。\n\n- **原子读写**：  \n  使用 `READ_ONCE()` 和 `WRITE_ONCE()` 对 `ns->memfd_noexec_scope` 进行访问，确保在并发环境下内存访问的可见性和顺序性。\n\n- **sysctl 注册**：  \n  通过 `register_sysctl(\"vm\", pid_ns_ctl_table_vm)` 将控制项注册到 `/proc/sys/vm/memfd_noexec` 路径下，供用户空间通过标准 sysctl 接口访问。\n\n- **条件编译**：  \n  整个功能仅在 `CONFIG_SYSCTL`（启用 sysctl 支持）和 `CONFIG_MEMFD_CREATE`（启用 memfd_create 系统调用）同时配置时编译，否则 `register_pid_ns_sysctl_table_vm` 为空内联函数，避免代码膨胀。\n\n## 4. 依赖关系\n\n- **`<linux/pid_namespace.h>`**：  \n  提供 `struct pid_namespace` 定义及辅助函数如 `task_active_pid_ns()` 和 `pidns_memfd_noexec_scope()`。\n\n- **`CONFIG_SYSCTL`**：  \n  内核配置选项，启用 sysctl 框架支持，提供 `register_sysctl`、`proc_dointvec_minmax` 等接口。\n\n- **`CONFIG_MEMFD_CREATE`**：  \n  内核配置选项，启用 `memfd_create()` 系统调用及相关功能（如 `memfd_noexec_scope` 字段）。\n\n- **能力子系统（Capabilities）**：  \n  依赖 `ns_capable()` 进行命名空间感知的权限检查。\n\n## 5. 使用场景\n\n- **安全策略配置**：  \n  系统管理员或容器运行时可通过写入 `/proc/sys/vm/memfd_noexec` 设置当前 PID 命名空间中 `memfd` 文件的执行限制级别（0=允许执行，1=禁止执行但可覆盖，2=严格禁止执行），用于防御基于内存文件的代码注入攻击。\n\n- **容器隔离**：  \n  在容器化环境中，不同容器运行在独立的 PID 命名空间中。父命名空间（如宿主机）可设置较严格的 `memfd_noexec` 策略，子容器无法降低该策略级别，从而实现自上而下的安全策略强制。\n\n- **运行时动态调整**：  \n  允许在系统运行期间动态调整 `memfd` 执行策略，无需重启或重新加载内核模块，提升系统灵活性与安全性。",
      "similarity": 0.5871979594230652,
      "chunks": []
    },
    {
      "source_file": "kernel/user-return-notifier.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:45:08\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `user-return-notifier.c`\n\n---\n\n# user-return-notifier.c 技术文档\n\n## 1. 文件概述\n\n`user-return-notifier.c` 实现了用户态返回通知机制（User Return Notifier），允许内核子系统在当前 CPU 即将从内核态返回用户态时注册回调函数。该机制用于在特定内核事件（如安全策略更新、性能监控等）发生后，延迟执行某些操作，直到进程真正返回用户空间，从而避免在关键内核路径中引入额外开销或竞态条件。\n\n## 2. 核心功能\n\n### 数据结构\n- `return_notifier_list`：每 CPU 变量（per-CPU variable），类型为 `struct hlist_head`，用于存储当前 CPU 上注册的所有用户返回通知器链表。\n\n### 主要函数\n- `user_return_notifier_register(struct user_return_notifier *urn)`  \n  注册一个用户返回通知器，将其加入当前 CPU 的通知链表，并设置当前任务的 `TIF_USER_RETURN_NOTIFY` 标志位。\n\n- `user_return_notifier_unregister(struct user_return_notifier *urn)`  \n  从当前 CPU 的通知链表中移除指定的通知器；若链表变为空，则清除当前任务的 `TIF_USER_RETURN_NOTIFY` 标志位。\n\n- `fire_user_return_notifiers(void)`  \n  遍历并调用当前 CPU 上所有已注册的通知器的回调函数 `on_user_return`，通常在内核即将返回用户态前由调度或系统调用退出路径调用。\n\n## 3. 关键实现\n\n- **每 CPU 链表设计**：使用 `DEFINE_PER_CPU` 定义 per-CPU 的哈希链表头，确保每个 CPU 维护独立的通知器列表，避免跨 CPU 同步开销。\n  \n- **原子上下文要求**：注册和注销操作必须在原子上下文中执行（不可睡眠），因为它们操作 per-CPU 数据且可能在中断或调度关键路径中被调用。\n\n- **线程标志位控制**：通过设置/清除任务结构体中的 `TIF_USER_RETURN_NOTIFY` 标志位（`TIF_` 表示 Thread Info Flag），通知内核在返回用户态前需调用 `fire_user_return_notifiers()`。\n\n- **安全遍历与调用**：`fire_user_return_notifiers()` 使用 `hlist_for_each_entry_safe` 安全遍历链表，允许回调函数在执行过程中注销自身或其他通知器。\n\n- **CPU 变量访问**：使用 `get_cpu_var()` 和 `put_cpu_var()` 保证在访问 per-CPU 变量期间禁止内核抢占，确保操作的 CPU 一致性。\n\n## 4. 依赖关系\n\n- `<linux/user-return-notifier.h>`：定义 `struct user_return_notifier` 及相关 API。\n- `<linux/percpu.h>`：提供 per-CPU 变量支持。\n- `<linux/sched.h>`：提供任务结构体（`current`）和线程标志位操作函数（如 `set_tsk_thread_flag`）。\n- `<linux/export.h>`：导出符号供其他内核模块使用（`EXPORT_SYMBOL_GPL`）。\n- 依赖架构相关的线程信息标志（`TIF_USER_RETURN_NOTIFY`）在 `thread_info` 中的定义。\n\n## 5. 使用场景\n\n- **安全模块**：如 SELinux 或 LSM 框架在策略更新后，需通知用户态进程重新评估权限，可延迟到返回用户态时触发。\n- **性能监控与跟踪**：在系统调用或中断处理完成后，于返回用户态前收集上下文切换或延迟信息。\n- **延迟工作调度**：某些不适合在中断或原子上下文中执行的操作，可注册为用户返回通知，在安全的用户态切换点执行。\n- **虚拟化与容器**：在客户机或容器退出内核时同步状态或注入事件。\n\n该机制是内核“延迟通知”模式的典型实现，确保高优先级内核路径不受回调逻辑影响，同时保证通知在正确的执行上下文中触发。",
      "similarity": 0.5831658840179443,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/user-return-notifier.c",
          "start_line": 1,
          "end_line": 14,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/sched.h>",
            "#include <linux/export.h>",
            "",
            "static DEFINE_PER_CPU(struct hlist_head, return_notifier_list);",
            "",
            "/*",
            " * Request a notification when the current cpu returns to userspace.  Must be",
            " * called in atomic context.  The notifier will also be called in atomic",
            " * context.",
            " */"
          ],
          "function_name": null,
          "description": "定义了一个 per-CPU 的哈希列表头结构 return_notifier_list，用于存储用户态返回通知器注册项。该结构通过 DEFINE_PER_CPU 宏为每个 CPU 创建独立的链表头，支持多 CPU 环境下的并发访问。",
          "similarity": 0.565194308757782
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/user-return-notifier.c",
          "start_line": 15,
          "end_line": 36,
          "content": [
            "void user_return_notifier_register(struct user_return_notifier *urn)",
            "{",
            "\tset_tsk_thread_flag(current, TIF_USER_RETURN_NOTIFY);",
            "\thlist_add_head(&urn->link, this_cpu_ptr(&return_notifier_list));",
            "}",
            "void user_return_notifier_unregister(struct user_return_notifier *urn)",
            "{",
            "\thlist_del(&urn->link);",
            "\tif (hlist_empty(this_cpu_ptr(&return_notifier_list)))",
            "\t\tclear_tsk_thread_flag(current, TIF_USER_RETURN_NOTIFY);",
            "}",
            "void fire_user_return_notifiers(void)",
            "{",
            "\tstruct user_return_notifier *urn;",
            "\tstruct hlist_node *tmp2;",
            "\tstruct hlist_head *head;",
            "",
            "\thead = &get_cpu_var(return_notifier_list);",
            "\thlist_for_each_entry_safe(urn, tmp2, head, link)",
            "\t\turn->on_user_return(urn);",
            "\tput_cpu_var(return_notifier_list);",
            "}"
          ],
          "function_name": "user_return_notifier_register, user_return_notifier_unregister, fire_user_return_notifiers",
          "description": "实现用户态返回通知器的注册/注销与触发机制。register 函数将通知器链接到当前 CPU 的链表并设置 TIF_USER_RETURN_NOTIFY 标志；unregister 函数移除节点并清理标志；fire 函数遍历当前 CPU 链表执行所有注册的 on_user_return 回调函数。",
          "similarity": 0.5310905575752258
        }
      ]
    }
  ]
}