{
  "query": "deadlock avoidance",
  "timestamp": "2025-12-26 01:04:03",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/osq_lock.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:43:41\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\osq_lock.c`\n\n---\n\n# `locking/osq_lock.c` 技术文档\n\n## 1. 文件概述\n\n`osq_lock.c` 实现了一种专为**乐观自旋（Optimistic Spinning）**设计的轻量级排队自旋锁机制，称为 **OSQ（Optimistic Spin Queue）锁**。该机制主要用于支持如互斥锁（mutex）、读写信号量（rwsem）等**可睡眠锁**在争用时进行乐观自旋，以避免不必要的上下文切换和调度开销。OSQ 锁基于 MCS（Mellor-Crummey and Scott）锁的思想，但针对 Linux 内核的调度和抢占模型进行了优化，利用每个 CPU 的静态 per-CPU 节点结构，确保在禁用抢占的自旋上下文中安全使用。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct optimistic_spin_node`：每个 CPU 对应一个静态节点，包含：\n  - `cpu`：编码后的 CPU 编号（实际值 = CPU ID + 1）\n  - `locked`：布尔标志，表示是否已获得锁\n  - `next`：指向队列中下一个节点的指针\n  - `prev`：指向前一个节点的指针\n- `struct optimistic_spin_queue`：OSQ 锁结构体，仅包含一个原子变量 `tail`，用于指向队列尾部（编码后的 CPU 编号），`OSQ_UNLOCKED_VAL`（值为 0）表示无锁。\n\n### 主要函数\n- `bool osq_lock(struct optimistic_spin_queue *lock)`  \n  尝试获取 OSQ 锁。若成功获得锁或决定放弃自旋（如需要调度或前驱被抢占），返回 `true`；若成功排队但未获得锁且需继续等待，则返回 `false`（实际逻辑中，失败路径最终也返回 `false` 表示未获得锁）。\n  \n- `void osq_unlock(struct optimistic_spin_queue *lock)`  \n  释放 OSQ 锁，唤醒队列中的下一个等待者（若存在）。\n\n- `static inline struct optimistic_spin_node *osq_wait_next(...)`  \n  辅助函数，用于在解锁或取消排队时安全地获取下一个节点，并处理队列尾部的原子更新。\n\n- `encode_cpu()` / `decode_cpu()` / `node_cpu()`  \n  用于在 CPU 编号与 per-CPU 节点指针之间进行编码/解码转换，其中 CPU 编号 0 被编码为 1，以 0 表示“无 CPU”（即锁空闲）。\n\n## 3. 关键实现\n\n### Per-CPU 静态节点设计\n- 每个 CPU 拥有一个静态的 `osq_node`（通过 `DEFINE_PER_CPU_SHARED_ALIGNED` 定义），避免动态分配开销。\n- 由于 OSQ 仅在**禁用抢占**的上下文中使用（如 mutex 的乐观自旋阶段），且**不可在中断上下文调用**，因此 per-CPU 节点的生命周期安全。\n\n### 锁获取流程 (`osq_lock`)\n1. **初始化本地节点**：设置 `locked=0`、`next=NULL`，并确保 `cpu` 字段为当前 CPU 编码值。\n2. **原子交换尾指针**：通过 `atomic_xchg(&lock->tail, curr)` 尝试入队。若原值为 `OSQ_UNLOCKED_VAL`，直接获得锁。\n3. **链接到前驱**：若已有前驱（`prev`），通过 `smp_wmb()` 确保内存顺序后，设置 `prev->next = node`。\n4. **自旋等待**：使用 `smp_cond_load_relaxed()` 等待 `node->locked` 变为 1，或满足退出条件（`need_resched()` 或前驱 CPU 被抢占 `vcpu_is_preempted()`）。\n5. **取消排队（Unqueue）**：若需退出自旋：\n   - **Step A**：尝试将 `prev->next` 置为 `NULL`，断开链接。\n   - **Step B**：调用 `osq_wait_next()` 确定下一个节点，并可能将锁尾指针回退。\n   - **Step C**：若存在 `next`，将其与 `prev` 直接链接，完成队列修复。\n\n### 锁释放流程 (`osq_unlock`)\n1. **快速路径**：若当前 CPU 是唯一持有者（`tail == curr`），直接将 `tail` 设为 `OSQ_UNLOCKED_VAL`。\n2. **慢速路径**：\n   - 若本地节点的 `next` 非空，直接设置 `next->locked = 1` 唤醒后继。\n   - 否则调用 `osq_wait_next()` 获取下一个节点（处理并发取消排队的情况），再唤醒。\n\n### 内存屏障与原子操作\n- 使用 `atomic_xchg`、`atomic_cmpxchg_acquire/release` 确保对 `lock->tail` 的操作具有适当的内存序。\n- `smp_wmb()` 保证在设置 `prev->next` 前，本地节点的初始化对其他 CPU 可见。\n- `WRITE_ONCE`/`READ_ONCE` 防止编译器优化破坏并发访问语义。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/percpu.h>`：提供 per-CPU 变量支持（`this_cpu_ptr`, `per_cpu_ptr`）。\n  - `<linux/sched.h>`：提供调度相关函数（`need_resched()`）和虚拟 CPU 抢占检测（`vcpu_is_preempted()`）。\n  - `<linux/osq_lock.h>`：定义 `struct optimistic_spin_queue`、`struct optimistic_spin_node` 及 `OSQ_UNLOCKED_VAL`。\n- **架构依赖**：依赖底层架构的原子操作（`atomic_*`）、内存屏障（`smp_wmb`, `smp_load_acquire`）和 CPU ID 获取（`smp_processor_id()`）。\n- **调度器集成**：与内核调度器紧密协作，通过 `need_resched()` 和 `vcpu_is_preempted()` 决定是否继续自旋。\n\n## 5. 使用场景\n\nOSQ 锁主要用于**可睡眠锁的乐观自旋优化**，典型场景包括：\n- **Mutex（互斥锁）**：在 `mutex_spin_on_owner()` 中，若锁持有者正在运行，当前 CPU 会尝试 OSQ 自旋而非立即睡眠。\n- **Rwsem（读写信号量）**：在写者争用时，若满足条件，会使用 OSQ 进行乐观自旋。\n- **其他睡眠锁**：任何希望在锁争用时避免立即进入睡眠、以降低延迟的同步原语。\n\n其核心价值在于：当锁持有者很可能在**另一个 CPU 上运行且未被抢占**时，通过短暂自旋可避免昂贵的上下文切换，提升性能；同时通过 `vcpu_is_preempted()` 检测虚拟化环境中的抢占，避免在持有者已让出 CPU 时无效自旋。",
      "similarity": 0.5511729121208191,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/osq_lock.c",
          "start_line": 213,
          "end_line": 238,
          "content": [
            "void osq_unlock(struct optimistic_spin_queue *lock)",
            "{",
            "\tstruct optimistic_spin_node *node, *next;",
            "\tint curr = encode_cpu(smp_processor_id());",
            "",
            "\t/*",
            "\t * Fast path for the uncontended case.",
            "\t */",
            "\tif (likely(atomic_cmpxchg_release(&lock->tail, curr,",
            "\t\t\t\t\t  OSQ_UNLOCKED_VAL) == curr))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Second most likely case.",
            "\t */",
            "\tnode = this_cpu_ptr(&osq_node);",
            "\tnext = xchg(&node->next, NULL);",
            "\tif (next) {",
            "\t\tWRITE_ONCE(next->locked, 1);",
            "\t\treturn;",
            "\t}",
            "",
            "\tnext = osq_wait_next(lock, node, NULL);",
            "\tif (next)",
            "\t\tWRITE_ONCE(next->locked, 1);",
            "}"
          ],
          "function_name": "osq_unlock",
          "description": "实现osq_unlock函数，处理锁的释放。通过原子比较交换操作快速处理无竞争情况，否则查找并唤醒下一个等待节点，确保锁状态的正确性与线程安全。",
          "similarity": 0.5332620143890381
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/osq_lock.c",
          "start_line": 20,
          "end_line": 149,
          "content": [
            "static inline int encode_cpu(int cpu_nr)",
            "{",
            "\treturn cpu_nr + 1;",
            "}",
            "static inline int node_cpu(struct optimistic_spin_node *node)",
            "{",
            "\treturn node->cpu - 1;",
            "}",
            "bool osq_lock(struct optimistic_spin_queue *lock)",
            "{",
            "\tstruct optimistic_spin_node *node = this_cpu_ptr(&osq_node);",
            "\tstruct optimistic_spin_node *prev, *next;",
            "\tint curr = encode_cpu(smp_processor_id());",
            "\tint old;",
            "",
            "\tnode->locked = 0;",
            "\tnode->next = NULL;",
            "\t/*",
            "\t * After this cpu member is initialized for the first time, it",
            "\t * would no longer change in fact. That could avoid cache misses",
            "\t * when spin and access the cpu member by other CPUs.",
            "\t */",
            "\tif (node->cpu != curr)",
            "\t\tnode->cpu = curr;",
            "",
            "\t/*",
            "\t * We need both ACQUIRE (pairs with corresponding RELEASE in",
            "\t * unlock() uncontended, or fastpath) and RELEASE (to publish",
            "\t * the node fields we just initialised) semantics when updating",
            "\t * the lock tail.",
            "\t */",
            "\told = atomic_xchg(&lock->tail, curr);",
            "\tif (old == OSQ_UNLOCKED_VAL)",
            "\t\treturn true;",
            "",
            "\tprev = decode_cpu(old);",
            "\tnode->prev = prev;",
            "",
            "\t/*",
            "\t * osq_lock()\t\t\tunqueue",
            "\t *",
            "\t * node->prev = prev\t\tosq_wait_next()",
            "\t * WMB\t\t\t\tMB",
            "\t * prev->next = node\t\tnext->prev = prev // unqueue-C",
            "\t *",
            "\t * Here 'node->prev' and 'next->prev' are the same variable and we need",
            "\t * to ensure these stores happen in-order to avoid corrupting the list.",
            "\t */",
            "\tsmp_wmb();",
            "",
            "\tWRITE_ONCE(prev->next, node);",
            "",
            "\t/*",
            "\t * Normally @prev is untouchable after the above store; because at that",
            "\t * moment unlock can proceed and wipe the node element from stack.",
            "\t *",
            "\t * However, since our nodes are static per-cpu storage, we're",
            "\t * guaranteed their existence -- this allows us to apply",
            "\t * cmpxchg in an attempt to undo our queueing.",
            "\t */",
            "",
            "\t/*",
            "\t * Wait to acquire the lock or cancellation. Note that need_resched()",
            "\t * will come with an IPI, which will wake smp_cond_load_relaxed() if it",
            "\t * is implemented with a monitor-wait. vcpu_is_preempted() relies on",
            "\t * polling, be careful.",
            "\t */",
            "\tif (smp_cond_load_relaxed(&node->locked, VAL || need_resched() ||",
            "\t\t\t\t  vcpu_is_preempted(node_cpu(node->prev))))",
            "\t\treturn true;",
            "",
            "\t/* unqueue */",
            "\t/*",
            "\t * Step - A  -- stabilize @prev",
            "\t *",
            "\t * Undo our @prev->next assignment; this will make @prev's",
            "\t * unlock()/unqueue() wait for a next pointer since @lock points to us",
            "\t * (or later).",
            "\t */",
            "",
            "\tfor (;;) {",
            "\t\t/*",
            "\t\t * cpu_relax() below implies a compiler barrier which would",
            "\t\t * prevent this comparison being optimized away.",
            "\t\t */",
            "\t\tif (data_race(prev->next) == node &&",
            "\t\t    cmpxchg(&prev->next, node, NULL) == node)",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * We can only fail the cmpxchg() racing against an unlock(),",
            "\t\t * in which case we should observe @node->locked becoming",
            "\t\t * true.",
            "\t\t */",
            "\t\tif (smp_load_acquire(&node->locked))",
            "\t\t\treturn true;",
            "",
            "\t\tcpu_relax();",
            "",
            "\t\t/*",
            "\t\t * Or we race against a concurrent unqueue()'s step-B, in which",
            "\t\t * case its step-C will write us a new @node->prev pointer.",
            "\t\t */",
            "\t\tprev = READ_ONCE(node->prev);",
            "\t}",
            "",
            "\t/*",
            "\t * Step - B -- stabilize @next",
            "\t *",
            "\t * Similar to unlock(), wait for @node->next or move @lock from @node",
            "\t * back to @prev.",
            "\t */",
            "",
            "\tnext = osq_wait_next(lock, node, prev);",
            "\tif (!next)",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Step - C -- unlink",
            "\t *",
            "\t * @prev is stable because its still waiting for a new @prev->next",
            "\t * pointer, @next is stable because our @node->next pointer is NULL and",
            "\t * it will wait in Step-A.",
            "\t */",
            "",
            "\tWRITE_ONCE(next->prev, prev);",
            "\tWRITE_ONCE(prev->next, next);",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "encode_cpu, node_cpu, osq_lock",
          "description": "实现osq_lock函数，负责获取乐观自旋锁。通过原子操作将当前节点插入队列，利用内存屏障保证顺序一致性，并通过循环等待条件满足或被唤醒，最终完成锁的获取过程。",
          "similarity": 0.5198639631271362
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/osq_lock.c",
          "start_line": 1,
          "end_line": 19,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/percpu.h>",
            "#include <linux/sched.h>",
            "#include <linux/osq_lock.h>",
            "",
            "/*",
            " * An MCS like lock especially tailored for optimistic spinning for sleeping",
            " * lock implementations (mutex, rwsem, etc).",
            " *",
            " * Using a single mcs node per CPU is safe because sleeping locks should not be",
            " * called from interrupt context and we have preemption disabled while",
            " * spinning.",
            " */",
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);",
            "",
            "/*",
            " * We use the value 0 to represent \"no CPU\", thus the encoded value",
            " * will be the CPU number incremented by 1.",
            " */"
          ],
          "function_name": null,
          "description": "定义全局的per-CPU乐观自旋节点osq_node，用于支持多CPU环境下乐观自旋锁的实现。通过encode_cpu和node_cpu函数处理CPU编号转换，为后续锁操作提供基础设施。",
          "similarity": 0.44930389523506165
        }
      ]
    },
    {
      "source_file": "kernel/locking/spinlock_rt.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:55:06\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\spinlock_rt.c`\n\n---\n\n# `locking/spinlock_rt.c` 技术文档\n\n## 1. 文件概述\n\n`spinlock_rt.c` 是 Linux 内核中 **PREEMPT_RT（实时抢占）补丁** 的核心实现文件之一，用于在实时内核中替代传统的自旋锁（`spinlock_t`）和读写锁（`rwlock_t`）。  \n在 PREEMPT_RT 模型下，传统的“忙等”自旋锁语义被基于 **RT-Mutex（实时互斥锁）** 的可睡眠锁机制所取代，同时通过额外机制（如禁用迁移、RCU 读侧锁定）来**模拟原始自旋锁的语义行为**，确保实时性和正确性。\n\n该文件实现了：\n- 实时版本的自旋锁（`rt_spin_lock/unlock/trylock`）\n- 实时版本的读写锁（`rt_read/write_lock/unlock/trylock`）\n- 与 Lockdep（锁依赖验证器）和 RCU（读-拷贝-更新）机制的集成\n\n## 2. 核心功能\n\n### 主要函数\n\n#### 自旋锁相关\n- `rt_spin_lock(spinlock_t *lock)`：获取实时自旋锁\n- `rt_spin_unlock(spinlock_t *lock)`：释放实时自旋锁\n- `rt_spin_trylock(spinlock_t *lock)`：尝试非阻塞获取锁\n- `rt_spin_trylock_bh(spinlock_t *lock)`：在禁用软中断上下文中尝试获取锁\n- `rt_spin_lock_unlock(spinlock_t *lock)`：用于等待锁释放的辅助函数（先锁后立即释放）\n- `rt_spin_lock_nested()` / `rt_spin_lock_nest_lock()`：支持锁嵌套的调试版本\n- `__rt_spin_lock_init()`：锁初始化（调试模式）\n\n#### 读写锁相关\n- `rt_read_lock(rwlock_t *rwlock)` / `rt_write_lock(rwlock_t *rwlock)`：获取读/写锁\n- `rt_read_unlock(rwlock_t *rwlock)` / `rt_write_unlock(rwlock_t *rwlock)`：释放读/写锁\n- `rt_read_trylock(rwlock_t *rwlock)` / `rt_write_trylock(rwlock_t *rwlock)`：尝试获取读/写锁\n- `rt_write_lock_nested()`：支持写锁嵌套的调试版本\n- `__rt_rwlock_init()`：读写锁初始化（调试模式）\n\n### 关键内联函数与宏\n- `__rt_spin_lock()`：自旋锁获取的核心内联实现\n- `rtlock_lock()`：封装 RT-Mutex 获取逻辑\n- `rtlock_might_resched()`：用于 `might_sleep()` 检查的变体，考虑 RCU 嵌套\n- `rwbase_*` 系列宏：为 `rwbase_rt.c` 提供 RT 特定的底层操作接口\n\n## 3. 关键实现\n\n### 3.1 基于 RT-Mutex 的锁实现\n- 所有锁操作底层均使用 `rt_mutex_base` 结构。\n- 快速路径使用 `rt_mutex_cmpxchg_acquire/release` 原子操作尝试获取/释放锁。\n- 慢速路径（竞争时）调用 `rtlock_slowlock()`、`rt_mutex_slowunlock()` 等函数，这些函数定义在 `rtmutex.c` 中（通过 `#include \"rtmutex.c\"` 复用代码）。\n\n### 3.2 状态保存与恢复（State Preservation）\n- 当任务因锁竞争而阻塞时，**保存当前任务状态**（通过 `current_save_and_set_rtlock_wait_state()`）。\n- 在获取锁后**恢复原始状态**（通过 `current_restore_rtlock_saved_state()`）。\n- 此机制确保在阻塞期间的唤醒信号不会丢失，并维持任务状态一致性。\n\n### 3.3 模拟传统自旋锁语义\n传统自旋锁在持有期间会：\n- **禁用抢占** → 实时版本通过 `migrate_disable()` 禁用 CPU 迁移（等效于禁止负载均衡迁移，但允许抢占）。\n- **隐式 RCU 读侧临界区** → 实时版本显式调用 `rcu_read_lock()` / `rcu_read_unlock()`。\n\n### 3.4 与调度器集成\n- 阻塞时调用 `schedule_rtlock()`（由 `rwbase_schedule()` 宏定义），这是专为 RT 锁设计的调度点。\n- 使用 `TASK_RTLOCK_WAIT` 作为任务等待状态。\n\n### 3.5 Lockdep 集成\n- 所有锁操作均调用 `spin_acquire()` / `spin_release()` 或 `rwlock_acquire()` / `rwlock_release()`，向 Lockdep 提供锁依赖信息。\n- 支持锁类子类（`subclass`）和嵌套锁（`nest_lock`）的调试功能。\n\n### 3.6 RCU 感知的 `might_sleep` 检查\n- `rtlock_might_resched()` 宏在调用 `__might_resched()` 时传入 `RCU` 嵌套深度偏移量，避免在合法 RCU 临界区内误报睡眠警告。\n\n## 4. 依赖关系\n\n- **`rtmutex.c`**：通过 `#define RT_MUTEX_BUILD_SPINLOCKS` 和 `#include \"rtmutex.c\"` 复用 RT-Mutex 的慢速路径实现。\n- **`rwbase_rt.c`**：通过宏定义（如 `rwbase_rtmutex_lock_state`）提供读写锁的通用逻辑，本文件提供 RT 特定的底层操作。\n- **`<linux/spinlock.h>`**：定义 `spinlock_t`、`rwlock_t` 及相关 API。\n- **`<linux/rcupdate.h>`**：使用 `rcu_read_lock()` / `rcu_read_unlock()`。\n- **`<linux/migrate.h>`**：使用 `migrate_disable()` / `migrate_enable()`。\n- **Lockdep 子系统**：通过 `spin_acquire`/`release` 等接口集成锁依赖验证。\n- **调度器**：依赖 `schedule_rtlock()` 实现阻塞调度。\n\n## 5. 使用场景\n\n- **PREEMPT_RT 内核配置**：仅在 `CONFIG_PREEMPT_RT` 启用时编译和使用。\n- **替换传统自旋锁/读写锁**：内核中所有 `spin_lock()`、`read_lock()` 等调用在 RT 内核中会重定向到本文件中的 `rt_*` 函数。\n- **实时任务同步**：为高优先级实时任务提供可预测的锁行为，避免传统自旋锁导致的优先级反转和不可抢占问题。\n- **驱动和子系统开发**：开发者无需修改代码，PREEMPT_RT 会自动将锁语义转换为实时安全版本。\n- **调试支持**：在 `CONFIG_DEBUG_LOCK_ALLOC` 启用时，提供锁初始化、嵌套和依赖跟踪功能。",
      "similarity": 0.5198768973350525,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/spinlock_rt.c",
          "start_line": 38,
          "end_line": 138,
          "content": [
            "static __always_inline void rtlock_lock(struct rt_mutex_base *rtm)",
            "{",
            "\tlockdep_assert(!current->pi_blocked_on);",
            "",
            "\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))",
            "\t\trtlock_slowlock(rtm);",
            "}",
            "static __always_inline void __rt_spin_lock(spinlock_t *lock)",
            "{",
            "\trtlock_might_resched();",
            "\trtlock_lock(&lock->lock);",
            "\trcu_read_lock();",
            "\tmigrate_disable();",
            "}",
            "void __sched rt_spin_lock(spinlock_t *lock)",
            "{",
            "\tspin_acquire(&lock->dep_map, 0, 0, _RET_IP_);",
            "\t__rt_spin_lock(lock);",
            "}",
            "void __sched rt_spin_lock_nested(spinlock_t *lock, int subclass)",
            "{",
            "\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);",
            "\t__rt_spin_lock(lock);",
            "}",
            "void __sched rt_spin_lock_nest_lock(spinlock_t *lock,",
            "\t\t\t\t    struct lockdep_map *nest_lock)",
            "{",
            "\tspin_acquire_nest(&lock->dep_map, 0, 0, nest_lock, _RET_IP_);",
            "\t__rt_spin_lock(lock);",
            "}",
            "void __sched rt_spin_unlock(spinlock_t *lock)",
            "{",
            "\tspin_release(&lock->dep_map, _RET_IP_);",
            "\tmigrate_enable();",
            "\trcu_read_unlock();",
            "",
            "\tif (unlikely(!rt_mutex_cmpxchg_release(&lock->lock, current, NULL)))",
            "\t\trt_mutex_slowunlock(&lock->lock);",
            "}",
            "void __sched rt_spin_lock_unlock(spinlock_t *lock)",
            "{",
            "\tspin_lock(lock);",
            "\tspin_unlock(lock);",
            "}",
            "static __always_inline int __rt_spin_trylock(spinlock_t *lock)",
            "{",
            "\tint ret = 1;",
            "",
            "\tif (unlikely(!rt_mutex_cmpxchg_acquire(&lock->lock, NULL, current)))",
            "\t\tret = rt_mutex_slowtrylock(&lock->lock);",
            "",
            "\tif (ret) {",
            "\t\tspin_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "\t\trcu_read_lock();",
            "\t\tmigrate_disable();",
            "\t}",
            "\treturn ret;",
            "}",
            "int __sched rt_spin_trylock(spinlock_t *lock)",
            "{",
            "\treturn __rt_spin_trylock(lock);",
            "}",
            "int __sched rt_spin_trylock_bh(spinlock_t *lock)",
            "{",
            "\tint ret;",
            "",
            "\tlocal_bh_disable();",
            "\tret = __rt_spin_trylock(lock);",
            "\tif (!ret)",
            "\t\tlocal_bh_enable();",
            "\treturn ret;",
            "}",
            "void __rt_spin_lock_init(spinlock_t *lock, const char *name,",
            "\t\t\t struct lock_class_key *key, bool percpu)",
            "{",
            "\tu8 type = percpu ? LD_LOCK_PERCPU : LD_LOCK_NORMAL;",
            "",
            "\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));",
            "\tlockdep_init_map_type(&lock->dep_map, name, key, 0, LD_WAIT_CONFIG,",
            "\t\t\t      LD_WAIT_INV, type);",
            "}",
            "static __always_inline int",
            "rwbase_rtmutex_lock_state(struct rt_mutex_base *rtm, unsigned int state)",
            "{",
            "\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))",
            "\t\trtlock_slowlock(rtm);",
            "\treturn 0;",
            "}",
            "static __always_inline int",
            "rwbase_rtmutex_slowlock_locked(struct rt_mutex_base *rtm, unsigned int state)",
            "{",
            "\trtlock_slowlock_locked(rtm);",
            "\treturn 0;",
            "}",
            "static __always_inline void rwbase_rtmutex_unlock(struct rt_mutex_base *rtm)",
            "{",
            "\tif (likely(rt_mutex_cmpxchg_acquire(rtm, current, NULL)))",
            "\t\treturn;",
            "",
            "\trt_mutex_slowunlock(rtm);",
            "}"
          ],
          "function_name": "rtlock_lock, __rt_spin_lock, rt_spin_lock, rt_spin_lock_nested, rt_spin_lock_nest_lock, rt_spin_unlock, rt_spin_lock_unlock, __rt_spin_trylock, rt_spin_trylock, rt_spin_trylock_bh, __rt_spin_lock_init, rwbase_rtmutex_lock_state, rwbase_rtmutex_slowlock_locked, rwbase_rtmutex_unlock",
          "description": "实现自旋锁的加锁/解锁逻辑，通过rt_mutex进行状态同步，禁用迁移并维护RCU读锁，在慢路径中处理阻塞唤醒，集成锁依赖检查和抢占状态管理",
          "similarity": 0.507716953754425
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/spinlock_rt.c",
          "start_line": 179,
          "end_line": 253,
          "content": [
            "static __always_inline int  rwbase_rtmutex_trylock(struct rt_mutex_base *rtm)",
            "{",
            "\tif (likely(rt_mutex_cmpxchg_acquire(rtm, NULL, current)))",
            "\t\treturn 1;",
            "",
            "\treturn rt_mutex_slowtrylock(rtm);",
            "}",
            "int __sched rt_read_trylock(rwlock_t *rwlock)",
            "{",
            "\tint ret;",
            "",
            "\tret = rwbase_read_trylock(&rwlock->rwbase);",
            "\tif (ret) {",
            "\t\trwlock_acquire_read(&rwlock->dep_map, 0, 1, _RET_IP_);",
            "\t\trcu_read_lock();",
            "\t\tmigrate_disable();",
            "\t}",
            "\treturn ret;",
            "}",
            "int __sched rt_write_trylock(rwlock_t *rwlock)",
            "{",
            "\tint ret;",
            "",
            "\tret = rwbase_write_trylock(&rwlock->rwbase);",
            "\tif (ret) {",
            "\t\trwlock_acquire(&rwlock->dep_map, 0, 1, _RET_IP_);",
            "\t\trcu_read_lock();",
            "\t\tmigrate_disable();",
            "\t}",
            "\treturn ret;",
            "}",
            "void __sched rt_read_lock(rwlock_t *rwlock)",
            "{",
            "\trtlock_might_resched();",
            "\trwlock_acquire_read(&rwlock->dep_map, 0, 0, _RET_IP_);",
            "\trwbase_read_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);",
            "\trcu_read_lock();",
            "\tmigrate_disable();",
            "}",
            "void __sched rt_write_lock(rwlock_t *rwlock)",
            "{",
            "\trtlock_might_resched();",
            "\trwlock_acquire(&rwlock->dep_map, 0, 0, _RET_IP_);",
            "\trwbase_write_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);",
            "\trcu_read_lock();",
            "\tmigrate_disable();",
            "}",
            "void __sched rt_write_lock_nested(rwlock_t *rwlock, int subclass)",
            "{",
            "\trtlock_might_resched();",
            "\trwlock_acquire(&rwlock->dep_map, subclass, 0, _RET_IP_);",
            "\trwbase_write_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);",
            "\trcu_read_lock();",
            "\tmigrate_disable();",
            "}",
            "void __sched rt_read_unlock(rwlock_t *rwlock)",
            "{",
            "\trwlock_release(&rwlock->dep_map, _RET_IP_);",
            "\tmigrate_enable();",
            "\trcu_read_unlock();",
            "\trwbase_read_unlock(&rwlock->rwbase, TASK_RTLOCK_WAIT);",
            "}",
            "void __sched rt_write_unlock(rwlock_t *rwlock)",
            "{",
            "\trwlock_release(&rwlock->dep_map, _RET_IP_);",
            "\trcu_read_unlock();",
            "\tmigrate_enable();",
            "\trwbase_write_unlock(&rwlock->rwbase);",
            "}",
            "void __rt_rwlock_init(rwlock_t *rwlock, const char *name,",
            "\t\t      struct lock_class_key *key)",
            "{",
            "\tdebug_check_no_locks_freed((void *)rwlock, sizeof(*rwlock));",
            "\tlockdep_init_map_wait(&rwlock->dep_map, name, key, 0, LD_WAIT_CONFIG);",
            "}"
          ],
          "function_name": "rwbase_rtmutex_trylock, rt_read_trylock, rt_write_trylock, rt_read_lock, rt_write_lock, rt_write_lock_nested, rt_read_unlock, rt_write_unlock, __rt_rwlock_init",
          "description": "提供读写锁的获取/释放接口，基于rtmutex实现读写状态控制，强制RCU读锁和迁移禁止，在解锁时恢复RCU状态并释放底层互斥体，支持嵌套子类锁配置",
          "similarity": 0.495970755815506
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/spinlock_rt.c",
          "start_line": 1,
          "end_line": 37,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * PREEMPT_RT substitution for spin/rw_locks",
            " *",
            " * spinlocks and rwlocks on RT are based on rtmutexes, with a few twists to",
            " * resemble the non RT semantics:",
            " *",
            " * - Contrary to plain rtmutexes, spinlocks and rwlocks are state",
            " *   preserving. The task state is saved before blocking on the underlying",
            " *   rtmutex, and restored when the lock has been acquired. Regular wakeups",
            " *   during that time are redirected to the saved state so no wake up is",
            " *   missed.",
            " *",
            " * - Non RT spin/rwlocks disable preemption and eventually interrupts.",
            " *   Disabling preemption has the side effect of disabling migration and",
            " *   preventing RCU grace periods.",
            " *",
            " *   The RT substitutions explicitly disable migration and take",
            " *   rcu_read_lock() across the lock held section.",
            " */",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "",
            "#define RT_MUTEX_BUILD_SPINLOCKS",
            "#include \"rtmutex.c\"",
            "",
            "/*",
            " * __might_resched() skips the state check as rtlocks are state",
            " * preserving. Take RCU nesting into account as spin/read/write_lock() can",
            " * legitimately nest into an RCU read side critical section.",
            " */",
            "#define RTLOCK_RESCHED_OFFSETS\t\t\t\t\t\t\\",
            "\t(rcu_preempt_depth() << MIGHT_RESCHED_RCU_SHIFT)",
            "",
            "#define rtlock_might_resched()\t\t\t\t\t\t\\",
            "\t__might_resched(__FILE__, __LINE__, RTLOCK_RESCHED_OFFSETS)",
            ""
          ],
          "function_name": null,
          "description": "定义PREEMPT_RT下的自旋锁和读写锁实现，基于rtmutex并保留任务状态，通过宏定义和头文件引入核心机制，处理抢占禁用、迁移禁止及RCU嵌套问题",
          "similarity": 0.4876028001308441
        }
      ]
    },
    {
      "source_file": "kernel/locking/rtmutex_api.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:49:05\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\rtmutex_api.c`\n\n---\n\n# `locking/rtmutex_api.c` 技术文档\n\n## 1. 文件概述\n\n`rtmutex_api.c` 是 Linux 内核中实时互斥锁（Real-Time Mutex, rtmutex）的公共 API 实现文件。该文件封装了底层 rtmutex 核心逻辑（定义在 `rtmutex.c` 中），为内核其他子系统提供统一、安全、可调试的互斥锁操作接口。它支持多种锁获取模式（不可中断、可中断、可终止）、调试锁依赖（lockdep）、PI（Priority Inheritance，优先级继承）机制，并为 futex（快速用户空间互斥）提供专用变体接口。该文件通过条件编译适配是否启用锁调试功能（`CONFIG_DEBUG_LOCK_ALLOC`）。\n\n## 2. 核心功能\n\n### 全局变量\n- `max_lock_depth`: 定义优先级继承链（boosting chain）的最大遍历深度，防止死锁检测时无限循环，默认值为 1024。\n\n### 主要函数\n\n#### 初始化与销毁\n- `rt_mutex_base_init()`: 初始化 `rt_mutex_base` 结构体的基础字段。\n- `__rt_mutex_init()`: 完整初始化一个 `rt_mutex`，包括底层 rtmutex 和 lockdep 调试信息。\n- `rt_mutex_init_proxy_locked()`: 为 PI-futex 场景初始化并立即锁定 rtmutex，指定代理持有者（proxy owner）。\n- `rt_mutex_proxy_unlock()`: 为 PI-futex 场景释放由代理持有的 rtmutex。\n\n#### 锁获取（Locking）\n- `rt_mutex_lock[_nested]()`: 以不可中断方式获取 rtmutex（支持 lockdep 嵌套子类）。\n- `_rt_mutex_lock_nest_lock()`: 获取 rtmutex 并关联一个嵌套锁（nest lock）用于 lockdep。\n- `rt_mutex_lock_interruptible()`: 以可被信号中断的方式获取 rtmutex。\n- `rt_mutex_lock_killable()`: 以可被致命信号中断的方式获取 rtmutex。\n- `rt_mutex_trylock()`: 尝试非阻塞获取 rtmutex，成功返回 1，失败返回 0。\n\n#### 锁释放（Unlocking）\n- `rt_mutex_unlock()`: 释放 rtmutex。\n- `rt_mutex_futex_unlock()`: 专用于 futex 的 rtmutex 释放接口。\n- `__rt_mutex_futex_unlock()`: futex 释放的内部实现，需配合 `rt_mutex_postunlock()` 使用。\n\n#### Futex 专用接口\n- `rt_mutex_futex_trylock()`: futex 使用的非阻塞尝试锁接口。\n- `__rt_mutex_futex_trylock()`: futex 尝试锁的底层实现。\n\n#### 代理锁操作（Proxy Locking，用于 PI-futex）\n- `__rt_mutex_start_proxy_lock()`: 为另一个任务启动代理锁获取流程（仅入队，不阻塞等待）。\n\n## 3. 关键实现\n\n### 锁操作通用封装\n- `__rt_mutex_lock_common()` 是所有阻塞式锁获取函数的统一入口。它负责：\n  - 调用 `might_sleep()` 提示可能睡眠。\n  - 通过 `mutex_acquire_nest()` 向 lockdep 子系统注册锁获取事件。\n  - 调用底层 `__rt_mutex_lock()` 执行实际的锁逻辑。\n  - 若获取失败（如被信号中断），则调用 `mutex_release()` 通知 lockdep 释放。\n\n### 调试支持\n- 在 `CONFIG_DEBUG_LOCK_ALLOC` 启用时，提供带 lockdep 子类和嵌套锁参数的锁接口（如 `rt_mutex_lock_nested`），增强死锁检测能力。\n- `rt_mutex_trylock()` 在调试模式下会检查调用上下文是否为任务上下文（`in_task()`），防止在中断上下文中误用。\n- 初始化函数 `__rt_mutex_init()` 调用 `debug_check_no_locks_freed()` 防止对已释放内存初始化锁。\n\n### Futex 特殊处理\n- Futex 相关接口（如 `rt_mutex_futex_unlock`）绕过 rtmutex 的 fast-path，直接使用 slow-path 实现。\n- `rt_mutex_init_proxy_locked()` 为 PI-futex 场景中的 `wait_lock` 分配独立的 lockdep 类键（`pi_futex_key`），避免与 futex 哈希桶自旋锁产生虚假的锁递归警告。\n- `__rt_mutex_futex_unlock()` 在释放锁时，若存在等待者，则调用 `mark_wakeup_next_waiter()` 准备唤醒，并返回 `true` 指示需后续调用 `rt_mutex_postunlock()` 完成唤醒。\n\n### 代理锁机制\n- 代理锁函数（如 `rt_mutex_init_proxy_locked` 和 `__rt_mutex_start_proxy_lock`）用于 PI-futex 实现，允许内核代表用户空间任务持有或竞争锁，是优先级继承在 futex 上的关键支撑。\n\n## 4. 依赖关系\n\n- **底层实现**: 通过 `#include \"rtmutex.c\"`（配合 `RT_MUTEX_BUILD_MUTEX` 宏）内联包含 `rtmutex.c` 中的核心逻辑（如 `__rt_mutex_lock`, `__rt_mutex_unlock` 等）。\n- **同步原语**: 依赖 `<linux/spinlock.h>` 提供自旋锁操作（如 `raw_spin_lock_irqsave`）。\n- **调试子系统**: \n  - 依赖 Lockdep（`<linux/lockdep.h>` 隐式包含）进行锁依赖和死锁检测。\n  - 依赖 RT Mutex 调试（`CONFIG_DEBUG_RT_MUTEXES`）进行运行时检查。\n- **调度器**: 使用 `TASK_*` 状态常量（如 `TASK_INTERRUPTIBLE`）与调度器交互，支持可中断睡眠。\n- **导出符号**: 通过 `EXPORT_SYMBOL` 和 `EXPORT_SYMBOL_GPL` 向内核其他模块（如 futex、PI 子系统）提供 API。\n\n## 5. 使用场景\n\n- **实时互斥锁**: 作为内核中支持优先级继承的互斥锁实现，用于需要避免优先级反转的实时任务同步。\n- **PI-futex 支持**: 为用户空间的 PI-aware futex（`FUTEX_LOCK_PI` 等操作）提供内核态代理锁管理，实现跨进程的优先级继承。\n- **内核子系统同步**: 被需要强优先级继承语义的内核子系统（如某些设备驱动、实时调度相关代码）直接使用。\n- **调试与验证**: 在启用锁调试的内核配置下，为 lockdep 提供详细的锁获取/释放轨迹，辅助死锁分析。",
      "similarity": 0.5044243931770325,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 590,
          "end_line": 607,
          "content": [
            "int __sched mutex_trylock(struct mutex *lock)",
            "{",
            "\tint ret;",
            "",
            "\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))",
            "\t\treturn 0;",
            "",
            "\tret = __rt_mutex_trylock(&lock->rtmutex);",
            "\tif (ret)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn ret;",
            "}",
            "void __sched mutex_unlock(struct mutex *lock)",
            "{",
            "\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\t__rt_mutex_unlock(&lock->rtmutex);",
            "}"
          ],
          "function_name": "mutex_trylock, mutex_unlock",
          "description": "实现互斥锁的尝试获取和释放操作，通过底层rtmutex_trylock进行非阻塞获取，成功时记录锁占用状态，释放时触发锁依赖跟踪和底层解锁流程。",
          "similarity": 0.5517550110816956
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 22,
          "end_line": 127,
          "content": [
            "static __always_inline int __rt_mutex_lock_common(struct rt_mutex *lock,",
            "\t\t\t\t\t\t  unsigned int state,",
            "\t\t\t\t\t\t  struct lockdep_map *nest_lock,",
            "\t\t\t\t\t\t  unsigned int subclass)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, _RET_IP_);",
            "\tret = __rt_mutex_lock(&lock->rtmutex, state);",
            "\tif (ret)",
            "\t\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\treturn ret;",
            "}",
            "void rt_mutex_base_init(struct rt_mutex_base *rtb)",
            "{",
            "\t__rt_mutex_base_init(rtb);",
            "}",
            "void __sched rt_mutex_lock_nested(struct rt_mutex *lock, unsigned int subclass)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, subclass);",
            "}",
            "void __sched _rt_mutex_lock_nest_lock(struct rt_mutex *lock, struct lockdep_map *nest_lock)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, nest_lock, 0);",
            "}",
            "void __sched rt_mutex_lock(struct rt_mutex *lock)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_lock_interruptible(struct rt_mutex *lock)",
            "{",
            "\treturn __rt_mutex_lock_common(lock, TASK_INTERRUPTIBLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_lock_killable(struct rt_mutex *lock)",
            "{",
            "\treturn __rt_mutex_lock_common(lock, TASK_KILLABLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_trylock(struct rt_mutex *lock)",
            "{",
            "\tint ret;",
            "",
            "\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))",
            "\t\treturn 0;",
            "",
            "\tret = __rt_mutex_trylock(&lock->rtmutex);",
            "\tif (ret)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn ret;",
            "}",
            "void __sched rt_mutex_unlock(struct rt_mutex *lock)",
            "{",
            "\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\t__rt_mutex_unlock(&lock->rtmutex);",
            "}",
            "int __sched rt_mutex_futex_trylock(struct rt_mutex_base *lock)",
            "{",
            "\treturn rt_mutex_slowtrylock(lock);",
            "}",
            "int __sched __rt_mutex_futex_trylock(struct rt_mutex_base *lock)",
            "{",
            "\treturn __rt_mutex_slowtrylock(lock);",
            "}",
            "bool __sched __rt_mutex_futex_unlock(struct rt_mutex_base *lock,",
            "\t\t\t\t     struct rt_wake_q_head *wqh)",
            "{",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tdebug_rt_mutex_unlock(lock);",
            "",
            "\tif (!rt_mutex_has_waiters(lock)) {",
            "\t\tlock->owner = NULL;",
            "\t\treturn false; /* done */",
            "\t}",
            "",
            "\t/*",
            "\t * We've already deboosted, mark_wakeup_next_waiter() will",
            "\t * retain preempt_disabled when we drop the wait_lock, to",
            "\t * avoid inversion prior to the wakeup.  preempt_disable()",
            "\t * therein pairs with rt_mutex_postunlock().",
            "\t */",
            "\tmark_wakeup_next_waiter(wqh, lock);",
            "",
            "\treturn true; /* call postunlock() */",
            "}",
            "void __sched rt_mutex_futex_unlock(struct rt_mutex_base *lock)",
            "{",
            "\tDEFINE_RT_WAKE_Q(wqh);",
            "\tunsigned long flags;",
            "\tbool postunlock;",
            "",
            "\traw_spin_lock_irqsave(&lock->wait_lock, flags);",
            "\tpostunlock = __rt_mutex_futex_unlock(lock, &wqh);",
            "\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);",
            "",
            "\tif (postunlock)",
            "\t\trt_mutex_postunlock(&wqh);",
            "}",
            "void __sched __rt_mutex_init(struct rt_mutex *lock, const char *name,",
            "\t\t\t     struct lock_class_key *key)",
            "{",
            "\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));",
            "\t__rt_mutex_base_init(&lock->rtmutex);",
            "\tlockdep_init_map_wait(&lock->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "}"
          ],
          "function_name": "__rt_mutex_lock_common, rt_mutex_base_init, rt_mutex_lock_nested, _rt_mutex_lock_nest_lock, rt_mutex_lock, rt_mutex_lock_interruptible, rt_mutex_lock_killable, rt_mutex_trylock, rt_mutex_unlock, rt_mutex_futex_trylock, __rt_mutex_futex_trylock, __rt_mutex_futex_unlock, rt_mutex_futex_unlock, __rt_mutex_init",
          "description": "实现多种rtmutex操作接口，包括常规加锁、尝试加锁、解锁及嵌套锁管理，通过统一入口函数处理不同睡眠状态和锁依赖追踪，维护锁状态转换和抢占控制。",
          "similarity": 0.4845591187477112
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 236,
          "end_line": 354,
          "content": [
            "void __sched rt_mutex_init_proxy_locked(struct rt_mutex_base *lock,",
            "\t\t\t\t\tstruct task_struct *proxy_owner)",
            "{",
            "\tstatic struct lock_class_key pi_futex_key;",
            "",
            "\t__rt_mutex_base_init(lock);",
            "\t/*",
            "\t * On PREEMPT_RT the futex hashbucket spinlock becomes 'sleeping'",
            "\t * and rtmutex based. That causes a lockdep false positive, because",
            "\t * some of the futex functions invoke spin_unlock(&hb->lock) with",
            "\t * the wait_lock of the rtmutex associated to the pi_futex held.",
            "\t * spin_unlock() in turn takes wait_lock of the rtmutex on which",
            "\t * the spinlock is based, which makes lockdep notice a lock",
            "\t * recursion. Give the futex/rtmutex wait_lock a separate key.",
            "\t */",
            "\tlockdep_set_class(&lock->wait_lock, &pi_futex_key);",
            "\trt_mutex_set_owner(lock, proxy_owner);",
            "}",
            "void __sched rt_mutex_proxy_unlock(struct rt_mutex_base *lock)",
            "{",
            "\tdebug_rt_mutex_proxy_unlock(lock);",
            "\trt_mutex_clear_owner(lock);",
            "}",
            "int __sched __rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t\tstruct rt_mutex_waiter *waiter,",
            "\t\t\t\t\tstruct task_struct *task)",
            "{",
            "\tint ret;",
            "",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tif (try_to_take_rt_mutex(lock, task, NULL))",
            "\t\treturn 1;",
            "",
            "\t/* We enforce deadlock detection for futexes */",
            "\tret = task_blocks_on_rt_mutex(lock, waiter, task, NULL,",
            "\t\t\t\t      RT_MUTEX_FULL_CHAINWALK);",
            "",
            "\tif (ret && !rt_mutex_owner(lock)) {",
            "\t\t/*",
            "\t\t * Reset the return value. We might have",
            "\t\t * returned with -EDEADLK and the owner",
            "\t\t * released the lock while we were walking the",
            "\t\t * pi chain.  Let the waiter sort it out.",
            "\t\t */",
            "\t\tret = 0;",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "int __sched rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t      struct rt_mutex_waiter *waiter,",
            "\t\t\t\t      struct task_struct *task)",
            "{",
            "\tint ret;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\tret = __rt_mutex_start_proxy_lock(lock, waiter, task);",
            "\tif (unlikely(ret))",
            "\t\tremove_waiter(lock, waiter);",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn ret;",
            "}",
            "int __sched rt_mutex_wait_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t     struct hrtimer_sleeper *to,",
            "\t\t\t\t     struct rt_mutex_waiter *waiter)",
            "{",
            "\tint ret;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\t/* sleep on the mutex */",
            "\tset_current_state(TASK_INTERRUPTIBLE);",
            "\tret = rt_mutex_slowlock_block(lock, NULL, TASK_INTERRUPTIBLE, to, waiter);",
            "\t/*",
            "\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might",
            "\t * have to fix that up.",
            "\t */",
            "\tfixup_rt_mutex_waiters(lock, true);",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn ret;",
            "}",
            "bool __sched rt_mutex_cleanup_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t\t struct rt_mutex_waiter *waiter)",
            "{",
            "\tbool cleanup = false;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\t/*",
            "\t * Do an unconditional try-lock, this deals with the lock stealing",
            "\t * state where __rt_mutex_futex_unlock() -> mark_wakeup_next_waiter()",
            "\t * sets a NULL owner.",
            "\t *",
            "\t * We're not interested in the return value, because the subsequent",
            "\t * test on rt_mutex_owner() will infer that. If the trylock succeeded,",
            "\t * we will own the lock and it will have removed the waiter. If we",
            "\t * failed the trylock, we're still not owner and we need to remove",
            "\t * ourselves.",
            "\t */",
            "\ttry_to_take_rt_mutex(lock, current, waiter);",
            "\t/*",
            "\t * Unless we're the owner; we're still enqueued on the wait_list.",
            "\t * So check if we became owner, if not, take us off the wait_list.",
            "\t */",
            "\tif (rt_mutex_owner(lock) != current) {",
            "\t\tremove_waiter(lock, waiter);",
            "\t\tcleanup = true;",
            "\t}",
            "\t/*",
            "\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might",
            "\t * have to fix that up.",
            "\t */",
            "\tfixup_rt_mutex_waiters(lock, false);",
            "",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn cleanup;",
            "}"
          ],
          "function_name": "rt_mutex_init_proxy_locked, rt_mutex_proxy_unlock, __rt_mutex_start_proxy_lock, rt_mutex_start_proxy_lock, rt_mutex_wait_proxy_lock, rt_mutex_cleanup_proxy_lock",
          "description": "处理锁代理机制，包含代理锁初始化、释放逻辑及死锁检测流程，通过遍历锁链进行优先级继承调整，确保多线程环境下的锁所有权安全转移。",
          "similarity": 0.4722486734390259
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 453,
          "end_line": 554,
          "content": [
            "void __sched rt_mutex_adjust_pi(struct task_struct *task)",
            "{",
            "\tstruct rt_mutex_waiter *waiter;",
            "\tstruct rt_mutex_base *next_lock;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&task->pi_lock, flags);",
            "",
            "\twaiter = task->pi_blocked_on;",
            "\tif (!waiter || rt_waiter_node_equal(&waiter->tree, task_to_waiter_node(task))) {",
            "\t\traw_spin_unlock_irqrestore(&task->pi_lock, flags);",
            "\t\treturn;",
            "\t}",
            "\tnext_lock = waiter->lock;",
            "\traw_spin_unlock_irqrestore(&task->pi_lock, flags);",
            "",
            "\t/* gets dropped in rt_mutex_adjust_prio_chain()! */",
            "\tget_task_struct(task);",
            "",
            "\trt_mutex_adjust_prio_chain(task, RT_MUTEX_MIN_CHAINWALK, NULL,",
            "\t\t\t\t   next_lock, NULL, task);",
            "}",
            "void __sched rt_mutex_postunlock(struct rt_wake_q_head *wqh)",
            "{",
            "\trt_mutex_wake_up_q(wqh);",
            "}",
            "void rt_mutex_debug_task_free(struct task_struct *task)",
            "{",
            "\tDEBUG_LOCKS_WARN_ON(!RB_EMPTY_ROOT(&task->pi_waiters.rb_root));",
            "\tDEBUG_LOCKS_WARN_ON(task->pi_blocked_on);",
            "}",
            "void __mutex_rt_init(struct mutex *mutex, const char *name,",
            "\t\t     struct lock_class_key *key)",
            "{",
            "\tdebug_check_no_locks_freed((void *)mutex, sizeof(*mutex));",
            "\tlockdep_init_map_wait(&mutex->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "}",
            "static __always_inline int __mutex_lock_common(struct mutex *lock,",
            "\t\t\t\t\t       unsigned int state,",
            "\t\t\t\t\t       unsigned int subclass,",
            "\t\t\t\t\t       struct lockdep_map *nest_lock,",
            "\t\t\t\t\t       unsigned long ip)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);",
            "\tret = __rt_mutex_lock(&lock->rtmutex, state);",
            "\tif (ret)",
            "\t\tmutex_release(&lock->dep_map, ip);",
            "\telse",
            "\t\tlock_acquired(&lock->dep_map, ip);",
            "\treturn ret;",
            "}",
            "void __sched mutex_lock_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched _mutex_lock_nest_lock(struct mutex *lock,",
            "\t\t\t\t   struct lockdep_map *nest_lock)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, nest_lock, _RET_IP_);",
            "}",
            "int __sched mutex_lock_interruptible_nested(struct mutex *lock,",
            "\t\t\t\t\t    unsigned int subclass)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_killable_nested(struct mutex *lock,",
            "\t\t\t\t\t    unsigned int subclass)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched mutex_lock_io_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\tint token;",
            "",
            "\tmight_sleep();",
            "",
            "\ttoken = io_schedule_prepare();",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "\tio_schedule_finish(token);",
            "}",
            "void __sched mutex_lock(struct mutex *lock)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_interruptible(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_killable(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);",
            "}",
            "void __sched mutex_lock_io(struct mutex *lock)",
            "{",
            "\tint token = io_schedule_prepare();",
            "",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "\tio_schedule_finish(token);",
            "}"
          ],
          "function_name": "rt_mutex_adjust_pi, rt_mutex_postunlock, rt_mutex_debug_task_free, __mutex_rt_init, __mutex_lock_common, mutex_lock_nested, _mutex_lock_nest_lock, mutex_lock_interruptible_nested, mutex_lock_killable_nested, mutex_lock_io_nested, mutex_lock, mutex_lock_interruptible, mutex_lock_killable, mutex_lock_io",
          "description": "提供标准互斥锁（mutex）的封装接口，将rtmutex操作映射到传统mutex接口，包含嵌套加锁、I/O路径加锁、优先级调整等特殊场景的支持实现。",
          "similarity": 0.4632236063480377
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 1,
          "end_line": 21,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * rtmutex API",
            " */",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "",
            "#define RT_MUTEX_BUILD_MUTEX",
            "#include \"rtmutex.c\"",
            "",
            "/*",
            " * Max number of times we'll walk the boosting chain:",
            " */",
            "int max_lock_depth = 1024;",
            "",
            "/*",
            " * Debug aware fast / slowpath lock,trylock,unlock",
            " *",
            " * The atomic acquire/release ops are compiled away, when either the",
            " * architecture does not support cmpxchg or when debugging is enabled.",
            " */"
          ],
          "function_name": null,
          "description": "定义实时互斥锁（rtmutex）的核心参数和调试相关配置，通过宏引入rtmutex实现文件，并设置最大锁深度限制，启用原子操作优化和调试支持。",
          "similarity": 0.4104763865470886
        }
      ]
    }
  ]
}