{
  "query": "共享内存区域的创建与同步方法",
  "timestamp": "2025-12-26 01:11:39",
  "retrieved_files": [
    {
      "source_file": "mm/memblock.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:38:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memblock.c`\n\n---\n\n# memblock.c 技术文档\n\n## 1. 文件概述\n\n`memblock.c` 实现了 Linux 内核早期启动阶段的内存管理机制——**memblock**。该机制用于在常规内存分配器（如 buddy allocator）尚未初始化之前，对物理内存进行粗粒度的区域管理。它将系统内存抽象为若干连续的内存区域（regions），支持“可用内存”（memory）、“保留内存”（reserved）和“物理内存”（physmem，部分架构支持）三种类型，为内核早期初始化提供内存添加、查询和分配能力。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct memblock_region`：表示一个连续的物理内存区域，包含基地址（base）、大小（size）、NUMA 节点 ID 和属性标志。\n- `struct memblock_type`：管理一类内存区域的集合，包含区域数组、当前数量（cnt）、最大容量（max）和名称。\n- `struct memblock`：全局 memblock 管理结构，包含 `memory` 和 `reserved` 两种类型的 `memblock_type`，以及分配方向（bottom_up）和当前分配上限（current_limit）。\n- `physmem`（条件编译）：描述不受 `mem=` 参数限制的实际物理内存布局。\n\n### 主要函数与变量\n- `memblock_add()` / `memblock_add_node()`：向 memblock 添加可用内存区域。\n- `memblock_reserve()`：标记内存区域为保留（不可用于动态分配）。\n- `memblock_phys_alloc*()` / `memblock_alloc*()`：分配物理或虚拟地址的内存。\n- `memblock_overlaps_region()`：判断指定区域是否与某类 memblock 区域重叠。\n- `__memblock_find_range_bottom_up()`：从低地址向高地址查找满足条件的空闲内存范围。\n- 全局变量 `memblock`：静态初始化的主 memblock 结构体。\n- `max_low_pfn`, `min_low_pfn`, `max_pfn`, `max_possible_pfn`：记录 PFN（页帧号）边界信息。\n\n### 配置宏\n- `INIT_MEMBLOCK_REGIONS`：初始内存/保留区域数组大小（默认 128）。\n- `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 类型支持。\n- `CONFIG_MEMBLOCK_KHO_SCRATCH`：支持仅从特定标记（KHO_SCRATCH）区域分配内存。\n- `CONFIG_ARCH_KEEP_MEMBLOCK`：决定是否在初始化完成后保留 memblock 数据结构。\n\n## 3. 关键实现\n\n### 初始化与存储\n- `memblock` 结构体在编译时静态初始化，其 `memory` 和 `reserved` 的区域数组分别使用 `memblock_memory_init_regions` 和 `memblock_reserved_init_regions`，初始容量由 `INIT_MEMBLOCK_*_REGIONS` 定义。\n- 每个 `memblock_type` 的 `cnt` 初始设为 1，但实际第一个条目为空的占位符，有效区域从索引 1 开始（后续代码处理）。\n- 支持通过 `memblock_allow_resize()` 动态扩容区域数组，但需谨慎避免与 initrd 等关键区域冲突。\n\n### 内存区域管理\n- 使用 `for_each_memblock_type` 宏遍历指定类型的区域。\n- `memblock_addrs_overlap()` 通过比较区间端点判断两个物理内存区域是否重叠。\n- `memblock_overlaps_region()` 封装了对某类所有区域的重叠检测。\n\n### 分配策略\n- 默认采用 **top-down**（从高地址向低地址）分配策略，可通过 `memblock_set_bottom_up(true)` 切换为 **bottom-up**。\n- 分配时受 `current_limit` 限制（默认 `MEMBLOCK_ALLOC_ANYWHERE` 表示无限制）。\n- 支持基于 NUMA 节点、对齐要求、内存属性（如 `MEMBLOCK_MIRROR`、`MEMBLOCK_KHO_SCRATCH`）的精细控制。\n- `choose_memblock_flags()` 根据 `kho_scratch_only` 和镜像内存存在性动态选择分配标志。\n\n### 安全与调试\n- `memblock_cap_size()` 防止地址计算溢出（确保 `base + size <= PHYS_ADDR_MAX`）。\n- 条件编译的 `memblock_dbg()` 宏用于调试输出（需开启 `memblock_debug`）。\n- 使用 `__initdata_memblock` 属性标记仅在初始化阶段使用的数据，便于后续释放。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memblock.h>`：定义 memblock API 和数据结构。\n  - `<linux/kernel.h>`, `<linux/init.h>`：提供基础内核功能和初始化宏。\n  - `<linux/pfn.h>`：PFN 相关操作。\n  - `<asm/sections.h>`：访问内核链接段信息。\n  - 架构相关头文件（如 `internal.h`）。\n- **配置依赖**：\n  - `CONFIG_NUMA`：影响 `contig_page_data` 的定义。\n  - `CONFIG_KEXEC_HANDOVER`：引入 kexec 相关头文件。\n  - `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 支持。\n- **后续移交**：在 `mem_init()` 中，memblock 管理的内存会被释放给 buddy allocator，完成内存管理权移交。\n\n## 5. 使用场景\n\n- **内核早期初始化**：在 `start_kernel()` 初期，架构代码（如 `setup_arch()`）调用 `memblock_add()` 注册可用物理内存，调用 `memblock_reserve()` 保留内核镜像、设备树、initrd 等关键区域。\n- **早期内存分配**：在 slab/buddy 分配器就绪前，使用 `memblock_alloc()` 分配大块连续内存（如页表、中断向量表、ACPI 表解析缓冲区）。\n- **内存布局查询**：通过 `for_each_memblock()` 等宏遍历内存区域，用于构建 e820 表、EFI 内存映射或 NUMA 拓扑。\n- **特殊分配需求**：支持从镜像内存（`MEMBLOCK_MIRROR`）或 KHO scratch 区域分配，满足安全启动或崩溃转储等场景。\n- **调试与分析**：通过 debugfs 接口（未在片段中体现）导出 memblock 布局，辅助内存问题诊断。",
      "similarity": 0.6415259838104248,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "mm/memblock.c",
          "start_line": 537,
          "end_line": 685,
          "content": [
            "static void __init_memblock memblock_merge_regions(struct memblock_type *type,",
            "\t\t\t\t\t\t   unsigned long start_rgn,",
            "\t\t\t\t\t\t   unsigned long end_rgn)",
            "{",
            "\tint i = 0;",
            "\tif (start_rgn)",
            "\t\ti = start_rgn - 1;",
            "\tend_rgn = min(end_rgn, type->cnt - 1);",
            "\twhile (i < end_rgn) {",
            "\t\tstruct memblock_region *this = &type->regions[i];",
            "\t\tstruct memblock_region *next = &type->regions[i + 1];",
            "",
            "\t\tif (this->base + this->size != next->base ||",
            "\t\t    memblock_get_region_node(this) !=",
            "\t\t    memblock_get_region_node(next) ||",
            "\t\t    this->flags != next->flags) {",
            "\t\t\tBUG_ON(this->base + this->size > next->base);",
            "\t\t\ti++;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tthis->size += next->size;",
            "\t\t/* move forward from next + 1, index of which is i + 2 */",
            "\t\tmemmove(next, next + 1, (type->cnt - (i + 2)) * sizeof(*next));",
            "\t\ttype->cnt--;",
            "\t\tend_rgn--;",
            "\t}",
            "}",
            "static void __init_memblock memblock_insert_region(struct memblock_type *type,",
            "\t\t\t\t\t\t   int idx, phys_addr_t base,",
            "\t\t\t\t\t\t   phys_addr_t size,",
            "\t\t\t\t\t\t   int nid,",
            "\t\t\t\t\t\t   enum memblock_flags flags)",
            "{",
            "\tstruct memblock_region *rgn = &type->regions[idx];",
            "",
            "\tBUG_ON(type->cnt >= type->max);",
            "\tmemmove(rgn + 1, rgn, (type->cnt - idx) * sizeof(*rgn));",
            "\trgn->base = base;",
            "\trgn->size = size;",
            "\trgn->flags = flags;",
            "\tmemblock_set_region_node(rgn, nid);",
            "\ttype->cnt++;",
            "\ttype->total_size += size;",
            "}",
            "static int __init_memblock memblock_add_range(struct memblock_type *type,",
            "\t\t\t\tphys_addr_t base, phys_addr_t size,",
            "\t\t\t\tint nid, enum memblock_flags flags)",
            "{",
            "\tbool insert = false;",
            "\tphys_addr_t obase = base;",
            "\tphys_addr_t end = base + memblock_cap_size(base, &size);",
            "\tint idx, nr_new, start_rgn = -1, end_rgn;",
            "\tstruct memblock_region *rgn;",
            "",
            "\tif (!size)",
            "\t\treturn 0;",
            "",
            "\t/* special case for empty array */",
            "\tif (type->regions[0].size == 0) {",
            "\t\tWARN_ON(type->cnt != 1 || type->total_size);",
            "\t\ttype->regions[0].base = base;",
            "\t\ttype->regions[0].size = size;",
            "\t\ttype->regions[0].flags = flags;",
            "\t\tmemblock_set_region_node(&type->regions[0], nid);",
            "\t\ttype->total_size = size;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * The worst case is when new range overlaps all existing regions,",
            "\t * then we'll need type->cnt + 1 empty regions in @type. So if",
            "\t * type->cnt * 2 + 1 is less than or equal to type->max, we know",
            "\t * that there is enough empty regions in @type, and we can insert",
            "\t * regions directly.",
            "\t */",
            "\tif (type->cnt * 2 + 1 <= type->max)",
            "\t\tinsert = true;",
            "",
            "repeat:",
            "\t/*",
            "\t * The following is executed twice.  Once with %false @insert and",
            "\t * then with %true.  The first counts the number of regions needed",
            "\t * to accommodate the new area.  The second actually inserts them.",
            "\t */",
            "\tbase = obase;",
            "\tnr_new = 0;",
            "",
            "\tfor_each_memblock_type(idx, type, rgn) {",
            "\t\tphys_addr_t rbase = rgn->base;",
            "\t\tphys_addr_t rend = rbase + rgn->size;",
            "",
            "\t\tif (rbase >= end)",
            "\t\t\tbreak;",
            "\t\tif (rend <= base)",
            "\t\t\tcontinue;",
            "\t\t/*",
            "\t\t * @rgn overlaps.  If it separates the lower part of new",
            "\t\t * area, insert that portion.",
            "\t\t */",
            "\t\tif (rbase > base) {",
            "#ifdef CONFIG_NUMA",
            "\t\t\tWARN_ON(nid != memblock_get_region_node(rgn));",
            "#endif",
            "\t\t\tWARN_ON(flags != MEMBLOCK_NONE && flags != rgn->flags);",
            "\t\t\tnr_new++;",
            "\t\t\tif (insert) {",
            "\t\t\t\tif (start_rgn == -1)",
            "\t\t\t\t\tstart_rgn = idx;",
            "\t\t\t\tend_rgn = idx + 1;",
            "\t\t\t\tmemblock_insert_region(type, idx++, base,",
            "\t\t\t\t\t\t       rbase - base, nid,",
            "\t\t\t\t\t\t       flags);",
            "\t\t\t}",
            "\t\t}",
            "\t\t/* area below @rend is dealt with, forget about it */",
            "\t\tbase = min(rend, end);",
            "\t}",
            "",
            "\t/* insert the remaining portion */",
            "\tif (base < end) {",
            "\t\tnr_new++;",
            "\t\tif (insert) {",
            "\t\t\tif (start_rgn == -1)",
            "\t\t\t\tstart_rgn = idx;",
            "\t\t\tend_rgn = idx + 1;",
            "\t\t\tmemblock_insert_region(type, idx, base, end - base,",
            "\t\t\t\t\t       nid, flags);",
            "\t\t}",
            "\t}",
            "",
            "\tif (!nr_new)",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * If this was the first round, resize array and repeat for actual",
            "\t * insertions; otherwise, merge and return.",
            "\t */",
            "\tif (!insert) {",
            "\t\twhile (type->cnt + nr_new > type->max)",
            "\t\t\tif (memblock_double_array(type, obase, size) < 0)",
            "\t\t\t\treturn -ENOMEM;",
            "\t\tinsert = true;",
            "\t\tgoto repeat;",
            "\t} else {",
            "\t\tmemblock_merge_regions(type, start_rgn, end_rgn);",
            "\t\treturn 0;",
            "\t}",
            "}"
          ],
          "function_name": "memblock_merge_regions, memblock_insert_region, memblock_add_range",
          "description": "实现内存区域合并（merge_regions）与插入（insert_region）逻辑，处理新增内存范围的拆分与整合，优化连续区域管理。",
          "similarity": 0.6650019884109497
        },
        {
          "chunk_id": 10,
          "file_path": "mm/memblock.c",
          "start_line": 1954,
          "end_line": 2057,
          "content": [
            "void __init memblock_mem_limit_remove_map(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr;",
            "",
            "\tif (!limit)",
            "\t\treturn;",
            "",
            "\tmax_addr = __find_max_addr(limit);",
            "",
            "\t/* @limit exceeds the total size of the memory, do nothing */",
            "\tif (max_addr == PHYS_ADDR_MAX)",
            "\t\treturn;",
            "",
            "\tmemblock_cap_memory_range(0, max_addr);",
            "}",
            "static int __init_memblock memblock_search(struct memblock_type *type, phys_addr_t addr)",
            "{",
            "\tunsigned int left = 0, right = type->cnt;",
            "",
            "\tdo {",
            "\t\tunsigned int mid = (right + left) / 2;",
            "",
            "\t\tif (addr < type->regions[mid].base)",
            "\t\t\tright = mid;",
            "\t\telse if (addr >= (type->regions[mid].base +",
            "\t\t\t\t  type->regions[mid].size))",
            "\t\t\tleft = mid + 1;",
            "\t\telse",
            "\t\t\treturn mid;",
            "\t} while (left < right);",
            "\treturn -1;",
            "}",
            "bool __init_memblock memblock_is_reserved(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.reserved, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_memory(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.memory, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_map_memory(phys_addr_t addr)",
            "{",
            "\tint i = memblock_search(&memblock.memory, addr);",
            "",
            "\tif (i == -1)",
            "\t\treturn false;",
            "\treturn !memblock_is_nomap(&memblock.memory.regions[i]);",
            "}",
            "int __init_memblock memblock_search_pfn_nid(unsigned long pfn,",
            "\t\t\t unsigned long *start_pfn, unsigned long *end_pfn)",
            "{",
            "\tstruct memblock_type *type = &memblock.memory;",
            "\tint mid = memblock_search(type, PFN_PHYS(pfn));",
            "",
            "\tif (mid == -1)",
            "\t\treturn -1;",
            "",
            "\t*start_pfn = PFN_DOWN(type->regions[mid].base);",
            "\t*end_pfn = PFN_DOWN(type->regions[mid].base + type->regions[mid].size);",
            "",
            "\treturn memblock_get_region_node(&type->regions[mid]);",
            "}",
            "bool __init_memblock memblock_is_region_memory(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tint idx = memblock_search(&memblock.memory, base);",
            "\tphys_addr_t end = base + memblock_cap_size(base, &size);",
            "",
            "\tif (idx == -1)",
            "\t\treturn false;",
            "\treturn (memblock.memory.regions[idx].base +",
            "\t\t memblock.memory.regions[idx].size) >= end;",
            "}",
            "bool __init_memblock memblock_is_region_reserved(phys_addr_t base, phys_addr_t size)",
            "{",
            "\treturn memblock_overlaps_region(&memblock.reserved, base, size);",
            "}",
            "void __init_memblock memblock_trim_memory(phys_addr_t align)",
            "{",
            "\tphys_addr_t start, end, orig_start, orig_end;",
            "\tstruct memblock_region *r;",
            "",
            "\tfor_each_mem_region(r) {",
            "\t\torig_start = r->base;",
            "\t\torig_end = r->base + r->size;",
            "\t\tstart = round_up(orig_start, align);",
            "\t\tend = round_down(orig_end, align);",
            "",
            "\t\tif (start == orig_start && end == orig_end)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (start < end) {",
            "\t\t\tr->base = start;",
            "\t\t\tr->size = end - start;",
            "\t\t} else {",
            "\t\t\tmemblock_remove_region(&memblock.memory,",
            "\t\t\t\t\t       r - memblock.memory.regions);",
            "\t\t\tr--;",
            "\t\t}",
            "\t}",
            "}",
            "void __init_memblock memblock_set_current_limit(phys_addr_t limit)",
            "{",
            "\tmemblock.current_limit = limit;",
            "}"
          ],
          "function_name": "memblock_mem_limit_remove_map, memblock_search, memblock_is_reserved, memblock_is_memory, memblock_is_map_memory, memblock_search_pfn_nid, memblock_is_region_memory, memblock_is_region_reserved, memblock_trim_memory, memblock_set_current_limit",
          "description": "实现内存块限制移除、搜索和区域判断逻辑，用于管理内存和保留区域的地址范围查询及修剪操作",
          "similarity": 0.6416192054748535
        },
        {
          "chunk_id": 2,
          "file_path": "mm/memblock.c",
          "start_line": 366,
          "end_line": 506,
          "content": [
            "static void __init_memblock memblock_remove_region(struct memblock_type *type, unsigned long r)",
            "{",
            "\ttype->total_size -= type->regions[r].size;",
            "\tmemmove(&type->regions[r], &type->regions[r + 1],",
            "\t\t(type->cnt - (r + 1)) * sizeof(type->regions[r]));",
            "\ttype->cnt--;",
            "",
            "\t/* Special case for empty arrays */",
            "\tif (type->cnt == 0) {",
            "\t\tWARN_ON(type->total_size != 0);",
            "\t\ttype->cnt = 1;",
            "\t\ttype->regions[0].base = 0;",
            "\t\ttype->regions[0].size = 0;",
            "\t\ttype->regions[0].flags = 0;",
            "\t\tmemblock_set_region_node(&type->regions[0], MAX_NUMNODES);",
            "\t}",
            "}",
            "void __init memblock_discard(void)",
            "{",
            "\tphys_addr_t addr, size;",
            "",
            "\tif (memblock.reserved.regions != memblock_reserved_init_regions) {",
            "\t\taddr = __pa(memblock.reserved.regions);",
            "\t\tsize = PAGE_ALIGN(sizeof(struct memblock_region) *",
            "\t\t\t\t  memblock.reserved.max);",
            "\t\tif (memblock_reserved_in_slab)",
            "\t\t\tkfree(memblock.reserved.regions);",
            "\t\telse",
            "\t\t\tmemblock_free_late(addr, size);",
            "\t}",
            "",
            "\tif (memblock.memory.regions != memblock_memory_init_regions) {",
            "\t\taddr = __pa(memblock.memory.regions);",
            "\t\tsize = PAGE_ALIGN(sizeof(struct memblock_region) *",
            "\t\t\t\t  memblock.memory.max);",
            "\t\tif (memblock_memory_in_slab)",
            "\t\t\tkfree(memblock.memory.regions);",
            "\t\telse",
            "\t\t\tmemblock_free_late(addr, size);",
            "\t}",
            "",
            "\tmemblock_memory = NULL;",
            "}",
            "static int __init_memblock memblock_double_array(struct memblock_type *type,",
            "\t\t\t\t\t\tphys_addr_t new_area_start,",
            "\t\t\t\t\t\tphys_addr_t new_area_size)",
            "{",
            "\tstruct memblock_region *new_array, *old_array;",
            "\tphys_addr_t old_alloc_size, new_alloc_size;",
            "\tphys_addr_t old_size, new_size, addr, new_end;",
            "\tint use_slab = slab_is_available();",
            "\tint *in_slab;",
            "",
            "\t/* We don't allow resizing until we know about the reserved regions",
            "\t * of memory that aren't suitable for allocation",
            "\t */",
            "\tif (!memblock_can_resize)",
            "\t\treturn -1;",
            "",
            "\t/* Calculate new doubled size */",
            "\told_size = type->max * sizeof(struct memblock_region);",
            "\tnew_size = old_size << 1;",
            "\t/*",
            "\t * We need to allocated new one align to PAGE_SIZE,",
            "\t *   so we can free them completely later.",
            "\t */",
            "\told_alloc_size = PAGE_ALIGN(old_size);",
            "\tnew_alloc_size = PAGE_ALIGN(new_size);",
            "",
            "\t/* Retrieve the slab flag */",
            "\tif (type == &memblock.memory)",
            "\t\tin_slab = &memblock_memory_in_slab;",
            "\telse",
            "\t\tin_slab = &memblock_reserved_in_slab;",
            "",
            "\t/* Try to find some space for it */",
            "\tif (use_slab) {",
            "\t\tnew_array = kmalloc(new_size, GFP_KERNEL);",
            "\t\taddr = new_array ? __pa(new_array) : 0;",
            "\t} else {",
            "\t\t/* only exclude range when trying to double reserved.regions */",
            "\t\tif (type != &memblock.reserved)",
            "\t\t\tnew_area_start = new_area_size = 0;",
            "",
            "\t\taddr = memblock_find_in_range(new_area_start + new_area_size,",
            "\t\t\t\t\t\tmemblock.current_limit,",
            "\t\t\t\t\t\tnew_alloc_size, PAGE_SIZE);",
            "\t\tif (!addr && new_area_size)",
            "\t\t\taddr = memblock_find_in_range(0,",
            "\t\t\t\tmin(new_area_start, memblock.current_limit),",
            "\t\t\t\tnew_alloc_size, PAGE_SIZE);",
            "",
            "\t\tif (addr) {",
            "\t\t\t/* The memory may not have been accepted, yet. */",
            "\t\t\taccept_memory(addr, new_alloc_size);",
            "",
            "\t\t\tnew_array = __va(addr);",
            "\t\t} else {",
            "\t\t\tnew_array = NULL;",
            "\t\t}",
            "\t}",
            "\tif (!addr) {",
            "\t\tpr_err(\"memblock: Failed to double %s array from %ld to %ld entries !\\n\",",
            "\t\t       type->name, type->max, type->max * 2);",
            "\t\treturn -1;",
            "\t}",
            "",
            "\tnew_end = addr + new_size - 1;",
            "\tmemblock_dbg(\"memblock: %s is doubled to %ld at [%pa-%pa]\",",
            "\t\t\ttype->name, type->max * 2, &addr, &new_end);",
            "",
            "\t/*",
            "\t * Found space, we now need to move the array over before we add the",
            "\t * reserved region since it may be our reserved array itself that is",
            "\t * full.",
            "\t */",
            "\tmemcpy(new_array, type->regions, old_size);",
            "\tmemset(new_array + type->max, 0, old_size);",
            "\told_array = type->regions;",
            "\ttype->regions = new_array;",
            "\ttype->max <<= 1;",
            "",
            "\t/* Free old array. We needn't free it if the array is the static one */",
            "\tif (*in_slab)",
            "\t\tkfree(old_array);",
            "\telse if (old_array != memblock_memory_init_regions &&",
            "\t\t old_array != memblock_reserved_init_regions)",
            "\t\tmemblock_free(old_array, old_alloc_size);",
            "",
            "\t/*",
            "\t * Reserve the new array if that comes from the memblock.  Otherwise, we",
            "\t * needn't do it",
            "\t */",
            "\tif (!use_slab)",
            "\t\tBUG_ON(memblock_reserve_kern(addr, new_alloc_size));",
            "",
            "\t/* Update slab flag */",
            "\t*in_slab = use_slab;",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "memblock_remove_region, memblock_discard, memblock_double_array",
          "description": "实现内存区域数组的动态扩容（double_array）、旧区域释放（discard）及区域移除操作，维护内存类型总大小统计。",
          "similarity": 0.6402370929718018
        },
        {
          "chunk_id": 1,
          "file_path": "mm/memblock.c",
          "start_line": 192,
          "end_line": 297,
          "content": [
            "static inline phys_addr_t memblock_cap_size(phys_addr_t base, phys_addr_t *size)",
            "{",
            "\treturn *size = min(*size, PHYS_ADDR_MAX - base);",
            "}",
            "unsigned long __init_memblock",
            "memblock_addrs_overlap(phys_addr_t base1, phys_addr_t size1, phys_addr_t base2,",
            "\t\t       phys_addr_t size2)",
            "{",
            "\treturn ((base1 < (base2 + size2)) && (base2 < (base1 + size1)));",
            "}",
            "bool __init_memblock memblock_overlaps_region(struct memblock_type *type,",
            "\t\t\t\t\tphys_addr_t base, phys_addr_t size)",
            "{",
            "\tunsigned long i;",
            "",
            "\tmemblock_cap_size(base, &size);",
            "",
            "\tfor (i = 0; i < type->cnt; i++)",
            "\t\tif (memblock_addrs_overlap(base, size, type->regions[i].base,",
            "\t\t\t\t\t   type->regions[i].size))",
            "\t\t\tbreak;",
            "\treturn i < type->cnt;",
            "}",
            "static phys_addr_t __init_memblock",
            "__memblock_find_range_bottom_up(phys_addr_t start, phys_addr_t end,",
            "\t\t\t\tphys_addr_t size, phys_addr_t align, int nid,",
            "\t\t\t\tenum memblock_flags flags)",
            "{",
            "\tphys_addr_t this_start, this_end, cand;",
            "\tu64 i;",
            "",
            "\tfor_each_free_mem_range(i, nid, flags, &this_start, &this_end, NULL) {",
            "\t\tthis_start = clamp(this_start, start, end);",
            "\t\tthis_end = clamp(this_end, start, end);",
            "",
            "\t\tcand = round_up(this_start, align);",
            "\t\tif (cand < this_end && this_end - cand >= size)",
            "\t\t\treturn cand;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static phys_addr_t __init_memblock",
            "__memblock_find_range_top_down(phys_addr_t start, phys_addr_t end,",
            "\t\t\t       phys_addr_t size, phys_addr_t align, int nid,",
            "\t\t\t       enum memblock_flags flags)",
            "{",
            "\tphys_addr_t this_start, this_end, cand;",
            "\tu64 i;",
            "",
            "\tfor_each_free_mem_range_reverse(i, nid, flags, &this_start, &this_end,",
            "\t\t\t\t\tNULL) {",
            "\t\tthis_start = clamp(this_start, start, end);",
            "\t\tthis_end = clamp(this_end, start, end);",
            "",
            "\t\tif (this_end < size)",
            "\t\t\tcontinue;",
            "",
            "\t\tcand = round_down(this_end - size, align);",
            "\t\tif (cand >= this_start)",
            "\t\t\treturn cand;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static phys_addr_t __init_memblock memblock_find_in_range_node(phys_addr_t size,",
            "\t\t\t\t\tphys_addr_t align, phys_addr_t start,",
            "\t\t\t\t\tphys_addr_t end, int nid,",
            "\t\t\t\t\tenum memblock_flags flags)",
            "{",
            "\t/* pump up @end */",
            "\tif (end == MEMBLOCK_ALLOC_ACCESSIBLE ||",
            "\t    end == MEMBLOCK_ALLOC_NOLEAKTRACE)",
            "\t\tend = memblock.current_limit;",
            "",
            "\t/* avoid allocating the first page */",
            "\tstart = max_t(phys_addr_t, start, PAGE_SIZE);",
            "\tend = max(start, end);",
            "",
            "\tif (memblock_bottom_up())",
            "\t\treturn __memblock_find_range_bottom_up(start, end, size, align,",
            "\t\t\t\t\t\t       nid, flags);",
            "\telse",
            "\t\treturn __memblock_find_range_top_down(start, end, size, align,",
            "\t\t\t\t\t\t      nid, flags);",
            "}",
            "static phys_addr_t __init_memblock memblock_find_in_range(phys_addr_t start,",
            "\t\t\t\t\tphys_addr_t end, phys_addr_t size,",
            "\t\t\t\t\tphys_addr_t align)",
            "{",
            "\tphys_addr_t ret;",
            "\tenum memblock_flags flags = choose_memblock_flags();",
            "",
            "again:",
            "\tret = memblock_find_in_range_node(size, align, start, end,",
            "\t\t\t\t\t    NUMA_NO_NODE, flags);",
            "",
            "\tif (!ret && (flags & MEMBLOCK_MIRROR)) {",
            "\t\tpr_warn_ratelimited(\"Could not allocate %pap bytes of mirrored memory\\n\",",
            "\t\t\t&size);",
            "\t\tflags &= ~MEMBLOCK_MIRROR;",
            "\t\tgoto again;",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "memblock_cap_size, memblock_addrs_overlap, memblock_overlaps_region, __memblock_find_range_bottom_up, __memblock_find_range_top_down, memblock_find_in_range_node, memblock_find_in_range",
          "description": "实现内存区域地址重叠检测与分配策略选择逻辑，包含范围查找算法（底向顶/顶向底）及镜像内存分配失败回退机制。",
          "similarity": 0.6213711500167847
        },
        {
          "chunk_id": 9,
          "file_path": "mm/memblock.c",
          "start_line": 1607,
          "end_line": 1734,
          "content": [
            "phys_addr_t __init memblock_phys_alloc_range(phys_addr_t size,",
            "\t\t\t\t\t     phys_addr_t align,",
            "\t\t\t\t\t     phys_addr_t start,",
            "\t\t\t\t\t     phys_addr_t end)",
            "{",
            "\tmemblock_dbg(\"%s: %llu bytes align=0x%llx from=%pa max_addr=%pa %pS\\n\",",
            "\t\t     __func__, (u64)size, (u64)align, &start, &end,",
            "\t\t     (void *)_RET_IP_);",
            "\treturn memblock_alloc_range_nid(size, align, start, end, NUMA_NO_NODE,",
            "\t\t\t\t\tfalse);",
            "}",
            "phys_addr_t __init memblock_phys_alloc_try_nid(phys_addr_t size, phys_addr_t align, int nid)",
            "{",
            "\treturn memblock_alloc_range_nid(size, align, 0,",
            "\t\t\t\t\tMEMBLOCK_ALLOC_ACCESSIBLE, nid, false);",
            "}",
            "void __init memblock_free_late(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t cursor, end;",
            "",
            "\tend = base + size - 1;",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\",",
            "\t\t     __func__, &base, &end, (void *)_RET_IP_);",
            "\tkmemleak_free_part_phys(base, size);",
            "\tcursor = PFN_UP(base);",
            "\tend = PFN_DOWN(base + size);",
            "",
            "\tfor (; cursor < end; cursor++) {",
            "\t\tmemblock_free_pages(pfn_to_page(cursor), cursor, 0);",
            "\t\ttotalram_pages_inc();",
            "\t}",
            "}",
            "phys_addr_t __init_memblock memblock_reserved_kern_size(phys_addr_t limit, int nid)",
            "{",
            "\tstruct memblock_region *r;",
            "\tphys_addr_t total = 0;",
            "",
            "\tfor_each_reserved_mem_region(r) {",
            "\t\tphys_addr_t size = r->size;",
            "",
            "\t\tif (r->base > limit)",
            "\t\t\tbreak;",
            "",
            "\t\tif (r->base + r->size > limit)",
            "\t\t\tsize = limit - r->base;",
            "",
            "\t\tif (nid == memblock_get_region_node(r) || !numa_valid_node(nid))",
            "\t\t\tif (r->flags & MEMBLOCK_RSRV_KERN)",
            "\t\t\t\ttotal += size;",
            "\t}",
            "",
            "\treturn total;",
            "}",
            "unsigned long __init memblock_estimated_nr_free_pages(void)",
            "{",
            "\treturn PHYS_PFN(memblock_phys_mem_size() - memblock_reserved_size());",
            "}",
            "static phys_addr_t __init_memblock __find_max_addr(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr = PHYS_ADDR_MAX;",
            "\tstruct memblock_region *r;",
            "",
            "\t/*",
            "\t * translate the memory @limit size into the max address within one of",
            "\t * the memory memblock regions, if the @limit exceeds the total size",
            "\t * of those regions, max_addr will keep original value PHYS_ADDR_MAX",
            "\t */",
            "\tfor_each_mem_region(r) {",
            "\t\tif (limit <= r->size) {",
            "\t\t\tmax_addr = r->base + limit;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tlimit -= r->size;",
            "\t}",
            "",
            "\treturn max_addr;",
            "}",
            "void __init memblock_enforce_memory_limit(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr;",
            "",
            "\tif (!limit)",
            "\t\treturn;",
            "",
            "\tmax_addr = __find_max_addr(limit);",
            "",
            "\t/* @limit exceeds the total size of the memory, do nothing */",
            "\tif (max_addr == PHYS_ADDR_MAX)",
            "\t\treturn;",
            "",
            "\t/* truncate both memory and reserved regions */",
            "\tmemblock_remove_range(&memblock.memory, max_addr,",
            "\t\t\t      PHYS_ADDR_MAX);",
            "\tmemblock_remove_range(&memblock.reserved, max_addr,",
            "\t\t\t      PHYS_ADDR_MAX);",
            "}",
            "void __init memblock_cap_memory_range(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tint start_rgn, end_rgn;",
            "\tint i, ret;",
            "",
            "\tif (!size)",
            "\t\treturn;",
            "",
            "\tif (!memblock_memory->total_size) {",
            "\t\tpr_warn(\"%s: No memory registered yet\\n\", __func__);",
            "\t\treturn;",
            "\t}",
            "",
            "\tret = memblock_isolate_range(&memblock.memory, base, size,",
            "\t\t\t\t\t\t&start_rgn, &end_rgn);",
            "\tif (ret)",
            "\t\treturn;",
            "",
            "\t/* remove all the MAP regions */",
            "\tfor (i = memblock.memory.cnt - 1; i >= end_rgn; i--)",
            "\t\tif (!memblock_is_nomap(&memblock.memory.regions[i]))",
            "\t\t\tmemblock_remove_region(&memblock.memory, i);",
            "",
            "\tfor (i = start_rgn - 1; i >= 0; i--)",
            "\t\tif (!memblock_is_nomap(&memblock.memory.regions[i]))",
            "\t\t\tmemblock_remove_region(&memblock.memory, i);",
            "",
            "\t/* truncate the reserved regions */",
            "\tmemblock_remove_range(&memblock.reserved, 0, base);",
            "\tmemblock_remove_range(&memblock.reserved,",
            "\t\t\tbase + size, PHYS_ADDR_MAX);",
            "}"
          ],
          "function_name": "memblock_phys_alloc_range, memblock_phys_alloc_try_nid, memblock_free_late, memblock_reserved_kern_size, memblock_estimated_nr_free_pages, __find_max_addr, memblock_enforce_memory_limit, memblock_cap_memory_range",
          "description": "实现物理内存分配/释放控制，包含内存上限强制限制、空闲页面估算、内存区域截断等管理功能，支持对保留内存的容量统计",
          "similarity": 0.6176987886428833
        }
      ]
    },
    {
      "source_file": "kernel/dma/pool.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:15:49\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `dma\\pool.c`\n\n---\n\n# `dma/pool.c` 技术文档\n\n## 1. 文件概述\n\n`dma/pool.c` 实现了 Linux 内核中的 **DMA 原子内存池（atomic DMA pools）** 机制，用于在无法睡眠的上下文（如中断处理、原子上下文）中分配一致性（coherent）DMA 内存。该机制通过预分配多个按内存区域（ZONE_DMA、ZONE_DMA32、普通内核内存）划分的通用内存池（`gen_pool`），并在池空间不足时通过工作队列异步扩展，从而支持在 GFP_ATOMIC 等限制性分配标志下安全地分配 DMA 内存。\n\n该文件主要用于支持 `dma-direct` 子系统中的原子 DMA 分配路径，确保即使在内存压力大或无法睡眠的场景下，设备驱动仍能获得满足地址限制（如 32 位或 24 位寻址）的一致性 DMA 缓冲区。\n\n## 2. 核心功能\n\n### 全局变量\n- `atomic_pool_dma` / `pool_size_dma`：用于 `GFP_DMA` 区域的原子 DMA 池及其已分配大小。\n- `atomic_pool_dma32` / `pool_size_dma32`：用于 `GFP_DMA32` 区域的原子 DMA 池及其已分配大小。\n- `atomic_pool_kernel` / `pool_size_kernel`：用于普通内核区域（无特殊 DMA 限制）的原子 DMA 池及其已分配大小。\n- `atomic_pool_size`：每个池的初始目标大小，可通过内核命令行参数 `coherent_pool=` 设置。\n- `atomic_pool_work`：用于后台动态扩展内存池的工作项。\n\n### 主要函数\n- `early_coherent_pool()`：解析内核命令行参数 `coherent_pool`，设置 `atomic_pool_size`。\n- `dma_atomic_pool_init()`：初始化所有原子 DMA 池（postcore 阶段调用）。\n- `__dma_atomic_pool_init()`：创建并填充指定 GFP 标志的原子池。\n- `atomic_pool_expand()`：向指定池中添加一块连续物理内存。\n- `atomic_pool_resize()` / `atomic_pool_work_fn()`：检查池剩余空间，若不足则触发扩展。\n- `dma_alloc_from_pool()`：从合适的原子池中分配指定大小的 DMA 内存。\n- `dma_free_from_pool()`：将内存归还到对应的原子池。\n- `dma_guess_pool()`：根据 GFP 标志和尝试顺序选择合适的内存池。\n- `cma_in_zone()`：判断 CMA 区域是否位于指定 DMA 区域内，以决定是否优先从 CMA 分配。\n- `dma_atomic_pool_debugfs_init()`：在 debugfs 中导出各池的当前大小。\n\n## 3. 关键实现\n\n### 内存池初始化策略\n- 若未通过 `coherent_pool=` 指定大小，则默认按 **每 1GB 物理内存分配 128KB** 原子池，最小 128KB，最大不超过 `MAX_ORDER_NR_PAGES` 对应的内存。\n- 每个池使用 `gen_pool` 管理，分配算法为 `gen_pool_first_fit_order_align`，保证分配地址按页对齐。\n- 初始化时调用 `atomic_pool_expand()` 预分配内存。\n\n### 内存分配来源\n- 优先尝试从 **CMA（Contiguous Memory Allocator）** 区域分配（若 CMA 区域位于目标 DMA zone 内）。\n- 若 CMA 不可用或不在目标 zone，则回退到 `alloc_pages()`。\n- 分配的内存块大小不超过 `MAX_PAGE_ORDER`，通过降序尝试（从大到小）提高分配成功率。\n\n### 内存属性处理\n- 调用 `arch_dma_prep_coherent()` 通知架构层准备一致性内存。\n- 在支持内存加密（如 AMD SEV、Intel TDX）的系统上，显式调用 `set_memory_decrypted()` 确保 DMA 内存为 **未加密状态**，因为设备无法访问加密内存。\n- 若启用了 `CONFIG_DMA_DIRECT_REMAP`，则通过 `dma_common_contiguous_remap()` 建立非缓存或设备专用的页表映射。\n\n### 动态扩展机制\n- 每次从池中分配内存后，检查剩余空间是否小于 `atomic_pool_size`。\n- 若不足，则调度 `atomic_pool_work` 工作项，在进程上下文中异步扩展对应池。\n- 扩展时尝试分配与当前池总大小相当的新内存块，避免频繁小量扩展。\n\n### 多池选择逻辑\n- `dma_guess_pool()` 实现池选择策略：\n  1. 首选与 GFP 标志匹配的池（DMA32 > DMA > 普通内核）。\n  2. 若首次分配失败，按 `kernel → dma32 → dma` 顺序尝试其他池（fallback 机制）。\n- 释放时遍历所有池，通过 `gen_pool_has_addr()` 确定内存归属。\n\n## 4. 依赖关系\n\n- **内存管理子系统**：\n  - 依赖 `genalloc`（`gen_pool`）实现内存池管理。\n  - 使用 `alloc_pages()`、`__free_pages()` 进行底层页分配。\n  - 依赖 CMA 接口（`dma_alloc_from_contiguous()`）获取大块连续内存。\n- **DMA 子系统**：\n  - 与 `dma-direct.c` 紧密集成，为其提供 `___dma_direct_alloc_pages()` 中的原子分配路径。\n  - 使用 `dma-map-ops.h` 和 `dma-direct.h` 中的辅助函数。\n- **架构相关支持**：\n  - 调用 `arch_dma_prep_coherent()`（架构可选实现）。\n  - 使用 `set_memory_decrypted()`/`set_memory_encrypted()`（x86/ARM64 等支持内存加密的架构）。\n  - 依赖 `DMA_BIT_MASK()` 和 `zone_dma_bits` 判断 DMA 地址范围。\n- **其他**：\n  - 使用 `debugfs` 导出调试信息。\n  - 依赖 `workqueue` 实现异步扩展。\n  - 使用 `slab.h` 中的内存分配器（间接）。\n\n## 5. 使用场景\n\n- **原子上下文 DMA 分配**：当设备驱动在中断处理程序、自旋锁保护区域或使用 `GFP_ATOMIC` 标志调用 `dma_alloc_coherent()` 时，若常规页分配器无法满足（如内存碎片），内核会回退到从原子池分配。\n- **满足地址限制的 DMA 缓冲区**：对于需要 24 位（ISA 设备）或 32 位（旧 PCIe 设备）寻址能力的设备，驱动使用 `DMA_BIT_MASK(24)` 或 `DMA_BIT_MASK(32)` 限制 DMA 地址范围，原子池确保分配的内存物理地址符合要求。\n- **一致性内存需求**：适用于需要 CPU 与设备之间缓存一致性的场景（如网络数据包缓冲区、音频流缓冲区），原子池分配的内存经过 `arch_dma_prep_coherent()` 处理，保证一致性。\n- **内存加密环境**：在启用内存加密的系统中，确保分配给设备的 DMA 内存处于解密状态，使设备能正常访问。",
      "similarity": 0.6405968070030212,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/dma/pool.c",
          "start_line": 145,
          "end_line": 207,
          "content": [
            "static void atomic_pool_resize(struct gen_pool *pool, gfp_t gfp)",
            "{",
            "\tif (pool && gen_pool_avail(pool) < atomic_pool_size)",
            "\t\tatomic_pool_expand(pool, gen_pool_size(pool), gfp);",
            "}",
            "static void atomic_pool_work_fn(struct work_struct *work)",
            "{",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA))",
            "\t\tatomic_pool_resize(atomic_pool_dma,",
            "\t\t\t\t   GFP_KERNEL | GFP_DMA);",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA32))",
            "\t\tatomic_pool_resize(atomic_pool_dma32,",
            "\t\t\t\t   GFP_KERNEL | GFP_DMA32);",
            "\tatomic_pool_resize(atomic_pool_kernel, GFP_KERNEL);",
            "}",
            "static int __init dma_atomic_pool_init(void)",
            "{",
            "\tint ret = 0;",
            "",
            "\t/*",
            "\t * If coherent_pool was not used on the command line, default the pool",
            "\t * sizes to 128KB per 1GB of memory, min 128KB, max MAX_PAGE_ORDER.",
            "\t */",
            "\tif (!atomic_pool_size) {",
            "\t\tunsigned long pages = totalram_pages() / (SZ_1G / SZ_128K);",
            "\t\tpages = min_t(unsigned long, pages, MAX_ORDER_NR_PAGES);",
            "\t\tatomic_pool_size = max_t(size_t, pages << PAGE_SHIFT, SZ_128K);",
            "\t}",
            "\tINIT_WORK(&atomic_pool_work, atomic_pool_work_fn);",
            "",
            "\tatomic_pool_kernel = __dma_atomic_pool_init(atomic_pool_size,",
            "\t\t\t\t\t\t    GFP_KERNEL);",
            "\tif (!atomic_pool_kernel)",
            "\t\tret = -ENOMEM;",
            "\tif (has_managed_dma()) {",
            "\t\tatomic_pool_dma = __dma_atomic_pool_init(atomic_pool_size,",
            "\t\t\t\t\t\tGFP_KERNEL | GFP_DMA);",
            "\t\tif (!atomic_pool_dma)",
            "\t\t\tret = -ENOMEM;",
            "\t}",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA32)) {",
            "\t\tatomic_pool_dma32 = __dma_atomic_pool_init(atomic_pool_size,",
            "\t\t\t\t\t\tGFP_KERNEL | GFP_DMA32);",
            "\t\tif (!atomic_pool_dma32)",
            "\t\t\tret = -ENOMEM;",
            "\t}",
            "",
            "\tdma_atomic_pool_debugfs_init();",
            "\treturn ret;",
            "}",
            "bool dma_free_from_pool(struct device *dev, void *start, size_t size)",
            "{",
            "\tstruct gen_pool *pool = NULL;",
            "",
            "\twhile ((pool = dma_guess_pool(pool, 0))) {",
            "\t\tif (!gen_pool_has_addr(pool, (unsigned long)start, size))",
            "\t\t\tcontinue;",
            "\t\tgen_pool_free(pool, (unsigned long)start, size);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "atomic_pool_resize, atomic_pool_work_fn, dma_atomic_pool_init, dma_free_from_pool",
          "description": "实现内存池的初始化与维护机制，包含池大小自动调节逻辑、后台扩展任务调度、默认尺寸计算及内存释放查找功能，提供设备内存池的统一管理接口。",
          "similarity": 0.6102306842803955
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/dma/pool.c",
          "start_line": 29,
          "end_line": 138,
          "content": [
            "static int __init early_coherent_pool(char *p)",
            "{",
            "\tatomic_pool_size = memparse(p, &p);",
            "\treturn 0;",
            "}",
            "static void __init dma_atomic_pool_debugfs_init(void)",
            "{",
            "\tstruct dentry *root;",
            "",
            "\troot = debugfs_create_dir(\"dma_pools\", NULL);",
            "\tdebugfs_create_ulong(\"pool_size_dma\", 0400, root, &pool_size_dma);",
            "\tdebugfs_create_ulong(\"pool_size_dma32\", 0400, root, &pool_size_dma32);",
            "\tdebugfs_create_ulong(\"pool_size_kernel\", 0400, root, &pool_size_kernel);",
            "}",
            "static void dma_atomic_pool_size_add(gfp_t gfp, size_t size)",
            "{",
            "\tif (gfp & __GFP_DMA)",
            "\t\tpool_size_dma += size;",
            "\telse if (gfp & __GFP_DMA32)",
            "\t\tpool_size_dma32 += size;",
            "\telse",
            "\t\tpool_size_kernel += size;",
            "}",
            "static bool cma_in_zone(gfp_t gfp)",
            "{",
            "\tunsigned long size;",
            "\tphys_addr_t end;",
            "\tstruct cma *cma;",
            "",
            "\tcma = dev_get_cma_area(NULL);",
            "\tif (!cma)",
            "\t\treturn false;",
            "",
            "\tsize = cma_get_size(cma);",
            "\tif (!size)",
            "\t\treturn false;",
            "",
            "\t/* CMA can't cross zone boundaries, see cma_activate_area() */",
            "\tend = cma_get_base(cma) + size - 1;",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA) && (gfp & GFP_DMA))",
            "\t\treturn end <= DMA_BIT_MASK(zone_dma_bits);",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA32) && (gfp & GFP_DMA32))",
            "\t\treturn end <= DMA_BIT_MASK(32);",
            "\treturn true;",
            "}",
            "static int atomic_pool_expand(struct gen_pool *pool, size_t pool_size,",
            "\t\t\t      gfp_t gfp)",
            "{",
            "\tunsigned int order;",
            "\tstruct page *page = NULL;",
            "\tvoid *addr;",
            "\tint ret = -ENOMEM;",
            "",
            "\t/* Cannot allocate larger than MAX_PAGE_ORDER */",
            "\torder = min(get_order(pool_size), MAX_PAGE_ORDER);",
            "",
            "\tdo {",
            "\t\tpool_size = 1 << (PAGE_SHIFT + order);",
            "\t\tif (cma_in_zone(gfp))",
            "\t\t\tpage = dma_alloc_from_contiguous(NULL, 1 << order,",
            "\t\t\t\t\t\t\t order, false);",
            "\t\tif (!page)",
            "\t\t\tpage = alloc_pages(gfp, order);",
            "\t} while (!page && order-- > 0);",
            "\tif (!page)",
            "\t\tgoto out;",
            "",
            "\tarch_dma_prep_coherent(page, pool_size);",
            "",
            "#ifdef CONFIG_DMA_DIRECT_REMAP",
            "\taddr = dma_common_contiguous_remap(page, pool_size,",
            "\t\t\tpgprot_decrypted(pgprot_dmacoherent(PAGE_KERNEL)),",
            "\t\t\t__builtin_return_address(0));",
            "\tif (!addr)",
            "\t\tgoto free_page;",
            "#else",
            "\taddr = page_to_virt(page);",
            "#endif",
            "\t/*",
            "\t * Memory in the atomic DMA pools must be unencrypted, the pools do not",
            "\t * shrink so no re-encryption occurs in dma_direct_free().",
            "\t */",
            "\tret = set_memory_decrypted((unsigned long)page_to_virt(page),",
            "\t\t\t\t   1 << order);",
            "\tif (ret)",
            "\t\tgoto remove_mapping;",
            "\tret = gen_pool_add_virt(pool, (unsigned long)addr, page_to_phys(page),",
            "\t\t\t\tpool_size, NUMA_NO_NODE);",
            "\tif (ret)",
            "\t\tgoto encrypt_mapping;",
            "",
            "\tdma_atomic_pool_size_add(gfp, pool_size);",
            "\treturn 0;",
            "",
            "encrypt_mapping:",
            "\tret = set_memory_encrypted((unsigned long)page_to_virt(page),",
            "\t\t\t\t   1 << order);",
            "\tif (WARN_ON_ONCE(ret)) {",
            "\t\t/* Decrypt succeeded but encrypt failed, purposely leak */",
            "\t\tgoto out;",
            "\t}",
            "remove_mapping:",
            "#ifdef CONFIG_DMA_DIRECT_REMAP",
            "\tdma_common_free_remap(addr, pool_size);",
            "free_page:",
            "\t__free_pages(page, order);",
            "#endif",
            "out:",
            "\treturn ret;",
            "}"
          ],
          "function_name": "early_coherent_pool, dma_atomic_pool_debugfs_init, dma_atomic_pool_size_add, cma_in_zone, atomic_pool_expand",
          "description": "实现DMA内存池的动态扩展逻辑，包含解析命令行参数、调试接口注册、内存分配策略选择、CMA区域有效性检测及池扩容操作，支持加密/解密内存映射管理。",
          "similarity": 0.5649285912513733
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/dma/pool.c",
          "start_line": 1,
          "end_line": 28,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 2012 ARM Ltd.",
            " * Copyright (C) 2020 Google LLC",
            " */",
            "#include <linux/cma.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/dma-map-ops.h>",
            "#include <linux/dma-direct.h>",
            "#include <linux/init.h>",
            "#include <linux/genalloc.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "",
            "static struct gen_pool *atomic_pool_dma __ro_after_init;",
            "static unsigned long pool_size_dma;",
            "static struct gen_pool *atomic_pool_dma32 __ro_after_init;",
            "static unsigned long pool_size_dma32;",
            "static struct gen_pool *atomic_pool_kernel __ro_after_init;",
            "static unsigned long pool_size_kernel;",
            "",
            "/* Size can be defined by the coherent_pool command line */",
            "static size_t atomic_pool_size;",
            "",
            "/* Dynamic background expansion when the atomic pool is near capacity */",
            "static struct work_struct atomic_pool_work;",
            ""
          ],
          "function_name": null,
          "description": "定义并初始化用于管理DMA内存池的全局变量，包括针对不同架构（DMA/DMA32/内核）的通用池指针、尺寸参数及动态扩展的工作队列。",
          "similarity": 0.5462188720703125
        }
      ]
    },
    {
      "source_file": "mm/cma.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:42:51\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `cma.c`\n\n---\n\n# cma.c 技术文档\n\n## 1. 文件概述\n\n`cma.c` 是 Linux 内核中 **Contiguous Memory Allocator**（CMA，连续内存分配器）的核心实现文件。该模块用于在系统启动早期预留大块物理连续的内存区域，并在运行时按需分配和释放这些内存，以满足设备驱动（如 GPU、多媒体硬件等）对大块连续物理内存的需求。CMA 在保证系统整体内存碎片可控的前提下，提供了一种高效管理连续内存的机制。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct cma`：表示一个 CMA 区域，包含基地址（`base_pfn`）、页数（`count`）、位图粒度（`order_per_bit`）、名称（`name`）、位图（`bitmap`）及自旋锁等。\n- `cma_areas_data[MAX_CMA_AREAS]`：静态数组，用于存储最多 `MAX_CMA_AREAS` 个 CMA 区域。\n- `cma_areas`：指向当前使用的 CMA 区域数组（可动态扩展）。\n- `cma_area_count`：已注册的 CMA 区域数量。\n- `cma_mutex`：保护 CMA 区域注册过程的互斥锁。\n\n### 主要函数\n- `cma_get_base()` / `cma_get_size()` / `cma_get_name()`：获取 CMA 区域的基地址、大小和名称。\n- `cma_bitmap_aligned_mask()` / `cma_bitmap_aligned_offset()` / `cma_bitmap_pages_to_bits()`：辅助函数，用于处理位图对齐和单位转换。\n- `cma_clear_bitmap()`：在 CMA 位图中标记指定范围为“空闲”。\n- `cma_activate_area()`：激活一个已预留的 CMA 区域，初始化其位图并验证区域有效性。\n- `cma_init_reserved_areas()`：在内核初始化阶段（`core_initcall`）激活所有已声明的 CMA 区域。\n- `cma_reserve_pages_on_error()`：设置标志，指示在激活失败时是否保留页面不释放回 buddy 系统。\n- `cma_alloc_areas()`：动态扩展 CMA 区域数组容量。\n- `cma_init_reserved_mem()`：从**已通过 memblock 预留的内存区域**创建 CMA 区域。\n- `cma_declare_contiguous_nid()`：**直接通过 memblock 预留内存并创建 CMA 区域**（支持 NUMA 节点指定）。\n\n## 3. 关键实现\n\n### 位图管理\n- CMA 使用位图（`bitmap`）跟踪区域内页面的分配状态。\n- 每个位可代表 `2^order_per_bit` 个页面（即 `1 << order_per_bit` 页），以减少位图内存开销。\n- 对齐分配通过 `cma_bitmap_aligned_mask()` 和 `cma_bitmap_aligned_offset()` 计算位图中的对齐偏移，确保分配起始地址满足对齐要求。\n\n### 区域激活与验证\n- `cma_activate_area()` 在内核 slab 分配器可用后执行：\n  - 分配位图内存（`bitmap_zalloc`）。\n  - **强制要求整个 CMA 区域位于同一内存 zone**（如 DMA、Normal），因为后续的 `alloc_contig_range()` 要求如此。\n  - 调用 `init_cma_reserved_pageblock()` 将页面块标记为 MIGRATE_CMA 类型，使其可被 CMA 分配器迁移/回收。\n- 若区域跨 zone 或位图分配失败，则根据 `reserve_pages_on_error` 标志决定是否将页面释放回 buddy 系统。\n\n### 内存预留方式\n- **方式一**（`cma_init_reserved_mem`）：由平台代码先调用 `memblock_reserve()` 预留内存，再通过此函数将其注册为 CMA 区域。\n- **方式二**（`cma_declare_contiguous_nid`）：直接在此函数内部调用 memblock 接口预留内存（支持指定 base/limit/alignment/fixed/NUMA node），是更常用的接口。\n\n### 初始化流程\n- CMA 区域在早期启动阶段通过上述两个函数之一注册（仅记录元数据）。\n- 所有区域在 `core_initcall` 阶段统一通过 `cma_init_reserved_areas()` 激活，此时内存子系统已基本就绪。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm.h>`、`<linux/memblock.h>`、`internal.h` 等，使用 page、zone、buddy allocator、migration 等机制。\n- **同步原语**：使用 `mutex`（`cma_mutex`）和 `spinlock`（`cma->lock`）保证并发安全。\n- **调试支持**：集成 `CONFIG_CMA_DEBUG`、`CONFIG_CMA_DEBUGFS`、`trace/events/cma.h` 提供调试信息和运行时监控。\n- **架构相关**：依赖 `PFN_PHYS`、`__pa()` 等宏，需架构提供正确实现。\n- **NUMA 支持**：通过 `nid` 参数支持多节点系统（需 `CONFIG_NUMA`）。\n\n## 5. 使用场景\n\n- **设备驱动**：GPU、视频编解码器、DMA 引擎等需要大块连续物理内存的驱动通过 `dma_alloc_coherent()` 等接口间接使用 CMA。\n- **系统启动配置**：通过内核命令行参数（如 `cma=64M@0-0xffffffff`）或设备树（`reserved-memory` 节点）声明 CMA 区域，最终由 `cma_declare_contiguous_nid()` 处理。\n- **平台特定预留**：SoC 厂商在板级初始化代码中调用 `cma_init_reserved_mem()` 将特定物理地址范围注册为 CMA。\n- **内存热插拔/休眠**：CMA 区域在系统休眠前需释放所有分配，在恢复后重新激活（依赖底层内存管理支持）。",
      "similarity": 0.6371853947639465,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/cma.c",
          "start_line": 196,
          "end_line": 385,
          "content": [
            "int __init cma_init_reserved_mem(phys_addr_t base, phys_addr_t size,",
            "\t\t\t\t unsigned int order_per_bit,",
            "\t\t\t\t const char *name,",
            "\t\t\t\t struct cma **res_cma)",
            "{",
            "\tstruct cma *cma;",
            "",
            "\t/* Sanity checks */",
            "\tif (cma_area_count == cma_areas_size) {",
            "\t\tpr_err(\"Not enough slots for CMA reserved regions!\\n\");",
            "\t\treturn -ENOSPC;",
            "\t}",
            "",
            "\tif (!size || !memblock_is_region_reserved(base, size))",
            "\t\treturn -EINVAL;",
            "",
            "\t/* ensure minimal alignment required by mm core */",
            "\tif (!IS_ALIGNED(base | size, CMA_MIN_ALIGNMENT_BYTES))",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * Each reserved area must be initialised later, when more kernel",
            "\t * subsystems (like slab allocator) are available.",
            "\t */",
            "\tcma = &cma_areas[cma_area_count];",
            "",
            "\tif (name)",
            "\t\tsnprintf(cma->name, CMA_MAX_NAME, name);",
            "\telse",
            "\t\tsnprintf(cma->name, CMA_MAX_NAME,  \"cma%d\\n\", cma_area_count);",
            "",
            "\tcma->base_pfn = PFN_DOWN(base);",
            "\tcma->count = size >> PAGE_SHIFT;",
            "\tcma->order_per_bit = order_per_bit;",
            "\t*res_cma = cma;",
            "\tcma_area_count++;",
            "\ttotalcma_pages += cma->count;",
            "",
            "\treturn 0;",
            "}",
            "int __init cma_declare_contiguous_nid(phys_addr_t base,",
            "\t\t\tphys_addr_t size, phys_addr_t limit,",
            "\t\t\tphys_addr_t alignment, unsigned int order_per_bit,",
            "\t\t\tbool fixed, const char *name, struct cma **res_cma,",
            "\t\t\tint nid)",
            "{",
            "\tphys_addr_t memblock_end = memblock_end_of_DRAM();",
            "\tphys_addr_t highmem_start;",
            "\tint ret = 0;",
            "",
            "\t/*",
            "\t * We can't use __pa(high_memory) directly, since high_memory",
            "\t * isn't a valid direct map VA, and DEBUG_VIRTUAL will (validly)",
            "\t * complain. Find the boundary by adding one to the last valid",
            "\t * address.",
            "\t */",
            "\thighmem_start = __pa(high_memory - 1) + 1;",
            "\tpr_debug(\"%s(size %pa, base %pa, limit %pa alignment %pa)\\n\",",
            "\t\t__func__, &size, &base, &limit, &alignment);",
            "",
            "\tif (cma_area_count == cma_areas_size) {",
            "\t\tpr_err(\"Not enough slots for CMA reserved regions!\\n\");",
            "\t\treturn -ENOSPC;",
            "\t}",
            "",
            "\tif (!size)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (alignment && !is_power_of_2(alignment))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (!IS_ENABLED(CONFIG_NUMA))",
            "\t\tnid = NUMA_NO_NODE;",
            "",
            "\t/* Sanitise input arguments. */",
            "\talignment = max_t(phys_addr_t, alignment, CMA_MIN_ALIGNMENT_BYTES);",
            "\tif (fixed && base & (alignment - 1)) {",
            "\t\tret = -EINVAL;",
            "\t\tpr_err(\"Region at %pa must be aligned to %pa bytes\\n\",",
            "\t\t\t&base, &alignment);",
            "\t\tgoto err;",
            "\t}",
            "\tbase = ALIGN(base, alignment);",
            "\tsize = ALIGN(size, alignment);",
            "\tlimit &= ~(alignment - 1);",
            "",
            "\tif (!base)",
            "\t\tfixed = false;",
            "",
            "\t/* size should be aligned with order_per_bit */",
            "\tif (!IS_ALIGNED(size >> PAGE_SHIFT, 1 << order_per_bit))",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * If allocating at a fixed base the request region must not cross the",
            "\t * low/high memory boundary.",
            "\t */",
            "\tif (fixed && base < highmem_start && base + size > highmem_start) {",
            "\t\tret = -EINVAL;",
            "\t\tpr_err(\"Region at %pa defined on low/high memory boundary (%pa)\\n\",",
            "\t\t\t&base, &highmem_start);",
            "\t\tgoto err;",
            "\t}",
            "",
            "\t/*",
            "\t * If the limit is unspecified or above the memblock end, its effective",
            "\t * value will be the memblock end. Set it explicitly to simplify further",
            "\t * checks.",
            "\t */",
            "\tif (limit == 0 || limit > memblock_end)",
            "\t\tlimit = memblock_end;",
            "",
            "\tif (base + size > limit) {",
            "\t\tret = -EINVAL;",
            "\t\tpr_err(\"Size (%pa) of region at %pa exceeds limit (%pa)\\n\",",
            "\t\t\t&size, &base, &limit);",
            "\t\tgoto err;",
            "\t}",
            "",
            "\t/* Reserve memory */",
            "\tif (fixed) {",
            "\t\tif (memblock_is_region_reserved(base, size) ||",
            "\t\t    memblock_reserve(base, size) < 0) {",
            "\t\t\tret = -EBUSY;",
            "\t\t\tgoto err;",
            "\t\t}",
            "\t} else {",
            "\t\tphys_addr_t addr = 0;",
            "",
            "\t\t/*",
            "\t\t * If there is enough memory, try a bottom-up allocation first.",
            "\t\t * It will place the new cma area close to the start of the node",
            "\t\t * and guarantee that the compaction is moving pages out of the",
            "\t\t * cma area and not into it.",
            "\t\t * Avoid using first 4GB to not interfere with constrained zones",
            "\t\t * like DMA/DMA32.",
            "\t\t */",
            "#ifdef CONFIG_PHYS_ADDR_T_64BIT",
            "\t\tif (!memblock_bottom_up() && memblock_end >= SZ_4G + size) {",
            "\t\t\tmemblock_set_bottom_up(true);",
            "\t\t\taddr = memblock_alloc_range_nid(size, alignment, SZ_4G,",
            "\t\t\t\t\t\t\tlimit, nid, true);",
            "\t\t\tmemblock_set_bottom_up(false);",
            "\t\t}",
            "#endif",
            "",
            "\t\t/*",
            "\t\t * All pages in the reserved area must come from the same zone.",
            "\t\t * If the requested region crosses the low/high memory boundary,",
            "\t\t * try allocating from high memory first and fall back to low",
            "\t\t * memory in case of failure.",
            "\t\t */",
            "\t\tif (!addr && base < highmem_start && limit > highmem_start) {",
            "\t\t\taddr = memblock_alloc_range_nid(size, alignment,",
            "\t\t\t\t\thighmem_start, limit, nid, true);",
            "\t\t\tlimit = highmem_start;",
            "\t\t}",
            "",
            "\t\tif (!addr) {",
            "\t\t\taddr = memblock_alloc_range_nid(size, alignment, base,",
            "\t\t\t\t\tlimit, nid, true);",
            "\t\t\tif (!addr) {",
            "\t\t\t\tret = -ENOMEM;",
            "\t\t\t\tgoto err;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * kmemleak scans/reads tracked objects for pointers to other",
            "\t\t * objects but this address isn't mapped and accessible",
            "\t\t */",
            "\t\tkmemleak_ignore_phys(addr);",
            "\t\tbase = addr;",
            "\t}",
            "",
            "\tret = cma_init_reserved_mem(base, size, order_per_bit, name, res_cma);",
            "\tif (ret)",
            "\t\tgoto free_mem;",
            "",
            "\tpr_info(\"Reserved %ld MiB at %pa on node %d\\n\", (unsigned long)size / SZ_1M,",
            "\t\t&base, nid);",
            "\treturn 0;",
            "",
            "free_mem:",
            "\tmemblock_phys_free(base, size);",
            "err:",
            "\tpr_err(\"Failed to reserve %ld MiB on node %d\\n\", (unsigned long)size / SZ_1M,",
            "\t       nid);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "cma_init_reserved_mem, cma_declare_contiguous_nid",
          "description": "提供CMA区域的声明与内存预留接口，包含对齐校验、节点绑定、内存范围限制处理及物理地址分配逻辑，确保CMA区域满足系统约束条件并正确初始化。",
          "similarity": 0.6077442169189453
        },
        {
          "chunk_id": 1,
          "file_path": "mm/cma.c",
          "start_line": 46,
          "end_line": 163,
          "content": [
            "phys_addr_t cma_get_base(const struct cma *cma)",
            "{",
            "\treturn PFN_PHYS(cma->base_pfn);",
            "}",
            "unsigned long cma_get_size(const struct cma *cma)",
            "{",
            "\treturn cma->count << PAGE_SHIFT;",
            "}",
            "static unsigned long cma_bitmap_aligned_mask(const struct cma *cma,",
            "\t\t\t\t\t     unsigned int align_order)",
            "{",
            "\tif (align_order <= cma->order_per_bit)",
            "\t\treturn 0;",
            "\treturn (1UL << (align_order - cma->order_per_bit)) - 1;",
            "}",
            "static unsigned long cma_bitmap_aligned_offset(const struct cma *cma,",
            "\t\t\t\t\t       unsigned int align_order)",
            "{",
            "\treturn (cma->base_pfn & ((1UL << align_order) - 1))",
            "\t\t>> cma->order_per_bit;",
            "}",
            "static unsigned long cma_bitmap_pages_to_bits(const struct cma *cma,",
            "\t\t\t\t\t      unsigned long pages)",
            "{",
            "\treturn ALIGN(pages, 1UL << cma->order_per_bit) >> cma->order_per_bit;",
            "}",
            "static void cma_clear_bitmap(struct cma *cma, unsigned long pfn,",
            "\t\t\t     unsigned long count)",
            "{",
            "\tunsigned long bitmap_no, bitmap_count;",
            "\tunsigned long flags;",
            "",
            "\tbitmap_no = (pfn - cma->base_pfn) >> cma->order_per_bit;",
            "\tbitmap_count = cma_bitmap_pages_to_bits(cma, count);",
            "",
            "\tspin_lock_irqsave(&cma->lock, flags);",
            "\tbitmap_clear(cma->bitmap, bitmap_no, bitmap_count);",
            "\tspin_unlock_irqrestore(&cma->lock, flags);",
            "}",
            "static void __init cma_activate_area(struct cma *cma)",
            "{",
            "\tunsigned long base_pfn = cma->base_pfn, pfn;",
            "\tstruct zone *zone;",
            "",
            "\tcma->bitmap = bitmap_zalloc(cma_bitmap_maxno(cma), GFP_KERNEL);",
            "\tif (!cma->bitmap)",
            "\t\tgoto out_error;",
            "",
            "\t/*",
            "\t * alloc_contig_range() requires the pfn range specified to be in the",
            "\t * same zone. Simplify by forcing the entire CMA resv range to be in the",
            "\t * same zone.",
            "\t */",
            "\tWARN_ON_ONCE(!pfn_valid(base_pfn));",
            "\tzone = page_zone(pfn_to_page(base_pfn));",
            "\tfor (pfn = base_pfn + 1; pfn < base_pfn + cma->count; pfn++) {",
            "\t\tWARN_ON_ONCE(!pfn_valid(pfn));",
            "\t\tif (page_zone(pfn_to_page(pfn)) != zone)",
            "\t\t\tgoto not_in_zone;",
            "\t}",
            "",
            "\tfor (pfn = base_pfn; pfn < base_pfn + cma->count;",
            "\t     pfn += pageblock_nr_pages)",
            "\t\tinit_cma_reserved_pageblock(pfn_to_page(pfn));",
            "",
            "\tspin_lock_init(&cma->lock);",
            "",
            "#ifdef CONFIG_CMA_DEBUGFS",
            "\tINIT_HLIST_HEAD(&cma->mem_head);",
            "\tspin_lock_init(&cma->mem_head_lock);",
            "#endif",
            "",
            "\treturn;",
            "",
            "not_in_zone:",
            "\tbitmap_free(cma->bitmap);",
            "out_error:",
            "\t/* Expose all pages to the buddy, they are useless for CMA. */",
            "\tif (!cma->reserve_pages_on_error) {",
            "\t\tfor (pfn = base_pfn; pfn < base_pfn + cma->count; pfn++)",
            "\t\t\tfree_reserved_page(pfn_to_page(pfn));",
            "\t}",
            "\ttotalcma_pages -= cma->count;",
            "\tcma->count = 0;",
            "\tpr_err(\"CMA area %s could not be activated\\n\", cma->name);",
            "\treturn;",
            "}",
            "static int __init cma_init_reserved_areas(void)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < cma_area_count; i++)",
            "\t\tcma_activate_area(&cma_areas[i]);",
            "",
            "\treturn 0;",
            "}",
            "void __init cma_reserve_pages_on_error(struct cma *cma)",
            "{",
            "\tcma->reserve_pages_on_error = true;",
            "}",
            "int __init cma_alloc_areas(unsigned int max_cma_size)",
            "{",
            "\tstruct cma *data;",
            "",
            "\tif (max_cma_size <= MAX_CMA_AREAS)",
            "\t\treturn 0;",
            "",
            "\tif (cma_area_count || cma_areas != cma_areas_data)",
            "\t\treturn -EPERM;",
            "",
            "\tdata = memblock_alloc(max_cma_size * sizeof(*cma_areas), SMP_CACHE_BYTES);",
            "\tif (!data)",
            "\t\treturn -ENOMEM;",
            "",
            "\tcma_areas = data;",
            "\tcma_areas_size = max_cma_size;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "cma_get_base, cma_get_size, cma_bitmap_aligned_mask, cma_bitmap_aligned_offset, cma_bitmap_pages_to_bits, cma_clear_bitmap, cma_activate_area, cma_init_reserved_areas, cma_reserve_pages_on_error, cma_alloc_areas",
          "description": "实现CMA区域的核心操作函数，包括获取基地址和大小、位图对齐计算、激活CMA区域（验证内存一致性并初始化位图）、错误处理及动态扩展CMA区域数组的逻辑。",
          "similarity": 0.6017960906028748
        },
        {
          "chunk_id": 3,
          "file_path": "mm/cma.c",
          "start_line": 409,
          "end_line": 498,
          "content": [
            "static void cma_debug_show_areas(struct cma *cma)",
            "{",
            "\tunsigned long next_zero_bit, next_set_bit, nr_zero;",
            "\tunsigned long start = 0;",
            "\tunsigned long nr_part, nr_total = 0;",
            "\tunsigned long nbits = cma_bitmap_maxno(cma);",
            "",
            "\tspin_lock_irq(&cma->lock);",
            "\tpr_info(\"number of available pages: \");",
            "\tfor (;;) {",
            "\t\tnext_zero_bit = find_next_zero_bit(cma->bitmap, nbits, start);",
            "\t\tif (next_zero_bit >= nbits)",
            "\t\t\tbreak;",
            "\t\tnext_set_bit = find_next_bit(cma->bitmap, nbits, next_zero_bit);",
            "\t\tnr_zero = next_set_bit - next_zero_bit;",
            "\t\tnr_part = nr_zero << cma->order_per_bit;",
            "\t\tpr_cont(\"%s%lu@%lu\", nr_total ? \"+\" : \"\", nr_part,",
            "\t\t\tnext_zero_bit);",
            "\t\tnr_total += nr_part;",
            "\t\tstart = next_zero_bit + nr_zero;",
            "\t}",
            "\tpr_cont(\"=> %lu free of %lu total pages\\n\", nr_total, cma->count);",
            "\tspin_unlock_irq(&cma->lock);",
            "}",
            "static inline void cma_debug_show_areas(struct cma *cma) { }",
            "bool cma_pages_valid(struct cma *cma, const struct page *pages,",
            "\t\t     unsigned long count)",
            "{",
            "\tunsigned long pfn;",
            "",
            "\tif (!cma || !pages)",
            "\t\treturn false;",
            "",
            "\tpfn = page_to_pfn(pages);",
            "",
            "\tif (pfn < cma->base_pfn || pfn >= cma->base_pfn + cma->count) {",
            "\t\tpr_debug(\"%s(page %p, count %lu)\\n\", __func__,",
            "\t\t\t\t\t\t(void *)pages, count);",
            "\t\treturn false;",
            "\t}",
            "",
            "\treturn true;",
            "}",
            "bool cma_release(struct cma *cma, const struct page *pages,",
            "\t\t unsigned long count)",
            "{",
            "\tunsigned long pfn;",
            "",
            "\tif (!cma_pages_valid(cma, pages, count))",
            "\t\treturn false;",
            "",
            "\tpr_debug(\"%s(page %p, count %lu)\\n\", __func__, (void *)pages, count);",
            "",
            "\tpfn = page_to_pfn(pages);",
            "",
            "\tVM_BUG_ON(pfn + count > cma->base_pfn + cma->count);",
            "",
            "\tfree_contig_range(pfn, count);",
            "\tcma_clear_bitmap(cma, pfn, count);",
            "\ttrace_cma_release(cma->name, pfn, pages, count);",
            "",
            "\treturn true;",
            "}",
            "bool cma_free_folio(struct cma *cma, const struct folio *folio)",
            "{",
            "\tif (WARN_ON(!folio_test_large(folio)))",
            "\t\treturn false;",
            "",
            "\treturn cma_release(cma, &folio->page, folio_nr_pages(folio));",
            "}",
            "int cma_for_each_area(int (*it)(struct cma *cma, void *data), void *data)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < cma_area_count; i++) {",
            "\t\tint ret = it(&cma_areas[i], data);",
            "",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void cma_enable_concurrency(struct cma *cma)",
            "{",
            "\tif (!cma)",
            "\t\treturn;",
            "",
            "\tcma->no_mutex = true;",
            "}"
          ],
          "function_name": "cma_debug_show_areas, cma_debug_show_areas, cma_pages_valid, cma_release, cma_free_folio, cma_for_each_area, cma_enable_concurrency",
          "description": "涵盖CMA区域的调试展示、页面有效性验证、连续内存释放及遍历操作，通过位图管理释放记录并暴露接口供上层调用，支持并发控制标志位设置。",
          "similarity": 0.5714993476867676
        },
        {
          "chunk_id": 0,
          "file_path": "mm/cma.c",
          "start_line": 1,
          "end_line": 45,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-or-later",
            "/*",
            " * Contiguous Memory Allocator",
            " *",
            " * Copyright (c) 2010-2011 by Samsung Electronics.",
            " * Copyright IBM Corporation, 2013",
            " * Copyright LG Electronics Inc., 2014",
            " * Written by:",
            " *\tMarek Szyprowski <m.szyprowski@samsung.com>",
            " *\tMichal Nazarewicz <mina86@mina86.com>",
            " *\tAneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>",
            " *\tJoonsoo Kim <iamjoonsoo.kim@lge.com>",
            " */",
            "",
            "#define pr_fmt(fmt) \"cma: \" fmt",
            "",
            "#ifdef CONFIG_CMA_DEBUG",
            "#ifndef DEBUG",
            "#  define DEBUG",
            "#endif",
            "#endif",
            "#define CREATE_TRACE_POINTS",
            "",
            "#include <linux/memblock.h>",
            "#include <linux/err.h>",
            "#include <linux/mm.h>",
            "#include <linux/sizes.h>",
            "#include <linux/slab.h>",
            "#include <linux/log2.h>",
            "#include <linux/cma.h>",
            "#include <linux/highmem.h>",
            "#include <linux/io.h>",
            "#include <linux/kmemleak.h>",
            "#include <trace/events/cma.h>",
            "",
            "#include \"internal.h\"",
            "#include \"cma.h\"",
            "",
            "static struct cma cma_areas_data[MAX_CMA_AREAS];",
            "static unsigned int cma_areas_size = MAX_CMA_AREAS;",
            "struct cma *cma_areas = cma_areas_data;",
            "",
            "unsigned cma_area_count;",
            "static DEFINE_MUTEX(cma_mutex);",
            ""
          ],
          "function_name": null,
          "description": "定义了CMA（Contiguous Memory Area）模块的全局数据结构和基础支持，包括CMA区域数组、计数器、互斥锁及必要的头文件引入，用于管理多个CMA区域的配置和状态。",
          "similarity": 0.5439214706420898
        }
      ]
    }
  ]
}