{
  "query": "共享内存死锁检测算法实现",
  "timestamp": "2025-12-26 01:11:39",
  "retrieved_files": [
    {
      "source_file": "kernel/watchdog.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:51:17\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `watchdog.c`\n\n---\n\n# watchdog.c 技术文档\n\n## 1. 文件概述\n\n`watchdog.c` 是 Linux 内核中实现 **硬锁死（hard lockup）** 和 **软锁死（soft lockup）** 检测机制的核心文件。该机制用于监控系统中 CPU 是否因长时间禁用中断或陷入无限循环而无法响应，从而帮助诊断系统挂死问题。硬锁死指 CPU 完全停止响应中断（包括 NMI），软锁死指内核线程长时间占用 CPU 且未调度其他任务。本文件主要聚焦于硬锁死检测的通用框架和部分实现，软锁死检测逻辑主要在其他文件（如 `softlockup.c`）中实现，但两者共享部分配置和控制逻辑。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `watchdog_enabled`：位掩码，表示当前启用的 watchdog 类型（软/硬锁死检测）。\n- `watchdog_user_enabled`：用户空间是否启用 watchdog（默认 1）。\n- `watchdog_hardlockup_user_enabled`：用户空间是否启用硬锁死检测（默认值取决于架构）。\n- `watchdog_softlockup_user_enabled`：用户空间是否启用软锁死检测（默认 1）。\n- `watchdog_thresh`：锁死检测阈值（秒，默认 10 秒）。\n- `watchdog_cpumask`：参与 watchdog 检测的 CPU 掩码。\n- `hardlockup_panic`：硬锁死发生时是否触发内核 panic（默认由 `CONFIG_BOOTPARAM_HARDLOCKUP_PANIC` 决定）。\n- `sysctl_hardlockup_all_cpu_backtrace`（SMP）：硬锁死时是否打印所有 CPU 的 backtrace。\n- `hardlockup_count`（SYSFS）：记录硬锁死事件发生次数。\n\n### 主要函数\n- `hardlockup_detector_disable(void)`：在启动早期禁用硬锁死检测（例如虚拟机环境）。\n- `hardlockup_panic_setup(char *str)`：解析内核启动参数 `nmi_watchdog=`，配置硬锁死行为。\n- `arch_touch_nmi_watchdog(void)`：架构相关函数，用于在关键路径“触摸”硬 watchdog，防止误报（导出符号）。\n- `watchdog_hardlockup_touch_cpu(unsigned int cpu)`：标记指定 CPU 已被“触摸”。\n- `is_hardlockup(unsigned int cpu)`：检查指定 CPU 是否发生硬锁死（基于高精度定时器中断计数）。\n- `watchdog_hardlockup_kick(void)`：在高精度定时器中断中“踢”硬 watchdog（更新中断计数）。\n- `watchdog_hardlockup_check(unsigned int cpu, struct pt_regs *regs)`：执行硬锁死检测逻辑，打印诊断信息并可能触发 panic。\n- `watchdog_hardlockup_enable/disable(unsigned int cpu)`：弱符号函数，由具体硬 watchdog 实现（如 perf-based）覆盖，用于启停 per-CPU 检测。\n- `watchdog_hardlockup_probe(void)`：弱符号函数，由具体实现提供，用于探测硬 watchdog 硬件/机制是否可用。\n\n### 核心数据结构（Per-CPU）\n- `hrtimer_interrupts`：高精度定时器中断计数器（原子变量）。\n- `hrtimer_interrupts_saved`：上次保存的中断计数值。\n- `watchdog_hardlockup_warned`：是否已为该 CPU 打印过硬锁死警告。\n- `watchdog_hardlockup_touched`：该 CPU 是否被“触摸”过（用于豁免检测）。\n\n## 3. 关键实现\n\n### 硬锁死检测机制（基于高精度定时器）\n当配置 `CONFIG_HARDLOCKUP_DETECTOR_COUNTS_HRTIMER` 时，硬锁死检测通过监控 **高精度定时器（hrtimer）中断** 的发生频率实现：\n1. **计数更新**：每次 hrtimer 中断发生时，调用 `watchdog_hardlockup_kick()` 原子递增 per-CPU 计数器 `hrtimer_interrupts`。\n2. **检测逻辑**：在 NMI（不可屏蔽中断）上下文（或其他检测点）调用 `watchdog_hardlockup_check()`：\n   - 若 CPU 被“触摸”（`watchdog_hardlockup_touched` 为真），则清除此标记并跳过检测。\n   - 否则调用 `is_hardlockup()`：比较当前 `hrtimer_interrupts` 与上次保存值 `hrtimer_interrupts_saved`。若相等，说明在检测周期内无 hrtimer 中断，判定为硬锁死。\n3. **告警与处理**：\n   - 首次检测到硬锁死时，打印紧急日志（CPU 信息、模块列表、中断跟踪、寄存器状态或栈回溯）。\n   - 若启用 `sysctl_hardlockup_all_cpu_backtrace`，触发其他 CPU 的 backtrace。\n   - 若 `hardlockup_panic` 为真，调用 `nmi_panic()` 触发内核 panic。\n   - 设置 `watchdog_hardlockup_warned` 避免重复告警。\n\n### 启动参数与配置\n- **`nmi_watchdog=` 参数**：通过 `__setup` 宏注册，支持以下值：\n  - `panic`/`nopanic`：设置 `hardlockup_panic`。\n  - `0`/`1`：启用/禁用硬锁死检测。\n  - `r...`：传递参数给 perf-based 检测器（`hardlockup_config_perf_event`）。\n- **早期禁用**：`hardlockup_detector_disable()` 可在解析命令行前禁用硬检测（如 KVM guest）。\n\n### 架构交互与豁免\n- **`arch_touch_nmi_watchdog()`**：允许架构代码或关键内核路径（如 printk）临时豁免硬 watchdog 检测，防止在已知安全的长操作中误报。使用 `raw_cpu_write` 确保在抢占/中断使能环境下安全。\n\n### 弱符号扩展点\n- `watchdog_hardlockup_enable/disable/probe` 声明为 `__weak`，允许不同架构或检测方法（如基于 perf event 的 NMI watchdog）提供具体实现，实现检测机制的可插拔。\n\n## 4. 依赖关系\n\n- **内核子系统**：\n  - `<linux/nmi.h>`：NMI 处理框架，硬锁死检测通常在 NMI 上下文触发。\n  - `<linux/hrtimer.h>`（隐含）：高精度定时器中断作为检测心跳源。\n  - `<linux/sched/*.h>`：调度器相关（`print_irqtrace_events`, `dump_stack`）。\n  - `<linux/sysctl.h>`：提供 `sysctl_hardlockup_all_cpu_backtrace` 控制接口。\n  - `<linux/sysfs.h>`：暴露 `hardlockup_count` 到 sysfs。\n  - `<asm/irq_regs.h>`：获取中断上下文寄存器状态（`show_regs`）。\n- **配置选项**：\n  - `CONFIG_HARDLOCKUP_DETECTOR`：启用硬锁死检测框架。\n  - `CONFIG_HARDLOCKUP_DETECTOR_COUNTS_HRTIMER`：使用 hrtimer 中断计数实现检测。\n  - `CONFIG_HARDLOCKUP_DETECTOR_SPARC64`：SPARC64 架构默认启用硬检测。\n  - `CONFIG_BOOTPARAM_HARDLOCKUP_PANIC`：设置默认 panic 行为。\n  - `CONFIG_SMP`：多核支持（`all_cpu_backtrace` 功能）。\n  - `CONFIG_SYSFS`：sysfs 接口支持。\n- **其他模块**：依赖具体架构的 NMI 实现（如 x86 的 perf-based NMI watchdog）提供检测触发点。\n\n## 5. 使用场景\n\n- **系统稳定性监控**：在生产服务器或嵌入式设备中持续监控 CPU 响应性，及时发现硬件故障、驱动 bug 或内核死锁导致的系统挂死。\n- **内核调试**：开发人员通过 watchdog 触发的 backtrace 和寄存器转储，定位导致系统无响应的代码路径。\n- **虚拟化环境**：在 hypervisor guest 中可选择性禁用硬 watchdog（因虚拟化开销可能导致误报），通过 `hardlockup_detector_disable()` 或启动参数控制。\n- **实时系统**：结合 CPU 隔离（`isolcpus`）和 watchdog 配置，确保关键 CPU 核心的响应性，同时避免在非关键核上产生干扰。\n- **panic 策略**：通过 `hardlockup_panic` 配置，使系统在硬锁死时自动重启，提高无人值守系统的可用性。",
      "similarity": 0.6216551661491394,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/watchdog.c",
          "start_line": 73,
          "end_line": 217,
          "content": [
            "static ssize_t hardlockup_count_show(struct kobject *kobj, struct kobj_attribute *attr,",
            "\t\t\t\t     char *page)",
            "{",
            "\treturn sysfs_emit(page, \"%u\\n\", hardlockup_count);",
            "}",
            "static __init int kernel_hardlockup_sysfs_init(void)",
            "{",
            "\tsysfs_add_file_to_group(kernel_kobj, &hardlockup_count_attr.attr, NULL);",
            "\treturn 0;",
            "}",
            "void __init hardlockup_detector_disable(void)",
            "{",
            "\twatchdog_hardlockup_user_enabled = 0;",
            "}",
            "static int __init hardlockup_panic_setup(char *str)",
            "{",
            "next:",
            "\tif (!strncmp(str, \"panic\", 5))",
            "\t\thardlockup_panic = 1;",
            "\telse if (!strncmp(str, \"nopanic\", 7))",
            "\t\thardlockup_panic = 0;",
            "\telse if (!strncmp(str, \"0\", 1))",
            "\t\twatchdog_hardlockup_user_enabled = 0;",
            "\telse if (!strncmp(str, \"1\", 1))",
            "\t\twatchdog_hardlockup_user_enabled = 1;",
            "\telse if (!strncmp(str, \"r\", 1))",
            "\t\thardlockup_config_perf_event(str + 1);",
            "\twhile (*(str++)) {",
            "\t\tif (*str == ',') {",
            "\t\t\tstr++;",
            "\t\t\tgoto next;",
            "\t\t}",
            "\t}",
            "\treturn 1;",
            "}",
            "notrace void arch_touch_nmi_watchdog(void)",
            "{",
            "\t/*",
            "\t * Using __raw here because some code paths have",
            "\t * preemption enabled.  If preemption is enabled",
            "\t * then interrupts should be enabled too, in which",
            "\t * case we shouldn't have to worry about the watchdog",
            "\t * going off.",
            "\t */",
            "\traw_cpu_write(watchdog_hardlockup_touched, true);",
            "}",
            "void watchdog_hardlockup_touch_cpu(unsigned int cpu)",
            "{",
            "\tper_cpu(watchdog_hardlockup_touched, cpu) = true;",
            "}",
            "static bool is_hardlockup(unsigned int cpu)",
            "{",
            "\tint hrint = atomic_read(&per_cpu(hrtimer_interrupts, cpu));",
            "",
            "\tif (per_cpu(hrtimer_interrupts_saved, cpu) == hrint)",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * NOTE: we don't need any fancy atomic_t or READ_ONCE/WRITE_ONCE",
            "\t * for hrtimer_interrupts_saved. hrtimer_interrupts_saved is",
            "\t * written/read by a single CPU.",
            "\t */",
            "\tper_cpu(hrtimer_interrupts_saved, cpu) = hrint;",
            "",
            "\treturn false;",
            "}",
            "static void watchdog_hardlockup_kick(void)",
            "{",
            "\tint new_interrupts;",
            "",
            "\tnew_interrupts = atomic_inc_return(this_cpu_ptr(&hrtimer_interrupts));",
            "\twatchdog_buddy_check_hardlockup(new_interrupts);",
            "}",
            "void watchdog_hardlockup_check(unsigned int cpu, struct pt_regs *regs)",
            "{",
            "\tif (per_cpu(watchdog_hardlockup_touched, cpu)) {",
            "\t\tper_cpu(watchdog_hardlockup_touched, cpu) = false;",
            "\t\treturn;",
            "\t}",
            "",
            "\t/*",
            "\t * Check for a hardlockup by making sure the CPU's timer",
            "\t * interrupt is incrementing. The timer interrupt should have",
            "\t * fired multiple times before we overflow'd. If it hasn't",
            "\t * then this is a good indication the cpu is stuck",
            "\t */",
            "\tif (is_hardlockup(cpu)) {",
            "\t\tunsigned int this_cpu = smp_processor_id();",
            "\t\tunsigned long flags;",
            "",
            "#ifdef CONFIG_SYSFS",
            "\t\t++hardlockup_count;",
            "#endif",
            "",
            "\t\t/* Only print hardlockups once. */",
            "\t\tif (per_cpu(watchdog_hardlockup_warned, cpu))",
            "\t\t\treturn;",
            "",
            "\t\t/*",
            "\t\t * Prevent multiple hard-lockup reports if one cpu is already",
            "\t\t * engaged in dumping all cpu back traces.",
            "\t\t */",
            "\t\tif (sysctl_hardlockup_all_cpu_backtrace) {",
            "\t\t\tif (test_and_set_bit_lock(0, &hard_lockup_nmi_warn))",
            "\t\t\t\treturn;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * NOTE: we call printk_cpu_sync_get_irqsave() after printing",
            "\t\t * the lockup message. While it would be nice to serialize",
            "\t\t * that printout, we really want to make sure that if some",
            "\t\t * other CPU somehow locked up while holding the lock associated",
            "\t\t * with printk_cpu_sync_get_irqsave() that we can still at least",
            "\t\t * get the message about the lockup out.",
            "\t\t */",
            "\t\tpr_emerg(\"CPU%u: Watchdog detected hard LOCKUP on cpu %u\\n\", this_cpu, cpu);",
            "\t\tprintk_cpu_sync_get_irqsave(flags);",
            "",
            "\t\tprint_modules();",
            "\t\tprint_irqtrace_events(current);",
            "\t\tif (cpu == this_cpu) {",
            "\t\t\tif (regs)",
            "\t\t\t\tshow_regs(regs);",
            "\t\t\telse",
            "\t\t\t\tdump_stack();",
            "\t\t\tprintk_cpu_sync_put_irqrestore(flags);",
            "\t\t} else {",
            "\t\t\tprintk_cpu_sync_put_irqrestore(flags);",
            "\t\t\ttrigger_single_cpu_backtrace(cpu);",
            "\t\t}",
            "",
            "\t\tif (sysctl_hardlockup_all_cpu_backtrace) {",
            "\t\t\ttrigger_allbutcpu_cpu_backtrace(cpu);",
            "\t\t\tif (!hardlockup_panic)",
            "\t\t\t\tclear_bit_unlock(0, &hard_lockup_nmi_warn);",
            "\t\t}",
            "",
            "\t\tif (hardlockup_panic)",
            "\t\t\tnmi_panic(regs, \"Hard LOCKUP\");",
            "",
            "\t\tper_cpu(watchdog_hardlockup_warned, cpu) = true;",
            "\t} else {",
            "\t\tper_cpu(watchdog_hardlockup_warned, cpu) = false;",
            "\t}",
            "}"
          ],
          "function_name": "hardlockup_count_show, kernel_hardlockup_sysfs_init, hardlockup_detector_disable, hardlockup_panic_setup, arch_touch_nmi_watchdog, watchdog_hardlockup_touch_cpu, is_hardlockup, watchdog_hardlockup_kick, watchdog_hardlockup_check",
          "description": "实现硬锁检测核心逻辑，包含硬锁判断、计数统计、NMI触发电路及异常上报功能，通过中断计数器检测CPU卡顿。",
          "similarity": 0.6391283273696899
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/watchdog.c",
          "start_line": 494,
          "end_line": 595,
          "content": [
            "static void tabulate_irq_count(struct irq_counts *irq_counts, int irq, u32 counts, int rank)",
            "{",
            "\tint i;",
            "\tstruct irq_counts new_count = {irq, counts};",
            "",
            "\tfor (i = 0; i < rank; i++) {",
            "\t\tif (counts > irq_counts[i].counts)",
            "\t\t\tswap(new_count, irq_counts[i]);",
            "\t}",
            "}",
            "static bool need_counting_irqs(void)",
            "{",
            "\tu8 util;",
            "\tint tail = __this_cpu_read(cpustat_tail);",
            "",
            "\ttail = (tail + NUM_HARDIRQ_REPORT - 1) % NUM_HARDIRQ_REPORT;",
            "\tutil = __this_cpu_read(cpustat_util[tail][STATS_HARDIRQ]);",
            "\treturn util > HARDIRQ_PERCENT_THRESH;",
            "}",
            "static void start_counting_irqs(void)",
            "{",
            "\tif (!__this_cpu_read(snapshot_taken)) {",
            "\t\tkstat_snapshot_irqs();",
            "\t\t__this_cpu_write(snapshot_taken, true);",
            "\t}",
            "}",
            "static void stop_counting_irqs(void)",
            "{",
            "\t__this_cpu_write(snapshot_taken, false);",
            "}",
            "static void print_irq_counts(void)",
            "{",
            "\tunsigned int i, count;",
            "\tstruct irq_counts irq_counts_sorted[NUM_HARDIRQ_REPORT] = {",
            "\t\t{-1, 0}, {-1, 0}, {-1, 0}, {-1, 0}, {-1, 0}",
            "\t};",
            "",
            "\tif (__this_cpu_read(snapshot_taken)) {",
            "\t\tfor_each_active_irq(i) {",
            "\t\t\tcount = kstat_get_irq_since_snapshot(i);",
            "\t\t\ttabulate_irq_count(irq_counts_sorted, i, count, NUM_HARDIRQ_REPORT);",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Outputting the \"watchdog\" prefix on every line is redundant and not",
            "\t\t * concise, and the original alarm information is sufficient for",
            "\t\t * positioning in logs, hence here printk() is used instead of pr_crit().",
            "\t\t */",
            "\t\tprintk(KERN_CRIT \"CPU#%d Detect HardIRQ Time exceeds %d%%. Most frequent HardIRQs:\\n\",",
            "\t\t       smp_processor_id(), HARDIRQ_PERCENT_THRESH);",
            "",
            "\t\tfor (i = 0; i < NUM_HARDIRQ_REPORT; i++) {",
            "\t\t\tif (irq_counts_sorted[i].irq == -1)",
            "\t\t\t\tbreak;",
            "",
            "\t\t\tprintk(KERN_CRIT \"\\t#%u: %-10u\\tirq#%d\\n\",",
            "\t\t\t       i + 1, irq_counts_sorted[i].counts,",
            "\t\t\t       irq_counts_sorted[i].irq);",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * If the hardirq time is less than HARDIRQ_PERCENT_THRESH% in the last",
            "\t\t * sample_period, then we suspect the interrupt storm might be subsiding.",
            "\t\t */",
            "\t\tif (!need_counting_irqs())",
            "\t\t\tstop_counting_irqs();",
            "\t}",
            "}",
            "static void report_cpu_status(void)",
            "{",
            "\tprint_cpustat();",
            "\tprint_irq_counts();",
            "}",
            "static inline void update_cpustat(void) { }",
            "static inline void report_cpu_status(void) { }",
            "static inline bool need_counting_irqs(void) { return false; }",
            "static inline void start_counting_irqs(void) { }",
            "static inline void stop_counting_irqs(void) { }",
            "static int get_softlockup_thresh(void)",
            "{",
            "\treturn watchdog_thresh * 2;",
            "}",
            "static unsigned long get_timestamp(void)",
            "{",
            "\treturn running_clock() >> 30LL;  /* 2^30 ~= 10^9 */",
            "}",
            "static void set_sample_period(void)",
            "{",
            "\t/*",
            "\t * convert watchdog_thresh from seconds to ns",
            "\t * the divide by 5 is to give hrtimer several chances (two",
            "\t * or three with the current relation between the soft",
            "\t * and hard thresholds) to increment before the",
            "\t * hardlockup detector generates a warning",
            "\t */",
            "\tsample_period = get_softlockup_thresh() * ((u64)NSEC_PER_SEC / NUM_SAMPLE_PERIODS);",
            "\twatchdog_update_hrtimer_threshold(sample_period);",
            "}",
            "static void update_report_ts(void)",
            "{",
            "\t__this_cpu_write(watchdog_report_ts, get_timestamp());",
            "}"
          ],
          "function_name": "tabulate_irq_count, need_counting_irqs, start_counting_irqs, stop_counting_irqs, print_irq_counts, report_cpu_status, update_cpustat, report_cpu_status, need_counting_irqs, start_counting_irqs, stop_counting_irqs, get_softlockup_thresh, get_timestamp, set_sample_period, update_report_ts",
          "description": "实现中断统计分析模块，通过记录中断次数分布识别潜在中断风暴，为软锁检测提供上下文信息。",
          "similarity": 0.598289966583252
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/watchdog.c",
          "start_line": 626,
          "end_line": 802,
          "content": [
            "static void update_touch_ts(void)",
            "{",
            "\t__this_cpu_write(watchdog_touch_ts, get_timestamp());",
            "\tupdate_report_ts();",
            "}",
            "notrace void touch_softlockup_watchdog_sched(void)",
            "{",
            "\t/*",
            "\t * Preemption can be enabled.  It doesn't matter which CPU's watchdog",
            "\t * report period gets restarted here, so use the raw_ operation.",
            "\t */",
            "\traw_cpu_write(watchdog_report_ts, SOFTLOCKUP_DELAY_REPORT);",
            "}",
            "notrace void touch_softlockup_watchdog(void)",
            "{",
            "\ttouch_softlockup_watchdog_sched();",
            "\twq_watchdog_touch(raw_smp_processor_id());",
            "}",
            "void touch_all_softlockup_watchdogs(void)",
            "{",
            "\tint cpu;",
            "",
            "\t/*",
            "\t * watchdog_mutex cannpt be taken here, as this might be called",
            "\t * from (soft)interrupt context, so the access to",
            "\t * watchdog_allowed_cpumask might race with a concurrent update.",
            "\t *",
            "\t * The watchdog time stamp can race against a concurrent real",
            "\t * update as well, the only side effect might be a cycle delay for",
            "\t * the softlockup check.",
            "\t */",
            "\tfor_each_cpu(cpu, &watchdog_allowed_mask) {",
            "\t\tper_cpu(watchdog_report_ts, cpu) = SOFTLOCKUP_DELAY_REPORT;",
            "\t\twq_watchdog_touch(cpu);",
            "\t}",
            "}",
            "void touch_softlockup_watchdog_sync(void)",
            "{",
            "\t__this_cpu_write(softlockup_touch_sync, true);",
            "\t__this_cpu_write(watchdog_report_ts, SOFTLOCKUP_DELAY_REPORT);",
            "}",
            "static int is_softlockup(unsigned long touch_ts,",
            "\t\t\t unsigned long period_ts,",
            "\t\t\t unsigned long now)",
            "{",
            "\tif ((watchdog_enabled & WATCHDOG_SOFTOCKUP_ENABLED) && watchdog_thresh) {",
            "\t\t/*",
            "\t\t * If period_ts has not been updated during a sample_period, then",
            "\t\t * in the subsequent few sample_periods, period_ts might also not",
            "\t\t * be updated, which could indicate a potential softlockup. In",
            "\t\t * this case, if we suspect the cause of the potential softlockup",
            "\t\t * might be interrupt storm, then we need to count the interrupts",
            "\t\t * to find which interrupt is storming.",
            "\t\t */",
            "\t\tif (time_after_eq(now, period_ts + get_softlockup_thresh() / NUM_SAMPLE_PERIODS) &&",
            "\t\t    need_counting_irqs())",
            "\t\t\tstart_counting_irqs();",
            "",
            "\t\t/* Warn about unreasonable delays. */",
            "\t\tif (time_after(now, period_ts + get_softlockup_thresh()))",
            "\t\t\treturn now - touch_ts;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int softlockup_fn(void *data)",
            "{",
            "\tupdate_touch_ts();",
            "\tstop_counting_irqs();",
            "\tcomplete(this_cpu_ptr(&softlockup_completion));",
            "",
            "\treturn 0;",
            "}",
            "static enum hrtimer_restart watchdog_timer_fn(struct hrtimer *hrtimer)",
            "{",
            "\tunsigned long touch_ts, period_ts, now;",
            "\tstruct pt_regs *regs = get_irq_regs();",
            "\tint duration;",
            "\tint softlockup_all_cpu_backtrace = sysctl_softlockup_all_cpu_backtrace;",
            "\tunsigned long flags;",
            "",
            "\tif (!watchdog_enabled)",
            "\t\treturn HRTIMER_NORESTART;",
            "",
            "\twatchdog_hardlockup_kick();",
            "",
            "\t/* kick the softlockup detector */",
            "\tif (completion_done(this_cpu_ptr(&softlockup_completion))) {",
            "\t\treinit_completion(this_cpu_ptr(&softlockup_completion));",
            "\t\tstop_one_cpu_nowait(smp_processor_id(),",
            "\t\t\t\tsoftlockup_fn, NULL,",
            "\t\t\t\tthis_cpu_ptr(&softlockup_stop_work));",
            "\t}",
            "",
            "\t/* .. and repeat */",
            "\thrtimer_forward_now(hrtimer, ns_to_ktime(sample_period));",
            "",
            "\t/*",
            "\t * Read the current timestamp first. It might become invalid anytime",
            "\t * when a virtual machine is stopped by the host or when the watchog",
            "\t * is touched from NMI.",
            "\t */",
            "\tnow = get_timestamp();",
            "\t/*",
            "\t * If a virtual machine is stopped by the host it can look to",
            "\t * the watchdog like a soft lockup. This function touches the watchdog.",
            "\t */",
            "\tkvm_check_and_clear_guest_paused();",
            "\t/*",
            "\t * The stored timestamp is comparable with @now only when not touched.",
            "\t * It might get touched anytime from NMI. Make sure that is_softlockup()",
            "\t * uses the same (valid) value.",
            "\t */",
            "\tperiod_ts = READ_ONCE(*this_cpu_ptr(&watchdog_report_ts));",
            "",
            "\tupdate_cpustat();",
            "",
            "\t/* Reset the interval when touched by known problematic code. */",
            "\tif (period_ts == SOFTLOCKUP_DELAY_REPORT) {",
            "\t\tif (unlikely(__this_cpu_read(softlockup_touch_sync))) {",
            "\t\t\t/*",
            "\t\t\t * If the time stamp was touched atomically",
            "\t\t\t * make sure the scheduler tick is up to date.",
            "\t\t\t */",
            "\t\t\t__this_cpu_write(softlockup_touch_sync, false);",
            "\t\t\tsched_clock_tick();",
            "\t\t}",
            "",
            "\t\tupdate_report_ts();",
            "\t\treturn HRTIMER_RESTART;",
            "\t}",
            "",
            "\t/* Check for a softlockup. */",
            "\ttouch_ts = __this_cpu_read(watchdog_touch_ts);",
            "\tduration = is_softlockup(touch_ts, period_ts, now);",
            "\tif (unlikely(duration)) {",
            "#ifdef CONFIG_SYSFS",
            "\t\t++softlockup_count;",
            "#endif",
            "",
            "\t\t/*",
            "\t\t * Prevent multiple soft-lockup reports if one cpu is already",
            "\t\t * engaged in dumping all cpu back traces.",
            "\t\t */",
            "\t\tif (softlockup_all_cpu_backtrace) {",
            "\t\t\tif (test_and_set_bit_lock(0, &soft_lockup_nmi_warn))",
            "\t\t\t\treturn HRTIMER_RESTART;",
            "\t\t}",
            "",
            "\t\t/* Start period for the next softlockup warning. */",
            "\t\tupdate_report_ts();",
            "",
            "\t\tprintk_cpu_sync_get_irqsave(flags);",
            "\t\tpr_emerg(\"BUG: soft lockup - CPU#%d stuck for %us! [%s:%d]\\n\",",
            "\t\t\tsmp_processor_id(), duration,",
            "\t\t\tcurrent->comm, task_pid_nr(current));",
            "\t\treport_cpu_status();",
            "\t\tprint_modules();",
            "\t\tprint_irqtrace_events(current);",
            "\t\tif (regs)",
            "\t\t\tshow_regs(regs);",
            "\t\telse",
            "\t\t\tdump_stack();",
            "\t\tprintk_cpu_sync_put_irqrestore(flags);",
            "",
            "\t\tif (softlockup_all_cpu_backtrace) {",
            "\t\t\ttrigger_allbutcpu_cpu_backtrace(smp_processor_id());",
            "\t\t\tif (!softlockup_panic)",
            "\t\t\t\tclear_bit_unlock(0, &soft_lockup_nmi_warn);",
            "\t\t}",
            "",
            "\t\tadd_taint(TAINT_SOFTLOCKUP, LOCKDEP_STILL_OK);",
            "\t\tif (softlockup_panic)",
            "\t\t\tpanic(\"softlockup: hung tasks\");",
            "\t}",
            "",
            "\treturn HRTIMER_RESTART;",
            "}"
          ],
          "function_name": "update_touch_ts, touch_softlockup_watchdog_sched, touch_softlockup_watchdog, touch_all_softlockup_watchdogs, touch_softlockup_watchdog_sync, is_softlockup, softlockup_fn, watchdog_timer_fn",
          "description": "处理软锁检测时序逻辑，包含超时判定算法、任务栈回溯触发机制及异常处理流程，协调硬件定时器与软件检测模块。",
          "similarity": 0.5856772661209106
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/watchdog.c",
          "start_line": 257,
          "end_line": 357,
          "content": [
            "static inline void watchdog_hardlockup_kick(void) { }",
            "void __weak watchdog_hardlockup_enable(unsigned int cpu) { }",
            "void __weak watchdog_hardlockup_disable(unsigned int cpu) { }",
            "int __weak __init watchdog_hardlockup_probe(void)",
            "{",
            "\treturn -ENODEV;",
            "}",
            "void __weak watchdog_hardlockup_stop(void) { }",
            "void __weak watchdog_hardlockup_start(void) { }",
            "static void lockup_detector_update_enable(void)",
            "{",
            "\twatchdog_enabled = 0;",
            "\tif (!watchdog_user_enabled)",
            "\t\treturn;",
            "\tif (watchdog_hardlockup_available && watchdog_hardlockup_user_enabled)",
            "\t\twatchdog_enabled |= WATCHDOG_HARDLOCKUP_ENABLED;",
            "\tif (watchdog_softlockup_user_enabled)",
            "\t\twatchdog_enabled |= WATCHDOG_SOFTOCKUP_ENABLED;",
            "}",
            "static ssize_t softlockup_count_show(struct kobject *kobj, struct kobj_attribute *attr,",
            "\t\t\t\t     char *page)",
            "{",
            "\treturn sysfs_emit(page, \"%u\\n\", softlockup_count);",
            "}",
            "static __init int kernel_softlockup_sysfs_init(void)",
            "{",
            "\tsysfs_add_file_to_group(kernel_kobj, &softlockup_count_attr.attr, NULL);",
            "\treturn 0;",
            "}",
            "static int __init softlockup_panic_setup(char *str)",
            "{",
            "\tsoftlockup_panic = simple_strtoul(str, NULL, 0);",
            "\treturn 1;",
            "}",
            "static int __init nowatchdog_setup(char *str)",
            "{",
            "\twatchdog_user_enabled = 0;",
            "\treturn 1;",
            "}",
            "static int __init nosoftlockup_setup(char *str)",
            "{",
            "\twatchdog_softlockup_user_enabled = 0;",
            "\treturn 1;",
            "}",
            "static int __init watchdog_thresh_setup(char *str)",
            "{",
            "\tget_option(&str, &watchdog_thresh);",
            "\treturn 1;",
            "}",
            "static u16 get_16bit_precision(u64 data_ns)",
            "{",
            "\treturn data_ns >> 24LL; /* 2^24ns ~= 16.8ms */",
            "}",
            "static void update_cpustat(void)",
            "{",
            "\tint i;",
            "\tu8 util;",
            "\tu16 old_stat, new_stat;",
            "\tstruct kernel_cpustat kcpustat;",
            "\tu64 *cpustat = kcpustat.cpustat;",
            "\tu8 tail = __this_cpu_read(cpustat_tail);",
            "\tu16 sample_period_16 = get_16bit_precision(sample_period);",
            "",
            "\tkcpustat_cpu_fetch(&kcpustat, smp_processor_id());",
            "",
            "\tfor (i = 0; i < NUM_STATS_PER_GROUP; i++) {",
            "\t\told_stat = __this_cpu_read(cpustat_old[i]);",
            "\t\tnew_stat = get_16bit_precision(cpustat[tracked_stats[i]]);",
            "\t\tutil = DIV_ROUND_UP(100 * (new_stat - old_stat), sample_period_16);",
            "\t\t__this_cpu_write(cpustat_util[tail][i], util);",
            "\t\t__this_cpu_write(cpustat_old[i], new_stat);",
            "\t}",
            "",
            "\t__this_cpu_write(cpustat_tail, (tail + 1) % NUM_SAMPLE_PERIODS);",
            "}",
            "static void print_cpustat(void)",
            "{",
            "\tint i, group;",
            "\tu8 tail = __this_cpu_read(cpustat_tail);",
            "\tu64 sample_period_second = sample_period;",
            "",
            "\tdo_div(sample_period_second, NSEC_PER_SEC);",
            "",
            "\t/*",
            "\t * Outputting the \"watchdog\" prefix on every line is redundant and not",
            "\t * concise, and the original alarm information is sufficient for",
            "\t * positioning in logs, hence here printk() is used instead of pr_crit().",
            "\t */",
            "\tprintk(KERN_CRIT \"CPU#%d Utilization every %llus during lockup:\\n\",",
            "\t       smp_processor_id(), sample_period_second);",
            "",
            "\tfor (i = 0; i < NUM_SAMPLE_PERIODS; i++) {",
            "\t\tgroup = (tail + i) % NUM_SAMPLE_PERIODS;",
            "\t\tprintk(KERN_CRIT \"\\t#%d: %3u%% system,\\t%3u%% softirq,\\t\"",
            "\t\t\t\"%3u%% hardirq,\\t%3u%% idle\\n\", i + 1,",
            "\t\t\t__this_cpu_read(cpustat_util[group][STATS_SYSTEM]),",
            "\t\t\t__this_cpu_read(cpustat_util[group][STATS_SOFTIRQ]),",
            "\t\t\t__this_cpu_read(cpustat_util[group][STATS_HARDIRQ]),",
            "\t\t\t__this_cpu_read(cpustat_util[group][STATS_IDLE]));",
            "\t}",
            "}"
          ],
          "function_name": "watchdog_hardlockup_kick, watchdog_hardlockup_enable, watchdog_hardlockup_disable, watchdog_hardlockup_probe, watchdog_hardlockup_stop, watchdog_hardlockup_start, lockup_detector_update_enable, softlockup_count_show, kernel_softlockup_sysfs_init, softlockup_panic_setup, nowatchdog_setup, nosoftlockup_setup, watchdog_thresh_setup, get_16bit_precision, update_cpustat, print_cpustat",
          "description": "提供软锁检测支持，包含统计周期设置、CPU利用率采集、中断事件追踪等辅助功能，维护软锁检测相关状态机。",
          "similarity": 0.566789984703064
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/watchdog.c",
          "start_line": 1,
          "end_line": 72,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Detect hard and soft lockups on a system",
            " *",
            " * started by Don Zickus, Copyright (C) 2010 Red Hat, Inc.",
            " *",
            " * Note: Most of this code is borrowed heavily from the original softlockup",
            " * detector, so thanks to Ingo for the initial implementation.",
            " * Some chunks also taken from the old x86-specific nmi watchdog code, thanks",
            " * to those contributors as well.",
            " */",
            "",
            "#define pr_fmt(fmt) \"watchdog: \" fmt",
            "",
            "#include <linux/cpu.h>",
            "#include <linux/init.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/irq.h>",
            "#include <linux/irqdesc.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/kvm_para.h>",
            "#include <linux/math64.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/nmi.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/tick.h>",
            "",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/isolation.h>",
            "",
            "#include <asm/irq_regs.h>",
            "",
            "static DEFINE_MUTEX(watchdog_mutex);",
            "",
            "#if defined(CONFIG_HARDLOCKUP_DETECTOR) || defined(CONFIG_HARDLOCKUP_DETECTOR_SPARC64)",
            "# define WATCHDOG_HARDLOCKUP_DEFAULT\t1",
            "#else",
            "# define WATCHDOG_HARDLOCKUP_DEFAULT\t0",
            "#endif",
            "",
            "#define NUM_SAMPLE_PERIODS\t5",
            "",
            "unsigned long __read_mostly watchdog_enabled;",
            "int __read_mostly watchdog_user_enabled = 1;",
            "static int __read_mostly watchdog_hardlockup_user_enabled = WATCHDOG_HARDLOCKUP_DEFAULT;",
            "static int __read_mostly watchdog_softlockup_user_enabled = 1;",
            "int __read_mostly watchdog_thresh = 10;",
            "static int __read_mostly watchdog_thresh_next;",
            "static int __read_mostly watchdog_hardlockup_available;",
            "",
            "struct cpumask watchdog_cpumask __read_mostly;",
            "unsigned long *watchdog_cpumask_bits = cpumask_bits(&watchdog_cpumask);",
            "",
            "#ifdef CONFIG_HARDLOCKUP_DETECTOR",
            "",
            "# ifdef CONFIG_SMP",
            "int __read_mostly sysctl_hardlockup_all_cpu_backtrace;",
            "# endif /* CONFIG_SMP */",
            "",
            "/*",
            " * Should we panic when a soft-lockup or hard-lockup occurs:",
            " */",
            "unsigned int __read_mostly hardlockup_panic =",
            "\t\t\tIS_ENABLED(CONFIG_BOOTPARAM_HARDLOCKUP_PANIC);",
            "",
            "#ifdef CONFIG_SYSFS",
            "",
            "static unsigned int hardlockup_count;",
            ""
          ],
          "function_name": null,
          "description": "定义硬锁和软锁检测模块的全局变量及配置选项，初始化硬锁检测相关数据结构和默认启用状态。",
          "similarity": 0.5585627555847168
        }
      ]
    },
    {
      "source_file": "kernel/watchdog_buddy.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:51:46\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `watchdog_buddy.c`\n\n---\n\n# watchdog_buddy.c 技术文档\n\n## 1. 文件概述\n\n`watchdog_buddy.c` 实现了 Linux 内核硬锁定检测（hardlockup detection）机制中的“伙伴检查”（buddy checking）逻辑。该机制通过让一个 CPU 负责监控其“下一个”CPU 的高精度定时器（hrtimer）中断是否正常触发，从而检测目标 CPU 是否陷入硬锁定状态（即完全停止响应中断）。该文件通过维护一个在线 CPU 掩码（`watchdog_cpus`）并定义 CPU 之间的监控关系，避免在 CPU 上下线过程中产生误报。\n\n## 2. 核心功能\n\n### 数据结构\n- `watchdog_cpus`：静态的 `cpumask_t` 类型变量，记录当前参与硬锁定检测的所有在线 CPU，使用 `__read_mostly` 优化缓存访问。\n\n### 主要函数\n- `watchdog_next_cpu(unsigned int cpu)`：根据 `watchdog_cpus` 掩码，返回指定 CPU 的下一个参与监控的 CPU；若已到末尾则回绕到第一个；若掩码中仅有一个 CPU，则返回 `nr_cpu_ids`（表示无效）。\n- `watchdog_hardlockup_probe(void)`：硬锁定探测初始化函数（当前实现为空，返回 0）。\n- `watchdog_hardlockup_enable(unsigned int cpu)`：启用指定 CPU 的硬锁定检测功能，将其加入 `watchdog_cpus` 掩码，并通过“触摸”（touch）机制防止上下线过程中的误报。\n- `watchdog_hardlockup_disable(unsigned int cpu)`：禁用指定 CPU 的硬锁定检测功能，将其从 `watchdog_cpus` 掩码中移除，并同样通过“触摸”机制防止误报。\n- `watchdog_buddy_check_hardlockup(int hrtimer_interrupts)`：由当前 CPU 调用，周期性检查其“伙伴”（下一个）CPU 是否发生硬锁定。\n\n## 3. 关键实现\n\n### 伙伴监控机制\n- 每个 CPU 不监控自身，而是监控 `watchdog_cpus` 掩码中逻辑上的“下一个”CPU（通过 `watchdog_next_cpu()` 确定）。\n- 检查频率为每 3 次 hrtimer 中断执行一次（`hrtimer_interrupts % 3 == 0`），对应时间约为 `watchdog_thresh * 1.2` 秒，略大于默认阈值，以平衡灵敏度与开销。\n\n### 防止误报的“触摸”策略\n- **CPU 上线时**：新上线的 CPU 和其下一个 CPU 都会被“触摸”（调用 `watchdog_hardlockup_touch_cpu()`），确保它们的看门狗计数器被重置，避免其他 CPU 在其 hrtimer 首次运行前误判为锁定。\n- **CPU 下线时**：下线 CPU 的下一个 CPU 会被“触摸”，防止前一个 CPU 立即检查该目标而触发误报。\n\n### 内存屏障同步\n- 在修改 `watchdog_cpus` 掩码前后使用 `smp_wmb()`（写内存屏障），确保“触摸”操作在掩码更新前对其他 CPU 可见。\n- 在读取伙伴 CPU 状态前使用 `smp_rmb()`（读内存屏障），确保能观察到最新的掩码状态和触摸操作，维持检查逻辑的一致性。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/cpu.h>`：CPU 热插拔相关接口。\n  - `<linux/cpumask.h>`：CPU 掩码操作函数（如 `cpumask_next`, `cpumask_first`）。\n  - `<linux/kernel.h>`：基础内核定义。\n  - `<linux/nmi.h>`：包含硬锁定检测相关函数声明（如 `watchdog_hardlockup_touch_cpu`, `watchdog_hardlockup_check`）。\n  - `<linux/percpu-defs.h>`：每 CPU 变量支持。\n- **外部函数依赖**：\n  - `watchdog_hardlockup_touch_cpu()` 和 `watchdog_hardlockup_check()`：由其他 watchdog 模块（如 `nmi_watchdog.c`）实现，用于重置看门狗计数器和执行实际锁定检测。\n- **配置依赖**：该文件通常在 `CONFIG_HARDLOCKUP_DETECTOR` 或相关看门狗配置启用时编译。\n\n## 5. 使用场景\n\n- **硬锁定检测**：作为内核 NMI 看门狗（NMI watchdog）的一部分，在启用了硬锁定检测功能的系统中运行。\n- **CPU 热插拔**：在 CPU 动态上线（`CPU_ONLINE`）或下线（`CPU_DEAD`）事件中被调用，确保监控拓扑正确更新且不产生误报。\n- **高可靠性系统**：在服务器、实时系统等对稳定性要求高的环境中，用于及时发现并处理 CPU 完全挂死的严重故障。\n- **调试与诊断**：当系统疑似因内核 bug 导致某 CPU 停止响应时，该机制可触发 panic 或记录日志，辅助问题定位。",
      "similarity": 0.6159678101539612,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/watchdog_buddy.c",
          "start_line": 11,
          "end_line": 109,
          "content": [
            "static unsigned int watchdog_next_cpu(unsigned int cpu)",
            "{",
            "\tunsigned int next_cpu;",
            "",
            "\tnext_cpu = cpumask_next(cpu, &watchdog_cpus);",
            "\tif (next_cpu >= nr_cpu_ids)",
            "\t\tnext_cpu = cpumask_first(&watchdog_cpus);",
            "",
            "\tif (next_cpu == cpu)",
            "\t\treturn nr_cpu_ids;",
            "",
            "\treturn next_cpu;",
            "}",
            "int __init watchdog_hardlockup_probe(void)",
            "{",
            "\treturn 0;",
            "}",
            "void watchdog_hardlockup_enable(unsigned int cpu)",
            "{",
            "\tunsigned int next_cpu;",
            "",
            "\t/*",
            "\t * The new CPU will be marked online before the hrtimer interrupt",
            "\t * gets a chance to run on it. If another CPU tests for a",
            "\t * hardlockup on the new CPU before it has run its the hrtimer",
            "\t * interrupt, it will get a false positive. Touch the watchdog on",
            "\t * the new CPU to delay the check for at least 3 sampling periods",
            "\t * to guarantee one hrtimer has run on the new CPU.",
            "\t */",
            "\twatchdog_hardlockup_touch_cpu(cpu);",
            "",
            "\t/*",
            "\t * We are going to check the next CPU. Our watchdog_hrtimer",
            "\t * need not be zero if the CPU has already been online earlier.",
            "\t * Touch the watchdog on the next CPU to avoid false positive",
            "\t * if we try to check it in less then 3 interrupts.",
            "\t */",
            "\tnext_cpu = watchdog_next_cpu(cpu);",
            "\tif (next_cpu < nr_cpu_ids)",
            "\t\twatchdog_hardlockup_touch_cpu(next_cpu);",
            "",
            "\t/*",
            "\t * Makes sure that watchdog is touched on this CPU before",
            "\t * other CPUs could see it in watchdog_cpus. The counter",
            "\t * part is in watchdog_buddy_check_hardlockup().",
            "\t */",
            "\tsmp_wmb();",
            "",
            "\tcpumask_set_cpu(cpu, &watchdog_cpus);",
            "}",
            "void watchdog_hardlockup_disable(unsigned int cpu)",
            "{",
            "\tunsigned int next_cpu = watchdog_next_cpu(cpu);",
            "",
            "\t/*",
            "\t * Offlining this CPU will cause the CPU before this one to start",
            "\t * checking the one after this one. If this CPU just finished checking",
            "\t * the next CPU and updating hrtimer_interrupts_saved, and then the",
            "\t * previous CPU checks it within one sample period, it will trigger a",
            "\t * false positive. Touch the watchdog on the next CPU to prevent it.",
            "\t */",
            "\tif (next_cpu < nr_cpu_ids)",
            "\t\twatchdog_hardlockup_touch_cpu(next_cpu);",
            "",
            "\t/*",
            "\t * Makes sure that watchdog is touched on the next CPU before",
            "\t * this CPU disappear in watchdog_cpus. The counter part is in",
            "\t * watchdog_buddy_check_hardlockup().",
            "\t */",
            "\tsmp_wmb();",
            "",
            "\tcpumask_clear_cpu(cpu, &watchdog_cpus);",
            "}",
            "void watchdog_buddy_check_hardlockup(int hrtimer_interrupts)",
            "{",
            "\tunsigned int next_cpu;",
            "",
            "\t/*",
            "\t * Test for hardlockups every 3 samples. The sample period is",
            "\t *  watchdog_thresh * 2 / 5, so 3 samples gets us back to slightly over",
            "\t *  watchdog_thresh (over by 20%).",
            "\t */",
            "\tif (hrtimer_interrupts % 3 != 0)",
            "\t\treturn;",
            "",
            "\t/* check for a hardlockup on the next CPU */",
            "\tnext_cpu = watchdog_next_cpu(smp_processor_id());",
            "\tif (next_cpu >= nr_cpu_ids)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Make sure that the watchdog was touched on next CPU when",
            "\t * watchdog_next_cpu() returned another one because of",
            "\t * a change in watchdog_hardlockup_enable()/disable().",
            "\t */",
            "\tsmp_rmb();",
            "",
            "\twatchdog_hardlockup_check(next_cpu, NULL);",
            "}"
          ],
          "function_name": "watchdog_next_cpu, watchdog_hardlockup_probe, watchdog_hardlockup_enable, watchdog_hardlockup_disable, watchdog_buddy_check_hardlockup",
          "description": "实现了看门狗硬锁死检测的CPU管理逻辑，包含CPU遍历、启用/禁用操作及检测触发机制，通过内存屏障保证多CPU状态更新的可见性，提供周期性硬锁死检查功能。",
          "similarity": 0.6420574188232422
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/watchdog_buddy.c",
          "start_line": 1,
          "end_line": 10,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "",
            "#include <linux/cpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/kernel.h>",
            "#include <linux/nmi.h>",
            "#include <linux/percpu-defs.h>",
            "",
            "static cpumask_t __read_mostly watchdog_cpus;",
            ""
          ],
          "function_name": null,
          "description": "定义了一个全局的CPU掩码变量watchdog_cpus，用于跟踪当前参与看门狗机制的CPU列表，初始化为只读属性。",
          "similarity": 0.5020581483840942
        }
      ]
    },
    {
      "source_file": "kernel/module/tree_lookup.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:09:32\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `module\\tree_lookup.c`\n\n---\n\n# module/tree_lookup.c 技术文档\n\n## 1. 文件概述\n\n`module/tree_lookup.c` 实现了一个基于**锁存红黑树（latched RB-tree）** 的模块地址查找机制，用于高效地根据内存地址定位所属的内核模块。该机制专为高性能、低延迟的地址查询场景设计，特别适用于性能事件（perf events）和跟踪（tracing）子系统在任意上下文（包括 NMI）中频繁调用 `__module_address()` 的情况。通过使用 RCU-sched 语义，该实现支持无锁读取，同时保证写操作（模块加载/卸载）的安全性。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `mod_tree_insert(struct module *mod)`  \n  将模块的所有内存区域（按类型）插入全局模块树 `mod_tree`。\n\n- `mod_tree_remove_init(struct module *mod)`  \n  仅移除模块的初始化内存区域（如 `.init.text`、`.init.data` 等）。\n\n- `mod_tree_remove(struct module *mod)`  \n  移除模块的所有内存区域。\n\n- `mod_find(unsigned long addr, struct mod_tree_root *tree)`  \n  在指定模块树中查找包含给定地址 `addr` 的模块，返回对应的 `struct module *`。\n\n- `__mod_tree_insert()` / `__mod_tree_remove()`  \n  内部辅助函数，封装对 `latch_tree_insert()` 和 `latch_tree_erase()` 的调用。\n\n### 关键数据结构\n\n- `struct latch_tree_ops mod_tree_ops`  \n  定义模块树的比较和排序逻辑，包含：\n  - `.less`：节点间大小比较函数\n  - `.comp`：键值与节点的范围比较函数\n\n- `struct mod_tree_node`（隐含在 `struct module_memory` 中）  \n  模块内存区域在红黑树中的节点表示，包含指向所属模块的指针。\n\n## 3. 关键实现\n\n### 锁存红黑树（Latched RB-tree）机制\n- 使用 `latch_tree` 数据结构，支持**双版本（double-buffered）** 更新，允许读者在不加锁的情况下通过 RCU-sched 安全遍历。\n- 写操作（插入/删除）由 `module_mutex` 串行化，确保树结构修改的原子性。\n- 读操作（`mod_find`）可在任意上下文（包括中断、NMI）中执行，无需获取锁。\n\n### 地址范围比较逻辑\n- 每个模块内存区域由基地址（`base`）和大小（`size`）定义。\n- `mod_tree_comp()` 函数实现**区间包含判断**：\n  - 若查询地址 `< base`，返回 `-1`（在左侧）\n  - 若查询地址 `>= base + size`，返回 `1`（在右侧）\n  - 否则返回 `0`（命中该区域）\n\n### 内存区域类型遍历\n- 使用宏 `for_each_mod_mem_type()` 和 `for_class_mod_mem_type()` 遍历模块的所有内存段类型（如代码段、数据段、初始化段等）。\n- 仅当内存区域大小非零时才插入/移除树节点，避免无效条目。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/module.h>`：提供 `struct module` 等核心模块定义\n  - `<linux/rbtree_latch.h>`：提供锁存红黑树实现\n  - `\"internal.h\"`：包含模块子系统内部数据结构（如 `mod_tree` 全局变量、`module_memory` 定义等）\n\n- **全局变量依赖**：\n  - `mod_tree`：全局 `struct mod_tree_root` 实例，定义在 `internal.h` 中\n  - `module_mutex`：序列化模块树修改操作的互斥锁\n\n- **条件编译**：  \n  该文件功能仅在 `CONFIG_PERF_EVENTS || CONFIG_TRACING` 启用时编译，因其主要服务于性能分析和跟踪场景。\n\n## 5. 使用场景\n\n- **性能分析（perf）**：  \n  在 perf 采样中断或 NMI 中，通过 `__module_address()` 快速确定程序计数器（PC）是否位于某个内核模块内，用于符号解析和调用栈展开。\n\n- **内核跟踪（ftrace/kprobes）**：  \n  跟踪点触发时需识别当前执行地址所属模块，以提供模块上下文信息。\n\n- **模块卸载安全检查**：  \n  在模块移除前，通过地址查询验证无活跃引用（如 kprobe、ftrace 等）。\n\n- **内核 Oops/panic 诊断**：  \n  在内核崩溃时，快速定位错误地址所属模块，辅助调试。\n\n该实现通过无锁读取和高效区间查询，显著提升了高频率地址查找场景下的系统性能和实时性。",
      "similarity": 0.6153736710548401,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/module/tree_lookup.c",
          "start_line": 1,
          "end_line": 21,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-or-later",
            "/*",
            " * Modules tree lookup",
            " *",
            " * Copyright (C) 2015 Peter Zijlstra",
            " * Copyright (C) 2015 Rusty Russell",
            " */",
            "",
            "#include <linux/module.h>",
            "#include <linux/rbtree_latch.h>",
            "#include \"internal.h\"",
            "",
            "/*",
            " * Use a latched RB-tree for __module_address(); this allows us to use",
            " * RCU-sched lookups of the address from any context.",
            " *",
            " * This is conditional on PERF_EVENTS || TRACING because those can really hit",
            " * __module_address() hard by doing a lot of stack unwinding; potentially from",
            " * NMI context.",
            " */",
            ""
          ],
          "function_name": null,
          "description": "定义使用带闩锁的RB树结构，用于支持模块地址查询，允许RCU-sched上下文下的安全查找，该实现依赖PERF_EVENTS或TRACING特性以应对高频栈遍历场景",
          "similarity": 0.55284583568573
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/module/tree_lookup.c",
          "start_line": 22,
          "end_line": 84,
          "content": [
            "static __always_inline unsigned long __mod_tree_val(struct latch_tree_node *n)",
            "{",
            "\tstruct module_memory *mod_mem = container_of(n, struct module_memory, mtn.node);",
            "",
            "\treturn (unsigned long)mod_mem->base;",
            "}",
            "static __always_inline unsigned long __mod_tree_size(struct latch_tree_node *n)",
            "{",
            "\tstruct module_memory *mod_mem = container_of(n, struct module_memory, mtn.node);",
            "",
            "\treturn (unsigned long)mod_mem->size;",
            "}",
            "static __always_inline bool",
            "mod_tree_less(struct latch_tree_node *a, struct latch_tree_node *b)",
            "{",
            "\treturn __mod_tree_val(a) < __mod_tree_val(b);",
            "}",
            "static __always_inline int",
            "mod_tree_comp(void *key, struct latch_tree_node *n)",
            "{",
            "\tunsigned long val = (unsigned long)key;",
            "\tunsigned long start, end;",
            "",
            "\tstart = __mod_tree_val(n);",
            "\tif (val < start)",
            "\t\treturn -1;",
            "",
            "\tend = start + __mod_tree_size(n);",
            "\tif (val >= end)",
            "\t\treturn 1;",
            "",
            "\treturn 0;",
            "}",
            "static noinline void __mod_tree_insert(struct mod_tree_node *node, struct mod_tree_root *tree)",
            "{",
            "\tlatch_tree_insert(&node->node, &tree->root, &mod_tree_ops);",
            "}",
            "static void __mod_tree_remove(struct mod_tree_node *node, struct mod_tree_root *tree)",
            "{",
            "\tlatch_tree_erase(&node->node, &tree->root, &mod_tree_ops);",
            "}",
            "void mod_tree_insert(struct module *mod)",
            "{",
            "\tfor_each_mod_mem_type(type) {",
            "\t\tmod->mem[type].mtn.mod = mod;",
            "\t\tif (mod->mem[type].size)",
            "\t\t\t__mod_tree_insert(&mod->mem[type].mtn, &mod_tree);",
            "\t}",
            "}",
            "void mod_tree_remove_init(struct module *mod)",
            "{",
            "\tfor_class_mod_mem_type(type, init) {",
            "\t\tif (mod->mem[type].size)",
            "\t\t\t__mod_tree_remove(&mod->mem[type].mtn, &mod_tree);",
            "\t}",
            "}",
            "void mod_tree_remove(struct module *mod)",
            "{",
            "\tfor_each_mod_mem_type(type) {",
            "\t\tif (mod->mem[type].size)",
            "\t\t\t__mod_tree_remove(&mod->mem[type].mtn, &mod_tree);",
            "\t}",
            "}"
          ],
          "function_name": "__mod_tree_val, __mod_tree_size, mod_tree_less, mod_tree_comp, __mod_tree_insert, __mod_tree_remove, mod_tree_insert, mod_tree_remove_init, mod_tree_remove",
          "description": "实现模块内存区域的树状管理逻辑，包含节点值/大小提取、比较函数及插入/删除操作，通过latch_tree接口维护模块地址映射表，支持模块加载时插入和卸载时移除内存节点",
          "similarity": 0.5361802577972412
        }
      ]
    }
  ]
}