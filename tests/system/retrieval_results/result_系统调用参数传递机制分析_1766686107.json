{
  "query": "系统调用参数传递机制分析",
  "timestamp": "2025-12-26 02:08:27",
  "retrieved_files": [
    {
      "source_file": "kernel/entry/syscall_user_dispatch.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:20:47\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `entry\\syscall_user_dispatch.c`\n\n---\n\n# entry/syscall_user_dispatch.c 技术文档\n\n## 1. 文件概述\n\n`entry/syscall_user_dispatch.c` 实现了 **系统调用用户分发（Syscall User Dispatch, SUD）** 机制，该机制允许用户空间程序通过 `prctl()` 系统调用配置一个“选择器”（selector），用于在特定条件下拦截或允许系统调用的执行。当系统调用指令指针位于指定区域之外且选择器状态为“阻塞”时，内核会回滚该系统调用并向进程发送 `SIGSYS` 信号，从而实现对系统调用的细粒度控制。此功能常用于沙箱、安全监控或调试场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `trigger_sigsys(struct pt_regs *regs)`  \n  构造并强制发送 `SIGSYS` 信号，携带被拦截系统调用的详细信息（如地址、系统调用号、架构等）。\n\n- `syscall_user_dispatch(struct pt_regs *regs)`  \n  系统调用入口处的分发判断逻辑。根据当前指令指针位置和用户选择器状态决定是否拦截系统调用。\n\n- `task_set_syscall_user_dispatch(struct task_struct *task, ...)`  \n  为指定任务设置系统调用用户分发配置（开启/关闭、偏移、长度、选择器地址）。\n\n- `set_syscall_user_dispatch(...)`  \n  为当前任务设置系统调用用户分发配置的封装接口，供 `prctl()` 调用。\n\n- `syscall_user_dispatch_get_config(...)`  \n  通过 `ptrace` 获取指定任务的 SUD 配置。\n\n- `syscall_user_dispatch_set_config(...)`  \n  通过 `ptrace` 设置指定任务的 SUD 配置。\n\n### 关键数据结构\n\n- `struct syscall_user_dispatch`（定义在 `<linux/syscall_user_dispatch.h>`）  \n  存储每个任务的 SUD 配置：\n  - `selector`：指向用户空间选择器字节的指针\n  - `offset` / `len`：允许直接执行系统调用的代码区域（[offset, offset+len)）\n  - `on_dispatch`：标志位，表示当前是否处于分发拦截状态\n\n- `struct ptrace_sud_config`  \n  用于 `ptrace` 接口传递 SUD 配置的结构体，包含 `mode`、`offset`、`len` 和 `selector`。\n\n## 3. 关键实现\n\n### 系统调用拦截逻辑\n\n1. **区域检查**：若当前指令指针（`instruction_pointer(regs)`）落在 `[offset, offset + len)` 范围内，则**允许**系统调用直接执行，不进行拦截。\n2. **vdso 例外**：若系统调用来自 vDSO 中的 `sigreturn`（如 `arch_syscall_is_vdso_sigreturn()` 返回 true），则跳过拦截，避免干扰信号返回路径。\n3. **选择器读取**：若配置了 `selector`，则从用户空间读取一个字节的状态值：\n   - `SYSCALL_DISPATCH_FILTER_ALLOW`（0）：允许系统调用\n   - `SYSCALL_DISPATCH_FILTER_BLOCK`（1）：触发拦截\n   - 其他值：视为非法，发送 `SIGSYS`\n4. **拦截处理**：\n   - 设置 `on_dispatch = true`\n   - 调用 `syscall_rollback()` 回滚系统调用（恢复寄存器状态）\n   - 调用 `trigger_sigsys()` 发送 `SIGSYS` 信号\n\n### 安全与健壮性设计\n\n- **地址合法性校验**：在设置 `selector` 时使用 `access_ok(untagged_addr(selector), ...)`，确保地址可访问，并处理内存标记（如 ARM MTE）场景下调试器（tracer）与被调试进程（tracee）地址标记不一致的问题。\n- **溢出防护**：检查 `offset + len <= offset` 防止整数溢出导致无效区域。\n- **权限隔离**：`ptrace` 接口允许调试器配置其他进程的 SUD，但需具备相应权限。\n\n### 信号信息构造\n\n`trigger_sigsys()` 构造的 `siginfo_t` 包含：\n- `si_signo = SIGSYS`\n- `si_code = SYS_USER_DISPATCH`\n- `si_call_addr`：触发系统调用的用户空间地址\n- `si_syscall`：系统调用号\n- `si_arch`：系统调用架构（如 x86_64、AArch64）\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/prctl.h>`：定义 `PR_SYS_DISPATCH_*` 常量\n  - `<linux/syscall_user_dispatch.h>`：定义 `struct syscall_user_dispatch` 和相关常量\n  - `<asm/syscall.h>`：提供 `syscall_get_arch()`、`syscall_get_nr()` 等架构相关接口\n  - `\"common.h\"`：可能包含内核入口通用辅助函数\n- **内核子系统**：\n  - **调度器（sched）**：访问 `current` 任务结构\n  - **信号子系统（signal）**：发送 `SIGSYS` 信号\n  - **内存管理（uaccess）**：用户空间内存访问（`__get_user`, `access_ok`）\n  - **ptrace**：支持调试器配置 SUD\n  - **ELF**：可能用于架构识别（间接依赖）\n\n## 5. 使用场景\n\n- **沙箱环境**：限制应用只能在特定代码段发起系统调用，防止恶意代码绕过安全策略。\n- **动态二进制插桩（DBI）**：工具（如 Valgrind、Intel Pin）可拦截系统调用进行分析或重定向。\n- **安全监控**：监控程序可配置选择器为“阻塞”，在 `SIGSYS` 信号处理程序中记录或审查系统调用。\n- **调试与测试**：通过 `ptrace` 动态启用/禁用 SUD，用于测试系统调用拦截逻辑。\n- **W^X 策略增强**：结合代码段只读与 SUD，确保只有可信代码路径可发起系统调用。",
      "similarity": 0.6019890308380127,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/entry/syscall_user_dispatch.c",
          "start_line": 127,
          "end_line": 163,
          "content": [
            "int syscall_user_dispatch_get_config(struct task_struct *task, unsigned long size,",
            "\t\t\t\t     void __user *data)",
            "{",
            "\tstruct syscall_user_dispatch *sd = &task->syscall_dispatch;",
            "\tstruct ptrace_sud_config cfg;",
            "",
            "\tif (size != sizeof(cfg))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (test_task_syscall_work(task, SYSCALL_USER_DISPATCH))",
            "\t\tcfg.mode = PR_SYS_DISPATCH_ON;",
            "\telse",
            "\t\tcfg.mode = PR_SYS_DISPATCH_OFF;",
            "",
            "\tcfg.offset = sd->offset;",
            "\tcfg.len = sd->len;",
            "\tcfg.selector = (__u64)(uintptr_t)sd->selector;",
            "",
            "\tif (copy_to_user(data, &cfg, sizeof(cfg)))",
            "\t\treturn -EFAULT;",
            "",
            "\treturn 0;",
            "}",
            "int syscall_user_dispatch_set_config(struct task_struct *task, unsigned long size,",
            "\t\t\t\t     void __user *data)",
            "{",
            "\tstruct ptrace_sud_config cfg;",
            "",
            "\tif (size != sizeof(cfg))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (copy_from_user(&cfg, data, sizeof(cfg)))",
            "\t\treturn -EFAULT;",
            "",
            "\treturn task_set_syscall_user_dispatch(task, cfg.mode, cfg.offset, cfg.len,",
            "\t\t\t\t\t      (char __user *)(uintptr_t)cfg.selector);",
            "}"
          ],
          "function_name": "syscall_user_dispatch_get_config, syscall_user_dispatch_set_config",
          "description": "提供系统调用分发配置的获取与设置接口，通过用户态指针操作实现配置参数的双向传递",
          "similarity": 0.6943199038505554
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/entry/syscall_user_dispatch.c",
          "start_line": 20,
          "end_line": 122,
          "content": [
            "static void trigger_sigsys(struct pt_regs *regs)",
            "{",
            "\tstruct kernel_siginfo info;",
            "",
            "\tclear_siginfo(&info);",
            "\tinfo.si_signo = SIGSYS;",
            "\tinfo.si_code = SYS_USER_DISPATCH;",
            "\tinfo.si_call_addr = (void __user *)KSTK_EIP(current);",
            "\tinfo.si_errno = 0;",
            "\tinfo.si_arch = syscall_get_arch(current);",
            "\tinfo.si_syscall = syscall_get_nr(current, regs);",
            "",
            "\tforce_sig_info(&info);",
            "}",
            "bool syscall_user_dispatch(struct pt_regs *regs)",
            "{",
            "\tstruct syscall_user_dispatch *sd = &current->syscall_dispatch;",
            "\tchar state;",
            "",
            "\tif (likely(instruction_pointer(regs) - sd->offset < sd->len))",
            "\t\treturn false;",
            "",
            "\tif (unlikely(arch_syscall_is_vdso_sigreturn(regs)))",
            "\t\treturn false;",
            "",
            "\tif (likely(sd->selector)) {",
            "\t\t/*",
            "\t\t * access_ok() is performed once, at prctl time, when",
            "\t\t * the selector is loaded by userspace.",
            "\t\t */",
            "\t\tif (unlikely(__get_user(state, sd->selector))) {",
            "\t\t\tforce_exit_sig(SIGSEGV);",
            "\t\t\treturn true;",
            "\t\t}",
            "",
            "\t\tif (likely(state == SYSCALL_DISPATCH_FILTER_ALLOW))",
            "\t\t\treturn false;",
            "",
            "\t\tif (state != SYSCALL_DISPATCH_FILTER_BLOCK) {",
            "\t\t\tforce_exit_sig(SIGSYS);",
            "\t\t\treturn true;",
            "\t\t}",
            "\t}",
            "",
            "\tsd->on_dispatch = true;",
            "\tsyscall_rollback(current, regs);",
            "\ttrigger_sigsys(regs);",
            "",
            "\treturn true;",
            "}",
            "static int task_set_syscall_user_dispatch(struct task_struct *task, unsigned long mode,",
            "\t\t\t\t\t  unsigned long offset, unsigned long len,",
            "\t\t\t\t\t  char __user *selector)",
            "{",
            "\tswitch (mode) {",
            "\tcase PR_SYS_DISPATCH_OFF:",
            "\t\tif (offset || len || selector)",
            "\t\t\treturn -EINVAL;",
            "\t\tbreak;",
            "\tcase PR_SYS_DISPATCH_ON:",
            "\t\t/*",
            "\t\t * Validate the direct dispatcher region just for basic",
            "\t\t * sanity against overflow and a 0-sized dispatcher",
            "\t\t * region.  If the user is able to submit a syscall from",
            "\t\t * an address, that address is obviously valid.",
            "\t\t */",
            "\t\tif (offset && offset + len <= offset)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * access_ok() will clear memory tags for tagged addresses",
            "\t\t * if current has memory tagging enabled.",
            "",
            "\t\t * To enable a tracer to set a tracees selector the",
            "\t\t * selector address must be untagged for access_ok(),",
            "\t\t * otherwise an untagged tracer will always fail to set a",
            "\t\t * tagged tracees selector.",
            "\t\t */",
            "\t\tif (selector && !access_ok(untagged_addr(selector), sizeof(*selector)))",
            "\t\t\treturn -EFAULT;",
            "",
            "\t\tbreak;",
            "\tdefault:",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\ttask->syscall_dispatch.selector = selector;",
            "\ttask->syscall_dispatch.offset = offset;",
            "\ttask->syscall_dispatch.len = len;",
            "\ttask->syscall_dispatch.on_dispatch = false;",
            "",
            "\tif (mode == PR_SYS_DISPATCH_ON)",
            "\t\tset_task_syscall_work(task, SYSCALL_USER_DISPATCH);",
            "\telse",
            "\t\tclear_task_syscall_work(task, SYSCALL_USER_DISPATCH);",
            "",
            "\treturn 0;",
            "}",
            "int set_syscall_user_dispatch(unsigned long mode, unsigned long offset,",
            "\t\t\t      unsigned long len, char __user *selector)",
            "{",
            "\treturn task_set_syscall_user_dispatch(current, mode, offset, len, selector);",
            "}"
          ],
          "function_name": "trigger_sigsys, syscall_user_dispatch, task_set_syscall_user_dispatch, set_syscall_user_dispatch",
          "description": "实现系统调用用户分发核心逻辑，包含触发SIGSYS信号处理、配置验证、拦截判断及模式切换功能",
          "similarity": 0.6446855664253235
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/entry/syscall_user_dispatch.c",
          "start_line": 1,
          "end_line": 19,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 2020 Collabora Ltd.",
            " */",
            "#include <linux/sched.h>",
            "#include <linux/prctl.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/syscall_user_dispatch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/signal.h>",
            "#include <linux/elf.h>",
            "",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task_stack.h>",
            "",
            "#include <asm/syscall.h>",
            "",
            "#include \"common.h\"",
            ""
          ],
          "function_name": null,
          "description": "包含系统调用用户分发功能所需头文件及通用定义，提供架构相关接口和内核调度必要声明",
          "similarity": 0.5829215049743652
        }
      ]
    },
    {
      "source_file": "kernel/sched/sched.h",
      "md_summary": "> 自动生成时间: 2025-10-25 16:16:13\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\sched.h`\n\n---\n\n# `sched/sched.h` 技术文档\n\n## 1. 文件概述\n\n`sched/sched.h` 是 Linux 内核调度器（Scheduler）的核心内部头文件，定义了调度子系统内部使用的类型、宏、辅助函数和全局变量。该文件不对外暴露给其他子系统直接使用，而是作为调度器各组件（如 CFS、RT、Deadline 调度类）之间的内部接口和共享基础设施。它整合了任务状态管理、负载计算、策略判断、CPU 能力建模、cgroup 权重转换等关键调度逻辑，并为调试、性能追踪和平台适配提供支持。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct asym_cap_data`：用于描述非对称 CPU 架构中不同 CPU 集合的计算能力（capacity），支持异构多核系统（如 big.LITTLE）的调度优化。\n- `struct rq`（前向声明）：运行队列（runqueue）结构体，每个 CPU 对应一个，是调度器管理可运行任务的核心数据结构。\n- `struct cpuidle_state`（前向声明）：CPU 空闲状态信息，用于与调度器协同进行能效管理。\n\n### 关键全局变量\n- `scheduler_running`：标志调度器是否已启动。\n- `calc_load_update` / `calc_load_tasks`：用于全局负载（load average）计算的时间戳和任务计数。\n- `sysctl_sched_rt_period` / `sysctl_sched_rt_runtime`：实时任务带宽控制参数。\n- `sched_rr_timeslice`：SCHED_RR 策略的时间片长度。\n- `asym_cap_list`：非对称 CPU 能力数据的全局链表。\n\n### 核心辅助函数与宏\n- **任务策略判断函数**：\n  - `idle_policy()` / `task_has_idle_policy()`\n  - `normal_policy()` / `fair_policy()`\n  - `rt_policy()` / `task_has_rt_policy()`\n  - `dl_policy()` / `task_has_dl_policy()`\n  - `valid_policy()`\n- **负载与权重转换**：\n  - `scale_load()` / `scale_load_down()`：在内部高精度负载值与用户可见权重间转换。\n  - `sched_weight_from_cgroup()` / `sched_weight_to_cgroup()`：cgroup 权重与调度器内部权重的映射。\n- **时间与精度处理**：\n  - `NS_TO_JIFFIES()`：纳秒转 jiffies。\n  - `update_avg()`：指数移动平均（EMA）更新。\n  - `shr_bound()`：安全右移，避免未定义行为。\n- **特殊调度标志**：\n  - `SCHED_FLAG_SUGOV`：用于 schedutil 频率调节器的特殊标志，使相关 kworker 临时获得高于 SCHED_DEADLINE 的优先级。\n  - `dl_entity_is_special()`：判断 Deadline 实体是否为 SUGOV 特殊任务。\n\n### 重要宏定义\n- `TASK_ON_RQ_QUEUED` / `TASK_ON_RQ_MIGRATING`：`task_struct::on_rq` 字段的状态值。\n- `NICE_0_LOAD`：nice 值为 0 的任务对应的内部负载基准值。\n- `DL_SCALE`：SCHED_DEADLINE 内部计算的精度因子。\n- `RUNTIME_INF`：表示无限运行时间的常量。\n- `SCHED_WARN_ON()`：调度器专用的条件警告宏（仅在 `CONFIG_SCHED_DEBUG` 时生效）。\n\n## 3. 关键实现\n\n### 高精度负载计算（64 位优化）\n在 64 位架构上，通过 `NICE_0_LOAD_SHIFT = 2 * SCHED_FIXEDPOINT_SHIFT` 提升内部负载计算的精度，改善低权重任务组（如 nice +19）和深层 cgroup 层级的负载均衡效果。`scale_load()` 和 `scale_load_down()` 实现了用户权重与内部高精度负载值之间的无损转换。\n\n### 非对称 CPU 能力建模\n`asym_cap_data` 结构体结合 `cpu_capacity_span()` 宏，将具有相同计算能力的 CPU 归为一组，并通过全局链表 `asym_cap_list` 管理。这为调度器在异构系统中进行负载均衡和任务迁移提供关键拓扑信息。\n\n### cgroup 权重标准化\n通过 `sched_weight_from_cgroup()` 和 `sched_weight_to_cgroup()`，将 cgroup 接口的权重范围（1–10000，默认 100）映射到调度器内部使用的权重值（基于 1024 基准），确保用户配置与调度行为的一致性。\n\n### SCHED_DEADLINE 与频率调节协同\n引入 `SCHED_FLAG_SUGOV` 标志，允许 `schedutil` 频率调节器的工作线程在需要时临时突破 SCHED_DEADLINE 的优先级限制，以解决某些平台无法原子切换 CPU 频率的问题。这是一种临时性 workaround，依赖于 `dl_entity_is_special()` 进行识别。\n\n### 安全位运算\n`shr_bound()` 宏确保右移操作不会因移位数过大而触发未定义行为（UB），通过 `min_t()` 将移位数限制在 `BITS_PER_TYPE(val) - 1` 以内。\n\n## 4. 依赖关系\n\n### 内核头文件依赖\n- **调度子系统内部**：包含多个调度相关子模块头文件（如 `affinity.h`, `deadline.h`, `topology.h`, `cpupri.h` 等）。\n- **核心内核设施**：依赖 `atomic.h`, `rcupdate.h`, `cpumask_api.h`, `ktime_api.h`, `trace/events/sched.h` 等。\n- **平台与虚拟化**：条件包含 `asm/paravirt.h`（半虚拟化支持）和 `asm/barrier.h`（内存屏障）。\n- **工作队列**：包含 `../workqueue_internal.h`，用于与工作队列子系统交互。\n\n### 配置选项依赖\n- `CONFIG_64BIT`：启用高精度负载计算。\n- `CONFIG_SCHED_DEBUG`：启用 `SCHED_WARN_ON()` 调试检查。\n- `CONFIG_CPU_FREQ_GOV_SCHEDUTIL`：启用 `SCHED_FLAG_SUGOV` 相关逻辑。\n- `CONFIG_SCHED_CLASS_EXT`：扩展调度类支持（影响 `normal_policy()` 判断）。\n- `CONFIG_PARAVIRT`：半虚拟化支持。\n\n## 5. 使用场景\n\n- **调度器初始化与运行**：`scheduler_running` 和负载计算变量在调度器启动和周期性负载更新中使用。\n- **任务调度策略处理**：所有调度类（CFS、RT、Deadline、Idle）在入队、出队、选择下一个任务时，通过策略判断函数确定任务类型。\n- **负载均衡与迁移**：`asym_cap_data` 和 CPU 拓扑信息用于跨 CPU 的任务迁移决策，尤其在异构系统中。\n- **cgroup 资源控制**：在设置或读取 cgroup 的 CPU 权重时，通过权重转换函数确保调度器内部表示与用户接口一致。\n- **实时带宽管理**：`sysctl_sched_rt_*` 参数用于限制 SCHED_FIFO/SCHED_RR 任务的 CPU 使用率。\n- **能效调度协同**：`SCHED_FLAG_SUGOV` 机制使频率调节器能及时响应 Deadline 任务的性能需求。\n- **内核调试与追踪**：`SCHED_WARN_ON()` 用于捕获调度器内部异常状态；tracepoint 定义支持调度事件追踪。",
      "similarity": 0.5912591218948364,
      "chunks": []
    },
    {
      "source_file": "kernel/events/callchain.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:21:29\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `events\\callchain.c`\n\n---\n\n# `events/callchain.c` 技术文档\n\n## 1. 文件概述\n\n`events/callchain.c` 是 Linux 内核性能事件（perf events）子系统中用于管理调用链（callchain）的核心实现文件。该文件负责为性能采样事件分配、管理和回收调用栈缓冲区，并提供统一接口用于在内核态和用户态采集函数调用链信息。调用链用于记录函数调用的层次结构，是性能分析（如火焰图）的关键数据来源。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct callchain_cpus_entries`**  \n  每 CPU 调用链条目数组的容器结构，通过 RCU 机制安全地管理生命周期。\n\n- **`struct perf_callchain_entry_ctx`**  \n  调用链构建上下文，包含当前条目指针、最大栈深度、已记录项数等状态信息（定义在 `internal.h` 中）。\n\n- **`struct perf_callchain_entry`**  \n  实际存储调用地址的结构（定义在 `<linux/perf_event.h>`），包含 `nr`（有效项数）和 `ip[]`（指令指针数组）。\n\n### 主要全局变量\n\n- `sysctl_perf_event_max_stack`：系统级调用栈最大深度（默认 `PERF_MAX_STACK_DEPTH`）。\n- `sysctl_perf_event_max_contexts_per_stack`：每个栈中允许的最大上下文标记数（如 `PERF_CONTEXT_KERNEL`/`USER`）。\n- `callchain_cpus_entries`：指向每 CPU 调用链缓冲区的全局指针，通过 RCU 保护。\n- `callchain_recursion`：每 CPU 递归上下文标记数组，防止在 NMI 或中断上下文中重复进入调用链采集。\n- `nr_callchain_events`：引用计数，跟踪当前活跃的需要调用链的 perf 事件数量。\n- `callchain_mutex`：保护缓冲区分配/释放和 sysctl 修改的互斥锁。\n\n### 主要函数\n\n- **`get_callchain_buffers()` / `put_callchain_buffers()`**  \n  引用计数式地分配和释放全局调用链缓冲区。\n\n- **`get_callchain_entry()` / `put_callchain_entry()`**  \n  获取/释放当前 CPU 上可用的调用链条目，支持多上下文（如中断、NMI）隔离。\n\n- **`get_perf_callchain()`**  \n  高层接口，根据寄存器状态采集内核态和/或用户态的完整调用链。\n\n- **`perf_callchain_kernel()` / `perf_callchain_user()`**  \n  弱符号函数，由各架构实现具体的栈回溯逻辑（如 x86 使用 `dump_trace()`）。\n\n- **`perf_event_max_stack_handler()`**  \n  sysctl 处理函数，允许动态调整最大栈深度（仅在无活跃事件时生效）。\n\n## 3. 关键实现\n\n### 调用链缓冲区管理\n\n- 使用 **每 CPU 独立缓冲区** 避免锁竞争，每个 CPU 分配 `PERF_NR_CONTEXTS` 个 `perf_callchain_entry`（支持中断、NMI 等多上下文）。\n- 缓冲区大小由 `perf_callchain_entry__sizeof()` 动态计算，结合 `sysctl_perf_event_max_stack` 和上下文标记数量。\n- 通过 **RCU 机制** 安全释放旧缓冲区，确保在可能的 NMI 上下文中仍可安全访问。\n\n### 递归上下文保护\n\n- `callchain_recursion` 数组标记当前 CPU 的调用链采集上下文（0=普通，1=NMI 等）。\n- `get_recursion_context()`/`put_recursion_context()` 确保同一上下文不会嵌套调用链采集，防止缓冲区覆盖。\n\n### 架构无关接口\n\n- `perf_callchain_kernel()` 和 `perf_callchain_user()` 为 **弱符号**，允许各架构（如 x86、ARM）提供具体实现。\n- 内核态回溯通常基于 `regs` 寄存器状态和内核栈；用户态回溯需切换到用户栈并解析 DWARF 或 frame pointer。\n\n### 安全限制\n\n- `get_callchain_buffers()` 检查请求的 `event_max_stack` 不超过全局上限，超限返回 `-EOVERFLOW`。\n- sysctl 修改需在无活跃事件时进行（`nr_callchain_events == 0`），否则返回 `-EBUSY`。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/perf_event.h>`：perf 事件核心定义。\n  - `<linux/slab.h>`：内存分配（`kmalloc`/`kfree`）。\n  - `<linux/sched/task_stack.h>`：任务栈相关辅助函数。\n  - `\"internal.h\"`：perf 子系统内部头文件，包含 `perf_callchain_entry_ctx` 等。\n\n- **架构依赖**：\n  - 各架构需实现 `perf_callchain_kernel()` 和 `perf_callchain_user()`（如 `arch/x86/events/core.c`）。\n\n- **子系统依赖**：\n  - RCU 机制（`call_rcu`, `rcu_dereference`）。\n  - Per-CPU 变量（`DEFINE_PER_CPU`, `this_cpu_ptr`）。\n  - 内存节点分配（`kmalloc_node`）。\n\n## 5. 使用场景\n\n- **性能分析工具**：`perf record -g` 采集调用链时，内核通过此模块记录函数调用栈。\n- **动态跟踪**：eBPF 程序或 ftrace 在需要栈回溯时调用 `get_perf_callchain()`。\n- **系统监控**：当 perf 事件配置为 `PERF_SAMPLE_CALLCHAIN` 时，采样中断处理中调用此模块。\n- **安全审计**：某些 LSM 模块可能利用调用链信息进行行为分析。\n- **调试场景**：内核 oops 或 lockdep 在需要栈信息时可能间接使用此机制。",
      "similarity": 0.5828218460083008,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/events/callchain.c",
          "start_line": 145,
          "end_line": 215,
          "content": [
            "void put_callchain_buffers(void)",
            "{",
            "\tif (atomic_dec_and_mutex_lock(&nr_callchain_events, &callchain_mutex)) {",
            "\t\trelease_callchain_buffers();",
            "\t\tmutex_unlock(&callchain_mutex);",
            "\t}",
            "}",
            "void",
            "put_callchain_entry(int rctx)",
            "{",
            "\tput_recursion_context(this_cpu_ptr(callchain_recursion), rctx);",
            "}",
            "static void fixup_uretprobe_trampoline_entries(struct perf_callchain_entry *entry,",
            "\t\t\t\t\t       int start_entry_idx)",
            "{",
            "#ifdef CONFIG_UPROBES",
            "\tstruct uprobe_task *utask = current->utask;",
            "\tstruct return_instance *ri;",
            "\t__u64 *cur_ip, *last_ip, tramp_addr;",
            "",
            "\tif (likely(!utask || !utask->return_instances))",
            "\t\treturn;",
            "",
            "\tcur_ip = &entry->ip[start_entry_idx];",
            "\tlast_ip = &entry->ip[entry->nr - 1];",
            "\tri = utask->return_instances;",
            "\ttramp_addr = uprobe_get_trampoline_vaddr();",
            "",
            "\t/*",
            "\t * If there are pending uretprobes for the current thread, they are",
            "\t * recorded in a list inside utask->return_instances; each such",
            "\t * pending uretprobe replaces traced user function's return address on",
            "\t * the stack, so when stack trace is captured, instead of seeing",
            "\t * actual function's return address, we'll have one or many uretprobe",
            "\t * trampoline addresses in the stack trace, which are not helpful and",
            "\t * misleading to users.",
            "\t * So here we go over the pending list of uretprobes, and each",
            "\t * encountered trampoline address is replaced with actual return",
            "\t * address.",
            "\t */",
            "\twhile (ri && cur_ip <= last_ip) {",
            "\t\tif (*cur_ip == tramp_addr) {",
            "\t\t\t*cur_ip = ri->orig_ret_vaddr;",
            "\t\t\tri = ri->next;",
            "\t\t}",
            "\t\tcur_ip++;",
            "\t}",
            "#endif",
            "}",
            "int perf_event_max_stack_handler(struct ctl_table *table, int write,",
            "\t\t\t\t void *buffer, size_t *lenp, loff_t *ppos)",
            "{",
            "\tint *value = table->data;",
            "\tint new_value = *value, ret;",
            "\tstruct ctl_table new_table = *table;",
            "",
            "\tnew_table.data = &new_value;",
            "\tret = proc_dointvec_minmax(&new_table, write, buffer, lenp, ppos);",
            "\tif (ret || !write)",
            "\t\treturn ret;",
            "",
            "\tmutex_lock(&callchain_mutex);",
            "\tif (atomic_read(&nr_callchain_events))",
            "\t\tret = -EBUSY;",
            "\telse",
            "\t\t*value = new_value;",
            "",
            "\tmutex_unlock(&callchain_mutex);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "put_callchain_buffers, put_callchain_entry, fixup_uretprobe_trampoline_entries, perf_event_max_stack_handler",
          "description": "提供调用链缓冲区的引用计数管理、URETPROBE陷阱地址修复逻辑，以及性能事件最大栈深度的动态配置处理函数，确保栈追踪数据的准确性与系统调参的原子性操作。",
          "similarity": 0.5556474328041077
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/events/callchain.c",
          "start_line": 26,
          "end_line": 131,
          "content": [
            "static inline size_t perf_callchain_entry__sizeof(void)",
            "{",
            "\treturn (sizeof(struct perf_callchain_entry) +",
            "\t\tsizeof(__u64) * (sysctl_perf_event_max_stack +",
            "\t\t\t\t sysctl_perf_event_max_contexts_per_stack));",
            "}",
            "__weak void perf_callchain_kernel(struct perf_callchain_entry_ctx *entry,",
            "\t\t\t\t  struct pt_regs *regs)",
            "{",
            "}",
            "__weak void perf_callchain_user(struct perf_callchain_entry_ctx *entry,",
            "\t\t\t\tstruct pt_regs *regs)",
            "{",
            "}",
            "static void release_callchain_buffers_rcu(struct rcu_head *head)",
            "{",
            "\tstruct callchain_cpus_entries *entries;",
            "\tint cpu;",
            "",
            "\tentries = container_of(head, struct callchain_cpus_entries, rcu_head);",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tkfree(entries->cpu_entries[cpu]);",
            "",
            "\tkfree(entries);",
            "}",
            "static void release_callchain_buffers(void)",
            "{",
            "\tstruct callchain_cpus_entries *entries;",
            "",
            "\tentries = callchain_cpus_entries;",
            "\tRCU_INIT_POINTER(callchain_cpus_entries, NULL);",
            "\tcall_rcu(&entries->rcu_head, release_callchain_buffers_rcu);",
            "}",
            "static int alloc_callchain_buffers(void)",
            "{",
            "\tint cpu;",
            "\tint size;",
            "\tstruct callchain_cpus_entries *entries;",
            "",
            "\t/*",
            "\t * We can't use the percpu allocation API for data that can be",
            "\t * accessed from NMI. Use a temporary manual per cpu allocation",
            "\t * until that gets sorted out.",
            "\t */",
            "\tsize = offsetof(struct callchain_cpus_entries, cpu_entries[nr_cpu_ids]);",
            "",
            "\tentries = kzalloc(size, GFP_KERNEL);",
            "\tif (!entries)",
            "\t\treturn -ENOMEM;",
            "",
            "\tsize = perf_callchain_entry__sizeof() * PERF_NR_CONTEXTS;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tentries->cpu_entries[cpu] = kmalloc_node(size, GFP_KERNEL,",
            "\t\t\t\t\t\t\t cpu_to_node(cpu));",
            "\t\tif (!entries->cpu_entries[cpu])",
            "\t\t\tgoto fail;",
            "\t}",
            "",
            "\trcu_assign_pointer(callchain_cpus_entries, entries);",
            "",
            "\treturn 0;",
            "",
            "fail:",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tkfree(entries->cpu_entries[cpu]);",
            "\tkfree(entries);",
            "",
            "\treturn -ENOMEM;",
            "}",
            "int get_callchain_buffers(int event_max_stack)",
            "{",
            "\tint err = 0;",
            "\tint count;",
            "",
            "\tmutex_lock(&callchain_mutex);",
            "",
            "\tcount = atomic_inc_return(&nr_callchain_events);",
            "\tif (WARN_ON_ONCE(count < 1)) {",
            "\t\terr = -EINVAL;",
            "\t\tgoto exit;",
            "\t}",
            "",
            "\t/*",
            "\t * If requesting per event more than the global cap,",
            "\t * return a different error to help userspace figure",
            "\t * this out.",
            "\t *",
            "\t * And also do it here so that we have &callchain_mutex held.",
            "\t */",
            "\tif (event_max_stack > sysctl_perf_event_max_stack) {",
            "\t\terr = -EOVERFLOW;",
            "\t\tgoto exit;",
            "\t}",
            "",
            "\tif (count == 1)",
            "\t\terr = alloc_callchain_buffers();",
            "exit:",
            "\tif (err)",
            "\t\tatomic_dec(&nr_callchain_events);",
            "",
            "\tmutex_unlock(&callchain_mutex);",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "perf_callchain_entry__sizeof, perf_callchain_kernel, perf_callchain_user, release_callchain_buffers_rcu, release_callchain_buffers, alloc_callchain_buffers, get_callchain_buffers",
          "description": "实现调用链缓冲区的动态分配与释放逻辑，包含缓冲区大小计算、跨CPU内存分配、RCU安全释放机制及根据当前事件栈需求进行缓冲区初始化和清理的操作。",
          "similarity": 0.5411708950996399
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/events/callchain.c",
          "start_line": 1,
          "end_line": 25,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Performance events callchain code, extracted from core.c:",
            " *",
            " *  Copyright (C) 2008 Thomas Gleixner <tglx@linutronix.de>",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Ingo Molnar",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Peter Zijlstra",
            " *  Copyright  ©  2009 Paul Mackerras, IBM Corp. <paulus@au1.ibm.com>",
            " */",
            "",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/uprobes.h>",
            "",
            "#include \"internal.h\"",
            "",
            "struct callchain_cpus_entries {",
            "\tstruct rcu_head\t\t\trcu_head;",
            "\tstruct perf_callchain_entry\t*cpu_entries[];",
            "};",
            "",
            "int sysctl_perf_event_max_stack __read_mostly = PERF_MAX_STACK_DEPTH;",
            "int sysctl_perf_event_max_contexts_per_stack __read_mostly = PERF_MAX_CONTEXTS_PER_STACK;",
            ""
          ],
          "function_name": null,
          "description": "定义callchain_cpus_entries结构体用于存储每个CPU的调用链条目数组，并声明两个sysctl全局变量用于配置性能事件的最大栈深度和每个栈的最大上下文数。",
          "similarity": 0.5326030254364014
        }
      ]
    }
  ]
}