{
  "query": "循环等待检测",
  "timestamp": "2025-12-26 01:05:35",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/test-ww_mutex.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:55:51\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\test-ww_mutex.c`\n\n---\n\n# `locking/test-ww_mutex.c` 技术文档\n\n## 1. 文件概述\n\n`test-ww_mutex.c` 是 Linux 内核中用于测试 **Wound/Wait 互斥锁（ww_mutex）** 机制的模块化单元测试文件。该文件通过模拟多种并发场景（如自锁、ABBA 死锁、循环死锁等），验证 ww_mutex 的正确性、互斥性以及死锁检测与恢复机制是否按预期工作。该测试模块主要用于内核开发和调试阶段，确保 ww_mutex 的实现符合设计规范。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct test_mutex`  \n  用于测试基本互斥行为的结构体，包含工作项、ww_mutex、完成量（completion）和测试标志。\n\n- `struct test_abba`  \n  用于模拟 ABBA 死锁场景的结构体，包含两个 ww_mutex、完成量、解析标志、trylock 标志及结果。\n\n- `struct test_cycle`  \n  用于测试多线程循环依赖死锁场景的结构体，支持 N 个线程形成环形依赖。\n\n- `ww_class`  \n  全局定义的 `ww_class`，用于标识 ww_mutex 所属的锁类，是 ww_mutex 正常工作的必要条件。\n\n### 主要函数\n\n- `test_mutex_work()`  \n  工作队列回调函数，执行 ww_mutex 的加锁/尝试加锁操作。\n\n- `__test_mutex()` / `test_mutex()`  \n  测试基本互斥语义，覆盖多种标志组合（自旋、trylock、带上下文等）。\n\n- `test_aa()`  \n  测试同一上下文对同一 ww_mutex 的重复加锁行为，验证 `-EALREADY` 返回值。\n\n- `test_abba_work()` / `test_abba()`  \n  测试经典的 ABBA 死锁场景，支持是否启用死锁解析（resolve）。\n\n- `test_cycle_work()` / `__test_cycle()`  \n  测试 N 线程环形依赖死锁，并验证 ww_mutex 的死锁自动解析能力。\n\n## 3. 关键实现\n\n### Wound/Wait 机制测试\n\n- 所有测试均基于 `ww_acquire_ctx` 上下文进行加锁，确保符合 ww_mutex 的使用规范。\n- 通过 `ww_mutex_lock()` 和 `ww_mutex_trylock()` 的组合，验证不同加锁路径的行为一致性。\n\n### 死锁检测与解析\n\n- 在 `test_abba()` 和 `__test_cycle()` 中，当检测到 `-EDEADLK` 时，主动调用 `ww_mutex_unlock()` 释放已持有锁，再通过 `ww_mutex_lock_slow()` 重新按顺序获取锁，模拟死锁恢复流程。\n- `test_abba()` 支持两种模式：  \n  - **不解析**：期望两个线程均返回 `-EDEADLK`；  \n  - **解析**：期望死锁被成功解除，返回 0。\n\n### 防止测试干扰\n\n- 使用 `CONFIG_DEBUG_WW_MUTEX_SLOWPATH` 宏控制是否禁用死锁注入（`deadlock_inject_countdown = ~0U`），确保测试结果可复现。\n- 所有工作项均使用 `INIT_WORK_ONSTACK` 初始化，并在测试结束时调用 `destroy_work_on_stack()`，避免内存泄漏。\n\n### 超时与同步机制\n\n- 使用 `completion` 机制协调主线程与工作线程的执行顺序。\n- 设置 `TIMEOUT = HZ / 16` 作为最大等待时间，防止测试挂起。\n- 在 `TEST_MTX_SPIN` 模式下，主动轮询完成状态并调用 `cond_resched()`，避免软死锁。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/ww_mutex.h>`：提供 ww_mutex 核心 API。\n  - `<linux/completion.h>`、`<linux/workqueue.h>`：用于线程同步与调度。\n  - `<linux/kthread.h>`、`<linux/slab.h>`：支持动态内存分配与内核线程。\n  - `<linux/prandom.h>`：虽未直接使用，但为潜在扩展预留。\n\n- **内核配置依赖**：\n  - 依赖 `CONFIG_WW_MUTEX` 编译选项。\n  - 调试模式下依赖 `CONFIG_DEBUG_WW_MUTEX_SLOWPATH`。\n\n- **运行时依赖**：\n  - 使用全局工作队列 `wq`（在文件外初始化），用于并发执行测试任务。\n\n## 5. 使用场景\n\n- **内核开发与回归测试**：在修改 ww_mutex 实现后，运行此模块验证功能正确性。\n- **死锁行为验证**：用于确认 ww_mutex 能正确检测并处理 ABBA、循环依赖等复杂死锁。\n- **API 兼容性测试**：确保 `ww_mutex_lock`、`ww_mutex_trylock`、`ww_mutex_lock_slow` 等接口行为符合预期。\n- **调试辅助**：当系统出现 ww_mutex 相关死锁时，可参考此测试逻辑复现问题。",
      "similarity": 0.5776384472846985,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 186,
          "end_line": 302,
          "content": [
            "static void test_abba_work(struct work_struct *work)",
            "{",
            "\tstruct test_abba *abba = container_of(work, typeof(*abba), work);",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint err;",
            "",
            "\tww_acquire_init_noinject(&ctx, &ww_class);",
            "\tif (!abba->trylock)",
            "\t\tww_mutex_lock(&abba->b_mutex, &ctx);",
            "\telse",
            "\t\tWARN_ON(!ww_mutex_trylock(&abba->b_mutex, &ctx));",
            "",
            "\tWARN_ON(READ_ONCE(abba->b_mutex.ctx) != &ctx);",
            "",
            "\tcomplete(&abba->b_ready);",
            "\twait_for_completion(&abba->a_ready);",
            "",
            "\terr = ww_mutex_lock(&abba->a_mutex, &ctx);",
            "\tif (abba->resolve && err == -EDEADLK) {",
            "\t\tww_mutex_unlock(&abba->b_mutex);",
            "\t\tww_mutex_lock_slow(&abba->a_mutex, &ctx);",
            "\t\terr = ww_mutex_lock(&abba->b_mutex, &ctx);",
            "\t}",
            "",
            "\tif (!err)",
            "\t\tww_mutex_unlock(&abba->a_mutex);",
            "\tww_mutex_unlock(&abba->b_mutex);",
            "\tww_acquire_fini(&ctx);",
            "",
            "\tabba->result = err;",
            "}",
            "static int test_abba(bool trylock, bool resolve)",
            "{",
            "\tstruct test_abba abba;",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint err, ret;",
            "",
            "\tww_mutex_init(&abba.a_mutex, &ww_class);",
            "\tww_mutex_init(&abba.b_mutex, &ww_class);",
            "\tINIT_WORK_ONSTACK(&abba.work, test_abba_work);",
            "\tinit_completion(&abba.a_ready);",
            "\tinit_completion(&abba.b_ready);",
            "\tabba.trylock = trylock;",
            "\tabba.resolve = resolve;",
            "",
            "\tschedule_work(&abba.work);",
            "",
            "\tww_acquire_init_noinject(&ctx, &ww_class);",
            "\tif (!trylock)",
            "\t\tww_mutex_lock(&abba.a_mutex, &ctx);",
            "\telse",
            "\t\tWARN_ON(!ww_mutex_trylock(&abba.a_mutex, &ctx));",
            "",
            "\tWARN_ON(READ_ONCE(abba.a_mutex.ctx) != &ctx);",
            "",
            "\tcomplete(&abba.a_ready);",
            "\twait_for_completion(&abba.b_ready);",
            "",
            "\terr = ww_mutex_lock(&abba.b_mutex, &ctx);",
            "\tif (resolve && err == -EDEADLK) {",
            "\t\tww_mutex_unlock(&abba.a_mutex);",
            "\t\tww_mutex_lock_slow(&abba.b_mutex, &ctx);",
            "\t\terr = ww_mutex_lock(&abba.a_mutex, &ctx);",
            "\t}",
            "",
            "\tif (!err)",
            "\t\tww_mutex_unlock(&abba.b_mutex);",
            "\tww_mutex_unlock(&abba.a_mutex);",
            "\tww_acquire_fini(&ctx);",
            "",
            "\tflush_work(&abba.work);",
            "\tdestroy_work_on_stack(&abba.work);",
            "",
            "\tret = 0;",
            "\tif (resolve) {",
            "\t\tif (err || abba.result) {",
            "\t\t\tpr_err(\"%s: failed to resolve ABBA deadlock, A err=%d, B err=%d\\n\",",
            "\t\t\t       __func__, err, abba.result);",
            "\t\t\tret = -EINVAL;",
            "\t\t}",
            "\t} else {",
            "\t\tif (err != -EDEADLK && abba.result != -EDEADLK) {",
            "\t\t\tpr_err(\"%s: missed ABBA deadlock, A err=%d, B err=%d\\n\",",
            "\t\t\t       __func__, err, abba.result);",
            "\t\t\tret = -EINVAL;",
            "\t\t}",
            "\t}",
            "\treturn ret;",
            "}",
            "static void test_cycle_work(struct work_struct *work)",
            "{",
            "\tstruct test_cycle *cycle = container_of(work, typeof(*cycle), work);",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint err, erra = 0;",
            "",
            "\tww_acquire_init_noinject(&ctx, &ww_class);",
            "\tww_mutex_lock(&cycle->a_mutex, &ctx);",
            "",
            "\tcomplete(cycle->a_signal);",
            "\twait_for_completion(&cycle->b_signal);",
            "",
            "\terr = ww_mutex_lock(cycle->b_mutex, &ctx);",
            "\tif (err == -EDEADLK) {",
            "\t\terr = 0;",
            "\t\tww_mutex_unlock(&cycle->a_mutex);",
            "\t\tww_mutex_lock_slow(cycle->b_mutex, &ctx);",
            "\t\terra = ww_mutex_lock(&cycle->a_mutex, &ctx);",
            "\t}",
            "",
            "\tif (!err)",
            "\t\tww_mutex_unlock(cycle->b_mutex);",
            "\tif (!erra)",
            "\t\tww_mutex_unlock(&cycle->a_mutex);",
            "\tww_acquire_fini(&ctx);",
            "",
            "\tcycle->result = err ?: erra;",
            "}"
          ],
          "function_name": "test_abba_work, test_abba, test_cycle_work",
          "description": "测试ABBA死锁场景及环形依赖问题，通过交替顺序加锁模拟死锁条件，验证系统能否检测并解除死锁状态",
          "similarity": 0.6203740835189819
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 489,
          "end_line": 629,
          "content": [
            "static void stress_reorder_work(struct work_struct *work)",
            "{",
            "\tstruct stress *stress = container_of(work, typeof(*stress), work);",
            "\tLIST_HEAD(locks);",
            "\tstruct ww_acquire_ctx ctx;",
            "\tstruct reorder_lock *ll, *ln;",
            "\tint *order;",
            "\tint n, err;",
            "",
            "\torder = get_random_order(stress->nlocks);",
            "\tif (!order)",
            "\t\treturn;",
            "",
            "\tfor (n = 0; n < stress->nlocks; n++) {",
            "\t\tll = kmalloc(sizeof(*ll), GFP_KERNEL);",
            "\t\tif (!ll)",
            "\t\t\tgoto out;",
            "",
            "\t\tll->lock = &stress->locks[order[n]];",
            "\t\tlist_add(&ll->link, &locks);",
            "\t}",
            "\tkfree(order);",
            "\torder = NULL;",
            "",
            "\tdo {",
            "\t\tww_acquire_init(&ctx, &ww_class);",
            "",
            "\t\tlist_for_each_entry(ll, &locks, link) {",
            "\t\t\terr = ww_mutex_lock(ll->lock, &ctx);",
            "\t\t\tif (!err)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tln = ll;",
            "\t\t\tlist_for_each_entry_continue_reverse(ln, &locks, link)",
            "\t\t\t\tww_mutex_unlock(ln->lock);",
            "",
            "\t\t\tif (err != -EDEADLK) {",
            "\t\t\t\tpr_err_once(\"stress (%s) failed with %d\\n\",",
            "\t\t\t\t\t    __func__, err);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "",
            "\t\t\tww_mutex_lock_slow(ll->lock, &ctx);",
            "\t\t\tlist_move(&ll->link, &locks); /* restarts iteration */",
            "\t\t}",
            "",
            "\t\tdummy_load(stress);",
            "\t\tlist_for_each_entry(ll, &locks, link)",
            "\t\t\tww_mutex_unlock(ll->lock);",
            "",
            "\t\tww_acquire_fini(&ctx);",
            "\t} while (!time_after(jiffies, stress->timeout));",
            "",
            "out:",
            "\tlist_for_each_entry_safe(ll, ln, &locks, link)",
            "\t\tkfree(ll);",
            "\tkfree(order);",
            "}",
            "static void stress_one_work(struct work_struct *work)",
            "{",
            "\tstruct stress *stress = container_of(work, typeof(*stress), work);",
            "\tconst int nlocks = stress->nlocks;",
            "\tstruct ww_mutex *lock = stress->locks + get_random_u32_below(nlocks);",
            "\tint err;",
            "",
            "\tdo {",
            "\t\terr = ww_mutex_lock(lock, NULL);",
            "\t\tif (!err) {",
            "\t\t\tdummy_load(stress);",
            "\t\t\tww_mutex_unlock(lock);",
            "\t\t} else {",
            "\t\t\tpr_err_once(\"stress (%s) failed with %d\\n\",",
            "\t\t\t\t    __func__, err);",
            "\t\t\tbreak;",
            "\t\t}",
            "\t} while (!time_after(jiffies, stress->timeout));",
            "}",
            "static int stress(int nlocks, int nthreads, unsigned int flags)",
            "{",
            "\tstruct ww_mutex *locks;",
            "\tstruct stress *stress_array;",
            "\tint n, count;",
            "",
            "\tlocks = kmalloc_array(nlocks, sizeof(*locks), GFP_KERNEL);",
            "\tif (!locks)",
            "\t\treturn -ENOMEM;",
            "",
            "\tstress_array = kmalloc_array(nthreads, sizeof(*stress_array),",
            "\t\t\t\t     GFP_KERNEL);",
            "\tif (!stress_array) {",
            "\t\tkfree(locks);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\tfor (n = 0; n < nlocks; n++)",
            "\t\tww_mutex_init(&locks[n], &ww_class);",
            "",
            "\tcount = 0;",
            "\tfor (n = 0; nthreads; n++) {",
            "\t\tstruct stress *stress;",
            "\t\tvoid (*fn)(struct work_struct *work);",
            "",
            "\t\tfn = NULL;",
            "\t\tswitch (n & 3) {",
            "\t\tcase 0:",
            "\t\t\tif (flags & STRESS_INORDER)",
            "\t\t\t\tfn = stress_inorder_work;",
            "\t\t\tbreak;",
            "\t\tcase 1:",
            "\t\t\tif (flags & STRESS_REORDER)",
            "\t\t\t\tfn = stress_reorder_work;",
            "\t\t\tbreak;",
            "\t\tcase 2:",
            "\t\t\tif (flags & STRESS_ONE)",
            "\t\t\t\tfn = stress_one_work;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tif (!fn)",
            "\t\t\tcontinue;",
            "",
            "\t\tstress = &stress_array[count++];",
            "",
            "\t\tINIT_WORK(&stress->work, fn);",
            "\t\tstress->locks = locks;",
            "\t\tstress->nlocks = nlocks;",
            "\t\tstress->timeout = jiffies + 2*HZ;",
            "",
            "\t\tqueue_work(wq, &stress->work);",
            "\t\tnthreads--;",
            "\t}",
            "",
            "\tflush_workqueue(wq);",
            "",
            "\tfor (n = 0; n < nlocks; n++)",
            "\t\tww_mutex_destroy(&locks[n]);",
            "\tkfree(stress_array);",
            "\tkfree(locks);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "stress_reorder_work, stress_one_work, stress",
          "description": "实施大规模并发压力测试，支持按序加锁、重排序加锁和单锁测试模式，验证系统在高强度并发下的稳定性与死锁预防能力",
          "similarity": 0.5846630334854126
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 315,
          "end_line": 444,
          "content": [
            "static int __test_cycle(unsigned int nthreads)",
            "{",
            "\tstruct test_cycle *cycles;",
            "\tunsigned int n, last = nthreads - 1;",
            "\tint ret;",
            "",
            "\tcycles = kmalloc_array(nthreads, sizeof(*cycles), GFP_KERNEL);",
            "\tif (!cycles)",
            "\t\treturn -ENOMEM;",
            "",
            "\tfor (n = 0; n < nthreads; n++) {",
            "\t\tstruct test_cycle *cycle = &cycles[n];",
            "",
            "\t\tww_mutex_init(&cycle->a_mutex, &ww_class);",
            "\t\tif (n == last)",
            "\t\t\tcycle->b_mutex = &cycles[0].a_mutex;",
            "\t\telse",
            "\t\t\tcycle->b_mutex = &cycles[n + 1].a_mutex;",
            "",
            "\t\tif (n == 0)",
            "\t\t\tcycle->a_signal = &cycles[last].b_signal;",
            "\t\telse",
            "\t\t\tcycle->a_signal = &cycles[n - 1].b_signal;",
            "\t\tinit_completion(&cycle->b_signal);",
            "",
            "\t\tINIT_WORK(&cycle->work, test_cycle_work);",
            "\t\tcycle->result = 0;",
            "\t}",
            "",
            "\tfor (n = 0; n < nthreads; n++)",
            "\t\tqueue_work(wq, &cycles[n].work);",
            "",
            "\tflush_workqueue(wq);",
            "",
            "\tret = 0;",
            "\tfor (n = 0; n < nthreads; n++) {",
            "\t\tstruct test_cycle *cycle = &cycles[n];",
            "",
            "\t\tif (!cycle->result)",
            "\t\t\tcontinue;",
            "",
            "\t\tpr_err(\"cyclic deadlock not resolved, ret[%d/%d] = %d\\n\",",
            "\t\t       n, nthreads, cycle->result);",
            "\t\tret = -EINVAL;",
            "\t\tbreak;",
            "\t}",
            "",
            "\tfor (n = 0; n < nthreads; n++)",
            "\t\tww_mutex_destroy(&cycles[n].a_mutex);",
            "\tkfree(cycles);",
            "\treturn ret;",
            "}",
            "static int test_cycle(unsigned int ncpus)",
            "{",
            "\tunsigned int n;",
            "\tint ret;",
            "",
            "\tfor (n = 2; n <= ncpus + 1; n++) {",
            "\t\tret = __test_cycle(n);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static inline u32 prandom_u32_below(u32 ceil)",
            "{",
            "\tu32 ret;",
            "",
            "\tspin_lock(&rng_lock);",
            "\tret = prandom_u32_state(&rng) % ceil;",
            "\tspin_unlock(&rng_lock);",
            "\treturn ret;",
            "}",
            "static void dummy_load(struct stress *stress)",
            "{",
            "\tusleep_range(1000, 2000);",
            "}",
            "static void stress_inorder_work(struct work_struct *work)",
            "{",
            "\tstruct stress *stress = container_of(work, typeof(*stress), work);",
            "\tconst int nlocks = stress->nlocks;",
            "\tstruct ww_mutex *locks = stress->locks;",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint *order;",
            "",
            "\torder = get_random_order(nlocks);",
            "\tif (!order)",
            "\t\treturn;",
            "",
            "\tdo {",
            "\t\tint contended = -1;",
            "\t\tint n, err;",
            "",
            "\t\tww_acquire_init(&ctx, &ww_class);",
            "retry:",
            "\t\terr = 0;",
            "\t\tfor (n = 0; n < nlocks; n++) {",
            "\t\t\tif (n == contended)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\terr = ww_mutex_lock(&locks[order[n]], &ctx);",
            "\t\t\tif (err < 0)",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t\tif (!err)",
            "\t\t\tdummy_load(stress);",
            "",
            "\t\tif (contended > n)",
            "\t\t\tww_mutex_unlock(&locks[order[contended]]);",
            "\t\tcontended = n;",
            "\t\twhile (n--)",
            "\t\t\tww_mutex_unlock(&locks[order[n]]);",
            "",
            "\t\tif (err == -EDEADLK) {",
            "\t\t\tww_mutex_lock_slow(&locks[order[contended]], &ctx);",
            "\t\t\tgoto retry;",
            "\t\t}",
            "",
            "\t\tif (err) {",
            "\t\t\tpr_err_once(\"stress (%s) failed with %d\\n\",",
            "\t\t\t\t    __func__, err);",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tww_acquire_fini(&ctx);",
            "\t} while (!time_after(jiffies, stress->timeout));",
            "",
            "\tkfree(order);",
            "}"
          ],
          "function_name": "__test_cycle, test_cycle, prandom_u32_below, dummy_load, stress_inorder_work",
          "description": "执行多线程环形死锁测试，动态分配资源并模拟复杂锁竞争场景，包含随机数生成和负载控制机制",
          "similarity": 0.5736091136932373
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 40,
          "end_line": 171,
          "content": [
            "static void test_mutex_work(struct work_struct *work)",
            "{",
            "\tstruct test_mutex *mtx = container_of(work, typeof(*mtx), work);",
            "",
            "\tcomplete(&mtx->ready);",
            "\twait_for_completion(&mtx->go);",
            "",
            "\tif (mtx->flags & TEST_MTX_TRY) {",
            "\t\twhile (!ww_mutex_trylock(&mtx->mutex, NULL))",
            "\t\t\tcond_resched();",
            "\t} else {",
            "\t\tww_mutex_lock(&mtx->mutex, NULL);",
            "\t}",
            "\tcomplete(&mtx->done);",
            "\tww_mutex_unlock(&mtx->mutex);",
            "}",
            "static int __test_mutex(unsigned int flags)",
            "{",
            "#define TIMEOUT (HZ / 16)",
            "\tstruct test_mutex mtx;",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint ret;",
            "",
            "\tww_mutex_init(&mtx.mutex, &ww_class);",
            "\tww_acquire_init(&ctx, &ww_class);",
            "",
            "\tINIT_WORK_ONSTACK(&mtx.work, test_mutex_work);",
            "\tinit_completion(&mtx.ready);",
            "\tinit_completion(&mtx.go);",
            "\tinit_completion(&mtx.done);",
            "\tmtx.flags = flags;",
            "",
            "\tschedule_work(&mtx.work);",
            "",
            "\twait_for_completion(&mtx.ready);",
            "\tww_mutex_lock(&mtx.mutex, (flags & TEST_MTX_CTX) ? &ctx : NULL);",
            "\tcomplete(&mtx.go);",
            "\tif (flags & TEST_MTX_SPIN) {",
            "\t\tunsigned long timeout = jiffies + TIMEOUT;",
            "",
            "\t\tret = 0;",
            "\t\tdo {",
            "\t\t\tif (completion_done(&mtx.done)) {",
            "\t\t\t\tret = -EINVAL;",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t\tcond_resched();",
            "\t\t} while (time_before(jiffies, timeout));",
            "\t} else {",
            "\t\tret = wait_for_completion_timeout(&mtx.done, TIMEOUT);",
            "\t}",
            "\tww_mutex_unlock(&mtx.mutex);",
            "\tww_acquire_fini(&ctx);",
            "",
            "\tif (ret) {",
            "\t\tpr_err(\"%s(flags=%x): mutual exclusion failure\\n\",",
            "\t\t       __func__, flags);",
            "\t\tret = -EINVAL;",
            "\t}",
            "",
            "\tflush_work(&mtx.work);",
            "\tdestroy_work_on_stack(&mtx.work);",
            "\treturn ret;",
            "#undef TIMEOUT",
            "}",
            "static int test_mutex(void)",
            "{",
            "\tint ret;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < __TEST_MTX_LAST; i++) {",
            "\t\tret = __test_mutex(i);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int test_aa(bool trylock)",
            "{",
            "\tstruct ww_mutex mutex;",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint ret;",
            "\tconst char *from = trylock ? \"trylock\" : \"lock\";",
            "",
            "\tww_mutex_init(&mutex, &ww_class);",
            "\tww_acquire_init(&ctx, &ww_class);",
            "",
            "\tif (!trylock) {",
            "\t\tret = ww_mutex_lock(&mutex, &ctx);",
            "\t\tif (ret) {",
            "\t\t\tpr_err(\"%s: initial lock failed!\\n\", __func__);",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t} else {",
            "\t\tret = !ww_mutex_trylock(&mutex, &ctx);",
            "\t\tif (ret) {",
            "\t\t\tpr_err(\"%s: initial trylock failed!\\n\", __func__);",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t}",
            "",
            "\tif (ww_mutex_trylock(&mutex, NULL))  {",
            "\t\tpr_err(\"%s: trylocked itself without context from %s!\\n\", __func__, from);",
            "\t\tww_mutex_unlock(&mutex);",
            "\t\tret = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (ww_mutex_trylock(&mutex, &ctx))  {",
            "\t\tpr_err(\"%s: trylocked itself with context from %s!\\n\", __func__, from);",
            "\t\tww_mutex_unlock(&mutex);",
            "\t\tret = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tret = ww_mutex_lock(&mutex, &ctx);",
            "\tif (ret != -EALREADY) {",
            "\t\tpr_err(\"%s: missed deadlock for recursing, ret=%d from %s\\n\",",
            "\t\t       __func__, ret, from);",
            "\t\tif (!ret)",
            "\t\t\tww_mutex_unlock(&mutex);",
            "\t\tret = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tww_mutex_unlock(&mutex);",
            "\tret = 0;",
            "out:",
            "\tww_acquire_fini(&ctx);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "test_mutex_work, __test_mutex, test_mutex, test_aa",
          "description": "实现ww_mutex的多种测试场景，包括尝试加锁、死锁检测、递归锁冲突验证，通过工作队列模拟并发操作并校验互斥行为",
          "similarity": 0.5639439821243286
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 638,
          "end_line": 691,
          "content": [
            "static int __init test_ww_mutex_init(void)",
            "{",
            "\tint ncpus = num_online_cpus();",
            "\tint ret, i;",
            "",
            "\tprintk(KERN_INFO \"Beginning ww mutex selftests\\n\");",
            "",
            "\tprandom_seed_state(&rng, get_random_u64());",
            "",
            "\twq = alloc_workqueue(\"test-ww_mutex\", WQ_UNBOUND, 0);",
            "\tif (!wq)",
            "\t\treturn -ENOMEM;",
            "",
            "\tret = test_mutex();",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = test_aa(false);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = test_aa(true);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tfor (i = 0; i < 4; i++) {",
            "\t\tret = test_abba(i & 1, i & 2);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\tret = test_cycle(ncpus);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = stress(16, 2*ncpus, STRESS_INORDER);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = stress(16, 2*ncpus, STRESS_REORDER);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = stress(2047, hweight32(STRESS_ALL)*ncpus, STRESS_ALL);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tprintk(KERN_INFO \"All ww mutex selftests passed\\n\");",
            "\treturn 0;",
            "}",
            "static void __exit test_ww_mutex_exit(void)",
            "{",
            "\tdestroy_workqueue(wq);",
            "}"
          ],
          "function_name": "test_ww_mutex_init, test_ww_mutex_exit",
          "description": "该代码段为ww_mutex子系统的自检模块，通过初始化函数注册并启动多线程测试任务，依次执行mutex、AA锁、ABBA死锁检测及压力测试等场景验证。其中`test_ww_mutex_init`负责创建工作队列并调用系列测试函数，`test_ww_mutex_exit`用于释放资源，但具体测试函数实现未在当前片段中展示，存在上下文缺失。",
          "similarity": 0.537948727607727
        }
      ]
    },
    {
      "source_file": "kernel/locking/semaphore.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:52:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\semaphore.c`\n\n---\n\n# `locking/semaphore.c` 技术文档\n\n## 1. 文件概述\n\n`locking/semaphore.c` 实现了 Linux 内核中的**计数信号量（counting semaphore）**机制。计数信号量允许多个任务（最多为初始计数值）同时持有该锁，当计数值耗尽时，后续请求者将被阻塞，直到有其他任务释放信号量。与互斥锁（mutex）不同，信号量支持更灵活的并发控制，适用于资源池、限流等场景。该文件提供了多种获取和释放信号量的接口，包括可中断、可超时、不可中断等变体，并支持在中断上下文中调用部分函数。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数名 | 功能描述 |\n|--------|--------|\n| `down(struct semaphore *sem)` | 不可中断地获取信号量，若不可用则睡眠。**已弃用**，建议使用可中断版本。 |\n| `down_interruptible(struct semaphore *sem)` | 可被普通信号中断的获取操作，成功返回 0，被信号中断返回 `-EINTR`。 |\n| `down_killable(struct semaphore *sem)` | 可被致命信号（fatal signal）中断的获取操作，返回值同上。 |\n| `down_trylock(struct semaphore *sem)` | 非阻塞尝试获取信号量，成功返回 0，失败返回 1（**注意返回值与 mutex/spinlock 相反**）。 |\n| `down_timeout(struct semaphore *sem, long timeout)` | 带超时的获取操作，超时返回 `-ETIME`，成功返回 0。 |\n| `up(struct semaphore *sem)` | 释放信号量，可由任意上下文（包括中断）调用，唤醒等待队列中的任务。 |\n\n### 静态辅助函数\n\n- `__down*()` 系列：处理信号量争用时的阻塞逻辑。\n- `__up()`：在有等待者时执行唤醒逻辑。\n- `___down_common()`：通用的阻塞等待实现，支持不同睡眠状态和超时。\n- `__sem_acquire()`：原子减少计数并记录持有者（用于 hung task 检测）。\n\n### 数据结构\n\n- `struct semaphore`（定义在 `<linux/semaphore.h>`）：\n  - `count`：当前可用资源数（>0 表示可立即获取）。\n  - `wait_list`：等待该信号量的任务链表。\n  - `lock`：保护上述成员的原始自旋锁（`raw_spinlock_t`）。\n  - `last_holder`（条件编译）：记录最后持有者，用于 `CONFIG_DETECT_HUNG_TASK_BLOCKER`。\n\n- `struct semaphore_waiter`：\n  - 用于将任务加入等待队列，包含任务指针和唤醒标志（`up`）。\n\n## 3. 关键实现\n\n### 中断安全与自旋锁\n- 所有对外接口（包括 `down*` 和 `up`）均使用 `raw_spin_lock_irqsave()` 获取自旋锁，确保在中断上下文安全。\n- 即使 `down()` 等函数通常在进程上下文调用，也使用 `irqsave` 变体，因为内核某些部分依赖在中断上下文成功调用 `down()`（当确定信号量可用时）。\n\n### 计数语义\n- `sem->count` 表示**还可被获取的次数**。初始值由 `sema_init()` 设置。\n- 获取时：若 `count > 0`，直接减 1；否则加入等待队列。\n- 释放时：若等待队列为空，`count++`；否则唤醒队首任务。\n\n### 等待与唤醒机制\n- 使用 `wake_q`（批量唤醒队列）优化唤醒路径，避免在持有自旋锁时调用 `wake_up_process()`。\n- 等待任务通过 `schedule_timeout()` 睡眠，并在循环中检查：\n  - 是否收到信号（根据睡眠状态判断）。\n  - 是否超时。\n  - 是否被 `__up()` 标记为 `waiter.up = true`（表示已被选中唤醒）。\n\n### Hung Task 支持\n- 当启用 `CONFIG_DETECT_HUNG_TASK_BLOCKER` 时：\n  - 获取信号量时记录当前任务为 `last_holder`。\n  - 释放时若当前任务是持有者，则清除记录。\n  - 提供 `sem_last_holder()` 供 hung task 检测模块查询阻塞源头。\n\n### 返回值约定\n- `down_trylock()` 返回 **0 表示成功**，**1 表示失败**，这与 `mutex_trylock()` 和 `spin_trylock()` **相反**，需特别注意。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/semaphore.h>`：信号量结构体和 API 声明。\n  - `<linux/spinlock.h>`：原始自旋锁实现。\n  - `<linux/sched.h>`、`<linux/sched/wake_q.h>`：任务调度和批量唤醒。\n  - `<trace/events/lock.h>`：锁争用跟踪点。\n  - `<linux/hung_task.h>`：hung task 检测支持。\n\n- **内核配置依赖**：\n  - `CONFIG_DETECT_HUNG_TASK_BLOCKER`：启用信号量持有者跟踪。\n\n- **与其他同步原语关系**：\n  - 与 `mutex.c` 形成对比：mutex 是二值、不可递归、带调试信息的互斥锁；信号量是计数、可被任意任务释放、更轻量。\n  - 底层依赖调度器（`schedule_timeout`）和中断管理（`irqsave`）。\n\n## 5. 使用场景\n\n- **资源池管理**：如限制同时访问某类硬件设备的任务数量。\n- **读写并发控制**：配合其他机制实现多读者/单写者模型。\n- **内核驱动**：设备驱动中控制对共享资源的并发访问。\n- **中断上下文释放**：因 `up()` 可在中断中调用，适用于中断处理程序释放资源的场景。\n- **不可睡眠路径**：使用 `down_trylock()` 在原子上下文尝试获取资源。\n\n> **注意**：由于信号量不强制所有权（任意任务可调用 `up()`），且缺乏死锁检测等调试特性，现代内核开发中更推荐使用 `mutex` 或 `rwsem`，除非明确需要计数语义或多释放者特性。",
      "similarity": 0.5774633288383484,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/semaphore.c",
          "start_line": 252,
          "end_line": 323,
          "content": [
            "static inline int __sched ___down_common(struct semaphore *sem, long state,",
            "\t\t\t\t\t\t\t\tlong timeout)",
            "{",
            "\tstruct semaphore_waiter waiter;",
            "",
            "\tlist_add_tail(&waiter.list, &sem->wait_list);",
            "\twaiter.task = current;",
            "\twaiter.up = false;",
            "",
            "\tfor (;;) {",
            "\t\tif (signal_pending_state(state, current))",
            "\t\t\tgoto interrupted;",
            "\t\tif (unlikely(timeout <= 0))",
            "\t\t\tgoto timed_out;",
            "\t\t__set_current_state(state);",
            "\t\traw_spin_unlock_irq(&sem->lock);",
            "\t\ttimeout = schedule_timeout(timeout);",
            "\t\traw_spin_lock_irq(&sem->lock);",
            "\t\tif (waiter.up) {",
            "\t\t\thung_task_sem_set_holder(sem);",
            "\t\t\treturn 0;",
            "\t\t}",
            "\t}",
            "",
            " timed_out:",
            "\tlist_del(&waiter.list);",
            "\treturn -ETIME;",
            "",
            " interrupted:",
            "\tlist_del(&waiter.list);",
            "\treturn -EINTR;",
            "}",
            "static inline int __sched __down_common(struct semaphore *sem, long state,",
            "\t\t\t\t\tlong timeout)",
            "{",
            "\tint ret;",
            "",
            "\thung_task_set_blocker(sem, BLOCKER_TYPE_SEM);",
            "",
            "\ttrace_contention_begin(sem, 0);",
            "\tret = ___down_common(sem, state, timeout);",
            "\ttrace_contention_end(sem, ret);",
            "",
            "\thung_task_clear_blocker();",
            "",
            "\treturn ret;",
            "}",
            "static noinline void __sched __down(struct semaphore *sem)",
            "{",
            "\t__down_common(sem, TASK_UNINTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);",
            "}",
            "static noinline int __sched __down_interruptible(struct semaphore *sem)",
            "{",
            "\treturn __down_common(sem, TASK_INTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);",
            "}",
            "static noinline int __sched __down_killable(struct semaphore *sem)",
            "{",
            "\treturn __down_common(sem, TASK_KILLABLE, MAX_SCHEDULE_TIMEOUT);",
            "}",
            "static noinline int __sched __down_timeout(struct semaphore *sem, long timeout)",
            "{",
            "\treturn __down_common(sem, TASK_UNINTERRUPTIBLE, timeout);",
            "}",
            "static noinline void __sched __up(struct semaphore *sem,",
            "\t\t\t\t  struct wake_q_head *wake_q)",
            "{",
            "\tstruct semaphore_waiter *waiter = list_first_entry(&sem->wait_list,",
            "\t\t\t\t\t\tstruct semaphore_waiter, list);",
            "\tlist_del(&waiter->list);",
            "\twaiter->up = true;",
            "\twake_q_add(wake_q, waiter->task);",
            "}"
          ],
          "function_name": "___down_common, __down_common, __down, __down_interruptible, __down_killable, __down_timeout, __up",
          "description": "实现了信号量的阻塞等待通用逻辑，包含___down_common/__down_common等辅助函数，处理信号量不足时的任务挂起、超时检测、信号处理及唤醒机制，通过循环等待并结合schedule_timeout实现阻塞式资源竞争解决",
          "similarity": 0.6215659976005554
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/semaphore.c",
          "start_line": 46,
          "end_line": 160,
          "content": [
            "static inline void hung_task_sem_set_holder(struct semaphore *sem)",
            "{",
            "\tWRITE_ONCE((sem)->last_holder, (unsigned long)current);",
            "}",
            "static inline void hung_task_sem_clear_if_holder(struct semaphore *sem)",
            "{",
            "\tif (READ_ONCE((sem)->last_holder) == (unsigned long)current)",
            "\t\tWRITE_ONCE((sem)->last_holder, 0UL);",
            "}",
            "unsigned long sem_last_holder(struct semaphore *sem)",
            "{",
            "\treturn READ_ONCE(sem->last_holder);",
            "}",
            "static inline void hung_task_sem_set_holder(struct semaphore *sem)",
            "{",
            "}",
            "static inline void hung_task_sem_clear_if_holder(struct semaphore *sem)",
            "{",
            "}",
            "unsigned long sem_last_holder(struct semaphore *sem)",
            "{",
            "\treturn 0UL;",
            "}",
            "static inline void __sem_acquire(struct semaphore *sem)",
            "{",
            "\tsem->count--;",
            "\thung_task_sem_set_holder(sem);",
            "}",
            "void __sched down(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\t__down(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "}",
            "int __sched down_interruptible(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tint result = 0;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\tresult = __down_interruptible(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn result;",
            "}",
            "int __sched down_killable(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tint result = 0;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\tresult = __down_killable(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn result;",
            "}",
            "int __sched down_trylock(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tint count;",
            "",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tcount = sem->count - 1;",
            "\tif (likely(count >= 0))",
            "\t\t__sem_acquire(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn (count < 0);",
            "}",
            "int __sched down_timeout(struct semaphore *sem, long timeout)",
            "{",
            "\tunsigned long flags;",
            "\tint result = 0;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\tresult = __down_timeout(sem, timeout);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn result;",
            "}",
            "void __sched up(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tDEFINE_WAKE_Q(wake_q);",
            "",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "",
            "\thung_task_sem_clear_if_holder(sem);",
            "",
            "\tif (likely(list_empty(&sem->wait_list)))",
            "\t\tsem->count++;",
            "\telse",
            "\t\t__up(sem, &wake_q);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "\tif (!wake_q_empty(&wake_q))",
            "\t\twake_up_q(&wake_q);",
            "}"
          ],
          "function_name": "hung_task_sem_set_holder, hung_task_sem_clear_if_holder, sem_last_holder, hung_task_sem_set_holder, hung_task_sem_clear_if_holder, sem_last_holder, __sem_acquire, down, down_interruptible, down_killable, down_trylock, down_timeout, up",
          "description": "实现了信号量的获取与释放核心逻辑，包括down/down_interruptible/down_killable/down_trylock/down_timeout等接口，通过spinlock保护共享资源，维护等待队列并处理任务状态变更，其中包含Hung Task检测相关函数的条件性实现",
          "similarity": 0.5724207162857056
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/semaphore.c",
          "start_line": 1,
          "end_line": 45,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Copyright (c) 2008 Intel Corporation",
            " * Author: Matthew Wilcox <willy@linux.intel.com>",
            " *",
            " * This file implements counting semaphores.",
            " * A counting semaphore may be acquired 'n' times before sleeping.",
            " * See mutex.c for single-acquisition sleeping locks which enforce",
            " * rules which allow code to be debugged more easily.",
            " */",
            "",
            "/*",
            " * Some notes on the implementation:",
            " *",
            " * The spinlock controls access to the other members of the semaphore.",
            " * down_trylock() and up() can be called from interrupt context, so we",
            " * have to disable interrupts when taking the lock.  It turns out various",
            " * parts of the kernel expect to be able to use down() on a semaphore in",
            " * interrupt context when they know it will succeed, so we have to use",
            " * irqsave variants for down(), down_interruptible() and down_killable()",
            " * too.",
            " *",
            " * The ->count variable represents how many more tasks can acquire this",
            " * semaphore.  If it's zero, there may be tasks waiting on the wait_list.",
            " */",
            "",
            "#include <linux/compiler.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>",
            "#include <linux/sched.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/semaphore.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/ftrace.h>",
            "#include <trace/events/lock.h>",
            "#include <linux/hung_task.h>",
            "",
            "static noinline void __down(struct semaphore *sem);",
            "static noinline int __down_interruptible(struct semaphore *sem);",
            "static noinline int __down_killable(struct semaphore *sem);",
            "static noinline int __down_timeout(struct semaphore *sem, long timeout);",
            "static noinline void __up(struct semaphore *sem, struct wake_q_head *wake_q);",
            "",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER"
          ],
          "function_name": null,
          "description": "此代码块定义了计数信号量的基础框架，包含实现计数信号量所需的头文件和注释，声明了多个内联函数及辅助函数，用于处理信号量的获取、释放及Hung Task检测相关逻辑，但由于代码截断，CONFIG_DETECT_HUNG_TASK_BLOCKER部分缺失，上下文不完整",
          "similarity": 0.48395442962646484
        }
      ]
    },
    {
      "source_file": "kernel/locking/mutex-debug.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:42:02\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\mutex-debug.c`\n\n---\n\n# `locking/mutex-debug.c` 技术文档\n\n## 1. 文件概述\n\n`mutex-debug.c` 是 Linux 内核中用于调试互斥锁（mutex）的辅助实现文件。该文件提供了一系列调试钩子函数，在启用锁调试功能（如 `CONFIG_DEBUG_MUTEXES` 或 `CONFIG_DEBUG_LOCK_ALLOC`）时，用于检测互斥锁使用中的常见错误，包括：\n- 重复初始化或销毁已持有的锁\n- 等待者（waiter）数据结构的非法状态\n- 死锁风险（通过与 lockdep 集成）\n- 内存污染（通过魔数 magic 和 poison 值）\n\n这些调试函数在正常编译配置下可能被编译器优化掉，仅在调试模式下生效，以最小化对性能的影响。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数名 | 功能描述 |\n|--------|--------|\n| `debug_mutex_lock_common()` | 初始化一个 `mutex_waiter` 结构，设置魔数和初始状态 |\n| `debug_mutex_wake_waiter()` | 在唤醒等待者前验证其状态合法性 |\n| `debug_mutex_free_waiter()` | 释放等待者结构前清空并标记为已释放 |\n| `debug_mutex_add_waiter()` | 将当前任务标记为阻塞在指定 mutex 上（用于死锁检测） |\n| `debug_mutex_remove_waiter()` | 从等待队列中移除等待者，并清除任务的阻塞状态 |\n| `debug_mutex_unlock()` | 验证解锁操作时 mutex 的一致性（如魔数、等待队列状态） |\n| `debug_mutex_init()` | 初始化 mutex 的调试字段，并集成 lockdep 锁类跟踪 |\n| `mutex_destroy()` | 标记 mutex 为不可用，防止后续误用 |\n| `__devm_mutex_init()` | 为设备资源管理（devres）提供自动销毁的 mutex 初始化接口 |\n\n### 关键数据结构字段（调试相关）\n\n- `mutex::magic`：指向自身，用于检测内存损坏或重复释放\n- `mutex_waiter::magic`：指向自身，用于验证 waiter 结构完整性\n- `task_struct::blocked_on`：指向当前任务正在等待的 waiter，用于死锁检测\n- `mutex_waiter::ww_ctx`：用于 ww_mutex（写写互斥锁）调试，初始化为 poison 值\n\n## 3. 关键实现\n\n### 魔数（Magic Number）与 Poison 值\n- 所有 mutex 和 waiter 结构在初始化时设置 `magic = self`，销毁时置为 `NULL` 或特定 poison 值（如 `MUTEX_DEBUG_INIT`/`MUTEX_DEBUG_FREE`）。\n- 通过 `DEBUG_LOCKS_WARN_ON()` 宏在关键路径检查这些值，一旦发现异常立即触发警告。\n\n### 与 Lockdep 集成\n- `debug_mutex_init()` 调用 `lockdep_init_map_wait()` 将 mutex 注册到 lockdep 锁依赖跟踪系统，支持死锁检测。\n- `debug_check_no_locks_freed()` 确保不会在锁仍被持有时重新初始化，防止状态混乱。\n\n### 等待者生命周期管理\n- `debug_mutex_add_waiter()` 设置 `task->blocked_on = waiter`，使 lockdep 能构建任务等待图。\n- `debug_mutex_remove_waiter()` 清除此指针，并验证 waiter 与 task 的一致性，防止悬挂引用。\n\n### 设备资源管理（devres）支持\n- `__devm_mutex_init()` 利用 devres 框架自动注册 `devm_mutex_release()` 回调，确保设备卸载时自动调用 `mutex_destroy()`，避免资源泄漏。\n\n### 断言与警告\n- 大量使用 `lockdep_assert_held(&lock->wait_lock)` 确保函数在正确锁保护下被调用。\n- `DEBUG_LOCKS_WARN_ON()` 在检测到非法状态时输出警告（仅在 `debug_locks` 全局变量启用时生效）。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/mutex.h>`：mutex 核心 API\n  - `<linux/debug_locks.h>`：调试锁的通用宏（如 `DEBUG_LOCKS_WARN_ON`）\n  - `<linux/lockdep.h>`（间接）：通过 `lockdep_init_map_wait` 和 `debug_check_no_locks_freed`\n  - `<linux/device.h>`：devres 相关接口\n  - `<linux/sched.h>`：访问 `task_struct::blocked_on`\n\n- **内核配置依赖**：\n  - `CONFIG_DEBUG_MUTEXES`：启用 mutex 调试逻辑\n  - `CONFIG_DEBUG_LOCK_ALLOC`：启用 lockdep 集成\n  - `CONFIG_DEBUG_LIST`：增强链表调试（通过 `DEBUG_LOCKS_WARN_ON(list_empty(...))`）\n\n- **内部依赖**：\n  - 依赖 `mutex.h`（本地头文件）中定义的内部结构（如 `mutex_waiter`）\n\n## 5. 使用场景\n\n- **内核开发与调试**：\n  - 在启用 `CONFIG_DEBUG_MUTEXES` 的内核中，所有 mutex 操作自动插入调试检查，帮助开发者发现竞态条件、死锁或 API 误用。\n\n- **死锁检测**：\n  - 通过 `task->blocked_on` 和 lockdep 的等待图分析，检测潜在的 AB-BA 死锁。\n\n- **内存安全验证**：\n  - 魔数和 poison 值用于检测 use-after-free 或内存越界写入导致的 mutex 结构损坏。\n\n- **设备驱动开发**：\n  - 驱动使用 `__devm_mutex_init()` 可自动管理 mutex 生命周期，避免在错误路径遗漏 `mutex_destroy()`。\n\n- **生产环境**：\n  - 在非调试内核中，所有调试函数为空或内联优化掉，对性能无影响。",
      "similarity": 0.570821225643158,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/mutex-debug.c",
          "start_line": 29,
          "end_line": 98,
          "content": [
            "void debug_mutex_lock_common(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\tmemset(waiter, MUTEX_DEBUG_INIT, sizeof(*waiter));",
            "\twaiter->magic = waiter;",
            "\tINIT_LIST_HEAD(&waiter->list);",
            "\twaiter->ww_ctx = MUTEX_POISON_WW_CTX;",
            "}",
            "void debug_mutex_wake_waiter(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "\tDEBUG_LOCKS_WARN_ON(list_empty(&lock->wait_list));",
            "\tDEBUG_LOCKS_WARN_ON(waiter->magic != waiter);",
            "\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));",
            "}",
            "void debug_mutex_free_waiter(struct mutex_waiter *waiter)",
            "{",
            "\tDEBUG_LOCKS_WARN_ON(!list_empty(&waiter->list));",
            "\tmemset(waiter, MUTEX_DEBUG_FREE, sizeof(*waiter));",
            "}",
            "void debug_mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,",
            "\t\t\t    struct task_struct *task)",
            "{",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\t/* Mark the current thread as blocked on the lock: */",
            "\ttask->blocked_on = waiter;",
            "}",
            "void debug_mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter,",
            "\t\t\t struct task_struct *task)",
            "{",
            "\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));",
            "\tDEBUG_LOCKS_WARN_ON(waiter->task != task);",
            "\tDEBUG_LOCKS_WARN_ON(task->blocked_on != waiter);",
            "\ttask->blocked_on = NULL;",
            "",
            "\tINIT_LIST_HEAD(&waiter->list);",
            "\twaiter->task = NULL;",
            "}",
            "void debug_mutex_unlock(struct mutex *lock)",
            "{",
            "\tif (likely(debug_locks)) {",
            "\t\tDEBUG_LOCKS_WARN_ON(lock->magic != lock);",
            "\t\tDEBUG_LOCKS_WARN_ON(!lock->wait_list.prev && !lock->wait_list.next);",
            "\t}",
            "}",
            "void debug_mutex_init(struct mutex *lock, const char *name,",
            "\t\t      struct lock_class_key *key)",
            "{",
            "#ifdef CONFIG_DEBUG_LOCK_ALLOC",
            "\t/*",
            "\t * Make sure we are not reinitializing a held lock:",
            "\t */",
            "\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));",
            "\tlockdep_init_map_wait(&lock->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "#endif",
            "\tlock->magic = lock;",
            "}",
            "static void devm_mutex_release(void *res)",
            "{",
            "\tmutex_destroy(res);",
            "}",
            "int __devm_mutex_init(struct device *dev, struct mutex *lock)",
            "{",
            "\treturn devm_add_action_or_reset(dev, devm_mutex_release, lock);",
            "}",
            "void mutex_destroy(struct mutex *lock)",
            "{",
            "\tDEBUG_LOCKS_WARN_ON(mutex_is_locked(lock));",
            "\tlock->magic = NULL;",
            "}"
          ],
          "function_name": "debug_mutex_lock_common, debug_mutex_wake_waiter, debug_mutex_free_waiter, debug_mutex_add_waiter, debug_mutex_remove_waiter, debug_mutex_unlock, debug_mutex_init, devm_mutex_release, __devm_mutex_init, mutex_destroy",
          "description": "实现了互斥锁调试核心函数，包括等待队列项初始化、唤醒/移除等待者、解锁验证、锁初始化及设备管理资源释放等功能，通过magic值校验和链表状态检测实现锁状态调试保障",
          "similarity": 0.599261462688446
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/mutex-debug.c",
          "start_line": 1,
          "end_line": 28,
          "content": [
            "/*",
            " * Debugging code for mutexes",
            " *",
            " * Started by Ingo Molnar:",
            " *",
            " *  Copyright (C) 2004, 2005, 2006 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>",
            " *",
            " * lock debugging, locking tree, deadlock detection started by:",
            " *",
            " *  Copyright (C) 2004, LynuxWorks, Inc., Igor Manyilov, Bill Huey",
            " *  Released under the General Public License (GPL).",
            " */",
            "#include <linux/mutex.h>",
            "#include <linux/delay.h>",
            "#include <linux/device.h>",
            "#include <linux/export.h>",
            "#include <linux/poison.h>",
            "#include <linux/sched.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/debug_locks.h>",
            "",
            "#include \"mutex.h\"",
            "",
            "/*",
            " * Must be called with lock->wait_lock held.",
            " */"
          ],
          "function_name": null,
          "description": "此代码块定义了互斥锁调试模块的头文件引入及基本注释，包含核心调试相关头文件并声明了互斥锁调试逻辑的实现位置，当前上下文不完整",
          "similarity": 0.4529486298561096
        }
      ]
    }
  ]
}