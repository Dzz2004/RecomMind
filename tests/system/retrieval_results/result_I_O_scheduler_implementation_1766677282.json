{
  "query": "I/O scheduler implementation",
  "timestamp": "2025-12-25 23:41:22",
  "retrieved_files": [
    {
      "source_file": "kernel/sched/cpufreq_schedutil.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:03:51\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\cpufreq_schedutil.c`\n\n---\n\n# `sched/cpufreq_schedutil.c` 技术文档\n\n## 1. 文件概述\n\n`sched/cpufreq_schedutil.c` 实现了 Linux 内核中基于调度器提供的 CPU 利用率数据的 **schedutil CPUFreq 调速器（governor）**。该调速器通过实时获取调度器计算的 CPU 利用率（包括 CFS、RT、DL 任务以及 I/O 等待状态），动态调整 CPU 频率，以在性能与能效之间取得平衡。其核心优势在于直接利用调度器的 `util` 信息，避免传统调速器依赖采样机制带来的延迟和不准确性。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct sugov_tunables`**  \n  调速器可调参数，包含：\n  - `rate_limit_us`：频率更新的最小时间间隔（微秒），防止过于频繁的频率切换。\n\n- **`struct sugov_policy`**  \n  每个 `cpufreq_policy` 对应的 schedutil 策略实例，包含：\n  - `policy`：关联的 CPUFreq 策略。\n  - `update_lock`：保护频率更新的自旋锁。\n  - `last_freq_update_time` / `freq_update_delay_ns`：控制频率更新速率。\n  - `next_freq` / `cached_raw_freq`：目标频率与原始计算频率缓存。\n  - `irq_work` / `worker` / `thread`：用于慢速切换平台（非 fast-switch）的异步工作队列机制。\n  - `limits_changed` / `need_freq_update`：标志策略限制（如 min/max freq）是否变更。\n\n- **`struct sugov_cpu`**  \n  每个 CPU 的 schedutil 状态，包含：\n  - `update_util`：注册到调度器的回调接口（`update_util_data`）。\n  - `util` / `bw_min`：当前有效利用率及带宽最小值。\n  - `iowait_boost` / `iowait_boost_pending`：I/O 等待唤醒时的频率提升机制。\n  - `last_update`：上次更新时间戳。\n\n### 主要函数\n\n- **`sugov_should_update_freq()`**  \n  判断是否应执行频率更新，考虑硬件是否支持本 CPU 更新、策略限制变更、以及频率更新间隔限制。\n\n- **`sugov_update_next_freq()`**  \n  更新目标频率，处理策略限制变更场景，避免不必要的驱动回调。\n\n- **`get_next_freq()`**  \n  核心频率计算函数，根据 CPU 利用率、最大容量和参考频率，计算目标频率，并通过 `cpufreq_driver_resolve_freq()` 映射到驱动支持的频率。\n\n- **`sugov_get_util()`**  \n  获取当前 CPU 的综合利用率，整合 CFS/RT/DL 任务利用率、boost 值，并调用 `sugov_effective_cpu_perf()` 计算有效性能目标。\n\n- **`sugov_effective_cpu_perf()`**  \n  计算最终的有效性能目标，确保不低于最小性能要求，并限制不超过实际需求。\n\n- **`sugov_iowait_reset()` / `sugov_iowait_boost()`**  \n  实现 I/O 等待唤醒时的动态频率提升机制：短时间内连续 I/O 唤醒会逐步提升 boost 值（从 `IOWAIT_BOOST_MIN` 到最大 OPP），超过一个 tick 无 I/O 唤醒则重置。\n\n- **`get_capacity_ref_freq()`**  \n  获取用于计算 CPU 容量的参考频率，优先使用架构特定的 `arch_scale_freq_ref()`，其次为最大频率或当前频率。\n\n- **`sugov_deferred_update()`**  \n  在不支持 fast-switch 的平台上，通过 `irq_work` 触发异步频率更新。\n\n## 3. 关键实现\n\n### 频率计算算法\n- **频率不变性支持**：若系统支持频率不变调度（`arch_scale_freq_invariant()`），则直接使用调度器提供的频率不变利用率 `util`，按比例计算目标频率：  \n  `next_freq = C * max_freq * util / max`  \n  其中常数 `C = 1.25`，使在 `util/max = 0.8` 时达到 `max_freq`，提供性能余量。\n- **非频率不变性**：使用原始利用率 `util_raw` 乘以 `(curr_freq / max_freq)` 近似频率不变利用率，再计算目标频率。\n\n### I/O 等待 Boost 机制\n- 当任务因 I/O 完成而唤醒时，标记 `SCHED_CPUFREQ_IOWAIT`。\n- 若在 **一个 tick 内** 多次发生 I/O 唤醒，则 `iowait_boost` 值倍增（上限为最大 OPP 对应的利用率）。\n- 若超过一个 tick 无 I/O 唤醒，则重置 boost 值为 `IOWAIT_BOOST_MIN`（`SCHED_CAPACITY_SCALE / 8`），避免对偶发 I/O 过度响应，提升能效。\n\n### 快速切换（Fast-Switch）与异步更新\n- **Fast-Switch 平台**：支持在调度上下文中直接调用 `cpufreq_driver_fast_switch()` 更新频率，延迟最低。\n- **非 Fast-Switch 平台**：通过 `irq_work` 触发内核线程（`kthread_worker`）异步执行频率更新，避免在中断上下文或持有 rq 锁时调用可能阻塞的驱动接口。\n\n### 策略限制变更处理\n- 当用户空间修改 policy 的 min/max 频率时，`sugov_limits()` 设置 `limits_changed` 标志。\n- 下次更新时，强制重新计算频率，并通过内存屏障（`smp_mb()`）确保读取到最新的策略限制。\n\n## 4. 依赖关系\n\n- **调度器子系统**：\n  - 依赖 `update_util_data` 回调机制（通过 `cpufreq_add_update_util_hook()` 注册）。\n  - 调用 `cpu_util_cfs_boost()`、`effective_cpu_util()` 等函数获取综合利用率。\n  - 使用 `scx_cpuperf_target()`（若启用了 SCHED_CLASS_EXT）。\n- **CPUFreq 核心**：\n  - 依赖 `cpufreq_policy`、`cpufreq_driver_resolve_freq()`、`cpufreq_driver_fast_switch()` 等接口。\n  - 使用 `cpufreq_this_cpu_can_update()` 判断硬件更新能力。\n- **架构相关支持**：\n  - 依赖 `arch_scale_freq_ref()` 和 `arch_scale_freq_invariant()` 提供频率不变性信息。\n- **内核基础设施**：\n  - 使用 `irq_work`、`kthread_worker` 实现异步更新。\n  - 依赖 `TICK_NSEC` 定义 tick 时间。\n\n## 5. 使用场景\n\n- **默认高性能能效平衡场景**：现代 Linux 发行版通常将 `schedutil` 作为默认 CPUFreq 调速器，适用于大多数桌面、服务器和移动设备。\n- **实时性要求较高的系统**：由于其低延迟特性（尤其在 fast-switch 平台上），适合对响应时间敏感的应用。\n- **能效敏感设备**：通过 I/O boost 机制和精确的利用率跟踪，在保证交互性能的同时降低空闲功耗。\n- **异构多核系统（如 big.LITTLE）**：结合调度器的 CPU capacity 信息，为不同性能核提供差异化频率调整。",
      "similarity": 0.5352804064750671,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 204,
          "end_line": 330,
          "content": [
            "unsigned long sugov_effective_cpu_perf(int cpu, unsigned long actual,",
            "\t\t\t\t unsigned long min,",
            "\t\t\t\t unsigned long max)",
            "{",
            "\t/* Add dvfs headroom to actual utilization */",
            "\tactual = map_util_perf(actual);",
            "\t/* Actually we don't need to target the max performance */",
            "\tif (actual < max)",
            "\t\tmax = actual;",
            "",
            "\t/*",
            "\t * Ensure at least minimum performance while providing more compute",
            "\t * capacity when possible.",
            "\t */",
            "\treturn max(min, max);",
            "}",
            "static void sugov_get_util(struct sugov_cpu *sg_cpu, unsigned long boost)",
            "{",
            "\tunsigned long min, max, util = scx_cpuperf_target(sg_cpu->cpu);",
            "",
            "\tif (!scx_switched_all())",
            "\t\tutil += cpu_util_cfs_boost(sg_cpu->cpu);",
            "\tutil = effective_cpu_util(sg_cpu->cpu, util, &min, &max);",
            "\tutil = max(util, boost);",
            "\tsg_cpu->bw_min = min;",
            "\tsg_cpu->util = sugov_effective_cpu_perf(sg_cpu->cpu, util, min, max);",
            "}",
            "static bool sugov_iowait_reset(struct sugov_cpu *sg_cpu, u64 time,",
            "\t\t\t       bool set_iowait_boost)",
            "{",
            "\ts64 delta_ns = time - sg_cpu->last_update;",
            "",
            "\t/* Reset boost only if a tick has elapsed since last request */",
            "\tif (delta_ns <= TICK_NSEC)",
            "\t\treturn false;",
            "",
            "\tsg_cpu->iowait_boost = set_iowait_boost ? IOWAIT_BOOST_MIN : 0;",
            "\tsg_cpu->iowait_boost_pending = set_iowait_boost;",
            "",
            "\treturn true;",
            "}",
            "static void sugov_iowait_boost(struct sugov_cpu *sg_cpu, u64 time,",
            "\t\t\t       unsigned int flags)",
            "{",
            "\tbool set_iowait_boost = flags & SCHED_CPUFREQ_IOWAIT;",
            "",
            "\t/* Reset boost if the CPU appears to have been idle enough */",
            "\tif (sg_cpu->iowait_boost &&",
            "\t    sugov_iowait_reset(sg_cpu, time, set_iowait_boost))",
            "\t\treturn;",
            "",
            "\t/* Boost only tasks waking up after IO */",
            "\tif (!set_iowait_boost)",
            "\t\treturn;",
            "",
            "\t/* Ensure boost doubles only one time at each request */",
            "\tif (sg_cpu->iowait_boost_pending)",
            "\t\treturn;",
            "\tsg_cpu->iowait_boost_pending = true;",
            "",
            "\t/* Double the boost at each request */",
            "\tif (sg_cpu->iowait_boost) {",
            "\t\tsg_cpu->iowait_boost =",
            "\t\t\tmin_t(unsigned int, sg_cpu->iowait_boost << 1, SCHED_CAPACITY_SCALE);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* First wakeup after IO: start with minimum boost */",
            "\tsg_cpu->iowait_boost = IOWAIT_BOOST_MIN;",
            "}",
            "static unsigned long sugov_iowait_apply(struct sugov_cpu *sg_cpu, u64 time,",
            "\t\t\t       unsigned long max_cap)",
            "{",
            "\t/* No boost currently required */",
            "\tif (!sg_cpu->iowait_boost)",
            "\t\treturn 0;",
            "",
            "\t/* Reset boost if the CPU appears to have been idle enough */",
            "\tif (sugov_iowait_reset(sg_cpu, time, false))",
            "\t\treturn 0;",
            "",
            "\tif (!sg_cpu->iowait_boost_pending) {",
            "\t\t/*",
            "\t\t * No boost pending; reduce the boost value.",
            "\t\t */",
            "\t\tsg_cpu->iowait_boost >>= 1;",
            "\t\tif (sg_cpu->iowait_boost < IOWAIT_BOOST_MIN) {",
            "\t\t\tsg_cpu->iowait_boost = 0;",
            "\t\t\treturn 0;",
            "\t\t}",
            "\t}",
            "",
            "\tsg_cpu->iowait_boost_pending = false;",
            "",
            "\t/*",
            "\t * sg_cpu->util is already in capacity scale; convert iowait_boost",
            "\t * into the same scale so we can compare.",
            "\t */",
            "\treturn (sg_cpu->iowait_boost * max_cap) >> SCHED_CAPACITY_SHIFT;",
            "}",
            "static bool sugov_hold_freq(struct sugov_cpu *sg_cpu)",
            "{",
            "\tunsigned long idle_calls;",
            "\tbool ret;",
            "",
            "\t/*",
            "\t * The heuristics in this function is for the fair class. For SCX, the",
            "\t * performance target comes directly from the BPF scheduler. Let's just",
            "\t * follow it.",
            "\t */",
            "\tif (scx_switched_all())",
            "\t\treturn false;",
            "",
            "\t/* if capped by uclamp_max, always update to be in compliance */",
            "\tif (uclamp_rq_is_capped(cpu_rq(sg_cpu->cpu)))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Maintain the frequency if the CPU has not been idle recently, as",
            "\t * reduction is likely to be premature.",
            "\t */",
            "\tidle_calls = tick_nohz_get_idle_calls_cpu(sg_cpu->cpu);",
            "\tret = idle_calls == sg_cpu->saved_idle_calls;",
            "",
            "\tsg_cpu->saved_idle_calls = idle_calls;",
            "\treturn ret;",
            "}"
          ],
          "function_name": "sugov_effective_cpu_perf, sugov_get_util, sugov_iowait_reset, sugov_iowait_boost, sugov_iowait_apply, sugov_hold_freq",
          "description": "处理利用率计算和I/O等待优化，sugov_effective_cpu_perf计算有效性能需求，sugov_get_util获取考虑boost后的利用率，sugov_iowait_*系列函数管理I/O等待场景下的频率提升机制。",
          "similarity": 0.5331511497497559
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 381,
          "end_line": 496,
          "content": [
            "static inline bool sugov_hold_freq(struct sugov_cpu *sg_cpu) { return false; }",
            "static inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu)",
            "{",
            "\tif (cpu_bw_dl(cpu_rq(sg_cpu->cpu)) > sg_cpu->bw_min)",
            "\t\tWRITE_ONCE(sg_cpu->sg_policy->limits_changed, true);",
            "}",
            "static inline bool sugov_update_single_common(struct sugov_cpu *sg_cpu,",
            "\t\t\t\t\t      u64 time, unsigned long max_cap,",
            "\t\t\t\t\t      unsigned int flags)",
            "{",
            "\tunsigned long boost;",
            "",
            "\tsugov_iowait_boost(sg_cpu, time, flags);",
            "\tsg_cpu->last_update = time;",
            "",
            "\tignore_dl_rate_limit(sg_cpu);",
            "",
            "\tif (!sugov_should_update_freq(sg_cpu->sg_policy, time))",
            "\t\treturn false;",
            "",
            "\tboost = sugov_iowait_apply(sg_cpu, time, max_cap);",
            "\tsugov_get_util(sg_cpu, boost);",
            "",
            "\treturn true;",
            "}",
            "static void sugov_update_single_freq(struct update_util_data *hook, u64 time,",
            "\t\t\t\t     unsigned int flags)",
            "{",
            "\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);",
            "\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;",
            "\tunsigned int cached_freq = sg_policy->cached_raw_freq;",
            "\tunsigned long max_cap;",
            "\tunsigned int next_f;",
            "",
            "\tmax_cap = arch_scale_cpu_capacity(sg_cpu->cpu);",
            "",
            "\tif (!sugov_update_single_common(sg_cpu, time, max_cap, flags))",
            "\t\treturn;",
            "",
            "\tnext_f = get_next_freq(sg_policy, sg_cpu->util, max_cap);",
            "",
            "\tif (sugov_hold_freq(sg_cpu) && next_f < sg_policy->next_freq &&",
            "\t    !sg_policy->need_freq_update) {",
            "\t\tnext_f = sg_policy->next_freq;",
            "",
            "\t\t/* Restore cached freq as next_freq has changed */",
            "\t\tsg_policy->cached_raw_freq = cached_freq;",
            "\t}",
            "",
            "\tif (!sugov_update_next_freq(sg_policy, time, next_f))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * This code runs under rq->lock for the target CPU, so it won't run",
            "\t * concurrently on two different CPUs for the same target and it is not",
            "\t * necessary to acquire the lock in the fast switch case.",
            "\t */",
            "\tif (sg_policy->policy->fast_switch_enabled) {",
            "\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);",
            "\t} else {",
            "\t\traw_spin_lock(&sg_policy->update_lock);",
            "\t\tsugov_deferred_update(sg_policy);",
            "\t\traw_spin_unlock(&sg_policy->update_lock);",
            "\t}",
            "}",
            "static void sugov_update_single_perf(struct update_util_data *hook, u64 time,",
            "\t\t\t\t     unsigned int flags)",
            "{",
            "\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);",
            "\tunsigned long prev_util = sg_cpu->util;",
            "\tunsigned long max_cap;",
            "",
            "\t/*",
            "\t * Fall back to the \"frequency\" path if frequency invariance is not",
            "\t * supported, because the direct mapping between the utilization and",
            "\t * the performance levels depends on the frequency invariance.",
            "\t */",
            "\tif (!arch_scale_freq_invariant()) {",
            "\t\tsugov_update_single_freq(hook, time, flags);",
            "\t\treturn;",
            "\t}",
            "",
            "\tmax_cap = arch_scale_cpu_capacity(sg_cpu->cpu);",
            "",
            "\tif (!sugov_update_single_common(sg_cpu, time, max_cap, flags))",
            "\t\treturn;",
            "",
            "\tif (sugov_hold_freq(sg_cpu) && sg_cpu->util < prev_util)",
            "\t\tsg_cpu->util = prev_util;",
            "",
            "\tcpufreq_driver_adjust_perf(sg_cpu->cpu, sg_cpu->bw_min,",
            "\t\t\t\t   sg_cpu->util, max_cap);",
            "",
            "\tsg_cpu->sg_policy->last_freq_update_time = time;",
            "}",
            "static unsigned int sugov_next_freq_shared(struct sugov_cpu *sg_cpu, u64 time)",
            "{",
            "\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;",
            "\tstruct cpufreq_policy *policy = sg_policy->policy;",
            "\tunsigned long util = 0, max_cap;",
            "\tunsigned int j;",
            "",
            "\tmax_cap = arch_scale_cpu_capacity(sg_cpu->cpu);",
            "",
            "\tfor_each_cpu(j, policy->cpus) {",
            "\t\tstruct sugov_cpu *j_sg_cpu = &per_cpu(sugov_cpu, j);",
            "\t\tunsigned long boost;",
            "",
            "\t\tboost = sugov_iowait_apply(j_sg_cpu, time, max_cap);",
            "\t\tsugov_get_util(j_sg_cpu, boost);",
            "",
            "\t\tutil = max(j_sg_cpu->util, util);",
            "\t}",
            "",
            "\treturn get_next_freq(sg_policy, util, max_cap);",
            "}"
          ],
          "function_name": "sugov_hold_freq, ignore_dl_rate_limit, sugov_update_single_common, sugov_update_single_freq, sugov_update_single_perf, sugov_next_freq_shared",
          "description": "实现单核/多核频率调整逻辑，sugov_update_single_freq处理单核频率更新，sugov_update_single_perf处理性能调优路径，sugov_next_freq_shared计算多核共享场景下的全局目标频率。",
          "similarity": 0.5304836630821228
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 508,
          "end_line": 651,
          "content": [
            "static void",
            "sugov_update_shared(struct update_util_data *hook, u64 time, unsigned int flags)",
            "{",
            "\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);",
            "\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;",
            "\tunsigned int next_f;",
            "",
            "\traw_spin_lock(&sg_policy->update_lock);",
            "",
            "\tsugov_iowait_boost(sg_cpu, time, flags);",
            "\tsg_cpu->last_update = time;",
            "",
            "\tignore_dl_rate_limit(sg_cpu);",
            "",
            "\tif (sugov_should_update_freq(sg_policy, time)) {",
            "\t\tnext_f = sugov_next_freq_shared(sg_cpu, time);",
            "",
            "\t\tif (!sugov_update_next_freq(sg_policy, time, next_f))",
            "\t\t\tgoto unlock;",
            "",
            "\t\tif (sg_policy->policy->fast_switch_enabled)",
            "\t\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);",
            "\t\telse",
            "\t\t\tsugov_deferred_update(sg_policy);",
            "\t}",
            "unlock:",
            "\traw_spin_unlock(&sg_policy->update_lock);",
            "}",
            "static void sugov_work(struct kthread_work *work)",
            "{",
            "\tstruct sugov_policy *sg_policy = container_of(work, struct sugov_policy, work);",
            "\tunsigned int freq;",
            "\tunsigned long flags;",
            "",
            "\t/*",
            "\t * Hold sg_policy->update_lock shortly to handle the case where:",
            "\t * in case sg_policy->next_freq is read here, and then updated by",
            "\t * sugov_deferred_update() just before work_in_progress is set to false",
            "\t * here, we may miss queueing the new update.",
            "\t *",
            "\t * Note: If a work was queued after the update_lock is released,",
            "\t * sugov_work() will just be called again by kthread_work code; and the",
            "\t * request will be proceed before the sugov thread sleeps.",
            "\t */",
            "\traw_spin_lock_irqsave(&sg_policy->update_lock, flags);",
            "\tfreq = sg_policy->next_freq;",
            "\tsg_policy->work_in_progress = false;",
            "\traw_spin_unlock_irqrestore(&sg_policy->update_lock, flags);",
            "",
            "\tmutex_lock(&sg_policy->work_lock);",
            "\t__cpufreq_driver_target(sg_policy->policy, freq, CPUFREQ_RELATION_L);",
            "\tmutex_unlock(&sg_policy->work_lock);",
            "}",
            "static void sugov_irq_work(struct irq_work *irq_work)",
            "{",
            "\tstruct sugov_policy *sg_policy;",
            "",
            "\tsg_policy = container_of(irq_work, struct sugov_policy, irq_work);",
            "",
            "\tkthread_queue_work(&sg_policy->worker, &sg_policy->work);",
            "}",
            "static ssize_t rate_limit_us_show(struct gov_attr_set *attr_set, char *buf)",
            "{",
            "\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);",
            "",
            "\treturn sprintf(buf, \"%u\\n\", tunables->rate_limit_us);",
            "}",
            "static ssize_t",
            "rate_limit_us_store(struct gov_attr_set *attr_set, const char *buf, size_t count)",
            "{",
            "\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);",
            "\tstruct sugov_policy *sg_policy;",
            "\tunsigned int rate_limit_us;",
            "",
            "\tif (kstrtouint(buf, 10, &rate_limit_us))",
            "\t\treturn -EINVAL;",
            "",
            "\ttunables->rate_limit_us = rate_limit_us;",
            "",
            "\tlist_for_each_entry(sg_policy, &attr_set->policy_list, tunables_hook)",
            "\t\tsg_policy->freq_update_delay_ns = rate_limit_us * NSEC_PER_USEC;",
            "",
            "\treturn count;",
            "}",
            "static void sugov_tunables_free(struct kobject *kobj)",
            "{",
            "\tstruct gov_attr_set *attr_set = to_gov_attr_set(kobj);",
            "",
            "\tkfree(to_sugov_tunables(attr_set));",
            "}",
            "static void sugov_policy_free(struct sugov_policy *sg_policy)",
            "{",
            "\tkfree(sg_policy);",
            "}",
            "static int sugov_kthread_create(struct sugov_policy *sg_policy)",
            "{",
            "\tstruct task_struct *thread;",
            "\tstruct sched_attr attr = {",
            "\t\t.size\t\t= sizeof(struct sched_attr),",
            "\t\t.sched_policy\t= SCHED_DEADLINE,",
            "\t\t.sched_flags\t= SCHED_FLAG_SUGOV,",
            "\t\t.sched_nice\t= 0,",
            "\t\t.sched_priority\t= 0,",
            "\t\t/*",
            "\t\t * Fake (unused) bandwidth; workaround to \"fix\"",
            "\t\t * priority inheritance.",
            "\t\t */",
            "\t\t.sched_runtime\t=  1000000,",
            "\t\t.sched_deadline = 10000000,",
            "\t\t.sched_period\t= 10000000,",
            "\t};",
            "\tstruct cpufreq_policy *policy = sg_policy->policy;",
            "\tint ret;",
            "",
            "\t/* kthread only required for slow path */",
            "\tif (policy->fast_switch_enabled)",
            "\t\treturn 0;",
            "",
            "\tkthread_init_work(&sg_policy->work, sugov_work);",
            "\tkthread_init_worker(&sg_policy->worker);",
            "\tthread = kthread_create(kthread_worker_fn, &sg_policy->worker,",
            "\t\t\t\t\"sugov:%d\",",
            "\t\t\t\tcpumask_first(policy->related_cpus));",
            "\tif (IS_ERR(thread)) {",
            "\t\tpr_err(\"failed to create sugov thread: %ld\\n\", PTR_ERR(thread));",
            "\t\treturn PTR_ERR(thread);",
            "\t}",
            "",
            "\tret = sched_setattr_nocheck(thread, &attr);",
            "\tif (ret) {",
            "\t\tkthread_stop(thread);",
            "\t\tpr_warn(\"%s: failed to set SCHED_DEADLINE\\n\", __func__);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tsg_policy->thread = thread;",
            "\tkthread_bind_mask(thread, policy->related_cpus);",
            "\tinit_irq_work(&sg_policy->irq_work, sugov_irq_work);",
            "\tmutex_init(&sg_policy->work_lock);",
            "",
            "\twake_up_process(thread);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "sugov_update_shared, sugov_work, sugov_irq_work, rate_limit_us_show, rate_limit_us_store, sugov_tunables_free, sugov_policy_free, sugov_kthread_create",
          "description": "管理频率调节的工作线程和参数配置，sugov_kthread_create创建慢速切换场景的后台线程，rate_limit_us_*/提供速率限制配置接口，sugov_work/sugov_irq_work处理异步频率更新任务。",
          "similarity": 0.528631329536438
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 62,
          "end_line": 168,
          "content": [
            "static bool sugov_should_update_freq(struct sugov_policy *sg_policy, u64 time)",
            "{",
            "\ts64 delta_ns;",
            "",
            "\t/*",
            "\t * Since cpufreq_update_util() is called with rq->lock held for",
            "\t * the @target_cpu, our per-CPU data is fully serialized.",
            "\t *",
            "\t * However, drivers cannot in general deal with cross-CPU",
            "\t * requests, so while get_next_freq() will work, our",
            "\t * sugov_update_commit() call may not for the fast switching platforms.",
            "\t *",
            "\t * Hence stop here for remote requests if they aren't supported",
            "\t * by the hardware, as calculating the frequency is pointless if",
            "\t * we cannot in fact act on it.",
            "\t *",
            "\t * This is needed on the slow switching platforms too to prevent CPUs",
            "\t * going offline from leaving stale IRQ work items behind.",
            "\t */",
            "\tif (!cpufreq_this_cpu_can_update(sg_policy->policy))",
            "\t\treturn false;",
            "",
            "\tif (unlikely(READ_ONCE(sg_policy->limits_changed))) {",
            "\t\tWRITE_ONCE(sg_policy->limits_changed, false);",
            "\t\tsg_policy->need_freq_update = true;",
            "",
            "\t\t/*",
            "\t\t * The above limits_changed update must occur before the reads",
            "\t\t * of policy limits in cpufreq_driver_resolve_freq() or a policy",
            "\t\t * limits update might be missed, so use a memory barrier to",
            "\t\t * ensure it.",
            "\t\t *",
            "\t\t * This pairs with the write memory barrier in sugov_limits().",
            "\t\t */",
            "\t\tsmp_mb();",
            "",
            "\t\treturn true;",
            "\t}",
            "",
            "\tdelta_ns = time - sg_policy->last_freq_update_time;",
            "",
            "\treturn delta_ns >= sg_policy->freq_update_delay_ns;",
            "}",
            "static bool sugov_update_next_freq(struct sugov_policy *sg_policy, u64 time,",
            "\t\t\t\t   unsigned int next_freq)",
            "{",
            "\tif (sg_policy->need_freq_update) {",
            "\t\tsg_policy->need_freq_update = false;",
            "\t\t/*",
            "\t\t * The policy limits have changed, but if the return value of",
            "\t\t * cpufreq_driver_resolve_freq() after applying the new limits",
            "\t\t * is still equal to the previously selected frequency, the",
            "\t\t * driver callback need not be invoked unless the driver",
            "\t\t * specifically wants that to happen on every update of the",
            "\t\t * policy limits.",
            "\t\t */",
            "\t\tif (sg_policy->next_freq == next_freq &&",
            "\t\t    !cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS))",
            "\t\t\treturn false;",
            "\t} else if (sg_policy->next_freq == next_freq) {",
            "\t\treturn false;",
            "\t}",
            "",
            "\tsg_policy->next_freq = next_freq;",
            "\tsg_policy->last_freq_update_time = time;",
            "",
            "\treturn true;",
            "}",
            "static void sugov_deferred_update(struct sugov_policy *sg_policy)",
            "{",
            "\tif (!sg_policy->work_in_progress) {",
            "\t\tsg_policy->work_in_progress = true;",
            "\t\tirq_work_queue(&sg_policy->irq_work);",
            "\t}",
            "}",
            "static __always_inline",
            "unsigned long get_capacity_ref_freq(struct cpufreq_policy *policy)",
            "{",
            "\tunsigned int freq = arch_scale_freq_ref(policy->cpu);",
            "",
            "\tif (freq)",
            "\t\treturn freq;",
            "",
            "\tif (arch_scale_freq_invariant())",
            "\t\treturn policy->cpuinfo.max_freq;",
            "",
            "\t/*",
            "\t * Apply a 25% margin so that we select a higher frequency than",
            "\t * the current one before the CPU is fully busy:",
            "\t */",
            "\treturn policy->cur + (policy->cur >> 2);",
            "}",
            "static unsigned int get_next_freq(struct sugov_policy *sg_policy,",
            "\t\t\t\t  unsigned long util, unsigned long max)",
            "{",
            "\tstruct cpufreq_policy *policy = sg_policy->policy;",
            "\tunsigned int freq;",
            "",
            "\tfreq = get_capacity_ref_freq(policy);",
            "\tfreq = map_util_freq(util, freq, max);",
            "",
            "\tif (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)",
            "\t\treturn sg_policy->next_freq;",
            "",
            "\tsg_policy->cached_raw_freq = freq;",
            "\treturn cpufreq_driver_resolve_freq(policy, freq);",
            "}"
          ],
          "function_name": "sugov_should_update_freq, sugov_update_next_freq, sugov_deferred_update, get_capacity_ref_freq, get_next_freq",
          "description": "实现了频率更新核心逻辑，sugov_should_update_freq判断是否需要更新频率，sugov_update_next_freq计算并记录目标频率，sugov_deferred_update触发异步更新，get_capacity_ref_freq获取基准频率，get_next_freq结合利用率计算最终目标频率。",
          "similarity": 0.48368752002716064
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 1,
          "end_line": 61,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * CPUFreq governor based on scheduler-provided CPU utilization data.",
            " *",
            " * Copyright (C) 2016, Intel Corporation",
            " * Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>",
            " */",
            "",
            "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)",
            "",
            "struct sugov_tunables {",
            "\tstruct gov_attr_set\tattr_set;",
            "\tunsigned int\t\trate_limit_us;",
            "};",
            "",
            "struct sugov_policy {",
            "\tstruct cpufreq_policy\t*policy;",
            "",
            "\tstruct sugov_tunables\t*tunables;",
            "\tstruct list_head\ttunables_hook;",
            "",
            "\traw_spinlock_t\t\tupdate_lock;",
            "\tu64\t\t\tlast_freq_update_time;",
            "\ts64\t\t\tfreq_update_delay_ns;",
            "\tunsigned int\t\tnext_freq;",
            "\tunsigned int\t\tcached_raw_freq;",
            "",
            "\t/* The next fields are only needed if fast switch cannot be used: */",
            "\tstruct\t\t\tirq_work irq_work;",
            "\tstruct\t\t\tkthread_work work;",
            "\tstruct\t\t\tmutex work_lock;",
            "\tstruct\t\t\tkthread_worker worker;",
            "\tstruct task_struct\t*thread;",
            "\tbool\t\t\twork_in_progress;",
            "",
            "\tbool\t\t\tlimits_changed;",
            "\tbool\t\t\tneed_freq_update;",
            "};",
            "",
            "struct sugov_cpu {",
            "\tstruct update_util_data\tupdate_util;",
            "\tstruct sugov_policy\t*sg_policy;",
            "\tunsigned int\t\tcpu;",
            "",
            "\tbool\t\t\tiowait_boost_pending;",
            "\tunsigned int\t\tiowait_boost;",
            "\tu64\t\t\tlast_update;",
            "",
            "\tunsigned long\t\tutil;",
            "\tunsigned long\t\tbw_min;",
            "",
            "\t/* The field below is for single-CPU policies only: */",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "\tunsigned long\t\tsaved_idle_calls;",
            "#endif",
            "};",
            "",
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);",
            "",
            "/************************ Governor internals ***********************/",
            ""
          ],
          "function_name": null,
          "description": "定义了CPU频率调节器所需的结构体和宏，包括sugov_tunables保存策略参数，sugov_policy管理策略状态，sugov_cpu保存每个CPU的运行数据，以及相关锁和标志位，用于协调多核间的频率调整操作。",
          "similarity": 0.471759170293808
        }
      ]
    },
    {
      "source_file": "kernel/time/itimer.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:39:13\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `time\\itimer.c`\n\n---\n\n# `time/itimer.c` 技术文档\n\n## 1. 文件概述\n\n`time/itimer.c` 是 Linux 内核中实现 POSIX 间隔定时器（interval timers，简称 itimers）的核心文件。该文件提供了对三种经典 Unix 间隔定时器的支持：\n\n- **ITIMER_REAL**：基于真实时间（墙上时钟）的定时器，到期时发送 `SIGALRM` 信号\n- **ITIMER_VIRTUAL**：基于进程用户态 CPU 时间的定时器，到期时发送 `SIGVTALRM` 信号\n- **ITIMER_PROF**：基于进程总 CPU 时间（用户态+内核态）的定时器，到期时发送 `SIGPROF` 信号\n\n该文件实现了 `getitimer()`、`setitimer()` 系统调用以及 `alarm()` 系统调用（在架构支持的情况下），为用户空间程序提供间隔定时器功能。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`itimer_get_remtime()`**：获取高精度实时定时器的剩余时间\n- **`get_cpu_itimer()`**：获取 CPU 时间相关的定时器（虚拟/性能）状态\n- **`do_getitimer()`**：内部实现获取指定类型定时器状态的逻辑\n- **`put_itimerval()`**：将内核内部的 `itimerspec64` 格式转换为用户空间的 `old_itimerval` 格式\n- **`getitimer()` 系统调用**：用户空间获取定时器状态的入口\n- **`it_real_fn()`**：ITIMER_REAL 定时器到期时的回调函数\n- **`set_cpu_itimer()`**：设置 CPU 时间相关的定时器\n- **`do_setitimer()`**：内部实现设置指定类型定时器的逻辑\n- **`clear_itimer()`**：在 SELinux 环境下清除所有定时器（安全相关）\n- **`alarm_setitimer()`**：实现 `alarm()` 系统调用的内部函数\n- **`alarm()` 系统调用**：设置单次实时定时器的简化接口\n\n### 数据结构\n\n- **`struct cpu_itimer`**：存储 CPU 时间定时器的状态（在 `signal_struct` 中）\n- **`struct hrtimer`**：高精度定时器，用于实现 ITIMER_REAL\n- **`struct itimerspec64`**：64 位时间规格结构，内核内部使用\n- **`struct __kernel_old_itimerval`**：用户空间兼容的定时器值结构\n\n## 3. 关键实现\n\n### 定时器类型实现差异\n\n- **ITIMER_REAL**：使用高精度定时器（`hrtimer`）实现，基于真实时间，通过 `hrtimer_start()` 启动，到期时调用 `it_real_fn()` 发送 `SIGALRM` 信号\n- **ITIMER_VIRTUAL/ITIMER_PROF**：基于 CPU 时间采样实现，通过 `thread_group_sample_cputime()` 获取当前进程组的 CPU 时间，与设定的过期时间比较来判断是否到期\n\n### 时间精度处理\n\n- 使用纳秒级精度的 `ktime_t` 和 `timespec64` 进行内部计算\n- 用户空间接口使用微秒精度（`tv_usec`），通过 `NSEC_PER_USEC` 进行单位转换\n- 对于即将到期的定时器，返回 `TICK_NSEC`（1 微秒）作为剩余时间，避免返回 0 导致用户误判\n\n### 并发安全\n\n- 使用 `siglock` 自旋锁保护信号结构体中的定时器状态\n- ITIMER_REAL 的设置操作需要处理定时器可能正在执行的竞态条件，通过 `hrtimer_try_to_cancel()` 和重试机制确保安全\n- CPU 定时器操作在 `siglock` 保护下进行，确保线程组内的一致性\n\n### 兼容性支持\n\n- 提供 32 位兼容接口（`COMPAT_SYSCALL_DEFINE2`）\n- 支持 `alarm()` 系统调用（在 `__ARCH_WANT_SYS_ALARM` 定义时）\n- 处理 32 位系统上的时间值溢出问题（限制为 `INT_MAX`）\n\n## 4. 依赖关系\n\n### 头文件依赖\n\n- **`<linux/hrtimer.h>`**：高精度定时器框架，用于 ITIMER_REAL 实现\n- **`<linux/sched/cputime.h>`**：CPU 时间采样功能，用于虚拟和性能定时器\n- **`<linux/posix-timers.h>`**：POSIX 定时器相关定义\n- **`<linux/sched/signal.h>`**：信号处理和 `signal_struct` 结构定义\n- **`<linux/time.h>`**：时间转换和操作函数\n- **`<trace/events/timer.h>`**：定时器事件跟踪支持\n\n### 内核子系统依赖\n\n- **调度子系统**：通过 `current` 获取当前任务，使用 `thread_group_sample_cputime()` 采样 CPU 时间\n- **信号子系统**：通过 `kill_pid_info()` 发送信号，使用 `siglock` 进行同步\n- **高精度定时器子系统**：ITIMER_REAL 的底层实现依赖 hrtimer 框架\n- **安全子系统**：SELinux 相关的 `clear_itimer()` 函数\n\n## 5. 使用场景\n\n### 用户空间编程\n\n- **定时任务**：应用程序使用 `setitimer()` 设置周期性或一次性定时器\n- **超时控制**：网络编程中设置 I/O 操作超时\n- **性能监控**：使用 ITIMER_PROF 监控程序 CPU 使用情况\n- **简单定时**：使用 `alarm()` 系统调用设置简单的秒级定时器\n\n### 内核内部使用\n\n- **进程管理**：在进程退出或权限变更时清除定时器（SELinux 场景）\n- **信号处理**：定时器到期时向进程发送相应信号\n- **时间跟踪**：通过 tracepoint 记录定时器状态变化和到期事件\n- **兼容层**：为不同架构和位数提供统一的定时器接口\n\n### 系统调用路径\n\n- **`getitimer()`** → `do_getitimer()` → 对应定时器类型的具体获取函数\n- **`setitimer()`** → `do_setitimer()` → 对应定时器类型的具体设置函数  \n- **`alarm()`** → `alarm_setitimer()` → `do_setitimer(ITIMER_REAL, ...)`\n\n该文件是 Linux 内核 POSIX 定时器功能的重要组成部分，为用户空间提供了经典的 Unix 间隔定时器接口。",
      "similarity": 0.5334424376487732,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/time/itimer.c",
          "start_line": 29,
          "end_line": 129,
          "content": [
            "static struct timespec64 itimer_get_remtime(struct hrtimer *timer)",
            "{",
            "\tktime_t rem = __hrtimer_get_remaining(timer, true);",
            "",
            "\t/*",
            "\t * Racy but safe: if the itimer expires after the above",
            "\t * hrtimer_get_remtime() call but before this condition",
            "\t * then we return 0 - which is correct.",
            "\t */",
            "\tif (hrtimer_active(timer)) {",
            "\t\tif (rem <= 0)",
            "\t\t\trem = NSEC_PER_USEC;",
            "\t} else",
            "\t\trem = 0;",
            "",
            "\treturn ktime_to_timespec64(rem);",
            "}",
            "static void get_cpu_itimer(struct task_struct *tsk, unsigned int clock_id,",
            "\t\t\t   struct itimerspec64 *const value)",
            "{",
            "\tu64 val, interval;",
            "\tstruct cpu_itimer *it = &tsk->signal->it[clock_id];",
            "",
            "\tspin_lock_irq(&tsk->sighand->siglock);",
            "",
            "\tval = it->expires;",
            "\tinterval = it->incr;",
            "\tif (val) {",
            "\t\tu64 t, samples[CPUCLOCK_MAX];",
            "",
            "\t\tthread_group_sample_cputime(tsk, samples);",
            "\t\tt = samples[clock_id];",
            "",
            "\t\tif (val < t)",
            "\t\t\t/* about to fire */",
            "\t\t\tval = TICK_NSEC;",
            "\t\telse",
            "\t\t\tval -= t;",
            "\t}",
            "",
            "\tspin_unlock_irq(&tsk->sighand->siglock);",
            "",
            "\tvalue->it_value = ns_to_timespec64(val);",
            "\tvalue->it_interval = ns_to_timespec64(interval);",
            "}",
            "static int do_getitimer(int which, struct itimerspec64 *value)",
            "{",
            "\tstruct task_struct *tsk = current;",
            "",
            "\tswitch (which) {",
            "\tcase ITIMER_REAL:",
            "\t\tspin_lock_irq(&tsk->sighand->siglock);",
            "\t\tvalue->it_value = itimer_get_remtime(&tsk->signal->real_timer);",
            "\t\tvalue->it_interval =",
            "\t\t\tktime_to_timespec64(tsk->signal->it_real_incr);",
            "\t\tspin_unlock_irq(&tsk->sighand->siglock);",
            "\t\tbreak;",
            "\tcase ITIMER_VIRTUAL:",
            "\t\tget_cpu_itimer(tsk, CPUCLOCK_VIRT, value);",
            "\t\tbreak;",
            "\tcase ITIMER_PROF:",
            "\t\tget_cpu_itimer(tsk, CPUCLOCK_PROF, value);",
            "\t\tbreak;",
            "\tdefault:",
            "\t\treturn(-EINVAL);",
            "\t}",
            "\treturn 0;",
            "}",
            "static int put_itimerval(struct __kernel_old_itimerval __user *o,",
            "\t\t\t const struct itimerspec64 *i)",
            "{",
            "\tstruct __kernel_old_itimerval v;",
            "",
            "\tv.it_interval.tv_sec = i->it_interval.tv_sec;",
            "\tv.it_interval.tv_usec = i->it_interval.tv_nsec / NSEC_PER_USEC;",
            "\tv.it_value.tv_sec = i->it_value.tv_sec;",
            "\tv.it_value.tv_usec = i->it_value.tv_nsec / NSEC_PER_USEC;",
            "\treturn copy_to_user(o, &v, sizeof(struct __kernel_old_itimerval)) ? -EFAULT : 0;",
            "}",
            "static int put_old_itimerval32(struct old_itimerval32 __user *o,",
            "\t\t\t       const struct itimerspec64 *i)",
            "{",
            "\tstruct old_itimerval32 v32;",
            "",
            "\tv32.it_interval.tv_sec = i->it_interval.tv_sec;",
            "\tv32.it_interval.tv_usec = i->it_interval.tv_nsec / NSEC_PER_USEC;",
            "\tv32.it_value.tv_sec = i->it_value.tv_sec;",
            "\tv32.it_value.tv_usec = i->it_value.tv_nsec / NSEC_PER_USEC;",
            "\treturn copy_to_user(o, &v32, sizeof(struct old_itimerval32)) ? -EFAULT : 0;",
            "}",
            "enum hrtimer_restart it_real_fn(struct hrtimer *timer)",
            "{",
            "\tstruct signal_struct *sig =",
            "\t\tcontainer_of(timer, struct signal_struct, real_timer);",
            "\tstruct pid *leader_pid = sig->pids[PIDTYPE_TGID];",
            "",
            "\ttrace_itimer_expire(ITIMER_REAL, leader_pid, 0);",
            "\tkill_pid_info(SIGALRM, SEND_SIG_PRIV, leader_pid);",
            "",
            "\treturn HRTIMER_NORESTART;",
            "}"
          ],
          "function_name": "itimer_get_remtime, get_cpu_itimer, do_getitimer, put_itimerval, put_old_itimerval32, it_real_fn",
          "description": "实现了itimer_get_remtime获取剩余时间、get_cpu_itimer读取CPU定时器信息、do_getitimer根据时钟类型获取定时器状态、put_itimerval/put_old_itimerval32转换并复制时间值到用户空间，以及it_real_fn作为实时时钟的超时处理函数",
          "similarity": 0.5258098840713501
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/time/itimer.c",
          "start_line": 313,
          "end_line": 348,
          "content": [
            "static int get_itimerval(struct itimerspec64 *o, const struct __kernel_old_itimerval __user *i)",
            "{",
            "\tstruct __kernel_old_itimerval v;",
            "",
            "\tif (copy_from_user(&v, i, sizeof(struct __kernel_old_itimerval)))",
            "\t\treturn -EFAULT;",
            "",
            "\t/* Validate the timevals in value. */",
            "\tif (!timeval_valid(&v.it_value) ||",
            "\t    !timeval_valid(&v.it_interval))",
            "\t\treturn -EINVAL;",
            "",
            "\to->it_interval.tv_sec = v.it_interval.tv_sec;",
            "\to->it_interval.tv_nsec = v.it_interval.tv_usec * NSEC_PER_USEC;",
            "\to->it_value.tv_sec = v.it_value.tv_sec;",
            "\to->it_value.tv_nsec = v.it_value.tv_usec * NSEC_PER_USEC;",
            "\treturn 0;",
            "}",
            "static int get_old_itimerval32(struct itimerspec64 *o, const struct old_itimerval32 __user *i)",
            "{",
            "\tstruct old_itimerval32 v32;",
            "",
            "\tif (copy_from_user(&v32, i, sizeof(struct old_itimerval32)))",
            "\t\treturn -EFAULT;",
            "",
            "\t/* Validate the timevals in value.  */",
            "\tif (!timeval_valid(&v32.it_value) ||",
            "\t    !timeval_valid(&v32.it_interval))",
            "\t\treturn -EINVAL;",
            "",
            "\to->it_interval.tv_sec = v32.it_interval.tv_sec;",
            "\to->it_interval.tv_nsec = v32.it_interval.tv_usec * NSEC_PER_USEC;",
            "\to->it_value.tv_sec = v32.it_value.tv_sec;",
            "\to->it_value.tv_nsec = v32.it_value.tv_usec * NSEC_PER_USEC;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "get_itimerval, get_old_itimerval32",
          "description": "实现get_itimerval/get_old_itimerval32将用户态时间值转换为内核时间结构体，执行有效性校验，确保输入时间值在合法范围内",
          "similarity": 0.5200729966163635
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/time/itimer.c",
          "start_line": 168,
          "end_line": 275,
          "content": [
            "static void set_cpu_itimer(struct task_struct *tsk, unsigned int clock_id,",
            "\t\t\t   const struct itimerspec64 *const value,",
            "\t\t\t   struct itimerspec64 *const ovalue)",
            "{",
            "\tu64 oval, nval, ointerval, ninterval;",
            "\tstruct cpu_itimer *it = &tsk->signal->it[clock_id];",
            "",
            "\tnval = timespec64_to_ns(&value->it_value);",
            "\tninterval = timespec64_to_ns(&value->it_interval);",
            "",
            "\tspin_lock_irq(&tsk->sighand->siglock);",
            "",
            "\toval = it->expires;",
            "\tointerval = it->incr;",
            "\tif (oval || nval) {",
            "\t\tif (nval > 0)",
            "\t\t\tnval += TICK_NSEC;",
            "\t\tset_process_cpu_timer(tsk, clock_id, &nval, &oval);",
            "\t}",
            "\tit->expires = nval;",
            "\tit->incr = ninterval;",
            "\ttrace_itimer_state(clock_id == CPUCLOCK_VIRT ?",
            "\t\t\t   ITIMER_VIRTUAL : ITIMER_PROF, value, nval);",
            "",
            "\tspin_unlock_irq(&tsk->sighand->siglock);",
            "",
            "\tif (ovalue) {",
            "\t\tovalue->it_value = ns_to_timespec64(oval);",
            "\t\tovalue->it_interval = ns_to_timespec64(ointerval);",
            "\t}",
            "}",
            "static int do_setitimer(int which, struct itimerspec64 *value,",
            "\t\t\tstruct itimerspec64 *ovalue)",
            "{",
            "\tstruct task_struct *tsk = current;",
            "\tstruct hrtimer *timer;",
            "\tktime_t expires;",
            "",
            "\tswitch (which) {",
            "\tcase ITIMER_REAL:",
            "again:",
            "\t\tspin_lock_irq(&tsk->sighand->siglock);",
            "\t\ttimer = &tsk->signal->real_timer;",
            "\t\tif (ovalue) {",
            "\t\t\tovalue->it_value = itimer_get_remtime(timer);",
            "\t\t\tovalue->it_interval",
            "\t\t\t\t= ktime_to_timespec64(tsk->signal->it_real_incr);",
            "\t\t}",
            "\t\t/* We are sharing ->siglock with it_real_fn() */",
            "\t\tif (hrtimer_try_to_cancel(timer) < 0) {",
            "\t\t\tspin_unlock_irq(&tsk->sighand->siglock);",
            "\t\t\thrtimer_cancel_wait_running(timer);",
            "\t\t\tgoto again;",
            "\t\t}",
            "\t\texpires = timespec64_to_ktime(value->it_value);",
            "\t\tif (expires != 0) {",
            "\t\t\ttsk->signal->it_real_incr =",
            "\t\t\t\ttimespec64_to_ktime(value->it_interval);",
            "\t\t\thrtimer_start(timer, expires, HRTIMER_MODE_REL);",
            "\t\t} else",
            "\t\t\ttsk->signal->it_real_incr = 0;",
            "",
            "\t\ttrace_itimer_state(ITIMER_REAL, value, 0);",
            "\t\tspin_unlock_irq(&tsk->sighand->siglock);",
            "\t\tbreak;",
            "\tcase ITIMER_VIRTUAL:",
            "\t\tset_cpu_itimer(tsk, CPUCLOCK_VIRT, value, ovalue);",
            "\t\tbreak;",
            "\tcase ITIMER_PROF:",
            "\t\tset_cpu_itimer(tsk, CPUCLOCK_PROF, value, ovalue);",
            "\t\tbreak;",
            "\tdefault:",
            "\t\treturn -EINVAL;",
            "\t}",
            "\treturn 0;",
            "}",
            "void clear_itimer(void)",
            "{",
            "\tstruct itimerspec64 v = {};",
            "\tint i;",
            "",
            "\tfor (i = 0; i < 3; i++)",
            "\t\tdo_setitimer(i, &v, NULL);",
            "}",
            "static unsigned int alarm_setitimer(unsigned int seconds)",
            "{",
            "\tstruct itimerspec64 it_new, it_old;",
            "",
            "#if BITS_PER_LONG < 64",
            "\tif (seconds > INT_MAX)",
            "\t\tseconds = INT_MAX;",
            "#endif",
            "\tit_new.it_value.tv_sec = seconds;",
            "\tit_new.it_value.tv_nsec = 0;",
            "\tit_new.it_interval.tv_sec = it_new.it_interval.tv_nsec = 0;",
            "",
            "\tdo_setitimer(ITIMER_REAL, &it_new, &it_old);",
            "",
            "\t/*",
            "\t * We can't return 0 if we have an alarm pending ...  And we'd",
            "\t * better return too much than too little anyway",
            "\t */",
            "\tif ((!it_old.it_value.tv_sec && it_old.it_value.tv_nsec) ||",
            "\t      it_old.it_value.tv_nsec >= (NSEC_PER_SEC / 2))",
            "\t\tit_old.it_value.tv_sec++;",
            "",
            "\treturn it_old.it_value.tv_sec;",
            "}"
          ],
          "function_name": "set_cpu_itimer, do_setitimer, clear_itimer, alarm_setitimer",
          "description": "包含set_cpu_itimer设置CPU定时器参数、do_setitimer根据时钟类型配置定时器、clear_itimer清除所有定时器、alarm_setitimer设置一次性闹钟，其中do_setitimer处理实时时钟的启动和取消操作",
          "similarity": 0.5134617686271667
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/time/itimer.c",
          "start_line": 1,
          "end_line": 28,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 1992 Darren Senn",
            " */",
            "",
            "/* These are all the functions necessary to implement itimers */",
            "",
            "#include <linux/mm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/time.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/hrtimer.h>",
            "#include <trace/events/timer.h>",
            "#include <linux/compat.h>",
            "",
            "#include <linux/uaccess.h>",
            "",
            "/**",
            " * itimer_get_remtime - get remaining time for the timer",
            " *",
            " * @timer: the timer to read",
            " *",
            " * Returns the delta between the expiry time and now, which can be",
            " * less than zero or 1usec for an pending expired timer",
            " */"
          ],
          "function_name": null,
          "description": "该代码块定义了itimer_get_remtime函数的原型，用于获取高精度定时器的剩余时间，通过计算当前时间与定时器到期时间的差值得到剩余时间，但未提供完整实现，上下文不完整",
          "similarity": 0.5042603611946106
        }
      ]
    },
    {
      "source_file": "kernel/sched/clock.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:58:20\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\clock.c`\n\n---\n\n# `sched/clock.c` 技术文档\n\n## 1. 文件概述\n\n`sched/clock.c` 实现了 Linux 内核中用于调度器的高分辨率时间戳机制 `sched_clock()`，特别针对 **不稳定 CPU 时钟源**（如 TSC 在某些硬件上不可靠）的场景。该文件提供了一个在单 CPU 上单调递增、高精度（纳秒级）、可在任意上下文（包括 NMI）中调用的时间源，并通过混合全局时间（GTOD）与本地时钟（如 TSC）来在多核系统中尽量减少时钟漂移。\n\n**重要警告**：不同 CPU 上的 `cpu_clock(i)` 与 `cpu_clock(j)`（i ≠ j）之间 **不保证全局单调性**，时间可能“倒退”。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数 | 说明 |\n|------|------|\n| `sched_clock()` | 弱符号默认实现，基于 jiffies 提供低精度时间戳；架构可覆盖 |\n| `local_clock()` | 宏定义，等价于当前 CPU 的 `cpu_clock(smp_processor_id())` |\n| `cpu_clock(int cpu)` | 返回指定 CPU 的高分辨率时间戳（纳秒） |\n| `sched_clock_stable()` | 判断当前系统是否已进入“稳定时钟”模式（TSC 可靠） |\n| `clear_sched_clock_stable()` | 标记时钟为不稳定（如检测到 TSC 异常），触发修复流程 |\n| `sched_clock_init()` / `sched_clock_init_late()` | 初始化时钟子系统，分早期和晚期阶段 |\n\n### 关键数据结构\n\n```c\nstruct sched_clock_data {\n    u64 tick_raw;   // 上次更新时的原始 sched_clock() 值（如 TSC）\n    u64 tick_gtod;  // 上次更新时的全局时间（ktime_get_ns()）\n    u64 clock;      // 当前推算出的本地高精度单调时间\n};\n```\n\n- 每个 CPU 拥有一个 `sched_clock_data` 实例（`per_cpu` 变量）\n- 全局偏移量：\n  - `__sched_clock_offset`：原始时钟到稳定时间的偏移\n  - `__gtod_offset`：GTOD 到稳定时间的偏移\n\n### 静态键（Static Keys）\n\n- `sched_clock_running`：标记时钟子系统是否已初始化\n- `__sched_clock_stable`：标记时钟源是否稳定（TSC 可靠）\n- `__sched_clock_stable_early`：启动早期假设时钟稳定，避免多次切换\n\n## 3. 关键实现\n\n### 3.1 两种模式\n\n- **稳定模式**（`CONFIG_HAVE_UNSTABLE_SCHED_CLOCK` 未定义）：  \n  直接使用架构提供的 `sched_clock()`，假定其全局同步且高精度（如 ARM64 的 arch counter）。\n\n- **不稳定模式**（`CONFIG_HAVE_UNSTABLE_SCHED_CLOCK` 定义）：  \n  混合 GTOD（`ktime_get_ns()`）与原始 `sched_clock()`（如 TSC）：\n  - 以 GTOD 为基准，利用 `sched_clock()` 的高分辨率 delta 提升精度\n  - 通过 `__sched_clock_offset` 和 `__gtod_offset` 对齐两个时钟源\n\n### 3.2 时钟对齐与漂移控制\n\n- 初始化时通过 `__sched_clock_gtod_offset()` 计算初始偏移量，确保切换时连续\n- `sched_clock_local()` 函数实现核心逻辑：\n  - 计算自上次更新以来的原始时钟增量（`delta = now - tick_raw`）\n  - 将 GTOD 基准时间（`tick_gtod + __gtod_offset`）加上 `delta` 得到新时间\n  - 使用 `wrap_min`/`wrap_max` 处理 64 位回绕，并限制时间跳跃范围（防止 TSC 异常）\n\n### 3.3 稳定性动态切换\n\n- **启动时假设稳定**：`__sched_clock_stable_early = 1`\n- **晚期初始化**（`late_initcall`）：\n  - 若仍认为稳定，则调用 `__set_sched_clock_stable()` 完成对齐并启用稳定模式\n  - 若驱动（如 ACPI/Intel Idle）标记 TSC 不稳定，则调用 `clear_sched_clock_stable()`\n- **不稳定处理**：\n  - 调度工作队列 `sched_clock_work`\n  - 重新以 GTOD 为基准重置所有 CPU 的 `sched_clock_data`\n\n### 3.4 中断与抢占安全\n\n- 关键操作（如 stamp、offset 计算）使用 `local_irq_disable()` 保证原子性\n- `notrace` 属性避免被 ftrace 拦截，确保在 NMI 等上下文中可用\n\n## 4. 依赖关系\n\n- **时间子系统**：\n  - 依赖 `ktime_get_ns()`（GTOD，来自 `kernel/time/`）\n  - 依赖 `jiffies` 和 `HZ`（用于默认 `sched_clock` 实现）\n- **调度器**：为 `kernel/sched/` 提供高精度时间戳（如 `rq->clock` 更新）\n- **时钟事件/源**：与 `tick` 子系统交互（`TICK_DEP_BIT_CLOCK_UNSTABLE`）\n- **架构支持**：\n  - 若架构定义 `CONFIG_HAVE_UNSTABLE_SCHED_CLOCK`，则启用混合模式\n  - 架构可提供自己的 `sched_clock()` 实现（如 x86 使用 TSC）\n\n## 5. 使用场景\n\n- **调度器时间统计**：计算任务运行时间、就绪队列时钟等\n- **延迟跟踪**：`ftrace`、`perf` 等性能工具依赖 `local_clock()` 获取精确时间戳\n- **锁竞争分析**：`lockdep` 使用 `sched_clock()` 记录锁持有时间\n- **RCU、中断处理**：需要高精度、低开销时间戳的内核子系统\n- **虚拟化与电源管理**：在 CPU 进入/退出 idle 时校正时钟（通过 `sched_clock_idle_*` 钩子，虽未在本文件实现但相关）",
      "similarity": 0.5250300765037537,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/clock.c",
          "start_line": 62,
          "end_line": 177,
          "content": [
            "notrace unsigned long long __weak sched_clock(void)",
            "{",
            "\treturn (unsigned long long)(jiffies - INITIAL_JIFFIES)",
            "\t\t\t\t\t* (NSEC_PER_SEC / HZ);",
            "}",
            "notrace int sched_clock_stable(void)",
            "{",
            "\treturn static_branch_likely(&__sched_clock_stable);",
            "}",
            "notrace static void __scd_stamp(struct sched_clock_data *scd)",
            "{",
            "\tscd->tick_gtod = ktime_get_ns();",
            "\tscd->tick_raw = sched_clock();",
            "}",
            "notrace static void __set_sched_clock_stable(void)",
            "{",
            "\tstruct sched_clock_data *scd;",
            "",
            "\t/*",
            "\t * Since we're still unstable and the tick is already running, we have",
            "\t * to disable IRQs in order to get a consistent scd->tick* reading.",
            "\t */",
            "\tlocal_irq_disable();",
            "\tscd = this_scd();",
            "\t/*",
            "\t * Attempt to make the (initial) unstable->stable transition continuous.",
            "\t */",
            "\t__sched_clock_offset = (scd->tick_gtod + __gtod_offset) - (scd->tick_raw);",
            "\tlocal_irq_enable();",
            "",
            "\tprintk(KERN_INFO \"sched_clock: Marking stable (%lld, %lld)->(%lld, %lld)\\n\",",
            "\t\t\tscd->tick_gtod, __gtod_offset,",
            "\t\t\tscd->tick_raw,  __sched_clock_offset);",
            "",
            "\tstatic_branch_enable(&__sched_clock_stable);",
            "\ttick_dep_clear(TICK_DEP_BIT_CLOCK_UNSTABLE);",
            "}",
            "notrace static void __sched_clock_work(struct work_struct *work)",
            "{",
            "\tstruct sched_clock_data *scd;",
            "\tint cpu;",
            "",
            "\t/* take a current timestamp and set 'now' */",
            "\tpreempt_disable();",
            "\tscd = this_scd();",
            "\t__scd_stamp(scd);",
            "\tscd->clock = scd->tick_gtod + __gtod_offset;",
            "\tpreempt_enable();",
            "",
            "\t/* clone to all CPUs */",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tper_cpu(sched_clock_data, cpu) = *scd;",
            "",
            "\tprintk(KERN_WARNING \"TSC found unstable after boot, most likely due to broken BIOS. Use 'tsc=unstable'.\\n\");",
            "\tprintk(KERN_INFO \"sched_clock: Marking unstable (%lld, %lld)<-(%lld, %lld)\\n\",",
            "\t\t\tscd->tick_gtod, __gtod_offset,",
            "\t\t\tscd->tick_raw,  __sched_clock_offset);",
            "",
            "\tstatic_branch_disable(&__sched_clock_stable);",
            "}",
            "notrace static void __clear_sched_clock_stable(void)",
            "{",
            "\tif (!sched_clock_stable())",
            "\t\treturn;",
            "",
            "\ttick_dep_set(TICK_DEP_BIT_CLOCK_UNSTABLE);",
            "\tschedule_work(&sched_clock_work);",
            "}",
            "notrace void clear_sched_clock_stable(void)",
            "{",
            "\t__sched_clock_stable_early = 0;",
            "",
            "\tsmp_mb(); /* matches sched_clock_init_late() */",
            "",
            "\tif (static_key_count(&sched_clock_running.key) == 2)",
            "\t\t__clear_sched_clock_stable();",
            "}",
            "notrace static void __sched_clock_gtod_offset(void)",
            "{",
            "\tstruct sched_clock_data *scd = this_scd();",
            "",
            "\t__scd_stamp(scd);",
            "\t__gtod_offset = (scd->tick_raw + __sched_clock_offset) - scd->tick_gtod;",
            "}",
            "void __init sched_clock_init(void)",
            "{",
            "\t/*",
            "\t * Set __gtod_offset such that once we mark sched_clock_running,",
            "\t * sched_clock_tick() continues where sched_clock() left off.",
            "\t *",
            "\t * Even if TSC is buggered, we're still UP at this point so it",
            "\t * can't really be out of sync.",
            "\t */",
            "\tlocal_irq_disable();",
            "\t__sched_clock_gtod_offset();",
            "\tlocal_irq_enable();",
            "",
            "\tstatic_branch_inc(&sched_clock_running);",
            "}",
            "static int __init sched_clock_init_late(void)",
            "{",
            "\tstatic_branch_inc(&sched_clock_running);",
            "\t/*",
            "\t * Ensure that it is impossible to not do a static_key update.",
            "\t *",
            "\t * Either {set,clear}_sched_clock_stable() must see sched_clock_running",
            "\t * and do the update, or we must see their __sched_clock_stable_early",
            "\t * and do the update, or both.",
            "\t */",
            "\tsmp_mb(); /* matches {set,clear}_sched_clock_stable() */",
            "",
            "\tif (__sched_clock_stable_early)",
            "\t\t__set_sched_clock_stable();",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "sched_clock, sched_clock_stable, __scd_stamp, __set_sched_clock_stable, __sched_clock_work, __clear_sched_clock_stable, clear_sched_clock_stable, __sched_clock_gtod_offset, sched_clock_init, sched_clock_init_late",
          "description": "实现调度器时钟状态管理，包含sched_clock函数默认实现、稳定性检测、时钟数据同步逻辑(__set_sched_clock_stable/__clear_sched_clock_stable)、初始化流程(sched_clock_init/sched_clock_init_late)及工作队列处理(__sched_clock_work)，用于动态调整时钟偏移与稳定性标志。",
          "similarity": 0.5738791227340698
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/sched/clock.c",
          "start_line": 388,
          "end_line": 477,
          "content": [
            "notrace u64 sched_clock_cpu(int cpu)",
            "{",
            "\tstruct sched_clock_data *scd;",
            "\tu64 clock;",
            "",
            "\tif (sched_clock_stable())",
            "\t\treturn sched_clock() + __sched_clock_offset;",
            "",
            "\tif (!static_branch_likely(&sched_clock_running))",
            "\t\treturn sched_clock();",
            "",
            "\tpreempt_disable_notrace();",
            "\tscd = cpu_sdc(cpu);",
            "",
            "\tif (cpu != smp_processor_id())",
            "\t\tclock = sched_clock_remote(scd);",
            "\telse",
            "\t\tclock = sched_clock_local(scd);",
            "\tpreempt_enable_notrace();",
            "",
            "\treturn clock;",
            "}",
            "notrace void sched_clock_tick(void)",
            "{",
            "\tstruct sched_clock_data *scd;",
            "",
            "\tif (sched_clock_stable())",
            "\t\treturn;",
            "",
            "\tif (!static_branch_likely(&sched_clock_running))",
            "\t\treturn;",
            "",
            "\tlockdep_assert_irqs_disabled();",
            "",
            "\tscd = this_scd();",
            "\t__scd_stamp(scd);",
            "\tsched_clock_local(scd);",
            "}",
            "notrace void sched_clock_tick_stable(void)",
            "{",
            "\tif (!sched_clock_stable())",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Called under watchdog_lock.",
            "\t *",
            "\t * The watchdog just found this TSC to (still) be stable, so now is a",
            "\t * good moment to update our __gtod_offset. Because once we find the",
            "\t * TSC to be unstable, any computation will be computing crap.",
            "\t */",
            "\tlocal_irq_disable();",
            "\t__sched_clock_gtod_offset();",
            "\tlocal_irq_enable();",
            "}",
            "notrace void sched_clock_idle_sleep_event(void)",
            "{",
            "\tsched_clock_cpu(smp_processor_id());",
            "}",
            "notrace void sched_clock_idle_wakeup_event(void)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tif (sched_clock_stable())",
            "\t\treturn;",
            "",
            "\tif (unlikely(timekeeping_suspended))",
            "\t\treturn;",
            "",
            "\tlocal_irq_save(flags);",
            "\tsched_clock_tick();",
            "\tlocal_irq_restore(flags);",
            "}",
            "void __init sched_clock_init(void)",
            "{",
            "\tstatic_branch_inc(&sched_clock_running);",
            "\tlocal_irq_disable();",
            "\tgeneric_sched_clock_init();",
            "\tlocal_irq_enable();",
            "}",
            "notrace u64 sched_clock_cpu(int cpu)",
            "{",
            "\tif (!static_branch_likely(&sched_clock_running))",
            "\t\treturn 0;",
            "",
            "\treturn sched_clock();",
            "}",
            "notrace u64 __weak running_clock(void)",
            "{",
            "\treturn local_clock();",
            "}"
          ],
          "function_name": "sched_clock_cpu, sched_clock_tick, sched_clock_tick_stable, sched_clock_idle_sleep_event, sched_clock_idle_wakeup_event, sched_clock_init, sched_clock_cpu, running_clock",
          "description": "实现CPU级时间戳查询(sched_clock_cpu)、时钟滴答事件处理(sched_clock_tick)、空闲状态事件记录(sched_clock_idle_*event)及初始化流程(sched_clock_init)，包含稳定/非稳定时钟模式切换逻辑，通过running_clock弱定义提供默认本地时钟访问接口。",
          "similarity": 0.5371822118759155
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/clock.c",
          "start_line": 247,
          "end_line": 369,
          "content": [
            "static __always_inline u64 wrap_min(u64 x, u64 y)",
            "{",
            "\treturn (s64)(x - y) < 0 ? x : y;",
            "}",
            "static __always_inline u64 wrap_max(u64 x, u64 y)",
            "{",
            "\treturn (s64)(x - y) > 0 ? x : y;",
            "}",
            "static __always_inline u64 sched_clock_local(struct sched_clock_data *scd)",
            "{",
            "\tu64 now, clock, old_clock, min_clock, max_clock, gtod;",
            "\ts64 delta;",
            "",
            "again:",
            "\tnow = sched_clock_noinstr();",
            "\tdelta = now - scd->tick_raw;",
            "\tif (unlikely(delta < 0))",
            "\t\tdelta = 0;",
            "",
            "\told_clock = scd->clock;",
            "",
            "\t/*",
            "\t * scd->clock = clamp(scd->tick_gtod + delta,",
            "\t *\t\t      max(scd->tick_gtod, scd->clock),",
            "\t *\t\t      scd->tick_gtod + TICK_NSEC);",
            "\t */",
            "",
            "\tgtod = scd->tick_gtod + __gtod_offset;",
            "\tclock = gtod + delta;",
            "\tmin_clock = wrap_max(gtod, old_clock);",
            "\tmax_clock = wrap_max(old_clock, gtod + TICK_NSEC);",
            "",
            "\tclock = wrap_max(clock, min_clock);",
            "\tclock = wrap_min(clock, max_clock);",
            "",
            "\tif (!raw_try_cmpxchg64(&scd->clock, &old_clock, clock))",
            "\t\tgoto again;",
            "",
            "\treturn clock;",
            "}",
            "noinstr u64 local_clock_noinstr(void)",
            "{",
            "\tu64 clock;",
            "",
            "\tif (static_branch_likely(&__sched_clock_stable))",
            "\t\treturn sched_clock_noinstr() + __sched_clock_offset;",
            "",
            "\tif (!static_branch_likely(&sched_clock_running))",
            "\t\treturn sched_clock_noinstr();",
            "",
            "\tclock = sched_clock_local(this_scd());",
            "",
            "\treturn clock;",
            "}",
            "u64 local_clock(void)",
            "{",
            "\tu64 now;",
            "\tpreempt_disable_notrace();",
            "\tnow = local_clock_noinstr();",
            "\tpreempt_enable_notrace();",
            "\treturn now;",
            "}",
            "static notrace u64 sched_clock_remote(struct sched_clock_data *scd)",
            "{",
            "\tstruct sched_clock_data *my_scd = this_scd();",
            "\tu64 this_clock, remote_clock;",
            "\tu64 *ptr, old_val, val;",
            "",
            "#if BITS_PER_LONG != 64",
            "again:",
            "\t/*",
            "\t * Careful here: The local and the remote clock values need to",
            "\t * be read out atomic as we need to compare the values and",
            "\t * then update either the local or the remote side. So the",
            "\t * cmpxchg64 below only protects one readout.",
            "\t *",
            "\t * We must reread via sched_clock_local() in the retry case on",
            "\t * 32-bit kernels as an NMI could use sched_clock_local() via the",
            "\t * tracer and hit between the readout of",
            "\t * the low 32-bit and the high 32-bit portion.",
            "\t */",
            "\tthis_clock = sched_clock_local(my_scd);",
            "\t/*",
            "\t * We must enforce atomic readout on 32-bit, otherwise the",
            "\t * update on the remote CPU can hit inbetween the readout of",
            "\t * the low 32-bit and the high 32-bit portion.",
            "\t */",
            "\tremote_clock = cmpxchg64(&scd->clock, 0, 0);",
            "#else",
            "\t/*",
            "\t * On 64-bit kernels the read of [my]scd->clock is atomic versus the",
            "\t * update, so we can avoid the above 32-bit dance.",
            "\t */",
            "\tsched_clock_local(my_scd);",
            "again:",
            "\tthis_clock = my_scd->clock;",
            "\tremote_clock = scd->clock;",
            "#endif",
            "",
            "\t/*",
            "\t * Use the opportunity that we have both locks",
            "\t * taken to couple the two clocks: we take the",
            "\t * larger time as the latest time for both",
            "\t * runqueues. (this creates monotonic movement)",
            "\t */",
            "\tif (likely((s64)(remote_clock - this_clock) < 0)) {",
            "\t\tptr = &scd->clock;",
            "\t\told_val = remote_clock;",
            "\t\tval = this_clock;",
            "\t} else {",
            "\t\t/*",
            "\t\t * Should be rare, but possible:",
            "\t\t */",
            "\t\tptr = &my_scd->clock;",
            "\t\told_val = this_clock;",
            "\t\tval = remote_clock;",
            "\t}",
            "",
            "\tif (!try_cmpxchg64(ptr, &old_val, val))",
            "\t\tgoto again;",
            "",
            "\treturn val;",
            "}"
          ],
          "function_name": "wrap_min, wrap_max, sched_clock_local, local_clock_noinstr, local_clock, sched_clock_remote",
          "description": "提供时间戳范围约束函数(wrap_min/wrap_max)及本地/远程时钟访问接口(sched_clock_local/local_clock_noinstr)，通过cmpxchg64原子操作保障多CPU间时间戳的一致性，特别处理32位系统下的原子读取问题，确保时间戳单调递增。",
          "similarity": 0.5226317048072815
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/clock.c",
          "start_line": 1,
          "end_line": 61,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * sched_clock() for unstable CPU clocks",
            " *",
            " *  Copyright (C) 2008 Red Hat, Inc., Peter Zijlstra",
            " *",
            " *  Updates and enhancements:",
            " *    Copyright (C) 2008 Red Hat, Inc. Steven Rostedt <srostedt@redhat.com>",
            " *",
            " * Based on code by:",
            " *   Ingo Molnar <mingo@redhat.com>",
            " *   Guillaume Chazarain <guichaz@gmail.com>",
            " *",
            " *",
            " * What this file implements:",
            " *",
            " * cpu_clock(i) provides a fast (execution time) high resolution",
            " * clock with bounded drift between CPUs. The value of cpu_clock(i)",
            " * is monotonic for constant i. The timestamp returned is in nanoseconds.",
            " *",
            " * ######################### BIG FAT WARNING ##########################",
            " * # when comparing cpu_clock(i) to cpu_clock(j) for i != j, time can #",
            " * # go backwards !!                                                  #",
            " * ####################################################################",
            " *",
            " * There is no strict promise about the base, although it tends to start",
            " * at 0 on boot (but people really shouldn't rely on that).",
            " *",
            " * cpu_clock(i)       -- can be used from any context, including NMI.",
            " * local_clock()      -- is cpu_clock() on the current CPU.",
            " *",
            " * sched_clock_cpu(i)",
            " *",
            " * How it is implemented:",
            " *",
            " * The implementation either uses sched_clock() when",
            " * !CONFIG_HAVE_UNSTABLE_SCHED_CLOCK, which means in that case the",
            " * sched_clock() is assumed to provide these properties (mostly it means",
            " * the architecture provides a globally synchronized highres time source).",
            " *",
            " * Otherwise it tries to create a semi stable clock from a mixture of other",
            " * clocks, including:",
            " *",
            " *  - GTOD (clock monotonic)",
            " *  - sched_clock()",
            " *  - explicit idle events",
            " *",
            " * We use GTOD as base and use sched_clock() deltas to improve resolution. The",
            " * deltas are filtered to provide monotonicity and keeping it within an",
            " * expected window.",
            " *",
            " * Furthermore, explicit sleep and wakeup hooks allow us to account for time",
            " * that is otherwise invisible (TSC gets stopped).",
            " *",
            " */",
            "",
            "/*",
            " * Scheduler clock - returns current time in nanosec units.",
            " * This is default implementation.",
            " * Architectures and sub-architectures can override this.",
            " */"
          ],
          "function_name": null,
          "description": "定义sched_clock函数，用于获取当前时间戳，在非稳定时钟配置下依赖架构提供的全局同步高精度时钟，通过混合GTOD、sched_clock及显式空闲事件实现半稳定时钟，支持跨CPU比较但需注意非单调性警告。",
          "similarity": 0.46179014444351196
        }
      ]
    }
  ]
}