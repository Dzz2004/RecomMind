{
  "query": "进程间通信消息队列代码结构",
  "timestamp": "2025-12-26 01:13:56",
  "retrieved_files": [
    {
      "source_file": "kernel/watch_queue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:50:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `watch_queue.c`\n\n---\n\n# watch_queue.c 技术文档\n\n## 文件概述\n\n`watch_queue.c` 实现了 Linux 内核中的**监视队列**（Watch Queue）机制，这是一种基于管道（pipe）构建的通用事件通知系统。该机制允许内核子系统（如文件系统、密钥管理、设备驱动等）向用户空间异步发送结构化通知。用户空间通过创建特殊类型的管道并关联监视队列，即可接收来自内核的各类事件通知。该文件定义了通知的投递、过滤、缓冲管理及与管道集成的核心逻辑。\n\n## 核心功能\n\n### 主要函数\n\n- **`__post_watch_notification()`**  \n  核心通知投递函数。遍历指定 `watch_list` 中所有匹配 `id` 的监视器（`watch`），对每个关联的 `watch_queue` 应用过滤规则、安全检查，并将通知写入底层管道。\n\n- **`post_one_notification()`**  \n  将单个通知写入指定 `watch_queue` 的底层管道缓冲区。负责从预分配的通知页中获取空闲槽位、填充数据、更新管道头指针并唤醒等待读取的进程。\n\n- **`filter_watch_notification()`**  \n  根据 `watch_filter` 中的类型、子类型和信息掩码规则，判断是否允许特定通知通过。\n\n- **`watch_queue_set_size()`**  \n  为监视队列分配预分配的通知缓冲区（页数组和位图），并调整底层管道的环形缓冲区大小。\n\n- **`watch_queue_pipe_buf_release()`**  \n  管道缓冲区释放回调。当用户空间读取完通知后，将对应的通知槽位在位图中标记为空闲，供后续复用。\n\n### 关键数据结构\n\n- **`struct watch_queue`**  \n  表示一个监视队列，包含：\n  - 指向底层 `pipe_inode_info` 的指针\n  - 预分配的通知页数组（`notes`）\n  - 通知槽位空闲位图（`notes_bitmap`）\n  - 通知过滤器（`filter`）\n  - 保护锁（`lock`）\n\n- **`struct watch_notification`**  \n  通用通知记录格式，包含类型（`type`）、子类型（`subtype`）、信息字段（`info`，含长度和ID）及可变负载。\n\n- **`struct watch_filter` / `struct watch_type_filter`**  \n  定义通知过滤规则，支持按类型、子类型及信息字段的位掩码进行精确过滤。\n\n- **`watch_queue_pipe_buf_ops`**  \n  自定义的 `pipe_buf_operations`，用于管理监视队列专用管道缓冲区的生命周期。\n\n## 关键实现\n\n### 基于管道的通知传输\n- 监视队列复用内核管道（`pipe_inode_info`）作为通知传输通道，利用其成熟的读写、轮询、异步通知机制。\n- 通过自定义 `pipe_buf_operations`（`watch_queue_pipe_buf_ops`）实现通知槽位的回收：当用户读取通知后，`release` 回调将对应槽位在 `notes_bitmap` 中置位，标记为空闲。\n\n### 预分配通知缓冲区\n- 通知数据存储在预分配的内核页（`notes`）中，每页划分为多个固定大小（128字节）的槽位（`WATCH_QUEUE_NOTE_SIZE`）。\n- 使用位图（`notes_bitmap`）跟踪槽位使用状态，1 表示空闲。投递通知时通过 `find_first_bit()` 快速查找空闲槽位。\n- 缓冲区大小由用户通过 `watch_queue_set_size()` 设置（1-512个通知），并受管道缓冲区配额限制。\n\n### 通知投递流程\n1. **匹配监视器**：遍历 `watch_list`，查找 `id` 匹配的 `watch`。\n2. **应用过滤**：若队列配置了过滤器，调用 `filter_watch_notification()` 决定是否丢弃。\n3. **安全检查**：调用 LSM 钩子 `security_post_notification()` 进行权限验证。\n4. **写入管道**：\n   - 获取空闲通知槽位，复制通知数据。\n   - 构造 `pipe_buffer` 指向该槽位，设置自定义操作集。\n   - 更新管道 `head` 指针，唤醒等待读取的进程。\n   - 若缓冲区满，标记前一个缓冲区为 `PIPE_BUF_FLAG_LOSS` 表示丢包。\n\n### 并发与同步\n- **RCU 保护**：`watch_list` 和 `watch_queue` 的访问通过 RCU 机制保护，确保遍历时结构体不被释放。\n- **自旋锁**：\n  - `wqueue->lock`：保护 `wqueue` 状态（如 `pipe` 指针有效性）。\n  - `pipe->rd_wait.lock`：保护管道环形缓冲区的读写操作。\n- **原子操作**：管道 `head` 指针使用 `smp_store_release()` 更新，确保与 `pipe_read()` 的同步。\n\n## 依赖关系\n\n- **管道子系统**（`fs/pipe.c`）  \n  依赖管道的核心数据结构（`pipe_inode_info`、`pipe_buffer`）和操作接口（`pipe_buf()`、`pipe_full()`、`generic_pipe_buf_*`）。\n\n- **内存管理**  \n  使用 `alloc_page()`、`kmap_atomic()` 管理通知缓冲区页，`bitmap_alloc()` 管理槽位位图。\n\n- **安全模块**（LSM）  \n  通过 `security_post_notification()` 钩子集成安全策略。\n\n- **用户空间接口**  \n  与 `fs/watch_queue.c` 中的系统调用（如 `watch_queue_set_size()`）协同工作，后者负责创建监视队列并与管道关联。\n\n- **头文件依赖**  \n  `linux/watch_queue.h`（核心数据结构定义）、`linux/pipe_fs_i.h`（管道内部接口）。\n\n## 使用场景\n\n- **文件系统事件监控**  \n  如 `fsnotify` 子系统可通过监视队列向用户空间报告文件访问、修改等事件。\n\n- **密钥管理通知**  \n  内核密钥环（`KEYS`）子系统使用该机制通知密钥状态变更（如过期、撤销）。\n\n- **设备事件上报**  \n  设备驱动可利用监视队列异步上报硬件状态变化或错误事件。\n\n- **通用内核事件分发**  \n  任何需要向特权用户空间守护进程（如 `systemd`）发送结构化事件的内核子系统均可集成此机制。\n\n- **用户空间消费**  \n  应用程序通过 `open(\"/dev/watch_queue\")` 获取监视队列文件描述符，调用 `ioctl()` 设置缓冲区大小和过滤器，然后像读取普通管道一样接收通知。",
      "similarity": 0.645015299320221,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/watch_queue.c",
          "start_line": 42,
          "end_line": 154,
          "content": [
            "static inline bool lock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_lock_bh(&wqueue->lock);",
            "\tif (unlikely(!wqueue->pipe)) {",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "\t\treturn false;",
            "\t}",
            "\treturn true;",
            "}",
            "static inline void unlock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_unlock_bh(&wqueue->lock);",
            "}",
            "static void watch_queue_pipe_buf_release(struct pipe_inode_info *pipe,",
            "\t\t\t\t\t struct pipe_buffer *buf)",
            "{",
            "\tstruct watch_queue *wqueue = (struct watch_queue *)buf->private;",
            "\tstruct page *page;",
            "\tunsigned int bit;",
            "",
            "\t/* We need to work out which note within the page this refers to, but",
            "\t * the note might have been maximum size, so merely ANDing the offset",
            "\t * off doesn't work.  OTOH, the note must've been more than zero size.",
            "\t */",
            "\tbit = buf->offset + buf->len;",
            "\tif ((bit & (WATCH_QUEUE_NOTE_SIZE - 1)) == 0)",
            "\t\tbit -= WATCH_QUEUE_NOTE_SIZE;",
            "\tbit /= WATCH_QUEUE_NOTE_SIZE;",
            "",
            "\tpage = buf->page;",
            "\tbit += page->index;",
            "",
            "\tset_bit(bit, wqueue->notes_bitmap);",
            "\tgeneric_pipe_buf_release(pipe, buf);",
            "}",
            "static bool post_one_notification(struct watch_queue *wqueue,",
            "\t\t\t\t  struct watch_notification *n)",
            "{",
            "\tvoid *p;",
            "\tstruct pipe_inode_info *pipe = wqueue->pipe;",
            "\tstruct pipe_buffer *buf;",
            "\tstruct page *page;",
            "\tunsigned int head, tail, note, offset, len;",
            "\tbool done = false;",
            "",
            "\tspin_lock_irq(&pipe->rd_wait.lock);",
            "",
            "\thead = pipe->head;",
            "\ttail = pipe->tail;",
            "\tif (pipe_full(head, tail, pipe->ring_size))",
            "\t\tgoto lost;",
            "",
            "\tnote = find_first_bit(wqueue->notes_bitmap, wqueue->nr_notes);",
            "\tif (note >= wqueue->nr_notes)",
            "\t\tgoto lost;",
            "",
            "\tpage = wqueue->notes[note / WATCH_QUEUE_NOTES_PER_PAGE];",
            "\toffset = note % WATCH_QUEUE_NOTES_PER_PAGE * WATCH_QUEUE_NOTE_SIZE;",
            "\tget_page(page);",
            "\tlen = n->info & WATCH_INFO_LENGTH;",
            "\tp = kmap_atomic(page);",
            "\tmemcpy(p + offset, n, len);",
            "\tkunmap_atomic(p);",
            "",
            "\tbuf = pipe_buf(pipe, head);",
            "\tbuf->page = page;",
            "\tbuf->private = (unsigned long)wqueue;",
            "\tbuf->ops = &watch_queue_pipe_buf_ops;",
            "\tbuf->offset = offset;",
            "\tbuf->len = len;",
            "\tbuf->flags = PIPE_BUF_FLAG_WHOLE;",
            "\tsmp_store_release(&pipe->head, head + 1); /* vs pipe_read() */",
            "",
            "\tif (!test_and_clear_bit(note, wqueue->notes_bitmap)) {",
            "\t\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\t\tBUG();",
            "\t}",
            "\twake_up_interruptible_sync_poll_locked(&pipe->rd_wait, EPOLLIN | EPOLLRDNORM);",
            "\tdone = true;",
            "",
            "out:",
            "\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\tif (done)",
            "\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);",
            "\treturn done;",
            "",
            "lost:",
            "\tbuf = pipe_buf(pipe, head - 1);",
            "\tbuf->flags |= PIPE_BUF_FLAG_LOSS;",
            "\tgoto out;",
            "}",
            "static bool filter_watch_notification(const struct watch_filter *wf,",
            "\t\t\t\t      const struct watch_notification *n)",
            "{",
            "\tconst struct watch_type_filter *wt;",
            "\tunsigned int st_bits = sizeof(wt->subtype_filter[0]) * 8;",
            "\tunsigned int st_index = n->subtype / st_bits;",
            "\tunsigned int st_bit = 1U << (n->subtype % st_bits);",
            "\tint i;",
            "",
            "\tif (!test_bit(n->type, wf->type_filter))",
            "\t\treturn false;",
            "",
            "\tfor (i = 0; i < wf->nr_filters; i++) {",
            "\t\twt = &wf->filters[i];",
            "\t\tif (n->type == wt->type &&",
            "\t\t    (wt->subtype_filter[st_index] & st_bit) &&",
            "\t\t    (n->info & wt->info_mask) == wt->info_filter)",
            "\t\t\treturn true;",
            "\t}",
            "",
            "\treturn false; /* If there is a filter, the default is to reject. */",
            "}"
          ],
          "function_name": "lock_wqueue, unlock_wqueue, watch_queue_pipe_buf_release, post_one_notification, filter_watch_notification",
          "description": "实现了watch_queue的锁操作、缓冲区释放、通知提交及过滤逻辑。lock_wqueue/unlock_wqueue用于保护队列访问，watch_queue_pipe_buf_release处理缓冲区回收并更新位图，post_one_notification将通知数据写入管道，filter_watch_notification进行类型和子类型的匹配判断。",
          "similarity": 0.5557284951210022
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/watch_queue.c",
          "start_line": 602,
          "end_line": 680,
          "content": [
            "void watch_queue_clear(struct watch_queue *wqueue)",
            "{",
            "\tstruct watch_list *wlist;",
            "\tstruct watch *watch;",
            "\tbool release;",
            "",
            "\trcu_read_lock();",
            "\tspin_lock_bh(&wqueue->lock);",
            "",
            "\t/*",
            "\t * This pipe can be freed by callers like free_pipe_info().",
            "\t * Removing this reference also prevents new notifications.",
            "\t */",
            "\twqueue->pipe = NULL;",
            "",
            "\twhile (!hlist_empty(&wqueue->watches)) {",
            "\t\twatch = hlist_entry(wqueue->watches.first, struct watch, queue_node);",
            "\t\thlist_del_init_rcu(&watch->queue_node);",
            "\t\t/* We now own a ref on the watch. */",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "",
            "\t\t/* We can't do the next bit under the queue lock as we need to",
            "\t\t * get the list lock - which would cause a deadlock if someone",
            "\t\t * was removing from the opposite direction at the same time or",
            "\t\t * posting a notification.",
            "\t\t */",
            "\t\twlist = rcu_dereference(watch->watch_list);",
            "\t\tif (wlist) {",
            "\t\t\tvoid (*release_watch)(struct watch *);",
            "",
            "\t\t\tspin_lock(&wlist->lock);",
            "",
            "\t\t\trelease = !hlist_unhashed(&watch->list_node);",
            "\t\t\tif (release) {",
            "\t\t\t\thlist_del_init_rcu(&watch->list_node);",
            "\t\t\t\trcu_assign_pointer(watch->watch_list, NULL);",
            "",
            "\t\t\t\t/* We now own a second ref on the watch. */",
            "\t\t\t}",
            "",
            "\t\t\trelease_watch = wlist->release_watch;",
            "\t\t\tspin_unlock(&wlist->lock);",
            "",
            "\t\t\tif (release) {",
            "\t\t\t\tif (release_watch) {",
            "\t\t\t\t\trcu_read_unlock();",
            "\t\t\t\t\t/* This might need to call dput(), so",
            "\t\t\t\t\t * we have to drop all the locks.",
            "\t\t\t\t\t */",
            "\t\t\t\t\t(*release_watch)(watch);",
            "\t\t\t\t\trcu_read_lock();",
            "\t\t\t\t}",
            "\t\t\t\tput_watch(watch);",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tput_watch(watch);",
            "\t\tspin_lock_bh(&wqueue->lock);",
            "\t}",
            "",
            "\tspin_unlock_bh(&wqueue->lock);",
            "\trcu_read_unlock();",
            "}",
            "int watch_queue_init(struct pipe_inode_info *pipe)",
            "{",
            "\tstruct watch_queue *wqueue;",
            "",
            "\twqueue = kzalloc(sizeof(*wqueue), GFP_KERNEL);",
            "\tif (!wqueue)",
            "\t\treturn -ENOMEM;",
            "",
            "\twqueue->pipe = pipe;",
            "\tkref_init(&wqueue->usage);",
            "\tspin_lock_init(&wqueue->lock);",
            "\tINIT_HLIST_HEAD(&wqueue->watches);",
            "",
            "\tpipe->watch_queue = wqueue;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "watch_queue_clear, watch_queue_init",
          "description": "该代码实现了监视队列的初始化与清理功能。  \n`watch_queue_clear`通过RCU和自旋锁机制安全地移除所有监视项并释放资源，`watch_queue_init`初始化监视队列结构并绑定至管道对象。  \n上下文不完整：`release_watch`等关键函数依赖外部定义，部分RCU回调逻辑未完全展示。",
          "similarity": 0.5385371446609497
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/watch_queue.c",
          "start_line": 1,
          "end_line": 41,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/* Watch queue and general notification mechanism, built on pipes",
            " *",
            " * Copyright (C) 2020 Red Hat, Inc. All Rights Reserved.",
            " * Written by David Howells (dhowells@redhat.com)",
            " *",
            " * See Documentation/core-api/watch_queue.rst",
            " */",
            "",
            "#define pr_fmt(fmt) \"watchq: \" fmt",
            "#include <linux/module.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/printk.h>",
            "#include <linux/miscdevice.h>",
            "#include <linux/fs.h>",
            "#include <linux/mm.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/poll.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <linux/security.h>",
            "#include <linux/cred.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/watch_queue.h>",
            "#include <linux/pipe_fs_i.h>",
            "",
            "MODULE_DESCRIPTION(\"Watch queue\");",
            "MODULE_AUTHOR(\"Red Hat, Inc.\");",
            "",
            "#define WATCH_QUEUE_NOTE_SIZE 128",
            "#define WATCH_QUEUE_NOTES_PER_PAGE (PAGE_SIZE / WATCH_QUEUE_NOTE_SIZE)",
            "",
            "/*",
            " * This must be called under the RCU read-lock, which makes",
            " * sure that the wqueue still exists. It can then take the lock,",
            " * and check that the wqueue hasn't been destroyed, which in",
            " * turn makes sure that the notification pipe still exists.",
            " */"
          ],
          "function_name": null,
          "description": "定义了watch_queue模块的头部信息，包含常量WATCH_QUEUE_NOTE_SIZE和NOTES_PER_PAGE，声明模块许可证及作者信息，并引入相关内核头文件，为后续实现提供基础框架。",
          "similarity": 0.5195296406745911
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/watch_queue.c",
          "start_line": 193,
          "end_line": 304,
          "content": [
            "void __post_watch_notification(struct watch_list *wlist,",
            "\t\t\t       struct watch_notification *n,",
            "\t\t\t       const struct cred *cred,",
            "\t\t\t       u64 id)",
            "{",
            "\tconst struct watch_filter *wf;",
            "\tstruct watch_queue *wqueue;",
            "\tstruct watch *watch;",
            "",
            "\tif (((n->info & WATCH_INFO_LENGTH) >> WATCH_INFO_LENGTH__SHIFT) == 0) {",
            "\t\tWARN_ON(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\trcu_read_lock();",
            "",
            "\thlist_for_each_entry_rcu(watch, &wlist->watchers, list_node) {",
            "\t\tif (watch->id != id)",
            "\t\t\tcontinue;",
            "\t\tn->info &= ~WATCH_INFO_ID;",
            "\t\tn->info |= watch->info_id;",
            "",
            "\t\twqueue = rcu_dereference(watch->queue);",
            "\t\twf = rcu_dereference(wqueue->filter);",
            "\t\tif (wf && !filter_watch_notification(wf, n))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (security_post_notification(watch->cred, cred, n) < 0)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (lock_wqueue(wqueue)) {",
            "\t\t\tpost_one_notification(wqueue, n);",
            "\t\t\tunlock_wqueue(wqueue);",
            "\t\t}",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "}",
            "long watch_queue_set_size(struct pipe_inode_info *pipe, unsigned int nr_notes)",
            "{",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tstruct page **pages;",
            "\tunsigned long *bitmap;",
            "\tunsigned long user_bufs;",
            "\tint ret, i, nr_pages;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "\tif (wqueue->notes)",
            "\t\treturn -EBUSY;",
            "",
            "\tif (nr_notes < 1 ||",
            "\t    nr_notes > 512) /* TODO: choose a better hard limit */",
            "\t\treturn -EINVAL;",
            "",
            "\tnr_pages = (nr_notes + WATCH_QUEUE_NOTES_PER_PAGE - 1);",
            "\tnr_pages /= WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tuser_bufs = account_pipe_buffers(pipe->user, pipe->nr_accounted, nr_pages);",
            "",
            "\tif (nr_pages > pipe->max_usage &&",
            "\t    (too_many_pipe_buffers_hard(user_bufs) ||",
            "\t     too_many_pipe_buffers_soft(user_bufs)) &&",
            "\t    pipe_is_unprivileged_user()) {",
            "\t\tret = -EPERM;",
            "\t\tgoto error;",
            "\t}",
            "",
            "\tnr_notes = nr_pages * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tret = pipe_resize_ring(pipe, roundup_pow_of_two(nr_notes));",
            "\tif (ret < 0)",
            "\t\tgoto error;",
            "",
            "\t/*",
            "\t * pipe_resize_ring() does not update nr_accounted for watch_queue",
            "\t * pipes, because the above vastly overprovisions. Set nr_accounted on",
            "\t * and max_usage this pipe to the number that was actually charged to",
            "\t * the user above via account_pipe_buffers.",
            "\t */",
            "\tpipe->max_usage = nr_pages;",
            "\tpipe->nr_accounted = nr_pages;",
            "",
            "\tret = -ENOMEM;",
            "\tpages = kcalloc(sizeof(struct page *), nr_pages, GFP_KERNEL);",
            "\tif (!pages)",
            "\t\tgoto error;",
            "",
            "\tfor (i = 0; i < nr_pages; i++) {",
            "\t\tpages[i] = alloc_page(GFP_KERNEL);",
            "\t\tif (!pages[i])",
            "\t\t\tgoto error_p;",
            "\t\tpages[i]->index = i * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\t}",
            "",
            "\tbitmap = bitmap_alloc(nr_notes, GFP_KERNEL);",
            "\tif (!bitmap)",
            "\t\tgoto error_p;",
            "",
            "\tbitmap_fill(bitmap, nr_notes);",
            "\twqueue->notes = pages;",
            "\twqueue->notes_bitmap = bitmap;",
            "\twqueue->nr_pages = nr_pages;",
            "\twqueue->nr_notes = nr_notes;",
            "\treturn 0;",
            "",
            "error_p:",
            "\twhile (--i >= 0)",
            "\t\t__free_page(pages[i]);",
            "\tkfree(pages);",
            "error:",
            "\t(void) account_pipe_buffers(pipe->user, nr_pages, pipe->nr_accounted);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__post_watch_notification, watch_queue_set_size",
          "description": "__post_watch_notification遍历watch列表并应用过滤器后提交通知，watch_queue_set_size动态调整管道容量，通过计算所需页数和位图分配，限制最大容量为512个笔记，支持扩展性需求。",
          "similarity": 0.4557933807373047
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/watch_queue.c",
          "start_line": 315,
          "end_line": 422,
          "content": [
            "long watch_queue_set_filter(struct pipe_inode_info *pipe,",
            "\t\t\t    struct watch_notification_filter __user *_filter)",
            "{",
            "\tstruct watch_notification_type_filter *tf;",
            "\tstruct watch_notification_filter filter;",
            "\tstruct watch_type_filter *q;",
            "\tstruct watch_filter *wfilter;",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tint ret, nr_filter = 0, i;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "",
            "\tif (!_filter) {",
            "\t\t/* Remove the old filter */",
            "\t\twfilter = NULL;",
            "\t\tgoto set;",
            "\t}",
            "",
            "\t/* Grab the user's filter specification */",
            "\tif (copy_from_user(&filter, _filter, sizeof(filter)) != 0)",
            "\t\treturn -EFAULT;",
            "\tif (filter.nr_filters == 0 ||",
            "\t    filter.nr_filters > 16 ||",
            "\t    filter.__reserved != 0)",
            "\t\treturn -EINVAL;",
            "",
            "\ttf = memdup_array_user(_filter->filters, filter.nr_filters, sizeof(*tf));",
            "\tif (IS_ERR(tf))",
            "\t\treturn PTR_ERR(tf);",
            "",
            "\tret = -EINVAL;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif ((tf[i].info_filter & ~tf[i].info_mask) ||",
            "\t\t    tf[i].info_mask & WATCH_INFO_LENGTH)",
            "\t\t\tgoto err_filter;",
            "\t\t/* Ignore any unknown types */",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "\t\tnr_filter++;",
            "\t}",
            "",
            "\t/* Now we need to build the internal filter from only the relevant",
            "\t * user-specified filters.",
            "\t */",
            "\tret = -ENOMEM;",
            "\twfilter = kzalloc(struct_size(wfilter, filters, nr_filter), GFP_KERNEL);",
            "\tif (!wfilter)",
            "\t\tgoto err_filter;",
            "\twfilter->nr_filters = nr_filter;",
            "",
            "\tq = wfilter->filters;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "",
            "\t\tq->type\t\t\t= tf[i].type;",
            "\t\tq->info_filter\t\t= tf[i].info_filter;",
            "\t\tq->info_mask\t\t= tf[i].info_mask;",
            "\t\tq->subtype_filter[0]\t= tf[i].subtype_filter[0];",
            "\t\t__set_bit(q->type, wfilter->type_filter);",
            "\t\tq++;",
            "\t}",
            "",
            "\tkfree(tf);",
            "set:",
            "\tpipe_lock(pipe);",
            "\twfilter = rcu_replace_pointer(wqueue->filter, wfilter,",
            "\t\t\t\t      lockdep_is_held(&pipe->mutex));",
            "\tpipe_unlock(pipe);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\treturn 0;",
            "",
            "err_filter:",
            "\tkfree(tf);",
            "\treturn ret;",
            "}",
            "static void __put_watch_queue(struct kref *kref)",
            "{",
            "\tstruct watch_queue *wqueue =",
            "\t\tcontainer_of(kref, struct watch_queue, usage);",
            "\tstruct watch_filter *wfilter;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < wqueue->nr_pages; i++)",
            "\t\t__free_page(wqueue->notes[i]);",
            "\tkfree(wqueue->notes);",
            "\tbitmap_free(wqueue->notes_bitmap);",
            "",
            "\twfilter = rcu_access_pointer(wqueue->filter);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\tkfree_rcu(wqueue, rcu);",
            "}",
            "void put_watch_queue(struct watch_queue *wqueue)",
            "{",
            "\tkref_put(&wqueue->usage, __put_watch_queue);",
            "}",
            "static void free_watch(struct rcu_head *rcu)",
            "{",
            "\tstruct watch *watch = container_of(rcu, struct watch, rcu);",
            "",
            "\tput_watch_queue(rcu_access_pointer(watch->queue));",
            "\tatomic_dec(&watch->cred->user->nr_watches);",
            "\tput_cred(watch->cred);",
            "\tkfree(watch);",
            "}"
          ],
          "function_name": "watch_queue_set_filter, __put_watch_queue, put_watch_queue, free_watch",
          "description": "watch_queue_set_filter设置过滤规则并转换为内核内部结构，__put_watch_queue释放watch_queue相关资源包括页面、位图和过滤器，put_watch_queue通过引用计数管理watch_queue生命周期，free_watch执行RCU回调完成最终释放。",
          "similarity": 0.4498724341392517
        }
      ]
    },
    {
      "source_file": "kernel/workqueue_internal.h",
      "md_summary": "> 自动生成时间: 2025-10-25 17:54:04\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `workqueue_internal.h`\n\n---\n\n# `workqueue_internal.h` 技术文档\n\n## 1. 文件概述\n\n`workqueue_internal.h` 是 Linux 内核工作队列（workqueue）子系统的内部头文件，仅限工作队列核心代码及内核关键子系统（如 `async` 和调度器）包含使用。该文件定义了工作队列内部使用的 `struct worker` 数据结构，并声明了调度器与工作队列交互所需的钩子函数。其主要作用是封装工作线程（worker）的内部状态和行为，为并发管理型工作队列（Concurrency Managed Workqueue, CMWQ）提供底层支持。\n\n## 2. 核心功能\n\n### 数据结构\n\n- **`struct worker`**  \n  表示一个工作队列的工作线程（worker），包含其运行状态、当前处理的工作项、所属线程池、调度信息等。关键字段包括：\n  - `entry` / `hentry`：联合体，用于在空闲时挂入空闲链表，繁忙时挂入哈希表。\n  - `current_work` / `current_func`：当前正在执行的工作项及其回调函数。\n  - `current_pwq`：当前工作项所属的 `pool_workqueue`。\n  - `sleeping`：标识该 worker 是否处于睡眠状态。\n  - `scheduled`：已调度但尚未执行的工作项链表。\n  - `task`：对应的内核线程（kthread）任务结构。\n  - `pool`：所属的 `worker_pool`。\n  - `flags` / `id`：worker 的标志位和唯一标识。\n  - `desc`：用于调试的描述字符串（通过 `work_set_desc()` 设置）。\n  - `rescue_wq`：仅用于 rescuer worker，指向需要被救援的工作队列。\n\n- **内联函数**\n  - **`current_wq_worker()`**：判断当前执行上下文是否为工作队列 worker 线程。若是，则返回对应的 `struct worker` 指针；否则返回 `NULL`。通过检查 `current->flags & PF_WQ_WORKER` 并调用 `kthread_data()` 实现。\n\n### 函数声明（调度器钩子）\n\n- **`wq_worker_running(struct task_struct *task)`**  \n  通知工作队列子系统：指定 worker 线程已开始运行。\n\n- **`wq_worker_sleeping(struct task_struct *task)`**  \n  通知工作队列子系统：指定 worker 线程即将进入睡眠状态。\n\n- **`wq_worker_tick(struct task_struct *task)`**  \n  由调度器周期性调用，用于更新 worker 的运行时统计信息（如 CPU 时间）。\n\n- **`wq_worker_last_func(struct task_struct *task)`**  \n  返回指定 worker 线程最近执行的工作函数指针，供调度器或调试使用。\n\n## 3. 关键实现\n\n- **Worker 状态管理**  \n  `struct worker` 使用联合体 `entry/hentry` 实现状态复用：空闲时通过 `entry` 挂入 `worker_pool` 的空闲链表；执行工作时通过 `hentry` 挂入 busy 哈希表，便于快速查找和管理。\n\n- **并发管理支持**  \n  通过 `sleeping` 字段和调度器钩子函数（如 `wq_worker_sleeping`/`wq_worker_running`），工作队列子系统可精确跟踪 worker 的运行状态，从而动态调整线程池大小，实现高效的并发控制。\n\n- **调试支持**  \n  `desc` 字段允许通过 `work_set_desc()` 为工作项设置可读描述，在内核崩溃（WARN/BUG/panic）或 SysRq 调试时输出，便于定位问题。\n\n- **Rescuer 机制**  \n  `rescue_wq` 字段专用于 rescuer worker（用于处理内存压力下无法创建新 worker 的紧急情况），指向需要被“救援”的工作队列。\n\n- **锁注释约定**  \n  结构体字段注释中的字母（如 `L`, `K`, `I`, `A`, `S`）表示访问该字段所需的锁或上下文，具体含义需参考 `workqueue.c` 中的说明（例如 `L` 表示 pool->lock，`K` 表示需要关闭内核抢占等）。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/workqueue.h>`：提供工作队列公共接口和基础类型（如 `work_struct`、`work_func_t`）。\n  - `<linux/kthread.h>`：提供内核线程相关功能（如 `kthread_data()`）。\n  - `<linux/preempt.h>`：用于内核抢占控制。\n\n- **模块依赖**：\n  - **`workqueue.c`**：工作队列核心实现，定义了 `struct worker` 的操作逻辑。\n  - **`kernel/async.c`**：异步初始化框架，使用内部 worker 结构。\n  - **`kernel/sched/`**：调度器子系统，调用 `wq_worker_*` 钩子函数以集成工作队列状态管理。\n\n## 5. 使用场景\n\n- **工作队列执行路径**  \n  当工作项被调度执行时，内核从 `worker_pool` 中唤醒或创建 `worker`，通过 `current_wq_worker()` 获取当前上下文的 worker 结构，并更新其状态字段（如 `current_work`、`last_func`）。\n\n- **调度器集成**  \n  调度器在 worker 线程状态切换（运行/睡眠）或时钟滴答（tick）时调用相应钩子，使工作队列子系统能动态管理线程池并发度。\n\n- **内存压力恢复**  \n  在内存紧张无法创建新 worker 时，rescuer worker 被激活，通过 `rescue_wq` 字段处理阻塞的工作队列。\n\n- **内核调试与诊断**  \n  在系统崩溃或通过 SysRq 触发任务转储时，`desc` 字段提供工作项的语义信息，辅助开发者分析死锁或性能问题。",
      "similarity": 0.6221924424171448,
      "chunks": []
    },
    {
      "source_file": "kernel/workqueue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:53:20\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `workqueue.c`\n\n---\n\n# workqueue.c 技术文档\n\n## 1. 文件概述\n\n`workqueue.c` 是 Linux 内核中实现通用异步执行机制的核心文件，提供基于共享工作线程池（worker pool）的延迟任务调度功能。工作项（work items）在进程上下文中执行，支持 CPU 绑定和非绑定两种模式。每个 CPU 默认拥有两个标准工作池（普通优先级和高优先级），同时支持动态创建非绑定工作池以满足不同工作队列的需求。该机制替代了早期的 taskqueue/keventd 实现，具有更高的可扩展性和资源利用率。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct worker_pool`**  \n  工作线程池结构体，管理一组工作线程（workers），包含：\n  - `lock`：保护池状态的自旋锁\n  - `cpu` / `node`：关联的 CPU 和 NUMA 节点（绑定池）\n  - `worklist`：待处理工作项队列\n  - `idle_list` / `busy_hash`：空闲和忙碌工作线程的管理结构\n  - `nr_workers` / `nr_idle`：工作线程数量统计\n  - `attrs`：工作线程属性（如优先级、CPU 亲和性）\n  - `mayday_timer`：紧急情况下的救援请求定时器\n\n- **`struct pool_workqueue`**  \n  工作队列与工作池之间的关联结构，每个工作队列在每个池中都有一个对应的 `pool_workqueue` 实例，用于：\n  - 管理工作项的入队和执行\n  - 实现 `max_active` 限制（控制并发执行数）\n  - 支持 flush 操作（等待所有工作完成）\n  - 统计性能指标（如启动/完成次数、CPU 时间等）\n\n- **`struct worker`**（定义在 `workqueue_internal.h`）  \n  工作线程的运行时上下文，包含状态标志（如 `WORKER_IDLE`, `WORKER_UNBOUND`）、当前执行的工作项等。\n\n### 关键枚举与常量\n\n- **池/工作线程标志**：\n  - `POOL_DISASSOCIATED`：CPU 离线时池进入非绑定状态\n  - `WORKER_UNBOUND`：工作线程可在任意 CPU 上运行\n  - `WORKER_CPU_INTENSIVE`：标记 CPU 密集型任务，影响并发控制\n\n- **配置参数**：\n  - `NR_STD_WORKER_POOLS = 2`：每 CPU 标准池数量（普通 + 高优先级）\n  - `IDLE_WORKER_TIMEOUT = 300 * HZ`：空闲线程保留时间（5 分钟）\n  - `MAYDAY_INITIAL_TIMEOUT`：工作积压时触发救援的延迟（10ms）\n\n- **统计指标**（`pool_workqueue_stats`）：\n  - `PWQ_STAT_STARTED` / `PWQ_STAT_COMPLETED`：工作项执行统计\n  - `PWQ_STAT_MAYDAY` / `PWQ_STAT_RESCUED`：紧急救援事件计数\n\n## 3. 关键实现\n\n### 工作池管理\n- **绑定池（Bound Pool）**：与特定 CPU 关联，工作线程默认绑定到该 CPU。当 CPU 离线时，池进入 `DISASSOCIATED` 状态，工作线程转为非绑定模式。\n- **非绑定池（Unbound Pool）**：动态创建，通过哈希表（`unbound_pool_hash`）按属性（`workqueue_attrs`）去重，支持跨 CPU 调度。\n- **并发控制**：通过 `nr_running` 计数器和 `max_active` 限制，防止工作项过度并发执行。\n\n### 工作线程生命周期\n- **空闲管理**：空闲线程加入 `idle_list`，超时（`IDLE_WORKER_TIMEOUT`）后被回收。\n- **动态伸缩**：当工作积压时，通过 `mayday_timer` 触发新线程创建；若创建失败，向全局救援线程（rescuer）求助。\n- **状态标志**：使用位标志（如 `WORKER_IDLE`, `WORKER_PREP`）高效管理线程状态，避免锁竞争。\n\n### 内存与同步\n- **RCU 保护**：工作池销毁通过 RCU 延迟释放，确保 `get_work_pool()` 等读取路径无锁安全。\n- **锁分层**：\n  - `pool->lock`（自旋锁）：保护池内部状态\n  - `wq_pool_mutex`：全局池管理互斥锁\n  - `wq_pool_attach_mutex`：防止 CPU 绑定状态变更冲突\n\n### 工作项调度\n- **数据指针复用**：`work_struct->data` 的高有效位存储 `pool_workqueue` 指针，低有效位用于标志位（如 `WORK_STRUCT_INACTIVE`）。\n- **优先级支持**：高优先级工作池使用 `HIGHPRI_NICE_LEVEL = MIN_NICE` 提升调度优先级。\n\n## 4. 依赖关系\n\n- **内核子系统**：\n  - **调度器**（`<linux/sched.h>`）：创建工作线程（kworker），管理 CPU 亲和性\n  - **内存管理**（`<linux/slab.h>`）：分配工作池、工作队列等结构\n  - **CPU 热插拔**（`<linux/cpu.h>`）：处理 CPU 上下线时的池绑定状态切换\n  - **RCU**（`<linux/rculist.h>`）：实现无锁读取路径\n  - **定时器**（`<linux/timer.h>`）：实现空闲超时和救援机制\n\n- **内部依赖**：\n  - `workqueue_internal.h`：定义 `struct worker` 等内部结构\n  - `Documentation/core-api/workqueue.rst`：详细设计文档\n\n## 5. 使用场景\n\n- **驱动程序延迟操作**：硬件中断后调度下半部处理（如网络包处理、磁盘 I/O 完成回调）。\n- **内核子系统异步任务**：文件系统元数据更新、内存回收、电源管理状态切换。\n- **高优先级任务**：使用 `WQ_HIGHPRI` 标志创建工作队列，确保关键任务及时执行（如死锁恢复）。\n- **CPU 密集型任务**：标记 `WQ_CPU_INTENSIVE` 避免占用过多并发槽位，提升系统响应性。\n- **NUMA 感知调度**：非绑定工作队列可指定 NUMA 节点，优化内存访问延迟。",
      "similarity": 0.6031338572502136,
      "chunks": [
        {
          "chunk_id": 30,
          "file_path": "kernel/workqueue.c",
          "start_line": 6019,
          "end_line": 6134,
          "content": [
            "static void apply_wqattrs_unlock(void)",
            "{",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tcpus_read_unlock();",
            "}",
            "static ssize_t wq_nice_show(struct device *dev, struct device_attribute *attr,",
            "\t\t\t    char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint written;",
            "",
            "\tmutex_lock(&wq->mutex);",
            "\twritten = scnprintf(buf, PAGE_SIZE, \"%d\\n\", wq->unbound_attrs->nice);",
            "\tmutex_unlock(&wq->mutex);",
            "",
            "\treturn written;",
            "}",
            "static ssize_t wq_nice_store(struct device *dev, struct device_attribute *attr,",
            "\t\t\t     const char *buf, size_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tstruct workqueue_attrs *attrs;",
            "\tint ret = -ENOMEM;",
            "",
            "\tapply_wqattrs_lock();",
            "",
            "\tattrs = wq_sysfs_prep_attrs(wq);",
            "\tif (!attrs)",
            "\t\tgoto out_unlock;",
            "",
            "\tif (sscanf(buf, \"%d\", &attrs->nice) == 1 &&",
            "\t    attrs->nice >= MIN_NICE && attrs->nice <= MAX_NICE)",
            "\t\tret = apply_workqueue_attrs_locked(wq, attrs);",
            "\telse",
            "\t\tret = -EINVAL;",
            "",
            "out_unlock:",
            "\tapply_wqattrs_unlock();",
            "\tfree_workqueue_attrs(attrs);",
            "\treturn ret ?: count;",
            "}",
            "static ssize_t wq_cpumask_show(struct device *dev,",
            "\t\t\t       struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint written;",
            "",
            "\tmutex_lock(&wq->mutex);",
            "\twritten = scnprintf(buf, PAGE_SIZE, \"%*pb\\n\",",
            "\t\t\t    cpumask_pr_args(wq->unbound_attrs->cpumask));",
            "\tmutex_unlock(&wq->mutex);",
            "\treturn written;",
            "}",
            "static ssize_t wq_cpumask_store(struct device *dev,",
            "\t\t\t\tstruct device_attribute *attr,",
            "\t\t\t\tconst char *buf, size_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tstruct workqueue_attrs *attrs;",
            "\tint ret = -ENOMEM;",
            "",
            "\tapply_wqattrs_lock();",
            "",
            "\tattrs = wq_sysfs_prep_attrs(wq);",
            "\tif (!attrs)",
            "\t\tgoto out_unlock;",
            "",
            "\tret = cpumask_parse(buf, attrs->cpumask);",
            "\tif (!ret)",
            "\t\tret = apply_workqueue_attrs_locked(wq, attrs);",
            "",
            "out_unlock:",
            "\tapply_wqattrs_unlock();",
            "\tfree_workqueue_attrs(attrs);",
            "\treturn ret ?: count;",
            "}",
            "static ssize_t wq_affn_scope_show(struct device *dev,",
            "\t\t\t\t  struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint written;",
            "",
            "\tmutex_lock(&wq->mutex);",
            "\tif (wq->unbound_attrs->affn_scope == WQ_AFFN_DFL)",
            "\t\twritten = scnprintf(buf, PAGE_SIZE, \"%s (%s)\\n\",",
            "\t\t\t\t    wq_affn_names[WQ_AFFN_DFL],",
            "\t\t\t\t    wq_affn_names[wq_affn_dfl]);",
            "\telse",
            "\t\twritten = scnprintf(buf, PAGE_SIZE, \"%s\\n\",",
            "\t\t\t\t    wq_affn_names[wq->unbound_attrs->affn_scope]);",
            "\tmutex_unlock(&wq->mutex);",
            "",
            "\treturn written;",
            "}",
            "static ssize_t wq_affn_scope_store(struct device *dev,",
            "\t\t\t\t   struct device_attribute *attr,",
            "\t\t\t\t   const char *buf, size_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tstruct workqueue_attrs *attrs;",
            "\tint affn, ret = -ENOMEM;",
            "",
            "\taffn = parse_affn_scope(buf);",
            "\tif (affn < 0)",
            "\t\treturn affn;",
            "",
            "\tapply_wqattrs_lock();",
            "\tattrs = wq_sysfs_prep_attrs(wq);",
            "\tif (attrs) {",
            "\t\tattrs->affn_scope = affn;",
            "\t\tret = apply_workqueue_attrs_locked(wq, attrs);",
            "\t}",
            "\tapply_wqattrs_unlock();",
            "\tfree_workqueue_attrs(attrs);",
            "\treturn ret ?: count;",
            "}"
          ],
          "function_name": "apply_wqattrs_unlock, wq_nice_show, wq_nice_store, wq_cpumask_show, wq_cpumask_store, wq_affn_scope_show, wq_affn_scope_store",
          "description": "实现工作队列属性的读写接口，通过device attribute接口暴露nice值、CPU掩码及亲和范围配置，支持动态调整工作队列调度策略，包含互斥锁保护和属性应用逻辑。",
          "similarity": 0.596868634223938
        },
        {
          "chunk_id": 9,
          "file_path": "kernel/workqueue.c",
          "start_line": 1982,
          "end_line": 2082,
          "content": [
            "bool queue_delayed_work_on(int cpu, struct workqueue_struct *wq,",
            "\t\t\t   struct delayed_work *dwork, unsigned long delay)",
            "{",
            "\tstruct work_struct *work = &dwork->work;",
            "\tbool ret = false;",
            "\tunsigned long flags;",
            "",
            "\t/* read the comment in __queue_work() */",
            "\tlocal_irq_save(flags);",
            "",
            "\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {",
            "\t\t__queue_delayed_work(cpu, wq, dwork, delay);",
            "\t\tret = true;",
            "\t}",
            "",
            "\tlocal_irq_restore(flags);",
            "\treturn ret;",
            "}",
            "bool mod_delayed_work_on(int cpu, struct workqueue_struct *wq,",
            "\t\t\t struct delayed_work *dwork, unsigned long delay)",
            "{",
            "\tunsigned long flags;",
            "\tint ret;",
            "",
            "\tdo {",
            "\t\tret = try_to_grab_pending(&dwork->work, true, &flags);",
            "\t} while (unlikely(ret == -EAGAIN));",
            "",
            "\tif (likely(ret >= 0)) {",
            "\t\t__queue_delayed_work(cpu, wq, dwork, delay);",
            "\t\tlocal_irq_restore(flags);",
            "\t}",
            "",
            "\t/* -ENOENT from try_to_grab_pending() becomes %true */",
            "\treturn ret;",
            "}",
            "static void rcu_work_rcufn(struct rcu_head *rcu)",
            "{",
            "\tstruct rcu_work *rwork = container_of(rcu, struct rcu_work, rcu);",
            "",
            "\t/* read the comment in __queue_work() */",
            "\tlocal_irq_disable();",
            "\t__queue_work(WORK_CPU_UNBOUND, rwork->wq, &rwork->work);",
            "\tlocal_irq_enable();",
            "}",
            "bool queue_rcu_work(struct workqueue_struct *wq, struct rcu_work *rwork)",
            "{",
            "\tstruct work_struct *work = &rwork->work;",
            "",
            "\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {",
            "\t\trwork->wq = wq;",
            "\t\tcall_rcu_hurry(&rwork->rcu, rcu_work_rcufn);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static void worker_attach_to_pool(struct worker *worker,",
            "\t\t\t\t   struct worker_pool *pool)",
            "{",
            "\tmutex_lock(&wq_pool_attach_mutex);",
            "",
            "\t/*",
            "\t * The wq_pool_attach_mutex ensures %POOL_DISASSOCIATED remains",
            "\t * stable across this function.  See the comments above the flag",
            "\t * definition for details.",
            "\t */",
            "\tif (pool->flags & POOL_DISASSOCIATED)",
            "\t\tworker->flags |= WORKER_UNBOUND;",
            "\telse",
            "\t\tkthread_set_per_cpu(worker->task, pool->cpu);",
            "",
            "\tif (worker->rescue_wq)",
            "\t\tset_cpus_allowed_ptr(worker->task, pool_allowed_cpus(pool));",
            "",
            "\tlist_add_tail(&worker->node, &pool->workers);",
            "\tworker->pool = pool;",
            "",
            "\tmutex_unlock(&wq_pool_attach_mutex);",
            "}",
            "static void worker_detach_from_pool(struct worker *worker)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "\tstruct completion *detach_completion = NULL;",
            "",
            "\tmutex_lock(&wq_pool_attach_mutex);",
            "",
            "\tkthread_set_per_cpu(worker->task, -1);",
            "\tlist_del(&worker->node);",
            "\tworker->pool = NULL;",
            "",
            "\tif (list_empty(&pool->workers) && list_empty(&pool->dying_workers))",
            "\t\tdetach_completion = pool->detach_completion;",
            "\tmutex_unlock(&wq_pool_attach_mutex);",
            "",
            "\t/* clear leftover flags without pool->lock after it is detached */",
            "\tworker->flags &= ~(WORKER_UNBOUND | WORKER_REBOUND);",
            "",
            "\tif (detach_completion)",
            "\t\tcomplete(detach_completion);",
            "}"
          ],
          "function_name": "queue_delayed_work_on, mod_delayed_work_on, rcu_work_rcufn, queue_rcu_work, worker_attach_to_pool, worker_detach_from_pool",
          "description": "该代码块管理RCU安全的工作队列操作。queue_delayed_work_on/mod_delayed_work_on控制延迟工作提交；rcu_work_rcufn处理RCU回调；worker_attach_to_pool/detach_from_pool管理worker与worker池的绑定关系。",
          "similarity": 0.5752260684967041
        },
        {
          "chunk_id": 28,
          "file_path": "kernel/workqueue.c",
          "start_line": 5717,
          "end_line": 5828,
          "content": [
            "void freeze_workqueues_begin(void)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tstruct pool_workqueue *pwq;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tWARN_ON_ONCE(workqueue_freezing);",
            "\tworkqueue_freezing = true;",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tmutex_lock(&wq->mutex);",
            "\t\tfor_each_pwq(pwq, wq)",
            "\t\t\tpwq_adjust_max_active(pwq);",
            "\t\tmutex_unlock(&wq->mutex);",
            "\t}",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "}",
            "bool freeze_workqueues_busy(void)",
            "{",
            "\tbool busy = false;",
            "\tstruct workqueue_struct *wq;",
            "\tstruct pool_workqueue *pwq;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tWARN_ON_ONCE(!workqueue_freezing);",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tif (!(wq->flags & WQ_FREEZABLE))",
            "\t\t\tcontinue;",
            "\t\t/*",
            "\t\t * nr_active is monotonically decreasing.  It's safe",
            "\t\t * to peek without lock.",
            "\t\t */",
            "\t\trcu_read_lock();",
            "\t\tfor_each_pwq(pwq, wq) {",
            "\t\t\tWARN_ON_ONCE(pwq->nr_active < 0);",
            "\t\t\tif (pwq->nr_active) {",
            "\t\t\t\tbusy = true;",
            "\t\t\t\trcu_read_unlock();",
            "\t\t\t\tgoto out_unlock;",
            "\t\t\t}",
            "\t\t}",
            "\t\trcu_read_unlock();",
            "\t}",
            "out_unlock:",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\treturn busy;",
            "}",
            "void thaw_workqueues(void)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tstruct pool_workqueue *pwq;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tif (!workqueue_freezing)",
            "\t\tgoto out_unlock;",
            "",
            "\tworkqueue_freezing = false;",
            "",
            "\t/* restore max_active and repopulate worklist */",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tmutex_lock(&wq->mutex);",
            "\t\tfor_each_pwq(pwq, wq)",
            "\t\t\tpwq_adjust_max_active(pwq);",
            "\t\tmutex_unlock(&wq->mutex);",
            "\t}",
            "",
            "out_unlock:",
            "\tmutex_unlock(&wq_pool_mutex);",
            "}",
            "static int workqueue_apply_unbound_cpumask(const cpumask_var_t unbound_cpumask)",
            "{",
            "\tLIST_HEAD(ctxs);",
            "\tint ret = 0;",
            "\tstruct workqueue_struct *wq;",
            "\tstruct apply_wqattrs_ctx *ctx, *n;",
            "",
            "\tlockdep_assert_held(&wq_pool_mutex);",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tif (!(wq->flags & WQ_UNBOUND))",
            "\t\t\tcontinue;",
            "\t\t/* creating multiple pwqs breaks ordering guarantee */",
            "\t\tif (wq->flags & __WQ_ORDERED)",
            "\t\t\tcontinue;",
            "",
            "\t\tctx = apply_wqattrs_prepare(wq, wq->unbound_attrs, unbound_cpumask);",
            "\t\tif (IS_ERR(ctx)) {",
            "\t\t\tret = PTR_ERR(ctx);",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tlist_add_tail(&ctx->list, &ctxs);",
            "\t}",
            "",
            "\tlist_for_each_entry_safe(ctx, n, &ctxs, list) {",
            "\t\tif (!ret)",
            "\t\t\tapply_wqattrs_commit(ctx);",
            "\t\tapply_wqattrs_cleanup(ctx);",
            "\t}",
            "",
            "\tif (!ret) {",
            "\t\tmutex_lock(&wq_pool_attach_mutex);",
            "\t\tcpumask_copy(wq_unbound_cpumask, unbound_cpumask);",
            "\t\tmutex_unlock(&wq_pool_attach_mutex);",
            "\t}",
            "\treturn ret;",
            "}"
          ],
          "function_name": "freeze_workqueues_begin, freeze_workqueues_busy, thaw_workqueues, workqueue_apply_unbound_cpumask",
          "description": "实现工作队列冻结/解冻逻辑，检查是否存在活跃任务并调整最大并发数，动态修改非绑定工作者的CPU掩码配置",
          "similarity": 0.5744525790214539
        },
        {
          "chunk_id": 29,
          "file_path": "kernel/workqueue.c",
          "start_line": 5864,
          "end_line": 5966,
          "content": [
            "int workqueue_unbound_exclude_cpumask(cpumask_var_t exclude_cpumask)",
            "{",
            "\tcpumask_var_t cpumask;",
            "\tint ret = 0;",
            "",
            "\tif (!zalloc_cpumask_var(&cpumask, GFP_KERNEL))",
            "\t\treturn -ENOMEM;",
            "",
            "\tlockdep_assert_cpus_held();",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\t/* Save the current isolated cpumask & export it via sysfs */",
            "\tcpumask_copy(wq_isolated_cpumask, exclude_cpumask);",
            "",
            "\t/*",
            "\t * If the operation fails, it will fall back to",
            "\t * wq_requested_unbound_cpumask which is initially set to",
            "\t * (HK_TYPE_WQ ∩ HK_TYPE_DOMAIN) house keeping mask and rewritten",
            "\t * by any subsequent write to workqueue/cpumask sysfs file.",
            "\t */",
            "\tif (!cpumask_andnot(cpumask, wq_requested_unbound_cpumask, exclude_cpumask))",
            "\t\tcpumask_copy(cpumask, wq_requested_unbound_cpumask);",
            "\tif (!cpumask_equal(cpumask, wq_unbound_cpumask))",
            "\t\tret = workqueue_apply_unbound_cpumask(cpumask);",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tfree_cpumask_var(cpumask);",
            "\treturn ret;",
            "}",
            "static int parse_affn_scope(const char *val)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < ARRAY_SIZE(wq_affn_names); i++) {",
            "\t\tif (!strncasecmp(val, wq_affn_names[i], strlen(wq_affn_names[i])))",
            "\t\t\treturn i;",
            "\t}",
            "\treturn -EINVAL;",
            "}",
            "static int wq_affn_dfl_set(const char *val, const struct kernel_param *kp)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tint affn, cpu;",
            "",
            "\taffn = parse_affn_scope(val);",
            "\tif (affn < 0)",
            "\t\treturn affn;",
            "\tif (affn == WQ_AFFN_DFL)",
            "\t\treturn -EINVAL;",
            "",
            "\tcpus_read_lock();",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\twq_affn_dfl = affn;",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tfor_each_online_cpu(cpu) {",
            "\t\t\twq_update_pod(wq, cpu, cpu, true);",
            "\t\t}",
            "\t}",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tcpus_read_unlock();",
            "",
            "\treturn 0;",
            "}",
            "static int wq_affn_dfl_get(char *buffer, const struct kernel_param *kp)",
            "{",
            "\treturn scnprintf(buffer, PAGE_SIZE, \"%s\\n\", wq_affn_names[wq_affn_dfl]);",
            "}",
            "static ssize_t per_cpu_show(struct device *dev, struct device_attribute *attr,",
            "\t\t\t    char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "",
            "\treturn scnprintf(buf, PAGE_SIZE, \"%d\\n\", (bool)!(wq->flags & WQ_UNBOUND));",
            "}",
            "static ssize_t max_active_show(struct device *dev,",
            "\t\t\t       struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "",
            "\treturn scnprintf(buf, PAGE_SIZE, \"%d\\n\", wq->saved_max_active);",
            "}",
            "static ssize_t max_active_store(struct device *dev,",
            "\t\t\t\tstruct device_attribute *attr, const char *buf,",
            "\t\t\t\tsize_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint val;",
            "",
            "\tif (sscanf(buf, \"%d\", &val) != 1 || val <= 0)",
            "\t\treturn -EINVAL;",
            "",
            "\tworkqueue_set_max_active(wq, val);",
            "\treturn count;",
            "}",
            "static void apply_wqattrs_lock(void)",
            "{",
            "\t/* CPUs should stay stable across pwq creations and installations */",
            "\tcpus_read_lock();",
            "\tmutex_lock(&wq_pool_mutex);",
            "}"
          ],
          "function_name": "workqueue_unbound_exclude_cpumask, parse_affn_scope, wq_affn_dfl_set, wq_affn_dfl_get, per_cpu_show, max_active_show, max_active_store, apply_wqattrs_lock",
          "description": "配置非绑定工作者的CPU排除掩码和默认亲和性策略，暴露工作队列属性供sysfs访问并管理最大并发数参数",
          "similarity": 0.5688204765319824
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/workqueue.c",
          "start_line": 1334,
          "end_line": 1463,
          "content": [
            "void wq_worker_tick(struct task_struct *task)",
            "{",
            "\tstruct worker *worker = kthread_data(task);",
            "\tstruct pool_workqueue *pwq = worker->current_pwq;",
            "\tstruct worker_pool *pool = worker->pool;",
            "",
            "\tif (!pwq)",
            "\t\treturn;",
            "",
            "\tpwq->stats[PWQ_STAT_CPU_TIME] += TICK_USEC;",
            "",
            "\tif (!wq_cpu_intensive_thresh_us)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If the current worker is concurrency managed and hogged the CPU for",
            "\t * longer than wq_cpu_intensive_thresh_us, it's automatically marked",
            "\t * CPU_INTENSIVE to avoid stalling other concurrency-managed work items.",
            "\t *",
            "\t * Set @worker->sleeping means that @worker is in the process of",
            "\t * switching out voluntarily and won't be contributing to",
            "\t * @pool->nr_running until it wakes up. As wq_worker_sleeping() also",
            "\t * decrements ->nr_running, setting CPU_INTENSIVE here can lead to",
            "\t * double decrements. The task is releasing the CPU anyway. Let's skip.",
            "\t * We probably want to make this prettier in the future.",
            "\t */",
            "\tif ((worker->flags & WORKER_NOT_RUNNING) || READ_ONCE(worker->sleeping) ||",
            "\t    worker->task->se.sum_exec_runtime - worker->current_at <",
            "\t    wq_cpu_intensive_thresh_us * NSEC_PER_USEC)",
            "\t\treturn;",
            "",
            "\traw_spin_lock(&pool->lock);",
            "",
            "\tworker_set_flags(worker, WORKER_CPU_INTENSIVE);",
            "\twq_cpu_intensive_report(worker->current_func);",
            "\tpwq->stats[PWQ_STAT_CPU_INTENSIVE]++;",
            "",
            "\tif (kick_pool(pool))",
            "\t\tpwq->stats[PWQ_STAT_CM_WAKEUP]++;",
            "",
            "\traw_spin_unlock(&pool->lock);",
            "}",
            "work_func_t wq_worker_last_func(struct task_struct *task)",
            "{",
            "\tstruct worker *worker = kthread_data(task);",
            "",
            "\treturn worker->last_func;",
            "}",
            "static void get_pwq(struct pool_workqueue *pwq)",
            "{",
            "\tlockdep_assert_held(&pwq->pool->lock);",
            "\tWARN_ON_ONCE(pwq->refcnt <= 0);",
            "\tpwq->refcnt++;",
            "}",
            "static void put_pwq(struct pool_workqueue *pwq)",
            "{",
            "\tlockdep_assert_held(&pwq->pool->lock);",
            "\tif (likely(--pwq->refcnt))",
            "\t\treturn;",
            "\t/*",
            "\t * @pwq can't be released under pool->lock, bounce to a dedicated",
            "\t * kthread_worker to avoid A-A deadlocks.",
            "\t */",
            "\tkthread_queue_work(pwq_release_worker, &pwq->release_work);",
            "}",
            "static void put_pwq_unlocked(struct pool_workqueue *pwq)",
            "{",
            "\tif (pwq) {",
            "\t\t/*",
            "\t\t * As both pwqs and pools are RCU protected, the",
            "\t\t * following lock operations are safe.",
            "\t\t */",
            "\t\traw_spin_lock_irq(&pwq->pool->lock);",
            "\t\tput_pwq(pwq);",
            "\t\traw_spin_unlock_irq(&pwq->pool->lock);",
            "\t}",
            "}",
            "static void pwq_activate_inactive_work(struct work_struct *work)",
            "{",
            "\tstruct pool_workqueue *pwq = get_work_pwq(work);",
            "",
            "\ttrace_workqueue_activate_work(work);",
            "\tif (list_empty(&pwq->pool->worklist))",
            "\t\tpwq->pool->watchdog_ts = jiffies;",
            "\tmove_linked_works(work, &pwq->pool->worklist, NULL);",
            "\t__clear_bit(WORK_STRUCT_INACTIVE_BIT, work_data_bits(work));",
            "\tpwq->nr_active++;",
            "}",
            "static void pwq_activate_first_inactive(struct pool_workqueue *pwq)",
            "{",
            "\tstruct work_struct *work = list_first_entry(&pwq->inactive_works,",
            "\t\t\t\t\t\t    struct work_struct, entry);",
            "",
            "\tpwq_activate_inactive_work(work);",
            "}",
            "static void pwq_dec_nr_in_flight(struct pool_workqueue *pwq, unsigned long work_data)",
            "{",
            "\tint color = get_work_color(work_data);",
            "",
            "\tif (!(work_data & WORK_STRUCT_INACTIVE)) {",
            "\t\tpwq->nr_active--;",
            "\t\tif (!list_empty(&pwq->inactive_works)) {",
            "\t\t\t/* one down, submit an inactive one */",
            "\t\t\tif (pwq->nr_active < pwq->max_active)",
            "\t\t\t\tpwq_activate_first_inactive(pwq);",
            "\t\t}",
            "\t}",
            "",
            "\tpwq->nr_in_flight[color]--;",
            "",
            "\t/* is flush in progress and are we at the flushing tip? */",
            "\tif (likely(pwq->flush_color != color))",
            "\t\tgoto out_put;",
            "",
            "\t/* are there still in-flight works? */",
            "\tif (pwq->nr_in_flight[color])",
            "\t\tgoto out_put;",
            "",
            "\t/* this pwq is done, clear flush_color */",
            "\tpwq->flush_color = -1;",
            "",
            "\t/*",
            "\t * If this was the last pwq, wake up the first flusher.  It",
            "\t * will handle the rest.",
            "\t */",
            "\tif (atomic_dec_and_test(&pwq->wq->nr_pwqs_to_flush))",
            "\t\tcomplete(&pwq->wq->first_flusher->done);",
            "out_put:",
            "\tput_pwq(pwq);",
            "}"
          ],
          "function_name": "wq_worker_tick, wq_worker_last_func, get_pwq, put_pwq, put_pwq_unlocked, pwq_activate_inactive_work, pwq_activate_first_inactive, pwq_dec_nr_in_flight",
          "description": "该代码块定义了工作队列中worker的CPU使用监控及PWQ管理。wq_worker_tick检测worker是否成为CPU密集型任务并更新统计信息；get_pwq/put_pwq管理PWQ引用计数；pwq_activate_inactive_work激活处于inactive状态的工作项并更新nr_active计数。",
          "similarity": 0.5639957189559937
        }
      ]
    }
  ]
}