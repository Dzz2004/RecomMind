{
  "query": "resource allocation in operating systems",
  "timestamp": "2025-12-26 01:00:38",
  "retrieved_files": [
    {
      "source_file": "mm/page_alloc.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:59:58\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `page_alloc.c`\n\n---\n\n# page_alloc.c 技术文档\n\n## 1. 文件概述\n\n`page_alloc.c` 是 Linux 内核内存管理子系统的核心文件之一，负责物理页面的分配与释放。该文件实现了基于区域（zone）和迁移类型（migratetype）的伙伴系统（Buddy System）内存分配器，管理系统的空闲页链表，并提供高效的页面分配/回收机制。它不处理小对象分配（由 slab/slub/slob 子系统负责），而是专注于以页为单位的大块物理内存管理。\n\n## 2. 核心功能\n\n### 主要数据结构\n- **`struct per_cpu_pages`**：每个 CPU 的每区（per-zone）页面缓存，用于减少锁竞争，提升分配性能。\n- **`node_states[NR_NODE_STATES]`**：全局节点状态掩码数组，跟踪各 NUMA 节点的状态（如在线、有内存等）。\n- **`sysctl_lowmem_reserve_ratio[MAX_NR_ZONES]`**：各内存区域的低内存保留比例，防止高优先级区域耗尽低优先级区域的内存。\n- **`zone_names[]` 和 `migratetype_names[]`**：内存区域和页面迁移类型的名称字符串，用于调试和日志。\n- **`gfp_allowed_mask`**：全局 GFP（Get Free Page）标志掩码，控制启动早期可使用的分配标志。\n\n### 主要函数（部分声明）\n- **`__free_pages_ok()`**：内部页面释放函数，执行实际的伙伴系统合并与链表插入逻辑。\n- 各种页面分配函数（如 `alloc_pages()`、`__alloc_pages()` 等，定义在其他位置但在此文件中实现核心逻辑）。\n- 每 CPU 页面列表操作辅助宏（如 `pcp_spin_lock()`、`pcp_spin_trylock()`）。\n\n### 关键常量与标志\n- **`fpi_t` 类型及标志**：\n  - `FPI_NONE`：无特殊要求。\n  - `FPI_SKIP_REPORT_NOTIFY`：跳过空闲页报告通知。\n  - `FPI_TO_TAIL`：将页面放回空闲链表尾部（用于优化场景如内存热插拔）。\n- **`min_free_kbytes`**：系统保留的最小空闲内存（KB），影响水位线计算。\n\n## 3. 关键实现\n\n### 每 CPU 页面缓存（Per-CPU Page Caching）\n- 通过 `struct per_cpu_pages` 为每个 CPU 维护热/冷页列表，避免频繁访问全局 zone 锁。\n- 使用 `pcpu_spin_lock` 宏族安全地访问每 CPU 数据，结合 `preempt_disable()`（非 RT）或 `migrate_disable()`（RT）防止任务迁移导致访问错误 CPU 的数据。\n- 在 UP 系统上，使用 IRQ 关闭防止重入；在 SMP/RT 系统上依赖自旋锁语义。\n\n### 内存区域（Zone）与 NUMA 支持\n- 支持多种内存区域（DMA、DMA32、Normal、HighMem、Movable、Device），通过 `zone_names` 标识。\n- 实现 `lowmem_reserve_ratio` 机制，确保高区域分配不会耗尽低区域的保留内存（如 ZONE_DMA 为设备保留）。\n- 通过 `node_states` 和 per-CPU 变量（如 `numa_node`、`_numa_mem_`）支持 NUMA 和无内存节点架构。\n\n### 空闲页管理优化\n- **`FPI_TO_TAIL` 标志**：允许将页面放回空闲链表尾部，配合内存打乱（shuffle）或热插拔时批量初始化。\n- **`FPI_SKIP_REPORT_NOTIFY` 标志**：在临时取出并归还页面时不触发空闲页报告机制，减少开销。\n- **水位线与保留内存**：`min_free_kbytes` 控制最低水位，影响 OOM（Out-Of-Memory）决策和内存回收行为。\n\n### 实时内核（PREEMPT_RT）适配\n- 在 RT 内核中使用 `migrate_disable()` 替代 `preempt_disable()`，避免干扰 RT 自旋锁的优先级继承机制。\n\n## 4. 依赖关系\n\n### 头文件依赖\n- **核心内存管理**：`<linux/mm.h>`, `<linux/highmem.h>`, `\"internal.h\"`\n- **同步机制**：`<linux/spinlock.h>`（隐含）、`<linux/mutex.h>`\n- **NUMA 与拓扑**：`<linux/topology.h>`, `<linux/nodemask.h>`\n- **调试与追踪**：`<linux/kasan.h>`, `<trace/events/kmem.h>`, `<linux/page_owner.h>`\n- **高级特性**：`<linux/compaction.h>`, `<linux/migrate.h>`, `<linux/memcontrol.h>`\n\n### 子系统交互\n- **Slab 分配器**：本文件不处理 kmalloc，由 `slab.c` 等负责。\n- **内存回收**：与 `vmscan.c` 协同，通过水位线触发 reclaim。\n- **内存热插拔**：通过 `memory_hotplug.h` 接口管理动态内存。\n- **OOM Killer**：通过 `oom.h` 和水位线机制触发 OOM。\n- **透明大页（THP）**：与 `khugepaged` 协同进行大页分配。\n\n## 5. 使用场景\n\n- **内核内存分配**：所有以页为单位的内核内存请求（如 `alloc_pages()`）最终由本文件处理。\n- **用户空间缺页处理**：匿名页、文件页的物理页分配。\n- **内存映射（mmap）**：大块物理内存的分配与管理。\n- **内存回收与迁移**：页面回收、压缩（compaction）、迁移（migration）过程中涉及的页面释放与重新分配。\n- **系统启动与热插拔**：初始化内存区域、处理动态添加/移除内存。\n- **实时系统**：在 PREEMPT_RT 内核中提供低延迟的页面分配路径。\n- **调试与监控**：通过 page owner、KASAN、tracepoint 等机制提供内存使用追踪。",
      "similarity": 0.6292082667350769,
      "chunks": [
        {
          "chunk_id": 31,
          "file_path": "mm/page_alloc.c",
          "start_line": 5966,
          "end_line": 6071,
          "content": [
            "static void setup_per_zone_lowmem_reserve(void)",
            "{",
            "\tstruct pglist_data *pgdat;",
            "\tenum zone_type i, j;",
            "",
            "\tfor_each_online_pgdat(pgdat) {",
            "\t\tfor (i = 0; i < MAX_NR_ZONES - 1; i++) {",
            "\t\t\tstruct zone *zone = &pgdat->node_zones[i];",
            "\t\t\tint ratio = sysctl_lowmem_reserve_ratio[i];",
            "\t\t\tbool clear = !ratio || !zone_managed_pages(zone);",
            "\t\t\tunsigned long managed_pages = 0;",
            "",
            "\t\t\tfor (j = i + 1; j < MAX_NR_ZONES; j++) {",
            "\t\t\t\tstruct zone *upper_zone = &pgdat->node_zones[j];",
            "",
            "\t\t\t\tmanaged_pages += zone_managed_pages(upper_zone);",
            "",
            "\t\t\t\tif (clear)",
            "\t\t\t\t\tzone->lowmem_reserve[j] = 0;",
            "\t\t\t\telse",
            "\t\t\t\t\tzone->lowmem_reserve[j] = managed_pages / ratio;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "\t/* update totalreserve_pages */",
            "\tcalculate_totalreserve_pages();",
            "}",
            "static void __setup_per_zone_wmarks(void)",
            "{",
            "\tunsigned long pages_min = min_free_kbytes >> (PAGE_SHIFT - 10);",
            "\tunsigned long lowmem_pages = 0;",
            "\tstruct zone *zone;",
            "\tunsigned long flags;",
            "",
            "\t/* Calculate total number of !ZONE_HIGHMEM and !ZONE_MOVABLE pages */",
            "\tfor_each_zone(zone) {",
            "\t\tif (!is_highmem(zone) && zone_idx(zone) != ZONE_MOVABLE)",
            "\t\t\tlowmem_pages += zone_managed_pages(zone);",
            "\t}",
            "",
            "\tfor_each_zone(zone) {",
            "\t\tu64 tmp;",
            "",
            "\t\tspin_lock_irqsave(&zone->lock, flags);",
            "\t\ttmp = (u64)pages_min * zone_managed_pages(zone);",
            "\t\tdo_div(tmp, lowmem_pages);",
            "\t\tif (is_highmem(zone) || zone_idx(zone) == ZONE_MOVABLE) {",
            "\t\t\t/*",
            "\t\t\t * __GFP_HIGH and PF_MEMALLOC allocations usually don't",
            "\t\t\t * need highmem and movable zones pages, so cap pages_min",
            "\t\t\t * to a small  value here.",
            "\t\t\t *",
            "\t\t\t * The WMARK_HIGH-WMARK_LOW and (WMARK_LOW-WMARK_MIN)",
            "\t\t\t * deltas control async page reclaim, and so should",
            "\t\t\t * not be capped for highmem and movable zones.",
            "\t\t\t */",
            "\t\t\tunsigned long min_pages;",
            "",
            "\t\t\tmin_pages = zone_managed_pages(zone) / 1024;",
            "\t\t\tmin_pages = clamp(min_pages, SWAP_CLUSTER_MAX, 128UL);",
            "\t\t\tzone->_watermark[WMARK_MIN] = min_pages;",
            "\t\t} else {",
            "\t\t\t/*",
            "\t\t\t * If it's a lowmem zone, reserve a number of pages",
            "\t\t\t * proportionate to the zone's size.",
            "\t\t\t */",
            "\t\t\tzone->_watermark[WMARK_MIN] = tmp;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Set the kswapd watermarks distance according to the",
            "\t\t * scale factor in proportion to available memory, but",
            "\t\t * ensure a minimum size on small systems.",
            "\t\t */",
            "\t\ttmp = max_t(u64, tmp >> 2,",
            "\t\t\t    mult_frac(zone_managed_pages(zone),",
            "\t\t\t\t      watermark_scale_factor, 10000));",
            "",
            "\t\tzone->watermark_boost = 0;",
            "\t\tzone->_watermark[WMARK_LOW]  = min_wmark_pages(zone) + tmp;",
            "\t\tzone->_watermark[WMARK_HIGH] = low_wmark_pages(zone) + tmp;",
            "\t\tzone->_watermark[WMARK_PROMO] = high_wmark_pages(zone) + tmp;",
            "",
            "\t\tspin_unlock_irqrestore(&zone->lock, flags);",
            "\t}",
            "",
            "\t/* update totalreserve_pages */",
            "\tcalculate_totalreserve_pages();",
            "}",
            "void setup_per_zone_wmarks(void)",
            "{",
            "\tstruct zone *zone;",
            "\tstatic DEFINE_SPINLOCK(lock);",
            "",
            "\tspin_lock(&lock);",
            "\t__setup_per_zone_wmarks();",
            "\tspin_unlock(&lock);",
            "",
            "\t/*",
            "\t * The watermark size have changed so update the pcpu batch",
            "\t * and high limits or the limits may be inappropriate.",
            "\t */",
            "\tfor_each_zone(zone)",
            "\t\tzone_pcp_update(zone, 0);",
            "}"
          ],
          "function_name": "setup_per_zone_lowmem_reserve, __setup_per_zone_wmarks, setup_per_zone_wmarks",
          "description": "设置各内存区域的低内存保留值和水印标记，根据系统配置调整内存管理参数，确保内存分配策略适应不同场景需求。",
          "similarity": 0.6186770796775818
        },
        {
          "chunk_id": 23,
          "file_path": "mm/page_alloc.c",
          "start_line": 4471,
          "end_line": 4660,
          "content": [
            "static inline bool prepare_alloc_pages(gfp_t gfp_mask, unsigned int order,",
            "\t\tint preferred_nid, nodemask_t *nodemask,",
            "\t\tstruct alloc_context *ac, gfp_t *alloc_gfp,",
            "\t\tunsigned int *alloc_flags)",
            "{",
            "\tac->highest_zoneidx = gfp_zone(gfp_mask);",
            "\tac->zonelist = node_zonelist(preferred_nid, gfp_mask);",
            "\tac->nodemask = nodemask;",
            "\tac->migratetype = gfp_migratetype(gfp_mask);",
            "",
            "\tif (cpusets_enabled()) {",
            "\t\t*alloc_gfp |= __GFP_HARDWALL;",
            "\t\t/*",
            "\t\t * When we are in the interrupt context, it is irrelevant",
            "\t\t * to the current task context. It means that any node ok.",
            "\t\t */",
            "\t\tif (in_task() && !ac->nodemask)",
            "\t\t\tac->nodemask = &cpuset_current_mems_allowed;",
            "\t\telse",
            "\t\t\t*alloc_flags |= ALLOC_CPUSET;",
            "\t}",
            "",
            "\tmight_alloc(gfp_mask);",
            "",
            "\tif (should_fail_alloc_page(gfp_mask, order))",
            "\t\treturn false;",
            "",
            "\t*alloc_flags = gfp_to_alloc_flags_cma(gfp_mask, *alloc_flags);",
            "",
            "\t/* Dirty zone balancing only done in the fast path */",
            "\tac->spread_dirty_pages = (gfp_mask & __GFP_WRITE);",
            "",
            "\t/*",
            "\t * The preferred zone is used for statistics but crucially it is",
            "\t * also used as the starting point for the zonelist iterator. It",
            "\t * may get reset for allocations that ignore memory policies.",
            "\t */",
            "\tac->preferred_zoneref = first_zones_zonelist(ac->zonelist,",
            "\t\t\t\t\tac->highest_zoneidx, ac->nodemask);",
            "",
            "\treturn true;",
            "}",
            "unsigned long alloc_pages_bulk_noprof(gfp_t gfp, int preferred_nid,",
            "\t\t\tnodemask_t *nodemask, int nr_pages,",
            "\t\t\tstruct list_head *page_list,",
            "\t\t\tstruct page **page_array)",
            "{",
            "\tstruct page *page;",
            "\tunsigned long __maybe_unused UP_flags;",
            "\tstruct zone *zone;",
            "\tstruct zoneref *z;",
            "\tstruct per_cpu_pages *pcp;",
            "\tstruct list_head *pcp_list;",
            "\tstruct alloc_context ac;",
            "\tgfp_t alloc_gfp;",
            "\tunsigned int alloc_flags = ALLOC_WMARK_LOW;",
            "\tint nr_populated = 0, nr_account = 0;",
            "",
            "\t/*",
            "\t * Skip populated array elements to determine if any pages need",
            "\t * to be allocated before disabling IRQs.",
            "\t */",
            "\twhile (page_array && nr_populated < nr_pages && page_array[nr_populated])",
            "\t\tnr_populated++;",
            "",
            "\t/* No pages requested? */",
            "\tif (unlikely(nr_pages <= 0))",
            "\t\tgoto out;",
            "",
            "\t/* Already populated array? */",
            "\tif (unlikely(page_array && nr_pages - nr_populated == 0))",
            "\t\tgoto out;",
            "",
            "\t/* Bulk allocator does not support memcg accounting. */",
            "\tif (memcg_kmem_online() && (gfp & __GFP_ACCOUNT))",
            "\t\tgoto failed;",
            "",
            "\t/* Use the single page allocator for one page. */",
            "\tif (nr_pages - nr_populated == 1)",
            "\t\tgoto failed;",
            "",
            "#ifdef CONFIG_PAGE_OWNER",
            "\t/*",
            "\t * PAGE_OWNER may recurse into the allocator to allocate space to",
            "\t * save the stack with pagesets.lock held. Releasing/reacquiring",
            "\t * removes much of the performance benefit of bulk allocation so",
            "\t * force the caller to allocate one page at a time as it'll have",
            "\t * similar performance to added complexity to the bulk allocator.",
            "\t */",
            "\tif (static_branch_unlikely(&page_owner_inited))",
            "\t\tgoto failed;",
            "#endif",
            "",
            "\t/* May set ALLOC_NOFRAGMENT, fragmentation will return 1 page. */",
            "\tgfp &= gfp_allowed_mask;",
            "\talloc_gfp = gfp;",
            "\tif (!prepare_alloc_pages(gfp, 0, preferred_nid, nodemask, &ac, &alloc_gfp, &alloc_flags))",
            "\t\tgoto out;",
            "\tgfp = alloc_gfp;",
            "",
            "\t/* Find an allowed local zone that meets the low watermark. */",
            "\tz = ac.preferred_zoneref;",
            "\tfor_next_zone_zonelist_nodemask(zone, z, ac.highest_zoneidx, ac.nodemask) {",
            "\t\tunsigned long mark;",
            "",
            "\t\tif (cpusets_enabled() && (alloc_flags & ALLOC_CPUSET) &&",
            "\t\t    !__cpuset_zone_allowed(zone, gfp)) {",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tif (nr_online_nodes > 1 && zone != ac.preferred_zoneref->zone &&",
            "\t\t    zone_to_nid(zone) != zone_to_nid(ac.preferred_zoneref->zone)) {",
            "\t\t\tgoto failed;",
            "\t\t}",
            "",
            "\t\tmark = wmark_pages(zone, alloc_flags & ALLOC_WMARK_MASK) + nr_pages;",
            "\t\tif (zone_watermark_fast(zone, 0,  mark,",
            "\t\t\t\tzonelist_zone_idx(ac.preferred_zoneref),",
            "\t\t\t\talloc_flags, gfp)) {",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * If there are no allowed local zones that meets the watermarks then",
            "\t * try to allocate a single page and reclaim if necessary.",
            "\t */",
            "\tif (unlikely(!zone))",
            "\t\tgoto failed;",
            "",
            "\t/* spin_trylock may fail due to a parallel drain or IRQ reentrancy. */",
            "\tpcp_trylock_prepare(UP_flags);",
            "\tpcp = pcp_spin_trylock(zone->per_cpu_pageset);",
            "\tif (!pcp)",
            "\t\tgoto failed_irq;",
            "",
            "\t/* Attempt the batch allocation */",
            "\tpcp_list = &pcp->lists[order_to_pindex(ac.migratetype, 0)];",
            "\twhile (nr_populated < nr_pages) {",
            "",
            "\t\t/* Skip existing pages */",
            "\t\tif (page_array && page_array[nr_populated]) {",
            "\t\t\tnr_populated++;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tpage = __rmqueue_pcplist(zone, 0, ac.migratetype, alloc_flags,",
            "\t\t\t\t\t\t\t\tpcp, pcp_list);",
            "\t\tif (unlikely(!page)) {",
            "\t\t\t/* Try and allocate at least one page */",
            "\t\t\tif (!nr_account) {",
            "\t\t\t\tpcp_spin_unlock(pcp);",
            "\t\t\t\tgoto failed_irq;",
            "\t\t\t}",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tnr_account++;",
            "",
            "\t\tprep_new_page(page, 0, gfp, 0);",
            "\t\tif (page_list)",
            "\t\t\tlist_add(&page->lru, page_list);",
            "\t\telse",
            "\t\t\tpage_array[nr_populated] = page;",
            "\t\tnr_populated++;",
            "\t}",
            "",
            "\tpcp_spin_unlock(pcp);",
            "\tpcp_trylock_finish(UP_flags);",
            "",
            "\t__count_zid_vm_events(PGALLOC, zone_idx(zone), nr_account);",
            "\tzone_statistics(ac.preferred_zoneref->zone, zone, nr_account);",
            "",
            "out:",
            "\treturn nr_populated;",
            "",
            "failed_irq:",
            "\tpcp_trylock_finish(UP_flags);",
            "",
            "failed:",
            "\tpage = __alloc_pages_noprof(gfp, 0, preferred_nid, nodemask);",
            "\tif (page) {",
            "\t\tif (page_list)",
            "\t\t\tlist_add(&page->lru, page_list);",
            "\t\telse",
            "\t\t\tpage_array[nr_populated] = page;",
            "\t\tnr_populated++;",
            "\t}",
            "",
            "\tgoto out;",
            "}"
          ],
          "function_name": "prepare_alloc_pages, alloc_pages_bulk_noprof",
          "description": "该代码段实现了内存页面的批量分配逻辑，其中`prepare_alloc_pages`用于初始化分配上下文参数并配置内存策略，`alloc_pages_bulk_noprof`则通过遍历内存区域尝试批量分配连续页面，优先使用本地节点且支持CPU集约束。  \n`prepare_alloc_pages`构建分配上下文，设置Zone列表、迁移类型及节点掩码，处理CPU集隔离与水位线检查；`alloc_pages_bulk_noprof`在满足水位线前提下批量分配页面，失败时回退至单页分配。  \n上下文完整，未引入未展示的API或机制。",
          "similarity": 0.6055178642272949
        },
        {
          "chunk_id": 21,
          "file_path": "mm/page_alloc.c",
          "start_line": 3958,
          "end_line": 4058,
          "content": [
            "static void wake_all_kswapds(unsigned int order, gfp_t gfp_mask,",
            "\t\t\t     const struct alloc_context *ac)",
            "{",
            "\tstruct zoneref *z;",
            "\tstruct zone *zone;",
            "\tpg_data_t *last_pgdat = NULL;",
            "\tenum zone_type highest_zoneidx = ac->highest_zoneidx;",
            "",
            "\tfor_each_zone_zonelist_nodemask(zone, z, ac->zonelist, highest_zoneidx,",
            "\t\t\t\t\tac->nodemask) {",
            "\t\tif (!managed_zone(zone))",
            "\t\t\tcontinue;",
            "\t\tif (last_pgdat != zone->zone_pgdat) {",
            "\t\t\twakeup_kswapd(zone, gfp_mask, order, highest_zoneidx);",
            "\t\t\tlast_pgdat = zone->zone_pgdat;",
            "\t\t}",
            "\t}",
            "}",
            "static inline unsigned int",
            "gfp_to_alloc_flags(gfp_t gfp_mask, unsigned int order)",
            "{",
            "\tunsigned int alloc_flags = ALLOC_WMARK_MIN | ALLOC_CPUSET;",
            "",
            "\t/*",
            "\t * __GFP_HIGH is assumed to be the same as ALLOC_MIN_RESERVE",
            "\t * and __GFP_KSWAPD_RECLAIM is assumed to be the same as ALLOC_KSWAPD",
            "\t * to save two branches.",
            "\t */",
            "\tBUILD_BUG_ON(__GFP_HIGH != (__force gfp_t) ALLOC_MIN_RESERVE);",
            "\tBUILD_BUG_ON(__GFP_KSWAPD_RECLAIM != (__force gfp_t) ALLOC_KSWAPD);",
            "",
            "\t/*",
            "\t * The caller may dip into page reserves a bit more if the caller",
            "\t * cannot run direct reclaim, or if the caller has realtime scheduling",
            "\t * policy or is asking for __GFP_HIGH memory.  GFP_ATOMIC requests will",
            "\t * set both ALLOC_NON_BLOCK and ALLOC_MIN_RESERVE(__GFP_HIGH).",
            "\t */",
            "\talloc_flags |= (__force int)",
            "\t\t(gfp_mask & (__GFP_HIGH | __GFP_KSWAPD_RECLAIM));",
            "",
            "\tif (!(gfp_mask & __GFP_DIRECT_RECLAIM)) {",
            "\t\t/*",
            "\t\t * Not worth trying to allocate harder for __GFP_NOMEMALLOC even",
            "\t\t * if it can't schedule.",
            "\t\t */",
            "\t\tif (!(gfp_mask & __GFP_NOMEMALLOC)) {",
            "\t\t\talloc_flags |= ALLOC_NON_BLOCK;",
            "",
            "\t\t\tif (order > 0)",
            "\t\t\t\talloc_flags |= ALLOC_HIGHATOMIC;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Ignore cpuset mems for non-blocking __GFP_HIGH (probably",
            "\t\t * GFP_ATOMIC) rather than fail, see the comment for",
            "\t\t * cpuset_node_allowed().",
            "\t\t */",
            "\t\tif (alloc_flags & ALLOC_MIN_RESERVE)",
            "\t\t\talloc_flags &= ~ALLOC_CPUSET;",
            "\t} else if (unlikely(rt_or_dl_task(current)) && in_task())",
            "\t\talloc_flags |= ALLOC_MIN_RESERVE;",
            "",
            "\talloc_flags = gfp_to_alloc_flags_cma(gfp_mask, alloc_flags);",
            "",
            "\treturn alloc_flags;",
            "}",
            "static bool oom_reserves_allowed(struct task_struct *tsk)",
            "{",
            "\tif (!tsk_is_oom_victim(tsk))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * !MMU doesn't have oom reaper so give access to memory reserves",
            "\t * only to the thread with TIF_MEMDIE set",
            "\t */",
            "\tif (!IS_ENABLED(CONFIG_MMU) && !test_thread_flag(TIF_MEMDIE))",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}",
            "static inline int __gfp_pfmemalloc_flags(gfp_t gfp_mask)",
            "{",
            "\tif (unlikely(gfp_mask & __GFP_NOMEMALLOC))",
            "\t\treturn 0;",
            "\tif (gfp_mask & __GFP_MEMALLOC)",
            "\t\treturn ALLOC_NO_WATERMARKS;",
            "\tif (in_serving_softirq() && (current->flags & PF_MEMALLOC))",
            "\t\treturn ALLOC_NO_WATERMARKS;",
            "\tif (!in_interrupt()) {",
            "\t\tif (current->flags & PF_MEMALLOC)",
            "\t\t\treturn ALLOC_NO_WATERMARKS;",
            "\t\telse if (oom_reserves_allowed(current))",
            "\t\t\treturn ALLOC_OOM;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "bool gfp_pfmemalloc_allowed(gfp_t gfp_mask)",
            "{",
            "\treturn !!__gfp_pfmemalloc_flags(gfp_mask);",
            "}"
          ],
          "function_name": "wake_all_kswapds, gfp_to_alloc_flags, oom_reserves_allowed, __gfp_pfmemalloc_flags, gfp_pfmemalloc_allowed",
          "description": "该代码段主要处理内存分配时的策略配置与回收机制。  \n`wake_all_kswapds` 遍历内存区并唤醒对应 kswapd 线程以触发页面回收；`gfp_to_alloc_flags` 根据 GFP 标志计算分配策略标志，控制内存回收行为；`oom_reserves_allowed` 和 `__gfp_pfmemalloc_flags` 共同决定是否允许绕过内存水印限制访问 OOM 预留内存。",
          "similarity": 0.5993417501449585
        },
        {
          "chunk_id": 19,
          "file_path": "mm/page_alloc.c",
          "start_line": 3493,
          "end_line": 3599,
          "content": [
            "static void warn_alloc_show_mem(gfp_t gfp_mask, nodemask_t *nodemask)",
            "{",
            "\tunsigned int filter = SHOW_MEM_FILTER_NODES;",
            "",
            "\t/*",
            "\t * This documents exceptions given to allocations in certain",
            "\t * contexts that are allowed to allocate outside current's set",
            "\t * of allowed nodes.",
            "\t */",
            "\tif (!(gfp_mask & __GFP_NOMEMALLOC))",
            "\t\tif (tsk_is_oom_victim(current) ||",
            "\t\t    (current->flags & (PF_MEMALLOC | PF_EXITING)))",
            "\t\t\tfilter &= ~SHOW_MEM_FILTER_NODES;",
            "\tif (!in_task() || !(gfp_mask & __GFP_DIRECT_RECLAIM))",
            "\t\tfilter &= ~SHOW_MEM_FILTER_NODES;",
            "",
            "\t__show_mem(filter, nodemask, gfp_zone(gfp_mask));",
            "}",
            "void warn_alloc(gfp_t gfp_mask, nodemask_t *nodemask, const char *fmt, ...)",
            "{",
            "\tstruct va_format vaf;",
            "\tva_list args;",
            "\tstatic DEFINE_RATELIMIT_STATE(nopage_rs, 10*HZ, 1);",
            "",
            "\tif ((gfp_mask & __GFP_NOWARN) ||",
            "\t     !__ratelimit(&nopage_rs) ||",
            "\t     ((gfp_mask & __GFP_DMA) && !has_managed_dma()))",
            "\t\treturn;",
            "",
            "\tva_start(args, fmt);",
            "\tvaf.fmt = fmt;",
            "\tvaf.va = &args;",
            "\tpr_warn(\"%s: %pV, mode:%#x(%pGg), nodemask=%*pbl\",",
            "\t\t\tcurrent->comm, &vaf, gfp_mask, &gfp_mask,",
            "\t\t\tnodemask_pr_args(nodemask));",
            "\tva_end(args);",
            "",
            "\tcpuset_print_current_mems_allowed();",
            "\tpr_cont(\"\\n\");",
            "\tdump_stack();",
            "\twarn_alloc_show_mem(gfp_mask, nodemask);",
            "}",
            "static inline bool",
            "should_compact_retry(struct alloc_context *ac, int order, int alloc_flags,",
            "\t\t     enum compact_result compact_result,",
            "\t\t     enum compact_priority *compact_priority,",
            "\t\t     int *compaction_retries)",
            "{",
            "\tint max_retries = MAX_COMPACT_RETRIES;",
            "\tint min_priority;",
            "\tbool ret = false;",
            "\tint retries = *compaction_retries;",
            "\tenum compact_priority priority = *compact_priority;",
            "",
            "\tif (!order)",
            "\t\treturn false;",
            "",
            "\tif (fatal_signal_pending(current))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Compaction was skipped due to a lack of free order-0",
            "\t * migration targets. Continue if reclaim can help.",
            "\t */",
            "\tif (compact_result == COMPACT_SKIPPED) {",
            "\t\tret = compaction_zonelist_suitable(ac, order, alloc_flags);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * Compaction managed to coalesce some page blocks, but the",
            "\t * allocation failed presumably due to a race. Retry some.",
            "\t */",
            "\tif (compact_result == COMPACT_SUCCESS) {",
            "\t\t/*",
            "\t\t * !costly requests are much more important than",
            "\t\t * __GFP_RETRY_MAYFAIL costly ones because they are de",
            "\t\t * facto nofail and invoke OOM killer to move on while",
            "\t\t * costly can fail and users are ready to cope with",
            "\t\t * that. 1/4 retries is rather arbitrary but we would",
            "\t\t * need much more detailed feedback from compaction to",
            "\t\t * make a better decision.",
            "\t\t */",
            "\t\tif (order > PAGE_ALLOC_COSTLY_ORDER)",
            "\t\t\tmax_retries /= 4;",
            "",
            "\t\tif (++(*compaction_retries) <= max_retries) {",
            "\t\t\tret = true;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * Compaction failed. Retry with increasing priority.",
            "\t */",
            "\tmin_priority = (order > PAGE_ALLOC_COSTLY_ORDER) ?",
            "\t\t\tMIN_COMPACT_COSTLY_PRIORITY : MIN_COMPACT_PRIORITY;",
            "",
            "\tif (*compact_priority > min_priority) {",
            "\t\t(*compact_priority)--;",
            "\t\t*compaction_retries = 0;",
            "\t\tret = true;",
            "\t}",
            "out:",
            "\ttrace_compact_retry(order, priority, compact_result, retries, max_retries, ret);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "warn_alloc_show_mem, warn_alloc, should_compact_retry",
          "description": "warn_alloc_show_mem 显示详细内存状态信息用于警告；warn_alloc 在内存不足时记录警告日志并触发栈跟踪；should_compact_retry 根据紧凑结果和策略决定是否重试分配，针对不同订单级别调整重试次数和优先级。",
          "similarity": 0.5926892161369324
        },
        {
          "chunk_id": 34,
          "file_path": "mm/page_alloc.c",
          "start_line": 6473,
          "end_line": 6610,
          "content": [
            "static void split_free_pages(struct list_head *list)",
            "{",
            "\tint order;",
            "",
            "\tfor (order = 0; order < NR_PAGE_ORDERS; order++) {",
            "\t\tstruct page *page, *next;",
            "\t\tint nr_pages = 1 << order;",
            "",
            "\t\tlist_for_each_entry_safe(page, next, &list[order], lru) {",
            "\t\t\tint i;",
            "",
            "\t\t\tpost_alloc_hook(page, order, __GFP_MOVABLE);",
            "\t\t\tif (!order)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tsplit_page(page, order);",
            "",
            "\t\t\t/* Add all subpages to the order-0 head, in sequence. */",
            "\t\t\tlist_del(&page->lru);",
            "\t\t\tfor (i = 0; i < nr_pages; i++)",
            "\t\t\t\tlist_add_tail(&page[i].lru, &list[0]);",
            "\t\t}",
            "\t}",
            "}",
            "int alloc_contig_range_noprof(unsigned long start, unsigned long end,",
            "\t\t       unsigned migratetype, gfp_t gfp_mask)",
            "{",
            "\tunsigned long outer_start, outer_end;",
            "\tint ret = 0;",
            "",
            "\tstruct compact_control cc = {",
            "\t\t.nr_migratepages = 0,",
            "\t\t.order = -1,",
            "\t\t.zone = page_zone(pfn_to_page(start)),",
            "\t\t.mode = MIGRATE_SYNC,",
            "\t\t.ignore_skip_hint = true,",
            "\t\t.no_set_skip_hint = true,",
            "\t\t.gfp_mask = current_gfp_context(gfp_mask),",
            "\t\t.alloc_contig = true,",
            "\t};",
            "\tINIT_LIST_HEAD(&cc.migratepages);",
            "",
            "\t/*",
            "\t * What we do here is we mark all pageblocks in range as",
            "\t * MIGRATE_ISOLATE.  Because pageblock and max order pages may",
            "\t * have different sizes, and due to the way page allocator",
            "\t * work, start_isolate_page_range() has special handlings for this.",
            "\t *",
            "\t * Once the pageblocks are marked as MIGRATE_ISOLATE, we",
            "\t * migrate the pages from an unaligned range (ie. pages that",
            "\t * we are interested in). This will put all the pages in",
            "\t * range back to page allocator as MIGRATE_ISOLATE.",
            "\t *",
            "\t * When this is done, we take the pages in range from page",
            "\t * allocator removing them from the buddy system.  This way",
            "\t * page allocator will never consider using them.",
            "\t *",
            "\t * This lets us mark the pageblocks back as",
            "\t * MIGRATE_CMA/MIGRATE_MOVABLE so that free pages in the",
            "\t * aligned range but not in the unaligned, original range are",
            "\t * put back to page allocator so that buddy can use them.",
            "\t */",
            "",
            "\tret = start_isolate_page_range(start, end, migratetype, 0, gfp_mask);",
            "\tif (ret)",
            "\t\tgoto done;",
            "",
            "\tdrain_all_pages(cc.zone);",
            "",
            "\t/*",
            "\t * In case of -EBUSY, we'd like to know which page causes problem.",
            "\t * So, just fall through. test_pages_isolated() has a tracepoint",
            "\t * which will report the busy page.",
            "\t *",
            "\t * It is possible that busy pages could become available before",
            "\t * the call to test_pages_isolated, and the range will actually be",
            "\t * allocated.  So, if we fall through be sure to clear ret so that",
            "\t * -EBUSY is not accidentally used or returned to caller.",
            "\t */",
            "\tret = __alloc_contig_migrate_range(&cc, start, end, migratetype);",
            "\tif (ret && ret != -EBUSY)",
            "\t\tgoto done;",
            "\tret = 0;",
            "",
            "\t/*",
            "\t * Pages from [start, end) are within a pageblock_nr_pages",
            "\t * aligned blocks that are marked as MIGRATE_ISOLATE.  What's",
            "\t * more, all pages in [start, end) are free in page allocator.",
            "\t * What we are going to do is to allocate all pages from",
            "\t * [start, end) (that is remove them from page allocator).",
            "\t *",
            "\t * The only problem is that pages at the beginning and at the",
            "\t * end of interesting range may be not aligned with pages that",
            "\t * page allocator holds, ie. they can be part of higher order",
            "\t * pages.  Because of this, we reserve the bigger range and",
            "\t * once this is done free the pages we are not interested in.",
            "\t *",
            "\t * We don't have to hold zone->lock here because the pages are",
            "\t * isolated thus they won't get removed from buddy.",
            "\t */",
            "\touter_start = find_large_buddy(start);",
            "",
            "\t/* Make sure the range is really isolated. */",
            "\tif (test_pages_isolated(outer_start, end, 0)) {",
            "\t\tret = -EBUSY;",
            "\t\tgoto done;",
            "\t}",
            "",
            "\t/* Grab isolated pages from freelists. */",
            "\touter_end = isolate_freepages_range(&cc, outer_start, end);",
            "\tif (!outer_end) {",
            "\t\tret = -EBUSY;",
            "\t\tgoto done;",
            "\t}",
            "",
            "\tif (!(gfp_mask & __GFP_COMP)) {",
            "\t\tsplit_free_pages(cc.freepages);",
            "",
            "\t\t/* Free head and tail (if any) */",
            "\t\tif (start != outer_start)",
            "\t\t\tfree_contig_range(outer_start, start - outer_start);",
            "\t\tif (end != outer_end)",
            "\t\t\tfree_contig_range(end, outer_end - end);",
            "\t} else if (start == outer_start && end == outer_end && is_power_of_2(end - start)) {",
            "\t\tstruct page *head = pfn_to_page(start);",
            "\t\tint order = ilog2(end - start);",
            "",
            "\t\tcheck_new_pages(head, order);",
            "\t\tprep_new_page(head, order, gfp_mask, 0);",
            "\t} else {",
            "\t\tret = -EINVAL;",
            "\t\tWARN(true, \"PFN range: requested [%lu, %lu), allocated [%lu, %lu)\\n\",",
            "\t\t     start, end, outer_start, outer_end);",
            "\t}",
            "done:",
            "\tundo_isolate_page_range(start, end, migratetype);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "split_free_pages, alloc_contig_range_noprof",
          "description": "实现连续物理内存范围分配功能，通过隔离页面块、迁移页面和调整区域状态，确保目标范围内内存可被系统使用并处理分配异常情况。",
          "similarity": 0.5889154672622681
        }
      ]
    },
    {
      "source_file": "kernel/resource.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:53:12\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `resource.c`\n\n---\n\n# resource.c 技术文档\n\n## 1. 文件概述\n\n`resource.c` 是 Linux 内核中用于管理和分配系统资源（如 I/O 端口和内存区域）的核心实现文件。它提供了一套通用的资源树管理机制，支持资源的申请、释放、查找和冲突检测。该文件维护了两个全局根资源节点：`ioport_resource`（用于 I/O 端口空间）和 `iomem_resource`（用于内存映射 I/O 空间），并通过树形结构组织所有已分配的子资源，确保资源分配的唯一性和安全性。\n\n## 2. 核心功能\n\n### 主要全局数据结构\n- `struct resource ioport_resource`：I/O 端口资源的根节点，范围为 `[0, IO_SPACE_LIMIT]`，标志为 `IORESOURCE_IO`。\n- `struct resource iomem_resource`：内存映射 I/O 资源的根节点，范围为 `[0, -1]`（即全地址空间），标志为 `IORESOURCE_MEM`。\n- `struct resource_constraint`：用于描述资源分配时的约束条件（最小/最大地址、对齐要求及自定义对齐函数）。\n\n### 关键函数\n- `request_resource(struct resource *root, struct resource *new)`：尝试在指定根资源下申请一段新资源，成功返回 0，冲突返回 `-EBUSY`。\n- `request_resource_conflict(...)`：与 `request_resource` 类似，但冲突时直接返回冲突的资源指针。\n- `release_resource(struct resource *old)`：释放已分配的资源。\n- `release_child_resources(struct resource *r)`：递归释放指定资源的所有子资源。\n- `find_next_iomem_res(...)`：在 `iomem_resource` 树中查找与指定区间 `[start, end]` 重叠且满足标志和描述符条件的下一个内存资源。\n- `for_each_resource` 宏：遍历资源树的通用宏，支持是否跳过子树的选项。\n\n### /proc 接口（条件编译）\n- 通过 `CONFIG_PROC_FS` 启用时，注册 `/proc/ioports` 和 `/proc/iomem` 文件，以树形格式展示当前系统中已分配的 I/O 端口和内存资源（仅对 `CAP_SYS_ADMIN` 权限用户显示实际地址）。\n\n## 3. 关键实现\n\n### 资源树结构\n- 资源以多叉树形式组织，每个 `struct resource` 包含 `child`（第一个子节点）、`sibling`（下一个兄弟节点）和 `parent` 指针。\n- 树内节点按起始地址升序排列，便于快速查找和插入。\n\n### 资源申请（`__request_resource`）\n- 在持有写锁 `resource_lock` 的前提下，遍历根节点的子链表。\n- 若新资源与现有节点无重叠，则按地址顺序插入；若存在重叠，则返回冲突节点。\n- 插入操作维护树的有序性：新节点插入到第一个起始地址大于其结束地址的节点之前。\n\n### 资源释放（`__release_resource`）\n- 支持两种模式：完全释放（含子资源）或仅提升子资源（当 `release_child=false` 时，将子节点直接挂到父节点下）。\n- 释放时调整兄弟链表指针，确保树结构完整性。\n\n### 资源遍历\n- `next_resource()`：深度优先遍历（先子节点，再兄弟节点）。\n- `next_resource_skip_children()`：仅遍历同级兄弟节点，跳过子树。\n- `/proc` 显示使用深度优先遍历，并限制最大显示层级（`MAX_IORES_LEVEL=5`）以避免过深嵌套。\n\n### 内存管理\n- 资源结构体通过 `alloc_resource()`（即 `kzalloc`）分配，通过 `free_resource()` 释放。\n- 注释指出：若资源由早期 `memblock` 分配，则无法安全释放（因非页对齐），会轻微泄漏，这是有意为之的简化设计。\n\n### 并发控制\n- 使用读写锁 `resource_lock` 保护全局资源树：\n  - 读操作（如 `/proc` 显示、`find_next_iomem_res`）使用 `read_lock`。\n  - 写操作（申请/释放资源）使用 `write_lock`。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/ioport.h>`：定义 `struct resource` 及相关宏（如 `IORESOURCE_IO`）。\n  - `<linux/proc_fs.h>`、`<linux/seq_file.h>`：实现 `/proc` 接口。\n  - `<linux/slab.h>`：资源结构体的动态分配。\n  - `<linux/spinlock.h>`：读写锁 `resource_lock` 的实现。\n  - `<asm/io.h>`：架构相关的 I/O 定义（如 `IO_SPACE_LIMIT`）。\n- **导出符号**：\n  - `ioport_resource`、`iomem_resource`、`request_resource`、`release_resource` 通过 `EXPORT_SYMBOL` 导出，供其他内核模块（如 PCI、platform_device 驱动）使用。\n- **配置依赖**：\n  - `/proc` 接口依赖 `CONFIG_PROC_FS`。\n\n## 5. 使用场景\n\n- **设备驱动资源管理**：PCI、platform 等总线驱动在探测设备时，调用 `request_resource()` 申请 I/O 端口或内存区域，防止资源冲突。\n- **固件/ACPI 资源解析**：内核解析 ACPI 表或 EFI 内存映射时，将保留区域注册到 `iomem_resource` 树中。\n- **系统调试与监控**：用户空间通过 `/proc/ioports` 和 `/proc/iomem` 查看硬件资源分配情况（需 root 权限）。\n- **内核子系统协作**：内存管理子系统（如 `devm_request_mem_region`）、DMA 引擎等依赖此机制确保物理地址资源的独占使用。\n- **热插拔支持**：设备移除时调用 `release_resource()` 释放资源，供后续设备重用。",
      "similarity": 0.626821756362915,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/resource.c",
          "start_line": 637,
          "end_line": 763,
          "content": [
            "int region_intersects(resource_size_t start, size_t size, unsigned long flags,",
            "\t\t      unsigned long desc)",
            "{",
            "\tint ret;",
            "",
            "\tread_lock(&resource_lock);",
            "\tret = __region_intersects(&iomem_resource, start, size, flags, desc);",
            "\tread_unlock(&resource_lock);",
            "",
            "\treturn ret;",
            "}",
            "void __weak arch_remove_reservations(struct resource *avail)",
            "{",
            "}",
            "static resource_size_t simple_align_resource(void *data,",
            "\t\t\t\t\t     const struct resource *avail,",
            "\t\t\t\t\t     resource_size_t size,",
            "\t\t\t\t\t     resource_size_t align)",
            "{",
            "\treturn avail->start;",
            "}",
            "static void resource_clip(struct resource *res, resource_size_t min,",
            "\t\t\t  resource_size_t max)",
            "{",
            "\tif (res->start < min)",
            "\t\tres->start = min;",
            "\tif (res->end > max)",
            "\t\tres->end = max;",
            "}",
            "static int __find_resource(struct resource *root, struct resource *old,",
            "\t\t\t struct resource *new,",
            "\t\t\t resource_size_t  size,",
            "\t\t\t struct resource_constraint *constraint)",
            "{",
            "\tstruct resource *this = root->child;",
            "\tstruct resource tmp = *new, avail, alloc;",
            "",
            "\ttmp.start = root->start;",
            "\t/*",
            "\t * Skip past an allocated resource that starts at 0, since the assignment",
            "\t * of this->start - 1 to tmp->end below would cause an underflow.",
            "\t */",
            "\tif (this && this->start == root->start) {",
            "\t\ttmp.start = (this == old) ? old->start : this->end + 1;",
            "\t\tthis = this->sibling;",
            "\t}",
            "\tfor(;;) {",
            "\t\tif (this)",
            "\t\t\ttmp.end = (this == old) ?  this->end : this->start - 1;",
            "\t\telse",
            "\t\t\ttmp.end = root->end;",
            "",
            "\t\tif (tmp.end < tmp.start)",
            "\t\t\tgoto next;",
            "",
            "\t\tresource_clip(&tmp, constraint->min, constraint->max);",
            "\t\tarch_remove_reservations(&tmp);",
            "",
            "\t\t/* Check for overflow after ALIGN() */",
            "\t\tavail.start = ALIGN(tmp.start, constraint->align);",
            "\t\tavail.end = tmp.end;",
            "\t\tavail.flags = new->flags & ~IORESOURCE_UNSET;",
            "\t\tif (avail.start >= tmp.start) {",
            "\t\t\talloc.flags = avail.flags;",
            "\t\t\talloc.start = constraint->alignf(constraint->alignf_data, &avail,",
            "\t\t\t\t\tsize, constraint->align);",
            "\t\t\talloc.end = alloc.start + size - 1;",
            "\t\t\tif (alloc.start <= alloc.end &&",
            "\t\t\t    resource_contains(&avail, &alloc)) {",
            "\t\t\t\tnew->start = alloc.start;",
            "\t\t\t\tnew->end = alloc.end;",
            "\t\t\t\treturn 0;",
            "\t\t\t}",
            "\t\t}",
            "",
            "next:\t\tif (!this || this->end == root->end)",
            "\t\t\tbreak;",
            "",
            "\t\tif (this != old)",
            "\t\t\ttmp.start = this->end + 1;",
            "\t\tthis = this->sibling;",
            "\t}",
            "\treturn -EBUSY;",
            "}",
            "static int find_resource(struct resource *root, struct resource *new,",
            "\t\t\tresource_size_t size,",
            "\t\t\tstruct resource_constraint  *constraint)",
            "{",
            "\treturn  __find_resource(root, NULL, new, size, constraint);",
            "}",
            "static int reallocate_resource(struct resource *root, struct resource *old,",
            "\t\t\t       resource_size_t newsize,",
            "\t\t\t       struct resource_constraint *constraint)",
            "{",
            "\tint err=0;",
            "\tstruct resource new = *old;",
            "\tstruct resource *conflict;",
            "",
            "\twrite_lock(&resource_lock);",
            "",
            "\tif ((err = __find_resource(root, old, &new, newsize, constraint)))",
            "\t\tgoto out;",
            "",
            "\tif (resource_contains(&new, old)) {",
            "\t\told->start = new.start;",
            "\t\told->end = new.end;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (old->child) {",
            "\t\terr = -EBUSY;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (resource_contains(old, &new)) {",
            "\t\told->start = new.start;",
            "\t\told->end = new.end;",
            "\t} else {",
            "\t\t__release_resource(old, true);",
            "\t\t*old = new;",
            "\t\tconflict = __request_resource(root, old);",
            "\t\tBUG_ON(conflict);",
            "\t}",
            "out:",
            "\twrite_unlock(&resource_lock);",
            "\treturn err;",
            "}"
          ],
          "function_name": "region_intersects, arch_remove_reservations, simple_align_resource, resource_clip, __find_resource, find_resource, reallocate_resource",
          "description": "实现资源分配策略核心逻辑，包含资源位置查找、尺寸调整、冲突检测等关键功能，支持带约束条件的资源重新分配与位置确定。",
          "similarity": 0.6388239860534668
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/resource.c",
          "start_line": 1072,
          "end_line": 1180,
          "content": [
            "int adjust_resource(struct resource *res, resource_size_t start,",
            "\t\t    resource_size_t size)",
            "{",
            "\tint result;",
            "",
            "\twrite_lock(&resource_lock);",
            "\tresult = __adjust_resource(res, start, size);",
            "\twrite_unlock(&resource_lock);",
            "\treturn result;",
            "}",
            "static void __init",
            "__reserve_region_with_split(struct resource *root, resource_size_t start,",
            "\t\t\t    resource_size_t end, const char *name)",
            "{",
            "\tstruct resource *parent = root;",
            "\tstruct resource *conflict;",
            "\tstruct resource *res = alloc_resource(GFP_ATOMIC);",
            "\tstruct resource *next_res = NULL;",
            "\tint type = resource_type(root);",
            "",
            "\tif (!res)",
            "\t\treturn;",
            "",
            "\tres->name = name;",
            "\tres->start = start;",
            "\tres->end = end;",
            "\tres->flags = type | IORESOURCE_BUSY;",
            "\tres->desc = IORES_DESC_NONE;",
            "",
            "\twhile (1) {",
            "",
            "\t\tconflict = __request_resource(parent, res);",
            "\t\tif (!conflict) {",
            "\t\t\tif (!next_res)",
            "\t\t\t\tbreak;",
            "\t\t\tres = next_res;",
            "\t\t\tnext_res = NULL;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\t/* conflict covered whole area */",
            "\t\tif (conflict->start <= res->start &&",
            "\t\t\t\tconflict->end >= res->end) {",
            "\t\t\tfree_resource(res);",
            "\t\t\tWARN_ON(next_res);",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\t/* failed, split and try again */",
            "\t\tif (conflict->start > res->start) {",
            "\t\t\tend = res->end;",
            "\t\t\tres->end = conflict->start - 1;",
            "\t\t\tif (conflict->end < end) {",
            "\t\t\t\tnext_res = alloc_resource(GFP_ATOMIC);",
            "\t\t\t\tif (!next_res) {",
            "\t\t\t\t\tfree_resource(res);",
            "\t\t\t\t\tbreak;",
            "\t\t\t\t}",
            "\t\t\t\tnext_res->name = name;",
            "\t\t\t\tnext_res->start = conflict->end + 1;",
            "\t\t\t\tnext_res->end = end;",
            "\t\t\t\tnext_res->flags = type | IORESOURCE_BUSY;",
            "\t\t\t\tnext_res->desc = IORES_DESC_NONE;",
            "\t\t\t}",
            "\t\t} else {",
            "\t\t\tres->start = conflict->end + 1;",
            "\t\t}",
            "\t}",
            "",
            "}",
            "void __init",
            "reserve_region_with_split(struct resource *root, resource_size_t start,",
            "\t\t\t  resource_size_t end, const char *name)",
            "{",
            "\tint abort = 0;",
            "",
            "\twrite_lock(&resource_lock);",
            "\tif (root->start > start || root->end < end) {",
            "\t\tpr_err(\"requested range [0x%llx-0x%llx] not in root %pr\\n\",",
            "\t\t       (unsigned long long)start, (unsigned long long)end,",
            "\t\t       root);",
            "\t\tif (start > root->end || end < root->start)",
            "\t\t\tabort = 1;",
            "\t\telse {",
            "\t\t\tif (end > root->end)",
            "\t\t\t\tend = root->end;",
            "\t\t\tif (start < root->start)",
            "\t\t\t\tstart = root->start;",
            "\t\t\tpr_err(\"fixing request to [0x%llx-0x%llx]\\n\",",
            "\t\t\t       (unsigned long long)start,",
            "\t\t\t       (unsigned long long)end);",
            "\t\t}",
            "\t\tdump_stack();",
            "\t}",
            "\tif (!abort)",
            "\t\t__reserve_region_with_split(root, start, end, name);",
            "\twrite_unlock(&resource_lock);",
            "}",
            "resource_size_t resource_alignment(struct resource *res)",
            "{",
            "\tswitch (res->flags & (IORESOURCE_SIZEALIGN | IORESOURCE_STARTALIGN)) {",
            "\tcase IORESOURCE_SIZEALIGN:",
            "\t\treturn resource_size(res);",
            "\tcase IORESOURCE_STARTALIGN:",
            "\t\treturn res->start;",
            "\tdefault:",
            "\t\treturn 0;",
            "\t}",
            "}"
          ],
          "function_name": "adjust_resource, __reserve_region_with_split, reserve_region_with_split, resource_alignment",
          "description": "实现资源区域分裂分配逻辑，处理大范围资源请求时的冲突分裂与重叠区域处理，提供资源对齐策略查询接口。",
          "similarity": 0.6361249685287476
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/resource.c",
          "start_line": 802,
          "end_line": 912,
          "content": [
            "int allocate_resource(struct resource *root, struct resource *new,",
            "\t\t      resource_size_t size, resource_size_t min,",
            "\t\t      resource_size_t max, resource_size_t align,",
            "\t\t      resource_size_t (*alignf)(void *,",
            "\t\t\t\t\t\tconst struct resource *,",
            "\t\t\t\t\t\tresource_size_t,",
            "\t\t\t\t\t\tresource_size_t),",
            "\t\t      void *alignf_data)",
            "{",
            "\tint err;",
            "\tstruct resource_constraint constraint;",
            "",
            "\tif (!alignf)",
            "\t\talignf = simple_align_resource;",
            "",
            "\tconstraint.min = min;",
            "\tconstraint.max = max;",
            "\tconstraint.align = align;",
            "\tconstraint.alignf = alignf;",
            "\tconstraint.alignf_data = alignf_data;",
            "",
            "\tif ( new->parent ) {",
            "\t\t/* resource is already allocated, try reallocating with",
            "\t\t   the new constraints */",
            "\t\treturn reallocate_resource(root, new, size, &constraint);",
            "\t}",
            "",
            "\twrite_lock(&resource_lock);",
            "\terr = find_resource(root, new, size, &constraint);",
            "\tif (err >= 0 && __request_resource(root, new))",
            "\t\terr = -EBUSY;",
            "\twrite_unlock(&resource_lock);",
            "\treturn err;",
            "}",
            "int insert_resource(struct resource *parent, struct resource *new)",
            "{",
            "\tstruct resource *conflict;",
            "",
            "\tconflict = insert_resource_conflict(parent, new);",
            "\treturn conflict ? -EBUSY : 0;",
            "}",
            "void insert_resource_expand_to_fit(struct resource *root, struct resource *new)",
            "{",
            "\tif (new->parent)",
            "\t\treturn;",
            "",
            "\twrite_lock(&resource_lock);",
            "\tfor (;;) {",
            "\t\tstruct resource *conflict;",
            "",
            "\t\tconflict = __insert_resource(root, new);",
            "\t\tif (!conflict)",
            "\t\t\tbreak;",
            "\t\tif (conflict == root)",
            "\t\t\tbreak;",
            "",
            "\t\t/* Ok, expand resource to cover the conflict, then try again .. */",
            "\t\tif (conflict->start < new->start)",
            "\t\t\tnew->start = conflict->start;",
            "\t\tif (conflict->end > new->end)",
            "\t\t\tnew->end = conflict->end;",
            "",
            "\t\tpr_info(\"Expanded resource %s due to conflict with %s\\n\", new->name, conflict->name);",
            "\t}",
            "\twrite_unlock(&resource_lock);",
            "}",
            "int remove_resource(struct resource *old)",
            "{",
            "\tint retval;",
            "",
            "\twrite_lock(&resource_lock);",
            "\tretval = __release_resource(old, false);",
            "\twrite_unlock(&resource_lock);",
            "\treturn retval;",
            "}",
            "static int __adjust_resource(struct resource *res, resource_size_t start,",
            "\t\t\t\tresource_size_t size)",
            "{",
            "\tstruct resource *tmp, *parent = res->parent;",
            "\tresource_size_t end = start + size - 1;",
            "\tint result = -EBUSY;",
            "",
            "\tif (!parent)",
            "\t\tgoto skip;",
            "",
            "\tif ((start < parent->start) || (end > parent->end))",
            "\t\tgoto out;",
            "",
            "\tif (res->sibling && (res->sibling->start <= end))",
            "\t\tgoto out;",
            "",
            "\ttmp = parent->child;",
            "\tif (tmp != res) {",
            "\t\twhile (tmp->sibling != res)",
            "\t\t\ttmp = tmp->sibling;",
            "\t\tif (start <= tmp->end)",
            "\t\t\tgoto out;",
            "\t}",
            "",
            "skip:",
            "\tfor (tmp = res->child; tmp; tmp = tmp->sibling)",
            "\t\tif ((tmp->start < start) || (tmp->end > end))",
            "\t\t\tgoto out;",
            "",
            "\tres->start = start;",
            "\tres->end = end;",
            "\tresult = 0;",
            "",
            " out:",
            "\treturn result;",
            "}"
          ],
          "function_name": "allocate_resource, insert_resource, insert_resource_expand_to_fit, remove_resource, __adjust_resource",
          "description": "实现资源分配逻辑，支持带约束条件的资源查找与申请，处理资源冲突及扩展调整，提供基础资源管理框架。",
          "similarity": 0.634727418422699
        },
        {
          "chunk_id": 9,
          "file_path": "kernel/resource.c",
          "start_line": 1561,
          "end_line": 1661,
          "content": [
            "static void devm_resource_release(struct device *dev, void *ptr)",
            "{",
            "\tstruct resource **r = ptr;",
            "",
            "\trelease_resource(*r);",
            "}",
            "int devm_request_resource(struct device *dev, struct resource *root,",
            "\t\t\t  struct resource *new)",
            "{",
            "\tstruct resource *conflict, **ptr;",
            "",
            "\tptr = devres_alloc(devm_resource_release, sizeof(*ptr), GFP_KERNEL);",
            "\tif (!ptr)",
            "\t\treturn -ENOMEM;",
            "",
            "\t*ptr = new;",
            "",
            "\tconflict = request_resource_conflict(root, new);",
            "\tif (conflict) {",
            "\t\tdev_err(dev, \"resource collision: %pR conflicts with %s %pR\\n\",",
            "\t\t\tnew, conflict->name, conflict);",
            "\t\tdevres_free(ptr);",
            "\t\treturn -EBUSY;",
            "\t}",
            "",
            "\tdevres_add(dev, ptr);",
            "\treturn 0;",
            "}",
            "static int devm_resource_match(struct device *dev, void *res, void *data)",
            "{",
            "\tstruct resource **ptr = res;",
            "",
            "\treturn *ptr == data;",
            "}",
            "void devm_release_resource(struct device *dev, struct resource *new)",
            "{",
            "\tWARN_ON(devres_release(dev, devm_resource_release, devm_resource_match,",
            "\t\t\t       new));",
            "}",
            "static void devm_region_release(struct device *dev, void *res)",
            "{",
            "\tstruct region_devres *this = res;",
            "",
            "\t__release_region(this->parent, this->start, this->n);",
            "}",
            "static int devm_region_match(struct device *dev, void *res, void *match_data)",
            "{",
            "\tstruct region_devres *this = res, *match = match_data;",
            "",
            "\treturn this->parent == match->parent &&",
            "\t\tthis->start == match->start && this->n == match->n;",
            "}",
            "void __devm_release_region(struct device *dev, struct resource *parent,",
            "\t\t\t   resource_size_t start, resource_size_t n)",
            "{",
            "\tstruct region_devres match_data = { parent, start, n };",
            "",
            "\t__release_region(parent, start, n);",
            "\tWARN_ON(devres_destroy(dev, devm_region_release, devm_region_match,",
            "\t\t\t       &match_data));",
            "}",
            "static int __init reserve_setup(char *str)",
            "{",
            "\tstatic int reserved;",
            "\tstatic struct resource reserve[MAXRESERVE];",
            "",
            "\tfor (;;) {",
            "\t\tunsigned int io_start, io_num;",
            "\t\tint x = reserved;",
            "\t\tstruct resource *parent;",
            "",
            "\t\tif (get_option(&str, &io_start) != 2)",
            "\t\t\tbreak;",
            "\t\tif (get_option(&str, &io_num) == 0)",
            "\t\t\tbreak;",
            "\t\tif (x < MAXRESERVE) {",
            "\t\t\tstruct resource *res = reserve + x;",
            "",
            "\t\t\t/*",
            "\t\t\t * If the region starts below 0x10000, we assume it's",
            "\t\t\t * I/O port space; otherwise assume it's memory.",
            "\t\t\t */",
            "\t\t\tif (io_start < 0x10000) {",
            "\t\t\t\tres->flags = IORESOURCE_IO;",
            "\t\t\t\tparent = &ioport_resource;",
            "\t\t\t} else {",
            "\t\t\t\tres->flags = IORESOURCE_MEM;",
            "\t\t\t\tparent = &iomem_resource;",
            "\t\t\t}",
            "\t\t\tres->name = \"reserved\";",
            "\t\t\tres->start = io_start;",
            "\t\t\tres->end = io_start + io_num - 1;",
            "\t\t\tres->flags |= IORESOURCE_BUSY;",
            "\t\t\tres->desc = IORES_DESC_NONE;",
            "\t\t\tres->child = NULL;",
            "\t\t\tif (request_resource(parent, res) == 0)",
            "\t\t\t\treserved = x+1;",
            "\t\t}",
            "\t}",
            "\treturn 1;",
            "}"
          ],
          "function_name": "devm_resource_release, devm_request_resource, devm_resource_match, devm_release_resource, devm_region_release, devm_region_match, __devm_release_region, reserve_setup",
          "description": "实现设备资源管理器（devm）的资源申请/释放机制，包含预留资源初始化及设备资源生命周期绑定功能。",
          "similarity": 0.5904031991958618
        },
        {
          "chunk_id": 8,
          "file_path": "kernel/resource.c",
          "start_line": 1407,
          "end_line": 1533,
          "content": [
            "void release_mem_region_adjustable(resource_size_t start, resource_size_t size)",
            "{",
            "\tstruct resource *parent = &iomem_resource;",
            "\tstruct resource *new_res = NULL;",
            "\tbool alloc_nofail = false;",
            "\tstruct resource **p;",
            "\tstruct resource *res;",
            "\tresource_size_t end;",
            "",
            "\tend = start + size - 1;",
            "\tif (WARN_ON_ONCE((start < parent->start) || (end > parent->end)))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * We free up quite a lot of memory on memory hotunplug (esp., memap),",
            "\t * just before releasing the region. This is highly unlikely to",
            "\t * fail - let's play save and make it never fail as the caller cannot",
            "\t * perform any error handling (e.g., trying to re-add memory will fail",
            "\t * similarly).",
            "\t */",
            "retry:",
            "\tnew_res = alloc_resource(GFP_KERNEL | (alloc_nofail ? __GFP_NOFAIL : 0));",
            "",
            "\tp = &parent->child;",
            "\twrite_lock(&resource_lock);",
            "",
            "\twhile ((res = *p)) {",
            "\t\tif (res->start >= end)",
            "\t\t\tbreak;",
            "",
            "\t\t/* look for the next resource if it does not fit into */",
            "\t\tif (res->start > start || res->end < end) {",
            "\t\t\tp = &res->sibling;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tif (!(res->flags & IORESOURCE_MEM))",
            "\t\t\tbreak;",
            "",
            "\t\tif (!(res->flags & IORESOURCE_BUSY)) {",
            "\t\t\tp = &res->child;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\t/* found the target resource; let's adjust accordingly */",
            "\t\tif (res->start == start && res->end == end) {",
            "\t\t\t/* free the whole entry */",
            "\t\t\t*p = res->sibling;",
            "\t\t\tfree_resource(res);",
            "\t\t} else if (res->start == start && res->end != end) {",
            "\t\t\t/* adjust the start */",
            "\t\t\tWARN_ON_ONCE(__adjust_resource(res, end + 1,",
            "\t\t\t\t\t\t       res->end - end));",
            "\t\t} else if (res->start != start && res->end == end) {",
            "\t\t\t/* adjust the end */",
            "\t\t\tWARN_ON_ONCE(__adjust_resource(res, res->start,",
            "\t\t\t\t\t\t       start - res->start));",
            "\t\t} else {",
            "\t\t\t/* split into two entries - we need a new resource */",
            "\t\t\tif (!new_res) {",
            "\t\t\t\tnew_res = alloc_resource(GFP_ATOMIC);",
            "\t\t\t\tif (!new_res) {",
            "\t\t\t\t\talloc_nofail = true;",
            "\t\t\t\t\twrite_unlock(&resource_lock);",
            "\t\t\t\t\tgoto retry;",
            "\t\t\t\t}",
            "\t\t\t}",
            "\t\t\tnew_res->name = res->name;",
            "\t\t\tnew_res->start = end + 1;",
            "\t\t\tnew_res->end = res->end;",
            "\t\t\tnew_res->flags = res->flags;",
            "\t\t\tnew_res->desc = res->desc;",
            "\t\t\tnew_res->parent = res->parent;",
            "\t\t\tnew_res->sibling = res->sibling;",
            "\t\t\tnew_res->child = NULL;",
            "",
            "\t\t\tif (WARN_ON_ONCE(__adjust_resource(res, res->start,",
            "\t\t\t\t\t\t\t   start - res->start)))",
            "\t\t\t\tbreak;",
            "\t\t\tres->sibling = new_res;",
            "\t\t\tnew_res = NULL;",
            "\t\t}",
            "",
            "\t\tbreak;",
            "\t}",
            "",
            "\twrite_unlock(&resource_lock);",
            "\tfree_resource(new_res);",
            "}",
            "static bool system_ram_resources_mergeable(struct resource *r1,",
            "\t\t\t\t\t   struct resource *r2)",
            "{",
            "\t/* We assume either r1 or r2 is IORESOURCE_SYSRAM_MERGEABLE. */",
            "\treturn r1->flags == r2->flags && r1->end + 1 == r2->start &&",
            "\t       r1->name == r2->name && r1->desc == r2->desc &&",
            "\t       !r1->child && !r2->child;",
            "}",
            "void merge_system_ram_resource(struct resource *res)",
            "{",
            "\tconst unsigned long flags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;",
            "\tstruct resource *cur;",
            "",
            "\tif (WARN_ON_ONCE((res->flags & flags) != flags))",
            "\t\treturn;",
            "",
            "\twrite_lock(&resource_lock);",
            "\tres->flags |= IORESOURCE_SYSRAM_MERGEABLE;",
            "",
            "\t/* Try to merge with next item in the list. */",
            "\tcur = res->sibling;",
            "\tif (cur && system_ram_resources_mergeable(res, cur)) {",
            "\t\tres->end = cur->end;",
            "\t\tres->sibling = cur->sibling;",
            "\t\tfree_resource(cur);",
            "\t}",
            "",
            "\t/* Try to merge with previous item in the list. */",
            "\tcur = res->parent->child;",
            "\twhile (cur && cur->sibling != res)",
            "\t\tcur = cur->sibling;",
            "\tif (cur && system_ram_resources_mergeable(cur, res)) {",
            "\t\tcur->end = res->end;",
            "\t\tcur->sibling = res->sibling;",
            "\t\tfree_resource(res);",
            "\t}",
            "\twrite_unlock(&resource_lock);",
            "}"
          ],
          "function_name": "release_mem_region_adjustable, system_ram_resources_mergeable, merge_system_ram_resource",
          "description": "实现可调整内存区域释放与系统RAM资源合并功能，支持热插拔场景下的动态资源调整与碎片化优化。",
          "similarity": 0.5881360173225403
        }
      ]
    },
    {
      "source_file": "kernel/irq/matrix.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:03:08\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\matrix.c`\n\n---\n\n# `irq/matrix.c` 技术文档\n\n## 1. 文件概述\n\n`irq/matrix.c` 实现了一个通用的中断位图（IRQ matrix）管理机制，用于在多 CPU 系统中高效地分配和管理中断向量（或中断位）。该机制支持两类中断分配：\n\n- **普通分配（allocated）**：由设备驱动等动态申请的中断。\n- **托管分配（managed）**：由内核子系统（如 MSI/MSI-X）预先保留、按需激活的中断。\n\n该文件通过 per-CPU 的位图结构，结合全局状态跟踪，实现了跨 CPU 的中断资源分配、预留、释放和在线/离线管理，特别适用于中断向量数量有限（如 x86 的 256 个向量）的架构。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct cpumap`**：每个 CPU 的本地中断位图状态\n  - `available`：当前 CPU 可用的中断数量\n  - `allocated`：已分配的普通中断数量\n  - `managed` / `managed_allocated`：预留和已激活的托管中断数量\n  - `alloc_map[]`：记录已分配的普通中断位\n  - `managed_map[]`：记录预留的托管中断位\n  - `initialized` / `online`：CPU 初始化和在线状态\n\n- **`struct irq_matrix`**：全局中断矩阵控制结构\n  - `matrix_bits`：总位图大小（≤ `IRQ_MATRIX_BITS`）\n  - `alloc_start` / `alloc_end`：可分配范围\n  - `global_available`：全局可用中断总数\n  - `system_map[]`：系统保留位（如 APIC 自身使用的向量）\n  - `maps`：指向 per-CPU `cpumap` 的指针\n  - `scratch_map[]`：临时位图，用于分配时的合并计算\n\n### 主要函数\n\n| 函数 | 功能 |\n|------|------|\n| `irq_alloc_matrix()` | 分配并初始化一个 `irq_matrix` 结构 |\n| `irq_matrix_online()` / `irq_matrix_offline()` | 将本地 CPU 的中断矩阵置为在线/离线状态 |\n| `irq_matrix_assign_system()` | 在矩阵中保留系统级中断位（如 APIC 向量） |\n| `irq_matrix_reserve_managed()` | 在指定 CPU 掩码上为托管中断预留位 |\n| `irq_matrix_remove_managed()` | 移除托管中断的预留位 |\n| `irq_matrix_alloc_managed()` | 从预留的托管中断中分配一个实际使用的中断 |\n| `matrix_alloc_area()` | 内部辅助函数：在合并位图中查找连续空闲区域 |\n| `matrix_find_best_cpu()` / `matrix_find_best_cpu_managed()` | 选择最优 CPU（基于可用数或托管分配数最少） |\n\n## 3. 关键实现\n\n### 位图合并分配策略\n- 在分配中断时，`matrix_alloc_area()` 会临时合并三个位图：\n  1. 当前 CPU 的 `managed_map`（托管预留）\n  2. 全局 `system_map`（系统保留）\n  3. 当前 CPU 的 `alloc_map`（已分配）\n- 使用 `bitmap_find_next_zero_area()` 在合并后的位图中查找连续空闲区域，确保不会重复分配。\n\n### 托管中断（Managed IRQ）机制\n- **两阶段分配**：\n  1. **预留（reserve）**：调用 `irq_matrix_reserve_managed()` 在多个 CPU 上各预留一个位（不一定对齐）。\n  2. **激活（alloc）**：调用 `irq_matrix_alloc_managed()` 从预留位中选择一个未使用的位进行实际分配。\n- **动态 CPU 选择**：`matrix_find_best_cpu_managed()` 优先选择 `managed_allocated` 最少的 CPU，实现负载均衡。\n\n### 系统中断保留\n- `irq_matrix_assign_system()` 用于保留如 x86 的 `IRQ0_VECTOR`（时钟中断）等关键系统向量。\n- 通过 `BUG_ON()` 强制保证：系统中断只能在单 CPU 初始化阶段分配，防止运行时冲突。\n\n### 在线/离线管理\n- CPU 上线时，将其 `available` 计数加入 `global_available`。\n- CPU 离线时，从全局计数中减去，但保留其位图数据（支持重新上线）。\n\n### 跟踪与调试\n- 集成 `trace/events/irq_matrix.h`，提供分配、预留、系统保留等关键操作的 tracepoint，便于调试中断分配问题。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/bitmap.h>`：位图操作（`bitmap_set`, `bitmap_find_next_zero_area` 等）\n  - `<linux/percpu.h>`：Per-CPU 变量支持\n  - `<linux/cpu.h>`：CPU 在线/离线状态\n  - `<linux/irq.h>`：中断子系统基础定义\n  - `<trace/events/irq_matrix.h>`：自定义 tracepoint\n\n- **内核子系统**：\n  - **中断子系统**：作为底层分配器，被 `irqdomain`、MSI/MSI-X 驱动等使用。\n  - **x86 APIC 驱动**：典型使用者，用于管理 256 个中断向量的分配（如 `kernel/irq/vector.c`）。\n\n## 5. 使用场景\n\n- **x86 中断向量管理**：在 `CONFIG_X86_IO_APIC` 或 `CONFIG_X86_LOCAL_APIC` 下，用于分配 IRQ 向量（0-255），区分系统向量、普通设备中断和 MSI 中断。\n- **MSI/MSI-X 中断分配**：PCIe 设备的 MSI 中断通过托管机制预留和分配，确保每个设备在多个 CPU 上有可用向量。\n- **CPU 热插拔**：支持 CPU 动态上线/下线时的中断资源重新平衡。\n- **中断负载均衡**：通过 `matrix_find_best_cpu*` 函数，在多 CPU 间均匀分配中断，避免单 CPU 向量耗尽。",
      "similarity": 0.6194155812263489,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 251,
          "end_line": 365,
          "content": [
            "void irq_matrix_remove_managed(struct irq_matrix *m, const struct cpumask *msk)",
            "{",
            "\tunsigned int cpu;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "\t\tunsigned int bit, end = m->alloc_end;",
            "",
            "\t\tif (WARN_ON_ONCE(!cm->managed))",
            "\t\t\tcontinue;",
            "",
            "\t\t/* Get managed bit which are not allocated */",
            "\t\tbitmap_andnot(m->scratch_map, cm->managed_map, cm->alloc_map, end);",
            "",
            "\t\tbit = find_first_bit(m->scratch_map, end);",
            "\t\tif (WARN_ON_ONCE(bit >= end))",
            "\t\t\tcontinue;",
            "",
            "\t\tclear_bit(bit, cm->managed_map);",
            "",
            "\t\tcm->managed--;",
            "\t\tif (cm->online) {",
            "\t\t\tcm->available++;",
            "\t\t\tm->global_available++;",
            "\t\t}",
            "\t\ttrace_irq_matrix_remove_managed(bit, cpu, m, cm);",
            "\t}",
            "}",
            "int irq_matrix_alloc_managed(struct irq_matrix *m, const struct cpumask *msk,",
            "\t\t\t     unsigned int *mapped_cpu)",
            "{",
            "\tunsigned int bit, cpu, end;",
            "\tstruct cpumap *cm;",
            "",
            "\tif (cpumask_empty(msk))",
            "\t\treturn -EINVAL;",
            "",
            "\tcpu = matrix_find_best_cpu_managed(m, msk);",
            "\tif (cpu == UINT_MAX)",
            "\t\treturn -ENOSPC;",
            "",
            "\tcm = per_cpu_ptr(m->maps, cpu);",
            "\tend = m->alloc_end;",
            "\t/* Get managed bit which are not allocated */",
            "\tbitmap_andnot(m->scratch_map, cm->managed_map, cm->alloc_map, end);",
            "\tbit = find_first_bit(m->scratch_map, end);",
            "\tif (bit >= end)",
            "\t\treturn -ENOSPC;",
            "\tset_bit(bit, cm->alloc_map);",
            "\tcm->allocated++;",
            "\tcm->managed_allocated++;",
            "\tm->total_allocated++;",
            "\t*mapped_cpu = cpu;",
            "\ttrace_irq_matrix_alloc_managed(bit, cpu, m, cm);",
            "\treturn bit;",
            "}",
            "void irq_matrix_assign(struct irq_matrix *m, unsigned int bit)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tif (WARN_ON_ONCE(bit < m->alloc_start || bit >= m->alloc_end))",
            "\t\treturn;",
            "\tif (WARN_ON_ONCE(test_and_set_bit(bit, cm->alloc_map)))",
            "\t\treturn;",
            "\tcm->allocated++;",
            "\tm->total_allocated++;",
            "\tcm->available--;",
            "\tm->global_available--;",
            "\ttrace_irq_matrix_assign(bit, smp_processor_id(), m, cm);",
            "}",
            "void irq_matrix_reserve(struct irq_matrix *m)",
            "{",
            "\tif (m->global_reserved == m->global_available)",
            "\t\tpr_warn(\"Interrupt reservation exceeds available resources\\n\");",
            "",
            "\tm->global_reserved++;",
            "\ttrace_irq_matrix_reserve(m);",
            "}",
            "void irq_matrix_remove_reserved(struct irq_matrix *m)",
            "{",
            "\tm->global_reserved--;",
            "\ttrace_irq_matrix_remove_reserved(m);",
            "}",
            "int irq_matrix_alloc(struct irq_matrix *m, const struct cpumask *msk,",
            "\t\t     bool reserved, unsigned int *mapped_cpu)",
            "{",
            "\tunsigned int cpu, bit;",
            "\tstruct cpumap *cm;",
            "",
            "\t/*",
            "\t * Not required in theory, but matrix_find_best_cpu() uses",
            "\t * for_each_cpu() which ignores the cpumask on UP .",
            "\t */",
            "\tif (cpumask_empty(msk))",
            "\t\treturn -EINVAL;",
            "",
            "\tcpu = matrix_find_best_cpu(m, msk);",
            "\tif (cpu == UINT_MAX)",
            "\t\treturn -ENOSPC;",
            "",
            "\tcm = per_cpu_ptr(m->maps, cpu);",
            "\tbit = matrix_alloc_area(m, cm, 1, false);",
            "\tif (bit >= m->alloc_end)",
            "\t\treturn -ENOSPC;",
            "\tcm->allocated++;",
            "\tcm->available--;",
            "\tm->total_allocated++;",
            "\tm->global_available--;",
            "\tif (reserved)",
            "\t\tm->global_reserved--;",
            "\t*mapped_cpu = cpu;",
            "\ttrace_irq_matrix_alloc(bit, cpu, m, cm);",
            "\treturn bit;",
            "",
            "}"
          ],
          "function_name": "irq_matrix_remove_managed, irq_matrix_alloc_managed, irq_matrix_assign, irq_matrix_reserve, irq_matrix_remove_reserved, irq_matrix_alloc",
          "description": "实现中断位的分配/回收机制，包含保留中断位的管理、跨CPU的中断分配逻辑，以及根据预留状态进行资源分配的控制流程",
          "similarity": 0.6430255174636841
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 78,
          "end_line": 205,
          "content": [
            "void irq_matrix_online(struct irq_matrix *m)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tBUG_ON(cm->online);",
            "",
            "\tif (!cm->initialized) {",
            "\t\tcm->available = m->alloc_size;",
            "\t\tcm->available -= cm->managed + m->systembits_inalloc;",
            "\t\tcm->initialized = true;",
            "\t}",
            "\tm->global_available += cm->available;",
            "\tcm->online = true;",
            "\tm->online_maps++;",
            "\ttrace_irq_matrix_online(m);",
            "}",
            "void irq_matrix_offline(struct irq_matrix *m)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\t/* Update the global available size */",
            "\tm->global_available -= cm->available;",
            "\tcm->online = false;",
            "\tm->online_maps--;",
            "\ttrace_irq_matrix_offline(m);",
            "}",
            "static unsigned int matrix_alloc_area(struct irq_matrix *m, struct cpumap *cm,",
            "\t\t\t\t      unsigned int num, bool managed)",
            "{",
            "\tunsigned int area, start = m->alloc_start;",
            "\tunsigned int end = m->alloc_end;",
            "",
            "\tbitmap_or(m->scratch_map, cm->managed_map, m->system_map, end);",
            "\tbitmap_or(m->scratch_map, m->scratch_map, cm->alloc_map, end);",
            "\tarea = bitmap_find_next_zero_area(m->scratch_map, end, start, num, 0);",
            "\tif (area >= end)",
            "\t\treturn area;",
            "\tif (managed)",
            "\t\tbitmap_set(cm->managed_map, area, num);",
            "\telse",
            "\t\tbitmap_set(cm->alloc_map, area, num);",
            "\treturn area;",
            "}",
            "static unsigned int matrix_find_best_cpu(struct irq_matrix *m,",
            "\t\t\t\t\tconst struct cpumask *msk)",
            "{",
            "\tunsigned int cpu, best_cpu, maxavl = 0;",
            "\tstruct cpumap *cm;",
            "",
            "\tbest_cpu = UINT_MAX;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tcm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\t\tif (!cm->online || cm->available <= maxavl)",
            "\t\t\tcontinue;",
            "",
            "\t\tbest_cpu = cpu;",
            "\t\tmaxavl = cm->available;",
            "\t}",
            "\treturn best_cpu;",
            "}",
            "static unsigned int matrix_find_best_cpu_managed(struct irq_matrix *m,",
            "\t\t\t\t\t\tconst struct cpumask *msk)",
            "{",
            "\tunsigned int cpu, best_cpu, allocated = UINT_MAX;",
            "\tstruct cpumap *cm;",
            "",
            "\tbest_cpu = UINT_MAX;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tcm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\t\tif (!cm->online || cm->managed_allocated > allocated)",
            "\t\t\tcontinue;",
            "",
            "\t\tbest_cpu = cpu;",
            "\t\tallocated = cm->managed_allocated;",
            "\t}",
            "\treturn best_cpu;",
            "}",
            "void irq_matrix_assign_system(struct irq_matrix *m, unsigned int bit,",
            "\t\t\t      bool replace)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tBUG_ON(bit > m->matrix_bits);",
            "\tBUG_ON(m->online_maps > 1 || (m->online_maps && !replace));",
            "",
            "\tset_bit(bit, m->system_map);",
            "\tif (replace) {",
            "\t\tBUG_ON(!test_and_clear_bit(bit, cm->alloc_map));",
            "\t\tcm->allocated--;",
            "\t\tm->total_allocated--;",
            "\t}",
            "\tif (bit >= m->alloc_start && bit < m->alloc_end)",
            "\t\tm->systembits_inalloc++;",
            "",
            "\ttrace_irq_matrix_assign_system(bit, m);",
            "}",
            "int irq_matrix_reserve_managed(struct irq_matrix *m, const struct cpumask *msk)",
            "{",
            "\tunsigned int cpu, failed_cpu;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "\t\tunsigned int bit;",
            "",
            "\t\tbit = matrix_alloc_area(m, cm, 1, true);",
            "\t\tif (bit >= m->alloc_end)",
            "\t\t\tgoto cleanup;",
            "\t\tcm->managed++;",
            "\t\tif (cm->online) {",
            "\t\t\tcm->available--;",
            "\t\t\tm->global_available--;",
            "\t\t}",
            "\t\ttrace_irq_matrix_reserve_managed(bit, cpu, m, cm);",
            "\t}",
            "\treturn 0;",
            "cleanup:",
            "\tfailed_cpu = cpu;",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tif (cpu == failed_cpu)",
            "\t\t\tbreak;",
            "\t\tirq_matrix_remove_managed(m, cpumask_of(cpu));",
            "\t}",
            "\treturn -ENOSPC;",
            "}"
          ],
          "function_name": "irq_matrix_online, irq_matrix_offline, matrix_alloc_area, matrix_find_best_cpu, matrix_find_best_cpu_managed, irq_matrix_assign_system, irq_matrix_reserve_managed",
          "description": "实现CPU矩阵的上线/下线操作，通过bitmap操作实现中断位的分配策略，包含寻找最佳CPU的逻辑，支持系统位管理和保留区域的分配与追踪",
          "similarity": 0.6129764318466187
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 418,
          "end_line": 483,
          "content": [
            "void irq_matrix_free(struct irq_matrix *m, unsigned int cpu,",
            "\t\t     unsigned int bit, bool managed)",
            "{",
            "\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\tif (WARN_ON_ONCE(bit < m->alloc_start || bit >= m->alloc_end))",
            "\t\treturn;",
            "",
            "\tif (WARN_ON_ONCE(!test_and_clear_bit(bit, cm->alloc_map)))",
            "\t\treturn;",
            "",
            "\tcm->allocated--;",
            "\tif(managed)",
            "\t\tcm->managed_allocated--;",
            "",
            "\tif (cm->online)",
            "\t\tm->total_allocated--;",
            "",
            "\tif (!managed) {",
            "\t\tcm->available++;",
            "\t\tif (cm->online)",
            "\t\t\tm->global_available++;",
            "\t}",
            "\ttrace_irq_matrix_free(bit, cpu, m, cm);",
            "}",
            "unsigned int irq_matrix_available(struct irq_matrix *m, bool cpudown)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tif (!cpudown)",
            "\t\treturn m->global_available;",
            "\treturn m->global_available - cm->available;",
            "}",
            "unsigned int irq_matrix_reserved(struct irq_matrix *m)",
            "{",
            "\treturn m->global_reserved;",
            "}",
            "unsigned int irq_matrix_allocated(struct irq_matrix *m)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\treturn cm->allocated - cm->managed_allocated;",
            "}",
            "void irq_matrix_debug_show(struct seq_file *sf, struct irq_matrix *m, int ind)",
            "{",
            "\tunsigned int nsys = bitmap_weight(m->system_map, m->matrix_bits);",
            "\tint cpu;",
            "",
            "\tseq_printf(sf, \"Online bitmaps:   %6u\\n\", m->online_maps);",
            "\tseq_printf(sf, \"Global available: %6u\\n\", m->global_available);",
            "\tseq_printf(sf, \"Global reserved:  %6u\\n\", m->global_reserved);",
            "\tseq_printf(sf, \"Total allocated:  %6u\\n\", m->total_allocated);",
            "\tseq_printf(sf, \"System: %u: %*pbl\\n\", nsys, m->matrix_bits,",
            "\t\t   m->system_map);",
            "\tseq_printf(sf, \"%*s| CPU | avl | man | mac | act | vectors\\n\", ind, \" \");",
            "\tcpus_read_lock();",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\t\tseq_printf(sf, \"%*s %4d  %4u  %4u  %4u %4u  %*pbl\\n\", ind, \" \",",
            "\t\t\t   cpu, cm->available, cm->managed,",
            "\t\t\t   cm->managed_allocated, cm->allocated,",
            "\t\t\t   m->matrix_bits, cm->alloc_map);",
            "\t}",
            "\tcpus_read_unlock();",
            "}"
          ],
          "function_name": "irq_matrix_free, irq_matrix_available, irq_matrix_reserved, irq_matrix_allocated, irq_matrix_debug_show",
          "description": "提供中断资源的释放接口，实现全局和CPU级的资源使用统计查询，包含调试信息展示功能，通过位图操作维护系统中断位的使用状态",
          "similarity": 0.6041897535324097
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 1,
          "end_line": 77,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "// Copyright (C) 2017 Thomas Gleixner <tglx@linutronix.de>",
            "",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpu.h>",
            "#include <linux/irq.h>",
            "",
            "#define IRQ_MATRIX_SIZE\t(BITS_TO_LONGS(IRQ_MATRIX_BITS))",
            "",
            "struct cpumap {",
            "\tunsigned int\t\tavailable;",
            "\tunsigned int\t\tallocated;",
            "\tunsigned int\t\tmanaged;",
            "\tunsigned int\t\tmanaged_allocated;",
            "\tbool\t\t\tinitialized;",
            "\tbool\t\t\tonline;",
            "\tunsigned long\t\talloc_map[IRQ_MATRIX_SIZE];",
            "\tunsigned long\t\tmanaged_map[IRQ_MATRIX_SIZE];",
            "};",
            "",
            "struct irq_matrix {",
            "\tunsigned int\t\tmatrix_bits;",
            "\tunsigned int\t\talloc_start;",
            "\tunsigned int\t\talloc_end;",
            "\tunsigned int\t\talloc_size;",
            "\tunsigned int\t\tglobal_available;",
            "\tunsigned int\t\tglobal_reserved;",
            "\tunsigned int\t\tsystembits_inalloc;",
            "\tunsigned int\t\ttotal_allocated;",
            "\tunsigned int\t\tonline_maps;",
            "\tstruct cpumap __percpu\t*maps;",
            "\tunsigned long\t\tscratch_map[IRQ_MATRIX_SIZE];",
            "\tunsigned long\t\tsystem_map[IRQ_MATRIX_SIZE];",
            "};",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/irq_matrix.h>",
            "",
            "/**",
            " * irq_alloc_matrix - Allocate a irq_matrix structure and initialize it",
            " * @matrix_bits:\tNumber of matrix bits must be <= IRQ_MATRIX_BITS",
            " * @alloc_start:\tFrom which bit the allocation search starts",
            " * @alloc_end:\t\tAt which bit the allocation search ends, i.e first",
            " *\t\t\tinvalid bit",
            " */",
            "__init struct irq_matrix *irq_alloc_matrix(unsigned int matrix_bits,",
            "\t\t\t\t\t   unsigned int alloc_start,",
            "\t\t\t\t\t   unsigned int alloc_end)",
            "{",
            "\tstruct irq_matrix *m;",
            "",
            "\tif (matrix_bits > IRQ_MATRIX_BITS)",
            "\t\treturn NULL;",
            "",
            "\tm = kzalloc(sizeof(*m), GFP_KERNEL);",
            "\tif (!m)",
            "\t\treturn NULL;",
            "",
            "\tm->matrix_bits = matrix_bits;",
            "\tm->alloc_start = alloc_start;",
            "\tm->alloc_end = alloc_end;",
            "\tm->alloc_size = alloc_end - alloc_start;",
            "\tm->maps = alloc_percpu(*m->maps);",
            "\tif (!m->maps) {",
            "\t\tkfree(m);",
            "\t\treturn NULL;",
            "\t}",
            "\treturn m;",
            "}",
            "",
            "/**",
            " * irq_matrix_online - Bring the local CPU matrix online",
            " * @m:\t\tMatrix pointer",
            " */"
          ],
          "function_name": null,
          "description": "定义irq_matrix结构体和相关辅助数据结构，提供irq_alloc_matrix函数用于初始化并分配irq_matrix实例，设置矩阵大小、起始结束位置等参数，并分配per-CPU的cpumap数组",
          "similarity": 0.52388596534729
        }
      ]
    }
  ]
}