{
  "query": "Linux内核多线程模型实现原理",
  "timestamp": "2025-12-26 00:49:54",
  "retrieved_files": [
    {
      "source_file": "kernel/time/timer.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:57:06\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `time\\timer.c`\n\n---\n\n# `time/timer.c` 技术文档\n\n## 1. 文件概述\n\n`time/timer.c` 是 Linux 内核中实现**内核定时器子系统**的核心文件，负责管理基于**定时器轮（timer wheel）** 的动态定时器机制。该文件提供了高效、可扩展的定时器调度框架，支持高精度超时处理、SMP（对称多处理）环境下的 per-CPU 定时器管理，以及与 NO_HZ（动态 tick）节能机制的集成。其设计目标是在保证大多数超时场景（如网络、I/O 超时）性能的同时，通过多级粒度结构避免传统定时器轮中频繁的级联（cascading）操作，从而提升系统可扩展性。\n\n## 2. 核心功能\n\n### 主要数据结构\n- **`jiffies_64`**：全局 64 位 jiffies 计数器，记录自系统启动以来的时钟滴答数，对齐缓存行以优化 SMP 访问。\n- **多级定时器轮（Timer Wheel）结构**：\n  - 由 `LVL_DEPTH` 层（通常为 8 或 9）组成，每层包含 `LVL_SIZE`（64）个桶（buckets）。\n  - 每层具有不同的时间粒度（granularity），随层级升高而增大。\n- **定时器基础（Timer Bases）**：\n  - `BASE_STD`：标准定时器基础，用于普通定时器。\n  - `BASE_DEF`：可延迟定时器基础（仅当 `CONFIG_NO_HZ_COMMON` 启用时存在），用于在 CPU 空闲时可推迟执行的定时器。\n\n### 关键宏定义\n- `LVL_CLK_SHIFT` / `LVL_CLK_DIV`：定义层级间的时间粒度缩放因子（默认为 8 倍）。\n- `LVL_GRAN(n)`：第 `n` 层的时间粒度（单位：jiffies）。\n- `LVL_START(n)`：第 `n` 层的起始偏移时间，用于计算定时器应插入的层级。\n- `WHEEL_TIMEOUT_CUTOFF` / `WHEEL_TIMEOUT_MAX`：定时器轮的最大支持超时时间（约 12 天 @ HZ=1000）。\n\n### 主要功能\n- 定时器的注册（`add_timer`）、删除（`del_timer`）和修改（`mod_timer`）。\n- 定时器到期处理（软中断上下文执行）。\n- 与 tick 管理子系统（`tick.h`）和 NO_HZ 模式协同工作。\n- 提供 `sys_sysinfo` 系统调用的底层支持。\n\n## 3. 关键实现\n\n### 多级定时器轮算法\n- **层级设计**：定时器根据其到期时间的远近被分配到不同层级。近到期定时器放入低层（高精度），远到期放入高层（低精度）。\n- **无级联机制**：与经典定时器轮不同，本实现**不进行定时器的级联迁移**。高层定时器到期时直接触发，牺牲少量精度换取显著性能提升。\n- **隐式批处理**：高层的粗粒度天然实现超时事件的批处理，减少中断和软中断开销。\n- **超时截断**：超过 `WHEEL_TIMEOUT_MAX` 的定时器会被强制设为最大支持超时值，实测表明实际使用中超时极少超过 5 天。\n\n### 粒度与范围（以 HZ=1000 为例）\n| 层级 | 偏移 | 粒度 | 范围 |\n|------|------|------|------|\n| 0 | 0 | 1 ms | 0 – 63 ms |\n| 1 | 64 | 8 ms | 64 – 511 ms |\n| ... | ... | ... | ... |\n| 8 | 512 | ~4 小时 | ~1 天 – ~12 天 |\n\n### NO_HZ 支持\n- 当启用 `CONFIG_NO_HZ_COMMON` 时，系统维护**两个独立的定时器轮**：\n  - `BASE_STD`：标准定时器，必须准时触发。\n  - `BASE_DEF`：可延迟定时器，在 CPU 进入空闲状态时可推迟执行，用于节能。\n\n### SMP 优化\n- 定时器默认绑定到注册时的 CPU，利用 per-CPU 数据结构减少锁竞争。\n- `jiffies_64` 使用 `__cacheline_aligned_in_smp` 对齐，避免 false sharing。\n\n## 4. 依赖关系\n\n### 头文件依赖\n- **时间子系统**：`<linux/time.h>`, `<linux/jiffies.h>`, `<asm/timex.h>`\n- **调度与中断**：`<linux/interrupt.h>`, `<linux/irq_work.h>`, `<linux/sched/*.h>`\n- **内存管理**：`<linux/slab.h>`, `<linux/mm.h>`\n- **系统调用**：`<linux/syscalls.h>`, `<linux/uaccess.h>`\n- **内部模块**：`\"tick-internal.h\"`（tick 管理）、`<trace/events/timer.h>`（跟踪点）\n\n### 内核子系统交互\n- **Tick 管理**：通过 `tick.h` 接口获取时钟事件，驱动定时器轮推进。\n- **软中断**：定时器到期回调在 `TIMER_SOFTIRQ` 软中断上下文中执行。\n- **POSIX 定时器**：为 `<linux/posix-timers.h>` 提供底层支持。\n- **CPU 热插拔**：通过 `cpu.h` 处理 CPU 上下线时的定时器迁移。\n- **电源管理**：与 `NO_HZ` 和 `sched/nohz.h` 协同实现动态 tick。\n\n## 5. 使用场景\n\n- **内核超时机制**：网络协议栈（TCP 重传、连接超时）、块设备 I/O 超时、文件系统缓存回收等。\n- **延迟执行任务**：通过 `mod_timer` 实现延迟工作队列（如 `delayed_work`）。\n- **系统时间维护**：为 `jiffies` 和 `get_jiffies_64()` 提供原子更新。\n- **用户空间接口**：支撑 `sysinfo` 系统调用返回 uptime、负载等信息。\n- **高精度定时需求**：短超时（<64ms @ HZ=1000）可获得毫秒级精度，满足实时性要求。\n- **低功耗系统**：在 `NO_HZ_IDLE` 或 `NO_HZ_FULL` 模式下，通过 `BASE_DEF` 减少不必要的 tick 中断。",
      "similarity": 0.6159292459487915,
      "chunks": [
        {
          "chunk_id": 11,
          "file_path": "kernel/time/timer.c",
          "start_line": 2190,
          "end_line": 2292,
          "content": [
            "signed long __sched schedule_timeout_killable(signed long timeout)",
            "{",
            "\t__set_current_state(TASK_KILLABLE);",
            "\treturn schedule_timeout(timeout);",
            "}",
            "signed long __sched schedule_timeout_uninterruptible(signed long timeout)",
            "{",
            "\t__set_current_state(TASK_UNINTERRUPTIBLE);",
            "\treturn schedule_timeout(timeout);",
            "}",
            "signed long __sched schedule_timeout_idle(signed long timeout)",
            "{",
            "\t__set_current_state(TASK_IDLE);",
            "\treturn schedule_timeout(timeout);",
            "}",
            "static void migrate_timer_list(struct timer_base *new_base, struct hlist_head *head)",
            "{",
            "\tstruct timer_list *timer;",
            "\tint cpu = new_base->cpu;",
            "",
            "\twhile (!hlist_empty(head)) {",
            "\t\ttimer = hlist_entry(head->first, struct timer_list, entry);",
            "\t\tdetach_timer(timer, false);",
            "\t\ttimer->flags = (timer->flags & ~TIMER_BASEMASK) | cpu;",
            "\t\tinternal_add_timer(new_base, timer);",
            "\t}",
            "}",
            "int timers_prepare_cpu(unsigned int cpu)",
            "{",
            "\tstruct timer_base *base;",
            "\tint b;",
            "",
            "\tfor (b = 0; b < NR_BASES; b++) {",
            "\t\tbase = per_cpu_ptr(&timer_bases[b], cpu);",
            "\t\tbase->clk = jiffies;",
            "\t\tbase->next_expiry = base->clk + NEXT_TIMER_MAX_DELTA;",
            "\t\tbase->next_expiry_recalc = false;",
            "\t\tbase->timers_pending = false;",
            "\t\tbase->is_idle = false;",
            "\t}",
            "\treturn 0;",
            "}",
            "int timers_dead_cpu(unsigned int cpu)",
            "{",
            "\tstruct timer_base *old_base;",
            "\tstruct timer_base *new_base;",
            "\tint b, i;",
            "",
            "\tfor (b = 0; b < NR_BASES; b++) {",
            "\t\told_base = per_cpu_ptr(&timer_bases[b], cpu);",
            "\t\tnew_base = get_cpu_ptr(&timer_bases[b]);",
            "\t\t/*",
            "\t\t * The caller is globally serialized and nobody else",
            "\t\t * takes two locks at once, deadlock is not possible.",
            "\t\t */",
            "\t\traw_spin_lock_irq(&new_base->lock);",
            "\t\traw_spin_lock_nested(&old_base->lock, SINGLE_DEPTH_NESTING);",
            "",
            "\t\t/*",
            "\t\t * The current CPUs base clock might be stale. Update it",
            "\t\t * before moving the timers over.",
            "\t\t */",
            "\t\tforward_timer_base(new_base);",
            "",
            "\t\tWARN_ON_ONCE(old_base->running_timer);",
            "\t\told_base->running_timer = NULL;",
            "",
            "\t\tfor (i = 0; i < WHEEL_SIZE; i++)",
            "\t\t\tmigrate_timer_list(new_base, old_base->vectors + i);",
            "",
            "\t\traw_spin_unlock(&old_base->lock);",
            "\t\traw_spin_unlock_irq(&new_base->lock);",
            "\t\tput_cpu_ptr(&timer_bases);",
            "\t}",
            "\treturn 0;",
            "}",
            "static void __init init_timer_cpu(int cpu)",
            "{",
            "\tstruct timer_base *base;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < NR_BASES; i++) {",
            "\t\tbase = per_cpu_ptr(&timer_bases[i], cpu);",
            "\t\tbase->cpu = cpu;",
            "\t\traw_spin_lock_init(&base->lock);",
            "\t\tbase->clk = jiffies;",
            "\t\tbase->next_expiry = base->clk + NEXT_TIMER_MAX_DELTA;",
            "\t\ttimer_base_init_expiry_lock(base);",
            "\t}",
            "}",
            "static void __init init_timer_cpus(void)",
            "{",
            "\tint cpu;",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tinit_timer_cpu(cpu);",
            "}",
            "void __init init_timers(void)",
            "{",
            "\tinit_timer_cpus();",
            "\tposix_cputimers_init_work();",
            "\topen_softirq(TIMER_SOFTIRQ, run_timer_softirq);",
            "}"
          ],
          "function_name": "schedule_timeout_killable, schedule_timeout_uninterruptible, schedule_timeout_idle, migrate_timer_list, timers_prepare_cpu, timers_dead_cpu, init_timer_cpu, init_timer_cpus, init_timers",
          "description": "该代码段实现Linux内核中的定时器管理和进程睡眠控制功能。  \n三个`schedule_timeout_*`函数通过设置任务状态（可中断/不可中断/空闲）实现进程睡眠并返回超时值；`migrate_timer_list`及`timers_prepare_cpu`/`timers_dead_cpu`系列函数负责多CPU环境下定时器列表的迁移与初始化，保障定时器在CPU热插拔时的数据一致性。  \n其余函数（`init_timer_cpu`/`init_timer_cpus`/`init_timers`）完成全局定时器基础结构的初始化，构建多核系统中定时器调度所需的底层资源。",
          "similarity": 0.6246768236160278
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/time/timer.c",
          "start_line": 1,
          "end_line": 230,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " *  Kernel internal timers",
            " *",
            " *  Copyright (C) 1991, 1992  Linus Torvalds",
            " *",
            " *  1997-01-28  Modified by Finn Arne Gangstad to make timers scale better.",
            " *",
            " *  1997-09-10  Updated NTP code according to technical memorandum Jan '96",
            " *              \"A Kernel Model for Precision Timekeeping\" by Dave Mills",
            " *  1998-12-24  Fixed a xtime SMP race (we need the xtime_lock rw spinlock to",
            " *              serialize accesses to xtime/lost_ticks).",
            " *                              Copyright (C) 1998  Andrea Arcangeli",
            " *  1999-03-10  Improved NTP compatibility by Ulrich Windl",
            " *  2002-05-31\tMove sys_sysinfo here and make its locking sane, Robert Love",
            " *  2000-10-05  Implemented scalable SMP per-CPU timer handling.",
            " *                              Copyright (C) 2000, 2001, 2002  Ingo Molnar",
            " *              Designed by David S. Miller, Alexey Kuznetsov and Ingo Molnar",
            " */",
            "",
            "#include <linux/kernel_stat.h>",
            "#include <linux/export.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/percpu.h>",
            "#include <linux/init.h>",
            "#include <linux/mm.h>",
            "#include <linux/swap.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/notifier.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/time.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/cpu.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/delay.h>",
            "#include <linux/tick.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/slab.h>",
            "#include <linux/compat.h>",
            "#include <linux/random.h>",
            "#include <linux/sysctl.h>",
            "",
            "#include <linux/uaccess.h>",
            "#include <asm/unistd.h>",
            "#include <asm/div64.h>",
            "#include <asm/timex.h>",
            "#include <asm/io.h>",
            "",
            "#include \"tick-internal.h\"",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/timer.h>",
            "",
            "__visible u64 jiffies_64 __cacheline_aligned_in_smp = INITIAL_JIFFIES;",
            "",
            "EXPORT_SYMBOL(jiffies_64);",
            "",
            "/*",
            " * The timer wheel has LVL_DEPTH array levels. Each level provides an array of",
            " * LVL_SIZE buckets. Each level is driven by its own clock and therefor each",
            " * level has a different granularity.",
            " *",
            " * The level granularity is:\t\tLVL_CLK_DIV ^ lvl",
            " * The level clock frequency is:\tHZ / (LVL_CLK_DIV ^ level)",
            " *",
            " * The array level of a newly armed timer depends on the relative expiry",
            " * time. The farther the expiry time is away the higher the array level and",
            " * therefor the granularity becomes.",
            " *",
            " * Contrary to the original timer wheel implementation, which aims for 'exact'",
            " * expiry of the timers, this implementation removes the need for recascading",
            " * the timers into the lower array levels. The previous 'classic' timer wheel",
            " * implementation of the kernel already violated the 'exact' expiry by adding",
            " * slack to the expiry time to provide batched expiration. The granularity",
            " * levels provide implicit batching.",
            " *",
            " * This is an optimization of the original timer wheel implementation for the",
            " * majority of the timer wheel use cases: timeouts. The vast majority of",
            " * timeout timers (networking, disk I/O ...) are canceled before expiry. If",
            " * the timeout expires it indicates that normal operation is disturbed, so it",
            " * does not matter much whether the timeout comes with a slight delay.",
            " *",
            " * The only exception to this are networking timers with a small expiry",
            " * time. They rely on the granularity. Those fit into the first wheel level,",
            " * which has HZ granularity.",
            " *",
            " * We don't have cascading anymore. timers with a expiry time above the",
            " * capacity of the last wheel level are force expired at the maximum timeout",
            " * value of the last wheel level. From data sampling we know that the maximum",
            " * value observed is 5 days (network connection tracking), so this should not",
            " * be an issue.",
            " *",
            " * The currently chosen array constants values are a good compromise between",
            " * array size and granularity.",
            " *",
            " * This results in the following granularity and range levels:",
            " *",
            " * HZ 1000 steps",
            " * Level Offset  Granularity            Range",
            " *  0      0         1 ms                0 ms -         63 ms",
            " *  1     64         8 ms               64 ms -        511 ms",
            " *  2    128        64 ms              512 ms -       4095 ms (512ms - ~4s)",
            " *  3    192       512 ms             4096 ms -      32767 ms (~4s - ~32s)",
            " *  4    256      4096 ms (~4s)      32768 ms -     262143 ms (~32s - ~4m)",
            " *  5    320     32768 ms (~32s)    262144 ms -    2097151 ms (~4m - ~34m)",
            " *  6    384    262144 ms (~4m)    2097152 ms -   16777215 ms (~34m - ~4h)",
            " *  7    448   2097152 ms (~34m)  16777216 ms -  134217727 ms (~4h - ~1d)",
            " *  8    512  16777216 ms (~4h)  134217728 ms - 1073741822 ms (~1d - ~12d)",
            " *",
            " * HZ  300",
            " * Level Offset  Granularity            Range",
            " *  0\t   0         3 ms                0 ms -        210 ms",
            " *  1\t  64        26 ms              213 ms -       1703 ms (213ms - ~1s)",
            " *  2\t 128       213 ms             1706 ms -      13650 ms (~1s - ~13s)",
            " *  3\t 192      1706 ms (~1s)      13653 ms -     109223 ms (~13s - ~1m)",
            " *  4\t 256     13653 ms (~13s)    109226 ms -     873810 ms (~1m - ~14m)",
            " *  5\t 320    109226 ms (~1m)     873813 ms -    6990503 ms (~14m - ~1h)",
            " *  6\t 384    873813 ms (~14m)   6990506 ms -   55924050 ms (~1h - ~15h)",
            " *  7\t 448   6990506 ms (~1h)   55924053 ms -  447392423 ms (~15h - ~5d)",
            " *  8    512  55924053 ms (~15h) 447392426 ms - 3579139406 ms (~5d - ~41d)",
            " *",
            " * HZ  250",
            " * Level Offset  Granularity            Range",
            " *  0\t   0         4 ms                0 ms -        255 ms",
            " *  1\t  64        32 ms              256 ms -       2047 ms (256ms - ~2s)",
            " *  2\t 128       256 ms             2048 ms -      16383 ms (~2s - ~16s)",
            " *  3\t 192      2048 ms (~2s)      16384 ms -     131071 ms (~16s - ~2m)",
            " *  4\t 256     16384 ms (~16s)    131072 ms -    1048575 ms (~2m - ~17m)",
            " *  5\t 320    131072 ms (~2m)    1048576 ms -    8388607 ms (~17m - ~2h)",
            " *  6\t 384   1048576 ms (~17m)   8388608 ms -   67108863 ms (~2h - ~18h)",
            " *  7\t 448   8388608 ms (~2h)   67108864 ms -  536870911 ms (~18h - ~6d)",
            " *  8    512  67108864 ms (~18h) 536870912 ms - 4294967288 ms (~6d - ~49d)",
            " *",
            " * HZ  100",
            " * Level Offset  Granularity            Range",
            " *  0\t   0         10 ms               0 ms -        630 ms",
            " *  1\t  64         80 ms             640 ms -       5110 ms (640ms - ~5s)",
            " *  2\t 128        640 ms            5120 ms -      40950 ms (~5s - ~40s)",
            " *  3\t 192       5120 ms (~5s)     40960 ms -     327670 ms (~40s - ~5m)",
            " *  4\t 256      40960 ms (~40s)   327680 ms -    2621430 ms (~5m - ~43m)",
            " *  5\t 320     327680 ms (~5m)   2621440 ms -   20971510 ms (~43m - ~5h)",
            " *  6\t 384    2621440 ms (~43m) 20971520 ms -  167772150 ms (~5h - ~1d)",
            " *  7\t 448   20971520 ms (~5h) 167772160 ms - 1342177270 ms (~1d - ~15d)",
            " */",
            "",
            "/* Clock divisor for the next level */",
            "#define LVL_CLK_SHIFT\t3",
            "#define LVL_CLK_DIV\t(1UL << LVL_CLK_SHIFT)",
            "#define LVL_CLK_MASK\t(LVL_CLK_DIV - 1)",
            "#define LVL_SHIFT(n)\t((n) * LVL_CLK_SHIFT)",
            "#define LVL_GRAN(n)\t(1UL << LVL_SHIFT(n))",
            "",
            "/*",
            " * The time start value for each level to select the bucket at enqueue",
            " * time. We start from the last possible delta of the previous level",
            " * so that we can later add an extra LVL_GRAN(n) to n (see calc_index()).",
            " */",
            "#define LVL_START(n)\t((LVL_SIZE - 1) << (((n) - 1) * LVL_CLK_SHIFT))",
            "",
            "/* Size of each clock level */",
            "#define LVL_BITS\t6",
            "#define LVL_SIZE\t(1UL << LVL_BITS)",
            "#define LVL_MASK\t(LVL_SIZE - 1)",
            "#define LVL_OFFS(n)\t((n) * LVL_SIZE)",
            "",
            "/* Level depth */",
            "#if HZ > 100",
            "# define LVL_DEPTH\t9",
            "# else",
            "# define LVL_DEPTH\t8",
            "#endif",
            "",
            "/* The cutoff (max. capacity of the wheel) */",
            "#define WHEEL_TIMEOUT_CUTOFF\t(LVL_START(LVL_DEPTH))",
            "#define WHEEL_TIMEOUT_MAX\t(WHEEL_TIMEOUT_CUTOFF - LVL_GRAN(LVL_DEPTH - 1))",
            "",
            "/*",
            " * The resulting wheel size. If NOHZ is configured we allocate two",
            " * wheels so we have a separate storage for the deferrable timers.",
            " */",
            "#define WHEEL_SIZE\t(LVL_SIZE * LVL_DEPTH)",
            "",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "# define NR_BASES\t2",
            "# define BASE_STD\t0",
            "# define BASE_DEF\t1",
            "#else",
            "# define NR_BASES\t1",
            "# define BASE_STD\t0",
            "# define BASE_DEF\t0",
            "#endif",
            "",
            "struct timer_base {",
            "\traw_spinlock_t\t\tlock;",
            "\tstruct timer_list\t*running_timer;",
            "#ifdef CONFIG_PREEMPT_RT",
            "\tspinlock_t\t\texpiry_lock;",
            "\tatomic_t\t\ttimer_waiters;",
            "#endif",
            "\tunsigned long\t\tclk;",
            "\tunsigned long\t\tnext_expiry;",
            "\tunsigned int\t\tcpu;",
            "\tbool\t\t\tnext_expiry_recalc;",
            "\tbool\t\t\tis_idle;",
            "\tbool\t\t\ttimers_pending;",
            "\tDECLARE_BITMAP(pending_map, WHEEL_SIZE);",
            "\tstruct hlist_head\tvectors[WHEEL_SIZE];",
            "} ____cacheline_aligned;",
            "",
            "static DEFINE_PER_CPU(struct timer_base, timer_bases[NR_BASES]);",
            "",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "",
            "static DEFINE_STATIC_KEY_FALSE(timers_nohz_active);",
            "static DEFINE_MUTEX(timer_keys_mutex);",
            "",
            "static void timer_update_keys(struct work_struct *work);",
            "static DECLARE_WORK(timer_update_work, timer_update_keys);",
            "",
            "#ifdef CONFIG_SMP",
            "static unsigned int sysctl_timer_migration = 1;",
            "",
            "DEFINE_STATIC_KEY_FALSE(timers_migration_enabled);",
            ""
          ],
          "function_name": null,
          "description": "定义并实现了内核定时器轮（timer wheel）的数据结构和宏观布局，通过多层级桶结构管理定时器，支持不同粒度的超时处理，包含对NOHZ模式的支持及动态调整机制。",
          "similarity": 0.5731500387191772
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/time/timer.c",
          "start_line": 460,
          "end_line": 560,
          "content": [
            "unsigned long __round_jiffies_up_relative(unsigned long j, int cpu)",
            "{",
            "\tunsigned long j0 = jiffies;",
            "",
            "\t/* Use j0 because jiffies might change while we run */",
            "\treturn round_jiffies_common(j + j0, cpu, true) - j0;",
            "}",
            "unsigned long round_jiffies_up(unsigned long j)",
            "{",
            "\treturn round_jiffies_common(j, raw_smp_processor_id(), true);",
            "}",
            "unsigned long round_jiffies_up_relative(unsigned long j)",
            "{",
            "\treturn __round_jiffies_up_relative(j, raw_smp_processor_id());",
            "}",
            "static inline unsigned int timer_get_idx(struct timer_list *timer)",
            "{",
            "\treturn (timer->flags & TIMER_ARRAYMASK) >> TIMER_ARRAYSHIFT;",
            "}",
            "static inline void timer_set_idx(struct timer_list *timer, unsigned int idx)",
            "{",
            "\ttimer->flags = (timer->flags & ~TIMER_ARRAYMASK) |",
            "\t\t\tidx << TIMER_ARRAYSHIFT;",
            "}",
            "static inline unsigned calc_index(unsigned long expires, unsigned lvl,",
            "\t\t\t\t  unsigned long *bucket_expiry)",
            "{",
            "",
            "\t/*",
            "\t * The timer wheel has to guarantee that a timer does not fire",
            "\t * early. Early expiry can happen due to:",
            "\t * - Timer is armed at the edge of a tick",
            "\t * - Truncation of the expiry time in the outer wheel levels",
            "\t *",
            "\t * Round up with level granularity to prevent this.",
            "\t */",
            "\texpires = (expires >> LVL_SHIFT(lvl)) + 1;",
            "\t*bucket_expiry = expires << LVL_SHIFT(lvl);",
            "\treturn LVL_OFFS(lvl) + (expires & LVL_MASK);",
            "}",
            "static int calc_wheel_index(unsigned long expires, unsigned long clk,",
            "\t\t\t    unsigned long *bucket_expiry)",
            "{",
            "\tunsigned long delta = expires - clk;",
            "\tunsigned int idx;",
            "",
            "\tif (delta < LVL_START(1)) {",
            "\t\tidx = calc_index(expires, 0, bucket_expiry);",
            "\t} else if (delta < LVL_START(2)) {",
            "\t\tidx = calc_index(expires, 1, bucket_expiry);",
            "\t} else if (delta < LVL_START(3)) {",
            "\t\tidx = calc_index(expires, 2, bucket_expiry);",
            "\t} else if (delta < LVL_START(4)) {",
            "\t\tidx = calc_index(expires, 3, bucket_expiry);",
            "\t} else if (delta < LVL_START(5)) {",
            "\t\tidx = calc_index(expires, 4, bucket_expiry);",
            "\t} else if (delta < LVL_START(6)) {",
            "\t\tidx = calc_index(expires, 5, bucket_expiry);",
            "\t} else if (delta < LVL_START(7)) {",
            "\t\tidx = calc_index(expires, 6, bucket_expiry);",
            "\t} else if (LVL_DEPTH > 8 && delta < LVL_START(8)) {",
            "\t\tidx = calc_index(expires, 7, bucket_expiry);",
            "\t} else if ((long) delta < 0) {",
            "\t\tidx = clk & LVL_MASK;",
            "\t\t*bucket_expiry = clk;",
            "\t} else {",
            "\t\t/*",
            "\t\t * Force expire obscene large timeouts to expire at the",
            "\t\t * capacity limit of the wheel.",
            "\t\t */",
            "\t\tif (delta >= WHEEL_TIMEOUT_CUTOFF)",
            "\t\t\texpires = clk + WHEEL_TIMEOUT_MAX;",
            "",
            "\t\tidx = calc_index(expires, LVL_DEPTH - 1, bucket_expiry);",
            "\t}",
            "\treturn idx;",
            "}",
            "static void",
            "trigger_dyntick_cpu(struct timer_base *base, struct timer_list *timer)",
            "{",
            "\tif (!is_timers_nohz_active())",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * TODO: This wants some optimizing similar to the code below, but we",
            "\t * will do that when we switch from push to pull for deferrable timers.",
            "\t */",
            "\tif (timer->flags & TIMER_DEFERRABLE) {",
            "\t\tif (tick_nohz_full_cpu(base->cpu))",
            "\t\t\twake_up_nohz_cpu(base->cpu);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/*",
            "\t * We might have to IPI the remote CPU if the base is idle and the",
            "\t * timer is not deferrable. If the other CPU is on the way to idle",
            "\t * then it can't set base->is_idle as we hold the base lock:",
            "\t */",
            "\tif (base->is_idle)",
            "\t\twake_up_nohz_cpu(base->cpu);",
            "}"
          ],
          "function_name": "__round_jiffies_up_relative, round_jiffies_up, round_jiffies_up_relative, timer_get_idx, timer_set_idx, calc_index, calc_wheel_index, trigger_dyntick_cpu",
          "description": "实现定时器层级索引计算逻辑和动态tick触发机制，通过层级间转换规则确定定时器存储位置，处理非活动CPU上的定时器唤醒需求。",
          "similarity": 0.5554161071777344
        },
        {
          "chunk_id": 8,
          "file_path": "kernel/time/timer.c",
          "start_line": 1717,
          "end_line": 1864,
          "content": [
            "static void expire_timers(struct timer_base *base, struct hlist_head *head)",
            "{",
            "\t/*",
            "\t * This value is required only for tracing. base->clk was",
            "\t * incremented directly before expire_timers was called. But expiry",
            "\t * is related to the old base->clk value.",
            "\t */",
            "\tunsigned long baseclk = base->clk - 1;",
            "",
            "\twhile (!hlist_empty(head)) {",
            "\t\tstruct timer_list *timer;",
            "\t\tvoid (*fn)(struct timer_list *);",
            "",
            "\t\ttimer = hlist_entry(head->first, struct timer_list, entry);",
            "",
            "\t\tbase->running_timer = timer;",
            "\t\tdetach_timer(timer, true);",
            "",
            "\t\tfn = timer->function;",
            "",
            "\t\tif (WARN_ON_ONCE(!fn)) {",
            "\t\t\t/* Should never happen. Emphasis on should! */",
            "\t\t\tbase->running_timer = NULL;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tif (timer->flags & TIMER_IRQSAFE) {",
            "\t\t\traw_spin_unlock(&base->lock);",
            "\t\t\tcall_timer_fn(timer, fn, baseclk);",
            "\t\t\traw_spin_lock(&base->lock);",
            "\t\t\tbase->running_timer = NULL;",
            "\t\t} else {",
            "\t\t\traw_spin_unlock_irq(&base->lock);",
            "\t\t\tcall_timer_fn(timer, fn, baseclk);",
            "\t\t\traw_spin_lock_irq(&base->lock);",
            "\t\t\tbase->running_timer = NULL;",
            "\t\t\ttimer_sync_wait_running(base);",
            "\t\t}",
            "\t}",
            "}",
            "static int collect_expired_timers(struct timer_base *base,",
            "\t\t\t\t  struct hlist_head *heads)",
            "{",
            "\tunsigned long clk = base->clk = base->next_expiry;",
            "\tstruct hlist_head *vec;",
            "\tint i, levels = 0;",
            "\tunsigned int idx;",
            "",
            "\tfor (i = 0; i < LVL_DEPTH; i++) {",
            "\t\tidx = (clk & LVL_MASK) + i * LVL_SIZE;",
            "",
            "\t\tif (__test_and_clear_bit(idx, base->pending_map)) {",
            "\t\t\tvec = base->vectors + idx;",
            "\t\t\thlist_move_list(vec, heads++);",
            "\t\t\tlevels++;",
            "\t\t}",
            "\t\t/* Is it time to look at the next level? */",
            "\t\tif (clk & LVL_CLK_MASK)",
            "\t\t\tbreak;",
            "\t\t/* Shift clock for the next level granularity */",
            "\t\tclk >>= LVL_CLK_SHIFT;",
            "\t}",
            "\treturn levels;",
            "}",
            "static int next_pending_bucket(struct timer_base *base, unsigned offset,",
            "\t\t\t       unsigned clk)",
            "{",
            "\tunsigned pos, start = offset + clk;",
            "\tunsigned end = offset + LVL_SIZE;",
            "",
            "\tpos = find_next_bit(base->pending_map, end, start);",
            "\tif (pos < end)",
            "\t\treturn pos - start;",
            "",
            "\tpos = find_next_bit(base->pending_map, start, offset);",
            "\treturn pos < start ? pos + LVL_SIZE - start : -1;",
            "}",
            "static unsigned long __next_timer_interrupt(struct timer_base *base)",
            "{",
            "\tunsigned long clk, next, adj;",
            "\tunsigned lvl, offset = 0;",
            "",
            "\tnext = base->clk + NEXT_TIMER_MAX_DELTA;",
            "\tclk = base->clk;",
            "\tfor (lvl = 0; lvl < LVL_DEPTH; lvl++, offset += LVL_SIZE) {",
            "\t\tint pos = next_pending_bucket(base, offset, clk & LVL_MASK);",
            "\t\tunsigned long lvl_clk = clk & LVL_CLK_MASK;",
            "",
            "\t\tif (pos >= 0) {",
            "\t\t\tunsigned long tmp = clk + (unsigned long) pos;",
            "",
            "\t\t\ttmp <<= LVL_SHIFT(lvl);",
            "\t\t\tif (time_before(tmp, next))",
            "\t\t\t\tnext = tmp;",
            "",
            "\t\t\t/*",
            "\t\t\t * If the next expiration happens before we reach",
            "\t\t\t * the next level, no need to check further.",
            "\t\t\t */",
            "\t\t\tif (pos <= ((LVL_CLK_DIV - lvl_clk) & LVL_CLK_MASK))",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t\t/*",
            "\t\t * Clock for the next level. If the current level clock lower",
            "\t\t * bits are zero, we look at the next level as is. If not we",
            "\t\t * need to advance it by one because that's going to be the",
            "\t\t * next expiring bucket in that level. base->clk is the next",
            "\t\t * expiring jiffie. So in case of:",
            "\t\t *",
            "\t\t * LVL5 LVL4 LVL3 LVL2 LVL1 LVL0",
            "\t\t *  0    0    0    0    0    0",
            "\t\t *",
            "\t\t * we have to look at all levels @index 0. With",
            "\t\t *",
            "\t\t * LVL5 LVL4 LVL3 LVL2 LVL1 LVL0",
            "\t\t *  0    0    0    0    0    2",
            "\t\t *",
            "\t\t * LVL0 has the next expiring bucket @index 2. The upper",
            "\t\t * levels have the next expiring bucket @index 1.",
            "\t\t *",
            "\t\t * In case that the propagation wraps the next level the same",
            "\t\t * rules apply:",
            "\t\t *",
            "\t\t * LVL5 LVL4 LVL3 LVL2 LVL1 LVL0",
            "\t\t *  0    0    0    0    F    2",
            "\t\t *",
            "\t\t * So after looking at LVL0 we get:",
            "\t\t *",
            "\t\t * LVL5 LVL4 LVL3 LVL2 LVL1",
            "\t\t *  0    0    0    1    0",
            "\t\t *",
            "\t\t * So no propagation from LVL1 to LVL2 because that happened",
            "\t\t * with the add already, but then we need to propagate further",
            "\t\t * from LVL2 to LVL3.",
            "\t\t *",
            "\t\t * So the simple check whether the lower bits of the current",
            "\t\t * level are 0 or not is sufficient for all cases.",
            "\t\t */",
            "\t\tadj = lvl_clk ? 1 : 0;",
            "\t\tclk >>= LVL_CLK_SHIFT;",
            "\t\tclk += adj;",
            "\t}",
            "",
            "\tbase->next_expiry_recalc = false;",
            "\tbase->timers_pending = !(next == base->clk + NEXT_TIMER_MAX_DELTA);",
            "",
            "\treturn next;",
            "}"
          ],
          "function_name": "expire_timers, collect_expired_timers, next_pending_bucket, __next_timer_interrupt",
          "description": "实现定时器超时处理逻辑，expire_timers遍历过期定时器并执行回调；collect_expired_timers收集多级桶中已过期定时器；next_pending_bucket定位下一个待处理桶；__next_timer_interrupt计算下一次定时器中断时间。",
          "similarity": 0.4997352361679077
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/time/timer.c",
          "start_line": 2030,
          "end_line": 2130,
          "content": [
            "static __latent_entropy void run_timer_softirq(struct softirq_action *h)",
            "{",
            "\tstruct timer_base *base = this_cpu_ptr(&timer_bases[BASE_STD]);",
            "",
            "\t__run_timers(base);",
            "\tif (IS_ENABLED(CONFIG_NO_HZ_COMMON))",
            "\t\t__run_timers(this_cpu_ptr(&timer_bases[BASE_DEF]));",
            "}",
            "static void run_local_timers(void)",
            "{",
            "\tstruct timer_base *base = this_cpu_ptr(&timer_bases[BASE_STD]);",
            "",
            "\thrtimer_run_queues();",
            "\t/* Raise the softirq only if required. */",
            "\tif (time_before(jiffies, base->next_expiry)) {",
            "\t\tif (!IS_ENABLED(CONFIG_NO_HZ_COMMON))",
            "\t\t\treturn;",
            "\t\t/* CPU is awake, so check the deferrable base. */",
            "\t\tbase++;",
            "\t\tif (time_before(jiffies, base->next_expiry))",
            "\t\t\treturn;",
            "\t}",
            "\traise_timer_softirq(TIMER_SOFTIRQ);",
            "}",
            "void update_process_times(int user_tick)",
            "{",
            "\tstruct task_struct *p = current;",
            "",
            "\t/* Note: this timer irq context must be accounted for as well. */",
            "\taccount_process_tick(p, user_tick);",
            "\trun_local_timers();",
            "\trcu_sched_clock_irq(user_tick);",
            "#ifdef CONFIG_IRQ_WORK",
            "\tif (in_irq())",
            "\t\tirq_work_tick();",
            "#endif",
            "\tsched_tick();",
            "\tif (IS_ENABLED(CONFIG_POSIX_TIMERS))",
            "\t\trun_posix_cpu_timers();",
            "}",
            "static void process_timeout(struct timer_list *t)",
            "{",
            "\tstruct process_timer *timeout = from_timer(timeout, t, timer);",
            "",
            "\twake_up_process(timeout->task);",
            "}",
            "signed long __sched schedule_timeout(signed long timeout)",
            "{",
            "\tstruct process_timer timer;",
            "\tunsigned long expire;",
            "",
            "\tswitch (timeout)",
            "\t{",
            "\tcase MAX_SCHEDULE_TIMEOUT:",
            "\t\t/*",
            "\t\t * These two special cases are useful to be comfortable",
            "\t\t * in the caller. Nothing more. We could take",
            "\t\t * MAX_SCHEDULE_TIMEOUT from one of the negative value",
            "\t\t * but I' d like to return a valid offset (>=0) to allow",
            "\t\t * the caller to do everything it want with the retval.",
            "\t\t */",
            "\t\tschedule();",
            "\t\tgoto out;",
            "\tdefault:",
            "\t\t/*",
            "\t\t * Another bit of PARANOID. Note that the retval will be",
            "\t\t * 0 since no piece of kernel is supposed to do a check",
            "\t\t * for a negative retval of schedule_timeout() (since it",
            "\t\t * should never happens anyway). You just have the printk()",
            "\t\t * that will tell you if something is gone wrong and where.",
            "\t\t */",
            "\t\tif (timeout < 0) {",
            "\t\t\tprintk(KERN_ERR \"schedule_timeout: wrong timeout \"",
            "\t\t\t\t\"value %lx\\n\", timeout);",
            "\t\t\tdump_stack();",
            "\t\t\t__set_current_state(TASK_RUNNING);",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t}",
            "",
            "\texpire = timeout + jiffies;",
            "",
            "\ttimer.task = current;",
            "\ttimer_setup_on_stack(&timer.timer, process_timeout, 0);",
            "\t__mod_timer(&timer.timer, expire, MOD_TIMER_NOTPENDING);",
            "\tschedule();",
            "\tdel_timer_sync(&timer.timer);",
            "",
            "\t/* Remove the timer from the object tracker */",
            "\tdestroy_timer_on_stack(&timer.timer);",
            "",
            "\ttimeout = expire - jiffies;",
            "",
            " out:",
            "\treturn timeout < 0 ? 0 : timeout;",
            "}",
            "signed long __sched schedule_timeout_interruptible(signed long timeout)",
            "{",
            "\t__set_current_state(TASK_INTERRUPTIBLE);",
            "\treturn schedule_timeout(timeout);",
            "}"
          ],
          "function_name": "run_timer_softirq, run_local_timers, update_process_times, process_timeout, schedule_timeout, schedule_timeout_interruptible",
          "description": "该代码段核心功能是处理定时器相关操作，涵盖软中断处理、本地定时器管理、进程时间更新及休眠超时控制。  \n`run_timer_softirq`和`run_local_timers`分别用于处理软中断中的定时器队列和本地定时器检查，`update_process_times`更新进程时间并触发本地定时器，`schedule_timeout`系列通过定时器实现进程休眠与超时唤醒。  \n上下文不完整：部分关键函数（如`__run_timers`、`hrtimer_run_queues`）的实现未展示，依赖外部知识理解其行为。",
          "similarity": 0.498348206281662
        }
      ]
    },
    {
      "source_file": "kernel/workqueue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:53:20\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `workqueue.c`\n\n---\n\n# workqueue.c 技术文档\n\n## 1. 文件概述\n\n`workqueue.c` 是 Linux 内核中实现通用异步执行机制的核心文件，提供基于共享工作线程池（worker pool）的延迟任务调度功能。工作项（work items）在进程上下文中执行，支持 CPU 绑定和非绑定两种模式。每个 CPU 默认拥有两个标准工作池（普通优先级和高优先级），同时支持动态创建非绑定工作池以满足不同工作队列的需求。该机制替代了早期的 taskqueue/keventd 实现，具有更高的可扩展性和资源利用率。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct worker_pool`**  \n  工作线程池结构体，管理一组工作线程（workers），包含：\n  - `lock`：保护池状态的自旋锁\n  - `cpu` / `node`：关联的 CPU 和 NUMA 节点（绑定池）\n  - `worklist`：待处理工作项队列\n  - `idle_list` / `busy_hash`：空闲和忙碌工作线程的管理结构\n  - `nr_workers` / `nr_idle`：工作线程数量统计\n  - `attrs`：工作线程属性（如优先级、CPU 亲和性）\n  - `mayday_timer`：紧急情况下的救援请求定时器\n\n- **`struct pool_workqueue`**  \n  工作队列与工作池之间的关联结构，每个工作队列在每个池中都有一个对应的 `pool_workqueue` 实例，用于：\n  - 管理工作项的入队和执行\n  - 实现 `max_active` 限制（控制并发执行数）\n  - 支持 flush 操作（等待所有工作完成）\n  - 统计性能指标（如启动/完成次数、CPU 时间等）\n\n- **`struct worker`**（定义在 `workqueue_internal.h`）  \n  工作线程的运行时上下文，包含状态标志（如 `WORKER_IDLE`, `WORKER_UNBOUND`）、当前执行的工作项等。\n\n### 关键枚举与常量\n\n- **池/工作线程标志**：\n  - `POOL_DISASSOCIATED`：CPU 离线时池进入非绑定状态\n  - `WORKER_UNBOUND`：工作线程可在任意 CPU 上运行\n  - `WORKER_CPU_INTENSIVE`：标记 CPU 密集型任务，影响并发控制\n\n- **配置参数**：\n  - `NR_STD_WORKER_POOLS = 2`：每 CPU 标准池数量（普通 + 高优先级）\n  - `IDLE_WORKER_TIMEOUT = 300 * HZ`：空闲线程保留时间（5 分钟）\n  - `MAYDAY_INITIAL_TIMEOUT`：工作积压时触发救援的延迟（10ms）\n\n- **统计指标**（`pool_workqueue_stats`）：\n  - `PWQ_STAT_STARTED` / `PWQ_STAT_COMPLETED`：工作项执行统计\n  - `PWQ_STAT_MAYDAY` / `PWQ_STAT_RESCUED`：紧急救援事件计数\n\n## 3. 关键实现\n\n### 工作池管理\n- **绑定池（Bound Pool）**：与特定 CPU 关联，工作线程默认绑定到该 CPU。当 CPU 离线时，池进入 `DISASSOCIATED` 状态，工作线程转为非绑定模式。\n- **非绑定池（Unbound Pool）**：动态创建，通过哈希表（`unbound_pool_hash`）按属性（`workqueue_attrs`）去重，支持跨 CPU 调度。\n- **并发控制**：通过 `nr_running` 计数器和 `max_active` 限制，防止工作项过度并发执行。\n\n### 工作线程生命周期\n- **空闲管理**：空闲线程加入 `idle_list`，超时（`IDLE_WORKER_TIMEOUT`）后被回收。\n- **动态伸缩**：当工作积压时，通过 `mayday_timer` 触发新线程创建；若创建失败，向全局救援线程（rescuer）求助。\n- **状态标志**：使用位标志（如 `WORKER_IDLE`, `WORKER_PREP`）高效管理线程状态，避免锁竞争。\n\n### 内存与同步\n- **RCU 保护**：工作池销毁通过 RCU 延迟释放，确保 `get_work_pool()` 等读取路径无锁安全。\n- **锁分层**：\n  - `pool->lock`（自旋锁）：保护池内部状态\n  - `wq_pool_mutex`：全局池管理互斥锁\n  - `wq_pool_attach_mutex`：防止 CPU 绑定状态变更冲突\n\n### 工作项调度\n- **数据指针复用**：`work_struct->data` 的高有效位存储 `pool_workqueue` 指针，低有效位用于标志位（如 `WORK_STRUCT_INACTIVE`）。\n- **优先级支持**：高优先级工作池使用 `HIGHPRI_NICE_LEVEL = MIN_NICE` 提升调度优先级。\n\n## 4. 依赖关系\n\n- **内核子系统**：\n  - **调度器**（`<linux/sched.h>`）：创建工作线程（kworker），管理 CPU 亲和性\n  - **内存管理**（`<linux/slab.h>`）：分配工作池、工作队列等结构\n  - **CPU 热插拔**（`<linux/cpu.h>`）：处理 CPU 上下线时的池绑定状态切换\n  - **RCU**（`<linux/rculist.h>`）：实现无锁读取路径\n  - **定时器**（`<linux/timer.h>`）：实现空闲超时和救援机制\n\n- **内部依赖**：\n  - `workqueue_internal.h`：定义 `struct worker` 等内部结构\n  - `Documentation/core-api/workqueue.rst`：详细设计文档\n\n## 5. 使用场景\n\n- **驱动程序延迟操作**：硬件中断后调度下半部处理（如网络包处理、磁盘 I/O 完成回调）。\n- **内核子系统异步任务**：文件系统元数据更新、内存回收、电源管理状态切换。\n- **高优先级任务**：使用 `WQ_HIGHPRI` 标志创建工作队列，确保关键任务及时执行（如死锁恢复）。\n- **CPU 密集型任务**：标记 `WQ_CPU_INTENSIVE` 避免占用过多并发槽位，提升系统响应性。\n- **NUMA 感知调度**：非绑定工作队列可指定 NUMA 节点，优化内存访问延迟。",
      "similarity": 0.6156280636787415,
      "chunks": [
        {
          "chunk_id": 33,
          "file_path": "kernel/workqueue.c",
          "start_line": 6492,
          "end_line": 6592,
          "content": [
            "static void panic_on_wq_watchdog(void)",
            "{",
            "\tstatic unsigned int wq_stall;",
            "",
            "\tif (wq_panic_on_stall) {",
            "\t\twq_stall++;",
            "\t\tBUG_ON(wq_stall >= wq_panic_on_stall);",
            "\t}",
            "}",
            "static void wq_watchdog_reset_touched(void)",
            "{",
            "\tint cpu;",
            "",
            "\twq_watchdog_touched = jiffies;",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tper_cpu(wq_watchdog_touched_cpu, cpu) = jiffies;",
            "}",
            "static void wq_watchdog_timer_fn(struct timer_list *unused)",
            "{",
            "\tunsigned long thresh = READ_ONCE(wq_watchdog_thresh) * HZ;",
            "\tbool lockup_detected = false;",
            "\tbool cpu_pool_stall = false;",
            "\tunsigned long now = jiffies;",
            "\tstruct worker_pool *pool;",
            "\tint pi;",
            "",
            "\tif (!thresh)",
            "\t\treturn;",
            "",
            "\trcu_read_lock();",
            "",
            "\tfor_each_pool(pool, pi) {",
            "\t\tunsigned long pool_ts, touched, ts;",
            "",
            "\t\tpool->cpu_stall = false;",
            "\t\tif (list_empty(&pool->worklist))",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * If a virtual machine is stopped by the host it can look to",
            "\t\t * the watchdog like a stall.",
            "\t\t */",
            "\t\tkvm_check_and_clear_guest_paused();",
            "",
            "\t\t/* get the latest of pool and touched timestamps */",
            "\t\tif (pool->cpu >= 0)",
            "\t\t\ttouched = READ_ONCE(per_cpu(wq_watchdog_touched_cpu, pool->cpu));",
            "\t\telse",
            "\t\t\ttouched = READ_ONCE(wq_watchdog_touched);",
            "\t\tpool_ts = READ_ONCE(pool->watchdog_ts);",
            "",
            "\t\tif (time_after(pool_ts, touched))",
            "\t\t\tts = pool_ts;",
            "\t\telse",
            "\t\t\tts = touched;",
            "",
            "\t\t/* did we stall? */",
            "\t\tif (time_after(now, ts + thresh)) {",
            "\t\t\tlockup_detected = true;",
            "\t\t\tif (pool->cpu >= 0) {",
            "\t\t\t\tpool->cpu_stall = true;",
            "\t\t\t\tcpu_pool_stall = true;",
            "\t\t\t}",
            "\t\t\tpr_emerg(\"BUG: workqueue lockup - pool\");",
            "\t\t\tpr_cont_pool_info(pool);",
            "\t\t\tpr_cont(\" stuck for %us!\\n\",",
            "\t\t\t\tjiffies_to_msecs(now - pool_ts) / 1000);",
            "\t\t}",
            "",
            "",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "",
            "\tif (lockup_detected)",
            "\t\tshow_all_workqueues();",
            "",
            "\tif (cpu_pool_stall)",
            "\t\tshow_cpu_pools_hogs();",
            "",
            "\tif (lockup_detected)",
            "\t\tpanic_on_wq_watchdog();",
            "",
            "\twq_watchdog_reset_touched();",
            "\tmod_timer(&wq_watchdog_timer, jiffies + thresh);",
            "}",
            "notrace void wq_watchdog_touch(int cpu)",
            "{",
            "\tunsigned long thresh = READ_ONCE(wq_watchdog_thresh) * HZ;",
            "\tunsigned long touch_ts = READ_ONCE(wq_watchdog_touched);",
            "\tunsigned long now = jiffies;",
            "",
            "\tif (cpu >= 0)",
            "\t\tper_cpu(wq_watchdog_touched_cpu, cpu) = now;",
            "\telse",
            "\t\tWARN_ONCE(1, \"%s should be called with valid CPU\", __func__);",
            "",
            "\t/* Don't unnecessarily store to global cacheline */",
            "\tif (time_after(now, touch_ts + thresh / 4))",
            "\t\tWRITE_ONCE(wq_watchdog_touched, jiffies);",
            "}"
          ],
          "function_name": "panic_on_wq_watchdog, wq_watchdog_reset_touched, wq_watchdog_timer_fn, wq_watchdog_touch",
          "description": "实现工作队列看门狗机制，通过定时器周期性检测任务阻塞状态，当检测到CPU池超时时触发警告日志和panic，包含超时阈值管理、时间戳更新及阻塞状态标识逻辑。",
          "similarity": 0.5466880202293396
        },
        {
          "chunk_id": 29,
          "file_path": "kernel/workqueue.c",
          "start_line": 5864,
          "end_line": 5966,
          "content": [
            "int workqueue_unbound_exclude_cpumask(cpumask_var_t exclude_cpumask)",
            "{",
            "\tcpumask_var_t cpumask;",
            "\tint ret = 0;",
            "",
            "\tif (!zalloc_cpumask_var(&cpumask, GFP_KERNEL))",
            "\t\treturn -ENOMEM;",
            "",
            "\tlockdep_assert_cpus_held();",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\t/* Save the current isolated cpumask & export it via sysfs */",
            "\tcpumask_copy(wq_isolated_cpumask, exclude_cpumask);",
            "",
            "\t/*",
            "\t * If the operation fails, it will fall back to",
            "\t * wq_requested_unbound_cpumask which is initially set to",
            "\t * (HK_TYPE_WQ ∩ HK_TYPE_DOMAIN) house keeping mask and rewritten",
            "\t * by any subsequent write to workqueue/cpumask sysfs file.",
            "\t */",
            "\tif (!cpumask_andnot(cpumask, wq_requested_unbound_cpumask, exclude_cpumask))",
            "\t\tcpumask_copy(cpumask, wq_requested_unbound_cpumask);",
            "\tif (!cpumask_equal(cpumask, wq_unbound_cpumask))",
            "\t\tret = workqueue_apply_unbound_cpumask(cpumask);",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tfree_cpumask_var(cpumask);",
            "\treturn ret;",
            "}",
            "static int parse_affn_scope(const char *val)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < ARRAY_SIZE(wq_affn_names); i++) {",
            "\t\tif (!strncasecmp(val, wq_affn_names[i], strlen(wq_affn_names[i])))",
            "\t\t\treturn i;",
            "\t}",
            "\treturn -EINVAL;",
            "}",
            "static int wq_affn_dfl_set(const char *val, const struct kernel_param *kp)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tint affn, cpu;",
            "",
            "\taffn = parse_affn_scope(val);",
            "\tif (affn < 0)",
            "\t\treturn affn;",
            "\tif (affn == WQ_AFFN_DFL)",
            "\t\treturn -EINVAL;",
            "",
            "\tcpus_read_lock();",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\twq_affn_dfl = affn;",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tfor_each_online_cpu(cpu) {",
            "\t\t\twq_update_pod(wq, cpu, cpu, true);",
            "\t\t}",
            "\t}",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tcpus_read_unlock();",
            "",
            "\treturn 0;",
            "}",
            "static int wq_affn_dfl_get(char *buffer, const struct kernel_param *kp)",
            "{",
            "\treturn scnprintf(buffer, PAGE_SIZE, \"%s\\n\", wq_affn_names[wq_affn_dfl]);",
            "}",
            "static ssize_t per_cpu_show(struct device *dev, struct device_attribute *attr,",
            "\t\t\t    char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "",
            "\treturn scnprintf(buf, PAGE_SIZE, \"%d\\n\", (bool)!(wq->flags & WQ_UNBOUND));",
            "}",
            "static ssize_t max_active_show(struct device *dev,",
            "\t\t\t       struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "",
            "\treturn scnprintf(buf, PAGE_SIZE, \"%d\\n\", wq->saved_max_active);",
            "}",
            "static ssize_t max_active_store(struct device *dev,",
            "\t\t\t\tstruct device_attribute *attr, const char *buf,",
            "\t\t\t\tsize_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint val;",
            "",
            "\tif (sscanf(buf, \"%d\", &val) != 1 || val <= 0)",
            "\t\treturn -EINVAL;",
            "",
            "\tworkqueue_set_max_active(wq, val);",
            "\treturn count;",
            "}",
            "static void apply_wqattrs_lock(void)",
            "{",
            "\t/* CPUs should stay stable across pwq creations and installations */",
            "\tcpus_read_lock();",
            "\tmutex_lock(&wq_pool_mutex);",
            "}"
          ],
          "function_name": "workqueue_unbound_exclude_cpumask, parse_affn_scope, wq_affn_dfl_set, wq_affn_dfl_get, per_cpu_show, max_active_show, max_active_store, apply_wqattrs_lock",
          "description": "配置非绑定工作者的CPU排除掩码和默认亲和性策略，暴露工作队列属性供sysfs访问并管理最大并发数参数",
          "similarity": 0.5431827306747437
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/workqueue.c",
          "start_line": 895,
          "end_line": 1037,
          "content": [
            "static inline void worker_clr_flags(struct worker *worker, unsigned int flags)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "\tunsigned int oflags = worker->flags;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\tworker->flags &= ~flags;",
            "",
            "\t/*",
            "\t * If transitioning out of NOT_RUNNING, increment nr_running.  Note",
            "\t * that the nested NOT_RUNNING is not a noop.  NOT_RUNNING is mask",
            "\t * of multiple flags, not a single flag.",
            "\t */",
            "\tif ((flags & WORKER_NOT_RUNNING) && (oflags & WORKER_NOT_RUNNING))",
            "\t\tif (!(worker->flags & WORKER_NOT_RUNNING))",
            "\t\t\tpool->nr_running++;",
            "}",
            "static void worker_enter_idle(struct worker *worker)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "",
            "\tif (WARN_ON_ONCE(worker->flags & WORKER_IDLE) ||",
            "\t    WARN_ON_ONCE(!list_empty(&worker->entry) &&",
            "\t\t\t (worker->hentry.next || worker->hentry.pprev)))",
            "\t\treturn;",
            "",
            "\t/* can't use worker_set_flags(), also called from create_worker() */",
            "\tworker->flags |= WORKER_IDLE;",
            "\tpool->nr_idle++;",
            "\tworker->last_active = jiffies;",
            "",
            "\t/* idle_list is LIFO */",
            "\tlist_add(&worker->entry, &pool->idle_list);",
            "",
            "\tif (too_many_workers(pool) && !timer_pending(&pool->idle_timer))",
            "\t\tmod_timer(&pool->idle_timer, jiffies + IDLE_WORKER_TIMEOUT);",
            "",
            "\t/* Sanity check nr_running. */",
            "\tWARN_ON_ONCE(pool->nr_workers == pool->nr_idle && pool->nr_running);",
            "}",
            "static void worker_leave_idle(struct worker *worker)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "",
            "\tif (WARN_ON_ONCE(!(worker->flags & WORKER_IDLE)))",
            "\t\treturn;",
            "\tworker_clr_flags(worker, WORKER_IDLE);",
            "\tpool->nr_idle--;",
            "\tlist_del_init(&worker->entry);",
            "}",
            "static void move_linked_works(struct work_struct *work, struct list_head *head,",
            "\t\t\t      struct work_struct **nextp)",
            "{",
            "\tstruct work_struct *n;",
            "",
            "\t/*",
            "\t * Linked worklist will always end before the end of the list,",
            "\t * use NULL for list head.",
            "\t */",
            "\tlist_for_each_entry_safe_from(work, n, NULL, entry) {",
            "\t\tlist_move_tail(&work->entry, head);",
            "\t\tif (!(*work_data_bits(work) & WORK_STRUCT_LINKED))",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\t/*",
            "\t * If we're already inside safe list traversal and have moved",
            "\t * multiple works to the scheduled queue, the next position",
            "\t * needs to be updated.",
            "\t */",
            "\tif (nextp)",
            "\t\t*nextp = n;",
            "}",
            "static bool assign_work(struct work_struct *work, struct worker *worker,",
            "\t\t\tstruct work_struct **nextp)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "\tstruct worker *collision;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\t/*",
            "\t * A single work shouldn't be executed concurrently by multiple workers.",
            "\t * __queue_work() ensures that @work doesn't jump to a different pool",
            "\t * while still running in the previous pool. Here, we should ensure that",
            "\t * @work is not executed concurrently by multiple workers from the same",
            "\t * pool. Check whether anyone is already processing the work. If so,",
            "\t * defer the work to the currently executing one.",
            "\t */",
            "\tcollision = find_worker_executing_work(pool, work);",
            "\tif (unlikely(collision)) {",
            "\t\tmove_linked_works(work, &collision->scheduled, nextp);",
            "\t\treturn false;",
            "\t}",
            "",
            "\tmove_linked_works(work, &worker->scheduled, nextp);",
            "\treturn true;",
            "}",
            "static bool kick_pool(struct worker_pool *pool)",
            "{",
            "\tstruct worker *worker = first_idle_worker(pool);",
            "\tstruct task_struct *p;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\tif (!need_more_worker(pool) || !worker)",
            "\t\treturn false;",
            "",
            "\tp = worker->task;",
            "",
            "#ifdef CONFIG_SMP",
            "\t/*",
            "\t * Idle @worker is about to execute @work and waking up provides an",
            "\t * opportunity to migrate @worker at a lower cost by setting the task's",
            "\t * wake_cpu field. Let's see if we want to move @worker to improve",
            "\t * execution locality.",
            "\t *",
            "\t * We're waking the worker that went idle the latest and there's some",
            "\t * chance that @worker is marked idle but hasn't gone off CPU yet. If",
            "\t * so, setting the wake_cpu won't do anything. As this is a best-effort",
            "\t * optimization and the race window is narrow, let's leave as-is for",
            "\t * now. If this becomes pronounced, we can skip over workers which are",
            "\t * still on cpu when picking an idle worker.",
            "\t *",
            "\t * If @pool has non-strict affinity, @worker might have ended up outside",
            "\t * its affinity scope. Repatriate.",
            "\t */",
            "\tif (!pool->attrs->affn_strict &&",
            "\t    !cpumask_test_cpu(p->wake_cpu, pool->attrs->__pod_cpumask)) {",
            "\t\tstruct work_struct *work = list_first_entry(&pool->worklist,",
            "\t\t\t\t\t\tstruct work_struct, entry);",
            "\t\tint wake_cpu = cpumask_any_and_distribute(pool->attrs->__pod_cpumask,",
            "\t\t\t\t\t\t\t  cpu_online_mask);",
            "\t\tif (wake_cpu < nr_cpu_ids) {",
            "\t\t\tp->wake_cpu = wake_cpu;",
            "\t\t\tget_work_pwq(work)->stats[PWQ_STAT_REPATRIATED]++;",
            "\t\t}",
            "\t}",
            "#endif",
            "\twake_up_process(p);",
            "\treturn true;",
            "}"
          ],
          "function_name": "worker_clr_flags, worker_enter_idle, worker_leave_idle, move_linked_works, assign_work, kick_pool",
          "description": "实现工作者线程空闲状态切换和工作项迁移机制，包含空闲工作者列表管理、链接工作项批量转移功能，以及唤醒工作者线程的调度逻辑，支持跨CPU亲和性迁移优化，确保工作项正确分发到可用工作者线程。",
          "similarity": 0.5378751754760742
        },
        {
          "chunk_id": 30,
          "file_path": "kernel/workqueue.c",
          "start_line": 6019,
          "end_line": 6134,
          "content": [
            "static void apply_wqattrs_unlock(void)",
            "{",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tcpus_read_unlock();",
            "}",
            "static ssize_t wq_nice_show(struct device *dev, struct device_attribute *attr,",
            "\t\t\t    char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint written;",
            "",
            "\tmutex_lock(&wq->mutex);",
            "\twritten = scnprintf(buf, PAGE_SIZE, \"%d\\n\", wq->unbound_attrs->nice);",
            "\tmutex_unlock(&wq->mutex);",
            "",
            "\treturn written;",
            "}",
            "static ssize_t wq_nice_store(struct device *dev, struct device_attribute *attr,",
            "\t\t\t     const char *buf, size_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tstruct workqueue_attrs *attrs;",
            "\tint ret = -ENOMEM;",
            "",
            "\tapply_wqattrs_lock();",
            "",
            "\tattrs = wq_sysfs_prep_attrs(wq);",
            "\tif (!attrs)",
            "\t\tgoto out_unlock;",
            "",
            "\tif (sscanf(buf, \"%d\", &attrs->nice) == 1 &&",
            "\t    attrs->nice >= MIN_NICE && attrs->nice <= MAX_NICE)",
            "\t\tret = apply_workqueue_attrs_locked(wq, attrs);",
            "\telse",
            "\t\tret = -EINVAL;",
            "",
            "out_unlock:",
            "\tapply_wqattrs_unlock();",
            "\tfree_workqueue_attrs(attrs);",
            "\treturn ret ?: count;",
            "}",
            "static ssize_t wq_cpumask_show(struct device *dev,",
            "\t\t\t       struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint written;",
            "",
            "\tmutex_lock(&wq->mutex);",
            "\twritten = scnprintf(buf, PAGE_SIZE, \"%*pb\\n\",",
            "\t\t\t    cpumask_pr_args(wq->unbound_attrs->cpumask));",
            "\tmutex_unlock(&wq->mutex);",
            "\treturn written;",
            "}",
            "static ssize_t wq_cpumask_store(struct device *dev,",
            "\t\t\t\tstruct device_attribute *attr,",
            "\t\t\t\tconst char *buf, size_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tstruct workqueue_attrs *attrs;",
            "\tint ret = -ENOMEM;",
            "",
            "\tapply_wqattrs_lock();",
            "",
            "\tattrs = wq_sysfs_prep_attrs(wq);",
            "\tif (!attrs)",
            "\t\tgoto out_unlock;",
            "",
            "\tret = cpumask_parse(buf, attrs->cpumask);",
            "\tif (!ret)",
            "\t\tret = apply_workqueue_attrs_locked(wq, attrs);",
            "",
            "out_unlock:",
            "\tapply_wqattrs_unlock();",
            "\tfree_workqueue_attrs(attrs);",
            "\treturn ret ?: count;",
            "}",
            "static ssize_t wq_affn_scope_show(struct device *dev,",
            "\t\t\t\t  struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint written;",
            "",
            "\tmutex_lock(&wq->mutex);",
            "\tif (wq->unbound_attrs->affn_scope == WQ_AFFN_DFL)",
            "\t\twritten = scnprintf(buf, PAGE_SIZE, \"%s (%s)\\n\",",
            "\t\t\t\t    wq_affn_names[WQ_AFFN_DFL],",
            "\t\t\t\t    wq_affn_names[wq_affn_dfl]);",
            "\telse",
            "\t\twritten = scnprintf(buf, PAGE_SIZE, \"%s\\n\",",
            "\t\t\t\t    wq_affn_names[wq->unbound_attrs->affn_scope]);",
            "\tmutex_unlock(&wq->mutex);",
            "",
            "\treturn written;",
            "}",
            "static ssize_t wq_affn_scope_store(struct device *dev,",
            "\t\t\t\t   struct device_attribute *attr,",
            "\t\t\t\t   const char *buf, size_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tstruct workqueue_attrs *attrs;",
            "\tint affn, ret = -ENOMEM;",
            "",
            "\taffn = parse_affn_scope(buf);",
            "\tif (affn < 0)",
            "\t\treturn affn;",
            "",
            "\tapply_wqattrs_lock();",
            "\tattrs = wq_sysfs_prep_attrs(wq);",
            "\tif (attrs) {",
            "\t\tattrs->affn_scope = affn;",
            "\t\tret = apply_workqueue_attrs_locked(wq, attrs);",
            "\t}",
            "\tapply_wqattrs_unlock();",
            "\tfree_workqueue_attrs(attrs);",
            "\treturn ret ?: count;",
            "}"
          ],
          "function_name": "apply_wqattrs_unlock, wq_nice_show, wq_nice_store, wq_cpumask_show, wq_cpumask_store, wq_affn_scope_show, wq_affn_scope_store",
          "description": "实现工作队列属性的读写接口，通过device attribute接口暴露nice值、CPU掩码及亲和范围配置，支持动态调整工作队列调度策略，包含互斥锁保护和属性应用逻辑。",
          "similarity": 0.5352236032485962
        },
        {
          "chunk_id": 8,
          "file_path": "kernel/workqueue.c",
          "start_line": 1832,
          "end_line": 1933,
          "content": [
            "bool queue_work_on(int cpu, struct workqueue_struct *wq,",
            "\t\t   struct work_struct *work)",
            "{",
            "\tbool ret = false;",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "",
            "\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {",
            "\t\t__queue_work(cpu, wq, work);",
            "\t\tret = true;",
            "\t}",
            "",
            "\tlocal_irq_restore(flags);",
            "\treturn ret;",
            "}",
            "static int select_numa_node_cpu(int node)",
            "{",
            "\tint cpu;",
            "",
            "\t/* Delay binding to CPU if node is not valid or online */",
            "\tif (node < 0 || node >= MAX_NUMNODES || !node_online(node))",
            "\t\treturn WORK_CPU_UNBOUND;",
            "",
            "\t/* Use local node/cpu if we are already there */",
            "\tcpu = raw_smp_processor_id();",
            "\tif (node == cpu_to_node(cpu))",
            "\t\treturn cpu;",
            "",
            "\t/* Use \"random\" otherwise know as \"first\" online CPU of node */",
            "\tcpu = cpumask_any_and(cpumask_of_node(node), cpu_online_mask);",
            "",
            "\t/* If CPU is valid return that, otherwise just defer */",
            "\treturn cpu < nr_cpu_ids ? cpu : WORK_CPU_UNBOUND;",
            "}",
            "bool queue_work_node(int node, struct workqueue_struct *wq,",
            "\t\t     struct work_struct *work)",
            "{",
            "\tunsigned long flags;",
            "\tbool ret = false;",
            "",
            "\t/*",
            "\t * This current implementation is specific to unbound workqueues.",
            "\t * Specifically we only return the first available CPU for a given",
            "\t * node instead of cycling through individual CPUs within the node.",
            "\t *",
            "\t * If this is used with a per-cpu workqueue then the logic in",
            "\t * workqueue_select_cpu_near would need to be updated to allow for",
            "\t * some round robin type logic.",
            "\t */",
            "\tWARN_ON_ONCE(!(wq->flags & WQ_UNBOUND));",
            "",
            "\tlocal_irq_save(flags);",
            "",
            "\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {",
            "\t\tint cpu = select_numa_node_cpu(node);",
            "",
            "\t\t__queue_work(cpu, wq, work);",
            "\t\tret = true;",
            "\t}",
            "",
            "\tlocal_irq_restore(flags);",
            "\treturn ret;",
            "}",
            "void delayed_work_timer_fn(struct timer_list *t)",
            "{",
            "\tstruct delayed_work *dwork = from_timer(dwork, t, timer);",
            "",
            "\t/* should have been called from irqsafe timer with irq already off */",
            "\t__queue_work(dwork->cpu, dwork->wq, &dwork->work);",
            "}",
            "static void __queue_delayed_work(int cpu, struct workqueue_struct *wq,",
            "\t\t\t\tstruct delayed_work *dwork, unsigned long delay)",
            "{",
            "\tstruct timer_list *timer = &dwork->timer;",
            "\tstruct work_struct *work = &dwork->work;",
            "",
            "\tWARN_ON_ONCE(!wq);",
            "\tWARN_ON_ONCE(timer->function != delayed_work_timer_fn);",
            "\tWARN_ON_ONCE(timer_pending(timer));",
            "\tWARN_ON_ONCE(!list_empty(&work->entry));",
            "",
            "\t/*",
            "\t * If @delay is 0, queue @dwork->work immediately.  This is for",
            "\t * both optimization and correctness.  The earliest @timer can",
            "\t * expire is on the closest next tick and delayed_work users depend",
            "\t * on that there's no such delay when @delay is 0.",
            "\t */",
            "\tif (!delay) {",
            "\t\t__queue_work(cpu, wq, &dwork->work);",
            "\t\treturn;",
            "\t}",
            "",
            "\tdwork->wq = wq;",
            "\tdwork->cpu = cpu;",
            "\ttimer->expires = jiffies + delay;",
            "",
            "\tif (unlikely(cpu != WORK_CPU_UNBOUND))",
            "\t\tadd_timer_on(timer, cpu);",
            "\telse",
            "\t\tadd_timer(timer);",
            "}"
          ],
          "function_name": "queue_work_on, select_numa_node_cpu, queue_work_node, delayed_work_timer_fn, __queue_delayed_work",
          "description": "该代码块实现基于NUMA节点的延迟工作调度。queue_work_on指定CPU提交工作；select_numa_node_cpu选择节点对应的CPU；delayed_work_timer_fn作为延迟工作超时时的回调；__queue_delayed_work设置定时器并安排工作项执行。",
          "similarity": 0.5255877375602722
        }
      ]
    },
    {
      "source_file": "kernel/stop_machine.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:30:03\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `stop_machine.c`\n\n---\n\n# `stop_machine.c` 技术文档\n\n## 1. 文件概述\n\n`stop_machine.c` 实现了 Linux 内核中用于在所有（或指定）CPU 上同步执行特定函数的机制，即 **stop_machine** 机制。该机制通过为每个 CPU 创建一个高优先级的内核线程（称为 stopper），在需要时唤醒这些线程以执行指定任务，并确保在执行期间其他任务无法抢占，从而实现对整个系统或部分 CPU 的“冻结”式同步操作。此机制常用于需要全局一致状态的关键内核操作，如 CPU 热插拔、模块加载、内核热补丁（livepatch）等。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct cpu_stop_done`**  \n  用于协调多个 CPU 上 stop 任务的完成状态，包含待完成任务计数（`nr_todo`）、返回值（`ret`）和完成信号量（`completion`）。\n\n- **`struct cpu_stopper`**  \n  每个 CPU 对应一个 stopper 实例，包含：\n  - `thread`：stopper 内核线程\n  - `lock`：保护 pending works 链表的自旋锁\n  - `enabled`：该 stopper 是否启用（对应 CPU 是否在线）\n  - `works`：待执行的 `cpu_stop_work` 链表\n  - `stop_work`、`caller`、`fn`：用于 `stop_cpus` 的临时字段\n\n- **`struct multi_stop_data`**  \n  用于多 CPU 同步执行的共享控制结构，包含：\n  - `fn` 和 `data`：要执行的函数及其参数\n  - `num_threads`：参与同步的线程数\n  - `active_cpus`：指定哪些 CPU 需要实际执行函数\n  - `state`：全局状态机（`MULTI_STOP_*` 枚举）\n  - `thread_ack`：用于状态同步的原子计数器\n\n- **`enum multi_stop_state`**  \n  多 CPU 同步执行的状态机，包括：\n  - `MULTI_STOP_NONE`\n  - `MULTI_STOP_PREPARE`\n  - `MULTI_STOP_DISABLE_IRQ`\n  - `MULTI_STOP_RUN`\n  - `MULTI_STOP_EXIT`\n\n### 主要函数\n\n- **`stop_one_cpu(cpu, fn, arg)`**  \n  在指定 CPU 上执行函数 `fn(arg)`，阻塞等待执行完成。若 CPU 离线则返回 `-ENOENT`。\n\n- **`cpu_stop_queue_work(cpu, work)`**  \n  将 stop 任务加入指定 CPU 的 stopper 队列，若 CPU 在线则唤醒其 stopper 线程。\n\n- **`multi_cpu_stop(data)`**  \n  stopper 线程的主函数，实现多 CPU 同步状态机，负责禁用中断、执行函数、状态同步等。\n\n- **`print_stop_info(log_lvl, task)`**  \n  调试辅助函数，若 `task` 是 stopper 线程，则打印其当前执行函数及调用者信息。\n\n- **`set_state()` / `ack_state()`**  \n  控制多 CPU 同步状态机的推进：`set_state` 设置新状态并重置 ack 计数器，`ack_state` 用于线程确认状态，最后一个确认者推进到下一状态。\n\n## 3. 关键实现\n\n### Stopper 线程模型\n- 每个可能的 CPU 都有一个 `cpu_stopper` 实例，其中包含一个专用内核线程。\n- 该线程运行 `multi_cpu_stop` 函数，处于高优先级实时调度策略（由 `smpboot` 框架设置），可抢占普通任务。\n- 当有 stop 任务时，通过 `wake_up_process` 唤醒对应 stopper 线程。\n\n### 多 CPU 同步状态机\n- 使用共享的 `multi_stop_data` 结构协调所有参与 CPU。\n- 状态转换通过 `set_state` 触发，所有线程通过轮询 `msdata->state` 检测状态变化。\n- 每个状态变更需所有线程调用 `ack_state` 确认，最后一个确认者推进到下一状态，确保严格同步。\n- 在 `MULTI_STOP_DISABLE_IRQ` 状态下，所有参与 CPU 禁用本地中断（包括硬中断），ARM64 还会屏蔽 SDEI 事件。\n- 仅 `active_cpus` 中的 CPU 在 `MULTI_STOP_RUN` 状态执行实际函数。\n\n### 中断与 NMI 安全\n- 执行期间禁用本地中断，防止中断处理程序干扰关键操作。\n- 在等待状态循环中调用 `touch_nmi_watchdog()` 防止 NMI watchdog 误报硬锁死。\n- 使用 `rcu_momentary_dyntick_idle()` 通知 RCU 系统当前 CPU 处于空闲状态，避免 RCU stall。\n\n### CPU 热插拔处理\n- `cpu_stopper.enabled` 标志反映 CPU 在线状态。\n- 若 CPU 离线时提交 stop 任务，则立即完成（调用 `cpu_stop_signal_done`），避免阻塞。\n- 支持从非活动 CPU（如 CPU hotplug 的 bringup 路径）调用 `stop_machine`，此时中断可能已禁用，需保存/恢复中断状态。\n\n### 死锁预防\n- `cpu_stop_queue_two_works` 函数通过嵌套锁（`SINGLE_DEPTH_NESTING`）和重试机制，确保两个 stopper 的入队操作原子性，避免与 `stop_cpus` 并发导致的死锁。\n- 使用 `preempt_disable()` 保证唤醒操作在不可抢占上下文中完成，防止唤醒丢失。\n\n## 4. 依赖关系\n\n- **调度子系统**：依赖 `kthread` 创建 stopper 线程，使用 `wake_up_process` 唤醒。\n- **SMP 子系统**：依赖 `smpboot.h` 的 CPU 热插拔通知机制来启用/禁用 stopper。\n- **中断子系统**：调用 `local_irq_disable/restore`、`hard_irq_disable` 控制中断。\n- **RCU 子系统**：通过 `rcu_momentary_dyntick_idle` 与 RCU 交互。\n- **NMI 子系统**：调用 `touch_nmi_watchdog` 避免 watchdog 误报。\n- **ARM64 架构**：条件编译包含 SDEI（Software Delegated Exception Interface）屏蔽/解除屏蔽。\n- **Per-CPU 基础设施**：使用 `DEFINE_PER_CPU` 和 `per_cpu_ptr` 管理 per-CPU stopper 实例。\n\n## 5. 使用场景\n\n- **CPU 热插拔**：在 CPU 上线/下线过程中执行需要全局同步的操作。\n- **内核模块加载/卸载**：某些架构或功能（如 ftrace）需要 stop_machine 来安全修改内核文本。\n- **内核热补丁（Livepatch）**：在应用补丁时冻结所有 CPU 以确保一致性。\n- **动态 tracing（如 ftrace）**：修改函数入口指令时需 stop_machine 保证原子性。\n- **内存热插拔**：某些内存操作需要全局同步。\n- **内核调试与诊断**：通过 `print_stop_info` 辅助分析 stopper 行为。\n- **架构特定操作**：如 ARM64 的 SDEI 事件处理需要在 stop_machine 上下文中屏蔽。",
      "similarity": 0.6146570444107056,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/stop_machine.c",
          "start_line": 401,
          "end_line": 502,
          "content": [
            "static bool queue_stop_cpus_work(const struct cpumask *cpumask,",
            "\t\t\t\t cpu_stop_fn_t fn, void *arg,",
            "\t\t\t\t struct cpu_stop_done *done)",
            "{",
            "\tstruct cpu_stop_work *work;",
            "\tunsigned int cpu;",
            "\tbool queued = false;",
            "",
            "\t/*",
            "\t * Disable preemption while queueing to avoid getting",
            "\t * preempted by a stopper which might wait for other stoppers",
            "\t * to enter @fn which can lead to deadlock.",
            "\t */",
            "\tpreempt_disable();",
            "\tstop_cpus_in_progress = true;",
            "\tbarrier();",
            "\tfor_each_cpu(cpu, cpumask) {",
            "\t\twork = &per_cpu(cpu_stopper.stop_work, cpu);",
            "\t\twork->fn = fn;",
            "\t\twork->arg = arg;",
            "\t\twork->done = done;",
            "\t\twork->caller = _RET_IP_;",
            "\t\tif (cpu_stop_queue_work(cpu, work))",
            "\t\t\tqueued = true;",
            "\t}",
            "\tbarrier();",
            "\tstop_cpus_in_progress = false;",
            "\tpreempt_enable();",
            "",
            "\treturn queued;",
            "}",
            "static int __stop_cpus(const struct cpumask *cpumask,",
            "\t\t       cpu_stop_fn_t fn, void *arg)",
            "{",
            "\tstruct cpu_stop_done done;",
            "",
            "\tcpu_stop_init_done(&done, cpumask_weight(cpumask));",
            "\tif (!queue_stop_cpus_work(cpumask, fn, arg, &done))",
            "\t\treturn -ENOENT;",
            "\twait_for_completion(&done.completion);",
            "\treturn done.ret;",
            "}",
            "static int stop_cpus(const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg)",
            "{",
            "\tint ret;",
            "",
            "\t/* static works are used, process one request at a time */",
            "\tmutex_lock(&stop_cpus_mutex);",
            "\tret = __stop_cpus(cpumask, fn, arg);",
            "\tmutex_unlock(&stop_cpus_mutex);",
            "\treturn ret;",
            "}",
            "static int cpu_stop_should_run(unsigned int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "\tunsigned long flags;",
            "\tint run;",
            "",
            "\traw_spin_lock_irqsave(&stopper->lock, flags);",
            "\trun = !list_empty(&stopper->works);",
            "\traw_spin_unlock_irqrestore(&stopper->lock, flags);",
            "\treturn run;",
            "}",
            "static void cpu_stopper_thread(unsigned int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "\tstruct cpu_stop_work *work;",
            "",
            "repeat:",
            "\twork = NULL;",
            "\traw_spin_lock_irq(&stopper->lock);",
            "\tif (!list_empty(&stopper->works)) {",
            "\t\twork = list_first_entry(&stopper->works,",
            "\t\t\t\t\tstruct cpu_stop_work, list);",
            "\t\tlist_del_init(&work->list);",
            "\t}",
            "\traw_spin_unlock_irq(&stopper->lock);",
            "",
            "\tif (work) {",
            "\t\tcpu_stop_fn_t fn = work->fn;",
            "\t\tvoid *arg = work->arg;",
            "\t\tstruct cpu_stop_done *done = work->done;",
            "\t\tint ret;",
            "",
            "\t\t/* cpu stop callbacks must not sleep, make in_atomic() == T */",
            "\t\tstopper->caller = work->caller;",
            "\t\tstopper->fn = fn;",
            "\t\tpreempt_count_inc();",
            "\t\tret = fn(arg);",
            "\t\tif (done) {",
            "\t\t\tif (ret)",
            "\t\t\t\tdone->ret = ret;",
            "\t\t\tcpu_stop_signal_done(done);",
            "\t\t}",
            "\t\tpreempt_count_dec();",
            "\t\tstopper->fn = NULL;",
            "\t\tstopper->caller = 0;",
            "\t\tWARN_ONCE(preempt_count(),",
            "\t\t\t  \"cpu_stop: %ps(%p) leaked preempt count\\n\", fn, arg);",
            "\t\tgoto repeat;",
            "\t}",
            "}"
          ],
          "function_name": "queue_stop_cpus_work, __stop_cpus, stop_cpus, cpu_stop_should_run, cpu_stopper_thread",
          "description": "实现批量CPU停止的中枢逻辑，通过互斥锁保证串行化处理。包含工作分发、停止执行、状态追踪等功能，支持通用CPU掩码的停止操作，并提供预处理检查和结果收集机制。",
          "similarity": 0.5373155474662781
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/stop_machine.c",
          "start_line": 269,
          "end_line": 369,
          "content": [
            "static int cpu_stop_queue_two_works(int cpu1, struct cpu_stop_work *work1,",
            "\t\t\t\t    int cpu2, struct cpu_stop_work *work2)",
            "{",
            "\tstruct cpu_stopper *stopper1 = per_cpu_ptr(&cpu_stopper, cpu1);",
            "\tstruct cpu_stopper *stopper2 = per_cpu_ptr(&cpu_stopper, cpu2);",
            "\tint err;",
            "",
            "retry:",
            "\t/*",
            "\t * The waking up of stopper threads has to happen in the same",
            "\t * scheduling context as the queueing.  Otherwise, there is a",
            "\t * possibility of one of the above stoppers being woken up by another",
            "\t * CPU, and preempting us. This will cause us to not wake up the other",
            "\t * stopper forever.",
            "\t */",
            "\tpreempt_disable();",
            "\traw_spin_lock_irq(&stopper1->lock);",
            "\traw_spin_lock_nested(&stopper2->lock, SINGLE_DEPTH_NESTING);",
            "",
            "\tif (!stopper1->enabled || !stopper2->enabled) {",
            "\t\terr = -ENOENT;",
            "\t\tgoto unlock;",
            "\t}",
            "",
            "\t/*",
            "\t * Ensure that if we race with __stop_cpus() the stoppers won't get",
            "\t * queued up in reverse order leading to system deadlock.",
            "\t *",
            "\t * We can't miss stop_cpus_in_progress if queue_stop_cpus_work() has",
            "\t * queued a work on cpu1 but not on cpu2, we hold both locks.",
            "\t *",
            "\t * It can be falsely true but it is safe to spin until it is cleared,",
            "\t * queue_stop_cpus_work() does everything under preempt_disable().",
            "\t */",
            "\tif (unlikely(stop_cpus_in_progress)) {",
            "\t\terr = -EDEADLK;",
            "\t\tgoto unlock;",
            "\t}",
            "",
            "\terr = 0;",
            "\t__cpu_stop_queue_work(stopper1, work1);",
            "\t__cpu_stop_queue_work(stopper2, work2);",
            "",
            "unlock:",
            "\traw_spin_unlock(&stopper2->lock);",
            "\traw_spin_unlock_irq(&stopper1->lock);",
            "",
            "\tif (unlikely(err == -EDEADLK)) {",
            "\t\tpreempt_enable();",
            "",
            "\t\twhile (stop_cpus_in_progress)",
            "\t\t\tcpu_relax();",
            "",
            "\t\tgoto retry;",
            "\t}",
            "",
            "\tif (!err) {",
            "\t\twake_up_process(stopper1->thread);",
            "\t\twake_up_process(stopper2->thread);",
            "\t}",
            "\tpreempt_enable();",
            "",
            "\treturn err;",
            "}",
            "int stop_two_cpus(unsigned int cpu1, unsigned int cpu2, cpu_stop_fn_t fn, void *arg)",
            "{",
            "\tstruct cpu_stop_done done;",
            "\tstruct cpu_stop_work work1, work2;",
            "\tstruct multi_stop_data msdata;",
            "",
            "\tmsdata = (struct multi_stop_data){",
            "\t\t.fn = fn,",
            "\t\t.data = arg,",
            "\t\t.num_threads = 2,",
            "\t\t.active_cpus = cpumask_of(cpu1),",
            "\t};",
            "",
            "\twork1 = work2 = (struct cpu_stop_work){",
            "\t\t.fn = multi_cpu_stop,",
            "\t\t.arg = &msdata,",
            "\t\t.done = &done,",
            "\t\t.caller = _RET_IP_,",
            "\t};",
            "",
            "\tcpu_stop_init_done(&done, 2);",
            "\tset_state(&msdata, MULTI_STOP_PREPARE);",
            "",
            "\tif (cpu1 > cpu2)",
            "\t\tswap(cpu1, cpu2);",
            "\tif (cpu_stop_queue_two_works(cpu1, &work1, cpu2, &work2))",
            "\t\treturn -ENOENT;",
            "",
            "\twait_for_completion(&done.completion);",
            "\treturn done.ret;",
            "}",
            "bool stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,",
            "\t\t\tstruct cpu_stop_work *work_buf)",
            "{",
            "\t*work_buf = (struct cpu_stop_work){ .fn = fn, .arg = arg, .caller = _RET_IP_, };",
            "\treturn cpu_stop_queue_work(cpu, work_buf);",
            "}"
          ],
          "function_name": "cpu_stop_queue_two_works, stop_two_cpus, stop_one_cpu_nowait",
          "description": "实现双CPU停止操作的协同逻辑，通过原子操作防止死锁，确保两个CPU的停止工作被正确排队和唤醒。包含针对两个CPU的停止接口和非阻塞式单CPU停止标记功能。",
          "similarity": 0.5294476747512817
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/stop_machine.c",
          "start_line": 56,
          "end_line": 201,
          "content": [
            "void print_stop_info(const char *log_lvl, struct task_struct *task)",
            "{",
            "\t/*",
            "\t * If @task is a stopper task, it cannot migrate and task_cpu() is",
            "\t * stable.",
            "\t */",
            "\tstruct cpu_stopper *stopper = per_cpu_ptr(&cpu_stopper, task_cpu(task));",
            "",
            "\tif (task != stopper->thread)",
            "\t\treturn;",
            "",
            "\tprintk(\"%sStopper: %pS <- %pS\\n\", log_lvl, stopper->fn, (void *)stopper->caller);",
            "}",
            "static void cpu_stop_init_done(struct cpu_stop_done *done, unsigned int nr_todo)",
            "{",
            "\tmemset(done, 0, sizeof(*done));",
            "\tatomic_set(&done->nr_todo, nr_todo);",
            "\tinit_completion(&done->completion);",
            "}",
            "static void cpu_stop_signal_done(struct cpu_stop_done *done)",
            "{",
            "\tif (atomic_dec_and_test(&done->nr_todo))",
            "\t\tcomplete(&done->completion);",
            "}",
            "static void __cpu_stop_queue_work(struct cpu_stopper *stopper,",
            "\t\t\t\t  struct cpu_stop_work *work)",
            "{",
            "\tlist_add_tail(&work->list, &stopper->works);",
            "}",
            "static bool cpu_stop_queue_work(unsigned int cpu, struct cpu_stop_work *work)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "\tunsigned long flags;",
            "\tbool enabled;",
            "",
            "\tpreempt_disable();",
            "\traw_spin_lock_irqsave(&stopper->lock, flags);",
            "\tenabled = stopper->enabled;",
            "\tif (enabled)",
            "\t\t__cpu_stop_queue_work(stopper, work);",
            "\telse if (work->done)",
            "\t\tcpu_stop_signal_done(work->done);",
            "\traw_spin_unlock_irqrestore(&stopper->lock, flags);",
            "",
            "\tif (enabled)",
            "\t\twake_up_process(stopper->thread);",
            "\tpreempt_enable();",
            "",
            "\treturn enabled;",
            "}",
            "int stop_one_cpu(unsigned int cpu, cpu_stop_fn_t fn, void *arg)",
            "{",
            "\tstruct cpu_stop_done done;",
            "\tstruct cpu_stop_work work = { .fn = fn, .arg = arg, .done = &done, .caller = _RET_IP_ };",
            "",
            "\tcpu_stop_init_done(&done, 1);",
            "\tif (!cpu_stop_queue_work(cpu, &work))",
            "\t\treturn -ENOENT;",
            "\t/*",
            "\t * In case @cpu == smp_proccessor_id() we can avoid a sleep+wakeup",
            "\t * cycle by doing a preemption:",
            "\t */",
            "\tcond_resched();",
            "\twait_for_completion(&done.completion);",
            "\treturn done.ret;",
            "}",
            "static void set_state(struct multi_stop_data *msdata,",
            "\t\t      enum multi_stop_state newstate)",
            "{",
            "\t/* Reset ack counter. */",
            "\tatomic_set(&msdata->thread_ack, msdata->num_threads);",
            "\tsmp_wmb();",
            "\tWRITE_ONCE(msdata->state, newstate);",
            "}",
            "static void ack_state(struct multi_stop_data *msdata)",
            "{",
            "\tif (atomic_dec_and_test(&msdata->thread_ack))",
            "\t\tset_state(msdata, msdata->state + 1);",
            "}",
            "notrace void __weak stop_machine_yield(const struct cpumask *cpumask)",
            "{",
            "\tcpu_relax();",
            "}",
            "static int multi_cpu_stop(void *data)",
            "{",
            "\tstruct multi_stop_data *msdata = data;",
            "\tenum multi_stop_state newstate, curstate = MULTI_STOP_NONE;",
            "\tint cpu = smp_processor_id(), err = 0;",
            "\tconst struct cpumask *cpumask;",
            "\tunsigned long flags;",
            "\tbool is_active;",
            "",
            "\t/*",
            "\t * When called from stop_machine_from_inactive_cpu(), irq might",
            "\t * already be disabled.  Save the state and restore it on exit.",
            "\t */",
            "\tlocal_save_flags(flags);",
            "",
            "\tif (!msdata->active_cpus) {",
            "\t\tcpumask = cpu_online_mask;",
            "\t\tis_active = cpu == cpumask_first(cpumask);",
            "\t} else {",
            "\t\tcpumask = msdata->active_cpus;",
            "\t\tis_active = cpumask_test_cpu(cpu, cpumask);",
            "\t}",
            "",
            "\t/* Simple state machine */",
            "\tdo {",
            "\t\t/* Chill out and ensure we re-read multi_stop_state. */",
            "\t\tstop_machine_yield(cpumask);",
            "\t\tnewstate = READ_ONCE(msdata->state);",
            "\t\tif (newstate != curstate) {",
            "\t\t\tcurstate = newstate;",
            "\t\t\tswitch (curstate) {",
            "\t\t\tcase MULTI_STOP_DISABLE_IRQ:",
            "\t\t\t\tlocal_irq_disable();",
            "\t\t\t\thard_irq_disable();",
            "#ifdef CONFIG_ARM64",
            "\t\t\t\tsdei_mask_local_cpu();",
            "#endif",
            "\t\t\t\tbreak;",
            "\t\t\tcase MULTI_STOP_RUN:",
            "\t\t\t\tif (is_active)",
            "\t\t\t\t\terr = msdata->fn(msdata->data);",
            "\t\t\t\tbreak;",
            "\t\t\tdefault:",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t\tack_state(msdata);",
            "\t\t} else if (curstate > MULTI_STOP_PREPARE) {",
            "\t\t\t/*",
            "\t\t\t * At this stage all other CPUs we depend on must spin",
            "\t\t\t * in the same loop. Any reason for hard-lockup should",
            "\t\t\t * be detected and reported on their side.",
            "\t\t\t */",
            "\t\t\ttouch_nmi_watchdog();",
            "\t\t}",
            "\t\trcu_momentary_dyntick_idle();",
            "\t} while (curstate != MULTI_STOP_EXIT);",
            "",
            "#ifdef CONFIG_ARM64",
            "\tsdei_unmask_local_cpu();",
            "#endif",
            "\tlocal_irq_restore(flags);",
            "\treturn err;",
            "}"
          ],
          "function_name": "print_stop_info, cpu_stop_init_done, cpu_stop_signal_done, __cpu_stop_queue_work, cpu_stop_queue_work, stop_one_cpu, set_state, ack_state, stop_machine_yield, multi_cpu_stop",
          "description": "实现了停止操作的核心控制逻辑，包括工作队列管理、状态同步、单CPU停止处理及多CPU状态机。提供打印停止信息、初始化完成状态、信号完成、排队工作、单CPU停止、状态切换等辅助函数。",
          "similarity": 0.5186982154846191
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/stop_machine.c",
          "start_line": 687,
          "end_line": 716,
          "content": [
            "int stop_machine_from_inactive_cpu(cpu_stop_fn_t fn, void *data,",
            "\t\t\t\t  const struct cpumask *cpus)",
            "{",
            "\tstruct multi_stop_data msdata = { .fn = fn, .data = data,",
            "\t\t\t\t\t    .active_cpus = cpus };",
            "\tstruct cpu_stop_done done;",
            "\tint ret;",
            "",
            "\t/* Local CPU must be inactive and CPU hotplug in progress. */",
            "\tBUG_ON(cpu_active(raw_smp_processor_id()));",
            "\tmsdata.num_threads = num_active_cpus() + 1;\t/* +1 for local */",
            "",
            "\t/* No proper task established and can't sleep - busy wait for lock. */",
            "\twhile (!mutex_trylock(&stop_cpus_mutex))",
            "\t\tcpu_relax();",
            "",
            "\t/* Schedule work on other CPUs and execute directly for local CPU */",
            "\tset_state(&msdata, MULTI_STOP_PREPARE);",
            "\tcpu_stop_init_done(&done, num_active_cpus());",
            "\tqueue_stop_cpus_work(cpu_active_mask, multi_cpu_stop, &msdata,",
            "\t\t\t     &done);",
            "\tret = multi_cpu_stop(&msdata);",
            "",
            "\t/* Busy wait for completion. */",
            "\twhile (!completion_done(&done.completion))",
            "\t\tcpu_relax();",
            "",
            "\tmutex_unlock(&stop_cpus_mutex);",
            "\treturn ret ?: done.ret;",
            "}"
          ],
          "function_name": "stop_machine_from_inactive_cpu",
          "description": "该函数用于在非活跃CPU上协调多CPU的停止操作，确保在CPU热插拔期间正确执行停止回调函数。  \n通过获取互斥锁、异步调度任务并在本地直接执行，最终阻塞等待所有停止操作完成。  \n依赖未显示的辅助函数（如`queue_stop_cpus_work`和`multi_cpu_stop`），上下文可能存在不完整情况。",
          "similarity": 0.4921301603317261
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/stop_machine.c",
          "start_line": 536,
          "end_line": 641,
          "content": [
            "void stop_machine_park(int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "\t/*",
            "\t * Lockless. cpu_stopper_thread() will take stopper->lock and flush",
            "\t * the pending works before it parks, until then it is fine to queue",
            "\t * the new works.",
            "\t */",
            "\tstopper->enabled = false;",
            "\tkthread_park(stopper->thread);",
            "}",
            "static void cpu_stop_create(unsigned int cpu)",
            "{",
            "\tsched_set_stop_task(cpu, per_cpu(cpu_stopper.thread, cpu));",
            "}",
            "static void cpu_stop_park(unsigned int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "",
            "\tWARN_ON(!list_empty(&stopper->works));",
            "}",
            "void stop_machine_unpark(int cpu)",
            "{",
            "\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "",
            "\tstopper->enabled = true;",
            "\tkthread_unpark(stopper->thread);",
            "}",
            "static int __init cpu_stop_init(void)",
            "{",
            "\tunsigned int cpu;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tstruct cpu_stopper *stopper = &per_cpu(cpu_stopper, cpu);",
            "",
            "\t\traw_spin_lock_init(&stopper->lock);",
            "\t\tINIT_LIST_HEAD(&stopper->works);",
            "\t}",
            "",
            "\tBUG_ON(smpboot_register_percpu_thread(&cpu_stop_threads));",
            "\tstop_machine_unpark(raw_smp_processor_id());",
            "\tstop_machine_initialized = true;",
            "\treturn 0;",
            "}",
            "int stop_machine_cpuslocked(cpu_stop_fn_t fn, void *data,",
            "\t\t\t    const struct cpumask *cpus)",
            "{",
            "\tstruct multi_stop_data msdata = {",
            "\t\t.fn = fn,",
            "\t\t.data = data,",
            "\t\t.num_threads = num_online_cpus(),",
            "\t\t.active_cpus = cpus,",
            "\t};",
            "",
            "\tlockdep_assert_cpus_held();",
            "",
            "\tif (!stop_machine_initialized) {",
            "\t\t/*",
            "\t\t * Handle the case where stop_machine() is called",
            "\t\t * early in boot before stop_machine() has been",
            "\t\t * initialized.",
            "\t\t */",
            "\t\tunsigned long flags;",
            "\t\tint ret;",
            "",
            "\t\tWARN_ON_ONCE(msdata.num_threads != 1);",
            "",
            "\t\tlocal_irq_save(flags);",
            "\t\thard_irq_disable();",
            "\t\tret = (*fn)(data);",
            "\t\tlocal_irq_restore(flags);",
            "",
            "\t\treturn ret;",
            "\t}",
            "",
            "\t/* Set the initial state and stop all online cpus. */",
            "\tset_state(&msdata, MULTI_STOP_PREPARE);",
            "\treturn stop_cpus(cpu_online_mask, multi_cpu_stop, &msdata);",
            "}",
            "int stop_machine(cpu_stop_fn_t fn, void *data, const struct cpumask *cpus)",
            "{",
            "\tint ret;",
            "",
            "\t/* No CPUs can come up or down during this. */",
            "\tcpus_read_lock();",
            "\tret = stop_machine_cpuslocked(fn, data, cpus);",
            "\tcpus_read_unlock();",
            "\treturn ret;",
            "}",
            "int stop_core_cpuslocked(unsigned int cpu, cpu_stop_fn_t fn, void *data)",
            "{",
            "\tconst struct cpumask *smt_mask = cpu_smt_mask(cpu);",
            "",
            "\tstruct multi_stop_data msdata = {",
            "\t\t.fn = fn,",
            "\t\t.data = data,",
            "\t\t.num_threads = cpumask_weight(smt_mask),",
            "\t\t.active_cpus = smt_mask,",
            "\t};",
            "",
            "\tlockdep_assert_cpus_held();",
            "",
            "\t/* Set the initial state and stop all online cpus. */",
            "\tset_state(&msdata, MULTI_STOP_PREPARE);",
            "\treturn stop_cpus(smt_mask, multi_cpu_stop, &msdata);",
            "}"
          ],
          "function_name": "stop_machine_park, cpu_stop_create, cpu_stop_park, stop_machine_unpark, cpu_stop_init, stop_machine_cpuslocked, stop_machine, stop_core_cpuslocked",
          "description": "负责停止器线程的生命周期管理和初始化。包含线程创建、挂起/恢复操作、核心初始化函数，以及带锁的CPU停止接口。提供针对特定CPU核心的停止功能和早期启动阶段的降级处理路径。",
          "similarity": 0.47935324907302856
        }
      ]
    }
  ]
}