{
  "query": "页表在地址转换中的作用",
  "timestamp": "2025-12-26 00:12:50",
  "retrieved_files": [
    {
      "source_file": "mm/page_io.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:03:03\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `page_io.c`\n\n---\n\n# page_io.c 技术文档\n\n## 1. 文件概述\n\n`page_io.c` 是 Linux 内核内存管理子系统中负责页面交换 I/O 操作的核心文件。该文件实现了将匿名页写入交换设备（swap-out）和从交换设备读回内存（swap-in）的底层机制，包括基于 `bio` 的块设备交换路径和基于文件系统的直接 I/O 交换路径。此外，还提供了通用的交换文件激活逻辑，用于在启用交换文件时构建物理块到交换页的映射。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `__end_swap_bio_write()` / `end_swap_bio_write()`：处理交换写操作完成的回调，处理写错误并结束写回。\n- `__end_swap_bio_read()` / `end_swap_bio_read()`：处理交换读操作完成的回调，设置页面 uptodate 状态或报告读错误。\n- `generic_swapfile_activate()`：为基于文件的交换设备（如 swapfile）构建连续的物理块映射，填充 `swap_info_struct`。\n- `swap_writepage()`：页面写回交换区的主入口函数，支持 zswap 压缩缓存、内存控制组限制等特性。\n- `swap_writepage_fs()`：通过文件系统直接 I/O 路径（如 swap-over-NFS）执行交换写操作。\n- `sio_pool_init()`：初始化用于异步交换 I/O 的内存池。\n- `sio_write_complete()`：处理基于 kiocb 的异步交换写完成回调。\n\n### 关键数据结构\n\n- `struct swap_iocb`：封装用于文件系统交换 I/O 的 `kiocb` 和 `bio_vec` 数组，支持批量交换页写入。\n- `sio_pool`：`mempool_t` 类型的内存池，用于分配 `swap_iocb` 结构，避免高内存压力下分配失败。\n\n## 3. 关键实现\n\n### 交换 I/O 完成处理\n- 写操作失败时，页面被重新标记为 dirty 并清除 `PG_reclaim` 标志，防止被错误回收，同时输出限频警告日志。\n- 读操作失败仅输出警告；成功则设置 `PG_uptodate` 并解锁页面。\n\n### 交换文件激活 (`generic_swapfile_activate`)\n- 遍历交换文件的逻辑块，使用 `bmap()` 获取物理块号。\n- 验证每个 PAGE_SIZE 对齐区域的物理块是否连续且对齐。\n- 通过 `add_swap_extent()` 将有效的交换页范围注册到交换子系统。\n- 计算交换空间的物理跨度（`span`），用于优化交换分配策略。\n\n### 交换写入路径选择\n- 默认使用 `__swap_writepage()`（基于 `bio` 的块设备路径）。\n- 若启用了 zswap 且压缩存储成功，则跳过磁盘 I/O。\n- 若内存控制组禁用 zswap 回写，则返回 `AOP_WRITEPAGE_ACTIVATE` 以保留页面在内存中。\n- 对于 NFS 等不支持 `bmap` 的文件系统，使用 `swap_writepage_fs()` 路径，通过 `kiocb` 异步 DIO 写入。\n\n### 异步交换 I/O 批处理\n- `swap_writepage_fs()` 支持通过 `wbc->swap_plug` 合并多个相邻页面的写请求到同一个 `swap_iocb`。\n- 利用 `mempool` 保证在内存紧张时仍能分配 I/O 控制块。\n- 完成回调中处理部分写入错误，标记所有相关页面为 dirty 并结束写回。\n\n### 资源统计与控制\n- 通过 `count_swpout_vm_event()` 更新透明大页（THP）和普通页的交换出计数。\n- 在配置了 MEMCG 和 BLK_CGROUP 时，通过 `bio_associate_blkg_from_page()` 将 I/O 请求关联到页面所属的 blkcg，实现 I/O 资源隔离。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm.h>`、`<linux/swap.h>`、`<linux/pagemap.h>` 等，与页面回收、反向映射、内存控制组紧密集成。\n- **块设备层**：通过 `<linux/bio.h>`、`<linux/blkdev.h>` 与块 I/O 子系统交互。\n- **文件系统接口**：使用 `bmap()` 和 `kiocb` 与具体文件系统（如 ext4、xfs）或网络文件系统（如 NFS）协作。\n- **压缩子系统**：集成 `<linux/zswap.h>`，支持透明压缩交换缓存。\n- **资源控制器**：依赖 MEMCG 和 BLK_CGROUP 实现内存与 I/O 的多租户隔离。\n- **内部头文件**：包含本地 `\"swap.h\"` 获取交换子系统私有接口。\n\n## 5. 使用场景\n\n- **系统内存不足时**：页面回收机制调用 `swap_writepage()` 将匿名页换出到交换设备。\n- **启用交换文件时**：`swapon` 系统调用执行 `generic_swapfile_activate()` 初始化交换文件的物理布局。\n- **从交换区缺页中断**：当访问已换出页面时，内核通过 `end_swap_bio_read` 路径将数据读回内存。\n- **容器环境**：在启用内存和 I/O 控制组的系统中，确保交换 I/O 正确归属到对应 cgroup。\n- **使用压缩交换缓存**：当 zswap 启用时，优先尝试压缩页面而非立即写入慢速交换设备。\n- **网络交换场景**：在无本地块设备的环境中（如云实例使用 NFS 作为交换后端），通过 `swap_writepage_fs()` 路径完成交换。",
      "similarity": 0.5920317769050598,
      "chunks": [
        {
          "chunk_id": 5,
          "file_path": "mm/page_io.c",
          "start_line": 543,
          "end_line": 553,
          "content": [
            "void __swap_read_unplug(struct swap_iocb *sio)",
            "{",
            "\tstruct iov_iter from;",
            "\tstruct address_space *mapping = sio->iocb.ki_filp->f_mapping;",
            "\tint ret;",
            "",
            "\tiov_iter_bvec(&from, ITER_DEST, sio->bvec, sio->pages, sio->len);",
            "\tret = mapping->a_ops->swap_rw(&sio->iocb, &from);",
            "\tif (ret != -EIOCBQUEUED)",
            "\t\tsio_read_complete(&sio->iocb, ret);",
            "}"
          ],
          "function_name": "__swap_read_unplug",
          "description": "该函数是处理交换读取操作的关键函数，在页置换过程中将从交换设备读取的数据通过I/O向量传递至文件地址空间。  \n它通过构建iov_iter并调用address_space的a_ops->swap_rw接口进行实际的数据读取，并根据返回状态触发相应的完成回调。  \n注：swap_rw的具体实现依赖于对应文件系统的a_ops，此处上下文不完整。",
          "similarity": 0.6014976501464844
        },
        {
          "chunk_id": 0,
          "file_path": "mm/page_io.c",
          "start_line": 1,
          "end_line": 29,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " *  linux/mm/page_io.c",
            " *",
            " *  Copyright (C) 1991, 1992, 1993, 1994  Linus Torvalds",
            " *",
            " *  Swap reorganised 29.12.95, ",
            " *  Asynchronous swapping added 30.12.95. Stephen Tweedie",
            " *  Removed race in async swapping. 14.4.1996. Bruno Haible",
            " *  Add swap of shared pages through the page cache. 20.2.1998. Stephen Tweedie",
            " *  Always use brw_page, life becomes simpler. 12 May 1998 Eric Biederman",
            " */",
            "",
            "#include <linux/mm.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/gfp.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/swap.h>",
            "#include <linux/bio.h>",
            "#include <linux/swapops.h>",
            "#include <linux/writeback.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/psi.h>",
            "#include <linux/uio.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/zswap.h>",
            "#include \"swap.h\"",
            ""
          ],
          "function_name": null,
          "description": "声明头文件并引入交换页面管理模块的基本依赖，为后续交换操作提供基础框架。",
          "similarity": 0.5984888076782227
        },
        {
          "chunk_id": 1,
          "file_path": "mm/page_io.c",
          "start_line": 30,
          "end_line": 169,
          "content": [
            "static void __end_swap_bio_write(struct bio *bio)",
            "{",
            "\tstruct folio *folio = bio_first_folio_all(bio);",
            "",
            "\tif (bio->bi_status) {",
            "\t\t/*",
            "\t\t * We failed to write the page out to swap-space.",
            "\t\t * Re-dirty the page in order to avoid it being reclaimed.",
            "\t\t * Also print a dire warning that things will go BAD (tm)",
            "\t\t * very quickly.",
            "\t\t *",
            "\t\t * Also clear PG_reclaim to avoid folio_rotate_reclaimable()",
            "\t\t */",
            "\t\tfolio_mark_dirty(folio);",
            "\t\tpr_alert_ratelimited(\"Write-error on swap-device (%u:%u:%llu)\\n\",",
            "\t\t\t\t     MAJOR(bio_dev(bio)), MINOR(bio_dev(bio)),",
            "\t\t\t\t     (unsigned long long)bio->bi_iter.bi_sector);",
            "\t\tfolio_clear_reclaim(folio);",
            "\t}",
            "\tfolio_end_writeback(folio);",
            "}",
            "static void end_swap_bio_write(struct bio *bio)",
            "{",
            "\t__end_swap_bio_write(bio);",
            "\tbio_put(bio);",
            "}",
            "static void __end_swap_bio_read(struct bio *bio)",
            "{",
            "\tstruct folio *folio = bio_first_folio_all(bio);",
            "",
            "\tif (bio->bi_status) {",
            "\t\tpr_alert_ratelimited(\"Read-error on swap-device (%u:%u:%llu)\\n\",",
            "\t\t\t\t     MAJOR(bio_dev(bio)), MINOR(bio_dev(bio)),",
            "\t\t\t\t     (unsigned long long)bio->bi_iter.bi_sector);",
            "\t} else {",
            "\t\tfolio_mark_uptodate(folio);",
            "\t}",
            "\tfolio_unlock(folio);",
            "}",
            "static void end_swap_bio_read(struct bio *bio)",
            "{",
            "\t__end_swap_bio_read(bio);",
            "\tbio_put(bio);",
            "}",
            "int generic_swapfile_activate(struct swap_info_struct *sis,",
            "\t\t\t\tstruct file *swap_file,",
            "\t\t\t\tsector_t *span)",
            "{",
            "\tstruct address_space *mapping = swap_file->f_mapping;",
            "\tstruct inode *inode = mapping->host;",
            "\tunsigned blocks_per_page;",
            "\tunsigned long page_no;",
            "\tunsigned blkbits;",
            "\tsector_t probe_block;",
            "\tsector_t last_block;",
            "\tsector_t lowest_block = -1;",
            "\tsector_t highest_block = 0;",
            "\tint nr_extents = 0;",
            "\tint ret;",
            "",
            "\tblkbits = inode->i_blkbits;",
            "\tblocks_per_page = PAGE_SIZE >> blkbits;",
            "",
            "\t/*",
            "\t * Map all the blocks into the extent tree.  This code doesn't try",
            "\t * to be very smart.",
            "\t */",
            "\tprobe_block = 0;",
            "\tpage_no = 0;",
            "\tlast_block = i_size_read(inode) >> blkbits;",
            "\twhile ((probe_block + blocks_per_page) <= last_block &&",
            "\t\t\tpage_no < sis->max) {",
            "\t\tunsigned block_in_page;",
            "\t\tsector_t first_block;",
            "",
            "\t\tcond_resched();",
            "",
            "\t\tfirst_block = probe_block;",
            "\t\tret = bmap(inode, &first_block);",
            "\t\tif (ret || !first_block)",
            "\t\t\tgoto bad_bmap;",
            "",
            "\t\t/*",
            "\t\t * It must be PAGE_SIZE aligned on-disk",
            "\t\t */",
            "\t\tif (first_block & (blocks_per_page - 1)) {",
            "\t\t\tprobe_block++;",
            "\t\t\tgoto reprobe;",
            "\t\t}",
            "",
            "\t\tfor (block_in_page = 1; block_in_page < blocks_per_page;",
            "\t\t\t\t\tblock_in_page++) {",
            "\t\t\tsector_t block;",
            "",
            "\t\t\tblock = probe_block + block_in_page;",
            "\t\t\tret = bmap(inode, &block);",
            "\t\t\tif (ret || !block)",
            "\t\t\t\tgoto bad_bmap;",
            "",
            "\t\t\tif (block != first_block + block_in_page) {",
            "\t\t\t\t/* Discontiguity */",
            "\t\t\t\tprobe_block++;",
            "\t\t\t\tgoto reprobe;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tfirst_block >>= (PAGE_SHIFT - blkbits);",
            "\t\tif (page_no) {\t/* exclude the header page */",
            "\t\t\tif (first_block < lowest_block)",
            "\t\t\t\tlowest_block = first_block;",
            "\t\t\tif (first_block > highest_block)",
            "\t\t\t\thighest_block = first_block;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * We found a PAGE_SIZE-length, PAGE_SIZE-aligned run of blocks",
            "\t\t */",
            "\t\tret = add_swap_extent(sis, page_no, 1, first_block);",
            "\t\tif (ret < 0)",
            "\t\t\tgoto out;",
            "\t\tnr_extents += ret;",
            "\t\tpage_no++;",
            "\t\tprobe_block += blocks_per_page;",
            "reprobe:",
            "\t\tcontinue;",
            "\t}",
            "\tret = nr_extents;",
            "\t*span = 1 + highest_block - lowest_block;",
            "\tif (page_no == 0)",
            "\t\tpage_no = 1;\t/* force Empty message */",
            "\tsis->max = page_no;",
            "\tsis->pages = page_no - 1;",
            "\tsis->highest_bit = page_no - 1;",
            "out:",
            "\treturn ret;",
            "bad_bmap:",
            "\tpr_err(\"swapon: swapfile has holes\\n\");",
            "\tret = -EINVAL;",
            "\tgoto out;",
            "}"
          ],
          "function_name": "__end_swap_bio_write, end_swap_bio_write, __end_swap_bio_read, end_swap_bio_read, generic_swapfile_activate",
          "description": "实现交换I/O完成回调函数，处理写入错误重标记脏页及读取错误日志；generic_swapfile_activate扫描交换文件块并构建交换区范围。",
          "similarity": 0.565778374671936
        },
        {
          "chunk_id": 3,
          "file_path": "mm/page_io.c",
          "start_line": 298,
          "end_line": 400,
          "content": [
            "static void swap_writepage_fs(struct folio *folio, struct writeback_control *wbc)",
            "{",
            "\tstruct swap_iocb *sio = NULL;",
            "\tstruct swap_info_struct *sis = swp_swap_info(folio->swap);",
            "\tstruct file *swap_file = sis->swap_file;",
            "\tloff_t pos = folio_file_pos(folio);",
            "",
            "\tcount_swpout_vm_event(folio);",
            "\tfolio_start_writeback(folio);",
            "\tfolio_unlock(folio);",
            "\tif (wbc->swap_plug)",
            "\t\tsio = *wbc->swap_plug;",
            "\tif (sio) {",
            "\t\tif (sio->iocb.ki_filp != swap_file ||",
            "\t\t    sio->iocb.ki_pos + sio->len != pos) {",
            "\t\t\tswap_write_unplug(sio);",
            "\t\t\tsio = NULL;",
            "\t\t}",
            "\t}",
            "\tif (!sio) {",
            "\t\tsio = mempool_alloc(sio_pool, GFP_NOIO);",
            "\t\tinit_sync_kiocb(&sio->iocb, swap_file);",
            "\t\tsio->iocb.ki_complete = sio_write_complete;",
            "\t\tsio->iocb.ki_pos = pos;",
            "\t\tsio->pages = 0;",
            "\t\tsio->len = 0;",
            "\t}",
            "\tbvec_set_folio(&sio->bvec[sio->pages], folio, folio_size(folio), 0);",
            "\tsio->len += folio_size(folio);",
            "\tsio->pages += 1;",
            "\tif (sio->pages == ARRAY_SIZE(sio->bvec) || !wbc->swap_plug) {",
            "\t\tswap_write_unplug(sio);",
            "\t\tsio = NULL;",
            "\t}",
            "\tif (wbc->swap_plug)",
            "\t\t*wbc->swap_plug = sio;",
            "}",
            "static void swap_writepage_bdev_sync(struct folio *folio,",
            "\t\tstruct writeback_control *wbc, struct swap_info_struct *sis)",
            "{",
            "\tstruct bio_vec bv;",
            "\tstruct bio bio;",
            "",
            "\tbio_init(&bio, sis->bdev, &bv, 1,",
            "\t\t REQ_OP_WRITE | REQ_SWAP | wbc_to_write_flags(wbc));",
            "\tbio.bi_iter.bi_sector = swap_folio_sector(folio);",
            "\tbio_add_folio_nofail(&bio, folio, folio_size(folio), 0);",
            "",
            "\tbio_associate_blkg_from_page(&bio, folio);",
            "\tcount_swpout_vm_event(folio);",
            "",
            "\tfolio_start_writeback(folio);",
            "\tfolio_unlock(folio);",
            "",
            "\tsubmit_bio_wait(&bio);",
            "\t__end_swap_bio_write(&bio);",
            "}",
            "static void swap_writepage_bdev_async(struct folio *folio,",
            "\t\tstruct writeback_control *wbc, struct swap_info_struct *sis)",
            "{",
            "\tstruct bio *bio;",
            "",
            "\tbio = bio_alloc(sis->bdev, 1,",
            "\t\t\tREQ_OP_WRITE | REQ_SWAP | wbc_to_write_flags(wbc),",
            "\t\t\tGFP_NOIO);",
            "\tbio->bi_iter.bi_sector = swap_folio_sector(folio);",
            "\tbio->bi_end_io = end_swap_bio_write;",
            "\tbio_add_folio_nofail(bio, folio, folio_size(folio), 0);",
            "",
            "\tbio_associate_blkg_from_page(bio, folio);",
            "\tcount_swpout_vm_event(folio);",
            "\tfolio_start_writeback(folio);",
            "\tfolio_unlock(folio);",
            "\tsubmit_bio(bio);",
            "}",
            "void __swap_writepage(struct folio *folio, struct writeback_control *wbc)",
            "{",
            "\tstruct swap_info_struct *sis = swp_swap_info(folio->swap);",
            "",
            "\tVM_BUG_ON_FOLIO(!folio_test_swapcache(folio), folio);",
            "\t/*",
            "\t * ->flags can be updated non-atomicially (scan_swap_map_slots),",
            "\t * but that will never affect SWP_FS_OPS, so the data_race",
            "\t * is safe.",
            "\t */",
            "\tif (data_race(sis->flags & SWP_FS_OPS))",
            "\t\tswap_writepage_fs(folio, wbc);",
            "\telse if (sis->flags & SWP_SYNCHRONOUS_IO)",
            "\t\tswap_writepage_bdev_sync(folio, wbc, sis);",
            "\telse",
            "\t\tswap_writepage_bdev_async(folio, wbc, sis);",
            "}",
            "void swap_write_unplug(struct swap_iocb *sio)",
            "{",
            "\tstruct iov_iter from;",
            "\tstruct address_space *mapping = sio->iocb.ki_filp->f_mapping;",
            "\tint ret;",
            "",
            "\tiov_iter_bvec(&from, ITER_SOURCE, sio->bvec, sio->pages, sio->len);",
            "\tret = mapping->a_ops->swap_rw(&sio->iocb, &from);",
            "\tif (ret != -EIOCBQUEUED)",
            "\t\tsio_write_complete(&sio->iocb, ret);",
            "}"
          ],
          "function_name": "swap_writepage_fs, swap_writepage_bdev_sync, swap_writepage_bdev_async, __swap_writepage, swap_write_unplug",
          "description": "__swap_writepage根据配置选择同步/异步块设备写入路径，通过bio结构执行交换页面写入操作，支持批量提交优化。",
          "similarity": 0.5462260246276855
        },
        {
          "chunk_id": 2,
          "file_path": "mm/page_io.c",
          "start_line": 179,
          "end_line": 280,
          "content": [
            "int swap_writepage(struct page *page, struct writeback_control *wbc)",
            "{",
            "\tstruct folio *folio = page_folio(page);",
            "\tint ret;",
            "",
            "\tif (folio_free_swap(folio)) {",
            "\t\tfolio_unlock(folio);",
            "\t\treturn 0;",
            "\t}",
            "\t/*",
            "\t * Arch code may have to preserve more data than just the page",
            "\t * contents, e.g. memory tags.",
            "\t */",
            "\tret = arch_prepare_to_swap(folio);",
            "\tif (ret) {",
            "\t\tfolio_mark_dirty(folio);",
            "\t\tfolio_unlock(folio);",
            "\t\treturn ret;",
            "\t}",
            "\tif (zswap_store(folio)) {",
            "\t\tfolio_start_writeback(folio);",
            "\t\tfolio_unlock(folio);",
            "\t\tfolio_end_writeback(folio);",
            "\t\treturn 0;",
            "\t}",
            "\tif (!mem_cgroup_zswap_writeback_enabled(folio_memcg(folio))) {",
            "\t\tfolio_mark_dirty(folio);",
            "\t\treturn AOP_WRITEPAGE_ACTIVATE;",
            "\t}",
            "",
            "\t__swap_writepage(folio, wbc);",
            "\treturn 0;",
            "}",
            "static inline void count_swpout_vm_event(struct folio *folio)",
            "{",
            "#ifdef CONFIG_TRANSPARENT_HUGEPAGE",
            "\tif (unlikely(folio_test_pmd_mappable(folio))) {",
            "\t\tcount_memcg_folio_events(folio, THP_SWPOUT, 1);",
            "\t\tcount_vm_event(THP_SWPOUT);",
            "\t}",
            "\tcount_mthp_stat(folio_order(folio), MTHP_STAT_SWPOUT);",
            "#endif",
            "\tcount_memcg_folio_events(folio, PSWPOUT, folio_nr_pages(folio));",
            "\tcount_vm_events(PSWPOUT, folio_nr_pages(folio));",
            "}",
            "static void bio_associate_blkg_from_page(struct bio *bio, struct folio *folio)",
            "{",
            "\tstruct cgroup_subsys_state *css;",
            "\tstruct mem_cgroup *memcg;",
            "",
            "\tmemcg = folio_memcg(folio);",
            "\tif (!memcg)",
            "\t\treturn;",
            "",
            "\trcu_read_lock();",
            "\tcss = cgroup_e_css(memcg->css.cgroup, &io_cgrp_subsys);",
            "\tbio_associate_blkg_from_css(bio, css);",
            "\trcu_read_unlock();",
            "}",
            "int sio_pool_init(void)",
            "{",
            "\tif (!sio_pool) {",
            "\t\tmempool_t *pool = mempool_create_kmalloc_pool(",
            "\t\t\tSWAP_CLUSTER_MAX, sizeof(struct swap_iocb));",
            "\t\tif (cmpxchg(&sio_pool, NULL, pool))",
            "\t\t\tmempool_destroy(pool);",
            "\t}",
            "\tif (!sio_pool)",
            "\t\treturn -ENOMEM;",
            "\treturn 0;",
            "}",
            "static void sio_write_complete(struct kiocb *iocb, long ret)",
            "{",
            "\tstruct swap_iocb *sio = container_of(iocb, struct swap_iocb, iocb);",
            "\tstruct page *page = sio->bvec[0].bv_page;",
            "\tint p;",
            "",
            "\tif (ret != sio->len) {",
            "\t\t/*",
            "\t\t * In the case of swap-over-nfs, this can be a",
            "\t\t * temporary failure if the system has limited",
            "\t\t * memory for allocating transmit buffers.",
            "\t\t * Mark the page dirty and avoid",
            "\t\t * folio_rotate_reclaimable but rate-limit the",
            "\t\t * messages but do not flag PageError like",
            "\t\t * the normal direct-to-bio case as it could",
            "\t\t * be temporary.",
            "\t\t */",
            "\t\tpr_err_ratelimited(\"Write error %ld on dio swapfile (%llu)\\n\",",
            "\t\t\t\t   ret, page_file_offset(page));",
            "\t\tfor (p = 0; p < sio->pages; p++) {",
            "\t\t\tpage = sio->bvec[p].bv_page;",
            "\t\t\tset_page_dirty(page);",
            "\t\t\tClearPageReclaim(page);",
            "\t\t}",
            "\t}",
            "",
            "\tfor (p = 0; p < sio->pages; p++)",
            "\t\tend_page_writeback(sio->bvec[p].bv_page);",
            "",
            "\tmempool_free(sio, sio_pool);",
            "}"
          ],
          "function_name": "swap_writepage, count_swpout_vm_event, bio_associate_blkg_from_page, sio_pool_init, sio_write_complete",
          "description": "swap_writepage发起页面换出流程，调用架构特定准备函数并处理ZSwap缓存；sio_write_complete处理异步写入完成，标记脏页并释放资源。",
          "similarity": 0.5428904294967651
        }
      ]
    },
    {
      "source_file": "mm/pgalloc-track.h",
      "md_summary": "> 自动生成时间: 2025-12-07 17:11:54\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `pgalloc-track.h`\n\n---\n\n# pgalloc-track.h 技术文档\n\n## 1. 文件概述\n\n`pgalloc-track.h` 是 Linux 内核中用于页表分配与修改追踪的辅助头文件。该文件提供了一组带“追踪”（track）功能的页表分配接口，能够在分配缺失的页表层级时，自动记录哪些页表层级被修改，以便后续进行 TLB 刷新、内存同步或其他页表一致性维护操作。这些接口主要用于支持内核在处理缺页异常或动态映射时高效地构建多级页表结构，并精确标记被修改的页表层级。\n\n## 2. 核心功能\n\n### 函数列表\n\n- `p4d_alloc_track(struct mm_struct *mm, pgd_t *pgd, unsigned long address, pgtbl_mod_mask *mod_mask)`  \n  分配并返回指定地址对应的 P4D（Page 4-level Directory）项指针，若原 PGD 项为空则分配新 P4D 表，并设置 `PGTBL_PGD_MODIFIED` 标志。\n\n- `pud_alloc_track(struct mm_struct *mm, p4d_t *p4d, unsigned long address, pgtbl_mod_mask *mod_mask)`  \n  分配并返回 PUD（Page Upper Directory）项指针，若原 P4D 项为空则分配新 PUD 表，并设置 `PGTBL_P4D_MODIFIED` 标志。\n\n- `pmd_alloc_track(struct mm_struct *mm, pud_t *pud, unsigned long address, pgtbl_mod_mask *mod_mask)`  \n  分配并返回 PMD（Page Middle Directory）项指针，若原 PUD 项为空则分配新 PMD 表，并设置 `PGTBL_PUD_MODIFIED` 标志。\n\n- `pte_alloc_kernel_track(pmd, address, mask)`（宏）  \n  为内核地址空间分配 PTE（Page Table Entry）页表，若原 PMD 项为空则调用 `__pte_alloc_kernel` 分配，并设置 `PGTBL_PMD_MODIFIED` 标志。\n\n### 数据结构依赖\n\n- `struct mm_struct`：进程内存描述符。\n- `pgd_t`, `p4d_t`, `pud_t`, `pmd_t`：各级页表项类型。\n- `pgtbl_mod_mask`：位掩码类型，用于记录哪些页表层级被修改（如 `PGTBL_PGD_MODIFIED` 等常量）。\n\n> 注：上述函数仅在 `CONFIG_MMU` 配置启用时定义，即仅适用于支持 MMU 的架构。\n\n## 3. 关键实现\n\n- **条件分配机制**：所有 `_alloc_track` 函数均采用“按需分配”策略。仅当上级页表项为 `none`（即未分配）时，才调用底层分配函数（如 `__p4d_alloc`）创建下一级页表。\n  \n- **修改标记追踪**：每次成功分配新的页表层级后，通过位或操作（`|=`）将对应的修改标志（如 `PGTBL_P4D_MODIFIED`）写入传入的 `mod_mask` 指针所指向的掩码变量中。这使得调用者能够精确知道在本次页表遍历过程中哪些层级发生了变更。\n\n- **内联与宏优化**：所有函数均为 `static inline`，以减少函数调用开销；`pte_alloc_kernel_track` 使用宏实现，结合三元运算符和语句表达式（`({...})`）在单行中完成条件判断、分配、标记和返回。\n\n- **错误处理**：若底层分配函数（如 `__pud_alloc`）失败，函数直接返回 `NULL`，由上层调用者处理错误。\n\n## 4. 依赖关系\n\n- **配置依赖**：依赖 `CONFIG_MMU` 内核配置选项，仅在支持虚拟内存管理单元（MMU）的系统上编译相关函数。\n- **头文件依赖**：隐式依赖以下内核头文件（虽未显式包含，但使用其定义）：\n  - `<linux/mm_types.h>`：定义 `struct mm_struct` 和页表项类型。\n  - `<asm/pgtable.h>`：提供 `pgd_none`、`p4d_offset` 等页表操作宏及 `__p4d_alloc` 等分配函数。\n  - `<linux/pgtable.h>`：可能定义 `pgtbl_mod_mask` 及相关修改标志（如 `PGTBL_PGD_MODIFIED`）。\n- **函数依赖**：依赖底层页表分配函数 `__p4d_alloc`、`__pud_alloc`、`__pmd_alloc` 和 `__pte_alloc_kernel`，这些通常由架构相关代码或通用内存管理模块提供。\n\n## 5. 使用场景\n\n- **缺页异常处理**：在 `handle_mm_fault()` 或类似路径中，当需要为用户或内核地址建立完整页表映射时，逐级调用这些 `_alloc_track` 函数构建页表，并收集修改掩码用于后续 TLB 批量刷新。\n  \n- **内核动态映射**：在内核需要动态映射物理内存（如 `ioremap`、`vmalloc` 等）时，使用 `pte_alloc_kernel_track` 安全地分配内核 PTE 页表并记录 PMD 修改状态。\n\n- **页表预分配或扩展**：在内存管理子系统预分配页表或扩展现有 VMA 映射范围时，利用该接口确保页表结构完整性并精确追踪变更。\n\n- **性能敏感路径**：由于采用内联和轻量级检查，适用于对性能要求较高的内存管理关键路径，同时保证修改信息的准确性以支持高效的 TLB 管理。",
      "similarity": 0.5888535380363464,
      "chunks": []
    },
    {
      "source_file": "mm/sparse-vmemmap.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:24:15\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sparse-vmemmap.c`\n\n---\n\n# sparse-vmemmap.c 技术文档\n\n## 1. 文件概述\n\n`sparse-vmemmap.c` 是 Linux 内核中用于实现 **虚拟内存映射（Virtual Memory Map, vmemmap）** 的核心文件之一。该机制为稀疏内存模型（sparse memory model）提供支持，使得 `pfn_to_page()`、`page_to_pfn()`、`virt_to_page()` 和 `page_address()` 等页管理原语可以通过简单的地址偏移计算实现，而无需访问内存中的间接结构。\n\n在支持 1:1 物理地址映射的架构上，vmemmap 利用已有的页表和 TLB 映射，仅需额外分配少量页面来构建一个连续的虚拟地址空间，用于存放所有物理页对应的 `struct page` 结构体。此文件主要负责在系统初始化阶段动态填充 vmemmap 所需的页表项，并支持使用替代内存分配器（如 ZONE_DEVICE 提供的 altmap）进行底层内存分配。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数名 | 功能说明 |\n|--------|--------|\n| `vmemmap_alloc_block()` | 分配用于 vmemmap 或其页表的内存块，优先使用 slab 分配器，早期启动阶段回退到 memblock |\n| `vmemmap_alloc_block_buf()` | 封装分配接口，支持通过 `vmem_altmap` 指定替代内存源 |\n| `altmap_alloc_block_buf()` | 使用 `vmem_altmap` 提供的预留内存区域分配 vmemmap 缓冲区 |\n| `vmemmap_populate_address()` | 为指定虚拟地址填充完整的四级（或五级）页表路径（PGD → P4D → PUD → PMD → PTE） |\n| `vmemmap_populate_range()` | 批量填充一段虚拟地址范围的页表 |\n| `vmemmap_populate_basepages()` | 公开接口，用于以基本页（4KB）粒度填充 vmemmap 区域 |\n| `vmemmap_pte_populate()` / `vmemmap_pmd_populate()` / ... | 各级页表项的按需填充函数 |\n| `vmemmap_verify()` | 验证分配的 `struct page` 是否位于预期 NUMA 节点，避免跨节点性能问题 |\n\n### 关键数据结构\n\n- **`struct vmem_altmap`**  \n  由外部（如 device-dax 或 pmem 驱动）提供，描述一块预留的物理内存区域，可用于替代常规内存分配 vmemmap 所需的 `struct page` 存储空间。包含字段：\n  - `base_pfn`：起始物理页帧号\n  - `reserve`：保留页数（通常用于元数据）\n  - `alloc`：已分配页数\n  - `align`：对齐填充页数\n  - `free`：总可用页数\n\n## 3. 关键实现\n\n### 内存分配策略\n- **运行时分配**：当 slab 分配器可用时（`slab_is_available()` 返回 true），使用 `alloc_pages_node()` 分配高阶页面。\n- **早期启动分配**：在 slab 不可用时，调用 `memblock_alloc_try_nid_raw()` 从 bootmem 分配器获取内存。\n- **替代内存支持**：通过 `vmem_altmap` 参数，允许将 `struct page` 存储在设备内存（如持久内存）中，减少对系统 DRAM 的占用。\n\n### 页表填充机制\n- 采用 **按需填充（on-demand population）** 策略，仅在访问 vmemmap 虚拟地址时构建对应页表。\n- 支持完整的 x86_64 / ARM64 等架构的多级页表（PGD → P4D → PUD → PMD → PTE）。\n- 每级页表项若为空（`*_none()`），则分配一个 4KB 页面作为下一级页表，并通过 `*_populate()` 填充。\n- 叶子 PTE 指向实际存储 `struct page` 的物理页面，权限设为 `PAGE_KERNEL`。\n\n### 对齐与验证\n- `altmap_alloc_block_buf()` 中实现 **动态对齐**：根据请求大小计算所需对齐边界（2 的幂），确保分配地址满足页表项对齐要求。\n- `vmemmap_verify()` 在调试/警告模式下检查分配的 `struct page` 所在 NUMA 节点是否与目标节点“本地”，避免远程访问开销。\n\n### 架构钩子函数\n- 提供弱符号（`__weak`）钩子如 `kernel_pte_init()`、`pmd_init()` 等，允许特定架构在分配页表页面后执行初始化操作（如设置特殊属性位）。\n\n## 4. 依赖关系\n\n- **内存管理子系统**：\n  - `<linux/mm.h>`、`<linux/mmzone.h>`：页帧、内存域、NUMA 节点管理\n  - `<linux/memblock.h>`：早期内存分配\n  - `<linux/vmalloc.h>`：虚拟内存管理（间接）\n- **页表操作**：\n  - `<asm/pgalloc.h>`：架构相关的页表分配/释放\n  - 依赖 `pgd_offset_k()`、`pud_populate()` 等架构宏/函数\n- **稀疏内存模型**：\n  - 与 `sparse.c` 协同工作，`sparse_buffer_alloc()` 用于复用预分配的缓冲区\n- **设备内存支持**：\n  - `<linux/memremap.h>`：`vmem_altmap` 定义，用于 ZONE_DEVICE 场景\n\n## 5. 使用场景\n\n1. **稀疏内存模型初始化**  \n   在 `sparse_init()` 过程中，为每个内存 section 调用 `vmemmap_populate_basepages()` 填充对应的 `struct page` 数组。\n\n2. **热插拔内存（Memory Hotplug）**  \n   新增内存区域时，动态填充其 vmemmap 映射，使新页可被内核页管理器识别。\n\n3. **持久内存（Persistent Memory）/ DAX 设备**  \n   通过 `vmem_altmap` 将 `struct page` 存储在设备自身内存中，避免消耗系统 RAM，典型用于 `fsdax` 或 `device-dax`。\n\n4. **大页优化（未完成功能）**  \n   文件末尾存在 `vmemmap_populate_hugepages()` 声明，表明未来可能支持使用透明大页（如 2MB PMD）映射 vmemmap，减少 TLB 压力（当前实现可能不完整或依赖架构支持）。\n\n5. **NUMA 感知分配**  \n   所有分配均指定目标 NUMA 节点（`node` 参数），确保 `struct page` 尽可能靠近其所描述的物理内存，优化访问延迟。",
      "similarity": 0.5809329748153687,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/sparse-vmemmap.c",
          "start_line": 91,
          "end_line": 203,
          "content": [
            "static unsigned long __meminit vmem_altmap_next_pfn(struct vmem_altmap *altmap)",
            "{",
            "\treturn altmap->base_pfn + altmap->reserve + altmap->alloc",
            "\t\t+ altmap->align;",
            "}",
            "static unsigned long __meminit vmem_altmap_nr_free(struct vmem_altmap *altmap)",
            "{",
            "\tunsigned long allocated = altmap->alloc + altmap->align;",
            "",
            "\tif (altmap->free > allocated)",
            "\t\treturn altmap->free - allocated;",
            "\treturn 0;",
            "}",
            "void __meminit vmemmap_verify(pte_t *pte, int node,",
            "\t\t\t\tunsigned long start, unsigned long end)",
            "{",
            "\tunsigned long pfn = pte_pfn(ptep_get(pte));",
            "\tint actual_node = early_pfn_to_nid(pfn);",
            "",
            "\tif (node_distance(actual_node, node) > LOCAL_DISTANCE)",
            "\t\tpr_warn_once(\"[%lx-%lx] potential offnode page_structs\\n\",",
            "\t\t\tstart, end - 1);",
            "}",
            "void __weak __meminit kernel_pte_init(void *addr)",
            "{",
            "}",
            "void __weak __meminit pmd_init(void *addr)",
            "{",
            "}",
            "void __weak __meminit pud_init(void *addr)",
            "{",
            "}",
            "static int __meminit vmemmap_populate_range(unsigned long start,",
            "\t\t\t\t\t    unsigned long end, int node,",
            "\t\t\t\t\t    struct vmem_altmap *altmap,",
            "\t\t\t\t\t    struct page *reuse)",
            "{",
            "\tunsigned long addr = start;",
            "\tpte_t *pte;",
            "",
            "\tfor (; addr < end; addr += PAGE_SIZE) {",
            "\t\tpte = vmemmap_populate_address(addr, node, altmap, reuse);",
            "\t\tif (!pte)",
            "\t\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int __meminit vmemmap_populate_basepages(unsigned long start, unsigned long end,",
            "\t\t\t\t\t int node, struct vmem_altmap *altmap)",
            "{",
            "\treturn vmemmap_populate_range(start, end, node, altmap, NULL);",
            "}",
            "void __weak __meminit vmemmap_set_pmd(pmd_t *pmd, void *p, int node,",
            "\t\t\t\t      unsigned long addr, unsigned long next)",
            "{",
            "}",
            "int __weak __meminit vmemmap_check_pmd(pmd_t *pmd, int node,",
            "\t\t\t\t       unsigned long addr, unsigned long next)",
            "{",
            "\treturn 0;",
            "}",
            "int __meminit vmemmap_populate_hugepages(unsigned long start, unsigned long end,",
            "\t\t\t\t\t int node, struct vmem_altmap *altmap)",
            "{",
            "\tunsigned long addr;",
            "\tunsigned long next;",
            "\tpgd_t *pgd;",
            "\tp4d_t *p4d;",
            "\tpud_t *pud;",
            "\tpmd_t *pmd;",
            "",
            "\tfor (addr = start; addr < end; addr = next) {",
            "\t\tnext = pmd_addr_end(addr, end);",
            "",
            "\t\tpgd = vmemmap_pgd_populate(addr, node);",
            "\t\tif (!pgd)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\t\tp4d = vmemmap_p4d_populate(pgd, addr, node);",
            "\t\tif (!p4d)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\t\tpud = vmemmap_pud_populate(p4d, addr, node);",
            "\t\tif (!pud)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\t\tpmd = pmd_offset(pud, addr);",
            "\t\tif (pmd_none(READ_ONCE(*pmd))) {",
            "\t\t\tvoid *p;",
            "",
            "\t\t\tp = vmemmap_alloc_block_buf(PMD_SIZE, node, altmap);",
            "\t\t\tif (p) {",
            "\t\t\t\tvmemmap_set_pmd(pmd, p, node, addr, next);",
            "\t\t\t\tcontinue;",
            "\t\t\t} else if (altmap) {",
            "\t\t\t\t/*",
            "\t\t\t\t * No fallback: In any case we care about, the",
            "\t\t\t\t * altmap should be reasonably sized and aligned",
            "\t\t\t\t * such that vmemmap_alloc_block_buf() will always",
            "\t\t\t\t * succeed. For consistency with the PTE case,",
            "\t\t\t\t * return an error here as failure could indicate",
            "\t\t\t\t * a configuration issue with the size of the altmap.",
            "\t\t\t\t */",
            "\t\t\t\treturn -ENOMEM;",
            "\t\t\t}",
            "\t\t} else if (vmemmap_check_pmd(pmd, node, addr, next))",
            "\t\t\tcontinue;",
            "\t\tif (vmemmap_populate_basepages(addr, next, node, altmap))",
            "\t\t\treturn -ENOMEM;",
            "\t}",
            "\treturn 0;",
            "}"
          ],
          "function_name": "vmem_altmap_next_pfn, vmem_altmap_nr_free, vmemmap_verify, kernel_pte_init, pmd_init, pud_init, vmemmap_populate_range, vmemmap_populate_basepages, vmemmap_set_pmd, vmemmap_check_pmd, vmemmap_populate_hugepages",
          "description": "实现了虚拟内存映射验证、页表初始化及大页填充逻辑，包含检查页表项节点一致性、弱函数声明以及递归填充连续地址范围的辅助函数",
          "similarity": 0.572472333908081
        },
        {
          "chunk_id": 2,
          "file_path": "mm/sparse-vmemmap.c",
          "start_line": 377,
          "end_line": 435,
          "content": [
            "static bool __meminit reuse_compound_section(unsigned long start_pfn,",
            "\t\t\t\t\t     struct dev_pagemap *pgmap)",
            "{",
            "\tunsigned long nr_pages = pgmap_vmemmap_nr(pgmap);",
            "\tunsigned long offset = start_pfn -",
            "\t\tPHYS_PFN(pgmap->ranges[pgmap->nr_range].start);",
            "",
            "\treturn !IS_ALIGNED(offset, nr_pages) && nr_pages > PAGES_PER_SUBSECTION;",
            "}",
            "static int __meminit vmemmap_populate_compound_pages(unsigned long start_pfn,",
            "\t\t\t\t\t\t     unsigned long start,",
            "\t\t\t\t\t\t     unsigned long end, int node,",
            "\t\t\t\t\t\t     struct dev_pagemap *pgmap)",
            "{",
            "\tunsigned long size, addr;",
            "\tpte_t *pte;",
            "\tint rc;",
            "",
            "\tif (reuse_compound_section(start_pfn, pgmap)) {",
            "\t\tpte = compound_section_tail_page(start);",
            "\t\tif (!pte)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\t\t/*",
            "\t\t * Reuse the page that was populated in the prior iteration",
            "\t\t * with just tail struct pages.",
            "\t\t */",
            "\t\treturn vmemmap_populate_range(start, end, node, NULL,",
            "\t\t\t\t\t      pte_page(ptep_get(pte)));",
            "\t}",
            "",
            "\tsize = min(end - start, pgmap_vmemmap_nr(pgmap) * sizeof(struct page));",
            "\tfor (addr = start; addr < end; addr += size) {",
            "\t\tunsigned long next, last = addr + size;",
            "",
            "\t\t/* Populate the head page vmemmap page */",
            "\t\tpte = vmemmap_populate_address(addr, node, NULL, NULL);",
            "\t\tif (!pte)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\t\t/* Populate the tail pages vmemmap page */",
            "\t\tnext = addr + PAGE_SIZE;",
            "\t\tpte = vmemmap_populate_address(next, node, NULL, NULL);",
            "\t\tif (!pte)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\t\t/*",
            "\t\t * Reuse the previous page for the rest of tail pages",
            "\t\t * See layout diagram in Documentation/mm/vmemmap_dedup.rst",
            "\t\t */",
            "\t\tnext += PAGE_SIZE;",
            "\t\trc = vmemmap_populate_range(next, last, node, NULL,",
            "\t\t\t\t\t    pte_page(ptep_get(pte)));",
            "\t\tif (rc)",
            "\t\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "reuse_compound_section, vmemmap_populate_compound_pages",
          "description": "提供复合页面内存复用机制，通过判断偏移对齐情况决定是否复用上一次迭代产生的尾部页面，从而优化vmentry结构体的内存分配效率",
          "similarity": 0.4975097179412842
        },
        {
          "chunk_id": 0,
          "file_path": "mm/sparse-vmemmap.c",
          "start_line": 1,
          "end_line": 90,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Virtual Memory Map support",
            " *",
            " * (C) 2007 sgi. Christoph Lameter.",
            " *",
            " * Virtual memory maps allow VM primitives pfn_to_page, page_to_pfn,",
            " * virt_to_page, page_address() to be implemented as a base offset",
            " * calculation without memory access.",
            " *",
            " * However, virtual mappings need a page table and TLBs. Many Linux",
            " * architectures already map their physical space using 1-1 mappings",
            " * via TLBs. For those arches the virtual memory map is essentially",
            " * for free if we use the same page size as the 1-1 mappings. In that",
            " * case the overhead consists of a few additional pages that are",
            " * allocated to create a view of memory for vmemmap.",
            " *",
            " * The architecture is expected to provide a vmemmap_populate() function",
            " * to instantiate the mapping.",
            " */",
            "#include <linux/mm.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/memblock.h>",
            "#include <linux/memremap.h>",
            "#include <linux/highmem.h>",
            "#include <linux/slab.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched.h>",
            "",
            "#include <asm/dma.h>",
            "#include <asm/pgalloc.h>",
            "",
            "/*",
            " * Allocate a block of memory to be used to back the virtual memory map",
            " * or to back the page tables that are used to create the mapping.",
            " * Uses the main allocators if they are available, else bootmem.",
            " */",
            "",
            "static void * __ref __earlyonly_bootmem_alloc(int node,",
            "\t\t\t\tunsigned long size,",
            "\t\t\t\tunsigned long align,",
            "\t\t\t\tunsigned long goal)",
            "{",
            "\treturn memblock_alloc_try_nid_raw(size, align, goal,",
            "\t\t\t\t\t       MEMBLOCK_ALLOC_ACCESSIBLE, node);",
            "}",
            "",
            "void * __meminit vmemmap_alloc_block(unsigned long size, int node)",
            "{",
            "\t/* If the main allocator is up use that, fallback to bootmem. */",
            "\tif (slab_is_available()) {",
            "\t\tgfp_t gfp_mask = GFP_KERNEL|__GFP_RETRY_MAYFAIL|__GFP_NOWARN;",
            "\t\tint order = get_order(size);",
            "\t\tstatic bool warned;",
            "\t\tstruct page *page;",
            "",
            "\t\tpage = alloc_pages_node(node, gfp_mask, order);",
            "\t\tif (page)",
            "\t\t\treturn page_address(page);",
            "",
            "\t\tif (!warned) {",
            "\t\t\twarn_alloc(gfp_mask & ~__GFP_NOWARN, NULL,",
            "\t\t\t\t   \"vmemmap alloc failure: order:%u\", order);",
            "\t\t\twarned = true;",
            "\t\t}",
            "\t\treturn NULL;",
            "\t} else",
            "\t\treturn __earlyonly_bootmem_alloc(node, size, size,",
            "\t\t\t\t__pa(MAX_DMA_ADDRESS));",
            "}",
            "",
            "static void * __meminit altmap_alloc_block_buf(unsigned long size,",
            "\t\t\t\t\t       struct vmem_altmap *altmap);",
            "",
            "/* need to make sure size is all the same during early stage */",
            "void * __meminit vmemmap_alloc_block_buf(unsigned long size, int node,",
            "\t\t\t\t\t struct vmem_altmap *altmap)",
            "{",
            "\tvoid *ptr;",
            "",
            "\tif (altmap)",
            "\t\treturn altmap_alloc_block_buf(size, altmap);",
            "",
            "\tptr = sparse_buffer_alloc(size);",
            "\tif (!ptr)",
            "\t\tptr = vmemmap_alloc_block(size, node);",
            "\treturn ptr;",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义了用于分配虚拟内存映射所需内存块的函数，包括对slab分配器和bootmem分配器的选择逻辑，用于在系统初始化期间为vmentry结构体分配物理存储",
          "similarity": 0.4421704411506653
        }
      ]
    }
  ]
}