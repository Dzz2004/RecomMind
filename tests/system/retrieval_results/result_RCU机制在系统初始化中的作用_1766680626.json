{
  "query": "RCU机制在系统初始化中的作用",
  "timestamp": "2025-12-26 00:37:06",
  "retrieved_files": [
    {
      "source_file": "kernel/rcu/tiny.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:45:52\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `rcu\\tiny.c`\n\n---\n\n# `rcu/tiny.c` 技术文档\n\n## 1. 文件概述\n\n`rcu/tiny.c` 是 Linux 内核中 **RCU（Read-Copy Update）机制的“精简版”（Tiny RCU）实现**，专为单处理器（UP）或资源受限系统（如嵌入式设备）设计。该实现去除了复杂的状态机、CPU 间通信和动态负载均衡等开销，仅保留 RCU 的核心语义：**在读端无锁、写端延迟回收**。由于系统只有一个 CPU，任何上下文切换或中断返回用户态都天然构成“宽限期”（Grace Period），因此无需复杂的跨 CPU 同步逻辑。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct rcu_ctrlblk`**：RCU 控制块，全局唯一，用于管理回调链表和宽限期状态。\n  - `rcucblist`：待处理的 RCU 回调链表头。\n  - `donetail`：指向最后一个已完成宽限期的回调的 `next` 指针。\n  - `curtail`：指向链表最后一个回调的 `next` 指针。\n  - `gp_seq`：宽限期序列号，每次宽限期结束递增 2（偶数表示完成状态）。\n\n### 主要函数\n\n| 函数 | 功能说明 |\n|------|--------|\n| `rcu_qs(void)` | 记录当前 CPU 的静默状态（Quiescent State），推进已完成回调指针并触发软中断处理回调。 |\n| `rcu_sched_clock_irq(int user)` | 调度时钟中断处理函数，若处于用户态则调用 `rcu_qs()`；否则标记当前任务需重新调度以尽快进入静默状态。 |\n| `call_rcu(struct rcu_head *head, rcu_callback_t func)` | 注册一个 RCU 回调，在下一个宽限期结束后执行。 |\n| `synchronize_rcu(void)` | 等待当前宽限期结束（在 UP 系统中立即完成，仅更新 `gp_seq`）。 |\n| `rcu_process_callbacks(struct softirq_action *unused)` | RCU 软中断处理函数，批量执行已完成宽限期的回调。 |\n| `rcu_barrier(void)` | 等待所有已注册的 RCU 回调执行完毕。 |\n| `get_state_synchronize_rcu()` / `start_poll_synchronize_rcu()` / `poll_state_synchronize_rcu()` | 支持轮询式宽限期检测的 API。 |\n| `rcu_init(void)` | RCU 子系统初始化，注册 RCU 软中断处理函数。 |\n\n## 3. 关键实现\n\n### 宽限期管理\n- **单 CPU 假设**：由于系统只有一个 CPU，任何从内核态返回用户态、发生上下文切换或空闲任务运行，都视为一个完整的宽限期。\n- **`gp_seq` 计数器**：初始值为 `0 - 300UL`（负数，确保早期调用 `get_state_synchronize_rcu()` 返回有效值）。每次调用 `rcu_qs()` 或 `synchronize_rcu()` 时递增 2，偶数值表示宽限期已完成。\n- **无实际等待**：`synchronize_rcu()` 不阻塞，仅更新 `gp_seq`，因为调用者本身已处于静默状态。\n\n### 回调队列管理\n- **双指针链表**：使用 `donetail` 和 `curtail` 实现无锁（在中断禁用下）的回调入队和出队。\n  - 新回调通过 `curtail` 追加到链表尾部。\n  - `rcu_qs()` 将 `donetail` 移至 `curtail`，表示此前所有回调已完成宽限期。\n  - 软中断 `rcu_process_callbacks()` 将 `donetail` 之前的所有回调移出并执行。\n\n### 回调执行\n- **软中断上下文**：回调在 `RCU_SOFTIRQ` 中执行，确保不在原子上下文。\n- **支持 `kvfree`**：通过 `__is_kvfree_rcu_offset` 判断是否为 `kvfree_rcu` 回调，若是则直接释放内存而非调用函数指针。\n- **调试支持**：包含双释放检测（`debug_rcu_head_queue`）和内存泄漏防护（`tiny_rcu_leak_callback`）。\n\n### 轮询 API 实现\n- `get_state_synchronize_rcu()` 返回当前 `gp_seq`。\n- `poll_state_synchronize_rcu(oldstate)` 判断 `oldstate` 是否已完成：若 `oldstate == RCU_GET_STATE_COMPLETED`（特殊值）或当前 `gp_seq != oldstate`，则返回 `true`。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/rcupdate_wait.h>`：提供 `wait_rcu_gp()` 实现 `rcu_barrier()`。\n  - `\"rcu.h\"`：RCU 内部头文件，定义调试宏、trace 点等。\n  - 其他通用内核头文件（如 `sched.h`, `softirq.h`, `slab.h` 等）。\n- **内核配置**：\n  - 仅在 `CONFIG_TINY_RCU` 或 `CONFIG_TINY_SRCU` 启用时编译。\n  - 与 `CONFIG_PREEMPT`、`CONFIG_SMP` 互斥（Tiny RCU 用于非抢占式 UP 系统）。\n- **软中断子系统**：依赖 `open_softirq()` 注册 `RCU_SOFTIRQ`。\n- **内存管理**：`kvfree_call_rcu()` 依赖 KASAN 的辅助栈记录（`CONFIG_KASAN_GENERIC`）。\n\n## 5. 使用场景\n\n- **单处理器嵌入式系统**：资源受限设备（如 IoT 设备、微控制器）中替代 Tree RCU，显著减少代码体积和运行时开销。\n- **内核测试与调试**：作为 RCU 行为的简化模型，用于验证 RCU 语义正确性。\n- **RCU 基础功能提供**：\n  - 为内核其他子系统（如网络、文件系统、设备驱动）提供 `call_rcu()` 和 `synchronize_rcu()` 接口。\n  - 支持延迟内存回收（如 `kfree_rcu()`）。\n  - 通过 `rcu_barrier()` 确保模块卸载前所有回调完成。\n- **轮询式同步**：适用于不能阻塞的上下文（如中断处理程序），通过 `poll_state_synchronize_rcu()` 轮询宽限期状态。",
      "similarity": 0.6728301644325256,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/rcu/tiny.c",
          "start_line": 45,
          "end_line": 161,
          "content": [
            "void rcu_barrier(void)",
            "{",
            "\twait_rcu_gp(call_rcu_hurry);",
            "}",
            "void rcu_qs(void)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\tif (rcu_ctrlblk.donetail != rcu_ctrlblk.curtail) {",
            "\t\trcu_ctrlblk.donetail = rcu_ctrlblk.curtail;",
            "\t\traise_softirq_irqoff(RCU_SOFTIRQ);",
            "\t}",
            "\tWRITE_ONCE(rcu_ctrlblk.gp_seq, rcu_ctrlblk.gp_seq + 2);",
            "\tlocal_irq_restore(flags);",
            "}",
            "void rcu_sched_clock_irq(int user)",
            "{",
            "\tif (user) {",
            "\t\trcu_qs();",
            "\t} else if (rcu_ctrlblk.donetail != rcu_ctrlblk.curtail) {",
            "\t\tset_tsk_need_resched(current);",
            "\t\tset_preempt_need_resched();",
            "\t}",
            "}",
            "static inline bool rcu_reclaim_tiny(struct rcu_head *head)",
            "{",
            "\trcu_callback_t f;",
            "\tunsigned long offset = (unsigned long)head->func;",
            "",
            "\trcu_lock_acquire(&rcu_callback_map);",
            "\tif (__is_kvfree_rcu_offset(offset)) {",
            "\t\ttrace_rcu_invoke_kvfree_callback(\"\", head, offset);",
            "\t\tkvfree((void *)head - offset);",
            "\t\trcu_lock_release(&rcu_callback_map);",
            "\t\treturn true;",
            "\t}",
            "",
            "\ttrace_rcu_invoke_callback(\"\", head);",
            "\tf = head->func;",
            "\tdebug_rcu_head_callback(head);",
            "\tWRITE_ONCE(head->func, (rcu_callback_t)0L);",
            "\tf(head);",
            "\trcu_lock_release(&rcu_callback_map);",
            "\treturn false;",
            "}",
            "static __latent_entropy void rcu_process_callbacks(struct softirq_action *unused)",
            "{",
            "\tstruct rcu_head *next, *list;",
            "\tunsigned long flags;",
            "",
            "\t/* Move the ready-to-invoke callbacks to a local list. */",
            "\tlocal_irq_save(flags);",
            "\tif (rcu_ctrlblk.donetail == &rcu_ctrlblk.rcucblist) {",
            "\t\t/* No callbacks ready, so just leave. */",
            "\t\tlocal_irq_restore(flags);",
            "\t\treturn;",
            "\t}",
            "\tlist = rcu_ctrlblk.rcucblist;",
            "\trcu_ctrlblk.rcucblist = *rcu_ctrlblk.donetail;",
            "\t*rcu_ctrlblk.donetail = NULL;",
            "\tif (rcu_ctrlblk.curtail == rcu_ctrlblk.donetail)",
            "\t\trcu_ctrlblk.curtail = &rcu_ctrlblk.rcucblist;",
            "\trcu_ctrlblk.donetail = &rcu_ctrlblk.rcucblist;",
            "\tlocal_irq_restore(flags);",
            "",
            "\t/* Invoke the callbacks on the local list. */",
            "\twhile (list) {",
            "\t\tnext = list->next;",
            "\t\tprefetch(next);",
            "\t\tdebug_rcu_head_unqueue(list);",
            "\t\tlocal_bh_disable();",
            "\t\trcu_reclaim_tiny(list);",
            "\t\tlocal_bh_enable();",
            "\t\tlist = next;",
            "\t}",
            "}",
            "void synchronize_rcu(void)",
            "{",
            "\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||",
            "\t\t\t lock_is_held(&rcu_lock_map) ||",
            "\t\t\t lock_is_held(&rcu_sched_lock_map),",
            "\t\t\t \"Illegal synchronize_rcu() in RCU read-side critical section\");",
            "\tWRITE_ONCE(rcu_ctrlblk.gp_seq, rcu_ctrlblk.gp_seq + 2);",
            "}",
            "static void tiny_rcu_leak_callback(struct rcu_head *rhp)",
            "{",
            "}",
            "void call_rcu(struct rcu_head *head, rcu_callback_t func)",
            "{",
            "\tstatic atomic_t doublefrees;",
            "\tunsigned long flags;",
            "",
            "\tif (debug_rcu_head_queue(head)) {",
            "\t\tif (atomic_inc_return(&doublefrees) < 4) {",
            "\t\t\tpr_err(\"%s(): Double-freed CB %p->%pS()!!!  \", __func__, head, head->func);",
            "\t\t\tmem_dump_obj(head);",
            "\t\t}",
            "",
            "\t\tif (!__is_kvfree_rcu_offset((unsigned long)head->func))",
            "\t\t\tWRITE_ONCE(head->func, tiny_rcu_leak_callback);",
            "\t\treturn;",
            "\t}",
            "",
            "\thead->func = func;",
            "\thead->next = NULL;",
            "",
            "\tlocal_irq_save(flags);",
            "\t*rcu_ctrlblk.curtail = head;",
            "\trcu_ctrlblk.curtail = &head->next;",
            "\tlocal_irq_restore(flags);",
            "",
            "\tif (unlikely(is_idle_task(current))) {",
            "\t\t/* force scheduling for rcu_qs() */",
            "\t\tresched_cpu(0);",
            "\t}",
            "}"
          ],
          "function_name": "rcu_barrier, rcu_qs, rcu_sched_clock_irq, rcu_reclaim_tiny, rcu_process_callbacks, synchronize_rcu, tiny_rcu_leak_callback, call_rcu",
          "description": "实现RCU核心函数，包括rcu_barrier触发同步屏障、rcu_process_callbacks处理回调队列、synchronize_rcu更新grace period序列号、call_rcu添加回调到链表并处理空闲任务调度。",
          "similarity": 0.6429077386856079
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/rcu/tiny.c",
          "start_line": 206,
          "end_line": 239,
          "content": [
            "void get_completed_synchronize_rcu_full(struct rcu_gp_oldstate *rgosp)",
            "{",
            "\trgosp->rgos_norm = RCU_GET_STATE_COMPLETED;",
            "}",
            "unsigned long get_state_synchronize_rcu(void)",
            "{",
            "\treturn READ_ONCE(rcu_ctrlblk.gp_seq);",
            "}",
            "unsigned long start_poll_synchronize_rcu(void)",
            "{",
            "\tunsigned long gp_seq = get_state_synchronize_rcu();",
            "",
            "\tif (unlikely(is_idle_task(current))) {",
            "\t\t/* force scheduling for rcu_qs() */",
            "\t\tresched_cpu(0);",
            "\t}",
            "\treturn gp_seq;",
            "}",
            "bool poll_state_synchronize_rcu(unsigned long oldstate)",
            "{",
            "\treturn oldstate == RCU_GET_STATE_COMPLETED || READ_ONCE(rcu_ctrlblk.gp_seq) != oldstate;",
            "}",
            "void kvfree_call_rcu(struct rcu_head *head, void *ptr)",
            "{",
            "\tif (head)",
            "\t\tkasan_record_aux_stack_noalloc(ptr);",
            "",
            "\t__kvfree_call_rcu(head, ptr);",
            "}",
            "void __init rcu_init(void)",
            "{",
            "\topen_softirq(RCU_SOFTIRQ, rcu_process_callbacks);",
            "\trcu_early_boot_tests();",
            "}"
          ],
          "function_name": "get_completed_synchronize_rcu_full, get_state_synchronize_rcu, start_poll_synchronize_rcu, poll_state_synchronize_rcu, kvfree_call_rcu, rcu_init",
          "description": "提供RCU状态查询接口，get_state_synchronize_rcu读取当前grace period序号，start_poll_synchronize_rcu用于轮询同步状态，rcu_init初始化RCU软中断处理函数注册。",
          "similarity": 0.6310443878173828
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/rcu/tiny.c",
          "start_line": 1,
          "end_line": 44,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0+",
            "/*",
            " * Read-Copy Update mechanism for mutual exclusion, the Bloatwatch edition.",
            " *",
            " * Copyright IBM Corporation, 2008",
            " *",
            " * Author: Paul E. McKenney <paulmck@linux.ibm.com>",
            " *",
            " * For detailed explanation of Read-Copy Update mechanism see -",
            " *\t\tDocumentation/RCU",
            " */",
            "#include <linux/completion.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/notifier.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/sched.h>",
            "#include <linux/types.h>",
            "#include <linux/init.h>",
            "#include <linux/time.h>",
            "#include <linux/cpu.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/slab.h>",
            "#include <linux/mm.h>",
            "",
            "#include \"rcu.h\"",
            "",
            "/* Global control variables for rcupdate callback mechanism. */",
            "struct rcu_ctrlblk {",
            "\tstruct rcu_head *rcucblist;\t/* List of pending callbacks (CBs). */",
            "\tstruct rcu_head **donetail;\t/* ->next pointer of last \"done\" CB. */",
            "\tstruct rcu_head **curtail;\t/* ->next pointer of last CB. */",
            "\tunsigned long gp_seq;\t\t/* Grace-period counter. */",
            "};",
            "",
            "/* Definition for rcupdate control block. */",
            "static struct rcu_ctrlblk rcu_ctrlblk = {",
            "\t.donetail\t= &rcu_ctrlblk.rcucblist,",
            "\t.curtail\t= &rcu_ctrlblk.rcucblist,",
            "\t.gp_seq\t\t= 0 - 300UL,",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义RCU控制块结构体rcu_ctrlblk，用于管理回调链表、尾指针及 grace period 序列号，初始化时设置 donetail 和 curtail 指向同一位置，gp_seq 初始化为负值以标记初始状态。",
          "similarity": 0.5928879380226135
        }
      ]
    },
    {
      "source_file": "kernel/rcu/tree.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:46:46\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `rcu\\tree.c`\n\n---\n\n# `rcu/tree.c` 技术文档\n\n## 1. 文件概述\n\n`rcu/tree.c` 是 Linux 内核中 **Read-Copy Update (RCU)** 机制的树形（tree-based）实现核心文件。RCU 是一种高性能的同步原语，用于在读多写少的场景下实现无锁读取与安全更新。该文件实现了基于分层树结构的 RCU 状态管理、宽限期（Grace Period）检测、回调处理、CPU 离线/上线处理以及与调度器、中断、kthread 等子系统的集成。树形结构的设计使得 RCU 能够高效扩展到大规模多核系统（数百甚至上千 CPU）。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct rcu_data`**（每 CPU）  \n  存储每个 CPU 的 RCU 状态，包括待处理的回调链表、宽限期序列号、QS（Quiescent State）状态等。\n  \n- **`struct rcu_state`**（全局）  \n  全局 RCU 状态机，包含宽限期状态（`gp_state`）、序列号（`gp_seq`）、树形节点层级结构（`level[]`）、互斥锁（如 `barrier_mutex`、`exp_mutex`）等。\n\n- **`struct rcu_node`**（层级节点）  \n  构成 RCU 树的内部节点，用于聚合子节点（CPU 或下层 `rcu_node`）的宽限期完成状态，实现分层检测，减少全局同步开销。\n\n- **全局变量**：\n  - `rcu_scheduler_active`：指示调度器是否已激活，影响 RCU 初始化和优化策略。\n  - `rcu_scheduler_fully_active`：指示 RCU 是否已完全初始化（包括 kthread 启动）。\n  - `rcu_num_lvls` / `num_rcu_lvl[]` / `rcu_num_nodes`：描述 RCU 树的层级结构和节点数量。\n  - 多个模块参数（如 `use_softirq`, `rcu_fanout_leaf`, `kthread_prio` 等）用于运行时调优和调试。\n\n### 主要函数（声明/定义）\n\n- **宽限期管理**：\n  - `rcu_report_qs_rnp()`：向上报告某 `rcu_node` 的 QS 状态。\n  - `invoke_rcu_core()`：触发 RCU 核心处理（如宽限期推进或回调执行）。\n\n- **回调处理**：\n  - `rcu_report_exp_rdp()`：报告扩展（expedited）宽限期完成。\n  - `check_cb_ovld_locked()`：检查回调过载情况。\n\n- **CPU 热插拔支持**：\n  - `rcu_boost_kthread_setaffinity()`：调整 RCU boost kthread 的 CPU 亲和性。\n  - `sync_sched_exp_online_cleanup()`：清理 CPU 上线时的扩展同步状态。\n  - `rcu_cleanup_dead_rnp()` / `rcu_init_new_rnp()`：处理 CPU 离线/上线时的 `rcu_node` 结构。\n\n- **辅助函数**：\n  - `rcu_rdp_is_offloaded()`：判断 RCU 回调是否被卸载到专用 kthread（NO_HZ_FULL/NO_CB 场景）。\n  - `rcu_rdp_cpu_online()`：检查对应 CPU 是否在线。\n  - `rcu_init_invoked()`：判断 RCU 初始化是否已启动。\n\n- **导出接口**：\n  - `rcu_get_gp_kthreads_prio()`：供 `rcutorture` 等测试模块获取 RCU kthread 优先级。\n\n## 3. 关键实现\n\n### 树形宽限期检测机制\nRCU 使用分层树结构（`rcu_node` 树）来高效检测宽限期完成：\n- 叶子层对应 CPU，上层节点聚合子节点状态。\n- 每个 `rcu_node` 维护一个位图（`qsmask`），记录哪些子节点尚未报告 QS。\n- 当所有子节点都报告 QS 后，该节点向上层报告，最终根节点完成整个宽限期。\n- 此设计将 O(N) 的全局同步开销降低为 O(log N)，适用于大规模系统。\n\n### 宽限期状态机\n- 全局状态 `rcu_state.gp_state` 控制宽限期生命周期（IDLE → WAITING → DONE 等）。\n- 使用 64 位序列号 `gp_seq` 标识宽限期，通过位移（`RCU_SEQ_CTR_SHIFT`）区分状态。\n- 初始序列号设为 `(0UL - 300UL) << RCU_SEQ_CTR_SHIFT`，确保启动时处于有效状态。\n\n### 调度器集成与启动阶段优化\n- `rcu_scheduler_active` 分三阶段：\n  1. `RCU_SCHEDULER_INACTIVE`：单任务阶段，`synchronize_rcu()` 退化为内存屏障。\n  2. `RCU_SCHEDULER_INIT`：调度器启动但 RCU 未完全初始化。\n  3. `RCU_SCHEDULER_RUNNING`：RCU 完全激活。\n- `rcu_scheduler_fully_active` 确保 RCU 回调和 kthread 在调度器支持多任务后才启用。\n\n### 回调处理策略\n- 支持两种回调执行模式：\n  - **软中断（`RCU_SOFTIRQ`）**：默认模式，通过 `rcu_softirq` 处理。\n  - **专用 kthread（`rcuc`/`rcub`）**：在 `PREEMPT_RT` 或配置 `NO_CB` 时使用，避免软中断延迟。\n- 通过 `use_softirq` 模块参数控制模式选择。\n\n### 调试与调优支持\n- 多个延迟参数（`gp_preinit_delay` 等）用于注入延迟以暴露竞态条件。\n- `rcu_unlock_delay` 在 `CONFIG_RCU_STRICT_GRACE_PERIOD` 下强制延迟 `rcu_read_unlock()`。\n- `dump_tree` 参数可在启动时打印 RCU 树结构用于验证。\n- `rcu_fanout_leaf` 和 `rcu_fanout_exact` 控制树的扇出（fanout）结构。\n\n### 内存与资源管理\n- `rcu_min_cached_objs` 控制每 CPU 缓存的最小对象数（以页为单位）。\n- `rcu_delay_page_cache_fill_msec` 在内存压力下延迟填充 RCU 缓存，避免与页回收冲突。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - 基础内核设施：`<linux/smp.h>`, `<linux/sched.h>`, `<linux/interrupt.h>`, `<linux/percpu.h>` 等。\n  - 时间子系统：`<linux/tick.h>`, `<linux/jiffies.h>`。\n  - 内存管理：`<linux/mm.h>`, `<linux/slab.h>`, `<linux/vmalloc.h>`。\n  - 调试与追踪：`<linux/lockdep.h>`, `<linux/ftrace.h>`, `<linux/kasan.h>`。\n  - RCU 内部头文件：`\"tree.h\"`, `\"rcu.h\"`。\n\n- **模块依赖**：\n  - 与调度器深度集成（`rcu_scheduler_active` 状态依赖 `sched/`）。\n  - 依赖中断子系统处理 QS 检测（如 tick 中断）。\n  - 与 CPU 热插拔机制协同（`cpuhp` 框架）。\n  - 在 `PREEMPT_RT` 下依赖实时调度特性。\n  - 与内存回收（shrinker）交互以管理缓存。\n\n## 5. 使用场景\n\n- **内核同步原语**：为 `synchronize_rcu()`, `call_rcu()` 等 API 提供底层实现。\n- **大规模多核系统**：通过树形结构支持数百至数千 CPU 的高效宽限期检测。\n- **实时系统**：通过 `rcuc` kthread 和优先级控制（`kthread_prio`）满足实时性要求。\n- **CPU 热插拔**：动态调整 RCU 树结构以适应 CPU 在线/离线。\n- **内存压力场景**：与页回收协同，避免 RCU 缓存加剧内存紧张。\n- **内核调试与测试**：\n  - `rcutorture` 模块利用此文件接口进行压力测试。\n  - 通过延迟参数和 `dump_tree` 辅助调试竞态和结构问题。\n- **低延迟场景**：在 `NO_HZ_FULL` 或 `NO_CB` 配置下，将 RCU 回调卸载到专用 CPU，减少主 CPU 干扰。",
      "similarity": 0.6702949404716492,
      "chunks": [
        {
          "chunk_id": 28,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 5098,
          "end_line": 5206,
          "content": [
            "static void __init rcu_dump_rcu_node_tree(void)",
            "{",
            "\tint level = 0;",
            "\tstruct rcu_node *rnp;",
            "",
            "\tpr_info(\"rcu_node tree layout dump\\n\");",
            "\tpr_info(\" \");",
            "\trcu_for_each_node_breadth_first(rnp) {",
            "\t\tif (rnp->level != level) {",
            "\t\t\tpr_cont(\"\\n\");",
            "\t\t\tpr_info(\" \");",
            "\t\t\tlevel = rnp->level;",
            "\t\t}",
            "\t\tpr_cont(\"%d:%d ^%d  \", rnp->grplo, rnp->grphi, rnp->grpnum);",
            "\t}",
            "\tpr_cont(\"\\n\");",
            "}",
            "static void __init kfree_rcu_batch_init(void)",
            "{",
            "\tint cpu;",
            "\tint i, j;",
            "\tstruct shrinker *kfree_rcu_shrinker;",
            "",
            "\t/* Clamp it to [0:100] seconds interval. */",
            "\tif (rcu_delay_page_cache_fill_msec < 0 ||",
            "\t\trcu_delay_page_cache_fill_msec > 100 * MSEC_PER_SEC) {",
            "",
            "\t\trcu_delay_page_cache_fill_msec =",
            "\t\t\tclamp(rcu_delay_page_cache_fill_msec, 0,",
            "\t\t\t\t(int) (100 * MSEC_PER_SEC));",
            "",
            "\t\tpr_info(\"Adjusting rcutree.rcu_delay_page_cache_fill_msec to %d ms.\\n\",",
            "\t\t\trcu_delay_page_cache_fill_msec);",
            "\t}",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tstruct kfree_rcu_cpu *krcp = per_cpu_ptr(&krc, cpu);",
            "",
            "\t\tfor (i = 0; i < KFREE_N_BATCHES; i++) {",
            "\t\t\tINIT_RCU_WORK(&krcp->krw_arr[i].rcu_work, kfree_rcu_work);",
            "\t\t\tkrcp->krw_arr[i].krcp = krcp;",
            "",
            "\t\t\tfor (j = 0; j < FREE_N_CHANNELS; j++)",
            "\t\t\t\tINIT_LIST_HEAD(&krcp->krw_arr[i].bulk_head_free[j]);",
            "\t\t}",
            "",
            "\t\tfor (i = 0; i < FREE_N_CHANNELS; i++)",
            "\t\t\tINIT_LIST_HEAD(&krcp->bulk_head[i]);",
            "",
            "\t\tINIT_DELAYED_WORK(&krcp->monitor_work, kfree_rcu_monitor);",
            "\t\tINIT_DELAYED_WORK(&krcp->page_cache_work, fill_page_cache_func);",
            "\t\tkrcp->initialized = true;",
            "\t}",
            "",
            "\tkfree_rcu_shrinker = shrinker_alloc(0, \"rcu-kfree\");",
            "\tif (!kfree_rcu_shrinker) {",
            "\t\tpr_err(\"Failed to allocate kfree_rcu() shrinker!\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tkfree_rcu_shrinker->count_objects = kfree_rcu_shrink_count;",
            "\tkfree_rcu_shrinker->scan_objects = kfree_rcu_shrink_scan;",
            "",
            "\tshrinker_register(kfree_rcu_shrinker);",
            "}",
            "void __init rcu_init(void)",
            "{",
            "\tint cpu = smp_processor_id();",
            "",
            "\trcu_early_boot_tests();",
            "",
            "\tkfree_rcu_batch_init();",
            "\trcu_bootup_announce();",
            "\tsanitize_kthread_prio();",
            "\trcu_init_geometry();",
            "\trcu_init_one();",
            "\tif (dump_tree)",
            "\t\trcu_dump_rcu_node_tree();",
            "\tif (use_softirq)",
            "\t\topen_softirq(RCU_SOFTIRQ, rcu_core_si);",
            "",
            "\t/*",
            "\t * We don't need protection against CPU-hotplug here because",
            "\t * this is called early in boot, before either interrupts",
            "\t * or the scheduler are operational.",
            "\t */",
            "\tpm_notifier(rcu_pm_notify, 0);",
            "\tWARN_ON(num_online_cpus() > 1); // Only one CPU this early in boot.",
            "\trcutree_prepare_cpu(cpu);",
            "\trcu_cpu_starting(cpu);",
            "\trcutree_online_cpu(cpu);",
            "",
            "\t/* Create workqueue for Tree SRCU and for expedited GPs. */",
            "\trcu_gp_wq = alloc_workqueue(\"rcu_gp\", WQ_MEM_RECLAIM, 0);",
            "\tWARN_ON(!rcu_gp_wq);",
            "\trcu_alloc_par_gp_wq();",
            "",
            "\t/* Fill in default value for rcutree.qovld boot parameter. */",
            "\t/* -After- the rcu_node ->lock fields are initialized! */",
            "\tif (qovld < 0)",
            "\t\tqovld_calc = DEFAULT_RCU_QOVLD_MULT * qhimark;",
            "\telse",
            "\t\tqovld_calc = qovld;",
            "",
            "\t// Kick-start in case any polled grace periods started early.",
            "\t(void)start_poll_synchronize_rcu_expedited();",
            "",
            "\trcu_test_sync_prims();",
            "}"
          ],
          "function_name": "rcu_dump_rcu_node_tree, kfree_rcu_batch_init, rcu_init",
          "description": "执行RCU节点树的调试输出，初始化内存回收批量机制，完成RCU子系统的整体初始化流程，包括资源分配、事件注册及核心组件启动。",
          "similarity": 0.6980698108673096
        },
        {
          "chunk_id": 24,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 4444,
          "end_line": 4559,
          "content": [
            "static void __init",
            "rcu_boot_init_percpu_data(int cpu)",
            "{",
            "\tstruct context_tracking *ct = this_cpu_ptr(&context_tracking);",
            "\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);",
            "",
            "\t/* Set up local state, ensuring consistent view of global state. */",
            "\trdp->grpmask = leaf_node_cpu_bit(rdp->mynode, cpu);",
            "\tINIT_WORK(&rdp->strict_work, strict_work_handler);",
            "\tWARN_ON_ONCE(ct->dynticks_nesting != 1);",
            "\tWARN_ON_ONCE(rcu_dynticks_in_eqs(rcu_dynticks_snap(cpu)));",
            "\trdp->barrier_seq_snap = rcu_state.barrier_sequence;",
            "\trdp->rcu_ofl_gp_seq = rcu_state.gp_seq;",
            "\trdp->rcu_ofl_gp_flags = RCU_GP_CLEANED;",
            "\trdp->rcu_onl_gp_seq = rcu_state.gp_seq;",
            "\trdp->rcu_onl_gp_flags = RCU_GP_CLEANED;",
            "\trdp->last_sched_clock = jiffies;",
            "\trdp->cpu = cpu;",
            "\trcu_boot_init_nocb_percpu_data(rdp);",
            "}",
            "int rcutree_prepare_cpu(unsigned int cpu)",
            "{",
            "\tunsigned long flags;",
            "\tstruct context_tracking *ct = per_cpu_ptr(&context_tracking, cpu);",
            "\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);",
            "\tstruct rcu_node *rnp = rcu_get_root();",
            "",
            "\t/* Set up local state, ensuring consistent view of global state. */",
            "\traw_spin_lock_irqsave_rcu_node(rnp, flags);",
            "\trdp->qlen_last_fqs_check = 0;",
            "\trdp->n_force_qs_snap = READ_ONCE(rcu_state.n_force_qs);",
            "\trdp->blimit = blimit;",
            "\tct->dynticks_nesting = 1;\t/* CPU not up, no tearing. */",
            "\traw_spin_unlock_rcu_node(rnp);\t\t/* irqs remain disabled. */",
            "",
            "\t/*",
            "\t * Only non-NOCB CPUs that didn't have early-boot callbacks need to be",
            "\t * (re-)initialized.",
            "\t */",
            "\tif (!rcu_segcblist_is_enabled(&rdp->cblist))",
            "\t\trcu_segcblist_init(&rdp->cblist);  /* Re-enable callbacks. */",
            "",
            "\t/*",
            "\t * Add CPU to leaf rcu_node pending-online bitmask.  Any needed",
            "\t * propagation up the rcu_node tree will happen at the beginning",
            "\t * of the next grace period.",
            "\t */",
            "\trnp = rdp->mynode;",
            "\traw_spin_lock_rcu_node(rnp);\t\t/* irqs already disabled. */",
            "\trdp->gp_seq = READ_ONCE(rnp->gp_seq);",
            "\trdp->gp_seq_needed = rdp->gp_seq;",
            "\trdp->cpu_no_qs.b.norm = true;",
            "\trdp->core_needs_qs = false;",
            "\trdp->rcu_iw_pending = false;",
            "\trdp->rcu_iw = IRQ_WORK_INIT_HARD(rcu_iw_handler);",
            "\trdp->rcu_iw_gp_seq = rdp->gp_seq - 1;",
            "\ttrace_rcu_grace_period(rcu_state.name, rdp->gp_seq, TPS(\"cpuonl\"));",
            "\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "",
            "\trcu_preempt_deferred_qs_init(rdp);",
            "\trcu_spawn_one_boost_kthread(rnp);",
            "\trcu_spawn_cpu_nocb_kthread(cpu);",
            "\tWRITE_ONCE(rcu_state.n_online_cpus, rcu_state.n_online_cpus + 1);",
            "",
            "\treturn 0;",
            "}",
            "static void rcutree_affinity_setting(unsigned int cpu, int outgoing)",
            "{",
            "\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);",
            "",
            "\trcu_boost_kthread_setaffinity(rdp->mynode, outgoing);",
            "}",
            "bool rcu_cpu_beenfullyonline(int cpu)",
            "{",
            "\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);",
            "",
            "\treturn smp_load_acquire(&rdp->beenonline);",
            "}",
            "int rcutree_online_cpu(unsigned int cpu)",
            "{",
            "\tunsigned long flags;",
            "\tstruct rcu_data *rdp;",
            "\tstruct rcu_node *rnp;",
            "",
            "\trdp = per_cpu_ptr(&rcu_data, cpu);",
            "\trnp = rdp->mynode;",
            "\traw_spin_lock_irqsave_rcu_node(rnp, flags);",
            "\trnp->ffmask |= rdp->grpmask;",
            "\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "\tif (rcu_scheduler_active == RCU_SCHEDULER_INACTIVE)",
            "\t\treturn 0; /* Too early in boot for scheduler work. */",
            "\tsync_sched_exp_online_cleanup(cpu);",
            "\trcutree_affinity_setting(cpu, -1);",
            "",
            "\t// Stop-machine done, so allow nohz_full to disable tick.",
            "\ttick_dep_clear(TICK_DEP_BIT_RCU);",
            "\treturn 0;",
            "}",
            "int rcutree_offline_cpu(unsigned int cpu)",
            "{",
            "\tunsigned long flags;",
            "\tstruct rcu_data *rdp;",
            "\tstruct rcu_node *rnp;",
            "",
            "\trdp = per_cpu_ptr(&rcu_data, cpu);",
            "\trnp = rdp->mynode;",
            "\traw_spin_lock_irqsave_rcu_node(rnp, flags);",
            "\trnp->ffmask &= ~rdp->grpmask;",
            "\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "",
            "\trcutree_affinity_setting(cpu, cpu);",
            "",
            "\t// nohz_full CPUs need the tick for stop-machine to work quickly",
            "\ttick_dep_set(TICK_DEP_BIT_RCU);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "rcu_boot_init_percpu_data, rcutree_prepare_cpu, rcutree_affinity_setting, rcu_cpu_beenfullyonline, rcutree_online_cpu, rcutree_offline_cpu",
          "description": "初始化每个CPU的RCU私有数据结构，处理CPU上线/下线时的RCU状态同步，配置中断亲和性，更新全局在线CPU计数器",
          "similarity": 0.6744164228439331
        },
        {
          "chunk_id": 13,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 2406,
          "end_line": 2512,
          "content": [
            "static void strict_work_handler(struct work_struct *work)",
            "{",
            "\trcu_read_lock();",
            "\trcu_read_unlock();",
            "}",
            "static __latent_entropy void rcu_core(void)",
            "{",
            "\tunsigned long flags;",
            "\tstruct rcu_data *rdp = raw_cpu_ptr(&rcu_data);",
            "\tstruct rcu_node *rnp = rdp->mynode;",
            "\t/*",
            "\t * On RT rcu_core() can be preempted when IRQs aren't disabled.",
            "\t * Therefore this function can race with concurrent NOCB (de-)offloading",
            "\t * on this CPU and the below condition must be considered volatile.",
            "\t * However if we race with:",
            "\t *",
            "\t * _ Offloading:   In the worst case we accelerate or process callbacks",
            "\t *                 concurrently with NOCB kthreads. We are guaranteed to",
            "\t *                 call rcu_nocb_lock() if that happens.",
            "\t *",
            "\t * _ Deoffloading: In the worst case we miss callbacks acceleration or",
            "\t *                 processing. This is fine because the early stage",
            "\t *                 of deoffloading invokes rcu_core() after setting",
            "\t *                 SEGCBLIST_RCU_CORE. So we guarantee that we'll process",
            "\t *                 what could have been dismissed without the need to wait",
            "\t *                 for the next rcu_pending() check in the next jiffy.",
            "\t */",
            "\tconst bool do_batch = !rcu_segcblist_completely_offloaded(&rdp->cblist);",
            "",
            "\tif (cpu_is_offline(smp_processor_id()))",
            "\t\treturn;",
            "\ttrace_rcu_utilization(TPS(\"Start RCU core\"));",
            "\tWARN_ON_ONCE(!rdp->beenonline);",
            "",
            "\t/* Report any deferred quiescent states if preemption enabled. */",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_COUNT) && (!(preempt_count() & PREEMPT_MASK))) {",
            "\t\trcu_preempt_deferred_qs(current);",
            "\t} else if (rcu_preempt_need_deferred_qs(current)) {",
            "\t\tset_tsk_need_resched(current);",
            "\t\tset_preempt_need_resched();",
            "\t}",
            "",
            "\t/* Update RCU state based on any recent quiescent states. */",
            "\trcu_check_quiescent_state(rdp);",
            "",
            "\t/* No grace period and unregistered callbacks? */",
            "\tif (!rcu_gp_in_progress() &&",
            "\t    rcu_segcblist_is_enabled(&rdp->cblist) && do_batch) {",
            "\t\trcu_nocb_lock_irqsave(rdp, flags);",
            "\t\tif (!rcu_segcblist_restempty(&rdp->cblist, RCU_NEXT_READY_TAIL))",
            "\t\t\trcu_accelerate_cbs_unlocked(rnp, rdp);",
            "\t\trcu_nocb_unlock_irqrestore(rdp, flags);",
            "\t}",
            "",
            "\trcu_check_gp_start_stall(rnp, rdp, rcu_jiffies_till_stall_check());",
            "",
            "\t/* If there are callbacks ready, invoke them. */",
            "\tif (do_batch && rcu_segcblist_ready_cbs(&rdp->cblist) &&",
            "\t    likely(READ_ONCE(rcu_scheduler_fully_active))) {",
            "\t\trcu_do_batch(rdp);",
            "\t\t/* Re-invoke RCU core processing if there are callbacks remaining. */",
            "\t\tif (rcu_segcblist_ready_cbs(&rdp->cblist))",
            "\t\t\tinvoke_rcu_core();",
            "\t}",
            "",
            "\t/* Do any needed deferred wakeups of rcuo kthreads. */",
            "\tdo_nocb_deferred_wakeup(rdp);",
            "\ttrace_rcu_utilization(TPS(\"End RCU core\"));",
            "",
            "\t// If strict GPs, schedule an RCU reader in a clean environment.",
            "\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))",
            "\t\tqueue_work_on(rdp->cpu, rcu_gp_wq, &rdp->strict_work);",
            "}",
            "static void rcu_core_si(struct softirq_action *h)",
            "{",
            "\trcu_core();",
            "}",
            "static void rcu_wake_cond(struct task_struct *t, int status)",
            "{",
            "\t/*",
            "\t * If the thread is yielding, only wake it when this",
            "\t * is invoked from idle",
            "\t */",
            "\tif (t && (status != RCU_KTHREAD_YIELDING || is_idle_task(current)))",
            "\t\twake_up_process(t);",
            "}",
            "static void invoke_rcu_core_kthread(void)",
            "{",
            "\tstruct task_struct *t;",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\t__this_cpu_write(rcu_data.rcu_cpu_has_work, 1);",
            "\tt = __this_cpu_read(rcu_data.rcu_cpu_kthread_task);",
            "\tif (t != NULL && t != current)",
            "\t\trcu_wake_cond(t, __this_cpu_read(rcu_data.rcu_cpu_kthread_status));",
            "\tlocal_irq_restore(flags);",
            "}",
            "static void invoke_rcu_core(void)",
            "{",
            "\tif (!cpu_online(smp_processor_id()))",
            "\t\treturn;",
            "\tif (use_softirq)",
            "\t\traise_softirq(RCU_SOFTIRQ);",
            "\telse",
            "\t\tinvoke_rcu_core_kthread();",
            "}"
          ],
          "function_name": "strict_work_handler, rcu_core, rcu_core_si, rcu_wake_cond, invoke_rcu_core_kthread, invoke_rcu_core",
          "description": "定义RCU核心处理流程，包含软中断模式下的回调处理、grace period状态验证及条件唤醒机制，支持严格grace period场景的特殊处理",
          "similarity": 0.6660553216934204
        },
        {
          "chunk_id": 26,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 4752,
          "end_line": 4863,
          "content": [
            "static int rcu_pm_notify(struct notifier_block *self,",
            "\t\t\t unsigned long action, void *hcpu)",
            "{",
            "\tswitch (action) {",
            "\tcase PM_HIBERNATION_PREPARE:",
            "\tcase PM_SUSPEND_PREPARE:",
            "\t\trcu_async_hurry();",
            "\t\trcu_expedite_gp();",
            "\t\tbreak;",
            "\tcase PM_POST_HIBERNATION:",
            "\tcase PM_POST_SUSPEND:",
            "\t\trcu_unexpedite_gp();",
            "\t\trcu_async_relax();",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tbreak;",
            "\t}",
            "\treturn NOTIFY_OK;",
            "}",
            "static void __init rcu_start_exp_gp_kworkers(void)",
            "{",
            "\tconst char *par_gp_kworker_name = \"rcu_exp_par_gp_kthread_worker\";",
            "\tconst char *gp_kworker_name = \"rcu_exp_gp_kthread_worker\";",
            "\tstruct sched_param param = { .sched_priority = kthread_prio };",
            "",
            "\trcu_exp_gp_kworker = kthread_create_worker(0, gp_kworker_name);",
            "\tif (IS_ERR_OR_NULL(rcu_exp_gp_kworker)) {",
            "\t\tpr_err(\"Failed to create %s!\\n\", gp_kworker_name);",
            "\t\trcu_exp_gp_kworker = NULL;",
            "\t\treturn;",
            "\t}",
            "",
            "\trcu_exp_par_gp_kworker = kthread_create_worker(0, par_gp_kworker_name);",
            "\tif (IS_ERR_OR_NULL(rcu_exp_par_gp_kworker)) {",
            "\t\tpr_err(\"Failed to create %s!\\n\", par_gp_kworker_name);",
            "\t\trcu_exp_par_gp_kworker = NULL;",
            "\t\tkthread_destroy_worker(rcu_exp_gp_kworker);",
            "\t\trcu_exp_gp_kworker = NULL;",
            "\t\treturn;",
            "\t}",
            "",
            "\tsched_setscheduler_nocheck(rcu_exp_gp_kworker->task, SCHED_FIFO, &param);",
            "\tsched_setscheduler_nocheck(rcu_exp_par_gp_kworker->task, SCHED_FIFO,",
            "\t\t\t\t   &param);",
            "}",
            "static inline void rcu_alloc_par_gp_wq(void)",
            "{",
            "}",
            "static void __init rcu_start_exp_gp_kworkers(void)",
            "{",
            "}",
            "static inline void rcu_alloc_par_gp_wq(void)",
            "{",
            "\trcu_par_gp_wq = alloc_workqueue(\"rcu_par_gp\", WQ_MEM_RECLAIM, 0);",
            "\tWARN_ON(!rcu_par_gp_wq);",
            "}",
            "static int __init rcu_spawn_gp_kthread(void)",
            "{",
            "\tunsigned long flags;",
            "\tstruct rcu_node *rnp;",
            "\tstruct sched_param sp;",
            "\tstruct task_struct *t;",
            "\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);",
            "",
            "\trcu_scheduler_fully_active = 1;",
            "\tt = kthread_create(rcu_gp_kthread, NULL, \"%s\", rcu_state.name);",
            "\tif (WARN_ONCE(IS_ERR(t), \"%s: Could not start grace-period kthread, OOM is now expected behavior\\n\", __func__))",
            "\t\treturn 0;",
            "\tif (kthread_prio) {",
            "\t\tsp.sched_priority = kthread_prio;",
            "\t\tsched_setscheduler_nocheck(t, SCHED_FIFO, &sp);",
            "\t}",
            "\trnp = rcu_get_root();",
            "\traw_spin_lock_irqsave_rcu_node(rnp, flags);",
            "\tWRITE_ONCE(rcu_state.gp_activity, jiffies);",
            "\tWRITE_ONCE(rcu_state.gp_req_activity, jiffies);",
            "\t// Reset .gp_activity and .gp_req_activity before setting .gp_kthread.",
            "\tsmp_store_release(&rcu_state.gp_kthread, t);  /* ^^^ */",
            "\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);",
            "\twake_up_process(t);",
            "\t/* This is a pre-SMP initcall, we expect a single CPU */",
            "\tWARN_ON(num_online_cpus() > 1);",
            "\t/*",
            "\t * Those kthreads couldn't be created on rcu_init() -> rcutree_prepare_cpu()",
            "\t * due to rcu_scheduler_fully_active.",
            "\t */",
            "\trcu_spawn_cpu_nocb_kthread(smp_processor_id());",
            "\trcu_spawn_one_boost_kthread(rdp->mynode);",
            "\trcu_spawn_core_kthreads();",
            "\t/* Create kthread worker for expedited GPs */",
            "\trcu_start_exp_gp_kworkers();",
            "\treturn 0;",
            "}",
            "void rcu_scheduler_starting(void)",
            "{",
            "\tunsigned long flags;",
            "\tstruct rcu_node *rnp;",
            "",
            "\tWARN_ON(num_online_cpus() != 1);",
            "\tWARN_ON(nr_context_switches() > 0);",
            "\trcu_test_sync_prims();",
            "",
            "\t// Fix up the ->gp_seq counters.",
            "\tlocal_irq_save(flags);",
            "\trcu_for_each_node_breadth_first(rnp)",
            "\t\trnp->gp_seq_needed = rnp->gp_seq = rcu_state.gp_seq;",
            "\tlocal_irq_restore(flags);",
            "",
            "\t// Switch out of early boot mode.",
            "\trcu_scheduler_active = RCU_SCHEDULER_INIT;",
            "\trcu_test_sync_prims();",
            "}"
          ],
          "function_name": "rcu_pm_notify, rcu_start_exp_gp_kworkers, rcu_alloc_par_gp_wq, rcu_start_exp_gp_kworkers, rcu_alloc_par_gp_wq, rcu_spawn_gp_kthread, rcu_scheduler_starting",
          "description": "管理系统休眠唤醒时的RCU急迫性切换，创建并配置用于处理急迫GRACE周期的内核线程工作者，同时初始化相关资源和调度参数。",
          "similarity": 0.6480416059494019
        },
        {
          "chunk_id": 22,
          "file_path": "kernel/rcu/tree.c",
          "start_line": 4072,
          "end_line": 4226,
          "content": [
            "static void rcu_barrier_trace(const char *s, int cpu, unsigned long done)",
            "{",
            "\ttrace_rcu_barrier(rcu_state.name, s, cpu,",
            "\t\t\t  atomic_read(&rcu_state.barrier_cpu_count), done);",
            "}",
            "static void rcu_barrier_callback(struct rcu_head *rhp)",
            "{",
            "\tunsigned long __maybe_unused s = rcu_state.barrier_sequence;",
            "",
            "\tif (atomic_dec_and_test(&rcu_state.barrier_cpu_count)) {",
            "\t\trcu_barrier_trace(TPS(\"LastCB\"), -1, s);",
            "\t\tcomplete(&rcu_state.barrier_completion);",
            "\t} else {",
            "\t\trcu_barrier_trace(TPS(\"CB\"), -1, s);",
            "\t}",
            "}",
            "static void rcu_barrier_entrain(struct rcu_data *rdp)",
            "{",
            "\tunsigned long gseq = READ_ONCE(rcu_state.barrier_sequence);",
            "\tunsigned long lseq = READ_ONCE(rdp->barrier_seq_snap);",
            "\tbool wake_nocb = false;",
            "\tbool was_alldone = false;",
            "",
            "\tlockdep_assert_held(&rcu_state.barrier_lock);",
            "\tif (rcu_seq_state(lseq) || !rcu_seq_state(gseq) || rcu_seq_ctr(lseq) != rcu_seq_ctr(gseq))",
            "\t\treturn;",
            "\trcu_barrier_trace(TPS(\"IRQ\"), -1, rcu_state.barrier_sequence);",
            "\trdp->barrier_head.func = rcu_barrier_callback;",
            "\tdebug_rcu_head_queue(&rdp->barrier_head);",
            "\trcu_nocb_lock(rdp);",
            "\t/*",
            "\t * Flush bypass and wakeup rcuog if we add callbacks to an empty regular",
            "\t * queue. This way we don't wait for bypass timer that can reach seconds",
            "\t * if it's fully lazy.",
            "\t */",
            "\twas_alldone = rcu_rdp_is_offloaded(rdp) && !rcu_segcblist_pend_cbs(&rdp->cblist);",
            "\tWARN_ON_ONCE(!rcu_nocb_flush_bypass(rdp, NULL, jiffies, false));",
            "\twake_nocb = was_alldone && rcu_segcblist_pend_cbs(&rdp->cblist);",
            "\tif (rcu_segcblist_entrain(&rdp->cblist, &rdp->barrier_head)) {",
            "\t\tatomic_inc(&rcu_state.barrier_cpu_count);",
            "\t} else {",
            "\t\tdebug_rcu_head_unqueue(&rdp->barrier_head);",
            "\t\trcu_barrier_trace(TPS(\"IRQNQ\"), -1, rcu_state.barrier_sequence);",
            "\t}",
            "\trcu_nocb_unlock(rdp);",
            "\tif (wake_nocb)",
            "\t\twake_nocb_gp(rdp, false);",
            "\tsmp_store_release(&rdp->barrier_seq_snap, gseq);",
            "}",
            "static void rcu_barrier_handler(void *cpu_in)",
            "{",
            "\tuintptr_t cpu = (uintptr_t)cpu_in;",
            "\tstruct rcu_data *rdp = per_cpu_ptr(&rcu_data, cpu);",
            "",
            "\tlockdep_assert_irqs_disabled();",
            "\tWARN_ON_ONCE(cpu != rdp->cpu);",
            "\tWARN_ON_ONCE(cpu != smp_processor_id());",
            "\traw_spin_lock(&rcu_state.barrier_lock);",
            "\trcu_barrier_entrain(rdp);",
            "\traw_spin_unlock(&rcu_state.barrier_lock);",
            "}",
            "void rcu_barrier(void)",
            "{",
            "\tuintptr_t cpu;",
            "\tunsigned long flags;",
            "\tunsigned long gseq;",
            "\tstruct rcu_data *rdp;",
            "\tunsigned long s = rcu_seq_snap(&rcu_state.barrier_sequence);",
            "",
            "\trcu_barrier_trace(TPS(\"Begin\"), -1, s);",
            "",
            "\t/* Take mutex to serialize concurrent rcu_barrier() requests. */",
            "\tmutex_lock(&rcu_state.barrier_mutex);",
            "",
            "\t/* Did someone else do our work for us? */",
            "\tif (rcu_seq_done(&rcu_state.barrier_sequence, s)) {",
            "\t\trcu_barrier_trace(TPS(\"EarlyExit\"), -1, rcu_state.barrier_sequence);",
            "\t\tsmp_mb(); /* caller's subsequent code after above check. */",
            "\t\tmutex_unlock(&rcu_state.barrier_mutex);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* Mark the start of the barrier operation. */",
            "\traw_spin_lock_irqsave(&rcu_state.barrier_lock, flags);",
            "\trcu_seq_start(&rcu_state.barrier_sequence);",
            "\tgseq = rcu_state.barrier_sequence;",
            "\trcu_barrier_trace(TPS(\"Inc1\"), -1, rcu_state.barrier_sequence);",
            "",
            "\t/*",
            "\t * Initialize the count to two rather than to zero in order",
            "\t * to avoid a too-soon return to zero in case of an immediate",
            "\t * invocation of the just-enqueued callback (or preemption of",
            "\t * this task).  Exclude CPU-hotplug operations to ensure that no",
            "\t * offline non-offloaded CPU has callbacks queued.",
            "\t */",
            "\tinit_completion(&rcu_state.barrier_completion);",
            "\tatomic_set(&rcu_state.barrier_cpu_count, 2);",
            "\traw_spin_unlock_irqrestore(&rcu_state.barrier_lock, flags);",
            "",
            "\t/*",
            "\t * Force each CPU with callbacks to register a new callback.",
            "\t * When that callback is invoked, we will know that all of the",
            "\t * corresponding CPU's preceding callbacks have been invoked.",
            "\t */",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\trdp = per_cpu_ptr(&rcu_data, cpu);",
            "retry:",
            "\t\tif (smp_load_acquire(&rdp->barrier_seq_snap) == gseq)",
            "\t\t\tcontinue;",
            "\t\traw_spin_lock_irqsave(&rcu_state.barrier_lock, flags);",
            "\t\tif (!rcu_segcblist_n_cbs(&rdp->cblist)) {",
            "\t\t\tWRITE_ONCE(rdp->barrier_seq_snap, gseq);",
            "\t\t\traw_spin_unlock_irqrestore(&rcu_state.barrier_lock, flags);",
            "\t\t\trcu_barrier_trace(TPS(\"NQ\"), cpu, rcu_state.barrier_sequence);",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tif (!rcu_rdp_cpu_online(rdp)) {",
            "\t\t\trcu_barrier_entrain(rdp);",
            "\t\t\tWARN_ON_ONCE(READ_ONCE(rdp->barrier_seq_snap) != gseq);",
            "\t\t\traw_spin_unlock_irqrestore(&rcu_state.barrier_lock, flags);",
            "\t\t\trcu_barrier_trace(TPS(\"OfflineNoCBQ\"), cpu, rcu_state.barrier_sequence);",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\traw_spin_unlock_irqrestore(&rcu_state.barrier_lock, flags);",
            "\t\tif (smp_call_function_single(cpu, rcu_barrier_handler, (void *)cpu, 1)) {",
            "\t\t\tschedule_timeout_uninterruptible(1);",
            "\t\t\tgoto retry;",
            "\t\t}",
            "\t\tWARN_ON_ONCE(READ_ONCE(rdp->barrier_seq_snap) != gseq);",
            "\t\trcu_barrier_trace(TPS(\"OnlineQ\"), cpu, rcu_state.barrier_sequence);",
            "\t}",
            "",
            "\t/*",
            "\t * Now that we have an rcu_barrier_callback() callback on each",
            "\t * CPU, and thus each counted, remove the initial count.",
            "\t */",
            "\tif (atomic_sub_and_test(2, &rcu_state.barrier_cpu_count))",
            "\t\tcomplete(&rcu_state.barrier_completion);",
            "",
            "\t/* Wait for all rcu_barrier_callback() callbacks to be invoked. */",
            "\twait_for_completion(&rcu_state.barrier_completion);",
            "",
            "\t/* Mark the end of the barrier operation. */",
            "\trcu_barrier_trace(TPS(\"Inc2\"), -1, rcu_state.barrier_sequence);",
            "\trcu_seq_end(&rcu_state.barrier_sequence);",
            "\tgseq = rcu_state.barrier_sequence;",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\trdp = per_cpu_ptr(&rcu_data, cpu);",
            "",
            "\t\tWRITE_ONCE(rdp->barrier_seq_snap, gseq);",
            "\t}",
            "",
            "\t/* Other rcu_barrier() invocations can now safely proceed. */",
            "\tmutex_unlock(&rcu_state.barrier_mutex);",
            "}"
          ],
          "function_name": "rcu_barrier_trace, rcu_barrier_callback, rcu_barrier_entrain, rcu_barrier_handler, rcu_barrier",
          "description": "实现RCU屏障功能，通过分发回调函数强制所有CPU完成当前RCU操作，使用原子计数器跟踪完成状态，通过completion等待所有回调完成",
          "similarity": 0.617214024066925
        }
      ]
    },
    {
      "source_file": "kernel/rcu/update.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:50:38\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `rcu\\update.c`\n\n---\n\n# `rcu/update.c` 技术文档\n\n## 1. 文件概述\n\n`rcu/update.c` 是 Linux 内核中 Read-Copy Update (RCU) 机制的核心实现文件之一，主要负责 RCU 宽限期（grace period）控制策略、运行时模式切换、异步回调调度策略以及与调试和测试相关的辅助功能。该文件不直接实现宽限期的检测逻辑（由 `tree.c`、`tiny.c` 等处理），而是提供全局控制接口，用于动态调整 RCU 行为，例如是否启用加速（expedited）宽限期、是否启用延迟（lazy）回调处理等。此外，它还包含用于锁依赖检查（lockdep）的 RCU 读侧临界区状态判断函数。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`rcu_read_lock_sched_held()`**  \n  在启用 `CONFIG_DEBUG_LOCK_ALLOC` 时，用于判断当前是否处于 RCU-sched 读侧临界区内。考虑 CPU 是否在线、是否处于空闲状态（extended quiescent state）等因素。\n\n- **`rcu_gp_is_normal()`**  \n  判断当前是否应使用普通（非加速）宽限期。受 `rcu_normal` 模块参数和调度器初始化状态影响。\n\n- **`rcu_gp_is_expedited()`**  \n  判断当前是否应使用加速宽限期。综合考虑 `rcu_expedited` 模块参数和 `rcu_expedite_gp()` 的嵌套调用。\n\n- **`rcu_expedite_gp()` / `rcu_unexpedite_gp()`**  \n  分别用于启用和禁用后续 RCU 同步操作的加速模式。通过原子计数器 `rcu_expedited_nesting` 实现嵌套控制。\n\n- **`rcu_async_should_hurry()`**  \n  判断异步 RCU 回调（如 `call_rcu()`）是否应被及时执行（非延迟）。\n\n- **`rcu_async_hurry()` / `rcu_async_relax()`**  \n  控制异步 RCU 回调的执行策略：及时处理或延迟处理。通过原子计数器 `rcu_async_hurry_nesting` 实现。\n\n- **`rcu_end_inkernel_boot()`**  \n  标记内核启动阶段结束，恢复 RCU 到正常运行模式（取消加速、启用延迟回调等）。\n\n- **`rcu_inkernel_boot_has_ended()`**  \n  查询内核启动阶段是否已结束，供测试模块（如 `rcutorture`）使用。\n\n- **`rcu_test_sync_prims()`**  \n  （代码片段未完整）用于在模式切换或早期启动阶段测试所有非 SRCU 的同步原语。\n\n### 主要数据结构与变量\n\n- **`rcu_expedited_nesting`** (`atomic_t`)  \n  嵌套计数器，控制是否强制使用加速宽限期。\n\n- **`rcu_async_hurry_nesting`** (`atomic_t`)  \n  嵌套计数器，控制异步 RCU 回调是否应被及时处理。\n\n- **`rcu_boot_ended`** (`bool`, `__read_mostly`)  \n  标志位，指示内核启动阶段是否结束。\n\n- **模块参数**：\n  - `rcu_expedited`：强制所有宽限期为加速模式。\n  - `rcu_normal`：强制所有宽限期为普通模式。\n  - `rcu_normal_after_boot`：在启动结束后自动切换到普通模式（特定配置下）。\n\n## 3. 关键实现\n\n- **加速/普通模式切换逻辑**：  \n  通过 `rcu_expedited_nesting` 和 `rcu_normal` 参数共同决定宽限期类型。若 `rcu_normal` 为真且调度器已激活，则使用普通模式；否则若 `rcu_expedited` 为真或 `rcu_expedited_nesting > 0`，则使用加速模式。`rcu_normal` 优先级高于 `rcu_expedited`。\n\n- **启动阶段特殊处理**：  \n  在 `rcu_scheduler_active == RCU_SCHEDULER_INIT` 阶段（即首个用户任务启动前），所有宽限期默认为加速模式。`rcu_end_inkernel_boot()` 被调用后，恢复为运行时配置（可能切换为普通模式并启用延迟回调）。\n\n- **异步回调延迟策略（RCU Lazy）**：  \n  当 `CONFIG_RCU_LAZY` 启用时，`call_rcu()` 回调默认可被延迟执行以节省能耗。`rcu_async_hurry()`/`rcu_async_relax()` 允许临时覆盖此行为，适用于需要及时释放资源的场景。\n\n- **Lockdep 集成**：  \n  `rcu_read_lock_sched_held()` 在 lockdep 启用时，不仅检查显式的 RCU 锁，还将不可抢占状态（如关中断、关抢占）视为 RCU-sched 读侧临界区。同时，若 CPU 处于空闲状态（`rcu_is_watching() == false`）或离线，则视为不在 RCU 临界区内，以避免阻塞宽限期。\n\n- **空闲状态处理**：  \n  CPU 在 `ct_idle_enter()` 到 `ct_idle_exit()` 之间被视为处于“扩展静默状态”（extended quiescent state），此时即使调用了 `rcu_read_lock()`，也被 RCU 忽略，以确保宽限期能及时完成。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `rcu.h`：RCU 内部核心头文件，定义关键数据结构和宏。\n  - `rcupdate_wait.h`、`rcupdate_trace.h`：RCU 等待和跟踪支持。\n  - `sched/`、`irq/`、`cpu/` 相关头文件：用于获取调度、中断、CPU 状态信息。\n  - `lockdep` 相关接口：用于 `rcu_read_lock_sched_held()` 的实现。\n\n- **配置依赖**：\n  - `CONFIG_TINY_RCU`：若启用，则跳过大部分运行时控制逻辑（仅保留基础功能）。\n  - `CONFIG_PREEMPT_RT`、`CONFIG_NO_HZ_FULL`：影响 `rcu_normal_after_boot` 参数的可用性。\n  - `CONFIG_RCU_LAZY`：控制异步回调延迟策略是否启用。\n  - `CONFIG_DEBUG_LOCK_ALLOC`：决定是否编译 `rcu_read_lock_sched_held()`。\n\n- **与其他 RCU 文件交互**：\n  - 与 `tree.c`（Tree RCU）、`tiny.c`（Tiny RCU）协同工作，提供统一的运行时控制接口。\n  - 被 `synchronize_rcu()`、`call_rcu()` 等 API 间接调用以决定执行策略。\n\n## 5. 使用场景\n\n- **系统启动与初始化**：  \n  在内核早期启动阶段自动使用加速宽限期以加快初始化；启动完成后通过 `rcu_end_inkernel_boot()` 切换至节能或高性能模式。\n\n- **实时性要求高的子系统**：  \n  通过 `rcu_expedite_gp()` 临时启用加速宽限期，确保关键路径的低延迟（如实时任务、中断处理）。\n\n- **电源管理**：  \n  在空闲或低功耗场景下，利用 RCU Lazy 特性延迟回调执行，减少 CPU 唤醒次数。\n\n- **调试与验证**：  \n  `rcu_read_lock_sched_held()` 被 `lockdep` 用于检测 RCU 读侧临界区内的非法阻塞操作；`rcu_test_sync_prims()` 用于验证 RCU 同步原语的正确性。\n\n- **测试框架集成**：  \n  `rcu_inkernel_boot_has_ended()` 供 `rcutorture` 等压力测试模块判断何时可开始高强度测试。",
      "similarity": 0.6652697920799255,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/rcu/update.c",
          "start_line": 604,
          "end_line": 662,
          "content": [
            "static void early_boot_test_call_rcu(void)",
            "{",
            "\tstatic struct rcu_head head;",
            "\tint idx;",
            "\tstatic struct rcu_head shead;",
            "\tstruct early_boot_kfree_rcu *rhp;",
            "",
            "\tidx = srcu_down_read(&early_srcu);",
            "\tsrcu_up_read(&early_srcu, idx);",
            "\tcall_rcu(&head, test_callback);",
            "\tearly_srcu_cookie = start_poll_synchronize_srcu(&early_srcu);",
            "\tcall_srcu(&early_srcu, &shead, test_callback);",
            "\trhp = kmalloc(sizeof(*rhp), GFP_KERNEL);",
            "\tif (!WARN_ON_ONCE(!rhp))",
            "\t\tkfree_rcu(rhp, rh);",
            "}",
            "void rcu_early_boot_tests(void)",
            "{",
            "\tpr_info(\"Running RCU self tests\\n\");",
            "",
            "\tif (rcu_self_test)",
            "\t\tearly_boot_test_call_rcu();",
            "\trcu_test_sync_prims();",
            "}",
            "static int rcu_verify_early_boot_tests(void)",
            "{",
            "\tint ret = 0;",
            "\tint early_boot_test_counter = 0;",
            "",
            "\tif (rcu_self_test) {",
            "\t\tearly_boot_test_counter++;",
            "\t\trcu_barrier();",
            "\t\tearly_boot_test_counter++;",
            "\t\tsrcu_barrier(&early_srcu);",
            "\t\tWARN_ON_ONCE(!poll_state_synchronize_srcu(&early_srcu, early_srcu_cookie));",
            "\t\tcleanup_srcu_struct(&early_srcu);",
            "\t}",
            "\tif (rcu_self_test_counter != early_boot_test_counter) {",
            "\t\tWARN_ON(1);",
            "\t\tret = -1;",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "void rcu_early_boot_tests(void) {}",
            "void __init rcupdate_announce_bootup_oddness(void)",
            "{",
            "\tif (rcu_normal)",
            "\t\tpr_info(\"\\tNo expedited grace period (rcu_normal).\\n\");",
            "\telse if (rcu_normal_after_boot)",
            "\t\tpr_info(\"\\tNo expedited grace period (rcu_normal_after_boot).\\n\");",
            "\telse if (rcu_expedited)",
            "\t\tpr_info(\"\\tAll grace periods are expedited (rcu_expedited).\\n\");",
            "\tif (rcu_cpu_stall_suppress)",
            "\t\tpr_info(\"\\tRCU CPU stall warnings suppressed (rcu_cpu_stall_suppress).\\n\");",
            "\tif (rcu_cpu_stall_timeout != CONFIG_RCU_CPU_STALL_TIMEOUT)",
            "\t\tpr_info(\"\\tRCU CPU stall warnings timeout set to %d (rcu_cpu_stall_timeout).\\n\", rcu_cpu_stall_timeout);",
            "\trcu_tasks_bootup_oddness();",
            "}"
          ],
          "function_name": "early_boot_test_call_rcu, rcu_early_boot_tests, rcu_verify_early_boot_tests, rcu_early_boot_tests, rcupdate_announce_bootup_oddness",
          "description": "实现早期启动阶段的RCU自检逻辑，通过call_rcu触发测试回调并验证grace period状态，用于系统初始化时的RCU机制校验。",
          "similarity": 0.710526168346405
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/rcu/update.c",
          "start_line": 379,
          "end_line": 482,
          "content": [
            "int rcu_read_lock_any_held(void)",
            "{",
            "\tbool ret;",
            "",
            "\tif (rcu_read_lock_held_common(&ret))",
            "\t\treturn ret;",
            "\tif (lock_is_held(&rcu_lock_map) ||",
            "\t    lock_is_held(&rcu_bh_lock_map) ||",
            "\t    lock_is_held(&rcu_sched_lock_map))",
            "\t\treturn 1;",
            "\treturn !preemptible();",
            "}",
            "void wakeme_after_rcu(struct rcu_head *head)",
            "{",
            "\tstruct rcu_synchronize *rcu;",
            "",
            "\trcu = container_of(head, struct rcu_synchronize, head);",
            "\tcomplete(&rcu->completion);",
            "}",
            "void __wait_rcu_gp(bool checktiny, int n, call_rcu_func_t *crcu_array,",
            "\t\t   struct rcu_synchronize *rs_array)",
            "{",
            "\tint i;",
            "\tint j;",
            "",
            "\t/* Initialize and register callbacks for each crcu_array element. */",
            "\tfor (i = 0; i < n; i++) {",
            "\t\tif (checktiny &&",
            "\t\t    (crcu_array[i] == call_rcu)) {",
            "\t\t\tmight_sleep();",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tfor (j = 0; j < i; j++)",
            "\t\t\tif (crcu_array[j] == crcu_array[i])",
            "\t\t\t\tbreak;",
            "\t\tif (j == i) {",
            "\t\t\tinit_rcu_head_on_stack(&rs_array[i].head);",
            "\t\t\tinit_completion(&rs_array[i].completion);",
            "\t\t\t(crcu_array[i])(&rs_array[i].head, wakeme_after_rcu);",
            "\t\t}",
            "\t}",
            "",
            "\t/* Wait for all callbacks to be invoked. */",
            "\tfor (i = 0; i < n; i++) {",
            "\t\tif (checktiny &&",
            "\t\t    (crcu_array[i] == call_rcu))",
            "\t\t\tcontinue;",
            "\t\tfor (j = 0; j < i; j++)",
            "\t\t\tif (crcu_array[j] == crcu_array[i])",
            "\t\t\t\tbreak;",
            "\t\tif (j == i) {",
            "\t\t\twait_for_completion(&rs_array[i].completion);",
            "\t\t\tdestroy_rcu_head_on_stack(&rs_array[i].head);",
            "\t\t}",
            "\t}",
            "}",
            "void finish_rcuwait(struct rcuwait *w)",
            "{",
            "\trcu_assign_pointer(w->task, NULL);",
            "\t__set_current_state(TASK_RUNNING);",
            "}",
            "void init_rcu_head(struct rcu_head *head)",
            "{",
            "\tdebug_object_init(head, &rcuhead_debug_descr);",
            "}",
            "void destroy_rcu_head(struct rcu_head *head)",
            "{",
            "\tdebug_object_free(head, &rcuhead_debug_descr);",
            "}",
            "static bool rcuhead_is_static_object(void *addr)",
            "{",
            "\treturn true;",
            "}",
            "void init_rcu_head_on_stack(struct rcu_head *head)",
            "{",
            "\tdebug_object_init_on_stack(head, &rcuhead_debug_descr);",
            "}",
            "void destroy_rcu_head_on_stack(struct rcu_head *head)",
            "{",
            "\tdebug_object_free(head, &rcuhead_debug_descr);",
            "}",
            "void do_trace_rcu_torture_read(const char *rcutorturename, struct rcu_head *rhp,",
            "\t\t\t       unsigned long secs,",
            "\t\t\t       unsigned long c_old, unsigned long c)",
            "{",
            "\ttrace_rcu_torture_read(rcutorturename, rhp, secs, c_old, c);",
            "}",
            "long rcutorture_sched_setaffinity(pid_t pid, const struct cpumask *in_mask)",
            "{",
            "\tint ret;",
            "",
            "\tret = sched_setaffinity(pid, in_mask);",
            "\tWARN_ONCE(ret, \"%s: sched_setaffinity() returned %d\\n\", __func__, ret);",
            "\treturn ret;",
            "}",
            "unsigned long get_completed_synchronize_rcu(void)",
            "{",
            "\treturn RCU_GET_STATE_COMPLETED;",
            "}",
            "static void test_callback(struct rcu_head *r)",
            "{",
            "\trcu_self_test_counter++;",
            "\tpr_info(\"RCU test callback executed %d\\n\", rcu_self_test_counter);",
            "}"
          ],
          "function_name": "rcu_read_lock_any_held, wakeme_after_rcu, __wait_rcu_gp, finish_rcuwait, init_rcu_head, destroy_rcu_head, rcuhead_is_static_object, init_rcu_head_on_stack, destroy_rcu_head_on_stack, do_trace_rcu_torture_read, rcutorture_sched_setaffinity, get_completed_synchronize_rcu, test_callback",
          "description": "包含RCU回调注册、等待grace period完成、RCU头结构体初始化/销毁及调试跟踪等功能，支持异步回调机制和RCU头对象的生命期管理。",
          "similarity": 0.5977559685707092
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/rcu/update.c",
          "start_line": 102,
          "end_line": 206,
          "content": [
            "static bool rcu_read_lock_held_common(bool *ret)",
            "{",
            "\tif (!debug_lockdep_rcu_enabled()) {",
            "\t\t*ret = true;",
            "\t\treturn true;",
            "\t}",
            "\tif (!rcu_is_watching()) {",
            "\t\t*ret = false;",
            "\t\treturn true;",
            "\t}",
            "\tif (!rcu_lockdep_current_cpu_online()) {",
            "\t\t*ret = false;",
            "\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "int rcu_read_lock_sched_held(void)",
            "{",
            "\tbool ret;",
            "",
            "\tif (rcu_read_lock_held_common(&ret))",
            "\t\treturn ret;",
            "\treturn lock_is_held(&rcu_sched_lock_map) || !preemptible();",
            "}",
            "bool rcu_gp_is_normal(void)",
            "{",
            "\treturn READ_ONCE(rcu_normal) &&",
            "\t       rcu_scheduler_active != RCU_SCHEDULER_INIT;",
            "}",
            "bool rcu_async_should_hurry(void)",
            "{",
            "\treturn !IS_ENABLED(CONFIG_RCU_LAZY) ||",
            "\t       atomic_read(&rcu_async_hurry_nesting);",
            "}",
            "void rcu_async_hurry(void)",
            "{",
            "\tif (IS_ENABLED(CONFIG_RCU_LAZY))",
            "\t\tatomic_inc(&rcu_async_hurry_nesting);",
            "}",
            "void rcu_async_relax(void)",
            "{",
            "\tif (IS_ENABLED(CONFIG_RCU_LAZY))",
            "\t\tatomic_dec(&rcu_async_hurry_nesting);",
            "}",
            "bool rcu_gp_is_expedited(void)",
            "{",
            "\treturn rcu_expedited || atomic_read(&rcu_expedited_nesting);",
            "}",
            "void rcu_expedite_gp(void)",
            "{",
            "\tatomic_inc(&rcu_expedited_nesting);",
            "}",
            "void rcu_unexpedite_gp(void)",
            "{",
            "\tatomic_dec(&rcu_expedited_nesting);",
            "}",
            "void rcu_end_inkernel_boot(void)",
            "{",
            "\trcu_unexpedite_gp();",
            "\trcu_async_relax();",
            "\tif (rcu_normal_after_boot)",
            "\t\tWRITE_ONCE(rcu_normal, 1);",
            "\trcu_boot_ended = true;",
            "}",
            "bool rcu_inkernel_boot_has_ended(void)",
            "{",
            "\treturn rcu_boot_ended;",
            "}",
            "void rcu_test_sync_prims(void)",
            "{",
            "\tif (!IS_ENABLED(CONFIG_PROVE_RCU))",
            "\t\treturn;",
            "\tpr_info(\"Running RCU synchronous self tests\\n\");",
            "\tsynchronize_rcu();",
            "\tsynchronize_rcu_expedited();",
            "}",
            "static int __init rcu_set_runtime_mode(void)",
            "{",
            "\trcu_test_sync_prims();",
            "\trcu_scheduler_active = RCU_SCHEDULER_RUNNING;",
            "\tkfree_rcu_scheduler_running();",
            "\trcu_test_sync_prims();",
            "\treturn 0;",
            "}",
            "noinstr int notrace debug_lockdep_rcu_enabled(void)",
            "{",
            "\treturn rcu_scheduler_active != RCU_SCHEDULER_INACTIVE && READ_ONCE(debug_locks) &&",
            "\t       current->lockdep_recursion == 0;",
            "}",
            "int rcu_read_lock_held(void)",
            "{",
            "\tbool ret;",
            "",
            "\tif (rcu_read_lock_held_common(&ret))",
            "\t\treturn ret;",
            "\treturn lock_is_held(&rcu_lock_map);",
            "}",
            "int rcu_read_lock_bh_held(void)",
            "{",
            "\tbool ret;",
            "",
            "\tif (rcu_read_lock_held_common(&ret))",
            "\t\treturn ret;",
            "\treturn in_softirq() || irqs_disabled();",
            "}"
          ],
          "function_name": "rcu_read_lock_held_common, rcu_read_lock_sched_held, rcu_gp_is_normal, rcu_async_should_hurry, rcu_async_hurry, rcu_async_relax, rcu_gp_is_expedited, rcu_expedite_gp, rcu_unexpedite_gp, rcu_end_inkernel_boot, rcu_inkernel_boot_has_ended, rcu_test_sync_prims, rcu_set_runtime_mode, debug_lockdep_rcu_enabled, rcu_read_lock_held, rcu_read_lock_bh_held",
          "description": "实现了一系列RCU读锁状态检查函数及grace period管理逻辑，用于判断当前是否处于正常或加速模式，并提供同步原语测试接口。",
          "similarity": 0.5726832151412964
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/rcu/update.c",
          "start_line": 1,
          "end_line": 101,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0+",
            "/*",
            " * Read-Copy Update mechanism for mutual exclusion",
            " *",
            " * Copyright IBM Corporation, 2001",
            " *",
            " * Authors: Dipankar Sarma <dipankar@in.ibm.com>",
            " *\t    Manfred Spraul <manfred@colorfullife.com>",
            " *",
            " * Based on the original work by Paul McKenney <paulmck@linux.ibm.com>",
            " * and inputs from Rusty Russell, Andrea Arcangeli and Andi Kleen.",
            " * Papers:",
            " * http://www.rdrop.com/users/paulmck/paper/rclockpdcsproof.pdf",
            " * http://lse.sourceforge.net/locking/rclock_OLS.2001.05.01c.sc.pdf (OLS2001)",
            " *",
            " * For detailed explanation of Read-Copy Update mechanism see -",
            " *\t\thttp://lse.sourceforge.net/locking/rcupdate.html",
            " *",
            " */",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/smp.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/atomic.h>",
            "#include <linux/bitops.h>",
            "#include <linux/percpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/delay.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/kthread.h>",
            "#include <linux/tick.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/slab.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/rcupdate_trace.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "",
            "#include \"rcu.h\"",
            "",
            "#ifdef MODULE_PARAM_PREFIX",
            "#undef MODULE_PARAM_PREFIX",
            "#endif",
            "#define MODULE_PARAM_PREFIX \"rcupdate.\"",
            "",
            "#ifndef CONFIG_TINY_RCU",
            "module_param(rcu_expedited, int, 0444);",
            "module_param(rcu_normal, int, 0444);",
            "static int rcu_normal_after_boot = IS_ENABLED(CONFIG_PREEMPT_RT);",
            "#if !defined(CONFIG_PREEMPT_RT) || defined(CONFIG_NO_HZ_FULL)",
            "module_param(rcu_normal_after_boot, int, 0444);",
            "#endif",
            "#endif /* #ifndef CONFIG_TINY_RCU */",
            "",
            "#ifdef CONFIG_DEBUG_LOCK_ALLOC",
            "/**",
            " * rcu_read_lock_held_common() - might we be in RCU-sched read-side critical section?",
            " * @ret:\tBest guess answer if lockdep cannot be relied on",
            " *",
            " * Returns true if lockdep must be ignored, in which case ``*ret`` contains",
            " * the best guess described below.  Otherwise returns false, in which",
            " * case ``*ret`` tells the caller nothing and the caller should instead",
            " * consult lockdep.",
            " *",
            " * If CONFIG_DEBUG_LOCK_ALLOC is selected, set ``*ret`` to nonzero iff in an",
            " * RCU-sched read-side critical section.  In absence of",
            " * CONFIG_DEBUG_LOCK_ALLOC, this assumes we are in an RCU-sched read-side",
            " * critical section unless it can prove otherwise.  Note that disabling",
            " * of preemption (including disabling irqs) counts as an RCU-sched",
            " * read-side critical section.  This is useful for debug checks in functions",
            " * that required that they be called within an RCU-sched read-side",
            " * critical section.",
            " *",
            " * Check debug_lockdep_rcu_enabled() to prevent false positives during boot",
            " * and while lockdep is disabled.",
            " *",
            " * Note that if the CPU is in the idle loop from an RCU point of view (ie:",
            " * that we are in the section between ct_idle_enter() and ct_idle_exit())",
            " * then rcu_read_lock_held() sets ``*ret`` to false even if the CPU did an",
            " * rcu_read_lock().  The reason for this is that RCU ignores CPUs that are",
            " * in such a section, considering these as in extended quiescent state,",
            " * so such a CPU is effectively never in an RCU read-side critical section",
            " * regardless of what RCU primitives it invokes.  This state of affairs is",
            " * required --- we need to keep an RCU-free window in idle where the CPU may",
            " * possibly enter into low power mode. This way we can notice an extended",
            " * quiescent state to other CPUs that started a grace period. Otherwise",
            " * we would delay any grace period as long as we run in the idle task.",
            " *",
            " * Similarly, we avoid claiming an RCU read lock held if the current",
            " * CPU is offline.",
            " */"
          ],
          "function_name": null,
          "description": "此代码块声明了RCU机制的相关头文件及模块参数，主要用于配置RCU的不同模式（如normal和expedited）和调试选项，但上下文不完整。",
          "similarity": 0.5726627707481384
        }
      ]
    }
  ]
}