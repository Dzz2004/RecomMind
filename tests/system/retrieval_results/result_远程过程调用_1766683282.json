{
  "query": "远程过程调用",
  "timestamp": "2025-12-26 01:21:22",
  "retrieved_files": [
    {
      "source_file": "kernel/static_call_inline.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:29:06\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `static_call_inline.c`\n\n---\n\n# static_call_inline.c 技术文档\n\n## 1. 文件概述\n\n`static_call_inline.c` 是 Linux 内核中实现 **静态调用（Static Call）** 机制的核心文件之一。静态调用是一种运行时可动态更新的函数调用优化技术，它在编译时将函数调用点内联为对跳板（trampoline）的直接跳转，而在运行时可通过 `__static_call_update()` 动态修改所有调用点，使其跳转到新的目标函数，从而避免传统函数指针调用的间接开销。该机制常用于性能敏感路径（如调度、RCU、tracepoint 等），同时支持模块热插拔和初始化阶段的特殊处理。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `static_call_force_reinit(void)`  \n  强制重新初始化静态调用机制，用于调试或特殊场景，必须在 `early_initcall()` 之前调用。\n\n- `__static_call_update(struct static_call_key *key, void *tramp, void *func)`  \n  核心更新函数：将指定 `key` 对应的所有静态调用点更新为调用 `func`，并更新跳板 `tramp`。支持内核和模块中的调用点。\n\n- `__static_call_init(struct module *mod, struct static_call_site *start, struct static_call_site *stop)`  \n  初始化静态调用站点，对站点按 `key` 排序，并建立 `key` 到站点的映射关系，同时执行首次 `arch_static_call_transform`。\n\n- `__static_call_text_reserved(...)`  \n  检查指定代码区间是否与活跃的静态调用站点冲突，用于内存热插拔或代码修改前的安全校验。\n\n### 主要数据结构\n\n- `struct static_call_site`  \n  描述一个静态调用点的位置（`addr`）和关联的 `key`（带标志位）。\n\n- `struct static_call_key`  \n  静态调用的“键”，用于将多个调用点分组。包含当前函数指针 `func` 和类型/模块信息。\n\n- `struct static_call_mod`  \n  用于模块场景下，将模块与该模块中属于某 `key` 的调用点列表关联。\n\n- 全局符号：\n  - `__start_static_call_sites[]` / `__stop_static_call_sites[]`：内核镜像中所有静态调用点的链接器生成数组。\n  - `__start_static_call_tramp_key[]` / `__stop_static_call_tramp_key[]`：跳板与 key 的映射。\n\n### 辅助函数与宏\n\n- `static_call_addr(site)`：计算调用点的实际地址（处理重定位）。\n- `static_call_key(site)`：从站点中提取 `static_call_key*`（忽略标志位）。\n- `static_call_is_init(site)` / `static_call_is_tail(site)`：检查站点是否位于 `__init` 段或是否为尾调用。\n- `static_call_sort_entries()`：对站点按 `key` 排序，便于批量处理。\n- `static_call_key_has_mods()` / `static_call_key_sites()`：判断 key 是否关联模块或直接站点。\n\n## 3. 关键实现\n\n### 地址重定位处理\n由于静态调用站点在编译时使用相对地址存储，`static_call_addr()` 和 `__static_call_key()` 通过 `(long)field + (long)&field` 的方式计算出运行时绝对地址，这是处理位置无关代码（PIC）和内核重定位的关键技巧。\n\n### 站点组织与模块支持\n- **内核（vmlinux）场景**：为节省内存和避免早期内存分配，将首个站点指针直接编码到 `key->type` 的低有效位中（通过 `| 1` 标记）。\n- **模块场景**：使用 `static_call_mod` 链表管理不同模块中属于同一 `key` 的站点，支持模块加载/卸载时的动态注册。\n\n### 初始化与更新流程\n1. **初始化**（`__static_call_init`）：\n   - 对站点按 `key` 排序。\n   - 标记位于 `__init` 段的站点（后续更新可跳过）。\n   - 建立 `key` 到站点的映射。\n   - 调用架构相关 `arch_static_call_transform` 执行首次转换（通常设为跳板）。\n\n2. **更新**（`__static_call_update`）：\n   - 更新 `key->func`。\n   - 更新跳板 `tramp` 指向新函数。\n   - 遍历所有关联站点（包括模块），调用 `arch_static_call_transform` 修改调用点指令（如 x86 的 `jmp` 目标）。\n   - 跳过 `__init` 段中已初始化的站点（因不会被执行）。\n\n### 安全与并发控制\n- 使用 `cpus_read_lock()` 防止 CPU 热插拔期间的并发问题。\n- 使用 `static_call_mutex` 保护 `key` 和站点数据结构的修改。\n- 通过 `kernel_text_address()` 验证调用点是否在可执行内核文本段，避免修改无效地址。\n\n## 4. 依赖关系\n\n- **架构依赖**：依赖 `asm/sections.h` 和 `arch_static_call_transform()`（由各架构实现，如 x86、ARM64）。\n- **内核子系统**：\n  - `linux/module.h`：模块加载/卸载时的静态调用站点管理。\n  - `linux/cpu.h` / `linux/smp.h`：CPU 热插拔和并发控制。\n  - `linux/sort.h`：站点排序。\n  - `linux/slab.h`：模块场景下的动态内存分配。\n- **链接器脚本**：依赖链接器生成的 `__start/stop_static_call_sites` 等符号，这些在 `vmlinux.lds` 中定义。\n\n## 5. 使用场景\n\n- **内核核心优化**：在调度器、RCU、中断处理等高频路径中替代函数指针，减少间接调用开销。\n- **动态追踪（ftrace）**：作为 tracepoint 或 kprobe 的底层机制，实现零开销探针。\n- **模块热插拔**：模块加载时注册其静态调用站点，卸载时自动清理，确保调用点始终有效。\n- **初始化优化**：`__init` 段的调用点在初始化完成后可被安全忽略，减少运行时开销。\n- **安全代码修改**：在 livepatch 或内核热补丁中，安全地替换函数实现而不影响运行中的调用。",
      "similarity": 0.600491464138031,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 220,
          "end_line": 340,
          "content": [
            "static int __static_call_init(struct module *mod,",
            "\t\t\t      struct static_call_site *start,",
            "\t\t\t      struct static_call_site *stop)",
            "{",
            "\tstruct static_call_site *site;",
            "\tstruct static_call_key *key, *prev_key = NULL;",
            "\tstruct static_call_mod *site_mod;",
            "",
            "\tif (start == stop)",
            "\t\treturn 0;",
            "",
            "\tstatic_call_sort_entries(start, stop);",
            "",
            "\tfor (site = start; site < stop; site++) {",
            "\t\tvoid *site_addr = static_call_addr(site);",
            "",
            "\t\tif ((mod && within_module_init((unsigned long)site_addr, mod)) ||",
            "\t\t    (!mod && init_section_contains(site_addr, 1)))",
            "\t\t\tstatic_call_set_init(site);",
            "",
            "\t\tkey = static_call_key(site);",
            "\t\tif (key != prev_key) {",
            "\t\t\tprev_key = key;",
            "",
            "\t\t\t/*",
            "\t\t\t * For vmlinux (!mod) avoid the allocation by storing",
            "\t\t\t * the sites pointer in the key itself. Also see",
            "\t\t\t * __static_call_update()'s @first.",
            "\t\t\t *",
            "\t\t\t * This allows architectures (eg. x86) to call",
            "\t\t\t * static_call_init() before memory allocation works.",
            "\t\t\t */",
            "\t\t\tif (!mod) {",
            "\t\t\t\tkey->sites = site;",
            "\t\t\t\tkey->type |= 1;",
            "\t\t\t\tgoto do_transform;",
            "\t\t\t}",
            "",
            "\t\t\tsite_mod = kzalloc(sizeof(*site_mod), GFP_KERNEL);",
            "\t\t\tif (!site_mod)",
            "\t\t\t\treturn -ENOMEM;",
            "",
            "\t\t\t/*",
            "\t\t\t * When the key has a direct sites pointer, extract",
            "\t\t\t * that into an explicit struct static_call_mod, so we",
            "\t\t\t * can have a list of modules.",
            "\t\t\t */",
            "\t\t\tif (static_call_key_sites(key)) {",
            "\t\t\t\tsite_mod->mod = NULL;",
            "\t\t\t\tsite_mod->next = NULL;",
            "\t\t\t\tsite_mod->sites = static_call_key_sites(key);",
            "",
            "\t\t\t\tkey->mods = site_mod;",
            "",
            "\t\t\t\tsite_mod = kzalloc(sizeof(*site_mod), GFP_KERNEL);",
            "\t\t\t\tif (!site_mod)",
            "\t\t\t\t\treturn -ENOMEM;",
            "\t\t\t}",
            "",
            "\t\t\tsite_mod->mod = mod;",
            "\t\t\tsite_mod->sites = site;",
            "\t\t\tsite_mod->next = static_call_key_next(key);",
            "\t\t\tkey->mods = site_mod;",
            "\t\t}",
            "",
            "do_transform:",
            "\t\tarch_static_call_transform(site_addr, NULL, key->func,",
            "\t\t\t\tstatic_call_is_tail(site));",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int addr_conflict(struct static_call_site *site, void *start, void *end)",
            "{",
            "\tunsigned long addr = (unsigned long)static_call_addr(site);",
            "",
            "\tif (addr <= (unsigned long)end &&",
            "\t    addr + CALL_INSN_SIZE > (unsigned long)start)",
            "\t\treturn 1;",
            "",
            "\treturn 0;",
            "}",
            "static int __static_call_text_reserved(struct static_call_site *iter_start,",
            "\t\t\t\t       struct static_call_site *iter_stop,",
            "\t\t\t\t       void *start, void *end, bool init)",
            "{",
            "\tstruct static_call_site *iter = iter_start;",
            "",
            "\twhile (iter < iter_stop) {",
            "\t\tif (init || !static_call_is_init(iter)) {",
            "\t\t\tif (addr_conflict(iter, start, end))",
            "\t\t\t\treturn 1;",
            "\t\t}",
            "\t\titer++;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int __static_call_mod_text_reserved(void *start, void *end)",
            "{",
            "\tstruct module *mod;",
            "\tint ret;",
            "",
            "\tpreempt_disable();",
            "\tmod = __module_text_address((unsigned long)start);",
            "\tWARN_ON_ONCE(__module_text_address((unsigned long)end) != mod);",
            "\tif (!try_module_get(mod))",
            "\t\tmod = NULL;",
            "\tpreempt_enable();",
            "",
            "\tif (!mod)",
            "\t\treturn 0;",
            "",
            "\tret = __static_call_text_reserved(mod->static_call_sites,",
            "\t\t\tmod->static_call_sites + mod->num_static_call_sites,",
            "\t\t\tstart, end, mod->state == MODULE_STATE_COMING);",
            "",
            "\tmodule_put(mod);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__static_call_init, addr_conflict, __static_call_text_reserved, __static_call_mod_text_reserved",
          "description": "执行静态调用初始化流程，分配模块关联结构体并进行地址转换，实现文本区域预留检查以避免内存覆盖。",
          "similarity": 0.597192108631134
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 453,
          "end_line": 552,
          "content": [
            "static int static_call_module_notify(struct notifier_block *nb,",
            "\t\t\t\t     unsigned long val, void *data)",
            "{",
            "\tstruct module *mod = data;",
            "\tint ret = 0;",
            "",
            "\tcpus_read_lock();",
            "\tstatic_call_lock();",
            "",
            "\tswitch (val) {",
            "\tcase MODULE_STATE_COMING:",
            "\t\tret = static_call_add_module(mod);",
            "\t\tif (ret) {",
            "\t\t\tpr_warn(\"Failed to allocate memory for static calls\\n\");",
            "\t\t\tstatic_call_del_module(mod);",
            "\t\t}",
            "\t\tbreak;",
            "\tcase MODULE_STATE_GOING:",
            "\t\tstatic_call_del_module(mod);",
            "\t\tbreak;",
            "\t}",
            "",
            "\tstatic_call_unlock();",
            "\tcpus_read_unlock();",
            "",
            "\treturn notifier_from_errno(ret);",
            "}",
            "int klp_static_call_register(struct module *mod)",
            "{",
            "\tint ret;",
            "",
            "\tret = static_call_module_notify(&static_call_module_nb, MODULE_STATE_COMING, mod);",
            "\treturn notifier_to_errno(ret);",
            "}",
            "static inline int __static_call_mod_text_reserved(void *start, void *end)",
            "{",
            "\treturn 0;",
            "}",
            "int static_call_text_reserved(void *start, void *end)",
            "{",
            "\tbool init = system_state < SYSTEM_RUNNING;",
            "\tint ret = __static_call_text_reserved(__start_static_call_sites,",
            "\t\t\t__stop_static_call_sites, start, end, init);",
            "",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\treturn __static_call_mod_text_reserved(start, end);",
            "}",
            "int __init static_call_init(void)",
            "{",
            "\tint ret;",
            "",
            "\t/* See static_call_force_reinit(). */",
            "\tif (static_call_initialized == 1)",
            "\t\treturn 0;",
            "",
            "\tcpus_read_lock();",
            "\tstatic_call_lock();",
            "\tret = __static_call_init(NULL, __start_static_call_sites,",
            "\t\t\t\t __stop_static_call_sites);",
            "\tstatic_call_unlock();",
            "\tcpus_read_unlock();",
            "",
            "\tif (ret) {",
            "\t\tpr_err(\"Failed to allocate memory for static_call!\\n\");",
            "\t\tBUG();",
            "\t}",
            "",
            "#ifdef CONFIG_MODULES",
            "\tif (!static_call_initialized)",
            "\t\tregister_module_notifier(&static_call_module_nb);",
            "#endif",
            "",
            "\tstatic_call_initialized = 1;",
            "\treturn 0;",
            "}",
            "static int func_a(int x)",
            "{",
            "\treturn x+1;",
            "}",
            "static int func_b(int x)",
            "{",
            "\treturn x+2;",
            "}",
            "static int __init test_static_call_init(void)",
            "{",
            "      int i;",
            "",
            "      for (i = 0; i < ARRAY_SIZE(static_call_data); i++ ) {",
            "\t      struct static_call_data *scd = &static_call_data[i];",
            "",
            "              if (scd->func)",
            "                      static_call_update(sc_selftest, scd->func);",
            "",
            "              WARN_ON(static_call(sc_selftest)(scd->val) != scd->expect);",
            "      }",
            "",
            "      return 0;",
            "}"
          ],
          "function_name": "static_call_module_notify, klp_static_call_register, __static_call_mod_text_reserved, static_call_text_reserved, static_call_init, func_a, func_b, test_static_call_init",
          "description": "实现模块状态变更通知机制，完成静态调用系统的初始化注册，包含测试函数用于验证静态调用逻辑的正确性。",
          "similarity": 0.5956720113754272
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 23,
          "end_line": 176,
          "content": [
            "void static_call_force_reinit(void)",
            "{",
            "\tif (WARN_ON_ONCE(!static_call_initialized))",
            "\t\treturn;",
            "",
            "\tstatic_call_initialized++;",
            "}",
            "static void static_call_lock(void)",
            "{",
            "\tmutex_lock(&static_call_mutex);",
            "}",
            "static void static_call_unlock(void)",
            "{",
            "\tmutex_unlock(&static_call_mutex);",
            "}",
            "static inline unsigned long __static_call_key(const struct static_call_site *site)",
            "{",
            "\treturn (long)site->key + (long)&site->key;",
            "}",
            "static inline bool static_call_is_init(struct static_call_site *site)",
            "{",
            "\treturn __static_call_key(site) & STATIC_CALL_SITE_INIT;",
            "}",
            "static inline bool static_call_is_tail(struct static_call_site *site)",
            "{",
            "\treturn __static_call_key(site) & STATIC_CALL_SITE_TAIL;",
            "}",
            "static inline void static_call_set_init(struct static_call_site *site)",
            "{",
            "\tsite->key = (__static_call_key(site) | STATIC_CALL_SITE_INIT) -",
            "\t\t    (long)&site->key;",
            "}",
            "static int static_call_site_cmp(const void *_a, const void *_b)",
            "{",
            "\tconst struct static_call_site *a = _a;",
            "\tconst struct static_call_site *b = _b;",
            "\tconst struct static_call_key *key_a = static_call_key(a);",
            "\tconst struct static_call_key *key_b = static_call_key(b);",
            "",
            "\tif (key_a < key_b)",
            "\t\treturn -1;",
            "",
            "\tif (key_a > key_b)",
            "\t\treturn 1;",
            "",
            "\treturn 0;",
            "}",
            "static void static_call_site_swap(void *_a, void *_b, int size)",
            "{",
            "\tlong delta = (unsigned long)_a - (unsigned long)_b;",
            "\tstruct static_call_site *a = _a;",
            "\tstruct static_call_site *b = _b;",
            "\tstruct static_call_site tmp = *a;",
            "",
            "\ta->addr = b->addr  - delta;",
            "\ta->key  = b->key   - delta;",
            "",
            "\tb->addr = tmp.addr + delta;",
            "\tb->key  = tmp.key  + delta;",
            "}",
            "static inline void static_call_sort_entries(struct static_call_site *start,",
            "\t\t\t\t\t    struct static_call_site *stop)",
            "{",
            "\tsort(start, stop - start, sizeof(struct static_call_site),",
            "\t     static_call_site_cmp, static_call_site_swap);",
            "}",
            "static inline bool static_call_key_has_mods(struct static_call_key *key)",
            "{",
            "\treturn !(key->type & 1);",
            "}",
            "void __static_call_update(struct static_call_key *key, void *tramp, void *func)",
            "{",
            "\tstruct static_call_site *site, *stop;",
            "\tstruct static_call_mod *site_mod, first;",
            "",
            "\tcpus_read_lock();",
            "\tstatic_call_lock();",
            "",
            "\tif (key->func == func)",
            "\t\tgoto done;",
            "",
            "\tkey->func = func;",
            "",
            "\tarch_static_call_transform(NULL, tramp, func, false);",
            "",
            "\t/*",
            "\t * If uninitialized, we'll not update the callsites, but they still",
            "\t * point to the trampoline and we just patched that.",
            "\t */",
            "\tif (WARN_ON_ONCE(!static_call_initialized))",
            "\t\tgoto done;",
            "",
            "\tfirst = (struct static_call_mod){",
            "\t\t.next = static_call_key_next(key),",
            "\t\t.mod = NULL,",
            "\t\t.sites = static_call_key_sites(key),",
            "\t};",
            "",
            "\tfor (site_mod = &first; site_mod; site_mod = site_mod->next) {",
            "\t\tbool init = system_state < SYSTEM_RUNNING;",
            "\t\tstruct module *mod = site_mod->mod;",
            "",
            "\t\tif (!site_mod->sites) {",
            "\t\t\t/*",
            "\t\t\t * This can happen if the static call key is defined in",
            "\t\t\t * a module which doesn't use it.",
            "\t\t\t *",
            "\t\t\t * It also happens in the has_mods case, where the",
            "\t\t\t * 'first' entry has no sites associated with it.",
            "\t\t\t */",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tstop = __stop_static_call_sites;",
            "",
            "\t\tif (mod) {",
            "#ifdef CONFIG_MODULES",
            "\t\t\tstop = mod->static_call_sites +",
            "\t\t\t       mod->num_static_call_sites;",
            "\t\t\tinit = mod->state == MODULE_STATE_COMING;",
            "#endif",
            "\t\t}",
            "",
            "\t\tfor (site = site_mod->sites;",
            "\t\t     site < stop && static_call_key(site) == key; site++) {",
            "\t\t\tvoid *site_addr = static_call_addr(site);",
            "",
            "\t\t\tif (!init && static_call_is_init(site))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tif (!kernel_text_address((unsigned long)site_addr)) {",
            "\t\t\t\t/*",
            "\t\t\t\t * This skips patching built-in __exit, which",
            "\t\t\t\t * is part of init_section_contains() but is",
            "\t\t\t\t * not part of kernel_text_address().",
            "\t\t\t\t *",
            "\t\t\t\t * Skipping built-in __exit is fine since it",
            "\t\t\t\t * will never be executed.",
            "\t\t\t\t */",
            "\t\t\t\tWARN_ONCE(!static_call_is_init(site),",
            "\t\t\t\t\t  \"can't patch static call site at %pS\",",
            "\t\t\t\t\t  site_addr);",
            "\t\t\t\tcontinue;",
            "\t\t\t}",
            "",
            "\t\t\tarch_static_call_transform(site_addr, NULL, func,",
            "\t\t\t\t\t\t   static_call_is_tail(site));",
            "\t\t}",
            "\t}",
            "",
            "done:",
            "\tstatic_call_unlock();",
            "\tcpus_read_unlock();",
            "}"
          ],
          "function_name": "static_call_force_reinit, static_call_lock, static_call_unlock, __static_call_key, static_call_is_init, static_call_is_tail, static_call_set_init, static_call_site_cmp, static_call_site_swap, static_call_sort_entries, static_call_key_has_mods, __static_call_update",
          "description": "实现静态调用的互斥锁控制、键值计算、站点排序及更新逻辑，包含地址冲突检测和模块间调用关系维护功能。",
          "similarity": 0.5836806297302246
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 347,
          "end_line": 449,
          "content": [
            "static unsigned long tramp_key_lookup(unsigned long addr)",
            "{",
            "\tstruct static_call_tramp_key *start = __start_static_call_tramp_key;",
            "\tstruct static_call_tramp_key *stop = __stop_static_call_tramp_key;",
            "\tstruct static_call_tramp_key *tramp_key;",
            "",
            "\tfor (tramp_key = start; tramp_key != stop; tramp_key++) {",
            "\t\tunsigned long tramp;",
            "",
            "\t\ttramp = (long)tramp_key->tramp + (long)&tramp_key->tramp;",
            "\t\tif (tramp == addr)",
            "\t\t\treturn (long)tramp_key->key + (long)&tramp_key->key;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int static_call_add_module(struct module *mod)",
            "{",
            "\tstruct static_call_site *start = mod->static_call_sites;",
            "\tstruct static_call_site *stop = start + mod->num_static_call_sites;",
            "\tstruct static_call_site *site;",
            "",
            "#ifdef CONFIG_LIVEPATCH_WO_FTRACE",
            "\tif (unlikely(!mod_klp_rel_completed(mod)))",
            "\t\treturn 0;",
            "#endif",
            "",
            "\tfor (site = start; site != stop; site++) {",
            "\t\tunsigned long s_key = __static_call_key(site);",
            "\t\tunsigned long addr = s_key & ~STATIC_CALL_SITE_FLAGS;",
            "\t\tunsigned long key;",
            "",
            "\t\t/*",
            "\t\t * Is the key is exported, 'addr' points to the key, which",
            "\t\t * means modules are allowed to call static_call_update() on",
            "\t\t * it.",
            "\t\t *",
            "\t\t * Otherwise, the key isn't exported, and 'addr' points to the",
            "\t\t * trampoline so we need to lookup the key.",
            "\t\t *",
            "\t\t * We go through this dance to prevent crazy modules from",
            "\t\t * abusing sensitive static calls.",
            "\t\t */",
            "\t\tif (!kernel_text_address(addr))",
            "\t\t\tcontinue;",
            "",
            "\t\tkey = tramp_key_lookup(addr);",
            "\t\tif (!key) {",
            "\t\t\tpr_warn(\"Failed to fixup __raw_static_call() usage at: %ps\\n\",",
            "\t\t\t\tstatic_call_addr(site));",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "",
            "\t\tkey |= s_key & STATIC_CALL_SITE_FLAGS;",
            "\t\tsite->key = key - (long)&site->key;",
            "\t}",
            "",
            "\treturn __static_call_init(mod, start, stop);",
            "}",
            "static void static_call_del_module(struct module *mod)",
            "{",
            "\tstruct static_call_site *start = mod->static_call_sites;",
            "\tstruct static_call_site *stop = mod->static_call_sites +",
            "\t\t\t\t\tmod->num_static_call_sites;",
            "\tstruct static_call_key *key, *prev_key = NULL;",
            "\tstruct static_call_mod *site_mod, **prev;",
            "\tstruct static_call_site *site;",
            "",
            "#ifdef CONFIG_LIVEPATCH_WO_FTRACE",
            "\tif (unlikely(!mod_klp_rel_completed(mod)))",
            "\t\treturn;",
            "#endif",
            "",
            "\tfor (site = start; site < stop; site++) {",
            "\t\tkey = static_call_key(site);",
            "",
            "\t\t/*",
            "\t\t * If the key was not updated due to a memory allocation",
            "\t\t * failure in __static_call_init() then treating key::sites",
            "\t\t * as key::mods in the code below would cause random memory",
            "\t\t * access and #GP. In that case all subsequent sites have",
            "\t\t * not been touched either, so stop iterating.",
            "\t\t */",
            "\t\tif (!static_call_key_has_mods(key))",
            "\t\t\tbreak;",
            "",
            "\t\tif (key == prev_key)",
            "\t\t\tcontinue;",
            "",
            "\t\tprev_key = key;",
            "",
            "\t\tfor (prev = &key->mods, site_mod = key->mods;",
            "\t\t     site_mod && site_mod->mod != mod;",
            "\t\t     prev = &site_mod->next, site_mod = site_mod->next)",
            "\t\t\t;",
            "",
            "\t\tif (!site_mod)",
            "\t\t\tcontinue;",
            "",
            "\t\t*prev = site_mod->next;",
            "\t\tkfree(site_mod);",
            "\t}",
            "}"
          ],
          "function_name": "tramp_key_lookup, static_call_add_module, static_call_del_module",
          "description": "处理模块动态加载/卸载时的静态调用更新，通过键查找机制确保跨模块调用正确性，并维护静态调用站点的模块绑定关系。",
          "similarity": 0.5662692785263062
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/static_call_inline.c",
          "start_line": 1,
          "end_line": 22,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/init.h>",
            "#include <linux/static_call.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>",
            "#include <linux/sort.h>",
            "#include <linux/slab.h>",
            "#include <linux/module.h>",
            "#include <linux/cpu.h>",
            "#include <linux/processor.h>",
            "#include <asm/sections.h>",
            "",
            "extern struct static_call_site __start_static_call_sites[],",
            "\t\t\t       __stop_static_call_sites[];",
            "extern struct static_call_tramp_key __start_static_call_tramp_key[],",
            "\t\t\t\t    __stop_static_call_tramp_key[];",
            "",
            "int static_call_initialized;",
            "",
            "/*",
            " * Must be called before early_initcall() to be effective.",
            " */"
          ],
          "function_name": null,
          "description": "声明静态调用相关的全局变量和外部符号，定义静态调用初始化标志位，为后续静态调用站点管理和地址转换提供基础结构。",
          "similarity": 0.5654555559158325
        }
      ]
    },
    {
      "source_file": "kernel/sched/rt.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:14:51\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\rt.c`\n\n---\n\n# `sched/rt.c` 技术文档\n\n## 1. 文件概述\n\n`sched/rt.c` 是 Linux 内核调度子系统中实现实时（Real-Time, RT）调度类的核心文件，主要支持 `SCHED_FIFO` 和 `SCHED_RR` 两种 POSIX 实时调度策略。该文件负责管理实时任务的运行队列、优先级调度、时间片分配、带宽限制（RT throttling）以及在多核系统（SMP）下的负载均衡机制。此外，它还提供了对实时任务组调度（RT Group Scheduling）的支持，允许通过 cgroups 对实时任务的 CPU 使用进行资源控制。\n\n## 2. 核心功能\n\n### 全局变量\n- `sched_rr_timeslice`：定义 `SCHED_RR` 策略的默认时间片长度（单位：调度 tick）。\n- `max_rt_runtime`：实时任务在单个周期内可使用的最大运行时间上限（通常为 4 小时以上）。\n- `sysctl_sched_rt_period`：实时带宽控制的周期，默认为 1,000,000 微秒（1 秒）。\n- `sysctl_sched_rt_runtime`：每个周期内允许实时任务运行的时间，默认为 950,000 微秒（0.95 秒）。\n\n### sysctl 接口（`CONFIG_SYSCTL` 启用时）\n- `/proc/sys/kernel/sched_rt_period_us`：设置 RT 带宽控制周期。\n- `/proc/sys/kernel/sched_rt_runtime_us`：设置 RT 带宽控制运行时间（可设为 -1 表示无限制）。\n- `/proc/sys/kernel/sched_rr_timeslice_ms`：设置 `SCHED_RR` 时间片（毫秒）。\n\n### 主要函数\n- `init_rt_rq(struct rt_rq *rt_rq)`：初始化实时运行队列（`rt_rq`），包括优先级位图、链表、SMP 相关字段及带宽控制状态。\n- `init_rt_bandwidth(struct rt_bandwidth *rt_b, u64 period, u64 runtime)`：初始化 RT 带宽控制结构，配置高精度定时器。\n- `sched_rt_period_timer(struct hrtimer *timer)`：高精度定时器回调函数，用于周期性重置 RT 运行时间配额。\n- `start_rt_bandwidth(struct rt_bandwidth *rt_b)`：启动 RT 带宽控制定时器。\n- `alloc_rt_sched_group / free_rt_sched_group / unregister_rt_sched_group`：管理实时任务组（task group）的资源分配与释放。\n- `init_tg_rt_entry`：初始化任务组在指定 CPU 上的 RT 调度实体和运行队列。\n- `rt_task_of / rq_of_rt_rq / rt_rq_of_se / rq_of_rt_se`：辅助函数，用于在调度实体、任务、运行队列和 CPU 队列之间相互转换。\n\n### SMP 支持函数（`CONFIG_SMP` 启用时）\n- `need_pull_rt_task`：判断是否需要从其他 CPU 拉取高优先级 RT 任务。\n- `rt_overloaded` / `rt_set_overload`：用于跟踪系统中是否存在过载的 RT 运行队列，支持 RT 任务迁移。\n\n## 3. 关键实现\n\n### 实时运行队列（`rt_rq`）管理\n- 使用 `rt_prio_array` 结构维护 0 到 `MAX_RT_PRIO-1`（通常为 99）共 100 个优先级的双向链表。\n- 通过位图（`bitmap`）快速查找最高优先级的可运行任务，`__set_bit(MAX_RT_PRIO, bitmap)` 作为位图搜索的终止标记。\n- `rt_queued` 标志表示是否有 RT 任务入队；`highest_prio.curr/next` 跟踪当前和下一个最高优先级（SMP 专用）。\n\n### RT 带宽控制（Throttling）\n- 通过 `rt_bandwidth` 结构限制 RT 任务在每个 `rt_period` 内最多使用 `rt_runtime` 的 CPU 时间。\n- 使用高精度定时器（`hrtimer`）实现周期性重置：每经过 `rt_period`，将 `rt_time` 清零并解除 throttling。\n- 若 `rt_runtime == RUNTIME_INF`（即 -1），则禁用带宽限制。\n- 定时器回调 `sched_rt_period_timer` 支持处理定时器 overrun（跳过多个周期），确保带宽控制的准确性。\n\n### RT 任务组调度（`CONFIG_RT_GROUP_SCHED`）\n- 每个 `task_group` 拥有 per-CPU 的 `rt_rq` 和 `sched_rt_entity`。\n- 根叶节点（普通任务）的 `rt_se` 直接链接到 CPU 的全局 `rt_rq`；非叶节点（cgroup）的 `rt_se` 链接到父组的 `rt_rq`，形成调度树。\n- `rt_entity_is_task()` 用于区分调度实体是任务还是任务组。\n\n### SMP 负载均衡\n- 当某 CPU 上运行的 RT 任务优先级降低（如被抢占或阻塞），若其当前最高优先级高于刚被替换的任务，则触发 `need_pull_rt_task`，尝试从其他 CPU 拉取更高优先级的 RT 任务。\n- `overloaded` 标志和 `pushable_tasks` 链表用于支持 RT 任务的主动推送（push）和拉取（pull）机制，确保高优先级任务尽快运行。\n\n## 4. 依赖关系\n\n- **调度核心**：依赖 `kernel/sched/core.c` 提供的通用调度框架、运行队列（`rq`）结构和调度类注册机制。\n- **高精度定时器**：使用 `kernel/time/hrtimer.c` 实现 RT 带宽控制的周期性重置。\n- **SMP 调度**：与 `kernel/sched/topology.c` 和 `kernel/sched/fair.c` 协同实现跨 CPU 的 RT 任务迁移。\n- **cgroups**：当启用 `CONFIG_RT_GROUP_SCHED` 时，与 `kernel/cgroup/` 子系统集成，支持基于 cgroup v1/v2 的 RT 带宽分配。\n- **sysctl**：通过 `kernel/sysctl.c` 暴露运行时可调参数。\n\n## 5. 使用场景\n\n- **实时应用调度**：为音视频处理、工业控制、机器人等需要确定性延迟的应用提供 `SCHED_FIFO`/`SCHED_RR` 调度支持。\n- **系统资源保护**：通过 `sched_rt_runtime_us` 限制 RT 任务的 CPU 占用率（默认 95%），防止其独占 CPU 导致系统僵死。\n- **多租户 RT 资源隔离**：在容器或虚拟化环境中，利用 RT 任务组调度为不同租户分配独立的 RT 带宽配额。\n- **SMP 实时性能优化**：在多核系统中，通过 RT 任务迁移机制减少高优先级任务的调度延迟，提升实时响应能力。",
      "similarity": 0.5791855454444885,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/rt.c",
          "start_line": 1,
          "end_line": 56,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Real-Time Scheduling Class (mapped to the SCHED_FIFO and SCHED_RR",
            " * policies)",
            " */",
            "",
            "int sched_rr_timeslice = RR_TIMESLICE;",
            "/* More than 4 hours if BW_SHIFT equals 20. */",
            "static const u64 max_rt_runtime = MAX_BW;",
            "",
            "/*",
            " * period over which we measure -rt task CPU usage in us.",
            " * default: 1s",
            " */",
            "int sysctl_sched_rt_period = 1000000;",
            "",
            "/*",
            " * part of the period that we allow rt tasks to run in us.",
            " * default: 0.95s",
            " */",
            "int sysctl_sched_rt_runtime = 950000;",
            "",
            "#ifdef CONFIG_SYSCTL",
            "static int sysctl_sched_rr_timeslice = (MSEC_PER_SEC * RR_TIMESLICE) / HZ;",
            "static int sched_rt_handler(struct ctl_table *table, int write, void *buffer,",
            "\t\tsize_t *lenp, loff_t *ppos);",
            "static int sched_rr_handler(struct ctl_table *table, int write, void *buffer,",
            "\t\tsize_t *lenp, loff_t *ppos);",
            "static struct ctl_table sched_rt_sysctls[] = {",
            "\t{",
            "\t\t.procname       = \"sched_rt_period_us\",",
            "\t\t.data           = &sysctl_sched_rt_period,",
            "\t\t.maxlen         = sizeof(int),",
            "\t\t.mode           = 0644,",
            "\t\t.proc_handler   = sched_rt_handler,",
            "\t\t.extra1         = SYSCTL_ONE,",
            "\t\t.extra2         = SYSCTL_INT_MAX,",
            "\t},",
            "\t{",
            "\t\t.procname       = \"sched_rt_runtime_us\",",
            "\t\t.data           = &sysctl_sched_rt_runtime,",
            "\t\t.maxlen         = sizeof(int),",
            "\t\t.mode           = 0644,",
            "\t\t.proc_handler   = sched_rt_handler,",
            "\t\t.extra1         = SYSCTL_NEG_ONE,",
            "\t\t.extra2         = (void *)&sysctl_sched_rt_period,",
            "\t},",
            "\t{",
            "\t\t.procname       = \"sched_rr_timeslice_ms\",",
            "\t\t.data           = &sysctl_sched_rr_timeslice,",
            "\t\t.maxlen         = sizeof(int),",
            "\t\t.mode           = 0644,",
            "\t\t.proc_handler   = sched_rr_handler,",
            "\t},",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义实时调度类的配置参数及sysctl接口，设置默认的实时任务周期和运行时间，并注册相应的proc_handler以允许动态调整。",
          "similarity": 0.5767199993133545
        },
        {
          "chunk_id": 11,
          "file_path": "kernel/sched/rt.c",
          "start_line": 1449,
          "end_line": 1589,
          "content": [
            "static void dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)",
            "{",
            "\tstruct rq *rq = rq_of_rt_se(rt_se);",
            "",
            "\tupdate_stats_dequeue_rt(rt_rq_of_se(rt_se), rt_se, flags);",
            "",
            "\tdequeue_rt_stack(rt_se, flags);",
            "",
            "\tfor_each_sched_rt_entity(rt_se) {",
            "\t\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);",
            "",
            "\t\tif (rt_rq && rt_rq->rt_nr_running)",
            "\t\t\t__enqueue_rt_entity(rt_se, flags);",
            "\t}",
            "\tenqueue_top_rt_rq(&rq->rt);",
            "}",
            "static void",
            "enqueue_task_rt(struct rq *rq, struct task_struct *p, int flags)",
            "{",
            "\tstruct sched_rt_entity *rt_se = &p->rt;",
            "",
            "\tif (flags & ENQUEUE_WAKEUP)",
            "\t\trt_se->timeout = 0;",
            "",
            "\tcheck_schedstat_required();",
            "\tupdate_stats_wait_start_rt(rt_rq_of_se(rt_se), rt_se);",
            "",
            "\tenqueue_rt_entity(rt_se, flags);",
            "",
            "\tif (!task_current(rq, p) && p->nr_cpus_allowed > 1)",
            "\t\tenqueue_pushable_task(rq, p);",
            "}",
            "static bool dequeue_task_rt(struct rq *rq, struct task_struct *p, int flags)",
            "{",
            "\tstruct sched_rt_entity *rt_se = &p->rt;",
            "",
            "\tupdate_curr_rt(rq);",
            "\tdequeue_rt_entity(rt_se, flags);",
            "",
            "\tdequeue_pushable_task(rq, p);",
            "",
            "\treturn true;",
            "}",
            "static void",
            "requeue_rt_entity(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se, int head)",
            "{",
            "\tif (on_rt_rq(rt_se)) {",
            "\t\tstruct rt_prio_array *array = &rt_rq->active;",
            "\t\tstruct list_head *queue = array->queue + rt_se_prio(rt_se);",
            "",
            "\t\tif (head)",
            "\t\t\tlist_move(&rt_se->run_list, queue);",
            "\t\telse",
            "\t\t\tlist_move_tail(&rt_se->run_list, queue);",
            "\t}",
            "}",
            "static void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)",
            "{",
            "\tstruct sched_rt_entity *rt_se = &p->rt;",
            "\tstruct rt_rq *rt_rq;",
            "",
            "\tfor_each_sched_rt_entity(rt_se) {",
            "\t\trt_rq = rt_rq_of_se(rt_se);",
            "\t\trequeue_rt_entity(rt_rq, rt_se, head);",
            "\t}",
            "}",
            "static void yield_task_rt(struct rq *rq)",
            "{",
            "\trequeue_task_rt(rq, rq->curr, 0);",
            "}",
            "static int",
            "select_task_rq_rt(struct task_struct *p, int cpu, int flags)",
            "{",
            "\tstruct task_struct *curr;",
            "\tstruct rq *rq;",
            "\tbool test;",
            "",
            "\t/* For anything but wake ups, just return the task_cpu */",
            "\tif (!(flags & (WF_TTWU | WF_FORK)))",
            "\t\tgoto out;",
            "",
            "\trq = cpu_rq(cpu);",
            "",
            "\trcu_read_lock();",
            "\tcurr = READ_ONCE(rq->curr); /* unlocked access */",
            "",
            "\t/*",
            "\t * If the current task on @p's runqueue is an RT task, then",
            "\t * try to see if we can wake this RT task up on another",
            "\t * runqueue. Otherwise simply start this RT task",
            "\t * on its current runqueue.",
            "\t *",
            "\t * We want to avoid overloading runqueues. If the woken",
            "\t * task is a higher priority, then it will stay on this CPU",
            "\t * and the lower prio task should be moved to another CPU.",
            "\t * Even though this will probably make the lower prio task",
            "\t * lose its cache, we do not want to bounce a higher task",
            "\t * around just because it gave up its CPU, perhaps for a",
            "\t * lock?",
            "\t *",
            "\t * For equal prio tasks, we just let the scheduler sort it out.",
            "\t *",
            "\t * Otherwise, just let it ride on the affined RQ and the",
            "\t * post-schedule router will push the preempted task away",
            "\t *",
            "\t * This test is optimistic, if we get it wrong the load-balancer",
            "\t * will have to sort it out.",
            "\t *",
            "\t * We take into account the capacity of the CPU to ensure it fits the",
            "\t * requirement of the task - which is only important on heterogeneous",
            "\t * systems like big.LITTLE.",
            "\t */",
            "\ttest = curr &&",
            "\t       unlikely(rt_task(curr)) &&",
            "\t       (curr->nr_cpus_allowed < 2 || curr->prio <= p->prio);",
            "",
            "\tif (test || !rt_task_fits_capacity(p, cpu)) {",
            "\t\tint target = find_lowest_rq(p);",
            "",
            "\t\t/*",
            "\t\t * Bail out if we were forcing a migration to find a better",
            "\t\t * fitting CPU but our search failed.",
            "\t\t */",
            "\t\tif (!test && target != -1 && !rt_task_fits_capacity(p, target))",
            "\t\t\tgoto out_unlock;",
            "",
            "\t\t/*",
            "\t\t * Don't bother moving it if the destination CPU is",
            "\t\t * not running a lower priority task.",
            "\t\t */",
            "\t\tif (target != -1 &&",
            "\t\t    p->prio < cpu_rq(target)->rt.highest_prio.curr)",
            "\t\t\tcpu = target;",
            "\t}",
            "",
            "out_unlock:",
            "\trcu_read_unlock();",
            "",
            "out:",
            "\treturn cpu;",
            "}"
          ],
          "function_name": "dequeue_rt_entity, enqueue_task_rt, dequeue_task_rt, requeue_rt_entity, requeue_task_rt, yield_task_rt, select_task_rq_rt",
          "description": "实现实时任务的出队逻辑、唤醒和迁移策略，提供CPU亲和性选择及负载均衡支持，维护优先级队列的动态调整。",
          "similarity": 0.575843334197998
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/sched/rt.c",
          "start_line": 529,
          "end_line": 633,
          "content": [
            "static void sched_rt_rq_enqueue(struct rt_rq *rt_rq)",
            "{",
            "\tstruct task_struct *curr = rq_of_rt_rq(rt_rq)->curr;",
            "\tstruct rq *rq = rq_of_rt_rq(rt_rq);",
            "\tstruct sched_rt_entity *rt_se;",
            "",
            "\tint cpu = cpu_of(rq);",
            "",
            "\trt_se = rt_rq->tg->rt_se[cpu];",
            "",
            "\tif (rt_rq->rt_nr_running) {",
            "\t\tif (!rt_se)",
            "\t\t\tenqueue_top_rt_rq(rt_rq);",
            "\t\telse if (!on_rt_rq(rt_se))",
            "\t\t\tenqueue_rt_entity(rt_se, 0);",
            "",
            "\t\tif (rt_rq->highest_prio.curr < curr->prio)",
            "\t\t\tresched_curr(rq);",
            "\t}",
            "}",
            "static void sched_rt_rq_dequeue(struct rt_rq *rt_rq)",
            "{",
            "\tstruct sched_rt_entity *rt_se;",
            "\tint cpu = cpu_of(rq_of_rt_rq(rt_rq));",
            "",
            "\trt_se = rt_rq->tg->rt_se[cpu];",
            "",
            "\tif (!rt_se) {",
            "\t\tdequeue_top_rt_rq(rt_rq, rt_rq->rt_nr_running);",
            "\t\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */",
            "\t\tcpufreq_update_util(rq_of_rt_rq(rt_rq), 0);",
            "\t}",
            "\telse if (on_rt_rq(rt_se))",
            "\t\tdequeue_rt_entity(rt_se, 0);",
            "}",
            "static inline int rt_rq_throttled(struct rt_rq *rt_rq)",
            "{",
            "\treturn rt_rq->rt_throttled && !rt_rq->rt_nr_boosted;",
            "}",
            "static int rt_se_boosted(struct sched_rt_entity *rt_se)",
            "{",
            "\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);",
            "\tstruct task_struct *p;",
            "",
            "\tif (rt_rq)",
            "\t\treturn !!rt_rq->rt_nr_boosted;",
            "",
            "\tp = rt_task_of(rt_se);",
            "\treturn p->prio != p->normal_prio;",
            "}",
            "bool sched_rt_bandwidth_account(struct rt_rq *rt_rq)",
            "{",
            "\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);",
            "",
            "\treturn (hrtimer_active(&rt_b->rt_period_timer) ||",
            "\t\trt_rq->rt_time < rt_b->rt_runtime);",
            "}",
            "static void do_balance_runtime(struct rt_rq *rt_rq)",
            "{",
            "\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);",
            "\tstruct root_domain *rd = rq_of_rt_rq(rt_rq)->rd;",
            "\tint i, weight;",
            "\tu64 rt_period;",
            "",
            "\tweight = cpumask_weight(rd->span);",
            "",
            "\traw_spin_lock(&rt_b->rt_runtime_lock);",
            "\trt_period = ktime_to_ns(rt_b->rt_period);",
            "\tfor_each_cpu(i, rd->span) {",
            "\t\tstruct rt_rq *iter = sched_rt_period_rt_rq(rt_b, i);",
            "\t\ts64 diff;",
            "",
            "\t\tif (iter == rt_rq)",
            "\t\t\tcontinue;",
            "",
            "\t\traw_spin_lock(&iter->rt_runtime_lock);",
            "\t\t/*",
            "\t\t * Either all rqs have inf runtime and there's nothing to steal",
            "\t\t * or __disable_runtime() below sets a specific rq to inf to",
            "\t\t * indicate its been disabled and disallow stealing.",
            "\t\t */",
            "\t\tif (iter->rt_runtime == RUNTIME_INF)",
            "\t\t\tgoto next;",
            "",
            "\t\t/*",
            "\t\t * From runqueues with spare time, take 1/n part of their",
            "\t\t * spare time, but no more than our period.",
            "\t\t */",
            "\t\tdiff = iter->rt_runtime - iter->rt_time;",
            "\t\tif (diff > 0) {",
            "\t\t\tdiff = div_u64((u64)diff, weight);",
            "\t\t\tif (rt_rq->rt_runtime + diff > rt_period)",
            "\t\t\t\tdiff = rt_period - rt_rq->rt_runtime;",
            "\t\t\titer->rt_runtime -= diff;",
            "\t\t\trt_rq->rt_runtime += diff;",
            "\t\t\tif (rt_rq->rt_runtime == rt_period) {",
            "\t\t\t\traw_spin_unlock(&iter->rt_runtime_lock);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t}",
            "next:",
            "\t\traw_spin_unlock(&iter->rt_runtime_lock);",
            "\t}",
            "\traw_spin_unlock(&rt_b->rt_runtime_lock);",
            "}"
          ],
          "function_name": "sched_rt_rq_enqueue, sched_rt_rq_dequeue, rt_rq_throttled, rt_se_boosted, sched_rt_bandwidth_account, do_balance_runtime",
          "description": "实现实时任务队列的插入/移除逻辑，跟踪运行时间消耗，通过跨CPU运行时间平衡算法实现带宽公平分配。",
          "similarity": 0.5648015737533569
        },
        {
          "chunk_id": 16,
          "file_path": "kernel/sched/rt.c",
          "start_line": 2395,
          "end_line": 2508,
          "content": [
            "static void task_woken_rt(struct rq *rq, struct task_struct *p)",
            "{",
            "\tbool need_to_push = !task_on_cpu(rq, p) &&",
            "\t\t\t    !test_tsk_need_resched(rq->curr) &&",
            "\t\t\t    p->nr_cpus_allowed > 1 &&",
            "\t\t\t    (dl_task(rq->curr) || rt_task(rq->curr)) &&",
            "\t\t\t    (rq->curr->nr_cpus_allowed < 2 ||",
            "\t\t\t     rq->curr->prio <= p->prio);",
            "",
            "\tif (need_to_push)",
            "\t\tpush_rt_tasks(rq);",
            "}",
            "static void rq_online_rt(struct rq *rq)",
            "{",
            "\tif (rq->rt.overloaded)",
            "\t\trt_set_overload(rq);",
            "",
            "\t__enable_runtime(rq);",
            "",
            "\tcpupri_set(&rq->rd->cpupri, rq->cpu, rq->rt.highest_prio.curr);",
            "}",
            "static void rq_offline_rt(struct rq *rq)",
            "{",
            "\tif (rq->rt.overloaded)",
            "\t\trt_clear_overload(rq);",
            "",
            "\t__disable_runtime(rq);",
            "",
            "\tcpupri_set(&rq->rd->cpupri, rq->cpu, CPUPRI_INVALID);",
            "}",
            "static void switched_from_rt(struct rq *rq, struct task_struct *p)",
            "{",
            "\t/*",
            "\t * If there are other RT tasks then we will reschedule",
            "\t * and the scheduling of the other RT tasks will handle",
            "\t * the balancing. But if we are the last RT task",
            "\t * we may need to handle the pulling of RT tasks",
            "\t * now.",
            "\t */",
            "\tif (!task_on_rq_queued(p) || rq->rt.rt_nr_running)",
            "\t\treturn;",
            "",
            "\trt_queue_pull_task(rq);",
            "}",
            "void __init init_sched_rt_class(void)",
            "{",
            "\tunsigned int i;",
            "",
            "\tfor_each_possible_cpu(i) {",
            "\t\tzalloc_cpumask_var_node(&per_cpu(local_cpu_mask, i),",
            "\t\t\t\t\tGFP_KERNEL, cpu_to_node(i));",
            "\t}",
            "}",
            "static void switched_to_rt(struct rq *rq, struct task_struct *p)",
            "{",
            "\t/*",
            "\t * If we are running, update the avg_rt tracking, as the running time",
            "\t * will now on be accounted into the latter.",
            "\t */",
            "\tif (task_current(rq, p)) {",
            "\t\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 0);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/*",
            "\t * If we are not running we may need to preempt the current",
            "\t * running task. If that current running task is also an RT task",
            "\t * then see if we can move to another run queue.",
            "\t */",
            "\tif (task_on_rq_queued(p)) {",
            "#ifdef CONFIG_SMP",
            "\t\tif (p->nr_cpus_allowed > 1 && rq->rt.overloaded)",
            "\t\t\trt_queue_push_tasks(rq);",
            "#endif /* CONFIG_SMP */",
            "\t\tif (p->prio < rq->curr->prio && cpu_online(cpu_of(rq)))",
            "\t\t\tresched_curr(rq);",
            "\t}",
            "}",
            "static void",
            "prio_changed_rt(struct rq *rq, struct task_struct *p, int oldprio)",
            "{",
            "\tif (!task_on_rq_queued(p))",
            "\t\treturn;",
            "",
            "\tif (task_current(rq, p)) {",
            "#ifdef CONFIG_SMP",
            "\t\t/*",
            "\t\t * If our priority decreases while running, we",
            "\t\t * may need to pull tasks to this runqueue.",
            "\t\t */",
            "\t\tif (oldprio < p->prio)",
            "\t\t\trt_queue_pull_task(rq);",
            "",
            "\t\t/*",
            "\t\t * If there's a higher priority task waiting to run",
            "\t\t * then reschedule.",
            "\t\t */",
            "\t\tif (p->prio > rq->rt.highest_prio.curr)",
            "\t\t\tresched_curr(rq);",
            "#else",
            "\t\t/* For UP simply resched on drop of prio */",
            "\t\tif (oldprio < p->prio)",
            "\t\t\tresched_curr(rq);",
            "#endif /* CONFIG_SMP */",
            "\t} else {",
            "\t\t/*",
            "\t\t * This task is not running, but if it is",
            "\t\t * greater than the current running task",
            "\t\t * then reschedule.",
            "\t\t */",
            "\t\tif (p->prio < rq->curr->prio)",
            "\t\t\tresched_curr(rq);",
            "\t}",
            "}"
          ],
          "function_name": "task_woken_rt, rq_online_rt, rq_offline_rt, switched_from_rt, init_sched_rt_class, switched_to_rt, prio_changed_rt",
          "description": "管理实时任务调度器的相关回调函数，包括任务唤醒后是否需要推送、CPU上线/下线时的实时队列更新、任务切换时的实时调度调整及实时调度类的初始化。",
          "similarity": 0.5570695400238037
        },
        {
          "chunk_id": 13,
          "file_path": "kernel/sched/rt.c",
          "start_line": 1776,
          "end_line": 1992,
          "content": [
            "static int pick_rt_task(struct rq *rq, struct task_struct *p, int cpu)",
            "{",
            "\tif (!task_on_cpu(rq, p) &&",
            "\t    cpumask_test_cpu(cpu, &p->cpus_mask))",
            "\t\treturn 1;",
            "",
            "\treturn 0;",
            "}",
            "static int find_lowest_rq(struct task_struct *task)",
            "{",
            "\tstruct sched_domain *sd;",
            "\tstruct cpumask *lowest_mask = this_cpu_cpumask_var_ptr(local_cpu_mask);",
            "\tint this_cpu = smp_processor_id();",
            "\tint cpu      = task_cpu(task);",
            "\tint ret;",
            "",
            "\t/* Make sure the mask is initialized first */",
            "\tif (unlikely(!lowest_mask))",
            "\t\treturn -1;",
            "",
            "\tif (task->nr_cpus_allowed == 1)",
            "\t\treturn -1; /* No other targets possible */",
            "",
            "\t/*",
            "\t * If we're on asym system ensure we consider the different capacities",
            "\t * of the CPUs when searching for the lowest_mask.",
            "\t */",
            "\tif (sched_asym_cpucap_active()) {",
            "",
            "\t\tret = cpupri_find_fitness(&task_rq(task)->rd->cpupri,",
            "\t\t\t\t\t  task, lowest_mask,",
            "\t\t\t\t\t  rt_task_fits_capacity);",
            "\t} else {",
            "",
            "\t\tret = cpupri_find(&task_rq(task)->rd->cpupri,",
            "\t\t\t\t  task, lowest_mask);",
            "\t}",
            "",
            "\tif (!ret)",
            "\t\treturn -1; /* No targets found */",
            "",
            "\t/*",
            "\t * At this point we have built a mask of CPUs representing the",
            "\t * lowest priority tasks in the system.  Now we want to elect",
            "\t * the best one based on our affinity and topology.",
            "\t *",
            "\t * We prioritize the last CPU that the task executed on since",
            "\t * it is most likely cache-hot in that location.",
            "\t */",
            "\tif (cpumask_test_cpu(cpu, lowest_mask))",
            "\t\treturn cpu;",
            "",
            "\t/*",
            "\t * Otherwise, we consult the sched_domains span maps to figure",
            "\t * out which CPU is logically closest to our hot cache data.",
            "\t */",
            "\tif (!cpumask_test_cpu(this_cpu, lowest_mask))",
            "\t\tthis_cpu = -1; /* Skip this_cpu opt if not among lowest */",
            "",
            "\trcu_read_lock();",
            "\tfor_each_domain(cpu, sd) {",
            "\t\tif (sd->flags & SD_WAKE_AFFINE) {",
            "\t\t\tint best_cpu;",
            "",
            "\t\t\t/*",
            "\t\t\t * \"this_cpu\" is cheaper to preempt than a",
            "\t\t\t * remote processor.",
            "\t\t\t */",
            "\t\t\tif (this_cpu != -1 &&",
            "\t\t\t    cpumask_test_cpu(this_cpu, sched_domain_span(sd))) {",
            "\t\t\t\trcu_read_unlock();",
            "\t\t\t\treturn this_cpu;",
            "\t\t\t}",
            "",
            "\t\t\tbest_cpu = cpumask_any_and_distribute(lowest_mask,",
            "\t\t\t\t\t\t\t      sched_domain_span(sd));",
            "\t\t\tif (best_cpu < nr_cpu_ids) {",
            "\t\t\t\trcu_read_unlock();",
            "\t\t\t\treturn best_cpu;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\t/*",
            "\t * And finally, if there were no matches within the domains",
            "\t * just give the caller *something* to work with from the compatible",
            "\t * locations.",
            "\t */",
            "\tif (this_cpu != -1)",
            "\t\treturn this_cpu;",
            "",
            "\tcpu = cpumask_any_distribute(lowest_mask);",
            "\tif (cpu < nr_cpu_ids)",
            "\t\treturn cpu;",
            "",
            "\treturn -1;",
            "}",
            "static int push_rt_task(struct rq *rq, bool pull)",
            "{",
            "\tstruct task_struct *next_task;",
            "\tstruct rq *lowest_rq;",
            "\tint ret = 0;",
            "",
            "\tif (!rq->rt.overloaded)",
            "\t\treturn 0;",
            "",
            "\tnext_task = pick_next_pushable_task(rq);",
            "\tif (!next_task)",
            "\t\treturn 0;",
            "",
            "retry:",
            "\t/*",
            "\t * It's possible that the next_task slipped in of",
            "\t * higher priority than current. If that's the case",
            "\t * just reschedule current.",
            "\t */",
            "\tif (unlikely(next_task->prio < rq->curr->prio)) {",
            "\t\tresched_curr(rq);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tif (is_migration_disabled(next_task)) {",
            "\t\tstruct task_struct *push_task = NULL;",
            "\t\tint cpu;",
            "",
            "\t\tif (!pull || rq->push_busy)",
            "\t\t\treturn 0;",
            "",
            "\t\t/*",
            "\t\t * Invoking find_lowest_rq() on anything but an RT task doesn't",
            "\t\t * make sense. Per the above priority check, curr has to",
            "\t\t * be of higher priority than next_task, so no need to",
            "\t\t * reschedule when bailing out.",
            "\t\t *",
            "\t\t * Note that the stoppers are masqueraded as SCHED_FIFO",
            "\t\t * (cf. sched_set_stop_task()), so we can't rely on rt_task().",
            "\t\t */",
            "\t\tif (rq->curr->sched_class != &rt_sched_class)",
            "\t\t\treturn 0;",
            "",
            "\t\tcpu = find_lowest_rq(rq->curr);",
            "\t\tif (cpu == -1 || cpu == rq->cpu)",
            "\t\t\treturn 0;",
            "",
            "\t\t/*",
            "\t\t * Given we found a CPU with lower priority than @next_task,",
            "\t\t * therefore it should be running. However we cannot migrate it",
            "\t\t * to this other CPU, instead attempt to push the current",
            "\t\t * running task on this CPU away.",
            "\t\t */",
            "\t\tpush_task = get_push_task(rq);",
            "\t\tif (push_task) {",
            "\t\t\tpreempt_disable();",
            "\t\t\traw_spin_rq_unlock(rq);",
            "\t\t\tstop_one_cpu_nowait(rq->cpu, push_cpu_stop,",
            "\t\t\t\t\t    push_task, &rq->push_work);",
            "\t\t\tpreempt_enable();",
            "\t\t\traw_spin_rq_lock(rq);",
            "\t\t}",
            "",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tif (WARN_ON(next_task == rq->curr))",
            "\t\treturn 0;",
            "",
            "\t/* We might release rq lock */",
            "\tget_task_struct(next_task);",
            "",
            "\t/* find_lock_lowest_rq locks the rq if found */",
            "\tlowest_rq = find_lock_lowest_rq(next_task, rq);",
            "\tif (!lowest_rq) {",
            "\t\tstruct task_struct *task;",
            "\t\t/*",
            "\t\t * find_lock_lowest_rq releases rq->lock",
            "\t\t * so it is possible that next_task has migrated.",
            "\t\t *",
            "\t\t * We need to make sure that the task is still on the same",
            "\t\t * run-queue and is also still the next task eligible for",
            "\t\t * pushing.",
            "\t\t */",
            "\t\ttask = pick_next_pushable_task(rq);",
            "\t\tif (task == next_task) {",
            "\t\t\t/*",
            "\t\t\t * The task hasn't migrated, and is still the next",
            "\t\t\t * eligible task, but we failed to find a run-queue",
            "\t\t\t * to push it to.  Do not retry in this case, since",
            "\t\t\t * other CPUs will pull from us when ready.",
            "\t\t\t */",
            "\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\tif (!task)",
            "\t\t\t/* No more tasks, just exit */",
            "\t\t\tgoto out;",
            "",
            "\t\t/*",
            "\t\t * Something has shifted, try again.",
            "\t\t */",
            "\t\tput_task_struct(next_task);",
            "\t\tnext_task = task;",
            "\t\tgoto retry;",
            "\t}",
            "",
            "\tdeactivate_task(rq, next_task, 0);",
            "\tset_task_cpu(next_task, lowest_rq->cpu);",
            "\tactivate_task(lowest_rq, next_task, 0);",
            "\tresched_curr(lowest_rq);",
            "\tret = 1;",
            "",
            "\tdouble_unlock_balance(rq, lowest_rq);",
            "out:",
            "\tput_task_struct(next_task);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "pick_rt_task, find_lowest_rq, push_rt_task",
          "description": "实现实时任务选择算法、低优先级CPU搜索及强制迁移逻辑，支持异构系统下的能效优化和拓扑感知调度。",
          "similarity": 0.5549204349517822
        }
      ]
    },
    {
      "source_file": "kernel/entry/syscall_user_dispatch.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:20:47\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `entry\\syscall_user_dispatch.c`\n\n---\n\n# entry/syscall_user_dispatch.c 技术文档\n\n## 1. 文件概述\n\n`entry/syscall_user_dispatch.c` 实现了 **系统调用用户分发（Syscall User Dispatch, SUD）** 机制，该机制允许用户空间程序通过 `prctl()` 系统调用配置一个“选择器”（selector），用于在特定条件下拦截或允许系统调用的执行。当系统调用指令指针位于指定区域之外且选择器状态为“阻塞”时，内核会回滚该系统调用并向进程发送 `SIGSYS` 信号，从而实现对系统调用的细粒度控制。此功能常用于沙箱、安全监控或调试场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `trigger_sigsys(struct pt_regs *regs)`  \n  构造并强制发送 `SIGSYS` 信号，携带被拦截系统调用的详细信息（如地址、系统调用号、架构等）。\n\n- `syscall_user_dispatch(struct pt_regs *regs)`  \n  系统调用入口处的分发判断逻辑。根据当前指令指针位置和用户选择器状态决定是否拦截系统调用。\n\n- `task_set_syscall_user_dispatch(struct task_struct *task, ...)`  \n  为指定任务设置系统调用用户分发配置（开启/关闭、偏移、长度、选择器地址）。\n\n- `set_syscall_user_dispatch(...)`  \n  为当前任务设置系统调用用户分发配置的封装接口，供 `prctl()` 调用。\n\n- `syscall_user_dispatch_get_config(...)`  \n  通过 `ptrace` 获取指定任务的 SUD 配置。\n\n- `syscall_user_dispatch_set_config(...)`  \n  通过 `ptrace` 设置指定任务的 SUD 配置。\n\n### 关键数据结构\n\n- `struct syscall_user_dispatch`（定义在 `<linux/syscall_user_dispatch.h>`）  \n  存储每个任务的 SUD 配置：\n  - `selector`：指向用户空间选择器字节的指针\n  - `offset` / `len`：允许直接执行系统调用的代码区域（[offset, offset+len)）\n  - `on_dispatch`：标志位，表示当前是否处于分发拦截状态\n\n- `struct ptrace_sud_config`  \n  用于 `ptrace` 接口传递 SUD 配置的结构体，包含 `mode`、`offset`、`len` 和 `selector`。\n\n## 3. 关键实现\n\n### 系统调用拦截逻辑\n\n1. **区域检查**：若当前指令指针（`instruction_pointer(regs)`）落在 `[offset, offset + len)` 范围内，则**允许**系统调用直接执行，不进行拦截。\n2. **vdso 例外**：若系统调用来自 vDSO 中的 `sigreturn`（如 `arch_syscall_is_vdso_sigreturn()` 返回 true），则跳过拦截，避免干扰信号返回路径。\n3. **选择器读取**：若配置了 `selector`，则从用户空间读取一个字节的状态值：\n   - `SYSCALL_DISPATCH_FILTER_ALLOW`（0）：允许系统调用\n   - `SYSCALL_DISPATCH_FILTER_BLOCK`（1）：触发拦截\n   - 其他值：视为非法，发送 `SIGSYS`\n4. **拦截处理**：\n   - 设置 `on_dispatch = true`\n   - 调用 `syscall_rollback()` 回滚系统调用（恢复寄存器状态）\n   - 调用 `trigger_sigsys()` 发送 `SIGSYS` 信号\n\n### 安全与健壮性设计\n\n- **地址合法性校验**：在设置 `selector` 时使用 `access_ok(untagged_addr(selector), ...)`，确保地址可访问，并处理内存标记（如 ARM MTE）场景下调试器（tracer）与被调试进程（tracee）地址标记不一致的问题。\n- **溢出防护**：检查 `offset + len <= offset` 防止整数溢出导致无效区域。\n- **权限隔离**：`ptrace` 接口允许调试器配置其他进程的 SUD，但需具备相应权限。\n\n### 信号信息构造\n\n`trigger_sigsys()` 构造的 `siginfo_t` 包含：\n- `si_signo = SIGSYS`\n- `si_code = SYS_USER_DISPATCH`\n- `si_call_addr`：触发系统调用的用户空间地址\n- `si_syscall`：系统调用号\n- `si_arch`：系统调用架构（如 x86_64、AArch64）\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/prctl.h>`：定义 `PR_SYS_DISPATCH_*` 常量\n  - `<linux/syscall_user_dispatch.h>`：定义 `struct syscall_user_dispatch` 和相关常量\n  - `<asm/syscall.h>`：提供 `syscall_get_arch()`、`syscall_get_nr()` 等架构相关接口\n  - `\"common.h\"`：可能包含内核入口通用辅助函数\n- **内核子系统**：\n  - **调度器（sched）**：访问 `current` 任务结构\n  - **信号子系统（signal）**：发送 `SIGSYS` 信号\n  - **内存管理（uaccess）**：用户空间内存访问（`__get_user`, `access_ok`）\n  - **ptrace**：支持调试器配置 SUD\n  - **ELF**：可能用于架构识别（间接依赖）\n\n## 5. 使用场景\n\n- **沙箱环境**：限制应用只能在特定代码段发起系统调用，防止恶意代码绕过安全策略。\n- **动态二进制插桩（DBI）**：工具（如 Valgrind、Intel Pin）可拦截系统调用进行分析或重定向。\n- **安全监控**：监控程序可配置选择器为“阻塞”，在 `SIGSYS` 信号处理程序中记录或审查系统调用。\n- **调试与测试**：通过 `ptrace` 动态启用/禁用 SUD，用于测试系统调用拦截逻辑。\n- **W^X 策略增强**：结合代码段只读与 SUD，确保只有可信代码路径可发起系统调用。",
      "similarity": 0.5772855877876282,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/entry/syscall_user_dispatch.c",
          "start_line": 127,
          "end_line": 163,
          "content": [
            "int syscall_user_dispatch_get_config(struct task_struct *task, unsigned long size,",
            "\t\t\t\t     void __user *data)",
            "{",
            "\tstruct syscall_user_dispatch *sd = &task->syscall_dispatch;",
            "\tstruct ptrace_sud_config cfg;",
            "",
            "\tif (size != sizeof(cfg))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (test_task_syscall_work(task, SYSCALL_USER_DISPATCH))",
            "\t\tcfg.mode = PR_SYS_DISPATCH_ON;",
            "\telse",
            "\t\tcfg.mode = PR_SYS_DISPATCH_OFF;",
            "",
            "\tcfg.offset = sd->offset;",
            "\tcfg.len = sd->len;",
            "\tcfg.selector = (__u64)(uintptr_t)sd->selector;",
            "",
            "\tif (copy_to_user(data, &cfg, sizeof(cfg)))",
            "\t\treturn -EFAULT;",
            "",
            "\treturn 0;",
            "}",
            "int syscall_user_dispatch_set_config(struct task_struct *task, unsigned long size,",
            "\t\t\t\t     void __user *data)",
            "{",
            "\tstruct ptrace_sud_config cfg;",
            "",
            "\tif (size != sizeof(cfg))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (copy_from_user(&cfg, data, sizeof(cfg)))",
            "\t\treturn -EFAULT;",
            "",
            "\treturn task_set_syscall_user_dispatch(task, cfg.mode, cfg.offset, cfg.len,",
            "\t\t\t\t\t      (char __user *)(uintptr_t)cfg.selector);",
            "}"
          ],
          "function_name": "syscall_user_dispatch_get_config, syscall_user_dispatch_set_config",
          "description": "提供系统调用分发配置的获取与设置接口，通过用户态指针操作实现配置参数的双向传递",
          "similarity": 0.6098324060440063
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/entry/syscall_user_dispatch.c",
          "start_line": 20,
          "end_line": 122,
          "content": [
            "static void trigger_sigsys(struct pt_regs *regs)",
            "{",
            "\tstruct kernel_siginfo info;",
            "",
            "\tclear_siginfo(&info);",
            "\tinfo.si_signo = SIGSYS;",
            "\tinfo.si_code = SYS_USER_DISPATCH;",
            "\tinfo.si_call_addr = (void __user *)KSTK_EIP(current);",
            "\tinfo.si_errno = 0;",
            "\tinfo.si_arch = syscall_get_arch(current);",
            "\tinfo.si_syscall = syscall_get_nr(current, regs);",
            "",
            "\tforce_sig_info(&info);",
            "}",
            "bool syscall_user_dispatch(struct pt_regs *regs)",
            "{",
            "\tstruct syscall_user_dispatch *sd = &current->syscall_dispatch;",
            "\tchar state;",
            "",
            "\tif (likely(instruction_pointer(regs) - sd->offset < sd->len))",
            "\t\treturn false;",
            "",
            "\tif (unlikely(arch_syscall_is_vdso_sigreturn(regs)))",
            "\t\treturn false;",
            "",
            "\tif (likely(sd->selector)) {",
            "\t\t/*",
            "\t\t * access_ok() is performed once, at prctl time, when",
            "\t\t * the selector is loaded by userspace.",
            "\t\t */",
            "\t\tif (unlikely(__get_user(state, sd->selector))) {",
            "\t\t\tforce_exit_sig(SIGSEGV);",
            "\t\t\treturn true;",
            "\t\t}",
            "",
            "\t\tif (likely(state == SYSCALL_DISPATCH_FILTER_ALLOW))",
            "\t\t\treturn false;",
            "",
            "\t\tif (state != SYSCALL_DISPATCH_FILTER_BLOCK) {",
            "\t\t\tforce_exit_sig(SIGSYS);",
            "\t\t\treturn true;",
            "\t\t}",
            "\t}",
            "",
            "\tsd->on_dispatch = true;",
            "\tsyscall_rollback(current, regs);",
            "\ttrigger_sigsys(regs);",
            "",
            "\treturn true;",
            "}",
            "static int task_set_syscall_user_dispatch(struct task_struct *task, unsigned long mode,",
            "\t\t\t\t\t  unsigned long offset, unsigned long len,",
            "\t\t\t\t\t  char __user *selector)",
            "{",
            "\tswitch (mode) {",
            "\tcase PR_SYS_DISPATCH_OFF:",
            "\t\tif (offset || len || selector)",
            "\t\t\treturn -EINVAL;",
            "\t\tbreak;",
            "\tcase PR_SYS_DISPATCH_ON:",
            "\t\t/*",
            "\t\t * Validate the direct dispatcher region just for basic",
            "\t\t * sanity against overflow and a 0-sized dispatcher",
            "\t\t * region.  If the user is able to submit a syscall from",
            "\t\t * an address, that address is obviously valid.",
            "\t\t */",
            "\t\tif (offset && offset + len <= offset)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * access_ok() will clear memory tags for tagged addresses",
            "\t\t * if current has memory tagging enabled.",
            "",
            "\t\t * To enable a tracer to set a tracees selector the",
            "\t\t * selector address must be untagged for access_ok(),",
            "\t\t * otherwise an untagged tracer will always fail to set a",
            "\t\t * tagged tracees selector.",
            "\t\t */",
            "\t\tif (selector && !access_ok(untagged_addr(selector), sizeof(*selector)))",
            "\t\t\treturn -EFAULT;",
            "",
            "\t\tbreak;",
            "\tdefault:",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\ttask->syscall_dispatch.selector = selector;",
            "\ttask->syscall_dispatch.offset = offset;",
            "\ttask->syscall_dispatch.len = len;",
            "\ttask->syscall_dispatch.on_dispatch = false;",
            "",
            "\tif (mode == PR_SYS_DISPATCH_ON)",
            "\t\tset_task_syscall_work(task, SYSCALL_USER_DISPATCH);",
            "\telse",
            "\t\tclear_task_syscall_work(task, SYSCALL_USER_DISPATCH);",
            "",
            "\treturn 0;",
            "}",
            "int set_syscall_user_dispatch(unsigned long mode, unsigned long offset,",
            "\t\t\t      unsigned long len, char __user *selector)",
            "{",
            "\treturn task_set_syscall_user_dispatch(current, mode, offset, len, selector);",
            "}"
          ],
          "function_name": "trigger_sigsys, syscall_user_dispatch, task_set_syscall_user_dispatch, set_syscall_user_dispatch",
          "description": "实现系统调用用户分发核心逻辑，包含触发SIGSYS信号处理、配置验证、拦截判断及模式切换功能",
          "similarity": 0.6089670658111572
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/entry/syscall_user_dispatch.c",
          "start_line": 1,
          "end_line": 19,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 2020 Collabora Ltd.",
            " */",
            "#include <linux/sched.h>",
            "#include <linux/prctl.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/syscall_user_dispatch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/signal.h>",
            "#include <linux/elf.h>",
            "",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task_stack.h>",
            "",
            "#include <asm/syscall.h>",
            "",
            "#include \"common.h\"",
            ""
          ],
          "function_name": null,
          "description": "包含系统调用用户分发功能所需头文件及通用定义，提供架构相关接口和内核调度必要声明",
          "similarity": 0.5257165431976318
        }
      ]
    }
  ]
}