{
  "query": "buffer working principle",
  "timestamp": "2025-12-25 23:49:05",
  "retrieved_files": [
    {
      "source_file": "kernel/bpf/ringbuf.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:29:46\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\ringbuf.c`\n\n---\n\n# `bpf/ringbuf.c` 技术文档\n\n## 1. 文件概述\n\n`bpf/ringbuf.c` 实现了 BPF（Berkeley Packet Filter）子系统中的**环形缓冲区（Ring Buffer）**机制，用于在内核与用户空间之间高效、安全地传递数据。该机制支持两种生产者模式：**内核生产者**（如 BPF 程序）和**用户空间生产者**，并提供内存映射（`mmap`）、等待队列通知、并发控制等核心功能，是 BPF 数据输出（如 perf event 替代方案）的关键基础设施。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct bpf_ringbuf`**  \n  环形缓冲区的核心结构体，包含：\n  - `waitq`：等待队列，用于通知用户空间有新数据\n  - `work`：IRQ 工作项，用于异步唤醒等待队列\n  - `mask`：环形缓冲区大小掩码（`data_sz - 1`），用于快速取模\n  - `pages` / `nr_pages`：物理页数组，支持双映射\n  - `spinlock`：用于内核生产者的自旋锁（SMP 对齐）\n  - `busy`：原子变量，用于用户空间生产者的互斥访问（避免持有自旋锁过久）\n  - `consumer_pos` / `producer_pos` / `pending_pos`：消费者、生产者和待提交位置（各自独占一页，支持不同 mmap 权限）\n  - `data[]`：实际数据存储区域（页对齐）\n\n- **`struct bpf_ringbuf_map`**  \n  封装标准 `bpf_map`，关联一个 `bpf_ringbuf` 实例。\n\n- **`struct bpf_ringbuf_hdr`**  \n  8 字节记录头，包含：\n  - `len`：记录有效载荷长度\n  - `pg_off`：记录在页内的偏移（用于跨页处理）\n\n### 主要函数\n\n- **`bpf_ringbuf_area_alloc()`**  \n  分配并初始化环形缓冲区的虚拟内存区域，采用**双映射数据页**技术简化环绕处理。\n\n- **`bpf_ringbuf_alloc()`**  \n  初始化 `bpf_ringbuf` 结构体，设置锁、等待队列、IRQ 工作项及初始位置。\n\n- **`bpf_ringbuf_free()`**  \n  释放环形缓冲区占用的虚拟内存和物理页。\n\n- **`ringbuf_map_alloc()`**  \n  BPF map 分配器回调，验证参数并创建 `bpf_ringbuf_map`。\n\n- **`ringbuf_map_free()`**  \n  BPF map 释放器回调，清理资源。\n\n- **`ringbuf_map_*_elem()` / `ringbuf_map_get_next_key()`**  \n  禁用标准 map 操作（返回 `-ENOTSUPP`），因为 ringbuf 不支持键值操作。\n\n- **`bpf_ringbuf_notify()`**  \n  IRQ 工作回调，唤醒所有等待数据的用户进程。\n\n## 3. 关键实现\n\n### 双映射数据页（Double-Mapped Data Pages）\n\n为简化环形缓冲区**环绕（wrap-around）**时的数据读取逻辑，数据页被**连续映射两次**：\n```\n[meta pages][data pages][data pages (same as first copy)]\n```\n当读取跨越缓冲区末尾时，可直接线性读取第二份映射，无需特殊处理。此设计同时适用于内核和用户空间 `mmap`。\n\n### 权限隔离与安全\n\n- **`consumer_pos` 和 `producer_pos` 各占独立页**，允许通过 `mmap` 设置不同权限：\n  - **内核生产者模式**：`producer_pos` 和数据页对用户空间为**只读**，防止篡改。\n  - **用户空间生产者模式**：仅 `consumer_pos` 对用户空间为**只读**，内核需严格验证用户提交的记录。\n\n### 并发控制策略\n\n- **内核生产者**：使用 `raw_spinlock_t` 保证多生产者安全。\n- **用户空间生产者**：使用 `atomic_t busy` 原子变量，避免在 BPF 程序回调期间长期持有 IRQ 自旋锁（可能导致死锁或延迟）。若 `busy` 被占用，`__bpf_user_ringbuf_peek()` 返回 `-EBUSY`。\n\n### 内存布局与对齐\n\n- 非 `mmap` 部分（`waitq` 到 `pending_pos`）大小由 `RINGBUF_PGOFF` 定义。\n- `consumer_pos`、`producer_pos` 和 `data` 均按 `PAGE_SIZE` 对齐，确保可独立映射。\n- 总元数据页数：`RINGBUF_NR_META_PAGES = RINGBUF_PGOFF + 2`（含 consumer/producer 页）。\n\n### 大小限制\n\n- 最大记录大小：`RINGBUF_MAX_RECORD_SZ = UINT_MAX / 4`（约 1GB）。\n- 最大缓冲区大小受 `bpf_ringbuf_hdr.pg_off`（32 位页偏移）限制，理论最大约 **64GB**。\n\n## 4. 依赖关系\n\n- **BPF 子系统**：依赖 `bpf_map` 基础设施（`bpf_map_area_alloc/free`、`bpf_map_init_from_attr`）。\n- **内存管理**：使用 `alloc_pages_node`、`vmap`/`vunmap`、`__free_page` 管理物理页和虚拟映射。\n- **同步机制**：依赖 `wait_queue`、`irq_work`、`raw_spinlock` 和 `atomic_t`。\n- **BTF（BPF Type Format）**：包含 BTF 相关头文件，可能用于未来类型验证（当前未直接使用）。\n- **用户 API**：与 `uapi/linux/bpf.h` 中的 `BPF_F_NUMA_NODE` 等标志交互。\n\n## 5. 使用场景\n\n- **BPF 程序输出数据**：替代 `bpf_perf_event_output()`，提供更低开销、更高吞吐的内核到用户空间数据通道。\n- **用户空间主动提交数据**：允许用户程序通过 ringbuf 向内核提交样本（需内核验证）。\n- **实时监控与追踪**：用于 eBPF 监控工具（如 `bpftrace`、`libbpf` 应用）高效收集内核事件。\n- **NUMA 感知分配**：支持通过 `BPF_F_NUMA_NODE` 标志在指定 NUMA 节点分配内存，优化性能。",
      "similarity": 0.6134544014930725,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/ringbuf.c",
          "start_line": 1,
          "end_line": 149,
          "content": [
            "#include <linux/bpf.h>",
            "#include <linux/btf.h>",
            "#include <linux/err.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/wait.h>",
            "#include <linux/poll.h>",
            "#include <linux/kmemleak.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/btf_ids.h>",
            "",
            "#define RINGBUF_CREATE_FLAG_MASK (BPF_F_NUMA_NODE)",
            "",
            "/* non-mmap()'able part of bpf_ringbuf (everything up to consumer page) */",
            "#define RINGBUF_PGOFF \\",
            "\t(offsetof(struct bpf_ringbuf, consumer_pos) >> PAGE_SHIFT)",
            "/* consumer page and producer page */",
            "#define RINGBUF_POS_PAGES 2",
            "#define RINGBUF_NR_META_PAGES (RINGBUF_PGOFF + RINGBUF_POS_PAGES)",
            "",
            "#define RINGBUF_MAX_RECORD_SZ (UINT_MAX/4)",
            "",
            "struct bpf_ringbuf {",
            "\twait_queue_head_t waitq;",
            "\tstruct irq_work work;",
            "\tu64 mask;",
            "\tstruct page **pages;",
            "\tint nr_pages;",
            "\traw_spinlock_t spinlock ____cacheline_aligned_in_smp;",
            "\t/* For user-space producer ring buffers, an atomic_t busy bit is used",
            "\t * to synchronize access to the ring buffers in the kernel, rather than",
            "\t * the spinlock that is used for kernel-producer ring buffers. This is",
            "\t * done because the ring buffer must hold a lock across a BPF program's",
            "\t * callback:",
            "\t *",
            "\t *    __bpf_user_ringbuf_peek() // lock acquired",
            "\t * -> program callback_fn()",
            "\t * -> __bpf_user_ringbuf_sample_release() // lock released",
            "\t *",
            "\t * It is unsafe and incorrect to hold an IRQ spinlock across what could",
            "\t * be a long execution window, so we instead simply disallow concurrent",
            "\t * access to the ring buffer by kernel consumers, and return -EBUSY from",
            "\t * __bpf_user_ringbuf_peek() if the busy bit is held by another task.",
            "\t */",
            "\tatomic_t busy ____cacheline_aligned_in_smp;",
            "\t/* Consumer and producer counters are put into separate pages to",
            "\t * allow each position to be mapped with different permissions.",
            "\t * This prevents a user-space application from modifying the",
            "\t * position and ruining in-kernel tracking. The permissions of the",
            "\t * pages depend on who is producing samples: user-space or the",
            "\t * kernel. Note that the pending counter is placed in the same",
            "\t * page as the producer, so that it shares the same cache line.",
            "\t *",
            "\t * Kernel-producer",
            "\t * ---------------",
            "\t * The producer position and data pages are mapped as r/o in",
            "\t * userspace. For this approach, bits in the header of samples are",
            "\t * used to signal to user-space, and to other producers, whether a",
            "\t * sample is currently being written.",
            "\t *",
            "\t * User-space producer",
            "\t * -------------------",
            "\t * Only the page containing the consumer position is mapped r/o in",
            "\t * user-space. User-space producers also use bits of the header to",
            "\t * communicate to the kernel, but the kernel must carefully check and",
            "\t * validate each sample to ensure that they're correctly formatted, and",
            "\t * fully contained within the ring buffer.",
            "\t */",
            "\tunsigned long consumer_pos __aligned(PAGE_SIZE);",
            "\tunsigned long producer_pos __aligned(PAGE_SIZE);",
            "\tunsigned long pending_pos;",
            "\tchar data[] __aligned(PAGE_SIZE);",
            "};",
            "",
            "struct bpf_ringbuf_map {",
            "\tstruct bpf_map map;",
            "\tstruct bpf_ringbuf *rb;",
            "};",
            "",
            "/* 8-byte ring buffer record header structure */",
            "struct bpf_ringbuf_hdr {",
            "\tu32 len;",
            "\tu32 pg_off;",
            "};",
            "",
            "static struct bpf_ringbuf *bpf_ringbuf_area_alloc(size_t data_sz, int numa_node)",
            "{",
            "\tconst gfp_t flags = GFP_KERNEL_ACCOUNT | __GFP_RETRY_MAYFAIL |",
            "\t\t\t    __GFP_NOWARN | __GFP_ZERO;",
            "\tint nr_meta_pages = RINGBUF_NR_META_PAGES;",
            "\tint nr_data_pages = data_sz >> PAGE_SHIFT;",
            "\tint nr_pages = nr_meta_pages + nr_data_pages;",
            "\tstruct page **pages, *page;",
            "\tstruct bpf_ringbuf *rb;",
            "\tsize_t array_size;",
            "\tint i;",
            "",
            "\t/* Each data page is mapped twice to allow \"virtual\"",
            "\t * continuous read of samples wrapping around the end of ring",
            "\t * buffer area:",
            "\t * ------------------------------------------------------",
            "\t * | meta pages |  real data pages  |  same data pages  |",
            "\t * ------------------------------------------------------",
            "\t * |            | 1 2 3 4 5 6 7 8 9 | 1 2 3 4 5 6 7 8 9 |",
            "\t * ------------------------------------------------------",
            "\t * |            | TA             DA | TA             DA |",
            "\t * ------------------------------------------------------",
            "\t *                               ^^^^^^^",
            "\t *                                  |",
            "\t * Here, no need to worry about special handling of wrapped-around",
            "\t * data due to double-mapped data pages. This works both in kernel and",
            "\t * when mmap()'ed in user-space, simplifying both kernel and",
            "\t * user-space implementations significantly.",
            "\t */",
            "\tarray_size = (nr_meta_pages + 2 * nr_data_pages) * sizeof(*pages);",
            "\tpages = bpf_map_area_alloc(array_size, numa_node);",
            "\tif (!pages)",
            "\t\treturn NULL;",
            "",
            "\tfor (i = 0; i < nr_pages; i++) {",
            "\t\tpage = alloc_pages_node(numa_node, flags, 0);",
            "\t\tif (!page) {",
            "\t\t\tnr_pages = i;",
            "\t\t\tgoto err_free_pages;",
            "\t\t}",
            "\t\tpages[i] = page;",
            "\t\tif (i >= nr_meta_pages)",
            "\t\t\tpages[nr_data_pages + i] = page;",
            "\t}",
            "",
            "\trb = vmap(pages, nr_meta_pages + 2 * nr_data_pages,",
            "\t\t  VM_MAP | VM_USERMAP, PAGE_KERNEL);",
            "\tif (rb) {",
            "\t\tkmemleak_not_leak(pages);",
            "\t\trb->pages = pages;",
            "\t\trb->nr_pages = nr_pages;",
            "\t\treturn rb;",
            "\t}",
            "",
            "err_free_pages:",
            "\tfor (i = 0; i < nr_pages; i++)",
            "\t\t__free_page(pages[i]);",
            "\tbpf_map_area_free(pages);",
            "\treturn NULL;",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义了bpf_ringbuf结构体及其相关宏，用于管理BPF环形缓冲区的元数据和数据区域。通过页面数组实现环形缓冲区的虚拟连续读取，支持用户态和内核态生产者的差异化权限控制，其中包含消费者/生产者位置指针、忙位原子变量及锁保护的元数据。",
          "similarity": 0.542289674282074
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/bpf/ringbuf.c",
          "start_line": 335,
          "end_line": 447,
          "content": [
            "static u64 ringbuf_map_mem_usage(const struct bpf_map *map)",
            "{",
            "\tstruct bpf_ringbuf *rb;",
            "\tint nr_data_pages;",
            "\tint nr_meta_pages;",
            "\tu64 usage = sizeof(struct bpf_ringbuf_map);",
            "",
            "\trb = container_of(map, struct bpf_ringbuf_map, map)->rb;",
            "\tusage += (u64)rb->nr_pages << PAGE_SHIFT;",
            "\tnr_meta_pages = RINGBUF_NR_META_PAGES;",
            "\tnr_data_pages = map->max_entries >> PAGE_SHIFT;",
            "\tusage += (nr_meta_pages + 2 * nr_data_pages) * sizeof(struct page *);",
            "\treturn usage;",
            "}",
            "static size_t bpf_ringbuf_rec_pg_off(struct bpf_ringbuf *rb,",
            "\t\t\t\t     struct bpf_ringbuf_hdr *hdr)",
            "{",
            "\treturn ((void *)hdr - (void *)rb) >> PAGE_SHIFT;",
            "}",
            "static void bpf_ringbuf_commit(void *sample, u64 flags, bool discard)",
            "{",
            "\tunsigned long rec_pos, cons_pos;",
            "\tstruct bpf_ringbuf_hdr *hdr;",
            "\tstruct bpf_ringbuf *rb;",
            "\tu32 new_len;",
            "",
            "\thdr = sample - BPF_RINGBUF_HDR_SZ;",
            "\trb = bpf_ringbuf_restore_from_rec(hdr);",
            "\tnew_len = hdr->len ^ BPF_RINGBUF_BUSY_BIT;",
            "\tif (discard)",
            "\t\tnew_len |= BPF_RINGBUF_DISCARD_BIT;",
            "",
            "\t/* update record header with correct final size prefix */",
            "\txchg(&hdr->len, new_len);",
            "",
            "\t/* if consumer caught up and is waiting for our record, notify about",
            "\t * new data availability",
            "\t */",
            "\trec_pos = (void *)hdr - (void *)rb->data;",
            "\tcons_pos = smp_load_acquire(&rb->consumer_pos) & rb->mask;",
            "",
            "\tif (flags & BPF_RB_FORCE_WAKEUP)",
            "\t\tirq_work_queue(&rb->work);",
            "\telse if (cons_pos == rec_pos && !(flags & BPF_RB_NO_WAKEUP))",
            "\t\tirq_work_queue(&rb->work);",
            "}",
            "static int __bpf_user_ringbuf_peek(struct bpf_ringbuf *rb, void **sample, u32 *size)",
            "{",
            "\tint err;",
            "\tu32 hdr_len, sample_len, total_len, flags, *hdr;",
            "\tu64 cons_pos, prod_pos;",
            "",
            "\t/* Synchronizes with smp_store_release() in user-space producer. */",
            "\tprod_pos = smp_load_acquire(&rb->producer_pos);",
            "\tif (prod_pos % 8)",
            "\t\treturn -EINVAL;",
            "",
            "\t/* Synchronizes with smp_store_release() in __bpf_user_ringbuf_sample_release() */",
            "\tcons_pos = smp_load_acquire(&rb->consumer_pos);",
            "\tif (cons_pos >= prod_pos)",
            "\t\treturn -ENODATA;",
            "",
            "\thdr = (u32 *)((uintptr_t)rb->data + (uintptr_t)(cons_pos & rb->mask));",
            "\t/* Synchronizes with smp_store_release() in user-space producer. */",
            "\thdr_len = smp_load_acquire(hdr);",
            "\tflags = hdr_len & (BPF_RINGBUF_BUSY_BIT | BPF_RINGBUF_DISCARD_BIT);",
            "\tsample_len = hdr_len & ~flags;",
            "\ttotal_len = round_up(sample_len + BPF_RINGBUF_HDR_SZ, 8);",
            "",
            "\t/* The sample must fit within the region advertised by the producer position. */",
            "\tif (total_len > prod_pos - cons_pos)",
            "\t\treturn -EINVAL;",
            "",
            "\t/* The sample must fit within the data region of the ring buffer. */",
            "\tif (total_len > ringbuf_total_data_sz(rb))",
            "\t\treturn -E2BIG;",
            "",
            "\t/* The sample must fit into a struct bpf_dynptr. */",
            "\terr = bpf_dynptr_check_size(sample_len);",
            "\tif (err)",
            "\t\treturn -E2BIG;",
            "",
            "\tif (flags & BPF_RINGBUF_DISCARD_BIT) {",
            "\t\t/* If the discard bit is set, the sample should be skipped.",
            "\t\t *",
            "\t\t * Update the consumer pos, and return -EAGAIN so the caller",
            "\t\t * knows to skip this sample and try to read the next one.",
            "\t\t */",
            "\t\tsmp_store_release(&rb->consumer_pos, cons_pos + total_len);",
            "\t\treturn -EAGAIN;",
            "\t}",
            "",
            "\tif (flags & BPF_RINGBUF_BUSY_BIT)",
            "\t\treturn -ENODATA;",
            "",
            "\t*sample = (void *)((uintptr_t)rb->data +",
            "\t\t\t   (uintptr_t)((cons_pos + BPF_RINGBUF_HDR_SZ) & rb->mask));",
            "\t*size = sample_len;",
            "\treturn 0;",
            "}",
            "static void __bpf_user_ringbuf_sample_release(struct bpf_ringbuf *rb, size_t size, u64 flags)",
            "{",
            "\tu64 consumer_pos;",
            "\tu32 rounded_size = round_up(size + BPF_RINGBUF_HDR_SZ, 8);",
            "",
            "\t/* Using smp_load_acquire() is unnecessary here, as the busy-bit",
            "\t * prevents another task from writing to consumer_pos after it was read",
            "\t * by this task with smp_load_acquire() in __bpf_user_ringbuf_peek().",
            "\t */",
            "\tconsumer_pos = rb->consumer_pos;",
            "\t /* Synchronizes with smp_load_acquire() in user-space producer. */",
            "\tsmp_store_release(&rb->consumer_pos, consumer_pos + rounded_size);",
            "}"
          ],
          "function_name": "ringbuf_map_mem_usage, bpf_ringbuf_rec_pg_off, bpf_ringbuf_commit, __bpf_user_ringbuf_peek, __bpf_user_ringbuf_sample_release",
          "description": "提供了环形缓冲区的内存占用统计、记录位置转换、样本提交及消费操作。包含用户态生产者与消费者的同步机制，通过忙位防止竞态条件，确保样本数据完整性校验和消费进度更新的有序性。",
          "similarity": 0.4615103006362915
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/bpf/ringbuf.c",
          "start_line": 150,
          "end_line": 258,
          "content": [
            "static void bpf_ringbuf_notify(struct irq_work *work)",
            "{",
            "\tstruct bpf_ringbuf *rb = container_of(work, struct bpf_ringbuf, work);",
            "",
            "\twake_up_all(&rb->waitq);",
            "}",
            "static void bpf_ringbuf_free(struct bpf_ringbuf *rb)",
            "{",
            "\t/* copy pages pointer and nr_pages to local variable, as we are going",
            "\t * to unmap rb itself with vunmap() below",
            "\t */",
            "\tstruct page **pages = rb->pages;",
            "\tint i, nr_pages = rb->nr_pages;",
            "",
            "\tvunmap(rb);",
            "\tfor (i = 0; i < nr_pages; i++)",
            "\t\t__free_page(pages[i]);",
            "\tbpf_map_area_free(pages);",
            "}",
            "static void ringbuf_map_free(struct bpf_map *map)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "\tbpf_ringbuf_free(rb_map->rb);",
            "\tbpf_map_area_free(rb_map);",
            "}",
            "static long ringbuf_map_update_elem(struct bpf_map *map, void *key, void *value,",
            "\t\t\t\t    u64 flags)",
            "{",
            "\treturn -ENOTSUPP;",
            "}",
            "static long ringbuf_map_delete_elem(struct bpf_map *map, void *key)",
            "{",
            "\treturn -ENOTSUPP;",
            "}",
            "static int ringbuf_map_get_next_key(struct bpf_map *map, void *key,",
            "\t\t\t\t    void *next_key)",
            "{",
            "\treturn -ENOTSUPP;",
            "}",
            "static int ringbuf_map_mmap_kern(struct bpf_map *map, struct vm_area_struct *vma)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "",
            "\tif (vma->vm_flags & VM_WRITE) {",
            "\t\t/* allow writable mapping for the consumer_pos only */",
            "\t\tif (vma->vm_pgoff != 0 || vma->vm_end - vma->vm_start != PAGE_SIZE)",
            "\t\t\treturn -EPERM;",
            "\t}",
            "\t/* remap_vmalloc_range() checks size and offset constraints */",
            "\treturn remap_vmalloc_range(vma, rb_map->rb,",
            "\t\t\t\t   vma->vm_pgoff + RINGBUF_PGOFF);",
            "}",
            "static int ringbuf_map_mmap_user(struct bpf_map *map, struct vm_area_struct *vma)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "",
            "\tif (vma->vm_flags & VM_WRITE) {",
            "\t\tif (vma->vm_pgoff == 0)",
            "\t\t\t/* Disallow writable mappings to the consumer pointer,",
            "\t\t\t * and allow writable mappings to both the producer",
            "\t\t\t * position, and the ring buffer data itself.",
            "\t\t\t */",
            "\t\t\treturn -EPERM;",
            "\t}",
            "\t/* remap_vmalloc_range() checks size and offset constraints */",
            "\treturn remap_vmalloc_range(vma, rb_map->rb, vma->vm_pgoff + RINGBUF_PGOFF);",
            "}",
            "static unsigned long ringbuf_avail_data_sz(struct bpf_ringbuf *rb)",
            "{",
            "\tunsigned long cons_pos, prod_pos;",
            "",
            "\tcons_pos = smp_load_acquire(&rb->consumer_pos);",
            "\tprod_pos = smp_load_acquire(&rb->producer_pos);",
            "\treturn prod_pos - cons_pos;",
            "}",
            "static u32 ringbuf_total_data_sz(const struct bpf_ringbuf *rb)",
            "{",
            "\treturn rb->mask + 1;",
            "}",
            "static __poll_t ringbuf_map_poll_kern(struct bpf_map *map, struct file *filp,",
            "\t\t\t\t      struct poll_table_struct *pts)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "\tpoll_wait(filp, &rb_map->rb->waitq, pts);",
            "",
            "\tif (ringbuf_avail_data_sz(rb_map->rb))",
            "\t\treturn EPOLLIN | EPOLLRDNORM;",
            "\treturn 0;",
            "}",
            "static __poll_t ringbuf_map_poll_user(struct bpf_map *map, struct file *filp,",
            "\t\t\t\t      struct poll_table_struct *pts)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "\tpoll_wait(filp, &rb_map->rb->waitq, pts);",
            "",
            "\tif (ringbuf_avail_data_sz(rb_map->rb) < ringbuf_total_data_sz(rb_map->rb))",
            "\t\treturn EPOLLOUT | EPOLLWRNORM;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "bpf_ringbuf_notify, bpf_ringbuf_free, ringbuf_map_free, ringbuf_map_update_elem, ringbuf_map_delete_elem, ringbuf_map_get_next_key, ringbuf_map_mmap_kern, ringbuf_map_mmap_user, ringbuf_avail_data_sz, ringbuf_total_data_sz, ringbuf_map_poll_kern, ringbuf_map_poll_user",
          "description": "实现了环形缓冲区的事件通知、资源释放、内存映射控制及I/O监控功能。包含针对用户态和内核态的差异化mmap处理逻辑，通过spinlock和atomic_t实现并发控制，提供poll接口检测缓冲区可用数据状态。",
          "similarity": 0.44299525022506714
        }
      ]
    },
    {
      "source_file": "kernel/bpf/bpf_local_storage.c",
      "md_summary": "> 自动生成时间: 2025-10-25 11:58:54\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\bpf_local_storage.c`\n\n---\n\n# bpf_local_storage.c 技术文档\n\n## 文件概述\n\n`bpf_local_storage.c` 实现了 BPF（Berkeley Packet Filter）本地存储（local storage）机制的核心功能。该机制允许 BPF 程序为内核对象（如 socket、task 等）动态关联私有数据，实现高效、安全的 per-object 存储管理。文件提供了存储元素（`bpf_local_storage_elem`）和存储容器（`bpf_local_storage`）的分配、释放、链接管理以及内存回收机制，并支持与 BPF 内存分配器（`bpf_mem_alloc`）集成以提升性能。\n\n## 核心功能\n\n### 主要数据结构\n- `struct bpf_local_storage_elem`：BPF 本地存储元素，包含指向 map、owner 和实际数据的指针\n- `struct bpf_local_storage`：BPF 本地存储容器，用于管理特定 owner 的所有存储元素\n- `struct bpf_local_storage_map`：扩展的 BPF map 类型，用于管理本地存储\n\n### 主要函数\n- `bpf_selem_alloc()`：分配并初始化 BPF 本地存储元素\n- `bpf_selem_free()`：释放 BPF 本地存储元素\n- `bpf_local_storage_free()`：释放 BPF 本地存储容器\n- `select_bucket()`：根据存储元素选择哈希桶\n- `mem_charge()` / `mem_uncharge()`：内存资源计费/释放\n- `owner_storage()`：获取 owner 对象的存储指针\n- `selem_linked_to_*()`：检查存储元素的链接状态\n\n## 关键实现\n\n### 内存管理策略\n- 支持两种内存分配模式：传统 `bpf_map_kzalloc` 和高性能 `bpf_mem_cache_alloc`\n- 通过 `smap->bpf_ma` 标志区分是否使用 BPF 内存分配器\n- 实现了精细的内存计费机制，通过 `map_local_storage_charge/uncharge` 回调\n\n### RCU 安全回收机制\n- 针对不同场景实现多种 RCU 回收策略：\n  - 普通 RCU (`call_rcu`)\n  - RCU Tasks Trace (`call_rcu_tasks_trace`)\n  - 直接释放（`reuse_now` 模式）\n- 根据 `rcu_trace_implies_rcu_gp()` 动态选择合适的释放方式\n- 支持立即重用模式（`reuse_now`），在对象销毁时直接回收内存\n\n### 存储元素管理\n- 使用哈希表组织存储元素，通过 `hash_ptr()` 计算桶位置\n- 通过 `hlist_unhashed()` 检查元素是否已链接到存储结构\n- 实现了安全的双向链接管理（map 链和 storage 链）\n\n### 对象生命周期管理\n- 在分配时支持值初始化和 uptr 交换\n- 释放时正确处理 BPF 对象字段的清理（`bpf_obj_free_fields`）\n- 支持克隆操作（通过 `BPF_F_CLONE` 标志）\n\n## 依赖关系\n\n### 内核头文件依赖\n- **RCU 相关**：`<linux/rculist.h>`, `<linux/rcupdate.h>`, `<linux/rcupdate_trace.h>`\n- **数据结构**：`<linux/list.h>`, `<linux/hash.h>`, `<linux/spinlock.h>`\n- **BPF 核心**：`<linux/bpf.h>`, `<linux/bpf_local_storage.h>`, `<linux/btf_ids.h>`\n- **网络子系统**：`<net/sock.h>`, `<uapi/linux/sock_diag.h>`\n- **内存管理**：`<linux/bpf_mem_alloc.h>`（隐式通过 bpf_mem_cache_* 函数）\n\n### 功能依赖\n- 依赖 BPF map 操作接口（`map->ops->map_owner_storage_ptr` 等）\n- 依赖 BPF 内存分配器（`bpf_mem_cache_*` 系列函数）\n- 依赖 BPF 对象引用管理（`bpf_obj_free_fields`, `bpf_obj_swap_uptrs`）\n\n## 使用场景\n\n### BPF 程序数据存储\n- BPF 程序需要为特定内核对象（如 socket、task）维护私有状态信息\n- 通过 `bpf_sk_storage_get()` 等 helper 函数访问本地存储\n\n### 网络监控和跟踪\n- Socket 本地存储用于网络连接的 per-socket 状态跟踪\n- Task 本地存储用于进程级别的监控和策略实施\n\n### 性能关键路径\n- 在高性能网络数据路径中，通过预分配和内存池减少分配开销\n- 利用 RCU Tasks Trace 实现低延迟的内存回收\n\n### 资源隔离和计费\n- 为不同 BPF map 实例提供独立的内存计费\n- 防止恶意 BPF 程序耗尽系统内存资源\n\n### 对象生命周期集成\n- 与内核对象（socket、task）的销毁流程紧密集成\n- 确保在对象销毁时正确清理关联的 BPF 存储数据",
      "similarity": 0.5924427509307861,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/bpf_local_storage.c",
          "start_line": 1,
          "end_line": 26,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/* Copyright (c) 2019 Facebook  */",
            "#include <linux/rculist.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/types.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/bpf.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/bpf_local_storage.h>",
            "#include <net/sock.h>",
            "#include <uapi/linux/sock_diag.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/rcupdate_wait.h>",
            "",
            "#define BPF_LOCAL_STORAGE_CREATE_FLAG_MASK (BPF_F_NO_PREALLOC | BPF_F_CLONE)",
            "",
            "static struct bpf_local_storage_map_bucket *",
            "select_bucket(struct bpf_local_storage_map *smap,",
            "\t      struct bpf_local_storage_elem *selem)",
            "{",
            "\treturn &smap->buckets[hash_ptr(selem, smap->bucket_log)];",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义BPF本地存储相关头文件和宏，提供`select_bucket`函数用于根据元素哈希值选择对应的桶结构。",
          "similarity": 0.5717089772224426
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/bpf/bpf_local_storage.c",
          "start_line": 730,
          "end_line": 892,
          "content": [
            "static void bpf_local_storage_cache_idx_free(struct bpf_local_storage_cache *cache,",
            "\t\t\t\t\t     u16 idx)",
            "{",
            "\tspin_lock(&cache->idx_lock);",
            "\tcache->idx_usage_counts[idx]--;",
            "\tspin_unlock(&cache->idx_lock);",
            "}",
            "int bpf_local_storage_map_alloc_check(union bpf_attr *attr)",
            "{",
            "\tif (attr->map_flags & ~BPF_LOCAL_STORAGE_CREATE_FLAG_MASK ||",
            "\t    !(attr->map_flags & BPF_F_NO_PREALLOC) ||",
            "\t    attr->max_entries ||",
            "\t    attr->key_size != sizeof(int) || !attr->value_size ||",
            "\t    /* Enforce BTF for userspace sk dumping */",
            "\t    !attr->btf_key_type_id || !attr->btf_value_type_id)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (attr->value_size > BPF_LOCAL_STORAGE_MAX_VALUE_SIZE)",
            "\t\treturn -E2BIG;",
            "",
            "\treturn 0;",
            "}",
            "int bpf_local_storage_map_check_btf(const struct bpf_map *map,",
            "\t\t\t\t    const struct btf *btf,",
            "\t\t\t\t    const struct btf_type *key_type,",
            "\t\t\t\t    const struct btf_type *value_type)",
            "{",
            "\tu32 int_data;",
            "",
            "\tif (BTF_INFO_KIND(key_type->info) != BTF_KIND_INT)",
            "\t\treturn -EINVAL;",
            "",
            "\tint_data = *(u32 *)(key_type + 1);",
            "\tif (BTF_INT_BITS(int_data) != 32 || BTF_INT_OFFSET(int_data))",
            "\t\treturn -EINVAL;",
            "",
            "\treturn 0;",
            "}",
            "void bpf_local_storage_destroy(struct bpf_local_storage *local_storage)",
            "{",
            "\tstruct bpf_local_storage_map *storage_smap;",
            "\tstruct bpf_local_storage_elem *selem;",
            "\tbool bpf_ma, free_storage = false;",
            "\tHLIST_HEAD(free_selem_list);",
            "\tstruct hlist_node *n;",
            "\tunsigned long flags;",
            "",
            "\tstorage_smap = rcu_dereference_check(local_storage->smap, bpf_rcu_lock_held());",
            "\tbpf_ma = check_storage_bpf_ma(local_storage, storage_smap, NULL);",
            "",
            "\t/* Neither the bpf_prog nor the bpf_map's syscall",
            "\t * could be modifying the local_storage->list now.",
            "\t * Thus, no elem can be added to or deleted from the",
            "\t * local_storage->list by the bpf_prog or by the bpf_map's syscall.",
            "\t *",
            "\t * It is racing with bpf_local_storage_map_free() alone",
            "\t * when unlinking elem from the local_storage->list and",
            "\t * the map's bucket->list.",
            "\t */",
            "\traw_spin_lock_irqsave(&local_storage->lock, flags);",
            "\thlist_for_each_entry_safe(selem, n, &local_storage->list, snode) {",
            "\t\t/* Always unlink from map before unlinking from",
            "\t\t * local_storage.",
            "\t\t */",
            "\t\tbpf_selem_unlink_map(selem);",
            "\t\t/* If local_storage list has only one element, the",
            "\t\t * bpf_selem_unlink_storage_nolock() will return true.",
            "\t\t * Otherwise, it will return false. The current loop iteration",
            "\t\t * intends to remove all local storage. So the last iteration",
            "\t\t * of the loop will set the free_cgroup_storage to true.",
            "\t\t */",
            "\t\tfree_storage = bpf_selem_unlink_storage_nolock(",
            "\t\t\tlocal_storage, selem, true, &free_selem_list);",
            "\t}",
            "\traw_spin_unlock_irqrestore(&local_storage->lock, flags);",
            "",
            "\tbpf_selem_free_list(&free_selem_list, true);",
            "",
            "\tif (free_storage)",
            "\t\tbpf_local_storage_free(local_storage, storage_smap, bpf_ma, true);",
            "}",
            "u64 bpf_local_storage_map_mem_usage(const struct bpf_map *map)",
            "{",
            "\tstruct bpf_local_storage_map *smap = (struct bpf_local_storage_map *)map;",
            "\tu64 usage = sizeof(*smap);",
            "",
            "\t/* The dynamically callocated selems are not counted currently. */",
            "\tusage += sizeof(*smap->buckets) * (1ULL << smap->bucket_log);",
            "\treturn usage;",
            "}",
            "void bpf_local_storage_map_free(struct bpf_map *map,",
            "\t\t\t\tstruct bpf_local_storage_cache *cache,",
            "\t\t\t\tint __percpu *busy_counter)",
            "{",
            "\tstruct bpf_local_storage_map_bucket *b;",
            "\tstruct bpf_local_storage_elem *selem;",
            "\tstruct bpf_local_storage_map *smap;",
            "\tunsigned int i;",
            "",
            "\tsmap = (struct bpf_local_storage_map *)map;",
            "\tbpf_local_storage_cache_idx_free(cache, smap->cache_idx);",
            "",
            "\t/* Note that this map might be concurrently cloned from",
            "\t * bpf_sk_storage_clone. Wait for any existing bpf_sk_storage_clone",
            "\t * RCU read section to finish before proceeding. New RCU",
            "\t * read sections should be prevented via bpf_map_inc_not_zero.",
            "\t */",
            "\tsynchronize_rcu();",
            "",
            "\t/* bpf prog and the userspace can no longer access this map",
            "\t * now.  No new selem (of this map) can be added",
            "\t * to the owner->storage or to the map bucket's list.",
            "\t *",
            "\t * The elem of this map can be cleaned up here",
            "\t * or when the storage is freed e.g.",
            "\t * by bpf_sk_storage_free() during __sk_destruct().",
            "\t */",
            "\tfor (i = 0; i < (1U << smap->bucket_log); i++) {",
            "\t\tb = &smap->buckets[i];",
            "",
            "\t\trcu_read_lock();",
            "\t\t/* No one is adding to b->list now */",
            "\t\twhile ((selem = hlist_entry_safe(",
            "\t\t\t\trcu_dereference_raw(hlist_first_rcu(&b->list)),",
            "\t\t\t\tstruct bpf_local_storage_elem, map_node))) {",
            "\t\t\tif (busy_counter) {",
            "\t\t\t\tmigrate_disable();",
            "\t\t\t\tthis_cpu_inc(*busy_counter);",
            "\t\t\t}",
            "\t\t\tbpf_selem_unlink(selem, true);",
            "\t\t\tif (busy_counter) {",
            "\t\t\t\tthis_cpu_dec(*busy_counter);",
            "\t\t\t\tmigrate_enable();",
            "\t\t\t}",
            "\t\t\tcond_resched_rcu();",
            "\t\t}",
            "\t\trcu_read_unlock();",
            "\t}",
            "",
            "\t/* While freeing the storage we may still need to access the map.",
            "\t *",
            "\t * e.g. when bpf_sk_storage_free() has unlinked selem from the map",
            "\t * which then made the above while((selem = ...)) loop",
            "\t * exit immediately.",
            "\t *",
            "\t * However, while freeing the storage one still needs to access the",
            "\t * smap->elem_size to do the uncharging in",
            "\t * bpf_selem_unlink_storage_nolock().",
            "\t *",
            "\t * Hence, wait another rcu grace period for the storage to be freed.",
            "\t */",
            "\tsynchronize_rcu();",
            "",
            "\tif (smap->bpf_ma) {",
            "\t\trcu_barrier_tasks_trace();",
            "\t\tif (!rcu_trace_implies_rcu_gp())",
            "\t\t\trcu_barrier();",
            "\t\tbpf_mem_alloc_destroy(&smap->selem_ma);",
            "\t\tbpf_mem_alloc_destroy(&smap->storage_ma);",
            "\t}",
            "\tkvfree(smap->buckets);",
            "\tbpf_map_area_free(smap);",
            "}"
          ],
          "function_name": "bpf_local_storage_cache_idx_free, bpf_local_storage_map_alloc_check, bpf_local_storage_map_check_btf, bpf_local_storage_destroy, bpf_local_storage_map_mem_usage, bpf_local_storage_map_free",
          "description": "该代码块实现BPF本地存储模块的内存管理和资源释放逻辑，核心功能包含参数校验、BTF类型验证、元素清理及内存统计。  \n`bpf_local_storage_map_alloc_check` 和 `bpf_local_storage_map_check_btf` 分别用于验证创建参数合法性及BTF类型约束，而 `bpf_local_storage_destroy` 通过RCU机制安全遍历并销毁存储元素。  \n部分函数依赖未展示的辅助函数（如 `bpf_selem_unlink_map`），且涉及复杂RCU同步策略，上下文存在一定缺失。",
          "similarity": 0.500888466835022
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/bpf/bpf_local_storage.c",
          "start_line": 499,
          "end_line": 605,
          "content": [
            "static int check_flags(const struct bpf_local_storage_data *old_sdata,",
            "\t\t       u64 map_flags)",
            "{",
            "\tif (old_sdata && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)",
            "\t\t/* elem already exists */",
            "\t\treturn -EEXIST;",
            "",
            "\tif (!old_sdata && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)",
            "\t\t/* elem doesn't exist, cannot update it */",
            "\t\treturn -ENOENT;",
            "",
            "\treturn 0;",
            "}",
            "int bpf_local_storage_alloc(void *owner,",
            "\t\t\t    struct bpf_local_storage_map *smap,",
            "\t\t\t    struct bpf_local_storage_elem *first_selem,",
            "\t\t\t    gfp_t gfp_flags)",
            "{",
            "\tstruct bpf_local_storage *prev_storage, *storage;",
            "\tstruct bpf_local_storage **owner_storage_ptr;",
            "\tint err;",
            "",
            "\terr = mem_charge(smap, owner, sizeof(*storage));",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tif (smap->bpf_ma) {",
            "\t\tmigrate_disable();",
            "\t\tstorage = bpf_mem_cache_alloc_flags(&smap->storage_ma, gfp_flags);",
            "\t\tmigrate_enable();",
            "\t} else {",
            "\t\tstorage = bpf_map_kzalloc(&smap->map, sizeof(*storage),",
            "\t\t\t\t\t  gfp_flags | __GFP_NOWARN);",
            "\t}",
            "",
            "\tif (!storage) {",
            "\t\terr = -ENOMEM;",
            "\t\tgoto uncharge;",
            "\t}",
            "",
            "\tRCU_INIT_POINTER(storage->smap, smap);",
            "\tINIT_HLIST_HEAD(&storage->list);",
            "\traw_spin_lock_init(&storage->lock);",
            "\tstorage->owner = owner;",
            "",
            "\tbpf_selem_link_storage_nolock(storage, first_selem);",
            "\tbpf_selem_link_map(smap, first_selem);",
            "",
            "\towner_storage_ptr =",
            "\t\t(struct bpf_local_storage **)owner_storage(smap, owner);",
            "\t/* Publish storage to the owner.",
            "\t * Instead of using any lock of the kernel object (i.e. owner),",
            "\t * cmpxchg will work with any kernel object regardless what",
            "\t * the running context is, bh, irq...etc.",
            "\t *",
            "\t * From now on, the owner->storage pointer (e.g. sk->sk_bpf_storage)",
            "\t * is protected by the storage->lock.  Hence, when freeing",
            "\t * the owner->storage, the storage->lock must be held before",
            "\t * setting owner->storage ptr to NULL.",
            "\t */",
            "\tprev_storage = cmpxchg(owner_storage_ptr, NULL, storage);",
            "\tif (unlikely(prev_storage)) {",
            "\t\tbpf_selem_unlink_map(first_selem);",
            "\t\terr = -EAGAIN;",
            "\t\tgoto uncharge;",
            "",
            "\t\t/* Note that even first_selem was linked to smap's",
            "\t\t * bucket->list, first_selem can be freed immediately",
            "\t\t * (instead of kfree_rcu) because",
            "\t\t * bpf_local_storage_map_free() does a",
            "\t\t * synchronize_rcu_mult (waiting for both sleepable and",
            "\t\t * normal programs) before walking the bucket->list.",
            "\t\t * Hence, no one is accessing selem from the",
            "\t\t * bucket->list under rcu_read_lock().",
            "\t\t */",
            "\t}",
            "",
            "\treturn 0;",
            "",
            "uncharge:",
            "\tbpf_local_storage_free(storage, smap, smap->bpf_ma, true);",
            "\tmem_uncharge(smap, owner, sizeof(*storage));",
            "\treturn err;",
            "}",
            "static u16 bpf_local_storage_cache_idx_get(struct bpf_local_storage_cache *cache)",
            "{",
            "\tu64 min_usage = U64_MAX;",
            "\tu16 i, res = 0;",
            "",
            "\tspin_lock(&cache->idx_lock);",
            "",
            "\tfor (i = 0; i < BPF_LOCAL_STORAGE_CACHE_SIZE; i++) {",
            "\t\tif (cache->idx_usage_counts[i] < min_usage) {",
            "\t\t\tmin_usage = cache->idx_usage_counts[i];",
            "\t\t\tres = i;",
            "",
            "\t\t\t/* Found a free cache_idx */",
            "\t\t\tif (!min_usage)",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "\tcache->idx_usage_counts[res]++;",
            "",
            "\tspin_unlock(&cache->idx_lock);",
            "",
            "\treturn res;",
            "}"
          ],
          "function_name": "check_flags, bpf_local_storage_alloc, bpf_local_storage_cache_idx_get",
          "description": "提供本地存储分配接口和缓存索引分配算法，包含冲突检测逻辑和基于内存缓存的分配实现。",
          "similarity": 0.47853660583496094
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/bpf/bpf_local_storage.c",
          "start_line": 343,
          "end_line": 449,
          "content": [
            "static bool check_storage_bpf_ma(struct bpf_local_storage *local_storage,",
            "\t\t\t\t struct bpf_local_storage_map *storage_smap,",
            "\t\t\t\t struct bpf_local_storage_elem *selem)",
            "{",
            "",
            "\tstruct bpf_local_storage_map *selem_smap;",
            "",
            "\t/* local_storage->smap may be NULL. If it is, get the bpf_ma",
            "\t * from any selem in the local_storage->list. The bpf_ma of all",
            "\t * local_storage and selem should have the same value",
            "\t * for the same map type.",
            "\t *",
            "\t * If the local_storage->list is already empty, the caller will not",
            "\t * care about the bpf_ma value also because the caller is not",
            "\t * responsibile to free the local_storage.",
            "\t */",
            "",
            "\tif (storage_smap)",
            "\t\treturn storage_smap->bpf_ma;",
            "",
            "\tif (!selem) {",
            "\t\tstruct hlist_node *n;",
            "",
            "\t\tn = rcu_dereference_check(hlist_first_rcu(&local_storage->list),",
            "\t\t\t\t\t  bpf_rcu_lock_held());",
            "\t\tif (!n)",
            "\t\t\treturn false;",
            "",
            "\t\tselem = hlist_entry(n, struct bpf_local_storage_elem, snode);",
            "\t}",
            "\tselem_smap = rcu_dereference_check(SDATA(selem)->smap, bpf_rcu_lock_held());",
            "",
            "\treturn selem_smap->bpf_ma;",
            "}",
            "static void bpf_selem_unlink_storage(struct bpf_local_storage_elem *selem,",
            "\t\t\t\t     bool reuse_now)",
            "{",
            "\tstruct bpf_local_storage_map *storage_smap;",
            "\tstruct bpf_local_storage *local_storage;",
            "\tbool bpf_ma, free_local_storage = false;",
            "\tHLIST_HEAD(selem_free_list);",
            "\tunsigned long flags;",
            "",
            "\tif (unlikely(!selem_linked_to_storage_lockless(selem)))",
            "\t\t/* selem has already been unlinked from sk */",
            "\t\treturn;",
            "",
            "\tlocal_storage = rcu_dereference_check(selem->local_storage,",
            "\t\t\t\t\t      bpf_rcu_lock_held());",
            "\tstorage_smap = rcu_dereference_check(local_storage->smap,",
            "\t\t\t\t\t     bpf_rcu_lock_held());",
            "\tbpf_ma = check_storage_bpf_ma(local_storage, storage_smap, selem);",
            "",
            "\traw_spin_lock_irqsave(&local_storage->lock, flags);",
            "\tif (likely(selem_linked_to_storage(selem)))",
            "\t\tfree_local_storage = bpf_selem_unlink_storage_nolock(",
            "\t\t\tlocal_storage, selem, true, &selem_free_list);",
            "\traw_spin_unlock_irqrestore(&local_storage->lock, flags);",
            "",
            "\tbpf_selem_free_list(&selem_free_list, reuse_now);",
            "",
            "\tif (free_local_storage)",
            "\t\tbpf_local_storage_free(local_storage, storage_smap, bpf_ma, reuse_now);",
            "}",
            "void bpf_selem_link_storage_nolock(struct bpf_local_storage *local_storage,",
            "\t\t\t\t   struct bpf_local_storage_elem *selem)",
            "{",
            "\tRCU_INIT_POINTER(selem->local_storage, local_storage);",
            "\thlist_add_head_rcu(&selem->snode, &local_storage->list);",
            "}",
            "static void bpf_selem_unlink_map(struct bpf_local_storage_elem *selem)",
            "{",
            "\tstruct bpf_local_storage_map *smap;",
            "\tstruct bpf_local_storage_map_bucket *b;",
            "\tunsigned long flags;",
            "",
            "\tif (unlikely(!selem_linked_to_map_lockless(selem)))",
            "\t\t/* selem has already be unlinked from smap */",
            "\t\treturn;",
            "",
            "\tsmap = rcu_dereference_check(SDATA(selem)->smap, bpf_rcu_lock_held());",
            "\tb = select_bucket(smap, selem);",
            "\traw_spin_lock_irqsave(&b->lock, flags);",
            "\tif (likely(selem_linked_to_map(selem)))",
            "\t\thlist_del_init_rcu(&selem->map_node);",
            "\traw_spin_unlock_irqrestore(&b->lock, flags);",
            "}",
            "void bpf_selem_link_map(struct bpf_local_storage_map *smap,",
            "\t\t\tstruct bpf_local_storage_elem *selem)",
            "{",
            "\tstruct bpf_local_storage_map_bucket *b = select_bucket(smap, selem);",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&b->lock, flags);",
            "\tRCU_INIT_POINTER(SDATA(selem)->smap, smap);",
            "\thlist_add_head_rcu(&selem->map_node, &b->list);",
            "\traw_spin_unlock_irqrestore(&b->lock, flags);",
            "}",
            "void bpf_selem_unlink(struct bpf_local_storage_elem *selem, bool reuse_now)",
            "{",
            "\t/* Always unlink from map before unlinking from local_storage",
            "\t * because selem will be freed after successfully unlinked from",
            "\t * the local_storage.",
            "\t */",
            "\tbpf_selem_unlink_map(selem);",
            "\tbpf_selem_unlink_storage(selem, reuse_now);",
            "}"
          ],
          "function_name": "check_storage_bpf_ma, bpf_selem_unlink_storage, bpf_selem_link_storage_nolock, bpf_selem_unlink_map, bpf_selem_link_map, bpf_selem_unlink",
          "description": "实现元素与存储结构的绑定/解除绑定操作，包含RCU锁保护的链表操作和存储结构生命周期管理。",
          "similarity": 0.42732036113739014
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/bpf/bpf_local_storage.c",
          "start_line": 27,
          "end_line": 135,
          "content": [
            "static int mem_charge(struct bpf_local_storage_map *smap, void *owner, u32 size)",
            "{",
            "\tstruct bpf_map *map = &smap->map;",
            "",
            "\tif (!map->ops->map_local_storage_charge)",
            "\t\treturn 0;",
            "",
            "\treturn map->ops->map_local_storage_charge(smap, owner, size);",
            "}",
            "static void mem_uncharge(struct bpf_local_storage_map *smap, void *owner,",
            "\t\t\t u32 size)",
            "{",
            "\tstruct bpf_map *map = &smap->map;",
            "",
            "\tif (map->ops->map_local_storage_uncharge)",
            "\t\tmap->ops->map_local_storage_uncharge(smap, owner, size);",
            "}",
            "static bool selem_linked_to_storage_lockless(const struct bpf_local_storage_elem *selem)",
            "{",
            "\treturn !hlist_unhashed_lockless(&selem->snode);",
            "}",
            "static bool selem_linked_to_storage(const struct bpf_local_storage_elem *selem)",
            "{",
            "\treturn !hlist_unhashed(&selem->snode);",
            "}",
            "static bool selem_linked_to_map_lockless(const struct bpf_local_storage_elem *selem)",
            "{",
            "\treturn !hlist_unhashed_lockless(&selem->map_node);",
            "}",
            "static bool selem_linked_to_map(const struct bpf_local_storage_elem *selem)",
            "{",
            "\treturn !hlist_unhashed(&selem->map_node);",
            "}",
            "static void __bpf_local_storage_free_trace_rcu(struct rcu_head *rcu)",
            "{",
            "\tstruct bpf_local_storage *local_storage;",
            "",
            "\t/* If RCU Tasks Trace grace period implies RCU grace period, do",
            "\t * kfree(), else do kfree_rcu().",
            "\t */",
            "\tlocal_storage = container_of(rcu, struct bpf_local_storage, rcu);",
            "\tif (rcu_trace_implies_rcu_gp())",
            "\t\tkfree(local_storage);",
            "\telse",
            "\t\tkfree_rcu(local_storage, rcu);",
            "}",
            "static void bpf_local_storage_free_rcu(struct rcu_head *rcu)",
            "{",
            "\tstruct bpf_local_storage *local_storage;",
            "",
            "\tlocal_storage = container_of(rcu, struct bpf_local_storage, rcu);",
            "\tbpf_mem_cache_raw_free(local_storage);",
            "}",
            "static void bpf_local_storage_free_trace_rcu(struct rcu_head *rcu)",
            "{",
            "\tif (rcu_trace_implies_rcu_gp())",
            "\t\tbpf_local_storage_free_rcu(rcu);",
            "\telse",
            "\t\tcall_rcu(rcu, bpf_local_storage_free_rcu);",
            "}",
            "static void __bpf_local_storage_free(struct bpf_local_storage *local_storage,",
            "\t\t\t\t     bool vanilla_rcu)",
            "{",
            "\tif (vanilla_rcu)",
            "\t\tkfree_rcu(local_storage, rcu);",
            "\telse",
            "\t\tcall_rcu_tasks_trace(&local_storage->rcu,",
            "\t\t\t\t     __bpf_local_storage_free_trace_rcu);",
            "}",
            "static void bpf_local_storage_free(struct bpf_local_storage *local_storage,",
            "\t\t\t\t   struct bpf_local_storage_map *smap,",
            "\t\t\t\t   bool bpf_ma, bool reuse_now)",
            "{",
            "\tif (!local_storage)",
            "\t\treturn;",
            "",
            "\tif (!bpf_ma) {",
            "\t\t__bpf_local_storage_free(local_storage, reuse_now);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (!reuse_now) {",
            "\t\tcall_rcu_tasks_trace(&local_storage->rcu,",
            "\t\t\t\t     bpf_local_storage_free_trace_rcu);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (smap) {",
            "\t\tmigrate_disable();",
            "\t\tbpf_mem_cache_free(&smap->storage_ma, local_storage);",
            "\t\tmigrate_enable();",
            "\t} else {",
            "\t\t/* smap could be NULL if the selem that triggered",
            "\t\t * this 'local_storage' creation had been long gone.",
            "\t\t * In this case, directly do call_rcu().",
            "\t\t */",
            "\t\tcall_rcu(&local_storage->rcu, bpf_local_storage_free_rcu);",
            "\t}",
            "}",
            "static void __bpf_selem_free_trace_rcu(struct rcu_head *rcu)",
            "{",
            "\tstruct bpf_local_storage_elem *selem;",
            "",
            "\tselem = container_of(rcu, struct bpf_local_storage_elem, rcu);",
            "\tif (rcu_trace_implies_rcu_gp())",
            "\t\tkfree(selem);",
            "\telse",
            "\t\tkfree_rcu(selem, rcu);",
            "}"
          ],
          "function_name": "mem_charge, mem_uncharge, selem_linked_to_storage_lockless, selem_linked_to_storage, selem_linked_to_map_lockless, selem_linked_to_map, __bpf_local_storage_free_trace_rcu, bpf_local_storage_free_rcu, bpf_local_storage_free_trace_rcu, __bpf_local_storage_free, bpf_local_storage_free, __bpf_selem_free_trace_rcu",
          "description": "实现内存充放电接口及元素链接状态检测，包含RCU安全的元素释放逻辑和不同RCU模式的内存回收方法。",
          "similarity": 0.42416685819625854
        }
      ]
    },
    {
      "source_file": "kernel/bpf/syscall.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:31:40\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\syscall.c`\n\n---\n\n# `bpf/syscall.c` 技术文档\n\n## 1. 文件概述\n\n`bpf/syscall.c` 是 Linux 内核中 BPF（Berkeley Packet Filter）子系统的核心实现文件之一，主要负责处理与 BPF 相关的系统调用逻辑。该文件实现了 BPF 程序、映射（map）和链接（link）对象的创建、更新、查询、删除等操作的底层支持，并管理这些对象的生命周期、权限控制、内存布局以及与用户空间的交互。此外，它还包含对 BPF 对象中用户指针（uptr）的内存固定（pinning）机制，确保内核安全访问用户空间内存。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `bpf_map_ops`：定义各类 BPF 映射的操作函数集，通过 `bpf_map_types[]` 数组按类型索引。\n- `bpf_map`：BPF 映射的通用抽象结构，包含类型、键/值大小、操作函数指针等。\n- IDR（Integer ID Allocator）结构：\n  - `prog_idr` / `map_idr` / `link_idr`：分别用于分配和管理 BPF 程序、映射和链接的全局唯一 ID。\n- `btf_record` 与 `btf_field`：用于描述 BPF 对象中包含的 BTF（BPF Type Format）元数据字段，特别是 `BPF_UPTR` 类型字段。\n\n### 主要函数\n- `bpf_check_uarg_tail_zero()`：验证用户传入的结构体尾部未使用字节是否为零，用于向前兼容。\n- `bpf_map_value_size()`：根据映射类型计算实际存储值的大小（如 per-CPU 映射需乘以 CPU 数）。\n- `bpf_map_update_value()`：统一入口，根据映射类型分发到对应的更新实现。\n- `bpf_obj_pin_uptrs()` / `bpf_obj_unpin_uptrs()`：对 BPF 对象中 `BPF_UPTR` 字段指向的用户空间内存进行长期固定（pin）或释放。\n- `maybe_wait_bpf_programs()`：在更新某些映射（如 map-in-map）后同步等待正在运行的 BPF 程序完成。\n- `bpf_map_write_active*()`：提供映射写入活跃状态的原子计数机制。\n\n### 全局变量\n- `sysctl_unprivileged_bpf_disabled`：控制非特权用户是否可使用 BPF 的运行时开关。\n- `bpf_prog_active`（per-CPU）：跟踪当前 CPU 上是否正在执行 BPF 程序。\n- `bpf_map_offload_ops`：用于硬件卸载（offload）场景的映射操作集。\n\n### 宏定义\n- `IS_FD_*` 系列宏：用于快速判断映射是否存储文件描述符（如程序、其他映射等）。\n- `BPF_OBJ_FLAG_MASK`：定义 BPF 对象创建时允许的标志位掩码。\n\n## 3. 关键实现\n\n### 用户参数兼容性检查\n`bpf_check_uarg_tail_zero()` 函数确保当用户空间传递比内核预期更大的结构体时，超出部分必须全为零。这防止新版本用户空间依赖尚未实现的内核特性，保障 ABI 的向前兼容性。该函数区分内核指针和用户指针，分别使用 `memchr_inv()` 和 `check_zeroed_user()` 进行检查。\n\n### BPF 映射值大小计算\n`bpf_map_value_size()` 根据映射类型动态计算实际存储开销：\n- 对于 per-CPU 类型（如 `PERCPU_HASH`、`PERCPU_ARRAY`），值大小需对齐到 8 字节并乘以可能的 CPU 数量。\n- 对于存储文件描述符的映射（如 `PROG_ARRAY`、`ARRAY_OF_MAPS`），值大小固定为 `sizeof(u32)`。\n- 其他类型直接使用 `map->value_size`。\n\n### 用户指针（uptr）内存固定机制\nBPF 支持在映射值或程序上下文中包含指向用户空间内存的指针（`BPF_UPTR`）。为确保内核安全访问：\n1. `bpf_obj_pin_uptrs()` 使用 `pin_user_pages_fast()` 将用户页长期固定（`FOLL_LONGTERM`），防止被换出。\n2. 要求目标结构体不能跨页（避免复杂性），且不支持高端内存（`PageHighMem`）。\n3. 固定成功后，将用户虚拟地址转换为内核线性映射地址存储。\n4. 出错时通过 `__bpf_obj_unpin_uptrs()` 回滚已固定的页。\n\n### 映射更新分发逻辑\n`bpf_map_update_value()` 是映射更新的核心分发函数：\n- 硬件卸载映射调用 `bpf_map_offload_update_elem()`。\n- 特殊映射（如 `CPUMAP`、`SOCKMAP`）调用其专属更新函数。\n- 文件描述符类映射（`PROG_ARRAY`、`ARRAY_OF_MAPS` 等）在 RCU 读锁保护下更新，确保并发安全。\n- per-CPU 映射调用对应的 per-CPU 更新函数。\n- 更新前调用 `bpf_disable_instrumentation()` 避免追踪干扰。\n\n### 同步机制\n- 对于 `HASH_OF_MAPS` 和 `ARRAY_OF_MAPS`，更新后调用 `synchronize_rcu()` 确保所有 CPU 上正在运行的 BPF 程序看到新值。\n- per-CPU 计数器 `bpf_prog_active` 用于检测 BPF 程序递归调用或死锁。\n\n## 4. 依赖关系\n\n- **BPF 子系统内部**：\n  - 依赖 `bpf_map_types.h` 自动生成的映射操作函数表。\n  - 与 `bpf_verifier.c`（验证器）、`bpf_helpers.c`（辅助函数）、各类映射实现（如 `arraymap.c`、`hashtab.c`）紧密协作。\n- **内存管理**：\n  - 使用 `pin_user_pages_fast()` / `unpin_user_page()` 管理用户页固定。\n  - 依赖 `mm/` 子系统的页表和内存分配机制。\n- **RCU 机制**：\n  - 在更新共享映射时使用 RCU 保证并发安全。\n- **BTF（BPF Type Format）**：\n  - 依赖 `btf.c` 提供的类型信息解析 `BPF_UPTR` 字段。\n- **网络子系统**：\n  - 包含 `netfilter/nf_bpf_link.h`、`netkit.h`、`tcx.h` 等头文件，支持网络相关的 BPF 链接类型。\n- **安全模块**：\n  - 与 LSM（`bpf_lsm.h`）、审计（`audit.h`）集成，实施权限检查。\n\n## 5. 使用场景\n\n- **系统调用处理**：作为 `bpf(2)` 系统调用的后端实现，处理 `BPF_MAP_CREATE`、`BPF_MAP_UPDATE_ELEM`、`BPF_PROG_LOAD` 等命令。\n- **eBPF 程序执行**：为运行中的 BPF 程序提供映射访问、程序调用（通过 `PROG_ARRAY`）等运行时支持。\n- **容器与 cgroup 集成**：通过 `CGROUP_ARRAY` 等映射类型实现资源控制策略。\n- **性能监控**：`PERF_EVENT_ARRAY` 映射用于将 BPF 程序与 perf 事件关联。\n- **网络数据平面**：`SOCKMAP`、`XSKMAP` 等用于加速 socket 和 AF_XDP 数据路径。\n- **内核追踪**：与 ftrace、kprobe 等子系统结合，实现动态追踪。\n- **安全策略实施**：通过 BPF LSM 钩子执行自定义安全策略。\n- **用户空间内存安全访问**：在需要内核直接访问用户缓冲区的场景（如某些高级 BPF 程序）中，通过 `BPF_UPTR` 机制安全固定内存。",
      "similarity": 0.5807117819786072,
      "chunks": [
        {
          "chunk_id": 13,
          "file_path": "kernel/bpf/syscall.c",
          "start_line": 2168,
          "end_line": 2272,
          "content": [
            "static int map_freeze(const union bpf_attr *attr)",
            "{",
            "\tint err = 0;",
            "\tstruct bpf_map *map;",
            "",
            "\tif (CHECK_ATTR(BPF_MAP_FREEZE))",
            "\t\treturn -EINVAL;",
            "",
            "\tCLASS(fd, f)(attr->map_fd);",
            "\tmap = __bpf_map_get(f);",
            "\tif (IS_ERR(map))",
            "\t\treturn PTR_ERR(map);",
            "",
            "\tif (map->map_type == BPF_MAP_TYPE_STRUCT_OPS || !IS_ERR_OR_NULL(map->record))",
            "\t\treturn -ENOTSUPP;",
            "",
            "\tif (!(map_get_sys_perms(map, f) & FMODE_CAN_WRITE))",
            "\t\treturn -EPERM;",
            "",
            "\tmutex_lock(&map->freeze_mutex);",
            "\tif (bpf_map_write_active(map)) {",
            "\t\terr = -EBUSY;",
            "\t\tgoto err_put;",
            "\t}",
            "\tif (READ_ONCE(map->frozen)) {",
            "\t\terr = -EBUSY;",
            "\t\tgoto err_put;",
            "\t}",
            "",
            "\tWRITE_ONCE(map->frozen, true);",
            "err_put:",
            "\tmutex_unlock(&map->freeze_mutex);",
            "\treturn err;",
            "}",
            "static int find_prog_type(enum bpf_prog_type type, struct bpf_prog *prog)",
            "{",
            "\tconst struct bpf_prog_ops *ops;",
            "",
            "\tif (type >= ARRAY_SIZE(bpf_prog_types))",
            "\t\treturn -EINVAL;",
            "\ttype = array_index_nospec(type, ARRAY_SIZE(bpf_prog_types));",
            "\tops = bpf_prog_types[type];",
            "\tif (!ops)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (!bpf_prog_is_offloaded(prog->aux))",
            "\t\tprog->aux->ops = ops;",
            "\telse",
            "\t\tprog->aux->ops = &bpf_offload_prog_ops;",
            "\tprog->type = type;",
            "\treturn 0;",
            "}",
            "static void bpf_audit_prog(const struct bpf_prog *prog, unsigned int op)",
            "{",
            "\tstruct audit_context *ctx = NULL;",
            "\tstruct audit_buffer *ab;",
            "",
            "\tif (WARN_ON_ONCE(op >= BPF_AUDIT_MAX))",
            "\t\treturn;",
            "\tif (audit_enabled == AUDIT_OFF)",
            "\t\treturn;",
            "\tif (!in_irq() && !irqs_disabled())",
            "\t\tctx = audit_context();",
            "\tab = audit_log_start(ctx, GFP_ATOMIC, AUDIT_BPF);",
            "\tif (unlikely(!ab))",
            "\t\treturn;",
            "\taudit_log_format(ab, \"prog-id=%u op=%s\",",
            "\t\t\t prog->aux->id, bpf_audit_str[op]);",
            "\taudit_log_end(ab);",
            "}",
            "static int bpf_prog_alloc_id(struct bpf_prog *prog)",
            "{",
            "\tint id;",
            "",
            "\tidr_preload(GFP_KERNEL);",
            "\tspin_lock_bh(&prog_idr_lock);",
            "\tid = idr_alloc_cyclic(&prog_idr, prog, 1, INT_MAX, GFP_ATOMIC);",
            "\tif (id > 0)",
            "\t\tprog->aux->id = id;",
            "\tspin_unlock_bh(&prog_idr_lock);",
            "\tidr_preload_end();",
            "",
            "\t/* id is in [1, INT_MAX) */",
            "\tif (WARN_ON_ONCE(!id))",
            "\t\treturn -ENOSPC;",
            "",
            "\treturn id > 0 ? 0 : id;",
            "}",
            "void bpf_prog_free_id(struct bpf_prog *prog)",
            "{",
            "\tunsigned long flags;",
            "",
            "\t/* cBPF to eBPF migrations are currently not in the idr store.",
            "\t * Offloaded programs are removed from the store when their device",
            "\t * disappears - even if someone grabs an fd to them they are unusable,",
            "\t * simply waiting for refcnt to drop to be freed.",
            "\t */",
            "\tif (!prog->aux->id)",
            "\t\treturn;",
            "",
            "\tspin_lock_irqsave(&prog_idr_lock, flags);",
            "\tidr_remove(&prog_idr, prog->aux->id);",
            "\tprog->aux->id = 0;",
            "\tspin_unlock_irqrestore(&prog_idr_lock, flags);",
            "}"
          ],
          "function_name": "map_freeze, find_prog_type, bpf_audit_prog, bpf_prog_alloc_id, bpf_prog_free_id",
          "description": "该代码段主要实现BPF子系统的核心控制逻辑：  \n1. `map_freeze` 管理BPF地图的冻结状态，防止在冻结期间对特定类型地图进行写操作；  \n2. `find_prog_type` 根据程序类型选择对应的BPF操作集（内联/离线），并绑定至程序辅助结构；  \n3. `bpf_audit_prog` 记录BPF程序操作到审计日志，`bpf_prog_alloc_id/free_id` 分配/释放程序唯一ID，均基于 IDR 管理。  \n\n注：代码片段完整展示各函数实现，未引入外部假设。",
          "similarity": 0.5341047048568726
        },
        {
          "chunk_id": 14,
          "file_path": "kernel/bpf/syscall.c",
          "start_line": 2300,
          "end_line": 2402,
          "content": [
            "static void __bpf_prog_put_rcu(struct rcu_head *rcu)",
            "{",
            "\tstruct bpf_prog_aux *aux = container_of(rcu, struct bpf_prog_aux, rcu);",
            "",
            "\tkvfree(aux->func_info);",
            "\tkfree(aux->func_info_aux);",
            "\tfree_uid(aux->user);",
            "\tsecurity_bpf_prog_free(aux->prog);",
            "\tbpf_prog_free(aux->prog);",
            "}",
            "static void __bpf_prog_put_noref(struct bpf_prog *prog, bool deferred)",
            "{",
            "\tbpf_prog_kallsyms_del_all(prog);",
            "\tbtf_put(prog->aux->btf);",
            "\tmodule_put(prog->aux->mod);",
            "\tkvfree(prog->aux->jited_linfo);",
            "\tkvfree(prog->aux->linfo);",
            "\tkfree(prog->aux->kfunc_tab);",
            "\tkfree(prog->aux->ctx_arg_info);",
            "\tif (prog->aux->attach_btf)",
            "\t\tbtf_put(prog->aux->attach_btf);",
            "",
            "\tif (deferred) {",
            "\t\tif (prog->sleepable)",
            "\t\t\tcall_rcu_tasks_trace(&prog->aux->rcu, __bpf_prog_put_rcu);",
            "\t\telse",
            "\t\t\tcall_rcu(&prog->aux->rcu, __bpf_prog_put_rcu);",
            "\t} else {",
            "\t\t__bpf_prog_put_rcu(&prog->aux->rcu);",
            "\t}",
            "}",
            "static void bpf_prog_put_deferred(struct work_struct *work)",
            "{",
            "\tstruct bpf_prog_aux *aux;",
            "\tstruct bpf_prog *prog;",
            "",
            "\taux = container_of(work, struct bpf_prog_aux, work);",
            "\tprog = aux->prog;",
            "\tperf_event_bpf_event(prog, PERF_BPF_EVENT_PROG_UNLOAD, 0);",
            "\tbpf_audit_prog(prog, BPF_AUDIT_UNLOAD);",
            "\tbpf_prog_free_id(prog);",
            "\t__bpf_prog_put_noref(prog, true);",
            "}",
            "static void __bpf_prog_put(struct bpf_prog *prog)",
            "{",
            "\tstruct bpf_prog_aux *aux = prog->aux;",
            "",
            "\tif (atomic64_dec_and_test(&aux->refcnt)) {",
            "\t\tif (in_irq() || irqs_disabled()) {",
            "\t\t\tINIT_WORK(&aux->work, bpf_prog_put_deferred);",
            "\t\t\tschedule_work(&aux->work);",
            "\t\t} else {",
            "\t\t\tbpf_prog_put_deferred(&aux->work);",
            "\t\t}",
            "\t}",
            "}",
            "void bpf_prog_put(struct bpf_prog *prog)",
            "{",
            "\t__bpf_prog_put(prog);",
            "}",
            "static int bpf_prog_release(struct inode *inode, struct file *filp)",
            "{",
            "\tstruct bpf_prog *prog = filp->private_data;",
            "",
            "\tbpf_prog_put(prog);",
            "\treturn 0;",
            "}",
            "void notrace bpf_prog_inc_misses_counter(struct bpf_prog *prog)",
            "{",
            "\tstruct bpf_prog_stats *stats;",
            "\tunsigned int flags;",
            "",
            "\tstats = this_cpu_ptr(prog->stats);",
            "\tflags = u64_stats_update_begin_irqsave(&stats->syncp);",
            "\tu64_stats_inc(&stats->misses);",
            "\tu64_stats_update_end_irqrestore(&stats->syncp, flags);",
            "}",
            "static void bpf_prog_get_stats(const struct bpf_prog *prog,",
            "\t\t\t       struct bpf_prog_kstats *stats)",
            "{",
            "\tu64 nsecs = 0, cnt = 0, misses = 0;",
            "\tint cpu;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tconst struct bpf_prog_stats *st;",
            "\t\tunsigned int start;",
            "\t\tu64 tnsecs, tcnt, tmisses;",
            "",
            "\t\tst = per_cpu_ptr(prog->stats, cpu);",
            "\t\tdo {",
            "\t\t\tstart = u64_stats_fetch_begin(&st->syncp);",
            "\t\t\ttnsecs = u64_stats_read(&st->nsecs);",
            "\t\t\ttcnt = u64_stats_read(&st->cnt);",
            "\t\t\ttmisses = u64_stats_read(&st->misses);",
            "\t\t} while (u64_stats_fetch_retry(&st->syncp, start));",
            "\t\tnsecs += tnsecs;",
            "\t\tcnt += tcnt;",
            "\t\tmisses += tmisses;",
            "\t}",
            "\tstats->nsecs = nsecs;",
            "\tstats->cnt = cnt;",
            "\tstats->misses = misses;",
            "}"
          ],
          "function_name": "__bpf_prog_put_rcu, __bpf_prog_put_noref, bpf_prog_put_deferred, __bpf_prog_put, bpf_prog_put, bpf_prog_release, bpf_prog_inc_misses_counter, bpf_prog_get_stats",
          "description": "该代码段实现了BPF程序的资源释放与统计管理，核心功能包括：通过RCU机制安全释放BPF辅助数据结构及关联资源，并支持延迟释放以避免中断上下文直接操作；  \n函数`__bpf_prog_put_noref`清理非引用计数相关资源并调度RCU释放，`bpf_prog_put`通过引用计数控制释放时机，`bpf_prog_release`作为文件操作回调触发程序释放；  \n统计函数`bpf_prog_inc_misses_counter`与`bpf_prog_get_stats`分别用于记录BPF程序命中次数并聚合多CPU统计信息。",
          "similarity": 0.5249233841896057
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/bpf/syscall.c",
          "start_line": 412,
          "end_line": 524,
          "content": [
            "void bpf_map_area_free(void *area)",
            "{",
            "\tkvfree(area);",
            "}",
            "static u32 bpf_map_flags_retain_permanent(u32 flags)",
            "{",
            "\t/* Some map creation flags are not tied to the map object but",
            "\t * rather to the map fd instead, so they have no meaning upon",
            "\t * map object inspection since multiple file descriptors with",
            "\t * different (access) properties can exist here. Thus, given",
            "\t * this has zero meaning for the map itself, lets clear these",
            "\t * from here.",
            "\t */",
            "\treturn flags & ~(BPF_F_RDONLY | BPF_F_WRONLY);",
            "}",
            "void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)",
            "{",
            "\tmap->map_type = attr->map_type;",
            "\tmap->key_size = attr->key_size;",
            "\tmap->value_size = attr->value_size;",
            "\tmap->max_entries = attr->max_entries;",
            "\tmap->map_flags = bpf_map_flags_retain_permanent(attr->map_flags);",
            "\tmap->numa_node = bpf_map_attr_numa_node(attr);",
            "\tmap->map_extra = attr->map_extra;",
            "}",
            "static int bpf_map_alloc_id(struct bpf_map *map)",
            "{",
            "\tint id;",
            "",
            "\tidr_preload(GFP_KERNEL);",
            "\tspin_lock_bh(&map_idr_lock);",
            "\tid = idr_alloc_cyclic(&map_idr, map, 1, INT_MAX, GFP_ATOMIC);",
            "\tif (id > 0)",
            "\t\tmap->id = id;",
            "\tspin_unlock_bh(&map_idr_lock);",
            "\tidr_preload_end();",
            "",
            "\tif (WARN_ON_ONCE(!id))",
            "\t\treturn -ENOSPC;",
            "",
            "\treturn id > 0 ? 0 : id;",
            "}",
            "void bpf_map_free_id(struct bpf_map *map)",
            "{",
            "\tunsigned long flags;",
            "",
            "\t/* Offloaded maps are removed from the IDR store when their device",
            "\t * disappears - even if someone holds an fd to them they are unusable,",
            "\t * the memory is gone, all ops will fail; they are simply waiting for",
            "\t * refcnt to drop to be freed.",
            "\t */",
            "\tif (!map->id)",
            "\t\treturn;",
            "",
            "\tspin_lock_irqsave(&map_idr_lock, flags);",
            "",
            "\tidr_remove(&map_idr, map->id);",
            "\tmap->id = 0;",
            "",
            "\tspin_unlock_irqrestore(&map_idr_lock, flags);",
            "}",
            "static void bpf_map_save_memcg(struct bpf_map *map)",
            "{",
            "\t/* Currently if a map is created by a process belonging to the root",
            "\t * memory cgroup, get_obj_cgroup_from_current() will return NULL.",
            "\t * So we have to check map->objcg for being NULL each time it's",
            "\t * being used.",
            "\t */",
            "\tif (memcg_bpf_enabled())",
            "\t\tmap->objcg = get_obj_cgroup_from_current();",
            "}",
            "static void bpf_map_release_memcg(struct bpf_map *map)",
            "{",
            "\tif (map->objcg)",
            "\t\tobj_cgroup_put(map->objcg);",
            "}",
            "static void bpf_map_save_memcg(struct bpf_map *map)",
            "{",
            "}",
            "static void bpf_map_release_memcg(struct bpf_map *map)",
            "{",
            "}",
            "int bpf_map_alloc_pages(const struct bpf_map *map, gfp_t gfp, int nid,",
            "\t\t\tunsigned long nr_pages, struct page **pages)",
            "{",
            "\tunsigned long i, j;",
            "\tstruct page *pg;",
            "\tint ret = 0;",
            "#ifdef CONFIG_MEMCG",
            "\tstruct mem_cgroup *memcg, *old_memcg;",
            "",
            "\tmemcg = bpf_map_get_memcg(map);",
            "\told_memcg = set_active_memcg(memcg);",
            "#endif",
            "\tfor (i = 0; i < nr_pages; i++) {",
            "\t\tpg = alloc_pages_node(nid, gfp | __GFP_ACCOUNT, 0);",
            "",
            "\t\tif (pg) {",
            "\t\t\tpages[i] = pg;",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tfor (j = 0; j < i; j++)",
            "\t\t\t__free_page(pages[j]);",
            "\t\tret = -ENOMEM;",
            "\t\tbreak;",
            "\t}",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tset_active_memcg(old_memcg);",
            "\tmem_cgroup_put(memcg);",
            "#endif",
            "\treturn ret;",
            "}"
          ],
          "function_name": "bpf_map_area_free, bpf_map_flags_retain_permanent, bpf_map_init_from_attr, bpf_map_alloc_id, bpf_map_free_id, bpf_map_save_memcg, bpf_map_release_memcg, bpf_map_save_memcg, bpf_map_release_memcg, bpf_map_alloc_pages",
          "description": "管理BPF map的ID分配、内存分配、NUMA节点绑定及内存控制组关联性维护",
          "similarity": 0.5201069116592407
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/bpf/syscall.c",
          "start_line": 239,
          "end_line": 358,
          "content": [
            "static int bpf_map_update_value(struct bpf_map *map, struct file *map_file,",
            "\t\t\t\tvoid *key, void *value, __u64 flags)",
            "{",
            "\tint err;",
            "",
            "\t/* Need to create a kthread, thus must support schedule */",
            "\tif (bpf_map_is_offloaded(map)) {",
            "\t\treturn bpf_map_offload_update_elem(map, key, value, flags);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_CPUMAP ||",
            "\t\t   map->map_type == BPF_MAP_TYPE_ARENA ||",
            "\t\t   map->map_type == BPF_MAP_TYPE_STRUCT_OPS) {",
            "\t\treturn map->ops->map_update_elem(map, key, value, flags);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_SOCKHASH ||",
            "\t\t   map->map_type == BPF_MAP_TYPE_SOCKMAP) {",
            "\t\treturn sock_map_update_elem_sys(map, key, value, flags);",
            "\t} else if (IS_FD_PROG_ARRAY(map)) {",
            "\t\treturn bpf_fd_array_map_update_elem(map, map_file, key, value,",
            "\t\t\t\t\t\t    flags);",
            "\t}",
            "",
            "\tbpf_disable_instrumentation();",
            "\tif (map->map_type == BPF_MAP_TYPE_PERCPU_HASH ||",
            "\t    map->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH) {",
            "\t\terr = bpf_percpu_hash_update(map, key, value, flags);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_PERCPU_ARRAY) {",
            "\t\terr = bpf_percpu_array_update(map, key, value, flags);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE) {",
            "\t\terr = bpf_percpu_cgroup_storage_update(map, key, value,",
            "\t\t\t\t\t\t       flags);",
            "\t} else if (IS_FD_ARRAY(map)) {",
            "\t\trcu_read_lock();",
            "\t\terr = bpf_fd_array_map_update_elem(map, map_file, key, value,",
            "\t\t\t\t\t\t   flags);",
            "\t\trcu_read_unlock();",
            "\t} else if (map->map_type == BPF_MAP_TYPE_HASH_OF_MAPS) {",
            "\t\trcu_read_lock();",
            "\t\terr = bpf_fd_htab_map_update_elem(map, map_file, key, value,",
            "\t\t\t\t\t\t  flags);",
            "\t\trcu_read_unlock();",
            "\t} else if (map->map_type == BPF_MAP_TYPE_REUSEPORT_SOCKARRAY) {",
            "\t\t/* rcu_read_lock() is not needed */",
            "\t\terr = bpf_fd_reuseport_array_update_elem(map, key, value,",
            "\t\t\t\t\t\t\t flags);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_QUEUE ||",
            "\t\t   map->map_type == BPF_MAP_TYPE_STACK ||",
            "\t\t   map->map_type == BPF_MAP_TYPE_BLOOM_FILTER) {",
            "\t\terr = map->ops->map_push_elem(map, value, flags);",
            "\t} else {",
            "\t\terr = bpf_obj_pin_uptrs(map->record, value);",
            "\t\tif (!err) {",
            "\t\t\trcu_read_lock();",
            "\t\t\terr = map->ops->map_update_elem(map, key, value, flags);",
            "\t\t\trcu_read_unlock();",
            "\t\t\tif (err)",
            "\t\t\t\tbpf_obj_unpin_uptrs(map->record, value);",
            "\t\t}",
            "\t}",
            "\tbpf_enable_instrumentation();",
            "",
            "\treturn err;",
            "}",
            "static int bpf_map_copy_value(struct bpf_map *map, void *key, void *value,",
            "\t\t\t      __u64 flags)",
            "{",
            "\tvoid *ptr;",
            "\tint err;",
            "",
            "\tif (bpf_map_is_offloaded(map))",
            "\t\treturn bpf_map_offload_lookup_elem(map, key, value);",
            "",
            "\tbpf_disable_instrumentation();",
            "\tif (map->map_type == BPF_MAP_TYPE_PERCPU_HASH ||",
            "\t    map->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH) {",
            "\t\terr = bpf_percpu_hash_copy(map, key, value);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_PERCPU_ARRAY) {",
            "\t\terr = bpf_percpu_array_copy(map, key, value);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE) {",
            "\t\terr = bpf_percpu_cgroup_storage_copy(map, key, value);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_STACK_TRACE) {",
            "\t\terr = bpf_stackmap_copy(map, key, value);",
            "\t} else if (IS_FD_ARRAY(map) || IS_FD_PROG_ARRAY(map)) {",
            "\t\terr = bpf_fd_array_map_lookup_elem(map, key, value);",
            "\t} else if (IS_FD_HASH(map)) {",
            "\t\terr = bpf_fd_htab_map_lookup_elem(map, key, value);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_REUSEPORT_SOCKARRAY) {",
            "\t\terr = bpf_fd_reuseport_array_lookup_elem(map, key, value);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_QUEUE ||",
            "\t\t   map->map_type == BPF_MAP_TYPE_STACK ||",
            "\t\t   map->map_type == BPF_MAP_TYPE_BLOOM_FILTER) {",
            "\t\terr = map->ops->map_peek_elem(map, value);",
            "\t} else if (map->map_type == BPF_MAP_TYPE_STRUCT_OPS) {",
            "\t\t/* struct_ops map requires directly updating \"value\" */",
            "\t\terr = bpf_struct_ops_map_sys_lookup_elem(map, key, value);",
            "\t} else {",
            "\t\trcu_read_lock();",
            "\t\tif (map->ops->map_lookup_elem_sys_only)",
            "\t\t\tptr = map->ops->map_lookup_elem_sys_only(map, key);",
            "\t\telse",
            "\t\t\tptr = map->ops->map_lookup_elem(map, key);",
            "\t\tif (IS_ERR(ptr)) {",
            "\t\t\terr = PTR_ERR(ptr);",
            "\t\t} else if (!ptr) {",
            "\t\t\terr = -ENOENT;",
            "\t\t} else {",
            "\t\t\terr = 0;",
            "\t\t\tif (flags & BPF_F_LOCK)",
            "\t\t\t\t/* lock 'ptr' and copy everything but lock */",
            "\t\t\t\tcopy_map_value_locked(map, value, ptr, true);",
            "\t\t\telse",
            "\t\t\t\tcopy_map_value(map, value, ptr);",
            "\t\t\t/* mask lock and timer, since value wasn't zero inited */",
            "\t\t\tcheck_and_init_map_value(map, value);",
            "\t\t}",
            "\t\trcu_read_unlock();",
            "\t}",
            "",
            "\tbpf_enable_instrumentation();",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "bpf_map_update_value, bpf_map_copy_value",
          "description": "实现BPF map值更新与复制逻辑，根据map类型选择相应操作路径并处理并发控制",
          "similarity": 0.5096845626831055
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/bpf/syscall.c",
          "start_line": 834,
          "end_line": 935,
          "content": [
            "static void bpf_map_free(struct bpf_map *map)",
            "{",
            "\tstruct btf_record *rec = map->record;",
            "\tstruct btf *btf = map->btf;",
            "",
            "\t/* implementation dependent freeing */",
            "\tmap->ops->map_free(map);",
            "\t/* Delay freeing of btf_record for maps, as map_free",
            "\t * callback usually needs access to them. It is better to do it here",
            "\t * than require each callback to do the free itself manually.",
            "\t *",
            "\t * Note that the btf_record stashed in map->inner_map_meta->record was",
            "\t * already freed using the map_free callback for map in map case which",
            "\t * eventually calls bpf_map_free_meta, since inner_map_meta is only a",
            "\t * template bpf_map struct used during verification.",
            "\t */",
            "\tbtf_record_free(rec);",
            "\t/* Delay freeing of btf for maps, as map_free callback may need",
            "\t * struct_meta info which will be freed with btf_put().",
            "\t */",
            "\tbtf_put(btf);",
            "}",
            "static void bpf_map_free_deferred(struct work_struct *work)",
            "{",
            "\tstruct bpf_map *map = container_of(work, struct bpf_map, work);",
            "",
            "\tsecurity_bpf_map_free(map);",
            "\tbpf_map_release_memcg(map);",
            "\tbpf_map_owner_free(map);",
            "\tbpf_map_free(map);",
            "}",
            "static void bpf_map_put_uref(struct bpf_map *map)",
            "{",
            "\tif (atomic64_dec_and_test(&map->usercnt)) {",
            "\t\tif (map->ops->map_release_uref)",
            "\t\t\tmap->ops->map_release_uref(map);",
            "\t}",
            "}",
            "static void bpf_map_free_in_work(struct bpf_map *map)",
            "{",
            "\tINIT_WORK(&map->work, bpf_map_free_deferred);",
            "\t/* Avoid spawning kworkers, since they all might contend",
            "\t * for the same mutex like slab_mutex.",
            "\t */",
            "\tqueue_work(system_unbound_wq, &map->work);",
            "}",
            "static void bpf_map_free_rcu_gp(struct rcu_head *rcu)",
            "{",
            "\tbpf_map_free_in_work(container_of(rcu, struct bpf_map, rcu));",
            "}",
            "static void bpf_map_free_mult_rcu_gp(struct rcu_head *rcu)",
            "{",
            "\tif (rcu_trace_implies_rcu_gp())",
            "\t\tbpf_map_free_rcu_gp(rcu);",
            "\telse",
            "\t\tcall_rcu(rcu, bpf_map_free_rcu_gp);",
            "}",
            "void bpf_map_put(struct bpf_map *map)",
            "{",
            "\tif (atomic64_dec_and_test(&map->refcnt)) {",
            "\t\t/* bpf_map_free_id() must be called first */",
            "\t\tbpf_map_free_id(map);",
            "",
            "\t\tWARN_ON_ONCE(atomic64_read(&map->sleepable_refcnt));",
            "\t\tif (READ_ONCE(map->free_after_mult_rcu_gp))",
            "\t\t\tcall_rcu_tasks_trace(&map->rcu, bpf_map_free_mult_rcu_gp);",
            "\t\telse if (READ_ONCE(map->free_after_rcu_gp))",
            "\t\t\tcall_rcu(&map->rcu, bpf_map_free_rcu_gp);",
            "\t\telse",
            "\t\t\tbpf_map_free_in_work(map);",
            "\t}",
            "}",
            "void bpf_map_put_with_uref(struct bpf_map *map)",
            "{",
            "\tbpf_map_put_uref(map);",
            "\tbpf_map_put(map);",
            "}",
            "static int bpf_map_release(struct inode *inode, struct file *filp)",
            "{",
            "\tstruct bpf_map *map = filp->private_data;",
            "",
            "\tif (map->ops->map_release)",
            "\t\tmap->ops->map_release(map, filp);",
            "",
            "\tbpf_map_put_with_uref(map);",
            "\treturn 0;",
            "}",
            "static fmode_t map_get_sys_perms(struct bpf_map *map, struct fd f)",
            "{",
            "\tfmode_t mode = fd_file(f)->f_mode;",
            "",
            "\t/* Our file permissions may have been overridden by global",
            "\t * map permissions facing syscall side.",
            "\t */",
            "\tif (READ_ONCE(map->frozen))",
            "\t\tmode &= ~FMODE_CAN_WRITE;",
            "\treturn mode;",
            "}",
            "static u64 bpf_map_memory_usage(const struct bpf_map *map)",
            "{",
            "\treturn map->ops->map_mem_usage(map);",
            "}"
          ],
          "function_name": "bpf_map_free, bpf_map_free_deferred, bpf_map_put_uref, bpf_map_free_in_work, bpf_map_free_rcu_gp, bpf_map_free_mult_rcu_gp, bpf_map_put, bpf_map_put_with_uref, bpf_map_release, map_get_sys_perms, bpf_map_memory_usage",
          "description": "实现BPF地图释放逻辑，通过调用map_free回调并延迟释放BTF记录/元数据，支持RCU/工作队列异步清理，管理用户/内核引用计数及权限检查",
          "similarity": 0.5041743516921997
        }
      ]
    }
  ]
}