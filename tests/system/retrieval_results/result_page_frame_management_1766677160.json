{
  "query": "page frame management",
  "timestamp": "2025-12-25 23:39:20",
  "retrieved_files": [
    {
      "source_file": "mm/page_vma_mapped.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:07:15\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `page_vma_mapped.c`\n\n---\n\n# page_vma_mapped.c 技术文档\n\n## 1. 文件概述\n\n`page_vma_mapped.c` 实现了用于遍历虚拟内存区域（VMA）中特定物理页帧（PFN）映射的通用机制。该文件的核心功能是提供 `page_vma_mapped_walk()` 函数，允许内核在给定 VMA 中查找指定 PFN 范围是否被映射，并返回对应的页表项（PTE/PMD）及其锁状态。此机制广泛用于内存管理操作，如页面迁移、反向映射（rmap）、设备私有内存（ZONE_DEVICE）处理等场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`page_vma_mapped_walk(struct page_vma_mapped_walk *pvmw)`**  \n  主入口函数，遍历 VMA 中指定 PFN 的映射。支持普通页、透明大页（THP）、HugeTLB 页以及迁移/设备私有交换条目。\n\n- **`check_pte(struct page_vma_mapped_walk *pvmw, unsigned long pte_nr)`**  \n  验证当前 PTE 是否确实映射了目标 PFN 范围，区分正常映射、迁移条目和设备私有条目。\n\n- **`map_pte(struct page_vma_mapped_walk *pvmw, spinlock_t **ptlp)`**  \n  安全地映射并（可选）锁定 PTE，处理同步模式（`PVMW_SYNC`）与非同步模式。\n\n- **`check_pmd(unsigned long pfn, struct page_vma_mapped_walk *pvmw)`**  \n  检查 PMD 级别的大页映射是否覆盖目标 PFN 范围。\n\n- **`step_forward(struct page_vma_mapped_walk *pvmw, unsigned long size)`**  \n  将遍历地址推进到下一个对齐边界，避免溢出。\n\n- **`not_found(struct page_vma_mapped_walk *pvmw)`**  \n  辅助函数，清理状态并返回 `false`。\n\n### 关键数据结构\n\n- **`struct page_vma_mapped_walk`**  \n  遍历上下文结构体，包含：\n  - `vma`：目标虚拟内存区域\n  - `address`：当前检查的虚拟地址\n  - `pfn`, `nr_pages`：目标物理页帧范围\n  - `flags`：控制行为（如 `PVMW_SYNC`, `PVMW_MIGRATION`）\n  - `pmd`, `pte`, `ptl`：当前页表项指针及自旋锁\n\n## 3. 关键实现\n\n### 映射遍历逻辑\n\n1. **HugeTLB 处理**：若 VMA 为 HugeTLB 类型，直接调用 `hugetlb_walk()` 获取 PTE，并使用 `huge_pte_lock()` 锁定。\n2. **多级页表遍历**：对于普通 VMA，从 PGD 逐级遍历至 PUD，再处理 PMD。\n3. **透明大页（THP）支持**：\n   - 若 PMD 为 `trans_huge` 或 `devmap`，直接检查 PMD 映射的 PFN 范围。\n   - 若 PMD 为迁移条目（`is_pmd_migration_entry`），验证其指向的 PFN。\n   - 若 THP 在遍历过程中被拆分，则回退到 PTE 级别处理。\n4. **PTE 级别处理**：\n   - 使用 `map_pte()` 安全获取 PTE。\n   - 通过 `check_pte()` 验证映射类型（正常页、迁移条目、设备私有条目）及 PFN 范围匹配。\n5. **设备私有内存支持**：特殊处理 `is_device_private_entry()` 和 `is_device_exclusive_entry()` 类型的交换条目，将其视为有效映射。\n\n### 同步与锁机制\n\n- **`PVMW_SYNC` 标志**：强制使用带锁的 `pte_offset_map_lock()`，确保遍历时页表不被并发修改。\n- **锁粒度**：PTE 使用 `ptl` 自旋锁，PMD 使用 `pmd_lock()`，HugeTLB 使用 `huge_pte_lock()`。\n- **安全遍历**：即使在非同步模式下，也返回正确的 `ptl` 指针，供调用者在后续循环中使用。\n\n### 边界与溢出处理\n\n- `step_forward()` 使用位掩码对齐地址，防止 `ULONG_MAX` 溢出。\n- 所有范围检查（如 `check_pte()`, `check_pmd()`）均采用防溢出比较方式。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/mm.h>`：内存管理基础定义\n  - `<linux/rmap.h>`：反向映射相关接口\n  - `<linux/hugetlb.h>`：HugeTLB 页支持\n  - `<linux/swap.h>`, `<linux/swapops.h>`：交换条目处理\n  - `\"internal.h\"`：MM 子系统内部接口\n\n- **关键内核子系统**：\n  - **内存管理（MM）**：页表遍历、锁机制、THP/HugeTLB 支持\n  - **HMM（Heterogeneous Memory Management）**：设备私有内存（`ZONE_DEVICE`）处理\n  - **页面迁移（Migration）**：迁移条目解析与验证\n\n## 5. 使用场景\n\n- **页面迁移（Page Migration）**：在迁移页面前，遍历所有映射以更新页表项。\n- **反向映射（RMAP）**：查找页面的所有虚拟地址映射，用于回收或同步。\n- **设备内存管理**：处理 CPU 不可访问的设备私有内存（如 GPU 内存），通过特殊交换条目维护映射计数。\n- **内存回收（Reclaim）**：在回收页面前，确认其映射状态并执行必要的清理（如写回、断开映射）。\n- **调试与监控**：内核工具（如 `/proc/pid/pagemap`）可能使用此接口查询页面映射信息。",
      "similarity": 0.5581845641136169,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/page_vma_mapped.c",
          "start_line": 138,
          "end_line": 294,
          "content": [
            "static bool check_pmd(unsigned long pfn, struct page_vma_mapped_walk *pvmw)",
            "{",
            "\tif ((pfn + HPAGE_PMD_NR - 1) < pvmw->pfn)",
            "\t\treturn false;",
            "\tif (pfn > pvmw->pfn + pvmw->nr_pages - 1)",
            "\t\treturn false;",
            "\treturn true;",
            "}",
            "static void step_forward(struct page_vma_mapped_walk *pvmw, unsigned long size)",
            "{",
            "\tpvmw->address = (pvmw->address + size) & ~(size - 1);",
            "\tif (!pvmw->address)",
            "\t\tpvmw->address = ULONG_MAX;",
            "}",
            "bool page_vma_mapped_walk(struct page_vma_mapped_walk *pvmw)",
            "{",
            "\tstruct vm_area_struct *vma = pvmw->vma;",
            "\tstruct mm_struct *mm = vma->vm_mm;",
            "\tunsigned long end;",
            "\tspinlock_t *ptl;",
            "\tpgd_t *pgd;",
            "\tp4d_t *p4d;",
            "\tpud_t *pud;",
            "\tpmd_t pmde;",
            "",
            "\t/* The only possible pmd mapping has been handled on last iteration */",
            "\tif (pvmw->pmd && !pvmw->pte)",
            "\t\treturn not_found(pvmw);",
            "",
            "\tif (unlikely(is_vm_hugetlb_page(vma))) {",
            "\t\tstruct hstate *hstate = hstate_vma(vma);",
            "\t\tunsigned long size = huge_page_size(hstate);",
            "\t\t/* The only possible mapping was handled on last iteration */",
            "\t\tif (pvmw->pte)",
            "\t\t\treturn not_found(pvmw);",
            "\t\t/*",
            "\t\t * All callers that get here will already hold the",
            "\t\t * i_mmap_rwsem.  Therefore, no additional locks need to be",
            "\t\t * taken before calling hugetlb_walk().",
            "\t\t */",
            "\t\tpvmw->pte = hugetlb_walk(vma, pvmw->address, size);",
            "\t\tif (!pvmw->pte)",
            "\t\t\treturn false;",
            "",
            "\t\tpvmw->ptl = huge_pte_lock(hstate, mm, pvmw->pte);",
            "\t\tif (!check_pte(pvmw, pages_per_huge_page(hstate)))",
            "\t\t\treturn not_found(pvmw);",
            "\t\treturn true;",
            "\t}",
            "",
            "\tend = vma_address_end(pvmw);",
            "\tif (pvmw->pte)",
            "\t\tgoto next_pte;",
            "restart:",
            "\tdo {",
            "\t\tpgd = pgd_offset(mm, pvmw->address);",
            "\t\tif (!pgd_present(*pgd)) {",
            "\t\t\tstep_forward(pvmw, PGDIR_SIZE);",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tp4d = p4d_offset(pgd, pvmw->address);",
            "\t\tif (!p4d_present(*p4d)) {",
            "\t\t\tstep_forward(pvmw, P4D_SIZE);",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tpud = pud_offset(p4d, pvmw->address);",
            "\t\tif (!pud_present(*pud)) {",
            "\t\t\tstep_forward(pvmw, PUD_SIZE);",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tpvmw->pmd = pmd_offset(pud, pvmw->address);",
            "\t\t/*",
            "\t\t * Make sure the pmd value isn't cached in a register by the",
            "\t\t * compiler and used as a stale value after we've observed a",
            "\t\t * subsequent update.",
            "\t\t */",
            "\t\tpmde = pmdp_get_lockless(pvmw->pmd);",
            "",
            "\t\tif (pmd_trans_huge(pmde) || is_pmd_migration_entry(pmde) ||",
            "\t\t    (pmd_present(pmde) && pmd_devmap(pmde))) {",
            "\t\t\tpvmw->ptl = pmd_lock(mm, pvmw->pmd);",
            "\t\t\tpmde = *pvmw->pmd;",
            "\t\t\tif (!pmd_present(pmde)) {",
            "\t\t\t\tswp_entry_t entry;",
            "",
            "\t\t\t\tif (!thp_migration_supported() ||",
            "\t\t\t\t    !(pvmw->flags & PVMW_MIGRATION))",
            "\t\t\t\t\treturn not_found(pvmw);",
            "\t\t\t\tentry = pmd_to_swp_entry(pmde);",
            "\t\t\t\tif (!is_migration_entry(entry) ||",
            "\t\t\t\t    !check_pmd(swp_offset_pfn(entry), pvmw))",
            "\t\t\t\t\treturn not_found(pvmw);",
            "\t\t\t\treturn true;",
            "\t\t\t}",
            "\t\t\tif (likely(pmd_trans_huge(pmde) || pmd_devmap(pmde))) {",
            "\t\t\t\tif (pvmw->flags & PVMW_MIGRATION)",
            "\t\t\t\t\treturn not_found(pvmw);",
            "\t\t\t\tif (!check_pmd(pmd_pfn(pmde), pvmw))",
            "\t\t\t\t\treturn not_found(pvmw);",
            "\t\t\t\treturn true;",
            "\t\t\t}",
            "\t\t\t/* THP pmd was split under us: handle on pte level */",
            "\t\t\tspin_unlock(pvmw->ptl);",
            "\t\t\tpvmw->ptl = NULL;",
            "\t\t} else if (!pmd_present(pmde)) {",
            "\t\t\t/*",
            "\t\t\t * If PVMW_SYNC, take and drop THP pmd lock so that we",
            "\t\t\t * cannot return prematurely, while zap_huge_pmd() has",
            "\t\t\t * cleared *pmd but not decremented compound_mapcount().",
            "\t\t\t */",
            "\t\t\tif ((pvmw->flags & PVMW_SYNC) &&",
            "\t\t\t    thp_vma_suitable_order(vma, pvmw->address,",
            "\t\t\t\t\t\t   PMD_ORDER) &&",
            "\t\t\t    (pvmw->nr_pages >= HPAGE_PMD_NR)) {",
            "\t\t\t\tspinlock_t *ptl = pmd_lock(mm, pvmw->pmd);",
            "",
            "\t\t\t\tspin_unlock(ptl);",
            "\t\t\t}",
            "\t\t\tstep_forward(pvmw, PMD_SIZE);",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tif (!map_pte(pvmw, &ptl)) {",
            "\t\t\tif (!pvmw->pte)",
            "\t\t\t\tgoto restart;",
            "\t\t\tgoto next_pte;",
            "\t\t}",
            "this_pte:",
            "\t\tif (check_pte(pvmw, 1))",
            "\t\t\treturn true;",
            "next_pte:",
            "\t\tdo {",
            "\t\t\tpvmw->address += PAGE_SIZE;",
            "\t\t\tif (pvmw->address >= end)",
            "\t\t\t\treturn not_found(pvmw);",
            "\t\t\t/* Did we cross page table boundary? */",
            "\t\t\tif ((pvmw->address & (PMD_SIZE - PAGE_SIZE)) == 0) {",
            "\t\t\t\tif (pvmw->ptl) {",
            "\t\t\t\t\tspin_unlock(pvmw->ptl);",
            "\t\t\t\t\tpvmw->ptl = NULL;",
            "\t\t\t\t}",
            "\t\t\t\tpte_unmap(pvmw->pte);",
            "\t\t\t\tpvmw->pte = NULL;",
            "\t\t\t\tgoto restart;",
            "\t\t\t}",
            "\t\t\tpvmw->pte++;",
            "\t\t} while (pte_none(ptep_get(pvmw->pte)));",
            "",
            "\t\tif (!pvmw->ptl) {",
            "\t\t\tpvmw->ptl = ptl;",
            "\t\t\tspin_lock(pvmw->ptl);",
            "\t\t}",
            "\t\tgoto this_pte;",
            "\t} while (pvmw->address < end);",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "check_pmd, step_forward, page_vma_mapped_walk",
          "description": "遍历页表层级（PGD/P4D/PUD/PMD），处理大页（HugeTLB）及迁移页表项，协调锁和地址推进。",
          "similarity": 0.5541533827781677
        },
        {
          "chunk_id": 1,
          "file_path": "mm/page_vma_mapped.c",
          "start_line": 10,
          "end_line": 111,
          "content": [
            "static inline bool not_found(struct page_vma_mapped_walk *pvmw)",
            "{",
            "\tpage_vma_mapped_walk_done(pvmw);",
            "\treturn false;",
            "}",
            "static bool map_pte(struct page_vma_mapped_walk *pvmw, spinlock_t **ptlp)",
            "{",
            "\tpte_t ptent;",
            "",
            "\tif (pvmw->flags & PVMW_SYNC) {",
            "\t\t/* Use the stricter lookup */",
            "\t\tpvmw->pte = pte_offset_map_lock(pvmw->vma->vm_mm, pvmw->pmd,",
            "\t\t\t\t\t\tpvmw->address, &pvmw->ptl);",
            "\t\t*ptlp = pvmw->ptl;",
            "\t\treturn !!pvmw->pte;",
            "\t}",
            "",
            "\t/*",
            "\t * It is important to return the ptl corresponding to pte,",
            "\t * in case *pvmw->pmd changes underneath us; so we need to",
            "\t * return it even when choosing not to lock, in case caller",
            "\t * proceeds to loop over next ptes, and finds a match later.",
            "\t * Though, in most cases, page lock already protects this.",
            "\t */",
            "\tpvmw->pte = pte_offset_map_nolock(pvmw->vma->vm_mm, pvmw->pmd,",
            "\t\t\t\t\t  pvmw->address, ptlp);",
            "\tif (!pvmw->pte)",
            "\t\treturn false;",
            "",
            "\tptent = ptep_get(pvmw->pte);",
            "",
            "\tif (pvmw->flags & PVMW_MIGRATION) {",
            "\t\tif (!is_swap_pte(ptent))",
            "\t\t\treturn false;",
            "\t} else if (is_swap_pte(ptent)) {",
            "\t\tswp_entry_t entry;",
            "\t\t/*",
            "\t\t * Handle un-addressable ZONE_DEVICE memory.",
            "\t\t *",
            "\t\t * We get here when we are trying to unmap a private",
            "\t\t * device page from the process address space. Such",
            "\t\t * page is not CPU accessible and thus is mapped as",
            "\t\t * a special swap entry, nonetheless it still does",
            "\t\t * count as a valid regular mapping for the page",
            "\t\t * (and is accounted as such in page maps count).",
            "\t\t *",
            "\t\t * So handle this special case as if it was a normal",
            "\t\t * page mapping ie lock CPU page table and return true.",
            "\t\t *",
            "\t\t * For more details on device private memory see HMM",
            "\t\t * (include/linux/hmm.h or mm/hmm.c).",
            "\t\t */",
            "\t\tentry = pte_to_swp_entry(ptent);",
            "\t\tif (!is_device_private_entry(entry) &&",
            "\t\t    !is_device_exclusive_entry(entry))",
            "\t\t\treturn false;",
            "\t} else if (!pte_present(ptent)) {",
            "\t\treturn false;",
            "\t}",
            "\tpvmw->ptl = *ptlp;",
            "\tspin_lock(pvmw->ptl);",
            "\treturn true;",
            "}",
            "static bool check_pte(struct page_vma_mapped_walk *pvmw, unsigned long pte_nr)",
            "{",
            "\tunsigned long pfn;",
            "\tpte_t ptent = ptep_get(pvmw->pte);",
            "",
            "\tif (pvmw->flags & PVMW_MIGRATION) {",
            "\t\tswp_entry_t entry;",
            "\t\tif (!is_swap_pte(ptent))",
            "\t\t\treturn false;",
            "\t\tentry = pte_to_swp_entry(ptent);",
            "",
            "\t\tif (!is_migration_entry(entry) &&",
            "\t\t    !is_device_exclusive_entry(entry))",
            "\t\t\treturn false;",
            "",
            "\t\tpfn = swp_offset_pfn(entry);",
            "\t} else if (is_swap_pte(ptent)) {",
            "\t\tswp_entry_t entry;",
            "",
            "\t\t/* Handle un-addressable ZONE_DEVICE memory */",
            "\t\tentry = pte_to_swp_entry(ptent);",
            "\t\tif (!is_device_private_entry(entry) &&",
            "\t\t    !is_device_exclusive_entry(entry))",
            "\t\t\treturn false;",
            "",
            "\t\tpfn = swp_offset_pfn(entry);",
            "\t} else {",
            "\t\tif (!pte_present(ptent))",
            "\t\t\treturn false;",
            "",
            "\t\tpfn = pte_pfn(ptent);",
            "\t}",
            "",
            "\tif ((pfn + pte_nr - 1) < pvmw->pfn)",
            "\t\treturn false;",
            "\tif (pfn > (pvmw->pfn + pvmw->nr_pages - 1))",
            "\t\treturn false;",
            "\treturn true;",
            "}"
          ],
          "function_name": "not_found, map_pte, check_pte",
          "description": "实现页表项查找与验证逻辑，map_pte处理锁和交换页检查，check_pte验证页表项有效性。",
          "similarity": 0.5470112562179565
        },
        {
          "chunk_id": 0,
          "file_path": "mm/page_vma_mapped.c",
          "start_line": 1,
          "end_line": 9,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/mm.h>",
            "#include <linux/rmap.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/swapops.h>",
            "",
            "#include \"internal.h\"",
            ""
          ],
          "function_name": null,
          "description": "包含页表遍历所需头文件及内部声明，提供内存管理和页表操作的基础接口。",
          "similarity": 0.5364925861358643
        },
        {
          "chunk_id": 3,
          "file_path": "mm/page_vma_mapped.c",
          "start_line": 333,
          "end_line": 352,
          "content": [
            "unsigned long page_mapped_in_vma(struct page *page, struct vm_area_struct *vma)",
            "{",
            "\tstruct folio *folio = page_folio(page);",
            "\tpgoff_t pgoff = folio->index + folio_page_idx(folio, page);",
            "\tstruct page_vma_mapped_walk pvmw = {",
            "\t\t.pfn = page_to_pfn(page),",
            "\t\t.nr_pages = 1,",
            "\t\t.vma = vma,",
            "\t\t.flags = PVMW_SYNC,",
            "\t};",
            "",
            "\tpvmw.address = vma_address(vma, pgoff, 1);",
            "\tif (pvmw.address == -EFAULT)",
            "\t\tgoto out;",
            "\tif (!page_vma_mapped_walk(&pvmw))",
            "\t\treturn -EFAULT;",
            "\tpage_vma_mapped_walk_done(&pvmw);",
            "out:",
            "\treturn pvmw.address;",
            "}"
          ],
          "function_name": "page_mapped_in_vma",
          "description": "通过页表遍历检查指定物理页面是否被映射到给定VMA区域，返回对应虚拟地址或错误码。",
          "similarity": 0.5303572416305542
        }
      ]
    },
    {
      "source_file": "mm/damon/paddr.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:49:43\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `damon\\paddr.c`\n\n---\n\n# `damon/paddr.c` 技术文档\n\n## 1. 文件概述\n\n`damon/paddr.c` 是 Linux 内核中 DAMON（Data Access MONitor）子系统的一部分，专门用于监控**物理地址空间**中的内存访问行为。该文件实现了针对物理页的访问检测、老化标记、访问状态检查以及基于策略的操作（如 pageout、LRU 调整等），为 DAMON 提供了面向物理内存的操作原语（primitives）。它注册了一组 `damon_operations`，使 DAMON 能够在不依赖虚拟地址映射的情况下直接对物理页进行监控和管理。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数名 | 功能说明 |\n|--------|--------|\n| `damon_pa_mkold()` | 将指定物理地址对应的 folio 标记为“未被访问”（老化），通过遍历其所有虚拟映射并清除 PTE/PMD 的 young 位，同时设置 folio idle 标志。 |\n| `damon_pa_young()` | 检查指定物理地址对应的 folio 是否近期被访问过，通过检查 PTE/PMD 的 young 位、folio idle 状态及 MMU notifier 的 young 状态。 |\n| `__damon_pa_prepare_access_check()` / `damon_pa_prepare_access_checks()` | 为每个监控区域随机选择一个采样地址，并调用 `damon_pa_mkold()` 进行预老化，为下一轮访问检测做准备。 |\n| `__damon_pa_check_access()` / `damon_pa_check_accesses()` | 检查各区域采样地址是否被访问，若被访问则递增 `nr_accesses`；支持缓存上一次检查结果以提升性能。 |\n| `damos_pa_filter_out()` / `__damos_pa_filter_out()` | 根据 DAMOS（DAMON Operation Scheme）过滤器（如匿名页、memcg ID）判断是否应跳过对某 folio 的操作。 |\n| `damon_pa_pageout()` | 对区域内所有符合条件的 folio 执行 pageout（回收到 swap 或释放），通过隔离 LRU 并调用 `reclaim_pages()`。 |\n| `damon_pa_mark_accessed()` / `damon_pa_deactivate_pages()` | 分别将 folio 标记为“已访问”（提升 LRU 优先级）或“非活跃”（降低 LRU 优先级）。 |\n| `damon_pa_apply_scheme()` | 根据 DAMOS 策略动作（如 `PAGEOUT`、`LRU_PRIO`、`LRU_DEPRIO`）执行对应操作。 |\n| `damon_pa_scheme_score()` | 为不同 DAMOS 动作返回评分（hot/cold），用于策略排序。 |\n| `damon_pa_initcall()` | 模块初始化函数，注册 `DAMON_OPS_PADDR` 操作集。 |\n\n### 关键数据结构\n\n- **`struct damon_operations`**：定义了 DAMON 物理地址监控所需的一组回调函数，ID 为 `DAMON_OPS_PADDR`。\n- **`struct rmap_walk_control`**：用于遍历 folio 的反向映射（rmap），以访问其所有虚拟地址映射。\n\n## 3. 关键实现\n\n### 访问检测机制\n- **预老化（Prepare）**：在每次采样周期开始前，随机选取区域内的一个物理地址，通过 `damon_pa_mkold()` 清除其所有虚拟映射的 young 位，并设置 folio idle 标志。\n- **访问检查（Check）**：在周期结束时，通过 `damon_pa_young()` 检查该地址是否被访问。检查逻辑包括：\n  - PTE/PMD 的 `young` 位是否置位；\n  - folio 的 `idle` 标志是否未设置；\n  - 通过 `mmu_notifier_test_young()` 查询硬件或架构特定的访问状态。\n- **结果缓存优化**：`__damon_pa_check_access()` 缓存上一次检查的物理地址、folio 大小和访问结果，若当前采样地址落在同一 folio 内，则复用结果，避免重复遍历 rmap。\n\n### 反向映射遍历\n- 使用 `page_vma_mapped_walk()` 遍历 folio 的所有 VMA 映射，分别处理 PTE 和 PMD（透明大页）层级。\n- 对于非匿名页或 KSM 页，需加 folio 锁以保证 rmap 遍历时的一致性。\n\n### DAMOS 策略执行\n- **Pageout**：隔离 folio 到临时链表，调用 `reclaim_pages()` 回收。\n- **LRU 调整**：通过 `folio_mark_accessed()`（提升到 active LRU）或 `folio_deactivate()`（降级到 inactive LRU）调整页面优先级。\n- **过滤机制**：支持按匿名页类型或 memcg ID 过滤目标页面，确保策略仅作用于指定内存。\n\n### 透明大页（THP）支持\n- 在 `__damon_pa_young()` 中，通过 `#ifdef CONFIG_TRANSPARENT_HUGEPAGE` 条件编译支持 PMD 层级的 young 位检查，若未启用 THP 则触发 `WARN_ON_ONCE(1)`。\n\n## 4. 依赖关系\n\n- **内核头文件依赖**：\n  - `<linux/page_idle.h>`：提供 `folio_set_idle()`、`folio_test_idle()` 等接口。\n  - `<linux/rmap.h>`：提供反向映射遍历功能（`rmap_walk`、`page_vma_mapped_walk`）。\n  - `<linux/mmu_notifier.h>`：用于跨架构的 young 状态查询。\n  - `<linux/swap.h>`：提供 `reclaim_pages()` 用于页面回收。\n  - `<linux/pagemap.h>`：提供 folio 相关操作。\n- **DAMON 内部依赖**：\n  - `../internal.h`：包含 DAMON 核心数据结构和辅助函数（如 `damon_get_folio()`、`damon_rand()`）。\n  - `\"ops-common.h\"`：提供通用操作辅助函数（如 `damon_ptep_mkold()`、`damon_pmdp_mkold()`）。\n- **配置依赖**：透明大页（`CONFIG_TRANSPARENT_HUGEPAGE`）为可选依赖，影响 PMD 层级访问检查。\n\n## 5. 使用场景\n\n- **物理内存监控**：当系统需要监控物理内存的访问热度（而非进程虚拟地址空间）时使用，例如 NUMA 节点内存分析、设备内存（如 CXL）监控。\n- **内存回收优化**：结合 DAMOS 策略，自动识别冷物理页并执行 pageout 或 LRU 降级，提升内存利用率。\n- **内核内存管理研究**：为内存子系统提供低开销的物理页访问行为数据，用于开发新的内存管理算法。\n- **容器/虚拟化环境**：通过 memcg 过滤器，对特定 cgroup 的物理内存使用情况进行监控和调控。\n\n该模块通过 `subsys_initcall` 在内核启动早期注册，可通过 DAMON 用户接口（如 debugfs 或 tracefs）激活 `paddr` 操作模式。",
      "similarity": 0.5524871945381165,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/damon/paddr.c",
          "start_line": 151,
          "end_line": 273,
          "content": [
            "static void __damon_pa_check_access(struct damon_region *r)",
            "{",
            "\tstatic unsigned long last_addr;",
            "\tstatic unsigned long last_folio_sz = PAGE_SIZE;",
            "\tstatic bool last_accessed;",
            "",
            "\t/* If the region is in the last checked page, reuse the result */",
            "\tif (ALIGN_DOWN(last_addr, last_folio_sz) ==",
            "\t\t\t\tALIGN_DOWN(r->sampling_addr, last_folio_sz)) {",
            "\t\tif (last_accessed)",
            "\t\t\tr->nr_accesses++;",
            "\t\treturn;",
            "\t}",
            "",
            "\tlast_accessed = damon_pa_young(r->sampling_addr, &last_folio_sz);",
            "\tif (last_accessed)",
            "\t\tr->nr_accesses++;",
            "",
            "\tlast_addr = r->sampling_addr;",
            "}",
            "static unsigned int damon_pa_check_accesses(struct damon_ctx *ctx)",
            "{",
            "\tstruct damon_target *t;",
            "\tstruct damon_region *r;",
            "\tunsigned int max_nr_accesses = 0;",
            "",
            "\tdamon_for_each_target(t, ctx) {",
            "\t\tdamon_for_each_region(r, t) {",
            "\t\t\t__damon_pa_check_access(r);",
            "\t\t\tmax_nr_accesses = max(r->nr_accesses, max_nr_accesses);",
            "\t\t}",
            "\t}",
            "",
            "\treturn max_nr_accesses;",
            "}",
            "static bool __damos_pa_filter_out(struct damos_filter *filter,",
            "\t\tstruct folio *folio)",
            "{",
            "\tbool matched = false;",
            "\tstruct mem_cgroup *memcg;",
            "",
            "\tswitch (filter->type) {",
            "\tcase DAMOS_FILTER_TYPE_ANON:",
            "\t\tmatched = folio_test_anon(folio);",
            "\t\tbreak;",
            "\tcase DAMOS_FILTER_TYPE_MEMCG:",
            "\t\trcu_read_lock();",
            "\t\tmemcg = folio_memcg_check(folio);",
            "\t\tif (!memcg)",
            "\t\t\tmatched = false;",
            "\t\telse",
            "\t\t\tmatched = filter->memcg_id == mem_cgroup_id(memcg);",
            "\t\trcu_read_unlock();",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn matched == filter->matching;",
            "}",
            "static bool damos_pa_filter_out(struct damos *scheme, struct folio *folio)",
            "{",
            "\tstruct damos_filter *filter;",
            "",
            "\tdamos_for_each_filter(filter, scheme) {",
            "\t\tif (__damos_pa_filter_out(filter, folio))",
            "\t\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "static unsigned long damon_pa_pageout(struct damon_region *r, struct damos *s)",
            "{",
            "\tunsigned long addr, applied;",
            "\tLIST_HEAD(folio_list);",
            "",
            "\tfor (addr = r->ar.start; addr < r->ar.end; addr += PAGE_SIZE) {",
            "\t\tstruct folio *folio = damon_get_folio(PHYS_PFN(addr));",
            "",
            "\t\tif (!folio)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (damos_pa_filter_out(s, folio))",
            "\t\t\tgoto put_folio;",
            "",
            "\t\tfolio_clear_referenced(folio);",
            "\t\tfolio_test_clear_young(folio);",
            "\t\tif (!folio_isolate_lru(folio))",
            "\t\t\tgoto put_folio;",
            "\t\tif (folio_test_unevictable(folio))",
            "\t\t\tfolio_putback_lru(folio);",
            "\t\telse",
            "\t\t\tlist_add(&folio->lru, &folio_list);",
            "put_folio:",
            "\t\tfolio_put(folio);",
            "\t}",
            "\tapplied = reclaim_pages(&folio_list, false);",
            "\tcond_resched();",
            "\treturn applied * PAGE_SIZE;",
            "}",
            "static inline unsigned long damon_pa_mark_accessed_or_deactivate(",
            "\t\tstruct damon_region *r, struct damos *s, bool mark_accessed)",
            "{",
            "\tunsigned long addr, applied = 0;",
            "",
            "\tfor (addr = r->ar.start; addr < r->ar.end; addr += PAGE_SIZE) {",
            "\t\tstruct folio *folio = damon_get_folio(PHYS_PFN(addr));",
            "",
            "\t\tif (!folio)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (damos_pa_filter_out(s, folio))",
            "\t\t\tgoto put_folio;",
            "",
            "\t\tif (mark_accessed)",
            "\t\t\tfolio_mark_accessed(folio);",
            "\t\telse",
            "\t\t\tfolio_deactivate(folio);",
            "\t\tapplied += folio_nr_pages(folio);",
            "put_folio:",
            "\t\tfolio_put(folio);",
            "\t}",
            "\treturn applied * PAGE_SIZE;",
            "}"
          ],
          "function_name": "__damon_pa_check_access, damon_pa_check_accesses, __damos_pa_filter_out, damos_pa_filter_out, damon_pa_pageout, damon_pa_mark_accessed_or_deactivate",
          "description": "执行页面访问统计与过滤策略，通过memcg标识筛选页面，实现页面回收(PageOut)与标记/失效操作，隔离LRU列表并计算回收页数。",
          "similarity": 0.5686998963356018
        },
        {
          "chunk_id": 1,
          "file_path": "mm/damon/paddr.c",
          "start_line": 19,
          "end_line": 144,
          "content": [
            "static bool __damon_pa_mkold(struct folio *folio, struct vm_area_struct *vma,",
            "\t\tunsigned long addr, void *arg)",
            "{",
            "\tDEFINE_FOLIO_VMA_WALK(pvmw, folio, vma, addr, 0);",
            "",
            "\twhile (page_vma_mapped_walk(&pvmw)) {",
            "\t\taddr = pvmw.address;",
            "\t\tif (pvmw.pte)",
            "\t\t\tdamon_ptep_mkold(pvmw.pte, vma, addr);",
            "\t\telse",
            "\t\t\tdamon_pmdp_mkold(pvmw.pmd, vma, addr);",
            "\t}",
            "\treturn true;",
            "}",
            "static void damon_pa_mkold(unsigned long paddr)",
            "{",
            "\tstruct folio *folio = damon_get_folio(PHYS_PFN(paddr));",
            "\tstruct rmap_walk_control rwc = {",
            "\t\t.rmap_one = __damon_pa_mkold,",
            "\t\t.anon_lock = folio_lock_anon_vma_read,",
            "\t};",
            "\tbool need_lock;",
            "",
            "\tif (!folio)",
            "\t\treturn;",
            "",
            "\tif (!folio_mapped(folio) || !folio_raw_mapping(folio)) {",
            "\t\tfolio_set_idle(folio);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tneed_lock = !folio_test_anon(folio) || folio_test_ksm(folio);",
            "\tif (need_lock && !folio_trylock(folio))",
            "\t\tgoto out;",
            "",
            "\trmap_walk(folio, &rwc);",
            "",
            "\tif (need_lock)",
            "\t\tfolio_unlock(folio);",
            "",
            "out:",
            "\tfolio_put(folio);",
            "}",
            "static void __damon_pa_prepare_access_check(struct damon_region *r)",
            "{",
            "\tr->sampling_addr = damon_rand(r->ar.start, r->ar.end);",
            "",
            "\tdamon_pa_mkold(r->sampling_addr);",
            "}",
            "static void damon_pa_prepare_access_checks(struct damon_ctx *ctx)",
            "{",
            "\tstruct damon_target *t;",
            "\tstruct damon_region *r;",
            "",
            "\tdamon_for_each_target(t, ctx) {",
            "\t\tdamon_for_each_region(r, t)",
            "\t\t\t__damon_pa_prepare_access_check(r);",
            "\t}",
            "}",
            "static bool __damon_pa_young(struct folio *folio, struct vm_area_struct *vma,",
            "\t\tunsigned long addr, void *arg)",
            "{",
            "\tbool *accessed = arg;",
            "\tDEFINE_FOLIO_VMA_WALK(pvmw, folio, vma, addr, 0);",
            "",
            "\t*accessed = false;",
            "\twhile (page_vma_mapped_walk(&pvmw)) {",
            "\t\taddr = pvmw.address;",
            "\t\tif (pvmw.pte) {",
            "\t\t\t*accessed = pte_young(ptep_get(pvmw.pte)) ||",
            "\t\t\t\t!folio_test_idle(folio) ||",
            "\t\t\t\tmmu_notifier_test_young(vma->vm_mm, addr);",
            "\t\t} else {",
            "#ifdef CONFIG_TRANSPARENT_HUGEPAGE",
            "\t\t\t*accessed = pmd_young(pmdp_get(pvmw.pmd)) ||",
            "\t\t\t\t!folio_test_idle(folio) ||",
            "\t\t\t\tmmu_notifier_test_young(vma->vm_mm, addr);",
            "#else",
            "\t\t\tWARN_ON_ONCE(1);",
            "#endif\t/* CONFIG_TRANSPARENT_HUGEPAGE */",
            "\t\t}",
            "\t\tif (*accessed) {",
            "\t\t\tpage_vma_mapped_walk_done(&pvmw);",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "",
            "\t/* If accessed, stop walking */",
            "\treturn *accessed == false;",
            "}",
            "static bool damon_pa_young(unsigned long paddr, unsigned long *folio_sz)",
            "{",
            "\tstruct folio *folio = damon_get_folio(PHYS_PFN(paddr));",
            "\tbool accessed = false;",
            "\tstruct rmap_walk_control rwc = {",
            "\t\t.arg = &accessed,",
            "\t\t.rmap_one = __damon_pa_young,",
            "\t\t.anon_lock = folio_lock_anon_vma_read,",
            "\t};",
            "\tbool need_lock;",
            "",
            "\tif (!folio)",
            "\t\treturn false;",
            "",
            "\tif (!folio_mapped(folio) || !folio_raw_mapping(folio)) {",
            "\t\tif (folio_test_idle(folio))",
            "\t\t\taccessed = false;",
            "\t\telse",
            "\t\t\taccessed = true;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tneed_lock = !folio_test_anon(folio) || folio_test_ksm(folio);",
            "\tif (need_lock && !folio_trylock(folio))",
            "\t\tgoto out;",
            "",
            "\trmap_walk(folio, &rwc);",
            "",
            "\tif (need_lock)",
            "\t\tfolio_unlock(folio);",
            "",
            "out:",
            "\t*folio_sz = folio_size(folio);",
            "\tfolio_put(folio);",
            "\treturn accessed;",
            "}"
          ],
          "function_name": "__damon_pa_mkold, damon_pa_mkold, __damon_pa_prepare_access_check, damon_pa_prepare_access_checks, __damon_pa_young, damon_pa_young",
          "description": "实现页面访问状态更新与检测逻辑，通过rmap遍历页表项进行mkold操作，检测页面young状态以评估访问频率，支持匿名/ksm页面锁机制。",
          "similarity": 0.5439592599868774
        },
        {
          "chunk_id": 3,
          "file_path": "mm/damon/paddr.c",
          "start_line": 283,
          "end_line": 345,
          "content": [
            "static unsigned long damon_pa_mark_accessed(struct damon_region *r,",
            "\tstruct damos *s)",
            "{",
            "\treturn damon_pa_mark_accessed_or_deactivate(r, s, true);",
            "}",
            "static unsigned long damon_pa_deactivate_pages(struct damon_region *r,",
            "\tstruct damos *s)",
            "{",
            "\treturn damon_pa_mark_accessed_or_deactivate(r, s, false);",
            "}",
            "static unsigned long damon_pa_apply_scheme(struct damon_ctx *ctx,",
            "\t\tstruct damon_target *t, struct damon_region *r,",
            "\t\tstruct damos *scheme)",
            "{",
            "\tswitch (scheme->action) {",
            "\tcase DAMOS_PAGEOUT:",
            "\t\treturn damon_pa_pageout(r, scheme);",
            "\tcase DAMOS_LRU_PRIO:",
            "\t\treturn damon_pa_mark_accessed(r, scheme);",
            "\tcase DAMOS_LRU_DEPRIO:",
            "\t\treturn damon_pa_deactivate_pages(r, scheme);",
            "\tcase DAMOS_STAT:",
            "\t\tbreak;",
            "\tdefault:",
            "\t\t/* DAMOS actions that not yet supported by 'paddr'. */",
            "\t\tbreak;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int damon_pa_scheme_score(struct damon_ctx *context,",
            "\t\tstruct damon_target *t, struct damon_region *r,",
            "\t\tstruct damos *scheme)",
            "{",
            "\tswitch (scheme->action) {",
            "\tcase DAMOS_PAGEOUT:",
            "\t\treturn damon_cold_score(context, r, scheme);",
            "\tcase DAMOS_LRU_PRIO:",
            "\t\treturn damon_hot_score(context, r, scheme);",
            "\tcase DAMOS_LRU_DEPRIO:",
            "\t\treturn damon_cold_score(context, r, scheme);",
            "\tdefault:",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn DAMOS_MAX_SCORE;",
            "}",
            "static int __init damon_pa_initcall(void)",
            "{",
            "\tstruct damon_operations ops = {",
            "\t\t.id = DAMON_OPS_PADDR,",
            "\t\t.init = NULL,",
            "\t\t.update = NULL,",
            "\t\t.prepare_access_checks = damon_pa_prepare_access_checks,",
            "\t\t.check_accesses = damon_pa_check_accesses,",
            "\t\t.reset_aggregated = NULL,",
            "\t\t.target_valid = NULL,",
            "\t\t.cleanup = NULL,",
            "\t\t.apply_scheme = damon_pa_apply_scheme,",
            "\t\t.get_scheme_score = damon_pa_scheme_score,",
            "\t};",
            "",
            "\treturn damon_register_ops(&ops);",
            "};"
          ],
          "function_name": "damon_pa_mark_accessed, damon_pa_deactivate_pages, damon_pa_apply_scheme, damon_pa_scheme_score, damon_pa_initcall",
          "description": "集成DAMON操作接口，注册物理地址空间处理模块，实现不同策略（PageOut/LRU）的差异化处理，通过score函数评估区域优先级，完成模块初始化注册。",
          "similarity": 0.5205079913139343
        },
        {
          "chunk_id": 0,
          "file_path": "mm/damon/paddr.c",
          "start_line": 1,
          "end_line": 18,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * DAMON Primitives for The Physical Address Space",
            " *",
            " * Author: SeongJae Park <sj@kernel.org>",
            " */",
            "",
            "#define pr_fmt(fmt) \"damon-pa: \" fmt",
            "",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/page_idle.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/rmap.h>",
            "#include <linux/swap.h>",
            "",
            "#include \"../internal.h\"",
            "#include \"ops-common.h\"",
            ""
          ],
          "function_name": null,
          "description": "定义DAMON物理地址空间模块的头部信息，包含许可证声明、内核头文件及内部依赖，为后续实现提供基础依赖和宏定义。",
          "similarity": 0.4016251564025879
        }
      ]
    },
    {
      "source_file": "mm/swap.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:25:49\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `swap.c`\n\n---\n\n# swap.c 技术文档\n\n## 1. 文件概述\n\n`swap.c` 是 Linux 内核内存管理子系统（MM）中的核心文件之一，主要负责页面回收（page reclaim）、LRU（Least Recently Used）链表管理、页面释放以及与交换（swap）机制相关的底层支持逻辑。尽管文件名为 `swap.c`，但其功能不仅限于交换，而是涵盖了通用的页面生命周期管理、LRU 链表操作、页面引用计数释放、可回收性判断等关键内存管理任务。该文件为页面缓存（page cache）、匿名页（anonymous pages）和大页（huge pages）提供统一的释放与 LRU 管理接口。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `page_cluster`：控制一次 I/O 操作中尝试换入/换出的页面数量（以 2 的幂表示），默认值由系统配置决定。\n- `page_cluster_max`：`page_cluster` 的最大允许值（31，即最多 2^31 页，实际受架构限制）。\n\n### 主要数据结构\n- `struct lru_rotate`：每个 CPU 私有的结构，用于在中断禁用上下文中批量处理需移至 LRU 链表尾部的页面（如 `folio_rotate_reclaimable` 场景）。\n- `struct cpu_fbatches`：每个 CPU 私有的 folio 批处理结构，包含多个 folio_batch，用于高效地向 LRU 链表添加、停用或激活页面，避免频繁获取 LRU 锁。\n\n### 主要函数\n- `__folio_put()`：释放一个 folio 的核心函数，根据 folio 类型（设备内存、大页、普通页）调用相应的释放路径。\n- `put_pages_list()`：批量释放通过 `lru` 字段链接的页面列表，常用于网络子系统或 compound page 释放。\n- `lru_add_fn()`：将 folio 添加到对应 LRU 链表的回调函数，处理可回收性（evictable/unevictable）状态转换和统计计数。\n- `folio_batch_move_lru()`：批量执行 LRU 操作（如添加、移动），在持有 LRU 锁期间完成所有 folio 的处理。\n- `folio_rotate_reclaimable()`：在写回完成后，若页面仍可回收，则将其移至 inactive LRU 链表尾部，以延迟其被回收的时间。\n- `lru_note_cost()`：记录 LRU 扫描过程中的 I/O 和旋转（rotation）成本，用于后续调整 anon/file LRU 的扫描比例。\n\n## 3. 关键实现\n\n### LRU 批处理机制\n为减少 LRU 锁竞争，内核采用 per-CPU 批处理（`folio_batch`）方式暂存待处理的 folio。当批处理满或遇到大页（`folio_test_large`）时，才批量获取 LRU 锁并执行操作（如 `lru_add_fn`）。这显著提升了高并发场景下的性能。\n\n### 可回收性管理\n页面是否可回收由 `folio_evictable()` 判断，主要依据是否被 mlock 锁定。在添加到 LRU 时：\n- 若页面变为可回收（原为 unevictable），则增加 `UNEVICTABLE_PGRESCUED` 统计；\n- 若页面不可回收，则清除 active 标志，设置 unevictable 标志，并重置 `mlock_count`，同时增加 `UNEVICTABLE_PGCULLED` 统计。\n\n### 页面释放路径\n`__folio_put()` 是 folio 引用计数归零后的释放入口：\n1. 设备内存 folio 调用 `free_zone_device_folio()`\n2. 大页 folio 调用 `free_huge_folio()`\n3. 普通 folio 先从 LRU 移除（若在 LRU 上），然后解绑内存控制组（memcg），最后调用 `free_unref_page()` 释放到伙伴系统。\n\n### LRU 旋转优化\n`folio_rotate_reclaimable()` 在写回结束时，若页面干净且未锁定，则将其移至 inactive LRU 尾部。此操作通过 per-CPU 的 `lru_rotate` 批处理完成，仅在必要时获取 LRU 锁，避免影响写回关键路径性能。\n\n### 成本跟踪\n`lru_note_cost()` 通过累加 `nr_io * SWAP_CLUSTER_MAX + nr_rotated` 来量化扫描成本，用于动态调整匿名页与文件页 LRU 的扫描比例，优化内存回收效率。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm.h>`、`<linux/pagevec.h>`、`\"internal.h\"` 等，使用伙伴系统、LRU 框架、内存控制组（memcg）等基础组件。\n- **交换子系统**：虽不直接实现 swap read/write，但为 `vmscan.c` 中的页面回收提供 LRU 操作接口，是 swap 机制的支撑模块。\n- **大页支持**：通过 `hugetlb.h` 与大页子系统交互，特殊处理大页释放。\n- **设备内存**：通过 `memremap.h` 支持持久内存（pmem）等 zone device 页面的释放。\n- **跟踪与统计**：使用 tracepoint（`trace/events/pagemap.h`）和 VM 统计（`kernel_stat.h`）进行性能分析。\n- **SMP 支持**：大量使用 per-CPU 变量（`DEFINE_PER_CPU`）和本地锁（`local_lock_t`）优化多核性能。\n\n## 5. 使用场景\n\n- **页面回收（Reclaim）**：当内存压力触发 kswapd 或 direct reclaim 时，`vmscan.c` 调用本文件的 LRU 操作函数来隔离、释放页面。\n- **页面缓存释放**：文件系统或网络子系统在释放 page cache 页面时，通过 `__folio_put()` 或 `put_pages_list()` 触发 LRU 移除和内存释放。\n- **写回完成处理**：块设备或文件系统在完成脏页写回后，调用 `folio_rotate_reclaimable()` 更新页面在 LRU 中的位置。\n- **内存控制组（cgroup）**：memcg 回收内存时，复用本文件的 LRU 批处理和 folio 释放逻辑。\n- **大页与设备内存管理**：透明大页（THP）或持久内存应用释放页面时，通过统一的 `__folio_put()` 接口分发到专用释放函数。\n- **系统调优**：管理员通过 `/proc/sys/vm/page-cluster` 调整 `page_cluster` 值，影响 swap 和 page cache 的 I/O 批量大小。",
      "similarity": 0.5482190847396851,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/swap.c",
          "start_line": 77,
          "end_line": 190,
          "content": [
            "static void __page_cache_release(struct folio *folio, struct lruvec **lruvecp,",
            "\t\tunsigned long *flagsp)",
            "{",
            "\tif (folio_test_lru(folio)) {",
            "\t\tfolio_lruvec_relock_irqsave(folio, lruvecp, flagsp);",
            "\t\tlruvec_del_folio(*lruvecp, folio);",
            "\t\t__folio_clear_lru_flags(folio);",
            "\t}",
            "}",
            "static void page_cache_release(struct folio *folio)",
            "{",
            "\tstruct lruvec *lruvec = NULL;",
            "\tunsigned long flags;",
            "",
            "\t__page_cache_release(folio, &lruvec, &flags);",
            "\tif (lruvec)",
            "\t\tunlock_page_lruvec_irqrestore(lruvec, flags);",
            "}",
            "void __folio_put(struct folio *folio)",
            "{",
            "\tif (unlikely(folio_is_zone_device(folio))) {",
            "\t\tfree_zone_device_folio(folio);",
            "\t\treturn;",
            "\t} else if (folio_test_hugetlb(folio)) {",
            "\t\tfree_huge_folio(folio);",
            "\t\treturn;",
            "\t}",
            "",
            "\tpage_cache_release(folio);",
            "\tfolio_unqueue_deferred_split(folio);",
            "\tmem_cgroup_uncharge(folio);",
            "\tfree_unref_page(&folio->page, folio_order(folio));",
            "}",
            "void put_pages_list(struct list_head *pages)",
            "{",
            "\tstruct folio_batch fbatch;",
            "\tstruct folio *folio, *next;",
            "",
            "\tfolio_batch_init(&fbatch);",
            "\tlist_for_each_entry_safe(folio, next, pages, lru) {",
            "\t\tif (!folio_put_testzero(folio))",
            "\t\t\tcontinue;",
            "\t\tif (folio_test_hugetlb(folio)) {",
            "\t\t\tfree_huge_folio(folio);",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\t/* LRU flag must be clear because it's passed using the lru */",
            "\t\tif (folio_batch_add(&fbatch, folio) > 0)",
            "\t\t\tcontinue;",
            "\t\tfree_unref_folios(&fbatch);",
            "\t}",
            "",
            "\tif (fbatch.nr)",
            "\t\tfree_unref_folios(&fbatch);",
            "\tINIT_LIST_HEAD(pages);",
            "}",
            "static void lru_add_fn(struct lruvec *lruvec, struct folio *folio)",
            "{",
            "\tint was_unevictable = folio_test_clear_unevictable(folio);",
            "\tlong nr_pages = folio_nr_pages(folio);",
            "",
            "\tVM_BUG_ON_FOLIO(folio_test_lru(folio), folio);",
            "",
            "\t/*",
            "\t * Is an smp_mb__after_atomic() still required here, before",
            "\t * folio_evictable() tests the mlocked flag, to rule out the possibility",
            "\t * of stranding an evictable folio on an unevictable LRU?  I think",
            "\t * not, because __munlock_folio() only clears the mlocked flag",
            "\t * while the LRU lock is held.",
            "\t *",
            "\t * (That is not true of __page_cache_release(), and not necessarily",
            "\t * true of folios_put(): but those only clear the mlocked flag after",
            "\t * folio_put_testzero() has excluded any other users of the folio.)",
            "\t */",
            "\tif (folio_evictable(folio)) {",
            "\t\tif (was_unevictable)",
            "\t\t\t__count_vm_events(UNEVICTABLE_PGRESCUED, nr_pages);",
            "\t} else {",
            "\t\tfolio_clear_active(folio);",
            "\t\tfolio_set_unevictable(folio);",
            "\t\t/*",
            "\t\t * folio->mlock_count = !!folio_test_mlocked(folio)?",
            "\t\t * But that leaves __mlock_folio() in doubt whether another",
            "\t\t * actor has already counted the mlock or not.  Err on the",
            "\t\t * safe side, underestimate, let page reclaim fix it, rather",
            "\t\t * than leaving a page on the unevictable LRU indefinitely.",
            "\t\t */",
            "\t\tfolio->mlock_count = 0;",
            "\t\tif (!was_unevictable)",
            "\t\t\t__count_vm_events(UNEVICTABLE_PGCULLED, nr_pages);",
            "\t}",
            "",
            "\tlruvec_add_folio(lruvec, folio);",
            "\ttrace_mm_lru_insertion(folio);",
            "}",
            "static void folio_batch_move_lru(struct folio_batch *fbatch, move_fn_t move_fn)",
            "{",
            "\tint i;",
            "\tstruct lruvec *lruvec = NULL;",
            "\tunsigned long flags = 0;",
            "",
            "\tfor (i = 0; i < folio_batch_count(fbatch); i++) {",
            "\t\tstruct folio *folio = fbatch->folios[i];",
            "",
            "\t\tfolio_lruvec_relock_irqsave(folio, &lruvec, &flags);",
            "\t\tmove_fn(lruvec, folio);",
            "",
            "\t\tfolio_set_lru(folio);",
            "\t}",
            "",
            "\tif (lruvec)",
            "\t\tunlock_page_lruvec_irqrestore(lruvec, flags);",
            "\tfolios_put(fbatch);",
            "}"
          ],
          "function_name": "__page_cache_release, page_cache_release, __folio_put, put_pages_list, lru_add_fn, folio_batch_move_lru",
          "description": "实现了页面缓存释放和LRU列表维护逻辑，包含__page_cache_release用于从LRU列表移除页面，page_cache_release处理普通页面释放流程，__folio_put负责释放非设备映射和大页，put_pages_list批量处理页面释放，lru_add_fn将页面添加到LRU列表并根据是否可交换设置相应标志。",
          "similarity": 0.5554051399230957
        },
        {
          "chunk_id": 4,
          "file_path": "mm/swap.c",
          "start_line": 496,
          "end_line": 600,
          "content": [
            "void folio_add_lru(struct folio *folio)",
            "{",
            "\tstruct folio_batch *fbatch;",
            "",
            "\tVM_BUG_ON_FOLIO(folio_test_active(folio) &&",
            "\t\t\tfolio_test_unevictable(folio), folio);",
            "\tVM_BUG_ON_FOLIO(folio_test_lru(folio), folio);",
            "",
            "\t/* see the comment in lru_gen_add_folio() */",
            "\tif (lru_gen_enabled() && !folio_test_unevictable(folio) &&",
            "\t    lru_gen_in_fault() && !(current->flags & PF_MEMALLOC))",
            "\t\tfolio_set_active(folio);",
            "",
            "\tfolio_get(folio);",
            "\tlocal_lock(&cpu_fbatches.lock);",
            "\tfbatch = this_cpu_ptr(&cpu_fbatches.lru_add);",
            "\tfolio_batch_add_and_move(fbatch, folio, lru_add_fn);",
            "\tlocal_unlock(&cpu_fbatches.lock);",
            "}",
            "void folio_add_lru_vma(struct folio *folio, struct vm_area_struct *vma)",
            "{",
            "\tVM_BUG_ON_FOLIO(folio_test_lru(folio), folio);",
            "",
            "\tif (unlikely((vma->vm_flags & (VM_LOCKED | VM_SPECIAL)) == VM_LOCKED))",
            "\t\tmlock_new_folio(folio);",
            "\telse",
            "\t\tfolio_add_lru(folio);",
            "}",
            "static void lru_deactivate_file_fn(struct lruvec *lruvec, struct folio *folio)",
            "{",
            "\tbool active = folio_test_active(folio);",
            "\tlong nr_pages = folio_nr_pages(folio);",
            "",
            "\tif (folio_test_unevictable(folio))",
            "\t\treturn;",
            "",
            "\t/* Some processes are using the folio */",
            "\tif (folio_mapped(folio))",
            "\t\treturn;",
            "",
            "\tlruvec_del_folio(lruvec, folio);",
            "\tfolio_clear_active(folio);",
            "\tfolio_clear_referenced(folio);",
            "",
            "\tif (folio_test_writeback(folio) || folio_test_dirty(folio)) {",
            "\t\t/*",
            "\t\t * Setting the reclaim flag could race with",
            "\t\t * folio_end_writeback() and confuse readahead.  But the",
            "\t\t * race window is _really_ small and  it's not a critical",
            "\t\t * problem.",
            "\t\t */",
            "\t\tlruvec_add_folio(lruvec, folio);",
            "\t\tfolio_set_reclaim(folio);",
            "\t} else {",
            "\t\t/*",
            "\t\t * The folio's writeback ended while it was in the batch.",
            "\t\t * We move that folio to the tail of the inactive list.",
            "\t\t */",
            "\t\tlruvec_add_folio_tail(lruvec, folio);",
            "\t\t__count_vm_events(PGROTATED, nr_pages);",
            "\t}",
            "",
            "\tif (active) {",
            "\t\t__count_vm_events(PGDEACTIVATE, nr_pages);",
            "\t\t__count_memcg_events(lruvec_memcg(lruvec), PGDEACTIVATE,",
            "\t\t\t\t     nr_pages);",
            "\t}",
            "}",
            "static void lru_deactivate_fn(struct lruvec *lruvec, struct folio *folio)",
            "{",
            "\tif (!folio_test_unevictable(folio) && (folio_test_active(folio) || lru_gen_enabled())) {",
            "\t\tlong nr_pages = folio_nr_pages(folio);",
            "",
            "\t\tlruvec_del_folio(lruvec, folio);",
            "\t\tfolio_clear_active(folio);",
            "\t\tfolio_clear_referenced(folio);",
            "\t\tlruvec_add_folio(lruvec, folio);",
            "",
            "\t\t__count_vm_events(PGDEACTIVATE, nr_pages);",
            "\t\t__count_memcg_events(lruvec_memcg(lruvec), PGDEACTIVATE,",
            "\t\t\t\t     nr_pages);",
            "\t}",
            "}",
            "static void lru_lazyfree_fn(struct lruvec *lruvec, struct folio *folio)",
            "{",
            "\tif (folio_test_anon(folio) && folio_test_swapbacked(folio) &&",
            "\t    !folio_test_swapcache(folio) && !folio_test_unevictable(folio)) {",
            "\t\tlong nr_pages = folio_nr_pages(folio);",
            "",
            "\t\tlruvec_del_folio(lruvec, folio);",
            "\t\tfolio_clear_active(folio);",
            "\t\tfolio_clear_referenced(folio);",
            "\t\t/*",
            "\t\t * Lazyfree folios are clean anonymous folios.  They have",
            "\t\t * the swapbacked flag cleared, to distinguish them from normal",
            "\t\t * anonymous folios",
            "\t\t */",
            "\t\tfolio_clear_swapbacked(folio);",
            "\t\tlruvec_add_folio(lruvec, folio);",
            "",
            "\t\t__count_vm_events(PGLAZYFREE, nr_pages);",
            "\t\t__count_memcg_events(lruvec_memcg(lruvec), PGLAZYFREE,",
            "\t\t\t\t     nr_pages);",
            "\t}",
            "}"
          ],
          "function_name": "folio_add_lru, folio_add_lru_vma, lru_deactivate_file_fn, lru_deactivate_fn, lru_lazyfree_fn",
          "description": "包含页面LRU列表插入和状态转换逻辑，folio_add_lru将页面加入LRU列表，folio_add_lru_vma处理VMA特定的页面添加，lru_deactivate_file_fn和lru_deactivate_fn处理文件页去激活操作，lru_lazyfree_fn处理延迟释放的匿名页面，均通过统一接口修改页面状态并触发统计事件。",
          "similarity": 0.5052171945571899
        },
        {
          "chunk_id": 3,
          "file_path": "mm/swap.c",
          "start_line": 332,
          "end_line": 460,
          "content": [
            "static void folio_activate_drain(int cpu)",
            "{",
            "\tstruct folio_batch *fbatch = &per_cpu(cpu_fbatches.activate, cpu);",
            "",
            "\tif (folio_batch_count(fbatch))",
            "\t\tfolio_batch_move_lru(fbatch, folio_activate_fn);",
            "}",
            "void folio_activate(struct folio *folio)",
            "{",
            "\tif (!folio_test_active(folio) && !folio_test_unevictable(folio)) {",
            "\t\tstruct folio_batch *fbatch;",
            "",
            "\t\tfolio_get(folio);",
            "\t\tif (!folio_test_clear_lru(folio)) {",
            "\t\t\tfolio_put(folio);",
            "\t\t\treturn;",
            "\t\t}",
            "",
            "\t\tlocal_lock(&cpu_fbatches.lock);",
            "\t\tfbatch = this_cpu_ptr(&cpu_fbatches.activate);",
            "\t\tfolio_batch_add_and_move(fbatch, folio, folio_activate_fn);",
            "\t\tlocal_unlock(&cpu_fbatches.lock);",
            "\t}",
            "}",
            "static inline void folio_activate_drain(int cpu)",
            "{",
            "}",
            "void folio_activate(struct folio *folio)",
            "{",
            "\tstruct lruvec *lruvec;",
            "",
            "\tif (folio_test_clear_lru(folio)) {",
            "\t\tlruvec = folio_lruvec_lock_irq(folio);",
            "\t\tfolio_activate_fn(lruvec, folio);",
            "\t\tunlock_page_lruvec_irq(lruvec);",
            "\t\tfolio_set_lru(folio);",
            "\t}",
            "}",
            "static void __lru_cache_activate_folio(struct folio *folio)",
            "{",
            "\tstruct folio_batch *fbatch;",
            "\tint i;",
            "",
            "\tlocal_lock(&cpu_fbatches.lock);",
            "\tfbatch = this_cpu_ptr(&cpu_fbatches.lru_add);",
            "",
            "\t/*",
            "\t * Search backwards on the optimistic assumption that the folio being",
            "\t * activated has just been added to this batch. Note that only",
            "\t * the local batch is examined as a !LRU folio could be in the",
            "\t * process of being released, reclaimed, migrated or on a remote",
            "\t * batch that is currently being drained. Furthermore, marking",
            "\t * a remote batch's folio active potentially hits a race where",
            "\t * a folio is marked active just after it is added to the inactive",
            "\t * list causing accounting errors and BUG_ON checks to trigger.",
            "\t */",
            "\tfor (i = folio_batch_count(fbatch) - 1; i >= 0; i--) {",
            "\t\tstruct folio *batch_folio = fbatch->folios[i];",
            "",
            "\t\tif (batch_folio == folio) {",
            "\t\t\tfolio_set_active(folio);",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "",
            "\tlocal_unlock(&cpu_fbatches.lock);",
            "}",
            "static void folio_inc_refs(struct folio *folio)",
            "{",
            "\tunsigned long new_flags, old_flags = READ_ONCE(folio->flags);",
            "",
            "\tif (folio_test_unevictable(folio))",
            "\t\treturn;",
            "",
            "\tif (!folio_test_referenced(folio)) {",
            "\t\tfolio_set_referenced(folio);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (!folio_test_workingset(folio)) {",
            "\t\tfolio_set_workingset(folio);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* see the comment on MAX_NR_TIERS */",
            "\tdo {",
            "\t\tnew_flags = old_flags & LRU_REFS_MASK;",
            "\t\tif (new_flags == LRU_REFS_MASK)",
            "\t\t\tbreak;",
            "",
            "\t\tnew_flags += BIT(LRU_REFS_PGOFF);",
            "\t\tnew_flags |= old_flags & ~LRU_REFS_MASK;",
            "\t} while (!try_cmpxchg(&folio->flags, &old_flags, new_flags));",
            "}",
            "static void folio_inc_refs(struct folio *folio)",
            "{",
            "}",
            "void folio_mark_accessed(struct folio *folio)",
            "{",
            "\tif (lru_gen_enabled()) {",
            "\t\tfolio_inc_refs(folio);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (!folio_test_referenced(folio)) {",
            "\t\tfolio_set_referenced(folio);",
            "\t} else if (folio_test_unevictable(folio)) {",
            "\t\t/*",
            "\t\t * Unevictable pages are on the \"LRU_UNEVICTABLE\" list. But,",
            "\t\t * this list is never rotated or maintained, so marking an",
            "\t\t * unevictable page accessed has no effect.",
            "\t\t */",
            "\t} else if (!folio_test_active(folio)) {",
            "\t\t/*",
            "\t\t * If the folio is on the LRU, queue it for activation via",
            "\t\t * cpu_fbatches.activate. Otherwise, assume the folio is in a",
            "\t\t * folio_batch, mark it active and it'll be moved to the active",
            "\t\t * LRU on the next drain.",
            "\t\t */",
            "\t\tif (folio_test_lru(folio))",
            "\t\t\tfolio_activate(folio);",
            "\t\telse",
            "\t\t\t__lru_cache_activate_folio(folio);",
            "\t\tfolio_clear_referenced(folio);",
            "\t\tworkingset_activation(folio);",
            "\t}",
            "\tif (folio_test_idle(folio))",
            "\t\tfolio_clear_idle(folio);",
            "}"
          ],
          "function_name": "folio_activate_drain, folio_activate, folio_activate_drain, folio_activate, __lru_cache_activate_folio, folio_inc_refs, folio_inc_refs, folio_mark_accessed",
          "description": "实现页面激活和引用计数管理，folio_activate_drain和folio_activate将页面从非活动列表转至活动列表，__lru_cache_activate_folio处理本地批次中的页面激活，folio_inc_refs更新页面引用标志，folio_mark_accessed标记页面访问状态并触发激活流程。",
          "similarity": 0.5041860342025757
        },
        {
          "chunk_id": 8,
          "file_path": "mm/swap.c",
          "start_line": 1079,
          "end_line": 1111,
          "content": [
            "void __folio_batch_release(struct folio_batch *fbatch)",
            "{",
            "\tif (!fbatch->percpu_pvec_drained) {",
            "\t\tlru_add_drain();",
            "\t\tfbatch->percpu_pvec_drained = true;",
            "\t}",
            "\tfolios_put(fbatch);",
            "}",
            "void folio_batch_remove_exceptionals(struct folio_batch *fbatch)",
            "{",
            "\tunsigned int i, j;",
            "",
            "\tfor (i = 0, j = 0; i < folio_batch_count(fbatch); i++) {",
            "\t\tstruct folio *folio = fbatch->folios[i];",
            "\t\tif (!xa_is_value(folio))",
            "\t\t\tfbatch->folios[j++] = folio;",
            "\t}",
            "\tfbatch->nr = j;",
            "}",
            "void __init swap_setup(void)",
            "{",
            "\tunsigned long megs = totalram_pages() >> (20 - PAGE_SHIFT);",
            "",
            "\t/* Use a smaller cluster for small-memory machines */",
            "\tif (megs < 16)",
            "\t\tpage_cluster = 2;",
            "\telse",
            "\t\tpage_cluster = 3;",
            "\t/*",
            "\t * Right now other parts of the system means that we",
            "\t * _really_ don't want to cluster much more",
            "\t */",
            "}"
          ],
          "function_name": "__folio_batch_release, folio_batch_remove_exceptionals, swap_setup",
          "description": "__folio_batch_release 标记并释放页面批次引用，folio_batch_remove_exceptionals 清理异常条目；swap_setup 初始化页面聚类参数，根据内存大小调整page_cluster值。",
          "similarity": 0.501179039478302
        },
        {
          "chunk_id": 2,
          "file_path": "mm/swap.c",
          "start_line": 211,
          "end_line": 317,
          "content": [
            "static void folio_batch_add_and_move(struct folio_batch *fbatch,",
            "\t\tstruct folio *folio, move_fn_t move_fn)",
            "{",
            "\tif (folio_batch_add(fbatch, folio) && !folio_test_large(folio) &&",
            "\t    !lru_cache_disabled())",
            "\t\treturn;",
            "\tfolio_batch_move_lru(fbatch, move_fn);",
            "}",
            "static void lru_move_tail_fn(struct lruvec *lruvec, struct folio *folio)",
            "{",
            "\tif (!folio_test_unevictable(folio)) {",
            "\t\tlruvec_del_folio(lruvec, folio);",
            "\t\tfolio_clear_active(folio);",
            "\t\tlruvec_add_folio_tail(lruvec, folio);",
            "\t\t__count_vm_events(PGROTATED, folio_nr_pages(folio));",
            "\t}",
            "}",
            "void folio_rotate_reclaimable(struct folio *folio)",
            "{",
            "\tif (!folio_test_locked(folio) && !folio_test_dirty(folio) &&",
            "\t    !folio_test_unevictable(folio)) {",
            "\t\tstruct folio_batch *fbatch;",
            "\t\tunsigned long flags;",
            "",
            "\t\tfolio_get(folio);",
            "\t\tif (!folio_test_clear_lru(folio)) {",
            "\t\t\tfolio_put(folio);",
            "\t\t\treturn;",
            "\t\t}",
            "",
            "\t\tlocal_lock_irqsave(&lru_rotate.lock, flags);",
            "\t\tfbatch = this_cpu_ptr(&lru_rotate.fbatch);",
            "\t\tfolio_batch_add_and_move(fbatch, folio, lru_move_tail_fn);",
            "\t\tlocal_unlock_irqrestore(&lru_rotate.lock, flags);",
            "\t}",
            "}",
            "void lru_note_cost(struct lruvec *lruvec, bool file,",
            "\t\t   unsigned int nr_io, unsigned int nr_rotated)",
            "{",
            "\tunsigned long cost;",
            "",
            "\t/*",
            "\t * Reflect the relative cost of incurring IO and spending CPU",
            "\t * time on rotations. This doesn't attempt to make a precise",
            "\t * comparison, it just says: if reloads are about comparable",
            "\t * between the LRU lists, or rotations are overwhelmingly",
            "\t * different between them, adjust scan balance for CPU work.",
            "\t */",
            "\tcost = nr_io * SWAP_CLUSTER_MAX + nr_rotated;",
            "",
            "\tdo {",
            "\t\tunsigned long lrusize;",
            "",
            "\t\t/*",
            "\t\t * Hold lruvec->lru_lock is safe here, since",
            "\t\t * 1) The pinned lruvec in reclaim, or",
            "\t\t * 2) From a pre-LRU page during refault (which also holds the",
            "\t\t *    rcu lock, so would be safe even if the page was on the LRU",
            "\t\t *    and could move simultaneously to a new lruvec).",
            "\t\t */",
            "\t\tspin_lock_irq(&lruvec->lru_lock);",
            "\t\t/* Record cost event */",
            "\t\tif (file)",
            "\t\t\tlruvec->file_cost += cost;",
            "\t\telse",
            "\t\t\tlruvec->anon_cost += cost;",
            "",
            "\t\t/*",
            "\t\t * Decay previous events",
            "\t\t *",
            "\t\t * Because workloads change over time (and to avoid",
            "\t\t * overflow) we keep these statistics as a floating",
            "\t\t * average, which ends up weighing recent refaults",
            "\t\t * more than old ones.",
            "\t\t */",
            "\t\tlrusize = lruvec_page_state(lruvec, NR_INACTIVE_ANON) +",
            "\t\t\t  lruvec_page_state(lruvec, NR_ACTIVE_ANON) +",
            "\t\t\t  lruvec_page_state(lruvec, NR_INACTIVE_FILE) +",
            "\t\t\t  lruvec_page_state(lruvec, NR_ACTIVE_FILE);",
            "",
            "\t\tif (lruvec->file_cost + lruvec->anon_cost > lrusize / 4) {",
            "\t\t\tlruvec->file_cost /= 2;",
            "\t\t\tlruvec->anon_cost /= 2;",
            "\t\t}",
            "\t\tspin_unlock_irq(&lruvec->lru_lock);",
            "\t} while ((lruvec = parent_lruvec(lruvec)));",
            "}",
            "void lru_note_cost_refault(struct folio *folio)",
            "{",
            "\tlru_note_cost(folio_lruvec(folio), folio_is_file_lru(folio),",
            "\t\t      folio_nr_pages(folio), 0);",
            "}",
            "static void folio_activate_fn(struct lruvec *lruvec, struct folio *folio)",
            "{",
            "\tif (!folio_test_active(folio) && !folio_test_unevictable(folio)) {",
            "\t\tlong nr_pages = folio_nr_pages(folio);",
            "",
            "\t\tlruvec_del_folio(lruvec, folio);",
            "\t\tfolio_set_active(folio);",
            "\t\tlruvec_add_folio(lruvec, folio);",
            "\t\ttrace_mm_lru_activate(folio);",
            "",
            "\t\t__count_vm_events(PGACTIVATE, nr_pages);",
            "\t\t__count_memcg_events(lruvec_memcg(lruvec), PGACTIVATE,",
            "\t\t\t\t     nr_pages);",
            "\t}",
            "}"
          ],
          "function_name": "folio_batch_add_and_move, lru_move_tail_fn, folio_rotate_reclaimable, lru_note_cost, lru_note_cost_refault, folio_activate_fn",
          "description": "提供LRU列表页面移动和成本统计功能，folio_batch_add_and_move处理页面批量移动，lru_move_tail_fn将页面移动到LRU尾部，folio_rotate_reclaimable将可回收页面转移到冷列表，lru_note_cost记录页面访问成本用于调整扫描策略，folio_activate_fn激活页面至活动列表。",
          "similarity": 0.49929696321487427
        }
      ]
    }
  ]
}