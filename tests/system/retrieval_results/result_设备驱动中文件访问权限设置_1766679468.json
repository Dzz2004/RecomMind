{
  "query": "设备驱动中文件访问权限设置",
  "timestamp": "2025-12-26 00:17:48",
  "retrieved_files": [
    {
      "source_file": "kernel/usermode_driver.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:47:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `usermode_driver.c`\n\n---\n\n# usermode_driver.c 技术文档\n\n## 文件概述\n\n`usermode_driver.c` 实现了 Linux 内核中用户态驱动（User Mode Driver, UMD）的支持机制。该文件提供了一套 API，允许内核模块将一段可执行的二进制数据（blob）加载为临时文件系统中的可执行文件，并以此为基础 fork 出一个用户态进程作为驱动程序运行。该机制常用于需要在用户空间执行复杂逻辑但又需与内核紧密协作的驱动场景（如某些固件加载器、安全模块或虚拟设备驱动）。\n\n## 核心功能\n\n### 主要函数\n\n- `blob_to_mnt(const void *data, size_t len, const char *name)`  \n  将二进制数据写入 tmpfs 文件系统中，返回挂载点（vfsmount）。\n\n- `umd_load_blob(struct umd_info *info, const void *data, size_t len)`  \n  将给定的二进制 blob 加载为可执行文件，并关联到 `umd_info` 结构中。\n\n- `umd_unload_blob(struct umd_info *info)`  \n  卸载之前加载的 blob，释放相关文件系统资源。\n\n- `fork_usermode_driver(struct umd_info *info)`  \n  基于已加载的 blob fork 并执行一个用户态驱动进程。\n\n- `umd_setup(struct subprocess_info *info, struct cred *new)`  \n  在子进程中设置执行环境，包括创建通信管道、设置工作目录等。\n\n- `umd_cleanup(struct subprocess_info *info)`  \n  子进程执行失败时的清理回调。\n\n- `umd_cleanup_helper(struct umd_info *info)`  \n  释放 `umd_setup` 中分配的资源（管道、PID 等）。\n\n### 关键数据结构\n\n- `struct umd_info`  \n  描述用户态驱动的上下文信息，包含：\n  - `wd`：工作目录（`struct path`），指向 tmpfs 中的可执行文件所在目录\n  - `driver_name`：驱动程序在 tmpfs 中的文件名\n  - `pipe_to_umh` / `pipe_from_umh`：与用户态进程通信的双向管道\n  - `tgid`：用户态驱动进程的线程组 ID（用于后续管理）\n\n## 关键实现\n\n### Blob 到可执行文件的转换\n\n`blob_to_mnt()` 函数通过以下步骤将内存中的二进制数据转换为可执行文件：\n\n1. 挂载 `tmpfs` 文件系统（使用 `kern_mount()`）\n2. 在挂载点根目录下以指定名称创建文件（权限 `0700`）\n3. 使用 `kernel_write()` 将数据写入文件\n4. 调用 `flush_delayed_fput()` 和 `task_work_run()` 确保文件描述符延迟释放完成，以便后续 `exec` 能以只读方式打开该文件\n\n此机制避免了将驱动二进制写入磁盘，提高了安全性和灵活性。\n\n### 用户态驱动进程的启动\n\n`fork_usermode_driver()` 利用内核的 `call_usermodehelper` 机制：\n\n- 使用 `call_usermodehelper_setup()` 注册 `umd_setup` 作为子进程初始化回调\n- 在 `umd_setup` 中：\n  - 创建两个匿名管道：一个用于内核向用户态发送数据（stdin 重定向），一个用于用户态向内核返回数据（stdout 重定向）\n  - 使用 `replace_fd()` 将标准输入/输出重定向到管道端点\n  - 设置当前进程的 pwd（工作目录）为 tmpfs 挂载点，使 `exec` 能直接以相对路径执行驱动文件\n  - 保存管道文件指针和子进程 TGID 到 `umd_info`\n- 执行 `call_usermodehelper_exec()` 启动进程\n\n### 资源管理与错误处理\n\n- `umd_load_blob()` 和 `umd_unload_blob()` 通过 `WARN_ON_ONCE` 确保状态一致性（避免重复加载/卸载）\n- 若 `exec` 失败，`umd_cleanup` 回调会调用 `umd_cleanup_helper` 释放管道和 PID\n- 所有资源（vfsmount、file、pipe、pid）均通过内核标准接口分配和释放，确保无泄漏\n\n## 依赖关系\n\n- **文件系统**：依赖 `tmpfs`（通过 `get_fs_type(\"tmpfs\")`），用于临时存储可执行 blob\n- **进程管理**：依赖 `call_usermodehelper` 子系统（`linux/kmod.h` 隐式包含），用于 fork/exec 用户态进程\n- **VFS 层**：使用 `kern_mount`/`kern_unmount`、`file_open_root_mnt`、`kernel_write` 等 VFS 接口\n- **IPC 机制**：依赖管道（`create_pipe_files`）实现内核与用户态驱动的双向通信\n- **内存管理**：依赖 `shmem_fs.h`（tmpfs 底层基于共享内存）\n- **任务工作队列**：调用 `task_work_run()` 确保文件描述符及时释放\n\n## 使用场景\n\n1. **动态用户态驱动加载**  \n   内核模块可将嵌入的 ELF 二进制或脚本作为 blob 加载，无需预先安装到文件系统。\n\n2. **安全隔离驱动**  \n   将可能含漏洞的驱动逻辑移至用户空间运行，通过管道与内核通信，降低内核攻击面。\n\n3. **固件或微码加载器**  \n   某些设备需要复杂的固件初始化逻辑，可通过 UMD 在用户态执行，避免内核复杂性。\n\n4. **虚拟设备后端**  \n   如 virtio-user、vhost-user 等场景，内核前端通过 UMD 与用户态后端进程协作。\n\n5. **测试与原型开发**  \n   快速验证驱动逻辑，无需频繁编译内核模块，提高开发效率。\n\n> **注意**：调用者需负责用户态进程的生命周期管理（健康检查、信号终止、管道关闭等）。",
      "similarity": 0.6148577928543091,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/usermode_driver.c",
          "start_line": 60,
          "end_line": 161,
          "content": [
            "int umd_load_blob(struct umd_info *info, const void *data, size_t len)",
            "{",
            "\tstruct vfsmount *mnt;",
            "",
            "\tif (WARN_ON_ONCE(info->wd.dentry || info->wd.mnt))",
            "\t\treturn -EBUSY;",
            "",
            "\tmnt = blob_to_mnt(data, len, info->driver_name);",
            "\tif (IS_ERR(mnt))",
            "\t\treturn PTR_ERR(mnt);",
            "",
            "\tinfo->wd.mnt = mnt;",
            "\tinfo->wd.dentry = mnt->mnt_root;",
            "\treturn 0;",
            "}",
            "int umd_unload_blob(struct umd_info *info)",
            "{",
            "\tif (WARN_ON_ONCE(!info->wd.mnt ||",
            "\t\t\t !info->wd.dentry ||",
            "\t\t\t info->wd.mnt->mnt_root != info->wd.dentry))",
            "\t\treturn -EINVAL;",
            "",
            "\tkern_unmount(info->wd.mnt);",
            "\tinfo->wd.mnt = NULL;",
            "\tinfo->wd.dentry = NULL;",
            "\treturn 0;",
            "}",
            "static int umd_setup(struct subprocess_info *info, struct cred *new)",
            "{",
            "\tstruct umd_info *umd_info = info->data;",
            "\tstruct file *from_umh[2];",
            "\tstruct file *to_umh[2];",
            "\tint err;",
            "",
            "\t/* create pipe to send data to umh */",
            "\terr = create_pipe_files(to_umh, 0);",
            "\tif (err)",
            "\t\treturn err;",
            "\terr = replace_fd(0, to_umh[0], 0);",
            "\tfput(to_umh[0]);",
            "\tif (err < 0) {",
            "\t\tfput(to_umh[1]);",
            "\t\treturn err;",
            "\t}",
            "",
            "\t/* create pipe to receive data from umh */",
            "\terr = create_pipe_files(from_umh, 0);",
            "\tif (err) {",
            "\t\tfput(to_umh[1]);",
            "\t\treplace_fd(0, NULL, 0);",
            "\t\treturn err;",
            "\t}",
            "\terr = replace_fd(1, from_umh[1], 0);",
            "\tfput(from_umh[1]);",
            "\tif (err < 0) {",
            "\t\tfput(to_umh[1]);",
            "\t\treplace_fd(0, NULL, 0);",
            "\t\tfput(from_umh[0]);",
            "\t\treturn err;",
            "\t}",
            "",
            "\tset_fs_pwd(current->fs, &umd_info->wd);",
            "\tumd_info->pipe_to_umh = to_umh[1];",
            "\tumd_info->pipe_from_umh = from_umh[0];",
            "\tumd_info->tgid = get_pid(task_tgid(current));",
            "\treturn 0;",
            "}",
            "static void umd_cleanup(struct subprocess_info *info)",
            "{",
            "\tstruct umd_info *umd_info = info->data;",
            "",
            "\t/* cleanup if umh_setup() was successful but exec failed */",
            "\tif (info->retval)",
            "\t\tumd_cleanup_helper(umd_info);",
            "}",
            "void umd_cleanup_helper(struct umd_info *info)",
            "{",
            "\tfput(info->pipe_to_umh);",
            "\tfput(info->pipe_from_umh);",
            "\tput_pid(info->tgid);",
            "\tinfo->tgid = NULL;",
            "}",
            "int fork_usermode_driver(struct umd_info *info)",
            "{",
            "\tstruct subprocess_info *sub_info;",
            "\tconst char *argv[] = { info->driver_name, NULL };",
            "\tint err;",
            "",
            "\tif (WARN_ON_ONCE(info->tgid))",
            "\t\treturn -EBUSY;",
            "",
            "\terr = -ENOMEM;",
            "\tsub_info = call_usermodehelper_setup(info->driver_name,",
            "\t\t\t\t\t     (char **)argv, NULL, GFP_KERNEL,",
            "\t\t\t\t\t     umd_setup, umd_cleanup, info);",
            "\tif (!sub_info)",
            "\t\tgoto out;",
            "",
            "\terr = call_usermodehelper_exec(sub_info, UMH_WAIT_EXEC);",
            "out:",
            "\treturn err;",
            "}"
          ],
          "function_name": "umd_load_blob, umd_unload_blob, umd_setup, umd_cleanup, umd_cleanup_helper, fork_usermode_driver",
          "description": "提供用户模式驱动程序的数据加载/卸载及子进程管理功能，包括挂载tmpfs、建立进程间管道通信、设置工作目录及清理资源，最终通过call_usermodehelper启动用户态驱动程序",
          "similarity": 0.5836646556854248
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/usermode_driver.c",
          "start_line": 1,
          "end_line": 59,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * umd - User mode driver support",
            " */",
            "#include <linux/shmem_fs.h>",
            "#include <linux/pipe_fs_i.h>",
            "#include <linux/mount.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/task_work.h>",
            "#include <linux/usermode_driver.h>",
            "",
            "static struct vfsmount *blob_to_mnt(const void *data, size_t len, const char *name)",
            "{",
            "\tstruct file_system_type *type;",
            "\tstruct vfsmount *mnt;",
            "\tstruct file *file;",
            "\tssize_t written;",
            "\tloff_t pos = 0;",
            "",
            "\ttype = get_fs_type(\"tmpfs\");",
            "\tif (!type)",
            "\t\treturn ERR_PTR(-ENODEV);",
            "",
            "\tmnt = kern_mount(type);",
            "\tput_filesystem(type);",
            "\tif (IS_ERR(mnt))",
            "\t\treturn mnt;",
            "",
            "\tfile = file_open_root_mnt(mnt, name, O_CREAT | O_WRONLY, 0700);",
            "\tif (IS_ERR(file)) {",
            "\t\tkern_unmount(mnt);",
            "\t\treturn ERR_CAST(file);",
            "\t}",
            "",
            "\twritten = kernel_write(file, data, len, &pos);",
            "\tif (written != len) {",
            "\t\tint err = written;",
            "\t\tif (err >= 0)",
            "\t\t\terr = -ENOMEM;",
            "\t\tfilp_close(file, NULL);",
            "\t\tkern_unmount(mnt);",
            "\t\treturn ERR_PTR(err);",
            "\t}",
            "",
            "\tfput(file);",
            "",
            "\t/* Flush delayed fput so exec can open the file read-only */",
            "\tflush_delayed_fput();",
            "\ttask_work_run();",
            "\treturn mnt;",
            "}",
            "",
            "/**",
            " * umd_load_blob - Remember a blob of bytes for fork_usermode_driver",
            " * @info: information about usermode driver",
            " * @data: a blob of bytes that can be executed as a file",
            " * @len:  The lentgh of the blob",
            " *",
            " */"
          ],
          "function_name": null,
          "description": "创建并挂载tmpfs文件系统以存储二进制数据，通过文件操作将输入数据写入新挂载点的指定名称文件，返回对应的vfsmount结构指针",
          "similarity": 0.4941290616989136
        }
      ]
    },
    {
      "source_file": "kernel/dma/direct.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:12:42\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `dma\\direct.c`\n\n---\n\n# `dma/direct.c` 技术文档\n\n## 1. 文件概述\n\n`dma/direct.c` 实现了 Linux 内核中 **DMA 直接映射操作（DMA direct mapping）** 的核心逻辑。该文件提供了一套不依赖 IOMMU 的 DMA 内存分配与映射机制，适用于物理地址可直接被设备访问的平台（如 x86、ARM64 等无 IOMMU 或 IOMMU 被禁用的场景）。其核心思想是将物理内存地址直接转换为设备可见的 DMA 地址，避免复杂的地址转换开销。\n\n该实现支持多种内存分配策略，包括：\n- 连续物理内存分配（CMA 或 buddy allocator）\n- SWIOTLB 回退机制（用于处理高地址设备无法访问的情况）\n- 原子池分配（用于不可阻塞上下文）\n- 高端内存重映射\n- 内存加密/解密（如 AMD SEV、Intel TDX 等安全特性）\n\n## 2. 核心功能\n\n### 全局变量\n- `zone_dma_bits`：定义 ZONE_DMA 的地址位宽（默认 24 位，即 16MB），可由架构代码覆盖。\n\n### 主要函数\n| 函数名 | 功能描述 |\n|--------|--------|\n| `phys_to_dma_direct()` | 将物理地址转换为 DMA 地址，支持强制解密场景 |\n| `dma_direct_to_page()` | 通过 DMA 地址反查对应的 `struct page` |\n| `dma_direct_get_required_mask()` | 计算设备所需的 DMA 地址掩码（基于系统最大物理地址）|\n| `dma_coherent_ok()` | 检查给定物理地址范围是否在设备的 DMA 地址能力范围内 |\n| `dma_direct_alloc()` | **主入口函数**：为设备分配 DMA 内存，支持多种属性和回退策略 |\n| `__dma_direct_alloc_pages()` | 底层页面分配函数，尝试最优内存区域并回退到低地址区域 |\n| `dma_direct_alloc_from_pool()` | 从原子池分配不可阻塞的 DMA 内存 |\n| `dma_direct_alloc_no_mapping()` | 分配无内核虚拟映射的 DMA 内存（返回 `struct page*`）|\n| `dma_set_decrypted()` / `dma_set_encrypted()` | 设置内存页为解密/加密状态（用于安全虚拟化）|\n\n### 辅助函数\n- `dma_direct_optimal_gfp_mask()`：根据设备 DMA 限制选择最优的 GFP 标志（GFP_DMA / GFP_DMA32）\n- `__dma_direct_free_pages()`：释放通过直接分配获得的页面（优先尝试 SWIOTLB 释放）\n\n## 3. 关键实现\n\n### 3.1 DMA 地址空间约束处理\n- 使用 `dev->coherent_dma_mask` 和 `dev->bus_dma_limit` 确定设备可寻址的物理地址上限。\n- 通过 `dma_coherent_ok()` 验证分配的物理内存是否在设备可访问范围内。\n- 若分配的内存超出范围，则回退到更低地址区域（先尝试 GFP_DMA32，再尝试 GFP_DMA）。\n\n### 3.2 多层次内存分配策略\n1. **首选 CMA 连续内存**：通过 `dma_alloc_contiguous()` 分配。\n2. **回退到 buddy allocator**：使用 `alloc_pages_node()`。\n3. **SWIOTLB 支持**：当设备无法访问高地址时，通过 `swiotlb_alloc()` 分配 bounce buffer。\n4. **原子上下文支持**：在不可阻塞场景下使用 `dma_direct_alloc_from_pool()` 从预分配池中获取内存。\n\n### 3.3 非一致性缓存与内存属性处理\n- 对于非一致性缓存架构（`!dev_is_dma_coherent()`）：\n  - 优先使用全局一致性内存池（`CONFIG_DMA_GLOBAL_POOL`）\n  - 或启用重映射（`CONFIG_DMA_DIRECT_REMAP`）创建 uncached 映射\n  - 或调用架构特定的 `arch_dma_alloc()`\n- 调用 `arch_dma_prep_coherent()` 清理内核别名的脏缓存行。\n\n### 3.4 安全内存处理（加密/解密）\n- 当 `force_dma_unencrypted(dev)` 为真（如 SEV 环境），分配的内存需标记为解密。\n- 使用 `set_memory_decrypted()` / `set_memory_encrypted()` 修改页表属性。\n- 解密操作可能阻塞，因此在原子上下文中需使用内存池。\n\n### 3.5 高端内存（HighMem）处理\n- 若分配的页面位于高端内存（`PageHighMem`），则必须通过 `dma_common_contiguous_remap()` 创建内核虚拟地址映射。\n- 重映射时应用设备特定的页保护属性（`dma_pgprot()`）并处理解密需求。\n\n## 4. 依赖关系\n\n### 内核头文件依赖\n- `<linux/memblock.h>`：获取 `max_pfn` 系统最大页帧号\n- `<linux/dma-map-ops.h>`：DMA 映射操作抽象接口\n- `<linux/scatterlist.h>`：SG 表支持（间接依赖）\n- `<linux/set_memory.h>`：内存加密/解密操作（`set_memory_decrypted` 等）\n- `<linux/vmalloc.h>`：高端内存重映射支持\n- `\"direct.h\"`：本地 DMA direct 实现的私有头文件\n\n### 配置选项依赖\n- `CONFIG_SWIOTLB`：SWIOTLB bounce buffer 支持\n- `CONFIG_DMA_COHERENT_POOL`：原子上下文 DMA 内存池\n- `CONFIG_DMA_GLOBAL_POOL`：全局一致性 DMA 内存池\n- `CONFIG_DMA_DIRECT_REMAP`：非一致性设备的重映射支持\n- `CONFIG_ZONE_DMA` / `CONFIG_ZONE_DMA32`：低地址内存区域支持\n- `CONFIG_ARCH_HAS_DMA_SET_UNCACHED`：架构特定 uncached 映射支持\n\n### 架构相关依赖\n- `phys_to_dma()` / `dma_to_phys()`：架构提供的物理地址与 DMA 地址转换函数\n- `arch_dma_prep_coherent()`：架构特定的缓存一致性准备\n- `arch_dma_alloc()`：架构特定的 DMA 分配回退路径\n\n## 5. 使用场景\n\n### 5.1 设备驱动 DMA 分配\n- 驱动调用 `dma_alloc_coherent()` 或 `dma_alloc_attrs()` 时，若系统未启用 IOMMU，则最终由 `dma_direct_alloc()` 处理。\n- 适用于大多数无 IOMMU 的嵌入式系统、传统 PC 平台或 IOMMU 被显式禁用的场景。\n\n### 5.2 安全虚拟化环境\n- 在 AMD SEV 或 Intel TDX 等机密计算环境中，DMA 内存需标记为“解密”，该文件通过 `force_dma_unencrypted()` 机制实现。\n\n### 5.3 资源受限或实时系统\n- 通过 `DMA_ATTR_NO_KERNEL_MAPPING` 属性分配无内核映射的 DMA 内存，减少 TLB 压力。\n- 在中断上下文等不可阻塞场景中，自动使用原子内存池分配。\n\n### 5.4 老旧设备兼容\n- 对仅支持 32 位或 24 位 DMA 地址的设备，自动分配低地址内存（通过 GFP_DMA32/GFP_DMA）并验证地址范围。\n\n### 5.5 高端内存平台\n- 在 32 位系统或内存大于直接映射区域的平台上，自动处理高端内存的重映射，确保返回有效的内核虚拟地址。",
      "similarity": 0.5986864566802979,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/dma/direct.c",
          "start_line": 520,
          "end_line": 633,
          "content": [
            "dma_addr_t dma_direct_map_resource(struct device *dev, phys_addr_t paddr,",
            "\t\tsize_t size, enum dma_data_direction dir, unsigned long attrs)",
            "{",
            "\tdma_addr_t dma_addr = paddr;",
            "",
            "\tif (unlikely(!dma_capable(dev, dma_addr, size, false))) {",
            "\t\tdev_err_once(dev,",
            "\t\t\t     \"DMA addr %pad+%zu overflow (mask %llx, bus limit %llx).\\n\",",
            "\t\t\t     &dma_addr, size, *dev->dma_mask, dev->bus_dma_limit);",
            "\t\tWARN_ON_ONCE(1);",
            "\t\treturn DMA_MAPPING_ERROR;",
            "\t}",
            "",
            "\treturn dma_addr;",
            "}",
            "int dma_direct_get_sgtable(struct device *dev, struct sg_table *sgt,",
            "\t\tvoid *cpu_addr, dma_addr_t dma_addr, size_t size,",
            "\t\tunsigned long attrs)",
            "{",
            "\tstruct page *page = dma_direct_to_page(dev, dma_addr);",
            "\tint ret;",
            "",
            "\tret = sg_alloc_table(sgt, 1, GFP_KERNEL);",
            "\tif (!ret)",
            "\t\tsg_set_page(sgt->sgl, page, PAGE_ALIGN(size), 0);",
            "\treturn ret;",
            "}",
            "bool dma_direct_can_mmap(struct device *dev)",
            "{",
            "\treturn dev_is_dma_coherent(dev) ||",
            "\t\tIS_ENABLED(CONFIG_DMA_NONCOHERENT_MMAP);",
            "}",
            "int dma_direct_mmap(struct device *dev, struct vm_area_struct *vma,",
            "\t\tvoid *cpu_addr, dma_addr_t dma_addr, size_t size,",
            "\t\tunsigned long attrs)",
            "{",
            "\tunsigned long user_count = vma_pages(vma);",
            "\tunsigned long count = PAGE_ALIGN(size) >> PAGE_SHIFT;",
            "\tunsigned long pfn = PHYS_PFN(dma_to_phys(dev, dma_addr));",
            "\tint ret = -ENXIO;",
            "",
            "\tvma->vm_page_prot = dma_pgprot(dev, vma->vm_page_prot, attrs);",
            "\tif (force_dma_unencrypted(dev))",
            "\t\tvma->vm_page_prot = pgprot_decrypted(vma->vm_page_prot);",
            "",
            "\tif (dma_mmap_from_dev_coherent(dev, vma, cpu_addr, size, &ret))",
            "\t\treturn ret;",
            "\tif (dma_mmap_from_global_coherent(vma, cpu_addr, size, &ret))",
            "\t\treturn ret;",
            "",
            "\tif (vma->vm_pgoff >= count || user_count > count - vma->vm_pgoff)",
            "\t\treturn -ENXIO;",
            "\treturn remap_pfn_range(vma, vma->vm_start, pfn + vma->vm_pgoff,",
            "\t\t\tuser_count << PAGE_SHIFT, vma->vm_page_prot);",
            "}",
            "int dma_direct_supported(struct device *dev, u64 mask)",
            "{",
            "\tu64 min_mask = (max_pfn - 1) << PAGE_SHIFT;",
            "",
            "\t/*",
            "\t * Because 32-bit DMA masks are so common we expect every architecture",
            "\t * to be able to satisfy them - either by not supporting more physical",
            "\t * memory, or by providing a ZONE_DMA32.  If neither is the case, the",
            "\t * architecture needs to use an IOMMU instead of the direct mapping.",
            "\t */",
            "\tif (mask >= DMA_BIT_MASK(32))",
            "\t\treturn 1;",
            "",
            "\t/*",
            "\t * This check needs to be against the actual bit mask value, so use",
            "\t * phys_to_dma_unencrypted() here so that the SME encryption mask isn't",
            "\t * part of the check.",
            "\t */",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA))",
            "\t\tmin_mask = min_t(u64, min_mask, DMA_BIT_MASK(zone_dma_bits));",
            "\treturn mask >= phys_to_dma_unencrypted(dev, min_mask);",
            "}",
            "size_t dma_direct_max_mapping_size(struct device *dev)",
            "{",
            "\t/* If SWIOTLB is active, use its maximum mapping size */",
            "\tif (is_swiotlb_active(dev) &&",
            "\t    (dma_addressing_limited(dev) || is_swiotlb_force_bounce(dev)))",
            "\t\treturn swiotlb_max_mapping_size(dev);",
            "\treturn SIZE_MAX;",
            "}",
            "bool dma_direct_need_sync(struct device *dev, dma_addr_t dma_addr)",
            "{",
            "\treturn !dev_is_dma_coherent(dev) ||",
            "\t       is_swiotlb_buffer(dev, dma_to_phys(dev, dma_addr));",
            "}",
            "int dma_direct_set_offset(struct device *dev, phys_addr_t cpu_start,",
            "\t\t\t dma_addr_t dma_start, u64 size)",
            "{",
            "\tstruct bus_dma_region *map;",
            "\tu64 offset = (u64)cpu_start - (u64)dma_start;",
            "",
            "\tif (dev->dma_range_map) {",
            "\t\tdev_err(dev, \"attempt to add DMA range to existing map\\n\");",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tif (!offset)",
            "\t\treturn 0;",
            "",
            "\tmap = kcalloc(2, sizeof(*map), GFP_KERNEL);",
            "\tif (!map)",
            "\t\treturn -ENOMEM;",
            "\tmap[0].cpu_start = cpu_start;",
            "\tmap[0].dma_start = dma_start;",
            "\tmap[0].offset = offset;",
            "\tmap[0].size = size;",
            "\tdev->dma_range_map = map;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "dma_direct_map_resource, dma_direct_get_sgtable, dma_direct_can_mmap, dma_direct_mmap, dma_direct_supported, dma_direct_max_mapping_size, dma_direct_need_sync, dma_direct_set_offset",
          "description": "包含DMA直接映射的资源映射、SG表构建、内存映射支持性检测及最大映射尺寸计算等功能。dma_direct_mmap实现设备内存的VMA映射，dma_direct_supported验证DMA掩码兼容性，dma_direct_set_offset用于配置DMA地址偏移量。",
          "similarity": 0.4915469288825989
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/dma/direct.c",
          "start_line": 25,
          "end_line": 140,
          "content": [
            "static inline dma_addr_t phys_to_dma_direct(struct device *dev,",
            "\t\tphys_addr_t phys)",
            "{",
            "\tif (force_dma_unencrypted(dev))",
            "\t\treturn phys_to_dma_unencrypted(dev, phys);",
            "\treturn phys_to_dma(dev, phys);",
            "}",
            "u64 dma_direct_get_required_mask(struct device *dev)",
            "{",
            "\tphys_addr_t phys = (phys_addr_t)(max_pfn - 1) << PAGE_SHIFT;",
            "\tu64 max_dma = phys_to_dma_direct(dev, phys);",
            "",
            "\treturn (1ULL << (fls64(max_dma) - 1)) * 2 - 1;",
            "}",
            "static gfp_t dma_direct_optimal_gfp_mask(struct device *dev, u64 *phys_limit)",
            "{",
            "\tu64 dma_limit = min_not_zero(",
            "\t\tdev->coherent_dma_mask,",
            "\t\tdev->bus_dma_limit);",
            "",
            "\t/*",
            "\t * Optimistically try the zone that the physical address mask falls",
            "\t * into first.  If that returns memory that isn't actually addressable",
            "\t * we will fallback to the next lower zone and try again.",
            "\t *",
            "\t * Note that GFP_DMA32 and GFP_DMA are no ops without the corresponding",
            "\t * zones.",
            "\t */",
            "\t*phys_limit = dma_to_phys(dev, dma_limit);",
            "\tif (*phys_limit <= DMA_BIT_MASK(zone_dma_bits))",
            "\t\treturn GFP_DMA;",
            "\tif (*phys_limit <= DMA_BIT_MASK(32))",
            "\t\treturn GFP_DMA32;",
            "\treturn 0;",
            "}",
            "bool dma_coherent_ok(struct device *dev, phys_addr_t phys, size_t size)",
            "{",
            "\tdma_addr_t dma_addr = phys_to_dma_direct(dev, phys);",
            "",
            "\tif (dma_addr == DMA_MAPPING_ERROR)",
            "\t\treturn false;",
            "\treturn dma_addr + size - 1 <=",
            "\t\tmin_not_zero(dev->coherent_dma_mask, dev->bus_dma_limit);",
            "}",
            "static int dma_set_decrypted(struct device *dev, void *vaddr, size_t size)",
            "{",
            "\tif (!force_dma_unencrypted(dev))",
            "\t\treturn 0;",
            "\treturn set_memory_decrypted((unsigned long)vaddr, PFN_UP(size));",
            "}",
            "static int dma_set_encrypted(struct device *dev, void *vaddr, size_t size)",
            "{",
            "\tint ret;",
            "",
            "\tif (!force_dma_unencrypted(dev))",
            "\t\treturn 0;",
            "\tret = set_memory_encrypted((unsigned long)vaddr, PFN_UP(size));",
            "\tif (ret)",
            "\t\tpr_warn_ratelimited(\"leaking DMA memory that can't be re-encrypted\\n\");",
            "\treturn ret;",
            "}",
            "static void __dma_direct_free_pages(struct device *dev, struct page *page,",
            "\t\t\t\t    size_t size)",
            "{",
            "\tif (swiotlb_free(dev, page, size))",
            "\t\treturn;",
            "\tdma_free_contiguous(dev, page, size);",
            "}",
            "static bool dma_direct_use_pool(struct device *dev, gfp_t gfp)",
            "{",
            "\treturn !gfpflags_allow_blocking(gfp) && !is_swiotlb_for_alloc(dev);",
            "}",
            "void dma_direct_free(struct device *dev, size_t size,",
            "\t\tvoid *cpu_addr, dma_addr_t dma_addr, unsigned long attrs)",
            "{",
            "\tunsigned int page_order = get_order(size);",
            "",
            "\tif ((attrs & DMA_ATTR_NO_KERNEL_MAPPING) &&",
            "\t    !force_dma_unencrypted(dev) && !is_swiotlb_for_alloc(dev)) {",
            "\t\t/* cpu_addr is a struct page cookie, not a kernel address */",
            "\t\tdma_free_contiguous(dev, cpu_addr, size);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (!IS_ENABLED(CONFIG_ARCH_HAS_DMA_SET_UNCACHED) &&",
            "\t    !IS_ENABLED(CONFIG_DMA_DIRECT_REMAP) &&",
            "\t    !IS_ENABLED(CONFIG_DMA_GLOBAL_POOL) &&",
            "\t    !dev_is_dma_coherent(dev) &&",
            "\t    !is_swiotlb_for_alloc(dev)) {",
            "\t\tarch_dma_free(dev, size, cpu_addr, dma_addr, attrs);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (IS_ENABLED(CONFIG_DMA_GLOBAL_POOL) &&",
            "\t    !dev_is_dma_coherent(dev)) {",
            "\t\tif (!dma_release_from_global_coherent(page_order, cpu_addr))",
            "\t\t\tWARN_ON_ONCE(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* If cpu_addr is not from an atomic pool, dma_free_from_pool() fails */",
            "\tif (IS_ENABLED(CONFIG_DMA_COHERENT_POOL) &&",
            "\t    dma_free_from_pool(dev, cpu_addr, PAGE_ALIGN(size)))",
            "\t\treturn;",
            "",
            "\tif (is_vmalloc_addr(cpu_addr)) {",
            "\t\tvunmap(cpu_addr);",
            "\t} else {",
            "\t\tif (IS_ENABLED(CONFIG_ARCH_HAS_DMA_CLEAR_UNCACHED))",
            "\t\t\tarch_dma_clear_uncached(cpu_addr, size);",
            "\t\tif (dma_set_encrypted(dev, cpu_addr, size))",
            "\t\t\treturn;",
            "\t}",
            "",
            "\t__dma_direct_free_pages(dev, dma_direct_to_page(dev, dma_addr), size);",
            "}"
          ],
          "function_name": "phys_to_dma_direct, dma_direct_get_required_mask, dma_direct_optimal_gfp_mask, dma_coherent_ok, dma_set_decrypted, dma_set_encrypted, __dma_direct_free_pages, dma_direct_use_pool, dma_direct_free",
          "description": "实现了DMA直接映射的核心辅助函数，包括物理地址转DMA地址、计算DMA掩码、优化内存分配策略、检查DMA一致性及加密内存设置等功能。dma_direct_free处理不同条件下的内存释放逻辑，涉及SWIOTLB、原子池和架构特定的释放路径。",
          "similarity": 0.4903256297111511
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/dma/direct.c",
          "start_line": 1,
          "end_line": 24,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 2018-2020 Christoph Hellwig.",
            " *",
            " * DMA operations that map physical memory directly without using an IOMMU.",
            " */",
            "#include <linux/memblock.h> /* for max_pfn */",
            "#include <linux/export.h>",
            "#include <linux/mm.h>",
            "#include <linux/dma-map-ops.h>",
            "#include <linux/scatterlist.h>",
            "#include <linux/pfn.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/slab.h>",
            "#include \"direct.h\"",
            "",
            "/*",
            " * Most architectures use ZONE_DMA for the first 16 Megabytes, but some use",
            " * it for entirely different regions. In that case the arch code needs to",
            " * override the variable below for dma-direct to work properly.",
            " */",
            "unsigned int zone_dma_bits __ro_after_init = 24;",
            ""
          ],
          "function_name": null,
          "description": "定义了用于DMA直接映射的全局变量zone_dma_bits，默认值为24位，表示DMA地址空间的位宽。该变量用于控制DMA操作的物理地址范围，架构代码可通过覆盖此变量调整DMA直接映射的行为。",
          "similarity": 0.43792879581451416
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/dma/direct.c",
          "start_line": 391,
          "end_line": 503,
          "content": [
            "void dma_direct_free_pages(struct device *dev, size_t size,",
            "\t\tstruct page *page, dma_addr_t dma_addr,",
            "\t\tenum dma_data_direction dir)",
            "{",
            "\tvoid *vaddr = page_address(page);",
            "",
            "\t/* If cpu_addr is not from an atomic pool, dma_free_from_pool() fails */",
            "\tif (IS_ENABLED(CONFIG_DMA_COHERENT_POOL) &&",
            "\t    dma_free_from_pool(dev, vaddr, size))",
            "\t\treturn;",
            "",
            "\tif (dma_set_encrypted(dev, vaddr, size))",
            "\t\treturn;",
            "\t__dma_direct_free_pages(dev, page, size);",
            "}",
            "void dma_direct_sync_sg_for_device(struct device *dev,",
            "\t\tstruct scatterlist *sgl, int nents, enum dma_data_direction dir)",
            "{",
            "\tstruct scatterlist *sg;",
            "\tint i;",
            "",
            "\tfor_each_sg(sgl, sg, nents, i) {",
            "\t\tphys_addr_t paddr = dma_to_phys(dev, sg_dma_address(sg));",
            "",
            "\t\tif (unlikely(is_swiotlb_buffer(dev, paddr)))",
            "\t\t\tswiotlb_sync_single_for_device(dev, paddr, sg->length,",
            "\t\t\t\t\t\t       dir);",
            "",
            "\t\tif (!dev_is_dma_coherent(dev))",
            "\t\t\tarch_sync_dma_for_device(paddr, sg->length,",
            "\t\t\t\t\tdir);",
            "\t}",
            "}",
            "void dma_direct_sync_sg_for_cpu(struct device *dev,",
            "\t\tstruct scatterlist *sgl, int nents, enum dma_data_direction dir)",
            "{",
            "\tstruct scatterlist *sg;",
            "\tint i;",
            "",
            "\tfor_each_sg(sgl, sg, nents, i) {",
            "\t\tphys_addr_t paddr = dma_to_phys(dev, sg_dma_address(sg));",
            "",
            "\t\tif (!dev_is_dma_coherent(dev))",
            "\t\t\tarch_sync_dma_for_cpu(paddr, sg->length, dir);",
            "",
            "\t\tif (unlikely(is_swiotlb_buffer(dev, paddr)))",
            "\t\t\tswiotlb_sync_single_for_cpu(dev, paddr, sg->length,",
            "\t\t\t\t\t\t    dir);",
            "",
            "\t\tif (dir == DMA_FROM_DEVICE)",
            "\t\t\tarch_dma_mark_clean(paddr, sg->length);",
            "\t}",
            "",
            "\tif (!dev_is_dma_coherent(dev))",
            "\t\tarch_sync_dma_for_cpu_all();",
            "}",
            "void dma_direct_unmap_sg(struct device *dev, struct scatterlist *sgl,",
            "\t\tint nents, enum dma_data_direction dir, unsigned long attrs)",
            "{",
            "\tstruct scatterlist *sg;",
            "\tint i;",
            "",
            "\tfor_each_sg(sgl,  sg, nents, i) {",
            "\t\tif (sg_dma_is_bus_address(sg))",
            "\t\t\tsg_dma_unmark_bus_address(sg);",
            "\t\telse",
            "\t\t\tdma_direct_unmap_page(dev, sg->dma_address,",
            "\t\t\t\t\t      sg_dma_len(sg), dir, attrs);",
            "\t}",
            "}",
            "int dma_direct_map_sg(struct device *dev, struct scatterlist *sgl, int nents,",
            "\t\tenum dma_data_direction dir, unsigned long attrs)",
            "{",
            "\tstruct pci_p2pdma_map_state p2pdma_state = {};",
            "\tenum pci_p2pdma_map_type map;",
            "\tstruct scatterlist *sg;",
            "\tint i, ret;",
            "",
            "\tfor_each_sg(sgl, sg, nents, i) {",
            "\t\tif (is_pci_p2pdma_page(sg_page(sg))) {",
            "\t\t\tmap = pci_p2pdma_map_segment(&p2pdma_state, dev, sg);",
            "\t\t\tswitch (map) {",
            "\t\t\tcase PCI_P2PDMA_MAP_BUS_ADDR:",
            "\t\t\t\tcontinue;",
            "\t\t\tcase PCI_P2PDMA_MAP_THRU_HOST_BRIDGE:",
            "\t\t\t\t/*",
            "\t\t\t\t * Any P2P mapping that traverses the PCI",
            "\t\t\t\t * host bridge must be mapped with CPU physical",
            "\t\t\t\t * address and not PCI bus addresses. This is",
            "\t\t\t\t * done with dma_direct_map_page() below.",
            "\t\t\t\t */",
            "\t\t\t\tbreak;",
            "\t\t\tdefault:",
            "\t\t\t\tret = -EREMOTEIO;",
            "\t\t\t\tgoto out_unmap;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tsg->dma_address = dma_direct_map_page(dev, sg_page(sg),",
            "\t\t\t\tsg->offset, sg->length, dir, attrs);",
            "\t\tif (sg->dma_address == DMA_MAPPING_ERROR) {",
            "\t\t\tret = -EIO;",
            "\t\t\tgoto out_unmap;",
            "\t\t}",
            "\t\tsg_dma_len(sg) = sg->length;",
            "\t}",
            "",
            "\treturn nents;",
            "",
            "out_unmap:",
            "\tdma_direct_unmap_sg(dev, sgl, i, dir, attrs | DMA_ATTR_SKIP_CPU_SYNC);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "dma_direct_free_pages, dma_direct_sync_sg_for_device, dma_direct_sync_sg_for_cpu, dma_direct_unmap_sg, dma_direct_map_sg",
          "description": "提供了SCATTERLIST的同步、解映射和映射操作实现，包括对非一致内存的架构同步、PCI P2P DMA的特殊处理以及SG表的构建。sync_sg系列函数负责设备与CPU之间的数据缓存一致性维护。",
          "similarity": 0.4328669011592865
        }
      ]
    },
    {
      "source_file": "kernel/dma.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:09:28\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `dma.c`\n\n---\n\n# `dma.c` 技术文档\n\n## 1. 文件概述\n\n`dma.c` 是 Linux 内核中用于管理系统 DMA（Direct Memory Access，直接内存访问）通道分配的核心文件。它提供了一套简单的资源管理机制，允许多个设备驱动程序以互斥方式请求和释放有限的系统 DMA 通道资源。该实现灵感来源于 `irq.c`，主要用于传统的 ISA 架构下的 DMA 控制器（如 Intel 8237），在现代系统中主要用于兼容旧硬件或特定嵌入式平台。文件还支持通过 `/proc/dma` 接口向用户空间暴露当前 DMA 通道的使用情况。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct dma_chan`**  \n  表示一个 DMA 通道的状态：\n  - `int lock`：标志位，非零表示通道已被占用。\n  - `const char *device_id`：占用该通道的设备标识字符串，用于 `/proc/dma` 显示。\n\n- **`dma_chan_busy[MAX_DMA_CHANNELS]`**  \n  全局静态数组，记录每个 DMA 通道的占用状态。其中通道 4 被预设为 `\"cascade\"`（用于级联主从 DMA 控制器），并标记为已占用。\n\n- **`dma_spin_lock`**  \n  全局自旋锁（`DEFINE_SPINLOCK`），用于保护 DMA 通道分配/释放操作的原子性（尽管当前实现未显式使用该锁，但供外部模块使用）。\n\n### 主要函数\n\n- **`request_dma(unsigned int dmanr, const char *device_id)`**  \n  请求指定编号的 DMA 通道。若通道有效且空闲，则标记为占用并记录设备 ID；否则返回 `-EINVAL`（通道号越界）或 `-EBUSY`（已被占用）。\n\n- **`free_dma(unsigned int dmanr)`**  \n  释放指定编号的 DMA 通道。若通道已被占用，则将其标记为空闲；若尝试释放未占用或无效通道，会打印警告信息。\n\n- **`proc_dma_show(struct seq_file *m, void *v)`**  \n  用于生成 `/proc/dma` 文件内容，遍历 `dma_chan_busy` 数组，输出所有被占用通道的编号及其设备 ID。\n\n- **`proc_dma_init(void)`**  \n  初始化函数，在内核启动时注册 `/proc/dma` 文件。\n\n## 3. 关键实现\n\n- **原子性保障**：  \n  使用 `xchg()` 原子操作实现对 `dma_chan_busy[].lock` 的读-改-写，确保多 CPU 环境下 DMA 通道分配/释放的线程安全，避免竞态条件。\n\n- **资源分配策略**：  \n  采用简单的位标志数组管理通道状态。通道 4 固定保留用于 DMA 控制器级联（cascade），不可被普通设备申请。\n\n- **条件编译支持**：  \n  通过 `#ifdef MAX_DMA_CHANNELS` 判断平台是否支持传统 DMA。若未定义（如纯现代平台），则 `request_dma()` 直接返回 `-EINVAL`，`free_dma()` 为空操作。\n\n- **/proc 接口**：  \n  仅在 `CONFIG_PROC_FS` 启用时编译 `/proc/dma` 支持。使用 `proc_create_single()` 创建只读文件，通过 `seq_printf()` 安全输出通道使用信息。\n\n- **资源释放顺序建议**：  \n  注释中强调：若同时使用 DMA 和 IRQ，应先申请 IRQ 再申请 DMA，释放时则先释放 DMA 再释放 IRQ，以避免不必要的分配失败（尤其在引入更复杂同步机制后）。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<asm/dma.h>`：定义平台相关的 `MAX_DMA_CHANNELS` 等宏。\n  - `<linux/spinlock.h>`：提供自旋锁和原子操作支持。\n  - `<linux/proc_fs.h>`、`<linux/seq_file.h>`：用于 `/proc/dma` 实现。\n  - 其他通用内核头文件（如 `kernel.h`、`errno.h` 等）。\n\n- **导出符号**：  \n  通过 `EXPORT_SYMBOL` 导出以下符号供其他内核模块使用：\n  - `request_dma`\n  - `free_dma`\n  - `dma_spin_lock`（虽未在本文件中使用，但供外部同步）\n\n- **架构依赖**：  \n  仅在定义了 `MAX_DMA_CHANNELS` 的架构（如 x86、部分 ARM 平台）上启用实际功能；否则提供空实现。\n\n## 5. 使用场景\n\n- **传统 ISA 设备驱动**：  \n  如声卡（Sound Blaster）、软盘控制器、早期网卡等依赖 ISA DMA 通道的设备，在初始化时调用 `request_dma()` 获取通道，退出时调用 `free_dma()` 释放。\n\n- **内核调试与监控**：  \n  用户可通过 `cat /proc/dma` 查看当前系统中 DMA 通道的占用情况，辅助硬件调试或资源冲突排查。\n\n- **嵌入式或兼容性平台**：  \n  在仍使用传统 DMA 控制器的嵌入式系统中，作为底层 DMA 资源管理的基础组件。\n\n- **资源协调**：  \n  在多设备共享有限 DMA 通道的系统中，确保设备驱动按规范申请/释放资源，避免冲突。",
      "similarity": 0.5959804654121399,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/dma.c",
          "start_line": 1,
          "end_line": 69,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * linux/kernel/dma.c: A DMA channel allocator. Inspired by linux/kernel/irq.c.",
            " *",
            " * Written by Hennus Bergman, 1992.",
            " *",
            " * 1994/12/26: Changes by Alex Nash to fix a minor bug in /proc/dma.",
            " *   In the previous version the reported device could end up being wrong,",
            " *   if a device requested a DMA channel that was already in use.",
            " *   [It also happened to remove the sizeof(char *) == sizeof(int)",
            " *   assumption introduced because of those /proc/dma patches. -- Hennus]",
            " */",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/errno.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/string.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/init.h>",
            "#include <asm/dma.h>",
            "",
            "",
            "",
            "/* A note on resource allocation:",
            " *",
            " * All drivers needing DMA channels, should allocate and release them",
            " * through the public routines `request_dma()' and `free_dma()'.",
            " *",
            " * In order to avoid problems, all processes should allocate resources in",
            " * the same sequence and release them in the reverse order.",
            " *",
            " * So, when allocating DMAs and IRQs, first allocate the IRQ, then the DMA.",
            " * When releasing them, first release the DMA, then release the IRQ.",
            " * If you don't, you may cause allocation requests to fail unnecessarily.",
            " * This doesn't really matter now, but it will once we get real semaphores",
            " * in the kernel.",
            " */",
            "",
            "",
            "DEFINE_SPINLOCK(dma_spin_lock);",
            "",
            "/*",
            " *\tIf our port doesn't define this it has no PC like DMA",
            " */",
            "",
            "#ifdef MAX_DMA_CHANNELS",
            "",
            "",
            "/* Channel n is busy iff dma_chan_busy[n].lock != 0.",
            " * DMA0 used to be reserved for DRAM refresh, but apparently not any more...",
            " * DMA4 is reserved for cascading.",
            " */",
            "",
            "struct dma_chan {",
            "\tint  lock;",
            "\tconst char *device_id;",
            "};",
            "",
            "static struct dma_chan dma_chan_busy[MAX_DMA_CHANNELS] = {",
            "\t[4] = { 1, \"cascade\" },",
            "};",
            "",
            "",
            "/**",
            " * request_dma - request and reserve a system DMA channel",
            " * @dmanr: DMA channel number",
            " * @device_id: reserving device ID string, used in /proc/dma",
            " */"
          ],
          "function_name": null,
          "description": "定义DMA通道管理的全局数据结构和辅助函数声明，包含DMA通道忙状态数组、锁变量及设备ID字符串，提供DMA资源分配与释放的公共接口原型",
          "similarity": 0.5017215609550476
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/dma.c",
          "start_line": 70,
          "end_line": 124,
          "content": [
            "int request_dma(unsigned int dmanr, const char * device_id)",
            "{",
            "\tif (dmanr >= MAX_DMA_CHANNELS)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (xchg(&dma_chan_busy[dmanr].lock, 1) != 0)",
            "\t\treturn -EBUSY;",
            "",
            "\tdma_chan_busy[dmanr].device_id = device_id;",
            "",
            "\t/* old flag was 0, now contains 1 to indicate busy */",
            "\treturn 0;",
            "} /* request_dma */",
            "void free_dma(unsigned int dmanr)",
            "{",
            "\tif (dmanr >= MAX_DMA_CHANNELS) {",
            "\t\tprintk(KERN_WARNING \"Trying to free DMA%d\\n\", dmanr);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (xchg(&dma_chan_busy[dmanr].lock, 0) == 0) {",
            "\t\tprintk(KERN_WARNING \"Trying to free free DMA%d\\n\", dmanr);",
            "\t\treturn;",
            "\t}",
            "",
            "} /* free_dma */",
            "int request_dma(unsigned int dmanr, const char *device_id)",
            "{",
            "\treturn -EINVAL;",
            "}",
            "void free_dma(unsigned int dmanr)",
            "{",
            "}",
            "static int proc_dma_show(struct seq_file *m, void *v)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0 ; i < MAX_DMA_CHANNELS ; i++) {",
            "\t\tif (dma_chan_busy[i].lock) {",
            "\t\t\tseq_printf(m, \"%2d: %s\\n\", i,",
            "\t\t\t\t   dma_chan_busy[i].device_id);",
            "\t\t}",
            "\t}",
            "\treturn 0;",
            "}",
            "static int proc_dma_show(struct seq_file *m, void *v)",
            "{",
            "\tseq_puts(m, \"No DMA\\n\");",
            "\treturn 0;",
            "}",
            "static int __init proc_dma_init(void)",
            "{",
            "\tproc_create_single(\"dma\", 0, NULL, proc_dma_show);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "request_dma, free_dma, request_dma, free_dma, proc_dma_show, proc_dma_show, proc_dma_init",
          "description": "实现DMA通道分配与释放逻辑，通过原子操作管理通道占用状态，包含/proc/dma接口实现但存在函数重复定义导致上下文不完整",
          "similarity": 0.5008527040481567
        }
      ]
    }
  ]
}