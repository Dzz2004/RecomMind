{
  "query": "硬中断与软中断区别",
  "timestamp": "2025-12-26 02:15:00",
  "retrieved_files": [
    {
      "source_file": "kernel/softirq.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:26:22\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `softirq.c`\n\n---\n\n# softirq.c 技术文档\n\n## 1. 文件概述\n\n`softirq.c` 是 Linux 内核中实现软中断（softirq）机制的核心文件。软中断是一种延迟执行中断处理下半部（bottom half）的机制，用于在中断上下文之外安全、高效地处理高频率、低延迟要求的任务。该文件负责软中断的注册、调度、执行以及与内核其他子系统（如调度器、RCU、SMP 等）的协同工作，并为每个 CPU 维护独立的软中断状态，确保无锁化和良好的 CPU 局部性。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `softirq_vec[NR_SOFTIRQS]`：全局数组，存储所有软中断类型的处理函数（`softirq_action`），每个软中断类型（如 `NET_RX`、`TIMER` 等）对应一个条目。\n- `ksoftirqd`：每 CPU 变量，指向该 CPU 上专用于处理软中断的内核线程（`ksoftirqd`）。\n- `softirq_to_name[NR_SOFTIRQS]`：软中断类型的名称字符串数组，用于调试和追踪。\n- `softirq_ctrl`（仅限 `CONFIG_PREEMPT_RT`）：每 CPU 结构体，包含本地锁（`local_lock_t`）和计数器（`cnt`），用于在实时内核中管理软中断禁用状态，支持抢占。\n- `irq_stat`：每 CPU 的中断统计结构体（若架构未提供）。\n\n### 主要函数\n\n- `wakeup_softirqd()`：唤醒当前 CPU 的 `ksoftirqd` 内核线程。\n- `__local_bh_disable_ip()` / `__local_bh_enable_ip()`：用于禁用/启用软中断（Bottom Half），并处理嵌套计数、RCU 锁、锁依赖追踪等。\n- `local_bh_blocked()`（仅限 RT）：检查当前 CPU 是否处于软中断被阻塞状态，用于 idle 任务避免误报。\n- `ksoftirqd_run_begin()` / `ksoftirqd_run_end()`：`ksoftirqd` 线程执行软中断前后的上下文管理。\n- `invoke_softirq()`：根据当前软中断状态决定是否唤醒 `ksoftirqd`。\n- `__do_softirq()`（声明在别处，但在此被调用）：实际执行挂起的软中断处理函数。\n\n## 3. 关键实现\n\n### 软中断执行模型\n- 软中断是 **CPU 本地** 的，无共享变量，天然支持 SMP。\n- 若软中断需要序列化（如 `TASKLET`），由其自身通过自旋锁实现。\n- 软中断执行具有 **弱 CPU 绑定**：仅在触发中断的 CPU 上标记为待执行，提升缓存局部性。\n\n### 实时内核（PREEMPT_RT）支持\n- 在 `CONFIG_PREEMPT_RT` 下，软中断禁用状态不再依赖抢占计数器，而是使用每任务（`task_struct::softirq_disable_cnt`）和每 CPU（`softirq_ctrl::cnt`）两个计数器。\n- 引入 `local_lock_t` 保护软中断临界区，允许在 BH 禁用期间被其他高优先级任务抢占。\n- `ksoftirqd` 线程通过 `ksoftirqd_run_begin/end` 获取本地锁，确保重入安全。\n\n### 软中断调度策略\n- 当软中断在原子上下文（不可抢占）中被启用且有待处理任务时，不直接执行，而是唤醒 `ksoftirqd` 线程处理，避免用户空间饥饿。\n- 在可抢占上下文中启用软中断时，若有待处理软中断，则立即调用 `__do_softirq()` 执行。\n\n### 调试与追踪\n- 集成 `lockdep` 锁依赖分析器，通过 `bh_lock_map` 跟踪软中断禁用区域。\n- 支持 `ftrace` 的 `irq` 事件追踪（通过 `trace/events/irq.h`）。\n- 提供 `in_softirq()`、`softirq_count()` 等宏用于上下文判断。\n\n## 4. 依赖关系\n\n- **中断子系统**：依赖 `irq.h`、`interrupt.h` 提供硬中断接口和状态管理。\n- **调度器**：与 `kthread.h` 协作创建和管理 `ksoftirqd` 内核线程；依赖 `sched.h` 相关机制进行唤醒和调度。\n- **RCU**：在 RT 模式下，软中断禁用区域需持有 `rcu_read_lock()`，确保 RCU 语义正确。\n- **SMP 支持**：使用 `smp.h`、`smpboot.h` 实现每 CPU 变量和 CPU 热插拔支持。\n- **内存管理**：依赖 `mm.h` 和 `percpu.h` 管理每 CPU 数据。\n- **调试设施**：集成 `lockdep`（`DEBUG_LOCK_ALLOC`）、`ftrace`、`irqflags tracing` 等调试框架。\n- **架构相关代码**：可能使用 `asm/softirq_stack.h` 提供的架构特定栈处理。\n\n## 5. 使用场景\n\n- **网络子系统**：`NET_RX` 和 `NET_TX` 软中断用于高效处理网络包接收和发送。\n- **块设备层**：`BLOCK` 软中断处理块 I/O 完成回调。\n- **定时器**：`TIMER` 和 `HRTIMER` 软中断用于执行高精度和普通定时器回调。\n- **RCU**：`RCU` 软中断用于执行宽限期（grace period）相关的回调。\n- **任务队列**：`TASKLET` 软中断提供轻量级、序列化的下半部机制。\n- **调度器事件**：`SCHED` 软中断用于处理调度相关的延迟任务（如负载均衡触发）。\n- **中断轮询**：`IRQ_POLL` 用于高吞吐场景下的中断合并与轮询。\n\n该机制广泛应用于需要在中断后快速、批量、低开销处理任务的内核子系统中，是 Linux 中断处理下半部的核心基础设施之一。",
      "similarity": 0.6172045469284058,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/softirq.c",
          "start_line": 1,
          "end_line": 73,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " *\tlinux/kernel/softirq.c",
            " *",
            " *\tCopyright (C) 1992 Linus Torvalds",
            " *",
            " *\tRewritten. Old one was good in 2.2, but in 2.3 it was immoral. --ANK (990903)",
            " */",
            "",
            "#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt",
            "",
            "#include <linux/export.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/init.h>",
            "#include <linux/local_lock.h>",
            "#include <linux/mm.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpu.h>",
            "#include <linux/freezer.h>",
            "#include <linux/kthread.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/smp.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/tick.h>",
            "#include <linux/irq.h>",
            "#include <linux/wait_bit.h>",
            "",
            "#include <asm/softirq_stack.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/irq.h>",
            "",
            "/*",
            "   - No shared variables, all the data are CPU local.",
            "   - If a softirq needs serialization, let it serialize itself",
            "     by its own spinlocks.",
            "   - Even if softirq is serialized, only local cpu is marked for",
            "     execution. Hence, we get something sort of weak cpu binding.",
            "     Though it is still not clear, will it result in better locality",
            "     or will not.",
            "",
            "   Examples:",
            "   - NET RX softirq. It is multithreaded and does not require",
            "     any global serialization.",
            "   - NET TX softirq. It kicks software netdevice queues, hence",
            "     it is logically serialized per device, but this serialization",
            "     is invisible to common code.",
            "   - Tasklets: serialized wrt itself.",
            " */",
            "",
            "#ifndef __ARCH_IRQ_STAT",
            "DEFINE_PER_CPU_ALIGNED(irq_cpustat_t, irq_stat);",
            "EXPORT_PER_CPU_SYMBOL(irq_stat);",
            "#endif",
            "",
            "static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;",
            "",
            "DEFINE_PER_CPU(struct task_struct *, ksoftirqd);",
            "",
            "const char * const softirq_to_name[NR_SOFTIRQS] = {",
            "\t\"HI\", \"TIMER\", \"NET_TX\", \"NET_RX\", \"BLOCK\", \"IRQ_POLL\",",
            "\t\"TASKLET\", \"SCHED\", \"HRTIMER\", \"RCU\"",
            "};",
            "",
            "/*",
            " * we cannot loop indefinitely here to avoid userspace starvation,",
            " * but we also don't want to introduce a worst case 1/HZ latency",
            " * to the pending events, so lets the scheduler to balance",
            " * the softirq load for us.",
            " */"
          ],
          "function_name": null,
          "description": "定义软中断相关数据结构和常量，包括每个CPU的中断统计信息、软中断动作数组及名称映射，描述软中断机制设计原则和示例场景。",
          "similarity": 0.6229656338691711
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/softirq.c",
          "start_line": 417,
          "end_line": 572,
          "content": [
            "static inline void softirq_handle_begin(void)",
            "{",
            "\t__local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET);",
            "}",
            "static inline void softirq_handle_end(void)",
            "{",
            "\t__local_bh_enable(SOFTIRQ_OFFSET);",
            "\tWARN_ON_ONCE(in_interrupt());",
            "}",
            "static inline void ksoftirqd_run_begin(void)",
            "{",
            "\tlocal_irq_disable();",
            "}",
            "static inline void ksoftirqd_run_end(void)",
            "{",
            "\tlocal_irq_enable();",
            "}",
            "static inline bool should_wake_ksoftirqd(void)",
            "{",
            "\treturn true;",
            "}",
            "static inline void invoke_softirq(void)",
            "{",
            "\tif (!force_irqthreads() || !__this_cpu_read(ksoftirqd)) {",
            "#ifdef CONFIG_HAVE_IRQ_EXIT_ON_IRQ_STACK",
            "\t\t/*",
            "\t\t * We can safely execute softirq on the current stack if",
            "\t\t * it is the irq stack, because it should be near empty",
            "\t\t * at this stage.",
            "\t\t */",
            "\t\t__do_softirq();",
            "#else",
            "\t\t/*",
            "\t\t * Otherwise, irq_exit() is called on the task stack that can",
            "\t\t * be potentially deep already. So call softirq in its own stack",
            "\t\t * to prevent from any overrun.",
            "\t\t */",
            "\t\tdo_softirq_own_stack();",
            "#endif",
            "\t} else {",
            "\t\twakeup_softirqd();",
            "\t}",
            "}",
            "asmlinkage __visible void do_softirq(void)",
            "{",
            "\t__u32 pending;",
            "\tunsigned long flags;",
            "",
            "\tif (in_interrupt())",
            "\t\treturn;",
            "",
            "\tlocal_irq_save(flags);",
            "",
            "\tpending = local_softirq_pending();",
            "",
            "\tif (pending)",
            "\t\tdo_softirq_own_stack();",
            "",
            "\tlocal_irq_restore(flags);",
            "}",
            "static inline bool lockdep_softirq_start(void)",
            "{",
            "\tbool in_hardirq = false;",
            "",
            "\tif (lockdep_hardirq_context()) {",
            "\t\tin_hardirq = true;",
            "\t\tlockdep_hardirq_exit();",
            "\t}",
            "",
            "\tlockdep_softirq_enter();",
            "",
            "\treturn in_hardirq;",
            "}",
            "static inline void lockdep_softirq_end(bool in_hardirq)",
            "{",
            "\tlockdep_softirq_exit();",
            "",
            "\tif (in_hardirq)",
            "\t\tlockdep_hardirq_enter();",
            "}",
            "static inline bool lockdep_softirq_start(void) { return false; }",
            "static inline void lockdep_softirq_end(bool in_hardirq) { }",
            "static void handle_softirqs(bool ksirqd)",
            "{",
            "\tunsigned long end = jiffies + MAX_SOFTIRQ_TIME;",
            "\tunsigned long old_flags = current->flags;",
            "\tint max_restart = MAX_SOFTIRQ_RESTART;",
            "\tstruct softirq_action *h;",
            "\tbool in_hardirq;",
            "\t__u32 pending;",
            "\tint softirq_bit;",
            "",
            "\t/*",
            "\t * Mask out PF_MEMALLOC as the current task context is borrowed for the",
            "\t * softirq. A softirq handled, such as network RX, might set PF_MEMALLOC",
            "\t * again if the socket is related to swapping.",
            "\t */",
            "\tcurrent->flags &= ~PF_MEMALLOC;",
            "",
            "\tpending = local_softirq_pending();",
            "",
            "\tsoftirq_handle_begin();",
            "\tin_hardirq = lockdep_softirq_start();",
            "\taccount_softirq_enter(current);",
            "",
            "restart:",
            "\t/* Reset the pending bitmask before enabling irqs */",
            "\tset_softirq_pending(0);",
            "",
            "\tlocal_irq_enable();",
            "",
            "\th = softirq_vec;",
            "",
            "\twhile ((softirq_bit = ffs(pending))) {",
            "\t\tunsigned int vec_nr;",
            "\t\tint prev_count;",
            "",
            "\t\th += softirq_bit - 1;",
            "",
            "\t\tvec_nr = h - softirq_vec;",
            "\t\tprev_count = preempt_count();",
            "",
            "\t\tkstat_incr_softirqs_this_cpu(vec_nr);",
            "",
            "\t\ttrace_softirq_entry(vec_nr);",
            "\t\th->action(h);",
            "\t\ttrace_softirq_exit(vec_nr);",
            "\t\tif (unlikely(prev_count != preempt_count())) {",
            "\t\t\tpr_err(\"huh, entered softirq %u %s %p with preempt_count %08x, exited with %08x?\\n\",",
            "\t\t\t       vec_nr, softirq_to_name[vec_nr], h->action,",
            "\t\t\t       prev_count, preempt_count());",
            "\t\t\tpreempt_count_set(prev_count);",
            "\t\t}",
            "\t\th++;",
            "\t\tpending >>= softirq_bit;",
            "\t}",
            "",
            "\tif (!IS_ENABLED(CONFIG_PREEMPT_RT) && ksirqd)",
            "\t\trcu_softirq_qs();",
            "",
            "\tlocal_irq_disable();",
            "",
            "\tpending = local_softirq_pending();",
            "\tif (pending) {",
            "\t\tif (time_before(jiffies, end) && !need_resched() &&",
            "\t\t    --max_restart)",
            "\t\t\tgoto restart;",
            "",
            "\t\twakeup_softirqd();",
            "\t}",
            "",
            "\taccount_softirq_exit(current);",
            "\tlockdep_softirq_end(in_hardirq);",
            "\tsoftirq_handle_end();",
            "\tcurrent_restore_flags(old_flags, PF_MEMALLOC);",
            "}"
          ],
          "function_name": "softirq_handle_begin, softirq_handle_end, ksoftirqd_run_begin, ksoftirqd_run_end, should_wake_ksoftirqd, invoke_softirq, do_softirq, lockdep_softirq_start, lockdep_softirq_end, lockdep_softirq_start, lockdep_softirq_end, handle_softirqs",
          "description": "实现软中断处理核心流程，包括pending位图扫描、动作执行、RCU状态更新及异常情况检测，包含硬中断上下文转换跟踪机制。",
          "similarity": 0.616725504398346
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/softirq.c",
          "start_line": 618,
          "end_line": 732,
          "content": [
            "void irq_enter_rcu(void)",
            "{",
            "\t__irq_enter_raw();",
            "",
            "\tif (tick_nohz_full_cpu(smp_processor_id()) ||",
            "\t    (is_idle_task(current) && (irq_count() == HARDIRQ_OFFSET)))",
            "\t\ttick_irq_enter();",
            "",
            "\taccount_hardirq_enter(current);",
            "}",
            "void irq_enter(void)",
            "{",
            "\tct_irq_enter();",
            "\tirq_enter_rcu();",
            "}",
            "static inline void tick_irq_exit(void)",
            "{",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "\tint cpu = smp_processor_id();",
            "",
            "\t/* Make sure that timer wheel updates are propagated */",
            "\tif ((sched_core_idle_cpu(cpu) && !need_resched()) || tick_nohz_full_cpu(cpu)) {",
            "\t\tif (!in_hardirq())",
            "\t\t\ttick_nohz_irq_exit();",
            "\t}",
            "#endif",
            "}",
            "static void wake_timersd(void)",
            "{",
            "\tstruct task_struct *tsk = __this_cpu_read(ktimerd);",
            "",
            "\tif (tsk)",
            "\t\twake_up_process(tsk);",
            "}",
            "static inline void wake_timersd(void) { }",
            "static inline void __irq_exit_rcu(void)",
            "{",
            "#ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED",
            "\tlocal_irq_disable();",
            "#else",
            "\tlockdep_assert_irqs_disabled();",
            "#endif",
            "\taccount_hardirq_exit(current);",
            "\tpreempt_count_sub(HARDIRQ_OFFSET);",
            "\tif (!in_interrupt() && local_softirq_pending())",
            "\t\tinvoke_softirq();",
            "",
            "\tif (IS_ENABLED(CONFIG_IRQ_FORCED_THREADING) && force_irqthreads() &&",
            "\t    local_timers_pending_force_th() && !(in_nmi() | in_hardirq()))",
            "\t\twake_timersd();",
            "",
            "\ttick_irq_exit();",
            "}",
            "void irq_exit_rcu(void)",
            "{",
            "\t__irq_exit_rcu();",
            "\t /* must be last! */",
            "\tlockdep_hardirq_exit();",
            "}",
            "void irq_exit(void)",
            "{",
            "\t__irq_exit_rcu();",
            "\tct_irq_exit();",
            "\t /* must be last! */",
            "\tlockdep_hardirq_exit();",
            "}",
            "inline void raise_softirq_irqoff(unsigned int nr)",
            "{",
            "\t__raise_softirq_irqoff(nr);",
            "",
            "\t/*",
            "\t * If we're in an interrupt or softirq, we're done",
            "\t * (this also catches softirq-disabled code). We will",
            "\t * actually run the softirq once we return from",
            "\t * the irq or softirq.",
            "\t *",
            "\t * Otherwise we wake up ksoftirqd to make sure we",
            "\t * schedule the softirq soon.",
            "\t */",
            "\tif (!in_interrupt() && should_wake_ksoftirqd())",
            "\t\twakeup_softirqd();",
            "}",
            "void raise_softirq(unsigned int nr)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\traise_softirq_irqoff(nr);",
            "\tlocal_irq_restore(flags);",
            "}",
            "void __raise_softirq_irqoff(unsigned int nr)",
            "{",
            "\tlockdep_assert_irqs_disabled();",
            "\ttrace_softirq_raise(nr);",
            "\tor_softirq_pending(1UL << nr);",
            "}",
            "void open_softirq(int nr, void (*action)(struct softirq_action *))",
            "{",
            "\tsoftirq_vec[nr].action = action;",
            "}",
            "static void __tasklet_schedule_common(struct tasklet_struct *t,",
            "\t\t\t\t      struct tasklet_head __percpu *headp,",
            "\t\t\t\t      unsigned int softirq_nr)",
            "{",
            "\tstruct tasklet_head *head;",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\thead = this_cpu_ptr(headp);",
            "\tt->next = NULL;",
            "\t*head->tail = t;",
            "\thead->tail = &(t->next);",
            "\traise_softirq_irqoff(softirq_nr);",
            "\tlocal_irq_restore(flags);",
            "}"
          ],
          "function_name": "irq_enter_rcu, irq_enter, tick_irq_exit, wake_timersd, wake_timersd, __irq_exit_rcu, irq_exit_rcu, irq_exit, raise_softirq_irqoff, raise_softirq, __raise_softirq_irqoff, open_softirq, __tasklet_schedule_common",
          "description": "处理中断上下文切换相关操作，包含软中断触发接口、中断进入/退出时的统计更新和唤醒逻辑，以及任务队列调度辅助函数。",
          "similarity": 0.5769151449203491
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/softirq.c",
          "start_line": 74,
          "end_line": 191,
          "content": [
            "static void wakeup_softirqd(void)",
            "{",
            "\t/* Interrupts are disabled: no need to stop preemption */",
            "\tstruct task_struct *tsk = __this_cpu_read(ksoftirqd);",
            "",
            "\tif (tsk)",
            "\t\twake_up_process(tsk);",
            "}",
            "bool local_bh_blocked(void)",
            "{",
            "\treturn __this_cpu_read(softirq_ctrl.cnt) != 0;",
            "}",
            "void __local_bh_disable_ip(unsigned long ip, unsigned int cnt)",
            "{",
            "\tunsigned long flags;",
            "\tint newcnt;",
            "",
            "\tWARN_ON_ONCE(in_hardirq());",
            "",
            "\tlock_map_acquire_read(&bh_lock_map);",
            "",
            "\t/* First entry of a task into a BH disabled section? */",
            "\tif (!current->softirq_disable_cnt) {",
            "\t\tif (preemptible()) {",
            "\t\t\tlocal_lock(&softirq_ctrl.lock);",
            "\t\t\t/* Required to meet the RCU bottomhalf requirements. */",
            "\t\t\trcu_read_lock();",
            "\t\t} else {",
            "\t\t\tDEBUG_LOCKS_WARN_ON(this_cpu_read(softirq_ctrl.cnt));",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * Track the per CPU softirq disabled state. On RT this is per CPU",
            "\t * state to allow preemption of bottom half disabled sections.",
            "\t */",
            "\tnewcnt = __this_cpu_add_return(softirq_ctrl.cnt, cnt);",
            "\t/*",
            "\t * Reflect the result in the task state to prevent recursion on the",
            "\t * local lock and to make softirq_count() & al work.",
            "\t */",
            "\tcurrent->softirq_disable_cnt = newcnt;",
            "",
            "\tif (IS_ENABLED(CONFIG_TRACE_IRQFLAGS) && newcnt == cnt) {",
            "\t\traw_local_irq_save(flags);",
            "\t\tlockdep_softirqs_off(ip);",
            "\t\traw_local_irq_restore(flags);",
            "\t}",
            "}",
            "static void __local_bh_enable(unsigned int cnt, bool unlock)",
            "{",
            "\tunsigned long flags;",
            "\tint newcnt;",
            "",
            "\tDEBUG_LOCKS_WARN_ON(current->softirq_disable_cnt !=",
            "\t\t\t    this_cpu_read(softirq_ctrl.cnt));",
            "",
            "\tif (IS_ENABLED(CONFIG_TRACE_IRQFLAGS) && softirq_count() == cnt) {",
            "\t\traw_local_irq_save(flags);",
            "\t\tlockdep_softirqs_on(_RET_IP_);",
            "\t\traw_local_irq_restore(flags);",
            "\t}",
            "",
            "\tnewcnt = __this_cpu_sub_return(softirq_ctrl.cnt, cnt);",
            "\tcurrent->softirq_disable_cnt = newcnt;",
            "",
            "\tif (!newcnt && unlock) {",
            "\t\trcu_read_unlock();",
            "\t\tlocal_unlock(&softirq_ctrl.lock);",
            "\t}",
            "}",
            "void __local_bh_enable_ip(unsigned long ip, unsigned int cnt)",
            "{",
            "\tbool preempt_on = preemptible();",
            "\tunsigned long flags;",
            "\tu32 pending;",
            "\tint curcnt;",
            "",
            "\tWARN_ON_ONCE(in_hardirq());",
            "\tlockdep_assert_irqs_enabled();",
            "",
            "\tlock_map_release(&bh_lock_map);",
            "",
            "\tlocal_irq_save(flags);",
            "\tcurcnt = __this_cpu_read(softirq_ctrl.cnt);",
            "",
            "\t/*",
            "\t * If this is not reenabling soft interrupts, no point in trying to",
            "\t * run pending ones.",
            "\t */",
            "\tif (curcnt != cnt)",
            "\t\tgoto out;",
            "",
            "\tpending = local_softirq_pending();",
            "\tif (!pending)",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * If this was called from non preemptible context, wake up the",
            "\t * softirq daemon.",
            "\t */",
            "\tif (!preempt_on) {",
            "\t\twakeup_softirqd();",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * Adjust softirq count to SOFTIRQ_OFFSET which makes",
            "\t * in_serving_softirq() become true.",
            "\t */",
            "\tcnt = SOFTIRQ_OFFSET;",
            "\t__local_bh_enable(cnt, false);",
            "\t__do_softirq();",
            "",
            "out:",
            "\t__local_bh_enable(cnt, preempt_on);",
            "\tlocal_irq_restore(flags);",
            "}"
          ],
          "function_name": "wakeup_softirqd, local_bh_blocked, __local_bh_disable_ip, __local_bh_enable, __local_bh_enable_ip",
          "description": "实现软中断屏蔽/恢复逻辑，通过修改per-CPU计数器控制软中断状态，包含唤醒ksoftirqd线程的逻辑，处理抢占和锁依赖关系。",
          "similarity": 0.5745692253112793
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/softirq.c",
          "start_line": 1059,
          "end_line": 1085,
          "content": [
            "static __init int spawn_ksoftirqd(void)",
            "{",
            "\tcpuhp_setup_state_nocalls(CPUHP_SOFTIRQ_DEAD, \"softirq:dead\", NULL,",
            "\t\t\t\t  takeover_tasklets);",
            "\tBUG_ON(smpboot_register_percpu_thread(&softirq_threads));",
            "#ifdef CONFIG_IRQ_FORCED_THREADING",
            "\tif (force_irqthreads())",
            "\t\tBUG_ON(smpboot_register_percpu_thread(&timer_thread));",
            "#endif",
            "\treturn 0;",
            "}",
            "int __init __weak early_irq_init(void)",
            "{",
            "\treturn 0;",
            "}",
            "int __init __weak arch_probe_nr_irqs(void)",
            "{",
            "\treturn NR_IRQS_LEGACY;",
            "}",
            "int __init __weak arch_early_irq_init(void)",
            "{",
            "\treturn 0;",
            "}",
            "unsigned int __weak arch_dynirq_lower_bound(unsigned int from)",
            "{",
            "\treturn from;",
            "}"
          ],
          "function_name": "spawn_ksoftirqd, early_irq_init, arch_probe_nr_irqs, arch_early_irq_init, arch_dynirq_lower_bound",
          "description": "实现软中断处理线程的注册与早期中断初始化，spawn_ksoftirqd注册软中断处理线程并绑定takeover_tasklets，arch_*系列弱符号接口处理不同架构的中断探测与动态中断范围计算",
          "similarity": 0.5284537076950073
        }
      ]
    },
    {
      "source_file": "kernel/irq/handle.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:55:29\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\handle.c`\n\n---\n\n# `irq/handle.c` 技术文档\n\n## 1. 文件概述\n\n`irq/handle.c` 是 Linux 内核通用中断子系统（Generic IRQ）的核心实现文件之一，负责中断事件的高层处理逻辑。该文件实现了中断处理流程中的关键函数，包括中断动作（`irqaction`）的调用、线程化中断的唤醒机制、未处理或异常中断的处理，以及架构无关的中断入口封装。其目标是为不同硬件架构提供统一、可扩展的中断处理框架。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`handle_bad_irq(struct irq_desc *desc)`**  \n  处理伪中断（spurious IRQ）或未注册处理函数的中断，记录统计信息并调用架构相关的 `ack_bad_irq()`。\n\n- **`no_action(int cpl, void *dev_id)`**  \n  空中断处理函数，返回 `IRQ_NONE`，常用于占位或测试。\n\n- **`__irq_wake_thread(struct irq_desc *desc, struct irqaction *action)`**  \n  唤醒与中断动作关联的内核线程（用于线程化中断），管理 `threads_oneshot` 和 `threads_active` 状态。\n\n- **`__handle_irq_event_percpu(struct irq_desc *desc)`**  \n  在当前 CPU 上遍历并执行该中断描述符关联的所有 `irqaction` 处理函数，支持 `IRQ_WAKE_THREAD` 返回值以触发线程化处理。\n\n- **`handle_irq_event_percpu(struct irq_desc *desc)`**  \n  对 `__handle_irq_event_percpu` 的封装，附加中断随机数注入（`add_interrupt_randomness`）和调试记录（`note_interrupt`）。\n\n- **`handle_irq_event(struct irq_desc *desc)`**  \n  中断事件处理的顶层入口，负责清除 `IRQS_PENDING` 状态、设置 `IRQD_IRQ_INPROGRESS` 标志，并在释放 `desc->lock` 后调用 per-CPU 处理函数，最后恢复锁和状态。\n\n- **`generic_handle_arch_irq(struct pt_regs *regs)`**（仅当 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 启用）  \n  架构无关的通用中断入口点，封装 `irq_enter()`/`irq_exit()` 和寄存器上下文切换。\n\n- **`set_handle_irq(void (*handle_irq)(struct pt_regs *))`**（仅当 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 启用）  \n  初始化架构特定的底层中断处理函数指针 `handle_arch_irq`。\n\n### 关键数据结构（引用）\n\n- `struct irq_desc`：中断描述符，包含中断状态、动作链表、锁等。\n- `struct irqaction`：中断动作，包含处理函数 `handler`、线程函数 `thread_fn`、设备 ID、标志等。\n- `handle_arch_irq`：函数指针，指向架构特定的底层中断分发函数（仅在 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 下定义）。\n\n## 3. 关键实现\n\n### 线程化中断唤醒机制\n\n当硬中断处理函数返回 `IRQ_WAKE_THREAD` 时，内核需唤醒对应的线程处理下半部。`__irq_wake_thread` 实现了以下关键逻辑：\n\n- 检查线程是否已退出（`PF_EXITING`），若是则忽略。\n- 使用原子位操作 `test_and_set_bit(IRQTF_RUNTHREAD, ...)` 避免重复唤醒。\n- 通过 `desc->threads_oneshot |= action->thread_mask` 标记需运行的线程。\n- 原子递增 `desc->threads_active`，供 `synchronize_irq()` 等同步原语使用。\n- 调用 `wake_up_process()` 唤醒内核线程。\n\n该机制通过 `IRQS_INPROGRESS` 状态和 `desc->lock` 实现硬中断上下文与中断线程之间的同步，确保 `threads_oneshot` 的读写安全。\n\n### 中断处理流程控制\n\n`handle_irq_event` 是中断流控的关键：\n\n1. 清除 `IRQS_PENDING`（表示中断已开始处理）。\n2. 设置 `IRQD_IRQ_INPROGRESS`（防止嵌套处理）。\n3. 释放 `desc->lock`，允许中断线程或其他 CPU 并发访问。\n4. 调用 `handle_irq_event_percpu` 执行实际处理。\n5. 重新获取锁，清除 `IRQD_IRQ_INPROGRESS`。\n\n此设计解耦了中断流控（如电平触发中断的 EOI）与具体处理逻辑，提高并发性。\n\n### 架构无关中断入口（`CONFIG_GENERIC_IRQ_MULTI_HANDLER`）\n\n该配置允许架构代码注册一个统一的中断入口函数 `handle_arch_irq`。`generic_handle_arch_irq` 作为通用包装器：\n\n- 调用 `irq_enter()` 进入中断上下文。\n- 使用 `set_irq_regs()` 切换当前 CPU 的中断寄存器上下文。\n- 调用注册的 `handle_arch_irq` 进行实际分发。\n- 恢复寄存器上下文并调用 `irq_exit()`。\n\n适用于不自行管理中断入口计数和上下文的架构（如 ARM64）。\n\n### 安全与调试\n\n- **中断使能检查**：在调用 `action->handler` 后，检查中断是否被意外使能（`WARN_ONCE(!irqs_disabled(), ...)`），若发现则强制禁用。\n- **伪中断处理**：`handle_bad_irq` 提供统一的异常中断处理路径，便于调试和统计。\n- **随机数注入**：通过 `add_interrupt_randomness()` 利用中断时间戳增强内核熵池。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/irq.h>`、`<linux/interrupt.h>`：中断核心 API 和数据结构。\n  - `<linux/kernel_stat.h>`：中断统计（`kstat_incr_irqs_this_cpu`）。\n  - `<linux/random.h>`：中断随机数注入。\n  - `<asm/irq_regs.h>`：架构相关的中断寄存器上下文管理。\n  - `\"internals.h\"`：中断子系统内部实现细节。\n  - `<trace/events/irq.h>`：中断事件跟踪点。\n\n- **模块依赖**：\n  - **Generic IRQ 子系统**：依赖 `irqdesc.c`、`irqchip.c` 等提供的 `irq_desc` 管理。\n  - **调度器**：`wake_up_process()` 依赖进程调度。\n  - **RCU 与同步原语**：`synchronize_irq()` 依赖 `threads_active` 计数。\n  - **架构代码**：`ack_bad_irq()`、`handle_arch_irq` 由具体架构实现。\n\n## 5. 使用场景\n\n- **设备驱动注册中断处理函数**：驱动通过 `request_irq()` 注册 `irqaction`，中断触发时由 `handle_irq_event_percpu` 调用其 `handler`。\n- **线程化中断处理**：驱动设置 `IRQF_ONESHOT` 并提供 `thread_fn`，硬中断返回 `IRQ_WAKE_THREAD` 后由 `__irq_wake_thread` 唤醒线程。\n- **伪中断或未处理中断**：硬件误触发或未注册处理函数的中断由 `handle_bad_irq` 统一处理。\n- **架构中断入口**：在 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 架构（如 ARM64）中，异常向量表直接跳转至 `generic_handle_arch_irq`。\n- **中断同步**：`synchronize_irq()` 等函数依赖 `threads_active` 计数等待线程化中断完成。\n- **内核调试与监控**：通过 `note_interrupt()` 记录异常中断，通过 ftrace 的 `irq_handler_entry/exit` 跟踪点监控中断处理性能。",
      "similarity": 0.5528929233551025,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/handle.c",
          "start_line": 1,
          "end_line": 32,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar",
            " * Copyright (C) 2005-2006, Thomas Gleixner, Russell King",
            " *",
            " * This file contains the core interrupt handling code. Detailed",
            " * information is available in Documentation/core-api/genericirq.rst",
            " *",
            " */",
            "",
            "#include <linux/irq.h>",
            "#include <linux/random.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "",
            "#include <asm/irq_regs.h>",
            "",
            "#include <trace/events/irq.h>",
            "",
            "#include \"internals.h\"",
            "",
            "#ifdef CONFIG_GENERIC_IRQ_MULTI_HANDLER",
            "void (*handle_arch_irq)(struct pt_regs *) __ro_after_init;",
            "#endif",
            "",
            "/**",
            " * handle_bad_irq - handle spurious and unhandled irqs",
            " * @desc:      description of the interrupt",
            " *",
            " * Handles spurious and unhandled IRQ's. It also prints a debugmessage.",
            " */"
          ],
          "function_name": null,
          "description": "定义了处理异常中断的函数handle_bad_irq，用于处理未处理或误触发的中断，打印调试信息并更新中断统计",
          "similarity": 0.5060085654258728
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/handle.c",
          "start_line": 33,
          "end_line": 178,
          "content": [
            "void handle_bad_irq(struct irq_desc *desc)",
            "{",
            "\tunsigned int irq = irq_desc_get_irq(desc);",
            "",
            "\tprint_irq_desc(irq, desc);",
            "\tkstat_incr_irqs_this_cpu(desc);",
            "\tack_bad_irq(irq);",
            "}",
            "irqreturn_t no_action(int cpl, void *dev_id)",
            "{",
            "\treturn IRQ_NONE;",
            "}",
            "static void warn_no_thread(unsigned int irq, struct irqaction *action)",
            "{",
            "\tif (test_and_set_bit(IRQTF_WARNED, &action->thread_flags))",
            "\t\treturn;",
            "",
            "\tprintk(KERN_WARNING \"IRQ %d device %s returned IRQ_WAKE_THREAD \"",
            "\t       \"but no thread function available.\", irq, action->name);",
            "}",
            "void __irq_wake_thread(struct irq_desc *desc, struct irqaction *action)",
            "{",
            "\t/*",
            "\t * In case the thread crashed and was killed we just pretend that",
            "\t * we handled the interrupt. The hardirq handler has disabled the",
            "\t * device interrupt, so no irq storm is lurking.",
            "\t */",
            "\tif (action->thread->flags & PF_EXITING)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Wake up the handler thread for this action. If the",
            "\t * RUNTHREAD bit is already set, nothing to do.",
            "\t */",
            "\tif (test_and_set_bit(IRQTF_RUNTHREAD, &action->thread_flags))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * It's safe to OR the mask lockless here. We have only two",
            "\t * places which write to threads_oneshot: This code and the",
            "\t * irq thread.",
            "\t *",
            "\t * This code is the hard irq context and can never run on two",
            "\t * cpus in parallel. If it ever does we have more serious",
            "\t * problems than this bitmask.",
            "\t *",
            "\t * The irq threads of this irq which clear their \"running\" bit",
            "\t * in threads_oneshot are serialized via desc->lock against",
            "\t * each other and they are serialized against this code by",
            "\t * IRQS_INPROGRESS.",
            "\t *",
            "\t * Hard irq handler:",
            "\t *",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tdesc->state |= IRQS_INPROGRESS;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *\tset_bit(IRQTF_RUNTHREAD, &action->thread_flags);",
            "\t *\tdesc->threads_oneshot |= mask;",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tdesc->state &= ~IRQS_INPROGRESS;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *",
            "\t * irq thread:",
            "\t *",
            "\t * again:",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tif (desc->state & IRQS_INPROGRESS) {",
            "\t *\t\tspin_unlock(desc->lock);",
            "\t *\t\twhile(desc->state & IRQS_INPROGRESS)",
            "\t *\t\t\tcpu_relax();",
            "\t *\t\tgoto again;",
            "\t *\t}",
            "\t *\tif (!test_bit(IRQTF_RUNTHREAD, &action->thread_flags))",
            "\t *\t\tdesc->threads_oneshot &= ~mask;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *",
            "\t * So either the thread waits for us to clear IRQS_INPROGRESS",
            "\t * or we are waiting in the flow handler for desc->lock to be",
            "\t * released before we reach this point. The thread also checks",
            "\t * IRQTF_RUNTHREAD under desc->lock. If set it leaves",
            "\t * threads_oneshot untouched and runs the thread another time.",
            "\t */",
            "\tdesc->threads_oneshot |= action->thread_mask;",
            "",
            "\t/*",
            "\t * We increment the threads_active counter in case we wake up",
            "\t * the irq thread. The irq thread decrements the counter when",
            "\t * it returns from the handler or in the exit path and wakes",
            "\t * up waiters which are stuck in synchronize_irq() when the",
            "\t * active count becomes zero. synchronize_irq() is serialized",
            "\t * against this code (hard irq handler) via IRQS_INPROGRESS",
            "\t * like the finalize_oneshot() code. See comment above.",
            "\t */",
            "\tatomic_inc(&desc->threads_active);",
            "",
            "\twake_up_process(action->thread);",
            "}",
            "irqreturn_t __handle_irq_event_percpu(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t retval = IRQ_NONE;",
            "\tunsigned int irq = desc->irq_data.irq;",
            "\tstruct irqaction *action;",
            "",
            "\trecord_irq_time(desc);",
            "",
            "\tfor_each_action_of_desc(desc, action) {",
            "\t\tirqreturn_t res;",
            "",
            "\t\t/*",
            "\t\t * If this IRQ would be threaded under force_irqthreads, mark it so.",
            "\t\t */",
            "\t\tif (irq_settings_can_thread(desc) &&",
            "\t\t    !(action->flags & (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT)))",
            "\t\t\tlockdep_hardirq_threaded();",
            "",
            "\t\ttrace_irq_handler_entry(irq, action);",
            "\t\tres = action->handler(irq, action->dev_id);",
            "\t\ttrace_irq_handler_exit(irq, action, res);",
            "",
            "\t\tif (WARN_ONCE(!irqs_disabled(),\"irq %u handler %pS enabled interrupts\\n\",",
            "\t\t\t      irq, action->handler))",
            "\t\t\tlocal_irq_disable();",
            "",
            "\t\tswitch (res) {",
            "\t\tcase IRQ_WAKE_THREAD:",
            "\t\t\t/*",
            "\t\t\t * Catch drivers which return WAKE_THREAD but",
            "\t\t\t * did not set up a thread function",
            "\t\t\t */",
            "\t\t\tif (unlikely(!action->thread_fn)) {",
            "\t\t\t\twarn_no_thread(irq, action);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "",
            "\t\t\t__irq_wake_thread(desc, action);",
            "\t\t\tbreak;",
            "",
            "\t\tdefault:",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tretval |= res;",
            "\t}",
            "",
            "\treturn retval;",
            "}"
          ],
          "function_name": "handle_bad_irq, no_action, warn_no_thread, __irq_wake_thread, __handle_irq_event_percpu",
          "description": "实现中断处理核心逻辑，包括错误中断处理、唤醒线程函数、事件分发及中断处理结果收集，包含中断线程唤醒与状态同步机制",
          "similarity": 0.48127686977386475
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/irq/handle.c",
          "start_line": 189,
          "end_line": 232,
          "content": [
            "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t retval;",
            "",
            "\tretval = __handle_irq_event_percpu(desc);",
            "",
            "\tadd_interrupt_randomness(desc->irq_data.irq);",
            "",
            "\tif (!irq_settings_no_debug(desc))",
            "\t\tnote_interrupt(desc, retval);",
            "\treturn retval;",
            "}",
            "irqreturn_t handle_irq_event(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t ret;",
            "",
            "\tdesc->istate &= ~IRQS_PENDING;",
            "\tirqd_set(&desc->irq_data, IRQD_IRQ_INPROGRESS);",
            "\traw_spin_unlock(&desc->lock);",
            "",
            "\tret = handle_irq_event_percpu(desc);",
            "",
            "\traw_spin_lock(&desc->lock);",
            "\tirqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);",
            "\treturn ret;",
            "}",
            "int __init set_handle_irq(void (*handle_irq)(struct pt_regs *))",
            "{",
            "\tif (handle_arch_irq)",
            "\t\treturn -EBUSY;",
            "",
            "\thandle_arch_irq = handle_irq;",
            "\treturn 0;",
            "}",
            "asmlinkage void noinstr generic_handle_arch_irq(struct pt_regs *regs)",
            "{",
            "\tstruct pt_regs *old_regs;",
            "",
            "\tirq_enter();",
            "\told_regs = set_irq_regs(regs);",
            "\thandle_arch_irq(regs);",
            "\tset_irq_regs(old_regs);",
            "\tirq_exit();",
            "}"
          ],
          "function_name": "handle_irq_event_percpu, handle_irq_event, set_handle_irq, generic_handle_arch_irq",
          "description": "提供中断事件处理接口，包含通用架构中断入口点generic_handle_arch_irq，管理中断处理流程并集成随机化干扰注入功能",
          "similarity": 0.4710526466369629
        }
      ]
    },
    {
      "source_file": "kernel/irq_work.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:11:23\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq_work.c`\n\n---\n\n# `irq_work.c` 技术文档\n\n## 1. 文件概述\n\n`irq_work.c` 实现了一个轻量级的中断上下文工作队列机制，允许在硬中断（hardirq）或 NMI（不可屏蔽中断）上下文中安全地调度回调函数，并在稍后的硬中断上下文或专用内核线程中执行。该机制的核心目标是提供一种 **NMI 安全** 的方式来延迟执行某些不能在 NMI 或硬中断中直接完成的操作。\n\n该框架特别适用于需要从 NMI 或硬中断中触发后续处理（如 perf 事件、ftrace、RCU 等子系统）但又不能阻塞或执行复杂逻辑的场景。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct irq_work`：表示一个中断工作项，包含回调函数 `func` 和状态标志（如 `IRQ_WORK_PENDING`、`IRQ_WORK_CLAIMED`、`IRQ_WORK_BUSY`、`IRQ_WORK_LAZY`、`IRQ_WORK_HARD_IRQ`）。\n- 每 CPU 变量：\n  - `raised_list`：存放需在硬中断上下文中立即处理的工作项。\n  - `lazy_list`：存放“惰性”工作项，在非硬中断上下文（如 tick 或专用线程）中处理。\n  - `irq_workd`：指向每 CPU 的 `irq_work` 内核线程（仅在 `CONFIG_PREEMPT_RT` 下使用）。\n\n### 主要函数\n\n| 函数 | 功能 |\n|------|------|\n| `irq_work_queue(struct irq_work *work)` | 在当前 CPU 上排队一个 `irq_work`，若未被声明则声明并入队。 |\n| `irq_work_queue_on(struct irq_work *work, int cpu)` | 将 `irq_work` 排队到指定 CPU（支持跨 CPU 调度）。 |\n| `irq_work_run(void)` | 在当前 CPU 上执行所有 `raised_list` 和（非 RT 下的）`lazy_list` 中的工作项。 |\n| `irq_work_tick(void)` | 由时钟 tick 调用，处理未被硬中断处理的 `raised_list` 和 `lazy_list`。 |\n| `irq_work_sync(struct irq_work *work)` | 同步等待指定 `irq_work` 执行完毕。 |\n| `irq_work_single(void *arg)` | 执行单个工作项的回调函数，并清理状态。 |\n| `arch_irq_work_raise(void)` | 架构相关函数，用于触发 IPI 或中断以唤醒处理逻辑（弱符号，默认为空）。 |\n\n## 3. 关键实现\n\n### 状态管理与原子操作\n\n- 每个 `irq_work` 通过 `atomic_t node.a_flags` 管理状态：\n  - `IRQ_WORK_PENDING`：表示工作项已入队但尚未执行。\n  - `IRQ_WORK_CLAIMED`：表示已被声明，防止重复入队。\n  - `IRQ_WORK_BUSY`：表示正在执行中。\n- `irq_work_claim()` 使用 `atomic_fetch_or()` 原子地设置 `CLAIMED` 和 `PENDING` 标志，并检查是否已存在，避免重复入队。\n\n### 双队列设计\n\n- **`raised_list`**：用于需要尽快在硬中断上下文执行的工作（如标记为 `IRQ_WORK_HARD_IRQ` 的项）。\n- **`lazy_list`**：\n  - 在非 RT 内核中，由 `irq_work_tick()` 或 `irq_work_run()` 在软中断或进程上下文中处理。\n  - 在 `CONFIG_PREEMPT_RT` 下，由每 CPU 的 `irq_work/%u` 内核线程处理（以避免在硬中断中执行非硬实时代码）。\n\n### NMI 安全性\n\n- 入队操作（如 `irq_work_queue`）仅使用原子操作和每 CPU 链表（`llist`），不涉及锁或内存分配，因此可在 NMI 上下文中安全调用。\n- 跨 CPU 入队时（`irq_work_queue_on`）会检查 `in_nmi()`，防止在 NMI 中调用非 NMI 安全的 IPI 发送函数。\n\n### PREEMPT_RT 支持\n\n- 在 RT 内核中，非 `IRQ_WORK_HARD_IRQ` 的工作项被放入 `lazy_list`，并通过专用内核线程执行，以避免在硬中断中运行可能阻塞或延迟高的代码。\n- 使用 `rcuwait` 机制实现 `irq_work_sync()` 的睡眠等待。\n\n### IPI 触发机制\n\n- 若架构支持（通过 `arch_irq_work_has_interrupt()`），调用 `arch_irq_work_raise()` 触发本地中断处理。\n- 否则依赖时钟 tick（`irq_work_tick`）或显式调用 `irq_work_run` 来处理队列。\n\n## 4. 依赖关系\n\n- **架构依赖**：\n  - `arch_irq_work_raise()` 和 `arch_irq_work_has_interrupt()` 需由具体架构实现（如 x86 提供）。\n- **内核子系统**：\n  - `llist`（无锁链表）：用于高效、无锁的每 CPU 队列管理。\n  - `smpboot`：用于注册每 CPU 内核线程（RT 模式）。\n  - `rcu`：`rcuwait` 用于同步等待（RT 模式）。\n  - `tick`：`tick_nohz_tick_stopped()` 用于判断是否需要立即触发处理。\n  - `trace_events`：IPI 跟踪点 `trace_ipi_send_cpu`。\n- **配置选项**：\n  - `CONFIG_SMP`：启用跨 CPU 调度和 IPI 支持。\n  - `CONFIG_PREEMPT_RT`：启用 RT 模式下的线程化处理。\n\n## 5. 使用场景\n\n- **性能监控（perf）**：从 NMI 中记录采样后，通过 `irq_work` 安全地将数据传递到常规上下文处理。\n- **ftrace / tracing**：在中断上下文中触发延迟的跟踪事件处理。\n- **RCU**：某些 RCU 实现使用 `irq_work` 来触发宽限期处理。\n- **热插拔 CPU**：在 CPU 离线前通过 `flush_smp_call_function_queue()` 调用 `irq_work_run()` 确保工作项被清空。\n- **中断负载均衡或延迟处理**：将非关键中断处理逻辑延迟到更安全的上下文执行。\n\n该机制为内核提供了一种高效、安全且可扩展的中断后处理框架，尤其适用于实时性和可靠性要求高的子系统。",
      "similarity": 0.528952419757843,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/irq_work.c",
          "start_line": 31,
          "end_line": 157,
          "content": [
            "static void wake_irq_workd(void)",
            "{",
            "\tstruct task_struct *tsk = __this_cpu_read(irq_workd);",
            "",
            "\tif (!llist_empty(this_cpu_ptr(&lazy_list)) && tsk)",
            "\t\twake_up_process(tsk);",
            "}",
            "static void irq_work_wake(struct irq_work *entry)",
            "{",
            "\twake_irq_workd();",
            "}",
            "static int irq_workd_should_run(unsigned int cpu)",
            "{",
            "\treturn !llist_empty(this_cpu_ptr(&lazy_list));",
            "}",
            "static bool irq_work_claim(struct irq_work *work)",
            "{",
            "\tint oflags;",
            "",
            "\toflags = atomic_fetch_or(IRQ_WORK_CLAIMED | CSD_TYPE_IRQ_WORK, &work->node.a_flags);",
            "\t/*",
            "\t * If the work is already pending, no need to raise the IPI.",
            "\t * The pairing smp_mb() in irq_work_single() makes sure",
            "\t * everything we did before is visible.",
            "\t */",
            "\tif (oflags & IRQ_WORK_PENDING)",
            "\t\treturn false;",
            "\treturn true;",
            "}",
            "void __weak arch_irq_work_raise(void)",
            "{",
            "\t/*",
            "\t * Lame architectures will get the timer tick callback",
            "\t */",
            "}",
            "static __always_inline void irq_work_raise(struct irq_work *work)",
            "{",
            "\tif (trace_ipi_send_cpu_enabled() && arch_irq_work_has_interrupt())",
            "\t\ttrace_ipi_send_cpu(smp_processor_id(), _RET_IP_, work->func);",
            "",
            "\tarch_irq_work_raise();",
            "}",
            "static void __irq_work_queue_local(struct irq_work *work)",
            "{",
            "\tstruct llist_head *list;",
            "\tbool rt_lazy_work = false;",
            "\tbool lazy_work = false;",
            "\tint work_flags;",
            "",
            "\twork_flags = atomic_read(&work->node.a_flags);",
            "\tif (work_flags & IRQ_WORK_LAZY)",
            "\t\tlazy_work = true;",
            "\telse if (IS_ENABLED(CONFIG_PREEMPT_RT) &&",
            "\t\t !(work_flags & IRQ_WORK_HARD_IRQ))",
            "\t\trt_lazy_work = true;",
            "",
            "\tif (lazy_work || rt_lazy_work)",
            "\t\tlist = this_cpu_ptr(&lazy_list);",
            "\telse",
            "\t\tlist = this_cpu_ptr(&raised_list);",
            "",
            "\tif (!llist_add(&work->node.llist, list))",
            "\t\treturn;",
            "",
            "\t/* If the work is \"lazy\", handle it from next tick if any */",
            "\tif (!lazy_work || tick_nohz_tick_stopped())",
            "\t\tirq_work_raise(work);",
            "}",
            "bool irq_work_queue(struct irq_work *work)",
            "{",
            "\t/* Only queue if not already pending */",
            "\tif (!irq_work_claim(work))",
            "\t\treturn false;",
            "",
            "\t/* Queue the entry and raise the IPI if needed. */",
            "\tpreempt_disable();",
            "\t__irq_work_queue_local(work);",
            "\tpreempt_enable();",
            "",
            "\treturn true;",
            "}",
            "bool irq_work_queue_on(struct irq_work *work, int cpu)",
            "{",
            "#ifndef CONFIG_SMP",
            "\treturn irq_work_queue(work);",
            "",
            "#else /* CONFIG_SMP: */",
            "\t/* All work should have been flushed before going offline */",
            "\tWARN_ON_ONCE(cpu_is_offline(cpu));",
            "",
            "\t/* Only queue if not already pending */",
            "\tif (!irq_work_claim(work))",
            "\t\treturn false;",
            "",
            "\tkasan_record_aux_stack_noalloc(work);",
            "",
            "\tpreempt_disable();",
            "\tif (cpu != smp_processor_id()) {",
            "\t\t/* Arch remote IPI send/receive backend aren't NMI safe */",
            "\t\tWARN_ON_ONCE(in_nmi());",
            "",
            "\t\t/*",
            "\t\t * On PREEMPT_RT the items which are not marked as",
            "\t\t * IRQ_WORK_HARD_IRQ are added to the lazy list and a HARD work",
            "\t\t * item is used on the remote CPU to wake the thread.",
            "\t\t */",
            "\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) &&",
            "\t\t    !(atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ)) {",
            "",
            "\t\t\tif (!llist_add(&work->node.llist, &per_cpu(lazy_list, cpu)))",
            "\t\t\t\tgoto out;",
            "",
            "\t\t\twork = &per_cpu(irq_work_wakeup, cpu);",
            "\t\t\tif (!irq_work_claim(work))",
            "\t\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\t__smp_call_single_queue(cpu, &work->node.llist);",
            "\t} else {",
            "\t\t__irq_work_queue_local(work);",
            "\t}",
            "out:",
            "\tpreempt_enable();",
            "",
            "\treturn true;",
            "#endif /* CONFIG_SMP */",
            "}"
          ],
          "function_name": "wake_irq_workd, irq_work_wake, irq_workd_should_run, irq_work_claim, arch_irq_work_raise, irq_work_raise, __irq_work_queue_local, irq_work_queue, irq_work_queue_on",
          "description": "实现了中断工作项的排队逻辑，区分硬中断与延迟工作项，通过IPI或线程唤醒机制确保跨CPU执行，支持PREEMPT_RT配置下的延迟处理",
          "similarity": 0.5483415722846985
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/irq_work.c",
          "start_line": 184,
          "end_line": 286,
          "content": [
            "bool irq_work_needs_cpu(void)",
            "{",
            "\tstruct llist_head *raised, *lazy;",
            "",
            "\traised = this_cpu_ptr(&raised_list);",
            "\tlazy = this_cpu_ptr(&lazy_list);",
            "",
            "\tif (llist_empty(raised) || arch_irq_work_has_interrupt())",
            "\t\tif (llist_empty(lazy))",
            "\t\t\treturn false;",
            "",
            "\t/* All work should have been flushed before going offline */",
            "\tWARN_ON_ONCE(cpu_is_offline(smp_processor_id()));",
            "",
            "\treturn true;",
            "}",
            "void irq_work_single(void *arg)",
            "{",
            "\tstruct irq_work *work = arg;",
            "\tint flags;",
            "",
            "\t/*",
            "\t * Clear the PENDING bit, after this point the @work can be re-used.",
            "\t * The PENDING bit acts as a lock, and we own it, so we can clear it",
            "\t * without atomic ops.",
            "\t */",
            "\tflags = atomic_read(&work->node.a_flags);",
            "\tflags &= ~IRQ_WORK_PENDING;",
            "\tatomic_set(&work->node.a_flags, flags);",
            "",
            "\t/*",
            "\t * See irq_work_claim().",
            "\t */",
            "\tsmp_mb();",
            "",
            "\tlockdep_irq_work_enter(flags);",
            "\twork->func(work);",
            "\tlockdep_irq_work_exit(flags);",
            "",
            "\t/*",
            "\t * Clear the BUSY bit, if set, and return to the free state if no-one",
            "\t * else claimed it meanwhile.",
            "\t */",
            "\t(void)atomic_cmpxchg(&work->node.a_flags, flags, flags & ~IRQ_WORK_BUSY);",
            "",
            "\tif ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||",
            "\t    !arch_irq_work_has_interrupt())",
            "\t\trcuwait_wake_up(&work->irqwait);",
            "}",
            "static void irq_work_run_list(struct llist_head *list)",
            "{",
            "\tstruct irq_work *work, *tmp;",
            "\tstruct llist_node *llnode;",
            "",
            "\t/*",
            "\t * On PREEMPT_RT IRQ-work which is not marked as HARD will be processed",
            "\t * in a per-CPU thread in preemptible context. Only the items which are",
            "\t * marked as IRQ_WORK_HARD_IRQ will be processed in hardirq context.",
            "\t */",
            "\tBUG_ON(!irqs_disabled() && !IS_ENABLED(CONFIG_PREEMPT_RT));",
            "",
            "\tif (llist_empty(list))",
            "\t\treturn;",
            "",
            "\tllnode = llist_del_all(list);",
            "\tllist_for_each_entry_safe(work, tmp, llnode, node.llist)",
            "\t\tirq_work_single(work);",
            "}",
            "void irq_work_run(void)",
            "{",
            "\tirq_work_run_list(this_cpu_ptr(&raised_list));",
            "\tif (!IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\tirq_work_run_list(this_cpu_ptr(&lazy_list));",
            "\telse",
            "\t\twake_irq_workd();",
            "}",
            "void irq_work_tick(void)",
            "{",
            "\tstruct llist_head *raised = this_cpu_ptr(&raised_list);",
            "",
            "\tif (!llist_empty(raised) && !arch_irq_work_has_interrupt())",
            "\t\tirq_work_run_list(raised);",
            "",
            "\tif (!IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\tirq_work_run_list(this_cpu_ptr(&lazy_list));",
            "\telse",
            "\t\twake_irq_workd();",
            "}",
            "void irq_work_sync(struct irq_work *work)",
            "{",
            "\tlockdep_assert_irqs_enabled();",
            "\tmight_sleep();",
            "",
            "\tif ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||",
            "\t    !arch_irq_work_has_interrupt()) {",
            "\t\trcuwait_wait_event(&work->irqwait, !irq_work_is_busy(work),",
            "\t\t\t\t   TASK_UNINTERRUPTIBLE);",
            "\t\treturn;",
            "\t}",
            "",
            "\twhile (irq_work_is_busy(work))",
            "\t\tcpu_relax();",
            "}"
          ],
          "function_name": "irq_work_needs_cpu, irq_work_single, irq_work_run_list, irq_work_run, irq_work_tick, irq_work_sync",
          "description": "处理工作项的实际执行流程，包含单次执行逻辑、链表遍历运行及同步等待机制，区分硬中断上下文与RCU等待状态的处理",
          "similarity": 0.48310917615890503
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq_work.c",
          "start_line": 1,
          "end_line": 30,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Copyright (C) 2010 Red Hat, Inc., Peter Zijlstra",
            " *",
            " * Provides a framework for enqueueing and running callbacks from hardirq",
            " * context. The enqueueing is NMI-safe.",
            " */",
            "",
            "#include <linux/bug.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/percpu.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/sched.h>",
            "#include <linux/tick.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/smp.h>",
            "#include <linux/smpboot.h>",
            "#include <asm/processor.h>",
            "#include <linux/kasan.h>",
            "",
            "#include <trace/events/ipi.h>",
            "",
            "static DEFINE_PER_CPU(struct llist_head, raised_list);",
            "static DEFINE_PER_CPU(struct llist_head, lazy_list);",
            "static DEFINE_PER_CPU(struct task_struct *, irq_workd);",
            ""
          ],
          "function_name": null,
          "description": "定义了用于管理中断工作队列的per-CPU链表（raised_list/lazy_list）和irq_workd线程指针，提供NMI安全的enqueue框架",
          "similarity": 0.4615271985530853
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/irq_work.c",
          "start_line": 303,
          "end_line": 316,
          "content": [
            "static void run_irq_workd(unsigned int cpu)",
            "{",
            "\tirq_work_run_list(this_cpu_ptr(&lazy_list));",
            "}",
            "static void irq_workd_setup(unsigned int cpu)",
            "{",
            "\tsched_set_fifo_low(current);",
            "}",
            "static __init int irq_work_init_threads(void)",
            "{",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\tBUG_ON(smpboot_register_percpu_thread(&irqwork_threads));",
            "\treturn 0;",
            "}"
          ],
          "function_name": "run_irq_workd, irq_workd_setup, irq_work_init_threads",
          "description": "初始化PREEMPT_RT环境下的per-CPU工作线程，注册并启动处理延迟工作项的专用线程，通过smpboot接口创建线程实体",
          "similarity": 0.3782879710197449
        }
      ]
    }
  ]
}