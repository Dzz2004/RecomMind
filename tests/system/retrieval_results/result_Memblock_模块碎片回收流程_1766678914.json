{
  "query": "Memblock 模块碎片回收流程",
  "timestamp": "2025-12-26 00:08:34",
  "retrieved_files": [
    {
      "source_file": "mm/memblock.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:38:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memblock.c`\n\n---\n\n# memblock.c 技术文档\n\n## 1. 文件概述\n\n`memblock.c` 实现了 Linux 内核早期启动阶段的内存管理机制——**memblock**。该机制用于在常规内存分配器（如 buddy allocator）尚未初始化之前，对物理内存进行粗粒度的区域管理。它将系统内存抽象为若干连续的内存区域（regions），支持“可用内存”（memory）、“保留内存”（reserved）和“物理内存”（physmem，部分架构支持）三种类型，为内核早期初始化提供内存添加、查询和分配能力。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct memblock_region`：表示一个连续的物理内存区域，包含基地址（base）、大小（size）、NUMA 节点 ID 和属性标志。\n- `struct memblock_type`：管理一类内存区域的集合，包含区域数组、当前数量（cnt）、最大容量（max）和名称。\n- `struct memblock`：全局 memblock 管理结构，包含 `memory` 和 `reserved` 两种类型的 `memblock_type`，以及分配方向（bottom_up）和当前分配上限（current_limit）。\n- `physmem`（条件编译）：描述不受 `mem=` 参数限制的实际物理内存布局。\n\n### 主要函数与变量\n- `memblock_add()` / `memblock_add_node()`：向 memblock 添加可用内存区域。\n- `memblock_reserve()`：标记内存区域为保留（不可用于动态分配）。\n- `memblock_phys_alloc*()` / `memblock_alloc*()`：分配物理或虚拟地址的内存。\n- `memblock_overlaps_region()`：判断指定区域是否与某类 memblock 区域重叠。\n- `__memblock_find_range_bottom_up()`：从低地址向高地址查找满足条件的空闲内存范围。\n- 全局变量 `memblock`：静态初始化的主 memblock 结构体。\n- `max_low_pfn`, `min_low_pfn`, `max_pfn`, `max_possible_pfn`：记录 PFN（页帧号）边界信息。\n\n### 配置宏\n- `INIT_MEMBLOCK_REGIONS`：初始内存/保留区域数组大小（默认 128）。\n- `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 类型支持。\n- `CONFIG_MEMBLOCK_KHO_SCRATCH`：支持仅从特定标记（KHO_SCRATCH）区域分配内存。\n- `CONFIG_ARCH_KEEP_MEMBLOCK`：决定是否在初始化完成后保留 memblock 数据结构。\n\n## 3. 关键实现\n\n### 初始化与存储\n- `memblock` 结构体在编译时静态初始化，其 `memory` 和 `reserved` 的区域数组分别使用 `memblock_memory_init_regions` 和 `memblock_reserved_init_regions`，初始容量由 `INIT_MEMBLOCK_*_REGIONS` 定义。\n- 每个 `memblock_type` 的 `cnt` 初始设为 1，但实际第一个条目为空的占位符，有效区域从索引 1 开始（后续代码处理）。\n- 支持通过 `memblock_allow_resize()` 动态扩容区域数组，但需谨慎避免与 initrd 等关键区域冲突。\n\n### 内存区域管理\n- 使用 `for_each_memblock_type` 宏遍历指定类型的区域。\n- `memblock_addrs_overlap()` 通过比较区间端点判断两个物理内存区域是否重叠。\n- `memblock_overlaps_region()` 封装了对某类所有区域的重叠检测。\n\n### 分配策略\n- 默认采用 **top-down**（从高地址向低地址）分配策略，可通过 `memblock_set_bottom_up(true)` 切换为 **bottom-up**。\n- 分配时受 `current_limit` 限制（默认 `MEMBLOCK_ALLOC_ANYWHERE` 表示无限制）。\n- 支持基于 NUMA 节点、对齐要求、内存属性（如 `MEMBLOCK_MIRROR`、`MEMBLOCK_KHO_SCRATCH`）的精细控制。\n- `choose_memblock_flags()` 根据 `kho_scratch_only` 和镜像内存存在性动态选择分配标志。\n\n### 安全与调试\n- `memblock_cap_size()` 防止地址计算溢出（确保 `base + size <= PHYS_ADDR_MAX`）。\n- 条件编译的 `memblock_dbg()` 宏用于调试输出（需开启 `memblock_debug`）。\n- 使用 `__initdata_memblock` 属性标记仅在初始化阶段使用的数据，便于后续释放。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memblock.h>`：定义 memblock API 和数据结构。\n  - `<linux/kernel.h>`, `<linux/init.h>`：提供基础内核功能和初始化宏。\n  - `<linux/pfn.h>`：PFN 相关操作。\n  - `<asm/sections.h>`：访问内核链接段信息。\n  - 架构相关头文件（如 `internal.h`）。\n- **配置依赖**：\n  - `CONFIG_NUMA`：影响 `contig_page_data` 的定义。\n  - `CONFIG_KEXEC_HANDOVER`：引入 kexec 相关头文件。\n  - `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 支持。\n- **后续移交**：在 `mem_init()` 中，memblock 管理的内存会被释放给 buddy allocator，完成内存管理权移交。\n\n## 5. 使用场景\n\n- **内核早期初始化**：在 `start_kernel()` 初期，架构代码（如 `setup_arch()`）调用 `memblock_add()` 注册可用物理内存，调用 `memblock_reserve()` 保留内核镜像、设备树、initrd 等关键区域。\n- **早期内存分配**：在 slab/buddy 分配器就绪前，使用 `memblock_alloc()` 分配大块连续内存（如页表、中断向量表、ACPI 表解析缓冲区）。\n- **内存布局查询**：通过 `for_each_memblock()` 等宏遍历内存区域，用于构建 e820 表、EFI 内存映射或 NUMA 拓扑。\n- **特殊分配需求**：支持从镜像内存（`MEMBLOCK_MIRROR`）或 KHO scratch 区域分配，满足安全启动或崩溃转储等场景。\n- **调试与分析**：通过 debugfs 接口（未在片段中体现）导出 memblock 布局，辅助内存问题诊断。",
      "similarity": 0.6273719072341919,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "mm/memblock.c",
          "start_line": 1,
          "end_line": 191,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-or-later",
            "/*",
            " * Procedures for maintaining information about logical memory blocks.",
            " *",
            " * Peter Bergner, IBM Corp.\tJune 2001.",
            " * Copyright (C) 2001 Peter Bergner.",
            " */",
            "",
            "#include <linux/kernel.h>",
            "#include <linux/slab.h>",
            "#include <linux/init.h>",
            "#include <linux/bitops.h>",
            "#include <linux/poison.h>",
            "#include <linux/pfn.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/memblock.h>",
            "#include <linux/mutex.h>",
            "",
            "#ifdef CONFIG_KEXEC_HANDOVER",
            "#include <linux/libfdt.h>",
            "#include <linux/kexec_handover.h>",
            "#endif /* CONFIG_KEXEC_HANDOVER */",
            "",
            "#include <asm/sections.h>",
            "#include <linux/io.h>",
            "",
            "#include \"internal.h\"",
            "",
            "#define INIT_MEMBLOCK_REGIONS\t\t\t128",
            "#define INIT_PHYSMEM_REGIONS\t\t\t4",
            "",
            "#ifndef INIT_MEMBLOCK_RESERVED_REGIONS",
            "# define INIT_MEMBLOCK_RESERVED_REGIONS\t\tINIT_MEMBLOCK_REGIONS",
            "#endif",
            "",
            "#ifndef INIT_MEMBLOCK_MEMORY_REGIONS",
            "#define INIT_MEMBLOCK_MEMORY_REGIONS\t\tINIT_MEMBLOCK_REGIONS",
            "#endif",
            "",
            "/**",
            " * DOC: memblock overview",
            " *",
            " * Memblock is a method of managing memory regions during the early",
            " * boot period when the usual kernel memory allocators are not up and",
            " * running.",
            " *",
            " * Memblock views the system memory as collections of contiguous",
            " * regions. There are several types of these collections:",
            " *",
            " * * ``memory`` - describes the physical memory available to the",
            " *   kernel; this may differ from the actual physical memory installed",
            " *   in the system, for instance when the memory is restricted with",
            " *   ``mem=`` command line parameter",
            " * * ``reserved`` - describes the regions that were allocated",
            " * * ``physmem`` - describes the actual physical memory available during",
            " *   boot regardless of the possible restrictions and memory hot(un)plug;",
            " *   the ``physmem`` type is only available on some architectures.",
            " *",
            " * Each region is represented by struct memblock_region that",
            " * defines the region extents, its attributes and NUMA node id on NUMA",
            " * systems. Every memory type is described by the struct memblock_type",
            " * which contains an array of memory regions along with",
            " * the allocator metadata. The \"memory\" and \"reserved\" types are nicely",
            " * wrapped with struct memblock. This structure is statically",
            " * initialized at build time. The region arrays are initially sized to",
            " * %INIT_MEMBLOCK_MEMORY_REGIONS for \"memory\" and",
            " * %INIT_MEMBLOCK_RESERVED_REGIONS for \"reserved\". The region array",
            " * for \"physmem\" is initially sized to %INIT_PHYSMEM_REGIONS.",
            " * The memblock_allow_resize() enables automatic resizing of the region",
            " * arrays during addition of new regions. This feature should be used",
            " * with care so that memory allocated for the region array will not",
            " * overlap with areas that should be reserved, for example initrd.",
            " *",
            " * The early architecture setup should tell memblock what the physical",
            " * memory layout is by using memblock_add() or memblock_add_node()",
            " * functions. The first function does not assign the region to a NUMA",
            " * node and it is appropriate for UMA systems. Yet, it is possible to",
            " * use it on NUMA systems as well and assign the region to a NUMA node",
            " * later in the setup process using memblock_set_node(). The",
            " * memblock_add_node() performs such an assignment directly.",
            " *",
            " * Once memblock is setup the memory can be allocated using one of the",
            " * API variants:",
            " *",
            " * * memblock_phys_alloc*() - these functions return the **physical**",
            " *   address of the allocated memory",
            " * * memblock_alloc*() - these functions return the **virtual** address",
            " *   of the allocated memory.",
            " *",
            " * Note, that both API variants use implicit assumptions about allowed",
            " * memory ranges and the fallback methods. Consult the documentation",
            " * of memblock_alloc_internal() and memblock_alloc_range_nid()",
            " * functions for more elaborate description.",
            " *",
            " * As the system boot progresses, the architecture specific mem_init()",
            " * function frees all the memory to the buddy page allocator.",
            " *",
            " * Unless an architecture enables %CONFIG_ARCH_KEEP_MEMBLOCK, the",
            " * memblock data structures (except \"physmem\") will be discarded after the",
            " * system initialization completes.",
            " */",
            "",
            "#ifndef CONFIG_NUMA",
            "struct pglist_data __refdata contig_page_data;",
            "EXPORT_SYMBOL(contig_page_data);",
            "#endif",
            "",
            "unsigned long max_low_pfn;",
            "unsigned long min_low_pfn;",
            "unsigned long max_pfn;",
            "unsigned long long max_possible_pfn;",
            "",
            "#ifdef CONFIG_MEMBLOCK_KHO_SCRATCH",
            "/* When set to true, only allocate from MEMBLOCK_KHO_SCRATCH ranges */",
            "static bool kho_scratch_only;",
            "#else",
            "#define kho_scratch_only false",
            "#endif",
            "",
            "static struct memblock_region memblock_memory_init_regions[INIT_MEMBLOCK_MEMORY_REGIONS] __initdata_memblock;",
            "static struct memblock_region memblock_reserved_init_regions[INIT_MEMBLOCK_RESERVED_REGIONS] __initdata_memblock;",
            "#ifdef CONFIG_HAVE_MEMBLOCK_PHYS_MAP",
            "static struct memblock_region memblock_physmem_init_regions[INIT_PHYSMEM_REGIONS];",
            "#endif",
            "",
            "struct memblock memblock __initdata_memblock = {",
            "\t.memory.regions\t\t= memblock_memory_init_regions,",
            "\t.memory.cnt\t\t= 1,\t/* empty dummy entry */",
            "\t.memory.max\t\t= INIT_MEMBLOCK_MEMORY_REGIONS,",
            "\t.memory.name\t\t= \"memory\",",
            "",
            "\t.reserved.regions\t= memblock_reserved_init_regions,",
            "\t.reserved.cnt\t\t= 1,\t/* empty dummy entry */",
            "\t.reserved.max\t\t= INIT_MEMBLOCK_RESERVED_REGIONS,",
            "\t.reserved.name\t\t= \"reserved\",",
            "",
            "\t.bottom_up\t\t= false,",
            "\t.current_limit\t\t= MEMBLOCK_ALLOC_ANYWHERE,",
            "};",
            "",
            "#ifdef CONFIG_HAVE_MEMBLOCK_PHYS_MAP",
            "struct memblock_type physmem = {",
            "\t.regions\t\t= memblock_physmem_init_regions,",
            "\t.cnt\t\t\t= 1,\t/* empty dummy entry */",
            "\t.max\t\t\t= INIT_PHYSMEM_REGIONS,",
            "\t.name\t\t\t= \"physmem\",",
            "};",
            "#endif",
            "",
            "/*",
            " * keep a pointer to &memblock.memory in the text section to use it in",
            " * __next_mem_range() and its helpers.",
            " *  For architectures that do not keep memblock data after init, this",
            " * pointer will be reset to NULL at memblock_discard()",
            " */",
            "static __refdata struct memblock_type *memblock_memory = &memblock.memory;",
            "",
            "#define for_each_memblock_type(i, memblock_type, rgn)\t\t\t\\",
            "\tfor (i = 0, rgn = &memblock_type->regions[0];\t\t\t\\",
            "\t     i < memblock_type->cnt;\t\t\t\t\t\\",
            "\t     i++, rgn = &memblock_type->regions[i])",
            "",
            "#define memblock_dbg(fmt, ...)\t\t\t\t\t\t\\",
            "\tdo {\t\t\t\t\t\t\t\t\\",
            "\t\tif (memblock_debug)\t\t\t\t\t\\",
            "\t\t\tpr_info(fmt, ##__VA_ARGS__);\t\t\t\\",
            "\t} while (0)",
            "",
            "static int memblock_debug __initdata_memblock;",
            "static bool system_has_some_mirror __initdata_memblock;",
            "static int memblock_can_resize __initdata_memblock;",
            "static int memblock_memory_in_slab __initdata_memblock;",
            "static int memblock_reserved_in_slab __initdata_memblock;",
            "",
            "bool __init_memblock memblock_has_mirror(void)",
            "{",
            "\treturn system_has_some_mirror;",
            "}",
            "",
            "static enum memblock_flags __init_memblock choose_memblock_flags(void)",
            "{",
            "\t/* skip non-scratch memory for kho early boot allocations */",
            "\tif (kho_scratch_only)",
            "\t\treturn MEMBLOCK_KHO_SCRATCH;",
            "",
            "\treturn system_has_some_mirror ? MEMBLOCK_MIRROR : MEMBLOCK_NONE;",
            "}",
            "",
            "/* adjust *@size so that (@base + *@size) doesn't overflow, return new size */"
          ],
          "function_name": null,
          "description": "定义memblock数据结构及初始化内存区域类型（memory/reserved），用于早期系统启动期间管理物理内存分区，支持动态扩容和NUMA节点绑定。",
          "similarity": 0.6269761919975281
        },
        {
          "chunk_id": 5,
          "file_path": "mm/memblock.c",
          "start_line": 887,
          "end_line": 987,
          "content": [
            "int __init_memblock memblock_remove(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\", __func__,",
            "\t\t     &base, &end, (void *)_RET_IP_);",
            "",
            "\treturn memblock_remove_range(&memblock.memory, base, size);",
            "}",
            "void __init_memblock memblock_free(void *ptr, size_t size)",
            "{",
            "\tif (ptr)",
            "\t\tmemblock_phys_free(__pa(ptr), size);",
            "}",
            "int __init_memblock memblock_phys_free(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\", __func__,",
            "\t\t     &base, &end, (void *)_RET_IP_);",
            "",
            "\tkmemleak_free_part_phys(base, size);",
            "\treturn memblock_remove_range(&memblock.reserved, base, size);",
            "}",
            "int __init_memblock __memblock_reserve(phys_addr_t base, phys_addr_t size,",
            "\t\t\t\t       int nid, enum memblock_flags flags)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] nid=%d flags=%x %pS\\n\", __func__,",
            "\t\t     &base, &end, nid, flags, (void *)_RET_IP_);",
            "",
            "\treturn memblock_add_range(&memblock.reserved, base, size, nid, flags);",
            "}",
            "int __init_memblock memblock_physmem_add(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\", __func__,",
            "\t\t     &base, &end, (void *)_RET_IP_);",
            "",
            "\treturn memblock_add_range(&physmem, base, size, MAX_NUMNODES, 0);",
            "}",
            "__init void memblock_set_kho_scratch_only(void)",
            "{",
            "\tkho_scratch_only = true;",
            "}",
            "__init void memblock_clear_kho_scratch_only(void)",
            "{",
            "\tkho_scratch_only = false;",
            "}",
            "__init void memmap_init_kho_scratch_pages(void)",
            "{",
            "\tphys_addr_t start, end;",
            "\tunsigned long pfn;",
            "\tint nid;",
            "\tu64 i;",
            "",
            "\tif (!IS_ENABLED(CONFIG_DEFERRED_STRUCT_PAGE_INIT))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Initialize struct pages for free scratch memory.",
            "\t * The struct pages for reserved scratch memory will be set up in",
            "\t * reserve_bootmem_region()",
            "\t */",
            "\t__for_each_mem_range(i, &memblock.memory, NULL, NUMA_NO_NODE,",
            "\t\t\t     MEMBLOCK_KHO_SCRATCH, &start, &end, &nid) {",
            "\t\tfor (pfn = PFN_UP(start); pfn < PFN_DOWN(end); pfn++)",
            "\t\t\tinit_deferred_page(pfn, nid);",
            "\t}",
            "}",
            "static int __init_memblock memblock_setclr_flag(struct memblock_type *type,",
            "\t\t\t\tphys_addr_t base, phys_addr_t size, int set, int flag)",
            "{",
            "\tint i, ret, start_rgn, end_rgn;",
            "",
            "\tret = memblock_isolate_range(type, base, size, &start_rgn, &end_rgn);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tfor (i = start_rgn; i < end_rgn; i++) {",
            "\t\tstruct memblock_region *r = &type->regions[i];",
            "",
            "\t\tif (set)",
            "\t\t\tr->flags |= flag;",
            "\t\telse",
            "\t\t\tr->flags &= ~flag;",
            "\t}",
            "",
            "\tmemblock_merge_regions(type, start_rgn, end_rgn);",
            "\treturn 0;",
            "}",
            "int __init_memblock memblock_mark_hotplug(phys_addr_t base, phys_addr_t size)",
            "{",
            "\treturn memblock_setclr_flag(&memblock.memory, base, size, 1, MEMBLOCK_HOTPLUG);",
            "}",
            "int __init_memblock memblock_clear_hotplug(phys_addr_t base, phys_addr_t size)",
            "{",
            "\treturn memblock_setclr_flag(&memblock.memory, base, size, 0, MEMBLOCK_HOTPLUG);",
            "}"
          ],
          "function_name": "memblock_remove, memblock_free, memblock_phys_free, __memblock_reserve, memblock_physmem_add, memblock_set_kho_scratch_only, memblock_clear_kho_scratch_only, memmap_init_kho_scratch_pages, memblock_setclr_flag, memblock_mark_hotplug, memblock_clear_hotplug",
          "description": "定义并实现内存块操作函数，用于移除/释放内存区域，标记预留内存属性，初始化KHO_SCRATCH页结构，并通过memblock_setclr_flag修改内存区域标志位，支持热插拔、镜像等特性",
          "similarity": 0.5742366909980774
        },
        {
          "chunk_id": 15,
          "file_path": "mm/memblock.c",
          "start_line": 2740,
          "end_line": 2788,
          "content": [
            "static int memblock_debug_show(struct seq_file *m, void *private)",
            "{",
            "\tstruct memblock_type *type = m->private;",
            "\tstruct memblock_region *reg;",
            "\tint i, j, nid;",
            "\tunsigned int count = ARRAY_SIZE(flagname);",
            "\tphys_addr_t end;",
            "",
            "\tfor (i = 0; i < type->cnt; i++) {",
            "\t\treg = &type->regions[i];",
            "\t\tend = reg->base + reg->size - 1;",
            "\t\tnid = memblock_get_region_node(reg);",
            "",
            "\t\tseq_printf(m, \"%4d: \", i);",
            "\t\tseq_printf(m, \"%pa..%pa \", &reg->base, &end);",
            "\t\tif (numa_valid_node(nid))",
            "\t\t\tseq_printf(m, \"%4d \", nid);",
            "\t\telse",
            "\t\t\tseq_printf(m, \"%4c \", 'x');",
            "\t\tif (reg->flags) {",
            "\t\t\tfor (j = 0; j < count; j++) {",
            "\t\t\t\tif (reg->flags & (1U << j)) {",
            "\t\t\t\t\tseq_printf(m, \"%s\\n\", flagname[j]);",
            "\t\t\t\t\tbreak;",
            "\t\t\t\t}",
            "\t\t\t}",
            "\t\t\tif (j == count)",
            "\t\t\t\tseq_printf(m, \"%s\\n\", \"UNKNOWN\");",
            "\t\t} else {",
            "\t\t\tseq_printf(m, \"%s\\n\", \"NONE\");",
            "\t\t}",
            "\t}",
            "\treturn 0;",
            "}",
            "static int __init memblock_init_debugfs(void)",
            "{",
            "\tstruct dentry *root = debugfs_create_dir(\"memblock\", NULL);",
            "",
            "\tdebugfs_create_file(\"memory\", 0444, root,",
            "\t\t\t    &memblock.memory, &memblock_debug_fops);",
            "\tdebugfs_create_file(\"reserved\", 0444, root,",
            "\t\t\t    &memblock.reserved, &memblock_debug_fops);",
            "#ifdef CONFIG_HAVE_MEMBLOCK_PHYS_MAP",
            "\tdebugfs_create_file(\"physmem\", 0444, root, &physmem,",
            "\t\t\t    &memblock_debug_fops);",
            "#endif",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "memblock_debug_show, memblock_init_debugfs",
          "description": "该代码段实现内存块调试信息的序列化输出与debugfs接口注册。  \n`memblock_debug_show` 函数遍历内存块区域，按序号、地址范围、节点ID及标志位格式化输出各内存区信息。  \n`memblock_init_debugfs` 注册到debugfs的\"memory\"和\"reserved\"接口，供用户空间读取内存块状态数据。",
          "similarity": 0.5725929737091064
        },
        {
          "chunk_id": 10,
          "file_path": "mm/memblock.c",
          "start_line": 1954,
          "end_line": 2057,
          "content": [
            "void __init memblock_mem_limit_remove_map(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr;",
            "",
            "\tif (!limit)",
            "\t\treturn;",
            "",
            "\tmax_addr = __find_max_addr(limit);",
            "",
            "\t/* @limit exceeds the total size of the memory, do nothing */",
            "\tif (max_addr == PHYS_ADDR_MAX)",
            "\t\treturn;",
            "",
            "\tmemblock_cap_memory_range(0, max_addr);",
            "}",
            "static int __init_memblock memblock_search(struct memblock_type *type, phys_addr_t addr)",
            "{",
            "\tunsigned int left = 0, right = type->cnt;",
            "",
            "\tdo {",
            "\t\tunsigned int mid = (right + left) / 2;",
            "",
            "\t\tif (addr < type->regions[mid].base)",
            "\t\t\tright = mid;",
            "\t\telse if (addr >= (type->regions[mid].base +",
            "\t\t\t\t  type->regions[mid].size))",
            "\t\t\tleft = mid + 1;",
            "\t\telse",
            "\t\t\treturn mid;",
            "\t} while (left < right);",
            "\treturn -1;",
            "}",
            "bool __init_memblock memblock_is_reserved(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.reserved, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_memory(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.memory, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_map_memory(phys_addr_t addr)",
            "{",
            "\tint i = memblock_search(&memblock.memory, addr);",
            "",
            "\tif (i == -1)",
            "\t\treturn false;",
            "\treturn !memblock_is_nomap(&memblock.memory.regions[i]);",
            "}",
            "int __init_memblock memblock_search_pfn_nid(unsigned long pfn,",
            "\t\t\t unsigned long *start_pfn, unsigned long *end_pfn)",
            "{",
            "\tstruct memblock_type *type = &memblock.memory;",
            "\tint mid = memblock_search(type, PFN_PHYS(pfn));",
            "",
            "\tif (mid == -1)",
            "\t\treturn -1;",
            "",
            "\t*start_pfn = PFN_DOWN(type->regions[mid].base);",
            "\t*end_pfn = PFN_DOWN(type->regions[mid].base + type->regions[mid].size);",
            "",
            "\treturn memblock_get_region_node(&type->regions[mid]);",
            "}",
            "bool __init_memblock memblock_is_region_memory(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tint idx = memblock_search(&memblock.memory, base);",
            "\tphys_addr_t end = base + memblock_cap_size(base, &size);",
            "",
            "\tif (idx == -1)",
            "\t\treturn false;",
            "\treturn (memblock.memory.regions[idx].base +",
            "\t\t memblock.memory.regions[idx].size) >= end;",
            "}",
            "bool __init_memblock memblock_is_region_reserved(phys_addr_t base, phys_addr_t size)",
            "{",
            "\treturn memblock_overlaps_region(&memblock.reserved, base, size);",
            "}",
            "void __init_memblock memblock_trim_memory(phys_addr_t align)",
            "{",
            "\tphys_addr_t start, end, orig_start, orig_end;",
            "\tstruct memblock_region *r;",
            "",
            "\tfor_each_mem_region(r) {",
            "\t\torig_start = r->base;",
            "\t\torig_end = r->base + r->size;",
            "\t\tstart = round_up(orig_start, align);",
            "\t\tend = round_down(orig_end, align);",
            "",
            "\t\tif (start == orig_start && end == orig_end)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (start < end) {",
            "\t\t\tr->base = start;",
            "\t\t\tr->size = end - start;",
            "\t\t} else {",
            "\t\t\tmemblock_remove_region(&memblock.memory,",
            "\t\t\t\t\t       r - memblock.memory.regions);",
            "\t\t\tr--;",
            "\t\t}",
            "\t}",
            "}",
            "void __init_memblock memblock_set_current_limit(phys_addr_t limit)",
            "{",
            "\tmemblock.current_limit = limit;",
            "}"
          ],
          "function_name": "memblock_mem_limit_remove_map, memblock_search, memblock_is_reserved, memblock_is_memory, memblock_is_map_memory, memblock_search_pfn_nid, memblock_is_region_memory, memblock_is_region_reserved, memblock_trim_memory, memblock_set_current_limit",
          "description": "实现内存块限制移除、搜索和区域判断逻辑，用于管理内存和保留区域的地址范围查询及修剪操作",
          "similarity": 0.5594029426574707
        },
        {
          "chunk_id": 11,
          "file_path": "mm/memblock.c",
          "start_line": 2094,
          "end_line": 2203,
          "content": [
            "static void __init_memblock memblock_dump(struct memblock_type *type)",
            "{",
            "\tphys_addr_t base, end, size;",
            "\tenum memblock_flags flags;",
            "\tint idx;",
            "\tstruct memblock_region *rgn;",
            "",
            "\tpr_info(\" %s.cnt  = 0x%lx\\n\", type->name, type->cnt);",
            "",
            "\tfor_each_memblock_type(idx, type, rgn) {",
            "\t\tchar nid_buf[32] = \"\";",
            "",
            "\t\tbase = rgn->base;",
            "\t\tsize = rgn->size;",
            "\t\tend = base + size - 1;",
            "\t\tflags = rgn->flags;",
            "#ifdef CONFIG_NUMA",
            "\t\tif (numa_valid_node(memblock_get_region_node(rgn)))",
            "\t\t\tsnprintf(nid_buf, sizeof(nid_buf), \" on node %d\",",
            "\t\t\t\t memblock_get_region_node(rgn));",
            "#endif",
            "\t\tpr_info(\" %s[%#x]\\t[%pa-%pa], %pa bytes%s flags: %#x\\n\",",
            "\t\t\ttype->name, idx, &base, &end, &size, nid_buf, flags);",
            "\t}",
            "}",
            "void __init memblock_allow_resize(void)",
            "{",
            "\tmemblock_can_resize = 1;",
            "}",
            "static int __init early_memblock(char *p)",
            "{",
            "\tif (p && strstr(p, \"debug\"))",
            "\t\tmemblock_debug = 1;",
            "\treturn 0;",
            "}",
            "static void __init free_memmap(unsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tstruct page *start_pg, *end_pg;",
            "\tphys_addr_t pg, pgend;",
            "",
            "\t/*",
            "\t * Convert start_pfn/end_pfn to a struct page pointer.",
            "\t */",
            "\tstart_pg = pfn_to_page(start_pfn - 1) + 1;",
            "\tend_pg = pfn_to_page(end_pfn - 1) + 1;",
            "",
            "\t/*",
            "\t * Convert to physical addresses, and round start upwards and end",
            "\t * downwards.",
            "\t */",
            "\tpg = PAGE_ALIGN(__pa(start_pg));",
            "\tpgend = __pa(end_pg) & PAGE_MASK;",
            "",
            "\t/*",
            "\t * If there are free pages between these, free the section of the",
            "\t * memmap array.",
            "\t */",
            "\tif (pg < pgend)",
            "\t\tmemblock_phys_free(pg, pgend - pg);",
            "}",
            "static void __init free_unused_memmap(void)",
            "{",
            "\tunsigned long start, end, prev_end = 0;",
            "\tint i;",
            "",
            "\tif (!IS_ENABLED(CONFIG_HAVE_ARCH_PFN_VALID) ||",
            "\t    IS_ENABLED(CONFIG_SPARSEMEM_VMEMMAP))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * This relies on each bank being in address order.",
            "\t * The banks are sorted previously in bootmem_init().",
            "\t */",
            "\tfor_each_mem_pfn_range(i, MAX_NUMNODES, &start, &end, NULL) {",
            "#ifdef CONFIG_SPARSEMEM",
            "\t\t/*",
            "\t\t * Take care not to free memmap entries that don't exist",
            "\t\t * due to SPARSEMEM sections which aren't present.",
            "\t\t */",
            "\t\tstart = min(start, ALIGN(prev_end, PAGES_PER_SECTION));",
            "#endif",
            "\t\t/*",
            "\t\t * Align down here since many operations in VM subsystem",
            "\t\t * presume that there are no holes in the memory map inside",
            "\t\t * a pageblock",
            "\t\t */",
            "\t\tstart = pageblock_start_pfn(start);",
            "",
            "\t\t/*",
            "\t\t * If we had a previous bank, and there is a space",
            "\t\t * between the current bank and the previous, free it.",
            "\t\t */",
            "\t\tif (prev_end && prev_end < start)",
            "\t\t\tfree_memmap(prev_end, start);",
            "",
            "\t\t/*",
            "\t\t * Align up here since many operations in VM subsystem",
            "\t\t * presume that there are no holes in the memory map inside",
            "\t\t * a pageblock",
            "\t\t */",
            "\t\tprev_end = pageblock_align(end);",
            "\t}",
            "",
            "#ifdef CONFIG_SPARSEMEM",
            "\tif (!IS_ALIGNED(prev_end, PAGES_PER_SECTION)) {",
            "\t\tprev_end = pageblock_align(end);",
            "\t\tfree_memmap(prev_end, ALIGN(prev_end, PAGES_PER_SECTION));",
            "\t}",
            "#endif",
            "}"
          ],
          "function_name": "memblock_dump, memblock_allow_resize, early_memblock, free_memmap, free_unused_memmap",
          "description": "提供内存块状态调试、调整支持、早期内存处理及未使用memmap释放功能，用于优化内存映射管理",
          "similarity": 0.5524312257766724
        }
      ]
    },
    {
      "source_file": "mm/list_lru.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:35:23\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `list_lru.c`\n\n---\n\n# list_lru.c 技术文档\n\n## 1. 文件概述\n\n`list_lru.c` 实现了 Linux 内核中通用的 **List-based LRU（Least Recently Used）基础设施**，用于管理可回收对象的双向链表。该机制支持按 NUMA 节点（node）和内存控制组（memcg）进行细粒度组织，便于内存压力下的高效回收。主要服务于 slab 分配器等子系统，作为 shrinker 框架的一部分，在内存紧张时协助释放非活跃对象。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct list_lru`：顶层 LRU 管理结构，包含 per-node 的 `list_lru_node`\n- `struct list_lru_node`：每个 NUMA 节点对应的 LRU 节点，含自旋锁和总项数\n- `struct list_lru_one`：实际存储对象链表和计数的单元（per-memcg per-node）\n- `struct list_lru_memcg`：当启用 `CONFIG_MEMCG` 时，为每个 memcg 存储 per-node 的 `list_lru_one`\n\n### 主要导出函数\n- `list_lru_add()` / `list_lru_add_obj()`：向 LRU 添加对象\n- `list_lru_del()` / `list_lru_del_obj()`：从 LRU 删除对象\n- `list_lru_isolate()` / `list_lru_isolate_move()`：在回收过程中隔离对象\n- `list_lru_count_one()` / `list_lru_count_node()`：查询 LRU 中对象数量\n- `list_lru_walk_one()` / `list_lru_walk_node()`：遍历并处理 LRU 中的对象（用于 shrinker 回调）\n\n### 内部辅助函数\n- `list_lru_from_memcg_idx()`：根据 memcg ID 获取对应的 `list_lru_one`\n- `__list_lru_walk_one()`：带锁的 LRU 遍历核心逻辑\n- `list_lru_register()` / `list_lru_unregister()`：注册/注销 memcg-aware 的 LRU（用于全局追踪）\n\n## 3. 关键实现\n\n### 内存控制组（memcg）支持\n- 通过 `CONFIG_MEMCG` 条件编译控制 memcg 相关逻辑\n- 使用 XArray (`lru->xa`) 动态存储每个 memcg 对应的 `list_lru_memcg` 结构\n- 每个 memcg 在每个 NUMA 节点上拥有独立的 `list_lru_one`，实现资源隔离\n- 全局 `memcg_list_lrus` 链表和 `list_lrus_mutex` 用于跟踪所有 memcg-aware 的 LRU 实例\n\n### 并发控制\n- 每个 NUMA 节点 (`list_lru_node`) 拥有独立的自旋锁 (`nlru->lock`)\n- 所有对 LRU 链表的操作（增、删、遍历）均在对应节点锁保护下进行\n- 提供 `_irq` 版本的遍历函数（`list_lru_walk_one_irq`）用于中断上下文\n\n### 回收遍历机制\n- `list_lru_walk_*` 函数接受回调函数 `isolate`，由调用者定义回收策略\n- 回调返回值控制遍历行为：\n  - `LRU_REMOVED`：成功移除\n  - `LRU_REMOVED_RETRY`：移除后需重新开始遍历（锁曾被释放）\n  - `LRU_RETRY`：未移除但需重新开始遍历\n  - `LRU_ROTATE`：将对象移到链表尾部（标记为最近使用）\n  - `LRU_SKIP`：跳过当前对象\n  - `LRU_STOP`：立即停止遍历\n- 通过 `nr_to_walk` 限制单次遍历的最大对象数，防止长时间持锁\n\n### Shrinker 集成\n- 当向空的 `list_lru_one` 添加首个对象时，调用 `set_shrinker_bit()` 标记该 memcg/node 需要被 shrinker 处理\n- `lru_shrinker_id()` 返回关联的 shrinker ID，用于通知内存回收子系统\n\n### 对象归属识别\n- `list_lru_add_obj()` / `list_lru_del_obj()` 通过 `mem_cgroup_from_slab_obj()` 自动获取对象所属的 memcg\n- 使用 `page_to_nid(virt_to_page(item))` 确定对象所在的 NUMA 节点\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/list_lru.h>`：定义核心数据结构和 API\n  - `<linux/memcontrol.h>`：memcg 相关接口（如 `memcg_kmem_id`）\n  - `\"slab.h\"` 和 `\"internal.h\"`：slab 分配器内部接口（如 `mem_cgroup_from_slab_obj`）\n- **配置依赖**：\n  - `CONFIG_MEMCG`：决定是否编译 memcg 相关代码\n  - `CONFIG_NUMA`：影响 per-node 数据结构的大小（通过 `nr_node_ids`）\n- **子系统依赖**：\n  - Slab 分配器：作为主要使用者，管理可回收 slab 对象\n  - Memory Control Group (memcg)：提供内存隔离和记账\n  - Shrinker 框架：通过 shrinker 回调触发 LRU 遍历回收\n\n## 5. 使用场景\n\n- **Slab 对象回收**：当系统内存压力大时，shrinker 通过 `list_lru_walk_*` 遍历 inactive slab 对象链表，释放可回收对象\n- **Per-memcg 内存限制**：在 cgroup 内存超限时，仅遍历该 memcg 对应的 LRU 部分，实现精确回收\n- **NUMA 感知管理**：按 NUMA 节点分离 LRU 链表，减少远程内存访问，提升性能\n- **通用 LRU 容器**：任何需要按 LRU 策略管理可回收对象的内核子系统均可使用此基础设施（如 dentry、inode 缓存等）",
      "similarity": 0.5984224081039429,
      "chunks": [
        {
          "chunk_id": 5,
          "file_path": "mm/list_lru.c",
          "start_line": 556,
          "end_line": 605,
          "content": [
            "static inline void memcg_init_list_lru(struct list_lru *lru, bool memcg_aware)",
            "{",
            "}",
            "static void memcg_destroy_list_lru(struct list_lru *lru)",
            "{",
            "}",
            "int __list_lru_init(struct list_lru *lru, bool memcg_aware,",
            "\t\t    struct lock_class_key *key, struct shrinker *shrinker)",
            "{",
            "\tint i;",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tif (shrinker)",
            "\t\tlru->shrinker_id = shrinker->id;",
            "\telse",
            "\t\tlru->shrinker_id = -1;",
            "#endif",
            "",
            "\tlru->node = kcalloc(nr_node_ids, sizeof(*lru->node), GFP_KERNEL);",
            "\tif (!lru->node)",
            "\t\treturn -ENOMEM;",
            "",
            "\tfor_each_node(i) {",
            "\t\tspin_lock_init(&lru->node[i].lock);",
            "\t\tif (key)",
            "\t\t\tlockdep_set_class(&lru->node[i].lock, key);",
            "\t\tinit_one_lru(&lru->node[i].lru);",
            "\t}",
            "",
            "\tmemcg_init_list_lru(lru, memcg_aware);",
            "\tlist_lru_register(lru);",
            "",
            "\treturn 0;",
            "}",
            "void list_lru_destroy(struct list_lru *lru)",
            "{",
            "\t/* Already destroyed or not yet initialized? */",
            "\tif (!lru->node)",
            "\t\treturn;",
            "",
            "\tlist_lru_unregister(lru);",
            "",
            "\tmemcg_destroy_list_lru(lru);",
            "\tkfree(lru->node);",
            "\tlru->node = NULL;",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tlru->shrinker_id = -1;",
            "#endif",
            "}"
          ],
          "function_name": "memcg_init_list_lru, memcg_destroy_list_lru, __list_lru_init, list_lru_destroy",
          "description": "该代码段实现了基于内存控制组（MEMCG）的LRU列表管理功能。  \n`__list_lru_init` 初始化 `list_lru` 结构体并注册到系统，其中包含 MEMCG 相关的 shrinker ID 设置及节点锁初始化；`list_lru_destroy` 反向清理资源，但 `memcg_init_list_lru` 和 `memcg_destroy_list_lru` 的具体实现缺失，上下文不完整。",
          "similarity": 0.574351966381073
        },
        {
          "chunk_id": 1,
          "file_path": "mm/list_lru.c",
          "start_line": 22,
          "end_line": 129,
          "content": [
            "static inline bool list_lru_memcg_aware(struct list_lru *lru)",
            "{",
            "\treturn lru->memcg_aware;",
            "}",
            "static void list_lru_register(struct list_lru *lru)",
            "{",
            "\tif (!list_lru_memcg_aware(lru))",
            "\t\treturn;",
            "",
            "\tmutex_lock(&list_lrus_mutex);",
            "\tlist_add(&lru->list, &memcg_list_lrus);",
            "\tmutex_unlock(&list_lrus_mutex);",
            "}",
            "static void list_lru_unregister(struct list_lru *lru)",
            "{",
            "\tif (!list_lru_memcg_aware(lru))",
            "\t\treturn;",
            "",
            "\tmutex_lock(&list_lrus_mutex);",
            "\tlist_del(&lru->list);",
            "\tmutex_unlock(&list_lrus_mutex);",
            "}",
            "static int lru_shrinker_id(struct list_lru *lru)",
            "{",
            "\treturn lru->shrinker_id;",
            "}",
            "static void list_lru_register(struct list_lru *lru)",
            "{",
            "}",
            "static void list_lru_unregister(struct list_lru *lru)",
            "{",
            "}",
            "static int lru_shrinker_id(struct list_lru *lru)",
            "{",
            "\treturn -1;",
            "}",
            "static inline bool list_lru_memcg_aware(struct list_lru *lru)",
            "{",
            "\treturn false;",
            "}",
            "bool list_lru_add(struct list_lru *lru, struct list_head *item, int nid,",
            "\t\t    struct mem_cgroup *memcg)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tstruct list_lru_one *l;",
            "",
            "\tspin_lock(&nlru->lock);",
            "\tif (list_empty(item)) {",
            "\t\tl = list_lru_from_memcg_idx(lru, nid, memcg_kmem_id(memcg));",
            "\t\tlist_add_tail(item, &l->list);",
            "\t\t/* Set shrinker bit if the first element was added */",
            "\t\tif (!l->nr_items++)",
            "\t\t\tset_shrinker_bit(memcg, nid, lru_shrinker_id(lru));",
            "\t\tnlru->nr_items++;",
            "\t\tspin_unlock(&nlru->lock);",
            "\t\treturn true;",
            "\t}",
            "\tspin_unlock(&nlru->lock);",
            "\treturn false;",
            "}",
            "bool list_lru_add_obj(struct list_lru *lru, struct list_head *item)",
            "{",
            "\tbool ret;",
            "\tint nid = page_to_nid(virt_to_page(item));",
            "",
            "\tif (list_lru_memcg_aware(lru)) {",
            "\t\trcu_read_lock();",
            "\t\tret = list_lru_add(lru, item, nid, mem_cgroup_from_slab_obj(item));",
            "\t\trcu_read_unlock();",
            "\t} else {",
            "\t\tret = list_lru_add(lru, item, nid, NULL);",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "bool list_lru_del(struct list_lru *lru, struct list_head *item, int nid,",
            "\t\t    struct mem_cgroup *memcg)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tstruct list_lru_one *l;",
            "",
            "\tspin_lock(&nlru->lock);",
            "\tif (!list_empty(item)) {",
            "\t\tl = list_lru_from_memcg_idx(lru, nid, memcg_kmem_id(memcg));",
            "\t\tlist_del_init(item);",
            "\t\tl->nr_items--;",
            "\t\tnlru->nr_items--;",
            "\t\tspin_unlock(&nlru->lock);",
            "\t\treturn true;",
            "\t}",
            "\tspin_unlock(&nlru->lock);",
            "\treturn false;",
            "}",
            "bool list_lru_del_obj(struct list_lru *lru, struct list_head *item)",
            "{",
            "\tbool ret;",
            "\tint nid = page_to_nid(virt_to_page(item));",
            "",
            "\tif (list_lru_memcg_aware(lru)) {",
            "\t\trcu_read_lock();",
            "\t\tret = list_lru_del(lru, item, nid, mem_cgroup_from_slab_obj(item));",
            "\t\trcu_read_unlock();",
            "\t} else {",
            "\t\tret = list_lru_del(lru, item, nid, NULL);",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "list_lru_memcg_aware, list_lru_register, list_lru_unregister, lru_shrinker_id, list_lru_register, list_lru_unregister, lru_shrinker_id, list_lru_memcg_aware, list_lru_add, list_lru_add_obj, list_lru_del, list_lru_del_obj",
          "description": "实现了LRU列表的添加/删除操作，支持MemCG感知的节点和内存组粒度管理，包含处理多核、内存组切换及RCU安全访问的逻辑。",
          "similarity": 0.5662265419960022
        },
        {
          "chunk_id": 4,
          "file_path": "mm/list_lru.c",
          "start_line": 425,
          "end_line": 551,
          "content": [
            "static void memcg_reparent_list_lru(struct list_lru *lru,",
            "\t\t\t\t    int src_idx, struct mem_cgroup *dst_memcg)",
            "{",
            "\tint i;",
            "",
            "\tfor_each_node(i)",
            "\t\tmemcg_reparent_list_lru_node(lru, i, src_idx, dst_memcg);",
            "",
            "\tmemcg_list_lru_free(lru, src_idx);",
            "}",
            "void memcg_reparent_list_lrus(struct mem_cgroup *memcg, struct mem_cgroup *parent)",
            "{",
            "\tstruct cgroup_subsys_state *css;",
            "\tstruct list_lru *lru;",
            "\tint src_idx = memcg->kmemcg_id;",
            "",
            "\t/*",
            "\t * Change kmemcg_id of this cgroup and all its descendants to the",
            "\t * parent's id, and then move all entries from this cgroup's list_lrus",
            "\t * to ones of the parent.",
            "\t *",
            "\t * After we have finished, all list_lrus corresponding to this cgroup",
            "\t * are guaranteed to remain empty. So we can safely free this cgroup's",
            "\t * list lrus in memcg_list_lru_free().",
            "\t *",
            "\t * Changing ->kmemcg_id to the parent can prevent memcg_list_lru_alloc()",
            "\t * from allocating list lrus for this cgroup after memcg_list_lru_free()",
            "\t * call.",
            "\t */",
            "\trcu_read_lock();",
            "\tcss_for_each_descendant_pre(css, &memcg->css) {",
            "\t\tstruct mem_cgroup *child;",
            "",
            "\t\tchild = mem_cgroup_from_css(css);",
            "\t\tWRITE_ONCE(child->kmemcg_id, parent->kmemcg_id);",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\tmutex_lock(&list_lrus_mutex);",
            "\tlist_for_each_entry(lru, &memcg_list_lrus, list)",
            "\t\tmemcg_reparent_list_lru(lru, src_idx, parent);",
            "\tmutex_unlock(&list_lrus_mutex);",
            "}",
            "static inline bool memcg_list_lru_allocated(struct mem_cgroup *memcg,",
            "\t\t\t\t\t    struct list_lru *lru)",
            "{",
            "\tint idx = memcg->kmemcg_id;",
            "",
            "\treturn idx < 0 || xa_load(&lru->xa, idx);",
            "}",
            "int memcg_list_lru_alloc(struct mem_cgroup *memcg, struct list_lru *lru,",
            "\t\t\t gfp_t gfp)",
            "{",
            "\tint i;",
            "\tunsigned long flags;",
            "\tstruct list_lru_memcg_table {",
            "\t\tstruct list_lru_memcg *mlru;",
            "\t\tstruct mem_cgroup *memcg;",
            "\t} *table;",
            "\tXA_STATE(xas, &lru->xa, 0);",
            "",
            "\tif (!list_lru_memcg_aware(lru) || memcg_list_lru_allocated(memcg, lru))",
            "\t\treturn 0;",
            "",
            "\tgfp &= GFP_RECLAIM_MASK;",
            "\ttable = kmalloc_array(memcg->css.cgroup->level, sizeof(*table), gfp);",
            "\tif (!table)",
            "\t\treturn -ENOMEM;",
            "",
            "\t/*",
            "\t * Because the list_lru can be reparented to the parent cgroup's",
            "\t * list_lru, we should make sure that this cgroup and all its",
            "\t * ancestors have allocated list_lru_memcg.",
            "\t */",
            "\tfor (i = 0; memcg; memcg = parent_mem_cgroup(memcg), i++) {",
            "\t\tif (memcg_list_lru_allocated(memcg, lru))",
            "\t\t\tbreak;",
            "",
            "\t\ttable[i].memcg = memcg;",
            "\t\ttable[i].mlru = memcg_init_list_lru_one(gfp);",
            "\t\tif (!table[i].mlru) {",
            "\t\t\twhile (i--)",
            "\t\t\t\tkfree(table[i].mlru);",
            "\t\t\tkfree(table);",
            "\t\t\treturn -ENOMEM;",
            "\t\t}",
            "\t}",
            "",
            "\txas_lock_irqsave(&xas, flags);",
            "\twhile (i--) {",
            "\t\tint index = READ_ONCE(table[i].memcg->kmemcg_id);",
            "\t\tstruct list_lru_memcg *mlru = table[i].mlru;",
            "",
            "\t\txas_set(&xas, index);",
            "retry:",
            "\t\tif (unlikely(index < 0 || xas_error(&xas) || xas_load(&xas))) {",
            "\t\t\tkfree(mlru);",
            "\t\t} else {",
            "\t\t\txas_store(&xas, mlru);",
            "\t\t\tif (xas_error(&xas) == -ENOMEM) {",
            "\t\t\t\txas_unlock_irqrestore(&xas, flags);",
            "\t\t\t\tif (xas_nomem(&xas, gfp))",
            "\t\t\t\t\txas_set_err(&xas, 0);",
            "\t\t\t\txas_lock_irqsave(&xas, flags);",
            "\t\t\t\t/*",
            "\t\t\t\t * The xas lock has been released, this memcg",
            "\t\t\t\t * can be reparented before us. So reload",
            "\t\t\t\t * memcg id. More details see the comments",
            "\t\t\t\t * in memcg_reparent_list_lrus().",
            "\t\t\t\t */",
            "\t\t\t\tindex = READ_ONCE(table[i].memcg->kmemcg_id);",
            "\t\t\t\tif (index < 0)",
            "\t\t\t\t\txas_set_err(&xas, 0);",
            "\t\t\t\telse if (!xas_error(&xas) && index != xas.xa_index)",
            "\t\t\t\t\txas_set(&xas, index);",
            "\t\t\t\tgoto retry;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "\t/* xas_nomem() is used to free memory instead of memory allocation. */",
            "\tif (xas.xa_alloc)",
            "\t\txas_nomem(&xas, gfp);",
            "\txas_unlock_irqrestore(&xas, flags);",
            "\tkfree(table);",
            "",
            "\treturn xas_error(&xas);",
            "}"
          ],
          "function_name": "memcg_reparent_list_lru, memcg_reparent_list_lrus, memcg_list_lru_allocated, memcg_list_lru_alloc",
          "description": "实现内存组层级间的LRU列表迁移与分配机制，包含递归子组处理、动态分配/释放LRU结构体及冲突解决逻辑。",
          "similarity": 0.5085473656654358
        },
        {
          "chunk_id": 0,
          "file_path": "mm/list_lru.c",
          "start_line": 1,
          "end_line": 21,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Copyright (c) 2013 Red Hat, Inc. and Parallels Inc. All rights reserved.",
            " * Authors: David Chinner and Glauber Costa",
            " *",
            " * Generic LRU infrastructure",
            " */",
            "#include <linux/kernel.h>",
            "#include <linux/module.h>",
            "#include <linux/mm.h>",
            "#include <linux/list_lru.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/memcontrol.h>",
            "#include \"slab.h\"",
            "#include \"internal.h\"",
            "",
            "#ifdef CONFIG_MEMCG",
            "static LIST_HEAD(memcg_list_lrus);",
            "static DEFINE_MUTEX(list_lrus_mutex);",
            ""
          ],
          "function_name": null,
          "description": "定义了支持内存控制组（MemCG）的LRU基础设施，声明了全局链表头memcg_list_lrus和互斥锁list_lrus_mutex，用于管理MemCG环境下的LRU列表注册与注销操作。",
          "similarity": 0.5081117153167725
        },
        {
          "chunk_id": 3,
          "file_path": "mm/list_lru.c",
          "start_line": 289,
          "end_line": 400,
          "content": [
            "unsigned long",
            "list_lru_walk_one_irq(struct list_lru *lru, int nid, struct mem_cgroup *memcg,",
            "\t\t      list_lru_walk_cb isolate, void *cb_arg,",
            "\t\t      unsigned long *nr_to_walk)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tunsigned long ret;",
            "",
            "\tspin_lock_irq(&nlru->lock);",
            "\tret = __list_lru_walk_one(lru, nid, memcg_kmem_id(memcg), isolate,",
            "\t\t\t\t  cb_arg, nr_to_walk);",
            "\tspin_unlock_irq(&nlru->lock);",
            "\treturn ret;",
            "}",
            "unsigned long list_lru_walk_node(struct list_lru *lru, int nid,",
            "\t\t\t\t list_lru_walk_cb isolate, void *cb_arg,",
            "\t\t\t\t unsigned long *nr_to_walk)",
            "{",
            "\tlong isolated = 0;",
            "",
            "\tisolated += list_lru_walk_one(lru, nid, NULL, isolate, cb_arg,",
            "\t\t\t\t      nr_to_walk);",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tif (*nr_to_walk > 0 && list_lru_memcg_aware(lru)) {",
            "\t\tstruct list_lru_memcg *mlru;",
            "\t\tunsigned long index;",
            "",
            "\t\txa_for_each(&lru->xa, index, mlru) {",
            "\t\t\tstruct list_lru_node *nlru = &lru->node[nid];",
            "",
            "\t\t\tspin_lock(&nlru->lock);",
            "\t\t\tisolated += __list_lru_walk_one(lru, nid, index,",
            "\t\t\t\t\t\t\tisolate, cb_arg,",
            "\t\t\t\t\t\t\tnr_to_walk);",
            "\t\t\tspin_unlock(&nlru->lock);",
            "",
            "\t\t\tif (*nr_to_walk <= 0)",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "#endif",
            "",
            "\treturn isolated;",
            "}",
            "static void init_one_lru(struct list_lru_one *l)",
            "{",
            "\tINIT_LIST_HEAD(&l->list);",
            "\tl->nr_items = 0;",
            "}",
            "static void memcg_list_lru_free(struct list_lru *lru, int src_idx)",
            "{",
            "\tstruct list_lru_memcg *mlru = xa_erase_irq(&lru->xa, src_idx);",
            "",
            "\t/*",
            "\t * The __list_lru_walk_one() can walk the list of this node.",
            "\t * We need kvfree_rcu() here. And the walking of the list",
            "\t * is under lru->node[nid]->lock, which can serve as a RCU",
            "\t * read-side critical section.",
            "\t */",
            "\tif (mlru)",
            "\t\tkvfree_rcu(mlru, rcu);",
            "}",
            "static inline void memcg_init_list_lru(struct list_lru *lru, bool memcg_aware)",
            "{",
            "\tif (memcg_aware)",
            "\t\txa_init_flags(&lru->xa, XA_FLAGS_LOCK_IRQ);",
            "\tlru->memcg_aware = memcg_aware;",
            "}",
            "static void memcg_destroy_list_lru(struct list_lru *lru)",
            "{",
            "\tXA_STATE(xas, &lru->xa, 0);",
            "\tstruct list_lru_memcg *mlru;",
            "",
            "\tif (!list_lru_memcg_aware(lru))",
            "\t\treturn;",
            "",
            "\txas_lock_irq(&xas);",
            "\txas_for_each(&xas, mlru, ULONG_MAX) {",
            "\t\tkfree(mlru);",
            "\t\txas_store(&xas, NULL);",
            "\t}",
            "\txas_unlock_irq(&xas);",
            "}",
            "static void memcg_reparent_list_lru_node(struct list_lru *lru, int nid,",
            "\t\t\t\t\t int src_idx, struct mem_cgroup *dst_memcg)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tint dst_idx = dst_memcg->kmemcg_id;",
            "\tstruct list_lru_one *src, *dst;",
            "",
            "\t/*",
            "\t * Since list_lru_{add,del} may be called under an IRQ-safe lock,",
            "\t * we have to use IRQ-safe primitives here to avoid deadlock.",
            "\t */",
            "\tspin_lock_irq(&nlru->lock);",
            "",
            "\tsrc = list_lru_from_memcg_idx(lru, nid, src_idx);",
            "\tif (!src)",
            "\t\tgoto out;",
            "\tdst = list_lru_from_memcg_idx(lru, nid, dst_idx);",
            "",
            "\tlist_splice_init(&src->list, &dst->list);",
            "",
            "\tif (src->nr_items) {",
            "\t\tdst->nr_items += src->nr_items;",
            "\t\tset_shrinker_bit(dst_memcg, nid, lru_shrinker_id(lru));",
            "\t\tsrc->nr_items = 0;",
            "\t}",
            "out:",
            "\tspin_unlock_irq(&nlru->lock);",
            "}"
          ],
          "function_name": "list_lru_walk_one_irq, list_lru_walk_node, init_one_lru, memcg_list_lru_free, memcg_init_list_lru, memcg_destroy_list_lru, memcg_reparent_list_lru_node",
          "description": "包含LRU节点初始化、内存组间列表迁移、资源释放等高级操作，涉及XA表管理、中断安全锁操作及内存组重新归属处理。",
          "similarity": 0.5037767887115479
        }
      ]
    },
    {
      "source_file": "mm/memtest.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:46:14\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memtest.c`\n\n---\n\n# memtest.c 技术文档\n\n## 1. 文件概述\n\n`memtest.c` 是 Linux 内核中用于在启动早期阶段对物理内存进行测试的模块。其主要功能是在内核初始化过程中，通过写入特定模式数据并回读验证的方式检测物理内存中的坏块（bad memory regions）。一旦发现错误，会将对应的物理内存区域通过 `memblock_reserve()` 标记为保留，防止后续被分配使用，并通过 `/proc/meminfo` 向用户空间报告坏内存的大小。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `early_memtest_done`：布尔值，标记是否已执行过早期内存测试。\n- `early_memtest_bad_size`：记录检测到的坏内存总字节数。\n- `patterns[]`：预定义的测试模式数组，包含多种位模式（如全0、全1、交替位等），用于写入内存以检测不同类型的故障。\n- `memtest_pattern`：控制执行多少轮内存测试，可通过内核启动参数 `memtest=` 配置。\n\n### 主要函数\n- `reserve_bad_mem()`：将检测到的坏内存区域通过 `memblock_reserve()` 保留，并累加坏内存大小。\n- `memtest()`：对指定物理地址范围执行单次内存测试，使用给定模式写入并验证。\n- `do_one_pass()`：遍历所有当前可用的空闲内存区域（通过 `for_each_free_mem_range`），并对每个与指定范围 `[start, end)` 重叠的部分执行 `memtest()`。\n- `parse_memtest()`：解析内核启动参数 `memtest=`，设置测试轮数。\n- `early_memtest()`：对外提供的主入口函数，在早期初始化阶段调用，执行指定次数的内存测试。\n- `memtest_report_meminfo()`：向 `/proc/meminfo` 输出坏内存统计信息（单位为 kB）。\n\n## 3. 关键实现\n\n### 内存测试算法\n- **对齐处理**：测试前将起始物理地址按 `sizeof(u64)` 对齐，确保访问自然对齐的 64 位字。\n- **两阶段操作**：\n  1. **写入阶段**：将整个测试区域按 8 字节步长写入指定模式。\n  2. **验证阶段**：逐字读回并与预期模式比较。\n- **坏块合并**：连续出错的地址会被合并为一个连续区间，仅在区间结束时调用 `reserve_bad_mem()` 一次，减少 `memblock` 操作次数。\n- **原子访问**：使用 `WRITE_ONCE()` 和 `READ_ONCE()` 确保编译器不优化内存访问，保证测试有效性。\n\n### 测试模式循环\n- 若 `memtest_pattern` 设为 N，则从 `patterns` 数组末尾开始向前执行 N 次测试（实际通过模运算循环使用模式）。\n- 默认 `memtest_pattern = 0` 表示禁用测试；若未指定参数但启用该功能，则默认使用全部模式（`ARRAY_SIZE(patterns)` 轮）。\n\n### 坏内存报告\n- 通过 `memtest_report_meminfo()` 向 `/proc/meminfo` 添加 `EarlyMemtestBad` 字段。\n- 即使坏内存小于 1KB，也至少报告为 1kB，避免显示为 0（0 表示无坏块或未执行测试）。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memblock.h>`：用于内存块管理，特别是 `memblock_reserve()` 和 `for_each_free_mem_range()`。\n  - `<linux/seq_file.h>`：用于 `/proc/meminfo` 的输出支持。\n  - `<linux/init.h>`：提供 `__init`、`early_param` 等初始化相关宏。\n- **配置依赖**：\n  - `CONFIG_PROC_FS`：控制是否编译 `memtest_report_meminfo()` 函数。\n- **调用关系**：\n  - `early_memtest()` 通常由体系结构相关的初始化代码（如 x86 的 `setup_arch()`）在 `memblock` 初始化完成后、页表建立前调用。\n  - `memtest_report_meminfo()` 被 `show_meminfo()`（在 `fs/proc/meminfo.c` 中）调用以填充 `/proc/meminfo`。\n\n## 5. 使用场景\n\n- **系统启动早期诊断**：在内核完全初始化前检测物理内存硬件故障，防止坏内存被分配给关键数据结构。\n- **嵌入式/服务器环境**：在高可靠性要求的系统中，通过启动参数 `memtest=N` 启用多轮内存测试，提升系统稳定性。\n- **调试内存问题**：开发人员可利用此功能快速定位物理内存缺陷，尤其是在新硬件平台 bring-up 阶段。\n- **用户空间监控**：通过 `/proc/meminfo` 中的 `EarlyMemtestBad` 字段，运维工具可监控系统是否存在物理内存故障。",
      "similarity": 0.5791487693786621,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/memtest.c",
          "start_line": 32,
          "end_line": 127,
          "content": [
            "static void __init reserve_bad_mem(u64 pattern, phys_addr_t start_bad, phys_addr_t end_bad)",
            "{",
            "\tpr_info(\"  %016llx bad mem addr %pa - %pa reserved\\n\",",
            "\t\tcpu_to_be64(pattern), &start_bad, &end_bad);",
            "\tmemblock_reserve(start_bad, end_bad - start_bad);",
            "\tearly_memtest_bad_size += (end_bad - start_bad);",
            "}",
            "static void __init memtest(u64 pattern, phys_addr_t start_phys, phys_addr_t size)",
            "{",
            "\tu64 *p, *start, *end;",
            "\tphys_addr_t start_bad, last_bad;",
            "\tphys_addr_t start_phys_aligned;",
            "\tconst size_t incr = sizeof(pattern);",
            "",
            "\tstart_phys_aligned = ALIGN(start_phys, incr);",
            "\tstart = __va(start_phys_aligned);",
            "\tend = start + (size - (start_phys_aligned - start_phys)) / incr;",
            "\tstart_bad = 0;",
            "\tlast_bad = 0;",
            "",
            "\tfor (p = start; p < end; p++)",
            "\t\tWRITE_ONCE(*p, pattern);",
            "",
            "\tfor (p = start; p < end; p++, start_phys_aligned += incr) {",
            "\t\tif (READ_ONCE(*p) == pattern)",
            "\t\t\tcontinue;",
            "\t\tif (start_phys_aligned == last_bad + incr) {",
            "\t\t\tlast_bad += incr;",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tif (start_bad)",
            "\t\t\treserve_bad_mem(pattern, start_bad, last_bad + incr);",
            "\t\tstart_bad = last_bad = start_phys_aligned;",
            "\t}",
            "\tif (start_bad)",
            "\t\treserve_bad_mem(pattern, start_bad, last_bad + incr);",
            "",
            "\tearly_memtest_done = true;",
            "}",
            "static void __init do_one_pass(u64 pattern, phys_addr_t start, phys_addr_t end)",
            "{",
            "\tu64 i;",
            "\tphys_addr_t this_start, this_end;",
            "",
            "\tfor_each_free_mem_range(i, NUMA_NO_NODE, MEMBLOCK_NONE, &this_start,",
            "\t\t\t\t&this_end, NULL) {",
            "\t\tthis_start = clamp(this_start, start, end);",
            "\t\tthis_end = clamp(this_end, start, end);",
            "\t\tif (this_start < this_end) {",
            "\t\t\tpr_info(\"  %pa - %pa pattern %016llx\\n\",",
            "\t\t\t\t&this_start, &this_end, cpu_to_be64(pattern));",
            "\t\t\tmemtest(pattern, this_start, this_end - this_start);",
            "\t\t}",
            "\t}",
            "}",
            "static int __init parse_memtest(char *arg)",
            "{",
            "\tint ret = 0;",
            "",
            "\tif (arg)",
            "\t\tret = kstrtouint(arg, 0, &memtest_pattern);",
            "\telse",
            "\t\tmemtest_pattern = ARRAY_SIZE(patterns);",
            "",
            "\treturn ret;",
            "}",
            "void __init early_memtest(phys_addr_t start, phys_addr_t end)",
            "{",
            "\tunsigned int i;",
            "\tunsigned int idx = 0;",
            "",
            "\tif (!memtest_pattern)",
            "\t\treturn;",
            "",
            "\tpr_info(\"early_memtest: # of tests: %u\\n\", memtest_pattern);",
            "\tfor (i = memtest_pattern-1; i < UINT_MAX; --i) {",
            "\t\tidx = i % ARRAY_SIZE(patterns);",
            "\t\tdo_one_pass(patterns[idx], start, end);",
            "\t}",
            "}",
            "void memtest_report_meminfo(struct seq_file *m)",
            "{",
            "\tunsigned long early_memtest_bad_size_kb;",
            "",
            "\tif (!IS_ENABLED(CONFIG_PROC_FS))",
            "\t\treturn;",
            "",
            "\tif (!early_memtest_done)",
            "\t\treturn;",
            "",
            "\tearly_memtest_bad_size_kb = early_memtest_bad_size >> 10;",
            "\tif (early_memtest_bad_size && !early_memtest_bad_size_kb)",
            "\t\tearly_memtest_bad_size_kb = 1;",
            "\t/* When 0 is reported, it means there actually was a successful test */",
            "\tseq_printf(m, \"EarlyMemtestBad:   %5lu kB\\n\", early_memtest_bad_size_kb);",
            "}"
          ],
          "function_name": "reserve_bad_mem, memtest, do_one_pass, parse_memtest, early_memtest, memtest_report_meminfo",
          "description": "实现早期内存测试核心逻辑，包含坏内存区域保留、模式填充验证、内存范围遍历测试、命令行参数解析及测试结果上报功能",
          "similarity": 0.5234981179237366
        },
        {
          "chunk_id": 0,
          "file_path": "mm/memtest.c",
          "start_line": 1,
          "end_line": 31,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>",
            "#include <linux/init.h>",
            "#include <linux/memblock.h>",
            "#include <linux/seq_file.h>",
            "",
            "static bool early_memtest_done;",
            "static phys_addr_t early_memtest_bad_size;",
            "",
            "static u64 patterns[] __initdata = {",
            "\t/* The first entry has to be 0 to leave memtest with zeroed memory */",
            "\t0,",
            "\t0xffffffffffffffffULL,",
            "\t0x5555555555555555ULL,",
            "\t0xaaaaaaaaaaaaaaaaULL,",
            "\t0x1111111111111111ULL,",
            "\t0x2222222222222222ULL,",
            "\t0x4444444444444444ULL,",
            "\t0x8888888888888888ULL,",
            "\t0x3333333333333333ULL,",
            "\t0x6666666666666666ULL,",
            "\t0x9999999999999999ULL,",
            "\t0xccccccccccccccccULL,",
            "\t0x7777777777777777ULL,",
            "\t0xbbbbbbbbbbbbbbbbULL,",
            "\t0xddddddddddddddddULL,",
            "\t0xeeeeeeeeeeeeeeeeULL,",
            "\t0x7a6c7258554e494cULL, /* yeah ;-) */",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义内存测试使用的模式数组，包含多种特定比特模式用于检测内存错误，首项为全零以保证测试结束后内存清零",
          "similarity": 0.48054301738739014
        }
      ]
    }
  ]
}