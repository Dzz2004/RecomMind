{
  "query": "动态加载机制在操作系统中的可扩展性应用",
  "timestamp": "2025-12-26 02:01:53",
  "retrieved_files": [
    {
      "source_file": "kernel/module/kmod.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:03:24\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `module\\kmod.c`\n\n---\n\n# `module/kmod.c` 技术文档\n\n## 1. 文件概述\n\n`kmod.c` 是 Linux 内核中负责**内核模块自动加载机制**的核心实现文件。它提供了从内核空间调用用户态 `modprobe` 工具以动态加载缺失模块的能力。该机制允许内核在运行时按需加载驱动或功能模块（例如当设备被探测到但对应驱动未加载时），从而提升系统灵活性和资源利用率。\n\n该文件实现了 `__request_module()` 接口，作为内核其他子系统请求模块加载的统一入口，并通过 `call_usermodehelper` 机制安全地调用用户空间的 `/sbin/modprobe`（或由 `modprobe_path` 指定的路径）。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`__request_module(bool wait, const char *fmt, ...)`**  \n  内核模块加载的主入口函数。支持格式化模块名，可选择同步（`wait=true`）或异步（`wait=false`）执行。返回值为 0 表示成功启动加载过程，负值为错误码，正值为 `modprobe` 的退出码。\n\n- **`call_modprobe(char *orig_module_name, int wait)`**  \n  封装对用户态 `modprobe` 的调用。构造命令行参数（`modprobe -q -- <module_name>`）和环境变量，通过 `call_usermodehelper_setup()` 和 `call_usermodehelper_exec()` 执行。\n\n- **`free_modprobe_argv(struct subprocess_info *info)`**  \n  释放 `call_modprobe` 中分配的参数内存，作为 `call_usermodehelper_setup()` 的清理回调。\n\n### 关键数据结构与变量\n\n- **`modprobe_path[KMOD_PATH_LEN]`**  \n  全局可配置的 `modprobe` 可执行文件路径，默认为 `CONFIG_MODPROBE_PATH`（通常为 `\"/sbin/modprobe\"`），可通过 `/proc/sys/kernel/modprobe` 修改。\n\n- **`kmod_concurrent_max`**  \n  信号量，限制同时进行的模块加载请求数量，上限为 `MAX_KMOD_CONCURRENT`（50），防止资源耗尽或递归依赖导致的死锁。\n\n- **`MAX_KMOD_ALL_BUSY_TIMEOUT`**  \n  超时阈值（5 秒），当所有并发槽位被占用超过此时间，判定为可能的模块依赖循环，拒绝新请求。\n\n## 3. 关键实现\n\n### 并发控制与死锁预防\n\n- 使用 `down_timeout(&kmod_concurrent_max, ...)` 限制并发加载线程数，避免系统资源（如内存、进程数）被大量 `modprobe` 进程耗尽。\n- 若所有 50 个并发槽位在 5 秒内未释放，内核判定为**模块依赖循环**（如 A 依赖 B，B 又依赖 A），主动拒绝请求并打印警告，防止无限递归。\n- 通过 `WARN_ON_ONCE(wait && current_is_async())` 禁止在异步上下文（如 workqueue、async 任务）中执行**同步**模块加载，避免与 `async_synchronize_full()` 产生死锁。\n\n### 安全与资源管理\n\n- 调用 `security_kernel_module_request()` 执行 LSM（Linux Security Module）安全检查，允许安全模块（如 SELinux、AppArmor）控制模块加载权限。\n- 使用 `UMH_KILLABLE` 标志使 `modprobe` 进程可被信号中断，提升系统响应性。\n- 通过 `kmod_dup_request_exists_wait()` 检测重复的模块加载请求，避免对同一模块发起多次 `modprobe` 调用，提升效率。\n\n### 用户态交互\n\n- 构造标准环境变量（`HOME=/`, `PATH=/sbin:/usr/sbin:/bin:/usr/bin`）确保 `modprobe` 在受限但可用的环境中执行。\n- 使用 `call_usermodehelper` 子系统创建内核线程执行用户态程序，该机制处理了凭证（cred）、文件描述符、挂载命名空间等上下文隔离。\n\n### 跟踪与调试\n\n- 集成 `trace_module_request` 跟踪点，可通过 ftrace 或 perf 监控模块加载请求。\n- 调用 `kmod_dup_request_announce()` 记录重复请求或失败事件，便于诊断。\n\n## 4. 依赖关系\n\n- **内核子系统依赖**：\n  - `call_usermodehelper`（`<linux/unistd.h>`, `<linux/binfmts.h>`）：用于执行用户态 helper 程序。\n  - LSM 框架（`<linux/security.h>`）：执行模块加载安全策略。\n  - 内存管理（`<linux/slab.h>`）：动态分配参数字符串。\n  - 同步原语（`<linux/semaphore.h>` via `DEFINE_SEMAPHORE`）：并发控制。\n  - 调试与跟踪（`<trace/events/module.h>`）：性能分析支持。\n- **配置依赖**：\n  - `CONFIG_MODULES`：模块支持必须启用。\n  - `CONFIG_MODPROBE_PATH`：定义默认 `modprobe` 路径。\n- **内部依赖**：\n  - `internal.h`：包含模块子系统内部声明（如 `kmod_dup_request_exists_wait`）。\n\n## 5. 使用场景\n\n- **设备驱动自动加载**：当内核探测到新硬件（如 USB 设备）但无对应驱动时，通过 `__request_module(\"usb:vXXXXpXXXX...\")` 触发驱动加载。\n- **文件系统按需挂载**：挂载未知文件系统类型时（如 `mount -t foo`），内核调用 `__request_module(\"fs-foo\")` 加载文件系统模块。\n- **网络协议模块加载**：使用未加载的网络协议（如 `AF_PHONET`）时自动加载对应模块。\n- **内核特性动态扩展**：如加密算法、压缩模块等在首次使用时按需加载。\n- **内核模块依赖解析**：当模块 A 依赖模块 B，而 B 未加载时，`insmod`/`modprobe` 内部会通过此机制加载 B。\n\n> **注意**：成功返回仅表示 `modprobe` 已启动，不保证模块最终加载成功。调用者必须验证所需功能是否可用。",
      "similarity": 0.5824941396713257,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/module/kmod.c",
          "start_line": 66,
          "end_line": 161,
          "content": [
            "static void free_modprobe_argv(struct subprocess_info *info)",
            "{",
            "\tkfree(info->argv[3]); /* check call_modprobe() */",
            "\tkfree(info->argv);",
            "}",
            "static int call_modprobe(char *orig_module_name, int wait)",
            "{",
            "\tstruct subprocess_info *info;",
            "\tstatic char *envp[] = {",
            "\t\t\"HOME=/\",",
            "\t\t\"TERM=linux\",",
            "\t\t\"PATH=/sbin:/usr/sbin:/bin:/usr/bin\",",
            "\t\tNULL",
            "\t};",
            "\tchar *module_name;",
            "\tint ret;",
            "",
            "\tchar **argv = kmalloc(sizeof(char *[5]), GFP_KERNEL);",
            "\tif (!argv)",
            "\t\tgoto out;",
            "",
            "\tmodule_name = kstrdup(orig_module_name, GFP_KERNEL);",
            "\tif (!module_name)",
            "\t\tgoto free_argv;",
            "",
            "\targv[0] = modprobe_path;",
            "\targv[1] = \"-q\";",
            "\targv[2] = \"--\";",
            "\targv[3] = module_name;\t/* check free_modprobe_argv() */",
            "\targv[4] = NULL;",
            "",
            "\tinfo = call_usermodehelper_setup(modprobe_path, argv, envp, GFP_KERNEL,",
            "\t\t\t\t\t NULL, free_modprobe_argv, NULL);",
            "\tif (!info)",
            "\t\tgoto free_module_name;",
            "",
            "\tret = call_usermodehelper_exec(info, wait | UMH_KILLABLE);",
            "\tkmod_dup_request_announce(orig_module_name, ret);",
            "\treturn ret;",
            "",
            "free_module_name:",
            "\tkfree(module_name);",
            "free_argv:",
            "\tkfree(argv);",
            "out:",
            "\tkmod_dup_request_announce(orig_module_name, -ENOMEM);",
            "\treturn -ENOMEM;",
            "}",
            "int __request_module(bool wait, const char *fmt, ...)",
            "{",
            "\tva_list args;",
            "\tchar module_name[MODULE_NAME_LEN];",
            "\tint ret, dup_ret;",
            "",
            "\t/*",
            "\t * We don't allow synchronous module loading from async.  Module",
            "\t * init may invoke async_synchronize_full() which will end up",
            "\t * waiting for this task which already is waiting for the module",
            "\t * loading to complete, leading to a deadlock.",
            "\t */",
            "\tWARN_ON_ONCE(wait && current_is_async());",
            "",
            "\tif (!modprobe_path[0])",
            "\t\treturn -ENOENT;",
            "",
            "\tva_start(args, fmt);",
            "\tret = vsnprintf(module_name, MODULE_NAME_LEN, fmt, args);",
            "\tva_end(args);",
            "\tif (ret >= MODULE_NAME_LEN)",
            "\t\treturn -ENAMETOOLONG;",
            "",
            "\tret = security_kernel_module_request(module_name);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = down_timeout(&kmod_concurrent_max, MAX_KMOD_ALL_BUSY_TIMEOUT * HZ);",
            "\tif (ret) {",
            "\t\tpr_warn_ratelimited(\"request_module: modprobe %s cannot be processed, kmod busy with %d threads for more than %d seconds now\",",
            "\t\t\t\t    module_name, MAX_KMOD_CONCURRENT, MAX_KMOD_ALL_BUSY_TIMEOUT);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\ttrace_module_request(module_name, wait, _RET_IP_);",
            "",
            "\tif (kmod_dup_request_exists_wait(module_name, wait, &dup_ret)) {",
            "\t\tret = dup_ret;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tret = call_modprobe(module_name, wait ? UMH_WAIT_PROC : UMH_WAIT_EXEC);",
            "",
            "out:",
            "\tup(&kmod_concurrent_max);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "free_modprobe_argv, call_modprobe, __request_module",
          "description": "实现模块请求处理逻辑，通过调用modprobe执行模块加载，包含参数构造、子进程管理及并发控制机制",
          "similarity": 0.6189272403717041
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/module/kmod.c",
          "start_line": 1,
          "end_line": 65,
          "content": [
            "/*",
            " * kmod - the kernel module loader",
            " *",
            " * Copyright (C) 2023 Luis Chamberlain <mcgrof@kernel.org>",
            " */",
            "",
            "#include <linux/module.h>",
            "#include <linux/sched.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/unistd.h>",
            "#include <linux/kmod.h>",
            "#include <linux/slab.h>",
            "#include <linux/completion.h>",
            "#include <linux/cred.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/security.h>",
            "#include <linux/mount.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init.h>",
            "#include <linux/resource.h>",
            "#include <linux/notifier.h>",
            "#include <linux/suspend.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/async.h>",
            "#include <linux/uaccess.h>",
            "",
            "#include <trace/events/module.h>",
            "#include \"internal.h\"",
            "",
            "/*",
            " * Assuming:",
            " *",
            " * threads = div64_u64((u64) totalram_pages * (u64) PAGE_SIZE,",
            " *\t\t       (u64) THREAD_SIZE * 8UL);",
            " *",
            " * If you need less than 50 threads would mean we're dealing with systems",
            " * smaller than 3200 pages. This assumes you are capable of having ~13M memory,",
            " * and this would only be an upper limit, after which the OOM killer would take",
            " * effect. Systems like these are very unlikely if modules are enabled.",
            " */",
            "#define MAX_KMOD_CONCURRENT 50",
            "static DEFINE_SEMAPHORE(kmod_concurrent_max, MAX_KMOD_CONCURRENT);",
            "",
            "/*",
            " * This is a restriction on having *all* MAX_KMOD_CONCURRENT threads",
            " * running at the same time without returning. When this happens we",
            " * believe you've somehow ended up with a recursive module dependency",
            " * creating a loop.",
            " *",
            " * We have no option but to fail.",
            " *",
            " * Userspace should proactively try to detect and prevent these.",
            " */",
            "#define MAX_KMOD_ALL_BUSY_TIMEOUT 5",
            "",
            "/*",
            "\tmodprobe_path is set via /proc/sys.",
            "*/",
            "char modprobe_path[KMOD_PATH_LEN] = CONFIG_MODPROBE_PATH;",
            ""
          ],
          "function_name": null,
          "description": "定义模块加载并发控制相关常量与全局变量，包含模块加载所需头文件并初始化modprobe路径",
          "similarity": 0.565995991230011
        }
      ]
    },
    {
      "source_file": "kernel/usermode_driver.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:47:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `usermode_driver.c`\n\n---\n\n# usermode_driver.c 技术文档\n\n## 文件概述\n\n`usermode_driver.c` 实现了 Linux 内核中用户态驱动（User Mode Driver, UMD）的支持机制。该文件提供了一套 API，允许内核模块将一段可执行的二进制数据（blob）加载为临时文件系统中的可执行文件，并以此为基础 fork 出一个用户态进程作为驱动程序运行。该机制常用于需要在用户空间执行复杂逻辑但又需与内核紧密协作的驱动场景（如某些固件加载器、安全模块或虚拟设备驱动）。\n\n## 核心功能\n\n### 主要函数\n\n- `blob_to_mnt(const void *data, size_t len, const char *name)`  \n  将二进制数据写入 tmpfs 文件系统中，返回挂载点（vfsmount）。\n\n- `umd_load_blob(struct umd_info *info, const void *data, size_t len)`  \n  将给定的二进制 blob 加载为可执行文件，并关联到 `umd_info` 结构中。\n\n- `umd_unload_blob(struct umd_info *info)`  \n  卸载之前加载的 blob，释放相关文件系统资源。\n\n- `fork_usermode_driver(struct umd_info *info)`  \n  基于已加载的 blob fork 并执行一个用户态驱动进程。\n\n- `umd_setup(struct subprocess_info *info, struct cred *new)`  \n  在子进程中设置执行环境，包括创建通信管道、设置工作目录等。\n\n- `umd_cleanup(struct subprocess_info *info)`  \n  子进程执行失败时的清理回调。\n\n- `umd_cleanup_helper(struct umd_info *info)`  \n  释放 `umd_setup` 中分配的资源（管道、PID 等）。\n\n### 关键数据结构\n\n- `struct umd_info`  \n  描述用户态驱动的上下文信息，包含：\n  - `wd`：工作目录（`struct path`），指向 tmpfs 中的可执行文件所在目录\n  - `driver_name`：驱动程序在 tmpfs 中的文件名\n  - `pipe_to_umh` / `pipe_from_umh`：与用户态进程通信的双向管道\n  - `tgid`：用户态驱动进程的线程组 ID（用于后续管理）\n\n## 关键实现\n\n### Blob 到可执行文件的转换\n\n`blob_to_mnt()` 函数通过以下步骤将内存中的二进制数据转换为可执行文件：\n\n1. 挂载 `tmpfs` 文件系统（使用 `kern_mount()`）\n2. 在挂载点根目录下以指定名称创建文件（权限 `0700`）\n3. 使用 `kernel_write()` 将数据写入文件\n4. 调用 `flush_delayed_fput()` 和 `task_work_run()` 确保文件描述符延迟释放完成，以便后续 `exec` 能以只读方式打开该文件\n\n此机制避免了将驱动二进制写入磁盘，提高了安全性和灵活性。\n\n### 用户态驱动进程的启动\n\n`fork_usermode_driver()` 利用内核的 `call_usermodehelper` 机制：\n\n- 使用 `call_usermodehelper_setup()` 注册 `umd_setup` 作为子进程初始化回调\n- 在 `umd_setup` 中：\n  - 创建两个匿名管道：一个用于内核向用户态发送数据（stdin 重定向），一个用于用户态向内核返回数据（stdout 重定向）\n  - 使用 `replace_fd()` 将标准输入/输出重定向到管道端点\n  - 设置当前进程的 pwd（工作目录）为 tmpfs 挂载点，使 `exec` 能直接以相对路径执行驱动文件\n  - 保存管道文件指针和子进程 TGID 到 `umd_info`\n- 执行 `call_usermodehelper_exec()` 启动进程\n\n### 资源管理与错误处理\n\n- `umd_load_blob()` 和 `umd_unload_blob()` 通过 `WARN_ON_ONCE` 确保状态一致性（避免重复加载/卸载）\n- 若 `exec` 失败，`umd_cleanup` 回调会调用 `umd_cleanup_helper` 释放管道和 PID\n- 所有资源（vfsmount、file、pipe、pid）均通过内核标准接口分配和释放，确保无泄漏\n\n## 依赖关系\n\n- **文件系统**：依赖 `tmpfs`（通过 `get_fs_type(\"tmpfs\")`），用于临时存储可执行 blob\n- **进程管理**：依赖 `call_usermodehelper` 子系统（`linux/kmod.h` 隐式包含），用于 fork/exec 用户态进程\n- **VFS 层**：使用 `kern_mount`/`kern_unmount`、`file_open_root_mnt`、`kernel_write` 等 VFS 接口\n- **IPC 机制**：依赖管道（`create_pipe_files`）实现内核与用户态驱动的双向通信\n- **内存管理**：依赖 `shmem_fs.h`（tmpfs 底层基于共享内存）\n- **任务工作队列**：调用 `task_work_run()` 确保文件描述符及时释放\n\n## 使用场景\n\n1. **动态用户态驱动加载**  \n   内核模块可将嵌入的 ELF 二进制或脚本作为 blob 加载，无需预先安装到文件系统。\n\n2. **安全隔离驱动**  \n   将可能含漏洞的驱动逻辑移至用户空间运行，通过管道与内核通信，降低内核攻击面。\n\n3. **固件或微码加载器**  \n   某些设备需要复杂的固件初始化逻辑，可通过 UMD 在用户态执行，避免内核复杂性。\n\n4. **虚拟设备后端**  \n   如 virtio-user、vhost-user 等场景，内核前端通过 UMD 与用户态后端进程协作。\n\n5. **测试与原型开发**  \n   快速验证驱动逻辑，无需频繁编译内核模块，提高开发效率。\n\n> **注意**：调用者需负责用户态进程的生命周期管理（健康检查、信号终止、管道关闭等）。",
      "similarity": 0.5688906311988831,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/usermode_driver.c",
          "start_line": 60,
          "end_line": 161,
          "content": [
            "int umd_load_blob(struct umd_info *info, const void *data, size_t len)",
            "{",
            "\tstruct vfsmount *mnt;",
            "",
            "\tif (WARN_ON_ONCE(info->wd.dentry || info->wd.mnt))",
            "\t\treturn -EBUSY;",
            "",
            "\tmnt = blob_to_mnt(data, len, info->driver_name);",
            "\tif (IS_ERR(mnt))",
            "\t\treturn PTR_ERR(mnt);",
            "",
            "\tinfo->wd.mnt = mnt;",
            "\tinfo->wd.dentry = mnt->mnt_root;",
            "\treturn 0;",
            "}",
            "int umd_unload_blob(struct umd_info *info)",
            "{",
            "\tif (WARN_ON_ONCE(!info->wd.mnt ||",
            "\t\t\t !info->wd.dentry ||",
            "\t\t\t info->wd.mnt->mnt_root != info->wd.dentry))",
            "\t\treturn -EINVAL;",
            "",
            "\tkern_unmount(info->wd.mnt);",
            "\tinfo->wd.mnt = NULL;",
            "\tinfo->wd.dentry = NULL;",
            "\treturn 0;",
            "}",
            "static int umd_setup(struct subprocess_info *info, struct cred *new)",
            "{",
            "\tstruct umd_info *umd_info = info->data;",
            "\tstruct file *from_umh[2];",
            "\tstruct file *to_umh[2];",
            "\tint err;",
            "",
            "\t/* create pipe to send data to umh */",
            "\terr = create_pipe_files(to_umh, 0);",
            "\tif (err)",
            "\t\treturn err;",
            "\terr = replace_fd(0, to_umh[0], 0);",
            "\tfput(to_umh[0]);",
            "\tif (err < 0) {",
            "\t\tfput(to_umh[1]);",
            "\t\treturn err;",
            "\t}",
            "",
            "\t/* create pipe to receive data from umh */",
            "\terr = create_pipe_files(from_umh, 0);",
            "\tif (err) {",
            "\t\tfput(to_umh[1]);",
            "\t\treplace_fd(0, NULL, 0);",
            "\t\treturn err;",
            "\t}",
            "\terr = replace_fd(1, from_umh[1], 0);",
            "\tfput(from_umh[1]);",
            "\tif (err < 0) {",
            "\t\tfput(to_umh[1]);",
            "\t\treplace_fd(0, NULL, 0);",
            "\t\tfput(from_umh[0]);",
            "\t\treturn err;",
            "\t}",
            "",
            "\tset_fs_pwd(current->fs, &umd_info->wd);",
            "\tumd_info->pipe_to_umh = to_umh[1];",
            "\tumd_info->pipe_from_umh = from_umh[0];",
            "\tumd_info->tgid = get_pid(task_tgid(current));",
            "\treturn 0;",
            "}",
            "static void umd_cleanup(struct subprocess_info *info)",
            "{",
            "\tstruct umd_info *umd_info = info->data;",
            "",
            "\t/* cleanup if umh_setup() was successful but exec failed */",
            "\tif (info->retval)",
            "\t\tumd_cleanup_helper(umd_info);",
            "}",
            "void umd_cleanup_helper(struct umd_info *info)",
            "{",
            "\tfput(info->pipe_to_umh);",
            "\tfput(info->pipe_from_umh);",
            "\tput_pid(info->tgid);",
            "\tinfo->tgid = NULL;",
            "}",
            "int fork_usermode_driver(struct umd_info *info)",
            "{",
            "\tstruct subprocess_info *sub_info;",
            "\tconst char *argv[] = { info->driver_name, NULL };",
            "\tint err;",
            "",
            "\tif (WARN_ON_ONCE(info->tgid))",
            "\t\treturn -EBUSY;",
            "",
            "\terr = -ENOMEM;",
            "\tsub_info = call_usermodehelper_setup(info->driver_name,",
            "\t\t\t\t\t     (char **)argv, NULL, GFP_KERNEL,",
            "\t\t\t\t\t     umd_setup, umd_cleanup, info);",
            "\tif (!sub_info)",
            "\t\tgoto out;",
            "",
            "\terr = call_usermodehelper_exec(sub_info, UMH_WAIT_EXEC);",
            "out:",
            "\treturn err;",
            "}"
          ],
          "function_name": "umd_load_blob, umd_unload_blob, umd_setup, umd_cleanup, umd_cleanup_helper, fork_usermode_driver",
          "description": "提供用户模式驱动程序的数据加载/卸载及子进程管理功能，包括挂载tmpfs、建立进程间管道通信、设置工作目录及清理资源，最终通过call_usermodehelper启动用户态驱动程序",
          "similarity": 0.5636416673660278
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/usermode_driver.c",
          "start_line": 1,
          "end_line": 59,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * umd - User mode driver support",
            " */",
            "#include <linux/shmem_fs.h>",
            "#include <linux/pipe_fs_i.h>",
            "#include <linux/mount.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/task_work.h>",
            "#include <linux/usermode_driver.h>",
            "",
            "static struct vfsmount *blob_to_mnt(const void *data, size_t len, const char *name)",
            "{",
            "\tstruct file_system_type *type;",
            "\tstruct vfsmount *mnt;",
            "\tstruct file *file;",
            "\tssize_t written;",
            "\tloff_t pos = 0;",
            "",
            "\ttype = get_fs_type(\"tmpfs\");",
            "\tif (!type)",
            "\t\treturn ERR_PTR(-ENODEV);",
            "",
            "\tmnt = kern_mount(type);",
            "\tput_filesystem(type);",
            "\tif (IS_ERR(mnt))",
            "\t\treturn mnt;",
            "",
            "\tfile = file_open_root_mnt(mnt, name, O_CREAT | O_WRONLY, 0700);",
            "\tif (IS_ERR(file)) {",
            "\t\tkern_unmount(mnt);",
            "\t\treturn ERR_CAST(file);",
            "\t}",
            "",
            "\twritten = kernel_write(file, data, len, &pos);",
            "\tif (written != len) {",
            "\t\tint err = written;",
            "\t\tif (err >= 0)",
            "\t\t\terr = -ENOMEM;",
            "\t\tfilp_close(file, NULL);",
            "\t\tkern_unmount(mnt);",
            "\t\treturn ERR_PTR(err);",
            "\t}",
            "",
            "\tfput(file);",
            "",
            "\t/* Flush delayed fput so exec can open the file read-only */",
            "\tflush_delayed_fput();",
            "\ttask_work_run();",
            "\treturn mnt;",
            "}",
            "",
            "/**",
            " * umd_load_blob - Remember a blob of bytes for fork_usermode_driver",
            " * @info: information about usermode driver",
            " * @data: a blob of bytes that can be executed as a file",
            " * @len:  The lentgh of the blob",
            " *",
            " */"
          ],
          "function_name": null,
          "description": "创建并挂载tmpfs文件系统以存储二进制数据，通过文件操作将输入数据写入新挂载点的指定名称文件，返回对应的vfsmount结构指针",
          "similarity": 0.49039342999458313
        }
      ]
    },
    {
      "source_file": "kernel/sched/pelt.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:13:26\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\pelt.c`\n\n---\n\n# `sched/pelt.c` 技术文档\n\n## 1. 文件概述\n\n`sched/pelt.c` 实现了 **Per-Entity Load Tracking（PELT）** 机制，这是 Linux 内核 CFS（Completely Fair Scheduler）调度器中用于精确跟踪每个调度实体（如任务或任务组）负载、可运行性和 CPU 利用率的核心算法。  \nPELT 将时间划分为约 1ms（1024ns）的周期段，使用指数衰减的几何级数对历史负载进行加权求和，使得近期负载权重更高，远期负载影响逐渐衰减。该机制为负载均衡、能效调度（如 EAS）和 CPU 频率调节等子系统提供关键的负载指标。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `decay_load(u64 val, u64 n)`  \n  计算负载值 `val` 经过 `n` 个时间单位后的衰减值，利用预计算的衰减系数表和位移优化实现高效指数衰减。\n\n- `__accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)`  \n  计算跨越多个完整周期时，负载贡献的三部分之和：上一周期剩余部分（d1）、中间完整周期总和（d2）、当前周期已过部分（d3）。\n\n- `accumulate_sum(u64 delta, struct sched_avg *sa, unsigned long load, unsigned long runnable, int running)`  \n  核心累加函数，根据时间增量 `delta` 更新 `load_sum`、`runnable_sum` 和 `util_sum`，处理跨周期衰减与新贡献累加。\n\n- `___update_load_sum(u64 now, struct sched_avg *sa, unsigned long load, unsigned long runnable, int running)`  \n  入口函数，计算自上次更新以来的时间差，调用 `accumulate_sum` 更新负载总和，并处理时间回退等异常情况。\n\n- `___update_load_avg(struct sched_avg *sa, unsigned long load)`  \n  根据当前 `*_sum` 值和动态除数（divider）计算并更新 `load_avg`、`runnable_avg` 和 `util_avg`。\n\n### 关键数据结构\n\n- `struct sched_avg`  \n  存储 PELT 相关状态，包括：\n  - `load_sum` / `runnable_sum` / `util_sum`：衰减加权后的负载总和\n  - `load_avg` / `runnable_avg` / `util_avg`：归一化后的平均负载值\n  - `last_update_time`：上次更新时间戳\n  - `period_contrib`：当前周期内已累积的时间（<1024ns）\n\n## 3. 关键实现\n\n### 时间分段与衰减模型\n- 时间以 **1024ns（≈1μs）** 为基本单位，每 **1024 单位（≈1ms）** 构成一个 PELT 周期。\n- 衰减因子 `y` 满足 `y^32 ≈ 0.5`，即约 32ms 前的负载贡献衰减至当前的一半。\n- 负载历史表示为几何级数：`u₀ + u₁·y + u₂·y² + ...`，其中 `uᵢ` 是第 `i` 个周期内的可运行比例。\n\n### 高效衰减计算\n- `decay_load()` 利用 `y^32 = 1/2` 的特性，将 `y^n` 拆分为 `1/2^(n/32) * y^(n%32)`。\n- 通过右移操作快速计算 `1/2^k` 部分，再查表 `runnable_avg_yN_inv[]` 获取 `y^(n%32)` 的倒数，结合 `mul_u64_u32_shr` 完成乘法。\n\n### 负载累加三段式\n当时间增量跨越多个周期时，负载贡献分为：\n1. **d1**：上一周期未完成部分（`1024 - period_contrib`）\n2. **d2**：中间完整周期的理论最大贡献（`LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024`）\n3. **d3**：当前周期已过部分（`delta % 1024`）\n\n### 动态归一化\n- 使用 `get_pelt_divider()` 获取当前周期位置对应的归一化除数，避免因周期未结束导致的平均值震荡。\n- 除数公式：`LOAD_AVG_MAX - 1024 + period_contrib`，确保最大负载值在 `[1002, 1024)` 区间稳定。\n\n### 状态一致性保障\n- 若 `load == 0`，强制 `runnable = running = 0`，避免已出队实体产生无效贡献。\n- 时间回退（如 TSC 切换）时直接重置 `last_update_time`，防止负时间差导致异常。\n\n## 4. 依赖关系\n\n- **头文件依赖**：  \n  依赖 `kernel/sched/sched.h` 中定义的 `struct sched_avg`、`SCHED_CAPACITY_SHIFT`、`LOAD_AVG_*` 常量及 `get_pelt_divider()` 等辅助函数。\n- **预计算表**：  \n  使用外部定义的 `runnable_avg_yN_inv[32]` 衰减系数表（通常在 `fair.c` 或 `pelt.h` 中初始化）。\n- **调度器集成**：  \n  被 `fair.c` 中的 CFS 调度实体（`sched_entity`）和 CFS 运行队列（`cfs_rq`）调用，用于更新任务/任务组的负载状态。\n- **能效调度**：  \n  为 Energy Aware Scheduling (EAS) 提供 `util_avg` 作为 CPU 需求预测依据。\n\n## 5. 使用场景\n\n- **任务负载跟踪**：  \n  每个 `task_struct` 的 `sched_entity` 通过 PELT 实时更新其 `load_avg` 和 `util_avg`，反映任务对 CPU 的历史需求。\n- **任务组调度**：  \n  CFS 任务组（`task_group`）的 `cfs_rq` 使用 PELT 聚合子任务的负载，实现层级化负载均衡。\n- **负载均衡决策**：  \n  `load_balance()` 等函数依据 `runnable_avg` 判断 CPU 间负载差异，触发任务迁移。\n- **CPU 频率调节**：  \n  CPUFreq 的 `schedutil` 调速器使用 `util_avg` 动态调整 CPU 频率，平衡性能与功耗。\n- **空闲负载处理**：  \n  在 `idle_balance()` 等场景中，即使任务已出队，仍需通过 PELT 正确衰减其历史负载贡献。",
      "similarity": 0.5641858577728271,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/pelt.c",
          "start_line": 256,
          "end_line": 384,
          "content": [
            "static __always_inline void",
            "___update_load_avg(struct sched_avg *sa, unsigned long load)",
            "{",
            "\tu32 divider = get_pelt_divider(sa);",
            "",
            "\t/*",
            "\t * Step 2: update *_avg.",
            "\t */",
            "\tsa->load_avg = div_u64(load * sa->load_sum, divider);",
            "\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);",
            "\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);",
            "}",
            "int __update_load_avg_blocked_se(u64 now, struct sched_entity *se)",
            "{",
            "\tif (___update_load_sum(now, &se->avg, 0, 0, 0)) {",
            "\t\t___update_load_avg(&se->avg, se_weight(se));",
            "\t\ttrace_pelt_se_tp(se);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int __update_load_avg_se(u64 now, struct cfs_rq *cfs_rq, struct sched_entity *se)",
            "{",
            "\tif (___update_load_sum(now, &se->avg, !!se->on_rq, se_runnable(se),",
            "\t\t\t\tcfs_rq->curr == se)) {",
            "",
            "\t\t___update_load_avg(&se->avg, se_weight(se));",
            "\t\tcfs_se_util_change(&se->avg);",
            "\t\ttrace_pelt_se_tp(se);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int __update_load_avg_cfs_rq(u64 now, struct cfs_rq *cfs_rq)",
            "{",
            "\tif (___update_load_sum(now, &cfs_rq->avg,",
            "\t\t\t\tscale_load_down(cfs_rq->load.weight),",
            "\t\t\t\tcfs_rq->h_nr_running,",
            "\t\t\t\tcfs_rq->curr != NULL)) {",
            "",
            "\t\t___update_load_avg(&cfs_rq->avg, 1);",
            "\t\ttrace_pelt_cfs_tp(cfs_rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_rt_rq_load_avg(u64 now, struct rq *rq, int running)",
            "{",
            "\tif (___update_load_sum(now, &rq->avg_rt,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning)) {",
            "",
            "\t\t___update_load_avg(&rq->avg_rt, 1);",
            "\t\ttrace_pelt_rt_tp(rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_dl_rq_load_avg(u64 now, struct rq *rq, int running)",
            "{",
            "\tif (___update_load_sum(now, &rq->avg_dl,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning)) {",
            "",
            "\t\t___update_load_avg(&rq->avg_dl, 1);",
            "\t\ttrace_pelt_dl_tp(rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_hw_load_avg(u64 now, struct rq *rq, u64 capacity)",
            "{",
            "\tif (___update_load_sum(now, &rq->avg_hw,",
            "\t\t\t       capacity,",
            "\t\t\t       capacity,",
            "\t\t\t       capacity)) {",
            "\t\t___update_load_avg(&rq->avg_hw, 1);",
            "\t\ttrace_pelt_hw_tp(rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_irq_load_avg(struct rq *rq, u64 running)",
            "{",
            "\tint ret = 0;",
            "",
            "\t/*",
            "\t * We can't use clock_pelt because irq time is not accounted in",
            "\t * clock_task. Instead we directly scale the running time to",
            "\t * reflect the real amount of computation",
            "\t */",
            "\trunning = cap_scale(running, arch_scale_freq_capacity(cpu_of(rq)));",
            "\trunning = cap_scale(running, arch_scale_cpu_capacity(cpu_of(rq)));",
            "",
            "\t/*",
            "\t * We know the time that has been used by interrupt since last update",
            "\t * but we don't when. Let be pessimistic and assume that interrupt has",
            "\t * happened just before the update. This is not so far from reality",
            "\t * because interrupt will most probably wake up task and trig an update",
            "\t * of rq clock during which the metric is updated.",
            "\t * We start to decay with normal context time and then we add the",
            "\t * interrupt context time.",
            "\t * We can safely remove running from rq->clock because",
            "\t * rq->clock += delta with delta >= running",
            "\t */",
            "\tret = ___update_load_sum(rq->clock - running, &rq->avg_irq,",
            "\t\t\t\t0,",
            "\t\t\t\t0,",
            "\t\t\t\t0);",
            "\tret += ___update_load_sum(rq->clock, &rq->avg_irq,",
            "\t\t\t\t1,",
            "\t\t\t\t1,",
            "\t\t\t\t1);",
            "",
            "\tif (ret) {",
            "\t\t___update_load_avg(&rq->avg_irq, 1);",
            "\t\ttrace_pelt_irq_tp(rq);",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "___update_load_avg, __update_load_avg_blocked_se, __update_load_avg_se, __update_load_avg_cfs_rq, update_rt_rq_load_avg, update_dl_rq_load_avg, update_hw_load_avg, update_irq_load_avg",
          "description": "提供多场景下的负载平均值更新接口，包含六个函数：___update_load_avg计算负载平均值；__update_load_avg_blocked_se更新阻塞任务实体；__update_load_avg_se处理CFS队列中任务实体；__update_load_avg_cfs_rq更新CFS队列负载；update_rt_rq_load_avg/update_dl_rq_load_avg分别处理实时/延迟调度队列；update_hw_load_avg和update_irq_load_avg分别更新硬件资源及中断负载统计",
          "similarity": 0.5672382712364197
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/pelt.c",
          "start_line": 31,
          "end_line": 178,
          "content": [
            "static u64 decay_load(u64 val, u64 n)",
            "{",
            "\tunsigned int local_n;",
            "",
            "\tif (unlikely(n > LOAD_AVG_PERIOD * 63))",
            "\t\treturn 0;",
            "",
            "\t/* after bounds checking we can collapse to 32-bit */",
            "\tlocal_n = n;",
            "",
            "\t/*",
            "\t * As y^PERIOD = 1/2, we can combine",
            "\t *    y^n = 1/2^(n/PERIOD) * y^(n%PERIOD)",
            "\t * With a look-up table which covers y^n (n<PERIOD)",
            "\t *",
            "\t * To achieve constant time decay_load.",
            "\t */",
            "\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {",
            "\t\tval >>= local_n / LOAD_AVG_PERIOD;",
            "\t\tlocal_n %= LOAD_AVG_PERIOD;",
            "\t}",
            "",
            "\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);",
            "\treturn val;",
            "}",
            "static u32 __accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)",
            "{",
            "\tu32 c1, c2, c3 = d3; /* y^0 == 1 */",
            "",
            "\t/*",
            "\t * c1 = d1 y^p",
            "\t */",
            "\tc1 = decay_load((u64)d1, periods);",
            "",
            "\t/*",
            "\t *            p-1",
            "\t * c2 = 1024 \\Sum y^n",
            "\t *            n=1",
            "\t *",
            "\t *              inf        inf",
            "\t *    = 1024 ( \\Sum y^n - \\Sum y^n - y^0 )",
            "\t *              n=0        n=p",
            "\t */",
            "\tc2 = LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024;",
            "",
            "\treturn c1 + c2 + c3;",
            "}",
            "static __always_inline u32",
            "accumulate_sum(u64 delta, struct sched_avg *sa,",
            "\t       unsigned long load, unsigned long runnable, int running)",
            "{",
            "\tu32 contrib = (u32)delta; /* p == 0 -> delta < 1024 */",
            "\tu64 periods;",
            "",
            "\tdelta += sa->period_contrib;",
            "\tperiods = delta / 1024; /* A period is 1024us (~1ms) */",
            "",
            "\t/*",
            "\t * Step 1: decay old *_sum if we crossed period boundaries.",
            "\t */",
            "\tif (periods) {",
            "\t\tsa->load_sum = decay_load(sa->load_sum, periods);",
            "\t\tsa->runnable_sum =",
            "\t\t\tdecay_load(sa->runnable_sum, periods);",
            "\t\tsa->util_sum = decay_load((u64)(sa->util_sum), periods);",
            "",
            "\t\t/*",
            "\t\t * Step 2",
            "\t\t */",
            "\t\tdelta %= 1024;",
            "\t\tif (load) {",
            "\t\t\t/*",
            "\t\t\t * This relies on the:",
            "\t\t\t *",
            "\t\t\t * if (!load)",
            "\t\t\t *\trunnable = running = 0;",
            "\t\t\t *",
            "\t\t\t * clause from ___update_load_sum(); this results in",
            "\t\t\t * the below usage of @contrib to disappear entirely,",
            "\t\t\t * so no point in calculating it.",
            "\t\t\t */",
            "\t\t\tcontrib = __accumulate_pelt_segments(periods,",
            "\t\t\t\t\t1024 - sa->period_contrib, delta);",
            "\t\t}",
            "\t}",
            "\tsa->period_contrib = delta;",
            "",
            "\tif (load)",
            "\t\tsa->load_sum += load * contrib;",
            "\tif (runnable)",
            "\t\tsa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;",
            "\tif (running)",
            "\t\tsa->util_sum += contrib << SCHED_CAPACITY_SHIFT;",
            "",
            "\treturn periods;",
            "}",
            "static __always_inline int",
            "___update_load_sum(u64 now, struct sched_avg *sa,",
            "\t\t  unsigned long load, unsigned long runnable, int running)",
            "{",
            "\tu64 delta;",
            "",
            "\tdelta = now - sa->last_update_time;",
            "\t/*",
            "\t * This should only happen when time goes backwards, which it",
            "\t * unfortunately does during sched clock init when we swap over to TSC.",
            "\t */",
            "\tif ((s64)delta < 0) {",
            "\t\tsa->last_update_time = now;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * Use 1024ns as the unit of measurement since it's a reasonable",
            "\t * approximation of 1us and fast to compute.",
            "\t */",
            "\tdelta >>= 10;",
            "\tif (!delta)",
            "\t\treturn 0;",
            "",
            "\tsa->last_update_time += delta << 10;",
            "",
            "\t/*",
            "\t * running is a subset of runnable (weight) so running can't be set if",
            "\t * runnable is clear. But there are some corner cases where the current",
            "\t * se has been already dequeued but cfs_rq->curr still points to it.",
            "\t * This means that weight will be 0 but not running for a sched_entity",
            "\t * but also for a cfs_rq if the latter becomes idle. As an example,",
            "\t * this happens during idle_balance() which calls",
            "\t * sched_balance_update_blocked_averages().",
            "\t *",
            "\t * Also see the comment in accumulate_sum().",
            "\t */",
            "\tif (!load)",
            "\t\trunnable = running = 0;",
            "",
            "\t/*",
            "\t * Now we know we crossed measurement unit boundaries. The *_avg",
            "\t * accrues by two steps:",
            "\t *",
            "\t * Step 1: accumulate *_sum since last_update_time. If we haven't",
            "\t * crossed period boundaries, finish.",
            "\t */",
            "\tif (!accumulate_sum(delta, sa, load, runnable, running))",
            "\t\treturn 0;",
            "",
            "\treturn 1;",
            "}"
          ],
          "function_name": "decay_load, __accumulate_pelt_segments, accumulate_sum, ___update_load_sum",
          "description": "实现PELT核心算法，包含四个关键函数：decay_load通过位移运算模拟指数衰减；__accumulate_pelt_segments计算周期性负载贡献；accumulate_sum根据时间差更新负载、运行时和利用率的加权总和；___update_load_sum处理时间边界穿越时的衰减逻辑并触发更新。所有函数共同维护调度实体的动态负载统计",
          "similarity": 0.5485678315162659
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/pelt.c",
          "start_line": 1,
          "end_line": 30,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Per Entity Load Tracking",
            " *",
            " *  Copyright (C) 2007 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>",
            " *",
            " *  Interactivity improvements by Mike Galbraith",
            " *  (C) 2007 Mike Galbraith <efault@gmx.de>",
            " *",
            " *  Various enhancements by Dmitry Adamushko.",
            " *  (C) 2007 Dmitry Adamushko <dmitry.adamushko@gmail.com>",
            " *",
            " *  Group scheduling enhancements by Srivatsa Vaddagiri",
            " *  Copyright IBM Corporation, 2007",
            " *  Author: Srivatsa Vaddagiri <vatsa@linux.vnet.ibm.com>",
            " *",
            " *  Scaled math optimizations by Thomas Gleixner",
            " *  Copyright (C) 2007, Thomas Gleixner <tglx@linutronix.de>",
            " *",
            " *  Adaptive scheduling granularity, math enhancements by Peter Zijlstra",
            " *  Copyright (C) 2007 Red Hat, Inc., Peter Zijlstra",
            " *",
            " *  Move PELT related code from fair.c into this pelt.c file",
            " *  Author: Vincent Guittot <vincent.guittot@linaro.org>",
            " */",
            "",
            "/*",
            " * Approximate:",
            " *   val * y^n,    where y^32 ~= 0.5 (~1 scheduling period)",
            " */"
          ],
          "function_name": null,
          "description": "此代码块为PELT（Per-entity Load Tracking）模块的头部注释，声明了该模块的版权信息、作者及主要贡献者，并概述了PELT算法的目标，即通过时间衰减模型精确跟踪调度实体的负载变化，支持交互性优化、分组调度等功能。上下文不完整",
          "similarity": 0.46237969398498535
        }
      ]
    }
  ]
}