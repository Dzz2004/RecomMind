{
  "query": "传输数据包 分布式系统特点",
  "timestamp": "2025-12-26 01:23:04",
  "retrieved_files": [
    {
      "source_file": "kernel/trace/ring_buffer.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:07:21\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `trace\\ring_buffer.c`\n\n---\n\n# `trace/ring_buffer.c` 技术文档\n\n## 1. 文件概述\n\n`trace/ring_buffer.c` 实现了 Linux 内核中通用的高性能环形缓冲区（ring buffer）机制，主要用于跟踪（tracing）子系统。该缓冲区支持多 CPU 并发写入、单读者或多读者无锁读取，并通过时间戳压缩、事件类型编码和页面交换等技术优化内存使用和性能。该实现是 ftrace、perf 和其他内核跟踪工具的核心基础设施。\n\n## 2. 核心功能\n\n### 主要函数\n- `ring_buffer_print_entry_header()`：输出环形缓冲区条目头部格式说明，用于调试或用户空间解析。\n- `ring_buffer_event_length()`：返回事件有效载荷（payload）的长度，对 TIME_EXTEND 类型自动跳过扩展头。\n- `rb_event_data()`（内联）：返回指向事件实际数据的指针，处理 TIME_EXTEND 和不同长度编码。\n- `rb_event_length()`：返回完整事件结构（含头部）的字节长度。\n- `rb_event_ts_length()`：返回 TIME_EXTEND 事件及其后续数据事件的总长度。\n- `rb_event_data_length()`：计算数据类型事件的总长度（含头部）。\n- `rb_null_event()` / `rb_event_set_padding()`：判断或设置空/填充事件。\n\n### 关键数据结构（隐含或引用）\n- `struct ring_buffer_event`：环形缓冲区中每个事件的通用头部结构。\n- `struct buffer_data_page`：每个 CPU 缓冲区页面的封装，包含数据和元数据。\n- 每 CPU 页面链表：每个 CPU 拥有独立的环形页面链，写者仅写本地 CPU 缓冲区。\n\n### 核心常量与宏\n- `RINGBUF_TYPE_PADDING`、`RINGBUF_TYPE_TIME_EXTEND`、`RINGBUF_TYPE_TIME_STAMP`、`RINGBUF_TYPE_DATA`：事件类型标识。\n- `RB_ALIGNMENT` / `RB_ARCH_ALIGNMENT`：数据对齐策略，根据架构是否支持 64 位对齐访问调整。\n- `RB_MAX_SMALL_DATA`：小数据事件的最大长度（基于 4 字节对齐和类型长度上限）。\n- `TS_MSB` / `ABS_TS_MASK`：用于处理 59 位时间戳的高位截断与恢复。\n\n## 3. 关键实现\n\n### 无锁读写架构\n- **写者**：每个 CPU 只能写入其对应的 per-CPU 缓冲区，通过原子操作和内存屏障保证写入一致性，无需全局锁。\n- **读者**：每个 per-CPU 缓冲区维护一个独立的“reader page”。当 reader page 被读完后，通过原子交换（未来使用 `cmpxchg`）将其与环形缓冲区中的一个页面互换。交换后，原 reader page 不再被写者访问，读者可安全地将其用于 splice、复制或释放。\n\n### 事件编码与压缩\n- 事件头部使用紧凑位域编码：\n  - `type_len`（5 位）：事件类型或小数据长度（≤31）。\n  - `time_delta`（27 位）：相对于前一事件的时间增量。\n  - `array`（32 位）：用于存储大长度值或事件数据。\n- **TIME_EXTEND 事件**：当时间增量超出 27 位或需要绝对时间戳时，插入一个 8 字节的 TIME_EXTEND 事件，后跟实际数据事件。\n- **数据长度编码**：\n  - 若 `type_len > 0` 且 ≤ `RINGBUF_TYPE_DATA_TYPE_LEN_MAX`，则数据长度 = `type_len * RB_ALIGNMENT`，数据从 `array[0]` 开始。\n  - 否则，数据长度存储在 `array[0]`，实际数据从 `array[1]` 开始。\n\n### 时间戳处理\n- 绝对时间戳仅保留低 59 位（`ABS_TS_MASK`），高 5 位（`TS_MSB`）若非零需单独保存并在读取时恢复，以支持长时间运行的跟踪。\n\n### 内存对齐优化\n- 在支持 64 位对齐访问的架构上（`CONFIG_HAVE_64BIT_ALIGNED_ACCESS`），强制 8 字节对齐（`RB_FORCE_8BYTE_ALIGNMENT`），提升访问性能；否则使用 4 字节对齐。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/ring_buffer.h>`：定义公共 API 和数据结构。\n  - `<linux/trace_clock.h>`、`<linux/sched/clock.h>`：提供高精度时间戳源。\n  - `<linux/percpu.h>`：支持 per-CPU 缓冲区分配。\n  - `<linux/spinlock.h>`、`<asm/local.h>`：提供底层原子操作和锁原语。\n  - `<linux/trace_recursion.h>`：防止跟踪递归。\n- **子系统依赖**：\n  - **ftrace**：主要消费者，用于函数跟踪、事件跟踪等。\n  - **perf**：通过 ring buffer 获取性能事件数据。\n  - **Security Module**：通过 `<linux/security.h>` 集成 LSM 钩子（如 trace 访问控制）。\n- **架构依赖**：依赖 `CONFIG_HAVE_64BIT_ALIGNED_ACCESS` 配置项优化对齐策略。\n\n## 5. 使用场景\n\n- **内核跟踪（ftrace）**：记录函数调用、上下文切换、中断等事件，数据写入 per-CPU ring buffer，用户通过 `tracefs` 读取。\n- **性能分析（perf）**：perf 工具通过 ring buffer 接收内核采样事件（如 PMU 中断、软件事件）。\n- **实时监控与调试**：开发者或运维人员通过读取 ring buffer 内容分析系统行为、延迟或错误。\n- **自测试（selftest）**：文件包含自测试逻辑（依赖 `<linux/kthread.h>`），用于验证 ring buffer 功能正确性。\n- **低开销事件记录**：由于其无锁设计和压缩编码，适用于高频事件记录场景（如每秒百万级事件）。",
      "similarity": 0.5236457586288452,
      "chunks": [
        {
          "chunk_id": 27,
          "file_path": "kernel/trace/ring_buffer.c",
          "start_line": 6041,
          "end_line": 6232,
          "content": [
            "static __init int rb_test(void *arg)",
            "{",
            "\tstruct rb_test_data *data = arg;",
            "",
            "\twhile (!kthread_should_stop()) {",
            "\t\trb_write_something(data, false);",
            "\t\tdata->cnt++;",
            "",
            "\t\tset_current_state(TASK_INTERRUPTIBLE);",
            "\t\t/* Now sleep between a min of 100-300us and a max of 1ms */",
            "\t\tusleep_range(((data->cnt % 3) + 1) * 100, 1000);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static __init void rb_ipi(void *ignore)",
            "{",
            "\tstruct rb_test_data *data;",
            "\tint cpu = smp_processor_id();",
            "",
            "\tdata = &rb_data[cpu];",
            "\trb_write_something(data, true);",
            "}",
            "static __init int rb_hammer_test(void *arg)",
            "{",
            "\twhile (!kthread_should_stop()) {",
            "",
            "\t\t/* Send an IPI to all cpus to write data! */",
            "\t\tsmp_call_function(rb_ipi, NULL, 1);",
            "\t\t/* No sleep, but for non preempt, let others run */",
            "\t\tschedule();",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static __init int test_ringbuffer(void)",
            "{",
            "\tstruct task_struct *rb_hammer;",
            "\tstruct trace_buffer *buffer;",
            "\tint cpu;",
            "\tint ret = 0;",
            "",
            "\tif (security_locked_down(LOCKDOWN_TRACEFS)) {",
            "\t\tpr_warn(\"Lockdown is enabled, skipping ring buffer tests\\n\");",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tpr_info(\"Running ring buffer tests...\\n\");",
            "",
            "\tbuffer = ring_buffer_alloc(RB_TEST_BUFFER_SIZE, RB_FL_OVERWRITE);",
            "\tif (WARN_ON(!buffer))",
            "\t\treturn 0;",
            "",
            "\t/* Disable buffer so that threads can't write to it yet */",
            "\tring_buffer_record_off(buffer);",
            "",
            "\tfor_each_online_cpu(cpu) {",
            "\t\trb_data[cpu].buffer = buffer;",
            "\t\trb_data[cpu].cpu = cpu;",
            "\t\trb_data[cpu].cnt = cpu;",
            "\t\trb_threads[cpu] = kthread_run_on_cpu(rb_test, &rb_data[cpu],",
            "\t\t\t\t\t\t     cpu, \"rbtester/%u\");",
            "\t\tif (WARN_ON(IS_ERR(rb_threads[cpu]))) {",
            "\t\t\tpr_cont(\"FAILED\\n\");",
            "\t\t\tret = PTR_ERR(rb_threads[cpu]);",
            "\t\t\tgoto out_free;",
            "\t\t}",
            "\t}",
            "",
            "\t/* Now create the rb hammer! */",
            "\trb_hammer = kthread_run(rb_hammer_test, NULL, \"rbhammer\");",
            "\tif (WARN_ON(IS_ERR(rb_hammer))) {",
            "\t\tpr_cont(\"FAILED\\n\");",
            "\t\tret = PTR_ERR(rb_hammer);",
            "\t\tgoto out_free;",
            "\t}",
            "",
            "\tring_buffer_record_on(buffer);",
            "\t/*",
            "\t * Show buffer is enabled before setting rb_test_started.",
            "\t * Yes there's a small race window where events could be",
            "\t * dropped and the thread wont catch it. But when a ring",
            "\t * buffer gets enabled, there will always be some kind of",
            "\t * delay before other CPUs see it. Thus, we don't care about",
            "\t * those dropped events. We care about events dropped after",
            "\t * the threads see that the buffer is active.",
            "\t */",
            "\tsmp_wmb();",
            "\trb_test_started = true;",
            "",
            "\tset_current_state(TASK_INTERRUPTIBLE);",
            "\t/* Just run for 10 seconds */;",
            "\tschedule_timeout(10 * HZ);",
            "",
            "\tkthread_stop(rb_hammer);",
            "",
            " out_free:",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tif (!rb_threads[cpu])",
            "\t\t\tbreak;",
            "\t\tkthread_stop(rb_threads[cpu]);",
            "\t}",
            "\tif (ret) {",
            "\t\tring_buffer_free(buffer);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\t/* Report! */",
            "\tpr_info(\"finished\\n\");",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct ring_buffer_event *event;",
            "\t\tstruct rb_test_data *data = &rb_data[cpu];",
            "\t\tstruct rb_item *item;",
            "\t\tunsigned long total_events;",
            "\t\tunsigned long total_dropped;",
            "\t\tunsigned long total_written;",
            "\t\tunsigned long total_alloc;",
            "\t\tunsigned long total_read = 0;",
            "\t\tunsigned long total_size = 0;",
            "\t\tunsigned long total_len = 0;",
            "\t\tunsigned long total_lost = 0;",
            "\t\tunsigned long lost;",
            "\t\tint big_event_size;",
            "\t\tint small_event_size;",
            "",
            "\t\tret = -1;",
            "",
            "\t\ttotal_events = data->events + data->events_nested;",
            "\t\ttotal_written = data->bytes_written + data->bytes_written_nested;",
            "\t\ttotal_alloc = data->bytes_alloc + data->bytes_alloc_nested;",
            "\t\ttotal_dropped = data->bytes_dropped + data->bytes_dropped_nested;",
            "",
            "\t\tbig_event_size = data->max_size + data->max_size_nested;",
            "\t\tsmall_event_size = data->min_size + data->min_size_nested;",
            "",
            "\t\tpr_info(\"CPU %d:\\n\", cpu);",
            "\t\tpr_info(\"              events:    %ld\\n\", total_events);",
            "\t\tpr_info(\"       dropped bytes:    %ld\\n\", total_dropped);",
            "\t\tpr_info(\"       alloced bytes:    %ld\\n\", total_alloc);",
            "\t\tpr_info(\"       written bytes:    %ld\\n\", total_written);",
            "\t\tpr_info(\"       biggest event:    %d\\n\", big_event_size);",
            "\t\tpr_info(\"      smallest event:    %d\\n\", small_event_size);",
            "",
            "\t\tif (RB_WARN_ON(buffer, total_dropped))",
            "\t\t\tbreak;",
            "",
            "\t\tret = 0;",
            "",
            "\t\twhile ((event = ring_buffer_consume(buffer, cpu, NULL, &lost))) {",
            "\t\t\ttotal_lost += lost;",
            "\t\t\titem = ring_buffer_event_data(event);",
            "\t\t\ttotal_len += ring_buffer_event_length(event);",
            "\t\t\ttotal_size += item->size + sizeof(struct rb_item);",
            "\t\t\tif (memcmp(&item->str[0], rb_string, item->size) != 0) {",
            "\t\t\t\tpr_info(\"FAILED!\\n\");",
            "\t\t\t\tpr_info(\"buffer had: %.*s\\n\", item->size, item->str);",
            "\t\t\t\tpr_info(\"expected:   %.*s\\n\", item->size, rb_string);",
            "\t\t\t\tRB_WARN_ON(buffer, 1);",
            "\t\t\t\tret = -1;",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t\ttotal_read++;",
            "\t\t}",
            "\t\tif (ret)",
            "\t\t\tbreak;",
            "",
            "\t\tret = -1;",
            "",
            "\t\tpr_info(\"         read events:   %ld\\n\", total_read);",
            "\t\tpr_info(\"         lost events:   %ld\\n\", total_lost);",
            "\t\tpr_info(\"        total events:   %ld\\n\", total_lost + total_read);",
            "\t\tpr_info(\"  recorded len bytes:   %ld\\n\", total_len);",
            "\t\tpr_info(\" recorded size bytes:   %ld\\n\", total_size);",
            "\t\tif (total_lost) {",
            "\t\t\tpr_info(\" With dropped events, record len and size may not match\\n\"",
            "\t\t\t\t\" alloced and written from above\\n\");",
            "\t\t} else {",
            "\t\t\tif (RB_WARN_ON(buffer, total_len != total_alloc ||",
            "\t\t\t\t       total_size != total_written))",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t\tif (RB_WARN_ON(buffer, total_lost + total_read != total_events))",
            "\t\t\tbreak;",
            "",
            "\t\tret = 0;",
            "\t}",
            "\tif (!ret)",
            "\t\tpr_info(\"Ring buffer PASSED!\\n\");",
            "",
            "\tring_buffer_free(buffer);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "rb_test, rb_ipi, rb_hammer_test, test_ringbuffer",
          "description": "rb_test 循环执行写入操作并休眠；rb_ipi 通过IPI触发其他CPU写入；rb_hammer_test 连续发送IPI进行并发写入；test_ringbuffer 初始化缓冲区，启动测试线程，运行测试用例并验证数据完整性，统计事件数量、丢弃情况及数据一致性",
          "similarity": 0.4921431243419647
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/trace/ring_buffer.c",
          "start_line": 2052,
          "end_line": 2363,
          "content": [
            "static bool",
            "rb_insert_pages(struct ring_buffer_per_cpu *cpu_buffer)",
            "{",
            "\tstruct list_head *pages = &cpu_buffer->new_pages;",
            "\tunsigned long flags;",
            "\tbool success;",
            "\tint retries;",
            "",
            "\t/* Can be called at early boot up, where interrupts must not been enabled */",
            "\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);",
            "\t/*",
            "\t * We are holding the reader lock, so the reader page won't be swapped",
            "\t * in the ring buffer. Now we are racing with the writer trying to",
            "\t * move head page and the tail page.",
            "\t * We are going to adapt the reader page update process where:",
            "\t * 1. We first splice the start and end of list of new pages between",
            "\t *    the head page and its previous page.",
            "\t * 2. We cmpxchg the prev_page->next to point from head page to the",
            "\t *    start of new pages list.",
            "\t * 3. Finally, we update the head->prev to the end of new list.",
            "\t *",
            "\t * We will try this process 10 times, to make sure that we don't keep",
            "\t * spinning.",
            "\t */",
            "\tretries = 10;",
            "\tsuccess = false;",
            "\twhile (retries--) {",
            "\t\tstruct list_head *head_page, *prev_page, *r;",
            "\t\tstruct list_head *last_page, *first_page;",
            "\t\tstruct list_head *head_page_with_bit;",
            "\t\tstruct buffer_page *hpage = rb_set_head_page(cpu_buffer);",
            "",
            "\t\tif (!hpage)",
            "\t\t\tbreak;",
            "\t\thead_page = &hpage->list;",
            "\t\tprev_page = head_page->prev;",
            "",
            "\t\tfirst_page = pages->next;",
            "\t\tlast_page  = pages->prev;",
            "",
            "\t\thead_page_with_bit = (struct list_head *)",
            "\t\t\t\t     ((unsigned long)head_page | RB_PAGE_HEAD);",
            "",
            "\t\tlast_page->next = head_page_with_bit;",
            "\t\tfirst_page->prev = prev_page;",
            "",
            "\t\tr = cmpxchg(&prev_page->next, head_page_with_bit, first_page);",
            "",
            "\t\tif (r == head_page_with_bit) {",
            "\t\t\t/*",
            "\t\t\t * yay, we replaced the page pointer to our new list,",
            "\t\t\t * now, we just have to update to head page's prev",
            "\t\t\t * pointer to point to end of list",
            "\t\t\t */",
            "\t\t\thead_page->prev = last_page;",
            "\t\t\tsuccess = true;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "",
            "\tif (success)",
            "\t\tINIT_LIST_HEAD(pages);",
            "\t/*",
            "\t * If we weren't successful in adding in new pages, warn and stop",
            "\t * tracing",
            "\t */",
            "\tRB_WARN_ON(cpu_buffer, !success);",
            "\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);",
            "",
            "\t/* free pages if they weren't inserted */",
            "\tif (!success) {",
            "\t\tstruct buffer_page *bpage, *tmp;",
            "\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,",
            "\t\t\t\t\t list) {",
            "\t\t\tlist_del_init(&bpage->list);",
            "\t\t\tfree_buffer_page(bpage);",
            "\t\t}",
            "\t}",
            "\treturn success;",
            "}",
            "static void rb_update_pages(struct ring_buffer_per_cpu *cpu_buffer)",
            "{",
            "\tbool success;",
            "",
            "\tif (cpu_buffer->nr_pages_to_update > 0)",
            "\t\tsuccess = rb_insert_pages(cpu_buffer);",
            "\telse",
            "\t\tsuccess = rb_remove_pages(cpu_buffer,",
            "\t\t\t\t\t-cpu_buffer->nr_pages_to_update);",
            "",
            "\tif (success)",
            "\t\tcpu_buffer->nr_pages += cpu_buffer->nr_pages_to_update;",
            "}",
            "static void update_pages_handler(struct work_struct *work)",
            "{",
            "\tstruct ring_buffer_per_cpu *cpu_buffer = container_of(work,",
            "\t\t\tstruct ring_buffer_per_cpu, update_pages_work);",
            "\trb_update_pages(cpu_buffer);",
            "\tcomplete(&cpu_buffer->update_done);",
            "}",
            "int ring_buffer_resize(struct trace_buffer *buffer, unsigned long size,",
            "\t\t\tint cpu_id)",
            "{",
            "\tstruct ring_buffer_per_cpu *cpu_buffer;",
            "\tunsigned long nr_pages;",
            "\tint cpu, err;",
            "",
            "\t/*",
            "\t * Always succeed at resizing a non-existent buffer:",
            "\t */",
            "\tif (!buffer)",
            "\t\treturn 0;",
            "",
            "\t/* Make sure the requested buffer exists */",
            "\tif (cpu_id != RING_BUFFER_ALL_CPUS &&",
            "\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))",
            "\t\treturn 0;",
            "",
            "\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);",
            "",
            "\t/* we need a minimum of two pages */",
            "\tif (nr_pages < 2)",
            "\t\tnr_pages = 2;",
            "",
            "\t/* prevent another thread from changing buffer sizes */",
            "\tmutex_lock(&buffer->mutex);",
            "\tatomic_inc(&buffer->resizing);",
            "",
            "\tif (cpu_id == RING_BUFFER_ALL_CPUS) {",
            "\t\t/*",
            "\t\t * Don't succeed if resizing is disabled, as a reader might be",
            "\t\t * manipulating the ring buffer and is expecting a sane state while",
            "\t\t * this is true.",
            "\t\t */",
            "\t\tfor_each_buffer_cpu(buffer, cpu) {",
            "\t\t\tcpu_buffer = buffer->buffers[cpu];",
            "\t\t\tif (atomic_read(&cpu_buffer->resize_disabled)) {",
            "\t\t\t\terr = -EBUSY;",
            "\t\t\t\tgoto out_err_unlock;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\t/* calculate the pages to update */",
            "\t\tfor_each_buffer_cpu(buffer, cpu) {",
            "\t\t\tcpu_buffer = buffer->buffers[cpu];",
            "",
            "\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -",
            "\t\t\t\t\t\t\tcpu_buffer->nr_pages;",
            "\t\t\t/*",
            "\t\t\t * nothing more to do for removing pages or no update",
            "\t\t\t */",
            "\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)",
            "\t\t\t\tcontinue;",
            "\t\t\t/*",
            "\t\t\t * to add pages, make sure all new pages can be",
            "\t\t\t * allocated without receiving ENOMEM",
            "\t\t\t */",
            "\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);",
            "\t\t\tif (__rb_allocate_pages(cpu_buffer, cpu_buffer->nr_pages_to_update,",
            "\t\t\t\t\t\t&cpu_buffer->new_pages)) {",
            "\t\t\t\t/* not enough memory for new pages */",
            "\t\t\t\terr = -ENOMEM;",
            "\t\t\t\tgoto out_err;",
            "\t\t\t}",
            "",
            "\t\t\tcond_resched();",
            "\t\t}",
            "",
            "\t\tcpus_read_lock();",
            "\t\t/*",
            "\t\t * Fire off all the required work handlers",
            "\t\t * We can't schedule on offline CPUs, but it's not necessary",
            "\t\t * since we can change their buffer sizes without any race.",
            "\t\t */",
            "\t\tfor_each_buffer_cpu(buffer, cpu) {",
            "\t\t\tcpu_buffer = buffer->buffers[cpu];",
            "\t\t\tif (!cpu_buffer->nr_pages_to_update)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\t/* Can't run something on an offline CPU. */",
            "\t\t\tif (!cpu_online(cpu)) {",
            "\t\t\t\trb_update_pages(cpu_buffer);",
            "\t\t\t\tcpu_buffer->nr_pages_to_update = 0;",
            "\t\t\t} else {",
            "\t\t\t\t/* Run directly if possible. */",
            "\t\t\t\tmigrate_disable();",
            "\t\t\t\tif (cpu != smp_processor_id()) {",
            "\t\t\t\t\tmigrate_enable();",
            "\t\t\t\t\tschedule_work_on(cpu,",
            "\t\t\t\t\t\t\t &cpu_buffer->update_pages_work);",
            "\t\t\t\t} else {",
            "\t\t\t\t\tupdate_pages_handler(&cpu_buffer->update_pages_work);",
            "\t\t\t\t\tmigrate_enable();",
            "\t\t\t\t}",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\t/* wait for all the updates to complete */",
            "\t\tfor_each_buffer_cpu(buffer, cpu) {",
            "\t\t\tcpu_buffer = buffer->buffers[cpu];",
            "\t\t\tif (!cpu_buffer->nr_pages_to_update)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tif (cpu_online(cpu))",
            "\t\t\t\twait_for_completion(&cpu_buffer->update_done);",
            "\t\t\tcpu_buffer->nr_pages_to_update = 0;",
            "\t\t}",
            "",
            "\t\tcpus_read_unlock();",
            "\t} else {",
            "\t\tcpu_buffer = buffer->buffers[cpu_id];",
            "",
            "\t\tif (nr_pages == cpu_buffer->nr_pages)",
            "\t\t\tgoto out;",
            "",
            "\t\t/*",
            "\t\t * Don't succeed if resizing is disabled, as a reader might be",
            "\t\t * manipulating the ring buffer and is expecting a sane state while",
            "\t\t * this is true.",
            "\t\t */",
            "\t\tif (atomic_read(&cpu_buffer->resize_disabled)) {",
            "\t\t\terr = -EBUSY;",
            "\t\t\tgoto out_err_unlock;",
            "\t\t}",
            "",
            "\t\tcpu_buffer->nr_pages_to_update = nr_pages -",
            "\t\t\t\t\t\tcpu_buffer->nr_pages;",
            "",
            "\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);",
            "\t\tif (cpu_buffer->nr_pages_to_update > 0 &&",
            "\t\t\t__rb_allocate_pages(cpu_buffer, cpu_buffer->nr_pages_to_update,",
            "\t\t\t\t\t    &cpu_buffer->new_pages)) {",
            "\t\t\terr = -ENOMEM;",
            "\t\t\tgoto out_err;",
            "\t\t}",
            "",
            "\t\tcpus_read_lock();",
            "",
            "\t\t/* Can't run something on an offline CPU. */",
            "\t\tif (!cpu_online(cpu_id))",
            "\t\t\trb_update_pages(cpu_buffer);",
            "\t\telse {",
            "\t\t\t/* Run directly if possible. */",
            "\t\t\tmigrate_disable();",
            "\t\t\tif (cpu_id == smp_processor_id()) {",
            "\t\t\t\trb_update_pages(cpu_buffer);",
            "\t\t\t\tmigrate_enable();",
            "\t\t\t} else {",
            "\t\t\t\tmigrate_enable();",
            "\t\t\t\tschedule_work_on(cpu_id,",
            "\t\t\t\t\t\t &cpu_buffer->update_pages_work);",
            "\t\t\t\twait_for_completion(&cpu_buffer->update_done);",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tcpu_buffer->nr_pages_to_update = 0;",
            "\t\tcpus_read_unlock();",
            "\t}",
            "",
            " out:",
            "\t/*",
            "\t * The ring buffer resize can happen with the ring buffer",
            "\t * enabled, so that the update disturbs the tracing as little",
            "\t * as possible. But if the buffer is disabled, we do not need",
            "\t * to worry about that, and we can take the time to verify",
            "\t * that the buffer is not corrupt.",
            "\t */",
            "\tif (atomic_read(&buffer->record_disabled)) {",
            "\t\tatomic_inc(&buffer->record_disabled);",
            "\t\t/*",
            "\t\t * Even though the buffer was disabled, we must make sure",
            "\t\t * that it is truly disabled before calling rb_check_pages.",
            "\t\t * There could have been a race between checking",
            "\t\t * record_disable and incrementing it.",
            "\t\t */",
            "\t\tsynchronize_rcu();",
            "\t\tfor_each_buffer_cpu(buffer, cpu) {",
            "\t\t\tunsigned long flags;",
            "",
            "\t\t\tcpu_buffer = buffer->buffers[cpu];",
            "\t\t\traw_spin_lock_irqsave(&cpu_buffer->reader_lock, flags);",
            "\t\t\trb_check_pages(cpu_buffer);",
            "\t\t\traw_spin_unlock_irqrestore(&cpu_buffer->reader_lock, flags);",
            "\t\t}",
            "\t\tatomic_dec(&buffer->record_disabled);",
            "\t}",
            "",
            "\tatomic_dec(&buffer->resizing);",
            "\tmutex_unlock(&buffer->mutex);",
            "\treturn 0;",
            "",
            " out_err:",
            "\tfor_each_buffer_cpu(buffer, cpu) {",
            "\t\tstruct buffer_page *bpage, *tmp;",
            "",
            "\t\tcpu_buffer = buffer->buffers[cpu];",
            "\t\tcpu_buffer->nr_pages_to_update = 0;",
            "",
            "\t\tif (list_empty(&cpu_buffer->new_pages))",
            "\t\t\tcontinue;",
            "",
            "\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,",
            "\t\t\t\t\tlist) {",
            "\t\t\tlist_del_init(&bpage->list);",
            "\t\t\tfree_buffer_page(bpage);",
            "\t\t}",
            "\t}",
            " out_err_unlock:",
            "\tatomic_dec(&buffer->resizing);",
            "\tmutex_unlock(&buffer->mutex);",
            "\treturn err;",
            "}"
          ],
          "function_name": "rb_insert_pages, rb_update_pages, update_pages_handler, ring_buffer_resize",
          "description": "实现将新分配的缓冲页插入到环形缓冲区的头部，通过CAS操作确保线程安全地更新链表结构，若失败则释放内存资源。包含调整缓冲区大小的核心逻辑，协调多CPU上的页面分配与更新操作。",
          "similarity": 0.49005910754203796
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/trace/ring_buffer.c",
          "start_line": 45,
          "end_line": 148,
          "content": [
            "int ring_buffer_print_entry_header(struct trace_seq *s)",
            "{",
            "\ttrace_seq_puts(s, \"# compressed entry header\\n\");",
            "\ttrace_seq_puts(s, \"\\ttype_len    :    5 bits\\n\");",
            "\ttrace_seq_puts(s, \"\\ttime_delta  :   27 bits\\n\");",
            "\ttrace_seq_puts(s, \"\\tarray       :   32 bits\\n\");",
            "\ttrace_seq_putc(s, '\\n');",
            "\ttrace_seq_printf(s, \"\\tpadding     : type == %d\\n\",",
            "\t\t\t RINGBUF_TYPE_PADDING);",
            "\ttrace_seq_printf(s, \"\\ttime_extend : type == %d\\n\",",
            "\t\t\t RINGBUF_TYPE_TIME_EXTEND);",
            "\ttrace_seq_printf(s, \"\\ttime_stamp : type == %d\\n\",",
            "\t\t\t RINGBUF_TYPE_TIME_STAMP);",
            "\ttrace_seq_printf(s, \"\\tdata max type_len  == %d\\n\",",
            "\t\t\t RINGBUF_TYPE_DATA_TYPE_LEN_MAX);",
            "",
            "\treturn !trace_seq_has_overflowed(s);",
            "}",
            "static inline bool rb_null_event(struct ring_buffer_event *event)",
            "{",
            "\treturn event->type_len == RINGBUF_TYPE_PADDING && !event->time_delta;",
            "}",
            "static void rb_event_set_padding(struct ring_buffer_event *event)",
            "{",
            "\t/* padding has a NULL time_delta */",
            "\tevent->type_len = RINGBUF_TYPE_PADDING;",
            "\tevent->time_delta = 0;",
            "}",
            "static unsigned",
            "rb_event_data_length(struct ring_buffer_event *event)",
            "{",
            "\tunsigned length;",
            "",
            "\tif (event->type_len)",
            "\t\tlength = event->type_len * RB_ALIGNMENT;",
            "\telse",
            "\t\tlength = event->array[0];",
            "\treturn length + RB_EVNT_HDR_SIZE;",
            "}",
            "static inline unsigned",
            "rb_event_length(struct ring_buffer_event *event)",
            "{",
            "\tswitch (event->type_len) {",
            "\tcase RINGBUF_TYPE_PADDING:",
            "\t\tif (rb_null_event(event))",
            "\t\t\t/* undefined */",
            "\t\t\treturn -1;",
            "\t\treturn  event->array[0] + RB_EVNT_HDR_SIZE;",
            "",
            "\tcase RINGBUF_TYPE_TIME_EXTEND:",
            "\t\treturn RB_LEN_TIME_EXTEND;",
            "",
            "\tcase RINGBUF_TYPE_TIME_STAMP:",
            "\t\treturn RB_LEN_TIME_STAMP;",
            "",
            "\tcase RINGBUF_TYPE_DATA:",
            "\t\treturn rb_event_data_length(event);",
            "\tdefault:",
            "\t\tWARN_ON_ONCE(1);",
            "\t}",
            "\t/* not hit */",
            "\treturn 0;",
            "}",
            "static inline unsigned",
            "rb_event_ts_length(struct ring_buffer_event *event)",
            "{",
            "\tunsigned len = 0;",
            "",
            "\tif (extended_time(event)) {",
            "\t\t/* time extends include the data event after it */",
            "\t\tlen = RB_LEN_TIME_EXTEND;",
            "\t\tevent = skip_time_extend(event);",
            "\t}",
            "\treturn len + rb_event_length(event);",
            "}",
            "unsigned ring_buffer_event_length(struct ring_buffer_event *event)",
            "{",
            "\tunsigned length;",
            "",
            "\tif (extended_time(event))",
            "\t\tevent = skip_time_extend(event);",
            "",
            "\tlength = rb_event_length(event);",
            "\tif (event->type_len > RINGBUF_TYPE_DATA_TYPE_LEN_MAX)",
            "\t\treturn length;",
            "\tlength -= RB_EVNT_HDR_SIZE;",
            "\tif (length > RB_MAX_SMALL_DATA + sizeof(event->array[0]))",
            "                length -= sizeof(event->array[0]);",
            "\treturn length;",
            "}",
            "static u64 rb_event_time_stamp(struct ring_buffer_event *event)",
            "{",
            "\tu64 ts;",
            "",
            "\tts = event->array[0];",
            "\tts <<= TS_SHIFT;",
            "\tts += event->time_delta;",
            "",
            "\treturn ts;",
            "}",
            "static void rb_init_page(struct buffer_data_page *bpage)",
            "{",
            "\tlocal_set(&bpage->commit, 0);",
            "}"
          ],
          "function_name": "ring_buffer_print_entry_header, rb_null_event, rb_event_set_padding, rb_event_data_length, rb_event_length, rb_event_ts_length, ring_buffer_event_length, rb_event_time_stamp, rb_init_page",
          "description": "实现环形缓冲区事件解析功能，包括打印事件头信息、识别空事件、设置填充事件、计算不同事件类型的数据长度及时间戳，提供事件长度和时间戳读取接口",
          "similarity": 0.4781017303466797
        },
        {
          "chunk_id": 14,
          "file_path": "kernel/trace/ring_buffer.c",
          "start_line": 3074,
          "end_line": 3177,
          "content": [
            "static void rb_start_commit(struct ring_buffer_per_cpu *cpu_buffer)",
            "{",
            "\tlocal_inc(&cpu_buffer->committing);",
            "\tlocal_inc(&cpu_buffer->commits);",
            "}",
            "static __always_inline void",
            "rb_set_commit_to_write(struct ring_buffer_per_cpu *cpu_buffer)",
            "{",
            "\tunsigned long max_count;",
            "",
            "\t/*",
            "\t * We only race with interrupts and NMIs on this CPU.",
            "\t * If we own the commit event, then we can commit",
            "\t * all others that interrupted us, since the interruptions",
            "\t * are in stack format (they finish before they come",
            "\t * back to us). This allows us to do a simple loop to",
            "\t * assign the commit to the tail.",
            "\t */",
            " again:",
            "\tmax_count = cpu_buffer->nr_pages * 100;",
            "",
            "\twhile (cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)) {",
            "\t\tif (RB_WARN_ON(cpu_buffer, !(--max_count)))",
            "\t\t\treturn;",
            "\t\tif (RB_WARN_ON(cpu_buffer,",
            "\t\t\t       rb_is_reader_page(cpu_buffer->tail_page)))",
            "\t\t\treturn;",
            "\t\t/*",
            "\t\t * No need for a memory barrier here, as the update",
            "\t\t * of the tail_page did it for this page.",
            "\t\t */",
            "\t\tlocal_set(&cpu_buffer->commit_page->page->commit,",
            "\t\t\t  rb_page_write(cpu_buffer->commit_page));",
            "\t\trb_inc_page(&cpu_buffer->commit_page);",
            "\t\t/* add barrier to keep gcc from optimizing too much */",
            "\t\tbarrier();",
            "\t}",
            "\twhile (rb_commit_index(cpu_buffer) !=",
            "\t       rb_page_write(cpu_buffer->commit_page)) {",
            "",
            "\t\t/* Make sure the readers see the content of what is committed. */",
            "\t\tsmp_wmb();",
            "\t\tlocal_set(&cpu_buffer->commit_page->page->commit,",
            "\t\t\t  rb_page_write(cpu_buffer->commit_page));",
            "\t\tRB_WARN_ON(cpu_buffer,",
            "\t\t\t   local_read(&cpu_buffer->commit_page->page->commit) &",
            "\t\t\t   ~RB_WRITE_MASK);",
            "\t\tbarrier();",
            "\t}",
            "",
            "\t/* again, keep gcc from optimizing */",
            "\tbarrier();",
            "",
            "\t/*",
            "\t * If an interrupt came in just after the first while loop",
            "\t * and pushed the tail page forward, we will be left with",
            "\t * a dangling commit that will never go forward.",
            "\t */",
            "\tif (unlikely(cpu_buffer->commit_page != READ_ONCE(cpu_buffer->tail_page)))",
            "\t\tgoto again;",
            "}",
            "static __always_inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)",
            "{",
            "\tunsigned long commits;",
            "",
            "\tif (RB_WARN_ON(cpu_buffer,",
            "\t\t       !local_read(&cpu_buffer->committing)))",
            "\t\treturn;",
            "",
            " again:",
            "\tcommits = local_read(&cpu_buffer->commits);",
            "\t/* synchronize with interrupts */",
            "\tbarrier();",
            "\tif (local_read(&cpu_buffer->committing) == 1)",
            "\t\trb_set_commit_to_write(cpu_buffer);",
            "",
            "\tlocal_dec(&cpu_buffer->committing);",
            "",
            "\t/* synchronize with interrupts */",
            "\tbarrier();",
            "",
            "\t/*",
            "\t * Need to account for interrupts coming in between the",
            "\t * updating of the commit page and the clearing of the",
            "\t * committing counter.",
            "\t */",
            "\tif (unlikely(local_read(&cpu_buffer->commits) != commits) &&",
            "\t    !local_read(&cpu_buffer->committing)) {",
            "\t\tlocal_inc(&cpu_buffer->committing);",
            "\t\tgoto again;",
            "\t}",
            "}",
            "static inline void rb_event_discard(struct ring_buffer_event *event)",
            "{",
            "\tif (extended_time(event))",
            "\t\tevent = skip_time_extend(event);",
            "",
            "\t/* array[0] holds the actual length for the discarded event */",
            "\tevent->array[0] = rb_event_data_length(event) - RB_EVNT_HDR_SIZE;",
            "\tevent->type_len = RINGBUF_TYPE_PADDING;",
            "\t/* time delta must be non zero */",
            "\tif (!event->time_delta)",
            "\t\tevent->time_delta = 1;",
            "}"
          ],
          "function_name": "rb_start_commit, rb_set_commit_to_write, rb_end_commit, rb_event_discard",
          "description": "管理事件提交流程，通过原子操作同步提交指针与事件数据，处理多中断场景下的提交冲突，标记被丢弃事件为填充数据，确保提交过程的线程安全性和数据完整性。",
          "similarity": 0.46827244758605957
        },
        {
          "chunk_id": 21,
          "file_path": "kernel/trace/ring_buffer.c",
          "start_line": 4511,
          "end_line": 4617,
          "content": [
            "static void",
            "rb_update_iter_read_stamp(struct ring_buffer_iter *iter,",
            "\t\t\t  struct ring_buffer_event *event)",
            "{",
            "\tu64 delta;",
            "",
            "\tswitch (event->type_len) {",
            "\tcase RINGBUF_TYPE_PADDING:",
            "\t\treturn;",
            "",
            "\tcase RINGBUF_TYPE_TIME_EXTEND:",
            "\t\tdelta = rb_event_time_stamp(event);",
            "\t\titer->read_stamp += delta;",
            "\t\treturn;",
            "",
            "\tcase RINGBUF_TYPE_TIME_STAMP:",
            "\t\tdelta = rb_event_time_stamp(event);",
            "\t\tdelta = rb_fix_abs_ts(delta, iter->read_stamp);",
            "\t\titer->read_stamp = delta;",
            "\t\treturn;",
            "",
            "\tcase RINGBUF_TYPE_DATA:",
            "\t\titer->read_stamp += event->time_delta;",
            "\t\treturn;",
            "",
            "\tdefault:",
            "\t\tRB_WARN_ON(iter->cpu_buffer, 1);",
            "\t}",
            "}",
            "static void rb_advance_reader(struct ring_buffer_per_cpu *cpu_buffer)",
            "{",
            "\tstruct ring_buffer_event *event;",
            "\tstruct buffer_page *reader;",
            "\tunsigned length;",
            "",
            "\treader = rb_get_reader_page(cpu_buffer);",
            "",
            "\t/* This function should not be called when buffer is empty */",
            "\tif (RB_WARN_ON(cpu_buffer, !reader))",
            "\t\treturn;",
            "",
            "\tevent = rb_reader_event(cpu_buffer);",
            "",
            "\tif (event->type_len <= RINGBUF_TYPE_DATA_TYPE_LEN_MAX)",
            "\t\tcpu_buffer->read++;",
            "",
            "\trb_update_read_stamp(cpu_buffer, event);",
            "",
            "\tlength = rb_event_length(event);",
            "\tcpu_buffer->reader_page->read += length;",
            "\tcpu_buffer->read_bytes += length;",
            "}",
            "static void rb_advance_iter(struct ring_buffer_iter *iter)",
            "{",
            "\tstruct ring_buffer_per_cpu *cpu_buffer;",
            "",
            "\tcpu_buffer = iter->cpu_buffer;",
            "",
            "\t/* If head == next_event then we need to jump to the next event */",
            "\tif (iter->head == iter->next_event) {",
            "\t\t/* If the event gets overwritten again, there's nothing to do */",
            "\t\tif (rb_iter_head_event(iter) == NULL)",
            "\t\t\treturn;",
            "\t}",
            "",
            "\titer->head = iter->next_event;",
            "",
            "\t/*",
            "\t * Check if we are at the end of the buffer.",
            "\t */",
            "\tif (iter->next_event >= rb_page_size(iter->head_page)) {",
            "\t\t/* discarded commits can make the page empty */",
            "\t\tif (iter->head_page == cpu_buffer->commit_page)",
            "\t\t\treturn;",
            "\t\trb_inc_iter(iter);",
            "\t\treturn;",
            "\t}",
            "",
            "\trb_update_iter_read_stamp(iter, iter->event);",
            "}",
            "static int rb_lost_events(struct ring_buffer_per_cpu *cpu_buffer)",
            "{",
            "\treturn cpu_buffer->lost_events;",
            "}",
            "static inline bool rb_reader_lock(struct ring_buffer_per_cpu *cpu_buffer)",
            "{",
            "\tif (likely(!in_nmi())) {",
            "\t\traw_spin_lock(&cpu_buffer->reader_lock);",
            "\t\treturn true;",
            "\t}",
            "",
            "\t/*",
            "\t * If an NMI die dumps out the content of the ring buffer",
            "\t * trylock must be used to prevent a deadlock if the NMI",
            "\t * preempted a task that holds the ring buffer locks. If",
            "\t * we get the lock then all is fine, if not, then continue",
            "\t * to do the read, but this can corrupt the ring buffer,",
            "\t * so it must be permanently disabled from future writes.",
            "\t * Reading from NMI is a oneshot deal.",
            "\t */",
            "\tif (raw_spin_trylock(&cpu_buffer->reader_lock))",
            "\t\treturn true;",
            "",
            "\t/* Continue without locking, but disable the ring buffer */",
            "\tatomic_inc(&cpu_buffer->record_disabled);",
            "\treturn false;",
            "}"
          ],
          "function_name": "rb_update_iter_read_stamp, rb_advance_reader, rb_advance_iter, rb_lost_events, rb_reader_lock",
          "description": "该代码段实现了环形缓冲区（ring buffer）的读取逻辑，包含事件时间戳更新、读指针推进、迭代器状态管理和锁控制等功能。  \n`rb_update_iter_read_stamp` 根据事件类型动态调整迭代器的读取时间戳，确保时间序列一致性；`rb_advance_reader` 和 `rb_advance_iter` 共同推进读取位置并维护事件追踪状态。  \n`rb_lost_events` 提供丢失事件计数接口，`rb_reader_lock` 在 NMI 场景下通过尝试加锁避免死锁，保障多线程环境下的数据安全。",
          "similarity": 0.4658959209918976
        }
      ]
    },
    {
      "source_file": "kernel/events/ring_buffer.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:25:08\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `events\\ring_buffer.c`\n\n---\n\n# `events/ring_buffer.c` 技术文档\n\n## 1. 文件概述\n\n`events/ring_buffer.c` 是 Linux 内核性能事件（perf events）子系统中用于实现高性能、无锁环形缓冲区（ring buffer）的核心文件。该文件提供了在内核态向用户态高效传递性能采样数据的机制，支持前向（forward）和后向（backward）两种写入模式，并确保在中断（IRQ）和不可屏蔽中断（NMI）上下文中安全使用。其设计重点在于高并发场景下的数据一致性、内存屏障语义以及与用户空间 mmap 映射的协同工作。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `perf_output_wakeup(struct perf_output_handle *handle)`  \n  触发事件唤醒机制，设置 poll 状态并调度 IRQ work 以通知用户空间有新数据可读。\n\n- `perf_output_get_handle(struct perf_output_handle *handle)`  \n  获取输出句柄，增加嵌套计数（`nest`），用于支持嵌套写入（如 NMI 中再次写入）。\n\n- `perf_output_put_handle(struct perf_output_handle *handle)`  \n  释放输出句柄，仅在最外层嵌套结束时更新用户页中的 `data_head`，并根据需要触发唤醒。\n\n- `__perf_output_begin(..., bool backward)`  \n  通用的输出开始函数，尝试为指定大小的数据在环形缓冲区中预留空间，支持前向/后向写入模式。\n\n- `perf_output_begin_forward(...)` / `perf_output_begin_backward(...)` / `perf_output_begin(...)`  \n  封装函数，分别用于前向写入、后向写入和根据事件属性自动选择方向的写入初始化。\n\n- `perf_output_copy(...)` / `perf_output_skip(...)`  \n  分别用于将数据拷贝到缓冲区或跳过指定字节数（预留空间）。\n\n- `perf_output_end(...)`  \n  结束一次输出操作，调用 `perf_output_put_handle` 并释放 RCU 锁。\n\n- `ring_buffer_init(...)`（未完整展示）  \n  初始化 `perf_buffer` 结构体，设置水位线等参数。\n\n### 关键数据结构（隐含）\n\n- `struct perf_buffer`：环形缓冲区的内核表示，包含 `head`、`tail`、`nest`、`lost`、`user_page` 等字段。\n- `struct perf_output_handle`：一次输出操作的上下文句柄，包含缓冲区页、地址、大小等信息。\n- `struct perf_event`：性能事件对象，关联其输出缓冲区。\n\n## 3. 关键实现\n\n### 嵌套写入与 NMI 安全性\n- 使用 `rb->nest` 计数器跟踪嵌套层数（如普通上下文写入过程中被 NMI 中断并再次写入）。\n- 仅当 `nest == 1`（最外层）退出时才更新用户可见的 `data_head`，防止中间状态暴露给用户空间。\n- 通过 `barrier()` 和 `volatile` 访问确保嵌套计数与 head 更新的顺序性。\n\n### 内存屏障与用户空间同步\n- 采用经典的 **生产者-消费者内存模型**：\n  - 内核（生产者）：先写数据，`smp_wmb()`，再更新 `data_head`。\n  - 用户空间（消费者）：先读 `data_head`，`smp_rmb()`，再读数据，最后写 `data_tail`。\n- 代码注释中明确标出屏障配对关系（A-D），确保跨 CPU 的数据一致性。\n\n### 环形缓冲区空间管理\n- 使用 `CIRC_SPACE` 宏计算可用空间，区分前向（`head >= tail`）和后向（`tail >= head`）模式。\n- 非覆盖模式（`!overwrite`）下，若空间不足则返回 `-ENOSPC` 并增加 `lost` 计数。\n- 使用 `local_try_cmpxchg` 原子地推进 `rb->head`，避免锁竞争。\n\n### 丢失事件处理\n- 若检测到 `rb->lost > 0`，自动在用户数据前插入 `PERF_RECORD_LOST` 记录，报告丢失样本数。\n- 通过 `perf_event_header__init_id` 和 `perf_event__output_id_sample` 确保 ID 信息正确。\n\n### 水位线与唤醒机制\n- 当 `head - wakeup > watermark` 时，推进 `wakeup` 指针并触发 `perf_output_wakeup`。\n- 唤醒通过设置 `poll` 事件位和调度 `irq_work` 实现，避免在原子上下文中直接唤醒。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/perf_event.h>`：perf 事件核心定义。\n  - `<linux/circ_buf.h>`：提供 `CIRC_SPACE` 等环形缓冲区宏。\n  - `<linux/nospec.h>`：防范推测执行漏洞。\n  - `\"internal.h\"`：perf 子系统内部头文件，包含 `__output_copy` 等辅助函数。\n- **内核子系统**：\n  - RCU（Read-Copy-Update）：用于安全访问 `event->rb`。\n  - IRQ Work：用于延迟执行唤醒操作。\n  - Slab/Vmalloc：用于分配缓冲区内存（虽未在片段中体现，但 `perf_buffer` 初始化时使用）。\n- **用户空间接口**：通过 `mmap()` 映射 `user_page` 和数据页，依赖约定的内存屏障语义。\n\n## 5. 使用场景\n\n- **性能监控工具**：如 `perf record`、`perf stat` 等通过此机制接收内核采样数据。\n- **动态追踪**：eBPF 程序或 kprobe 事件通过 perf ring buffer 向用户空间传递追踪信息。\n- **硬件性能计数器溢出处理**：当 PMU 计数器溢出时，中断处理程序使用此接口记录样本。\n- **NMI 上下文采样**：支持在不可屏蔽中断中安全写入（如 NMI watchdog 触发的栈回溯）。\n- **前向/后向缓冲区**：前向用于常规流式输出；后向用于“最后 N 个事件”场景（如崩溃前状态捕获）。",
      "similarity": 0.5101224184036255,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 542,
          "end_line": 727,
          "content": [
            "int perf_aux_output_skip(struct perf_output_handle *handle, unsigned long size)",
            "{",
            "\tstruct perf_buffer *rb = handle->rb;",
            "",
            "\tif (size > handle->size)",
            "\t\treturn -ENOSPC;",
            "",
            "\trb->aux_head += size;",
            "",
            "\tWRITE_ONCE(rb->user_page->aux_head, rb->aux_head);",
            "\tif (rb_need_aux_wakeup(rb)) {",
            "\t\tperf_output_wakeup(handle);",
            "\t\thandle->wakeup = rb->aux_wakeup + rb->aux_watermark;",
            "\t}",
            "",
            "\thandle->head = rb->aux_head;",
            "\thandle->size -= size;",
            "",
            "\treturn 0;",
            "}",
            "long perf_output_copy_aux(struct perf_output_handle *aux_handle,",
            "\t\t\t  struct perf_output_handle *handle,",
            "\t\t\t  unsigned long from, unsigned long to)",
            "{",
            "\tstruct perf_buffer *rb = aux_handle->rb;",
            "\tunsigned long tocopy, remainder, len = 0;",
            "\tvoid *addr;",
            "",
            "\tfrom &= (rb->aux_nr_pages << PAGE_SHIFT) - 1;",
            "\tto &= (rb->aux_nr_pages << PAGE_SHIFT) - 1;",
            "",
            "\tdo {",
            "\t\ttocopy = PAGE_SIZE - offset_in_page(from);",
            "\t\tif (to > from)",
            "\t\t\ttocopy = min(tocopy, to - from);",
            "\t\tif (!tocopy)",
            "\t\t\tbreak;",
            "",
            "\t\taddr = rb->aux_pages[from >> PAGE_SHIFT];",
            "\t\taddr += offset_in_page(from);",
            "",
            "\t\tremainder = perf_output_copy(handle, addr, tocopy);",
            "\t\tif (remainder)",
            "\t\t\treturn -EFAULT;",
            "",
            "\t\tlen += tocopy;",
            "\t\tfrom += tocopy;",
            "\t\tfrom &= (rb->aux_nr_pages << PAGE_SHIFT) - 1;",
            "\t} while (to != from);",
            "",
            "\treturn len;",
            "}",
            "static void rb_free_aux_page(struct perf_buffer *rb, int idx)",
            "{",
            "\tstruct page *page = virt_to_page(rb->aux_pages[idx]);",
            "",
            "\tClearPagePrivate(page);",
            "\tpage->mapping = NULL;",
            "\t__free_page(page);",
            "}",
            "static void __rb_free_aux(struct perf_buffer *rb)",
            "{",
            "\tint pg;",
            "",
            "\t/*",
            "\t * Should never happen, the last reference should be dropped from",
            "\t * perf_mmap_close() path, which first stops aux transactions (which",
            "\t * in turn are the atomic holders of aux_refcount) and then does the",
            "\t * last rb_free_aux().",
            "\t */",
            "\tWARN_ON_ONCE(in_atomic());",
            "",
            "\tif (rb->aux_priv) {",
            "\t\trb->free_aux(rb->aux_priv);",
            "\t\trb->free_aux = NULL;",
            "\t\trb->aux_priv = NULL;",
            "\t}",
            "",
            "\tif (rb->aux_nr_pages) {",
            "\t\tfor (pg = 0; pg < rb->aux_nr_pages; pg++)",
            "\t\t\trb_free_aux_page(rb, pg);",
            "",
            "\t\tkfree(rb->aux_pages);",
            "\t\trb->aux_nr_pages = 0;",
            "\t}",
            "}",
            "int rb_alloc_aux(struct perf_buffer *rb, struct perf_event *event,",
            "\t\t pgoff_t pgoff, int nr_pages, long watermark, int flags)",
            "{",
            "\tbool overwrite = !(flags & RING_BUFFER_WRITABLE);",
            "\tint node = (event->cpu == -1) ? -1 : cpu_to_node(event->cpu);",
            "\tint ret = -ENOMEM, max_order;",
            "",
            "\tif (!has_aux(event))",
            "\t\treturn -EOPNOTSUPP;",
            "",
            "\tif (!overwrite) {",
            "\t\t/*",
            "\t\t * Watermark defaults to half the buffer, and so does the",
            "\t\t * max_order, to aid PMU drivers in double buffering.",
            "\t\t */",
            "\t\tif (!watermark)",
            "\t\t\twatermark = min_t(unsigned long,",
            "\t\t\t\t\t  U32_MAX,",
            "\t\t\t\t\t  (unsigned long)nr_pages << (PAGE_SHIFT - 1));",
            "",
            "\t\t/*",
            "\t\t * Use aux_watermark as the basis for chunking to",
            "\t\t * help PMU drivers honor the watermark.",
            "\t\t */",
            "\t\tmax_order = get_order(watermark);",
            "\t} else {",
            "\t\t/*",
            "\t\t * We need to start with the max_order that fits in nr_pages,",
            "\t\t * not the other way around, hence ilog2() and not get_order.",
            "\t\t */",
            "\t\tmax_order = ilog2(nr_pages);",
            "\t\twatermark = 0;",
            "\t}",
            "",
            "\t/*",
            "\t * kcalloc_node() is unable to allocate buffer if the size is larger",
            "\t * than: PAGE_SIZE << MAX_PAGE_ORDER; directly bail out in this case.",
            "\t */",
            "\tif (get_order((unsigned long)nr_pages * sizeof(void *)) > MAX_PAGE_ORDER)",
            "\t\treturn -ENOMEM;",
            "\trb->aux_pages = kcalloc_node(nr_pages, sizeof(void *), GFP_KERNEL,",
            "\t\t\t\t     node);",
            "\tif (!rb->aux_pages)",
            "\t\treturn -ENOMEM;",
            "",
            "\trb->free_aux = event->pmu->free_aux;",
            "\tfor (rb->aux_nr_pages = 0; rb->aux_nr_pages < nr_pages;) {",
            "\t\tstruct page *page;",
            "\t\tint last, order;",
            "",
            "\t\torder = min(max_order, ilog2(nr_pages - rb->aux_nr_pages));",
            "\t\tpage = rb_alloc_aux_page(node, order);",
            "\t\tif (!page)",
            "\t\t\tgoto out;",
            "",
            "\t\tfor (last = rb->aux_nr_pages + (1 << page_private(page));",
            "\t\t     last > rb->aux_nr_pages; rb->aux_nr_pages++)",
            "\t\t\trb->aux_pages[rb->aux_nr_pages] = page_address(page++);",
            "\t}",
            "",
            "\t/*",
            "\t * In overwrite mode, PMUs that don't support SG may not handle more",
            "\t * than one contiguous allocation, since they rely on PMI to do double",
            "\t * buffering. In this case, the entire buffer has to be one contiguous",
            "\t * chunk.",
            "\t */",
            "\tif ((event->pmu->capabilities & PERF_PMU_CAP_AUX_NO_SG) &&",
            "\t    overwrite) {",
            "\t\tstruct page *page = virt_to_page(rb->aux_pages[0]);",
            "",
            "\t\tif (page_private(page) != max_order)",
            "\t\t\tgoto out;",
            "\t}",
            "",
            "\trb->aux_priv = event->pmu->setup_aux(event, rb->aux_pages, nr_pages,",
            "\t\t\t\t\t     overwrite);",
            "\tif (!rb->aux_priv)",
            "\t\tgoto out;",
            "",
            "\tret = 0;",
            "",
            "\t/*",
            "\t * aux_pages (and pmu driver's private data, aux_priv) will be",
            "\t * referenced in both producer's and consumer's contexts, thus",
            "\t * we keep a refcount here to make sure either of the two can",
            "\t * reference them safely.",
            "\t */",
            "\trefcount_set(&rb->aux_refcount, 1);",
            "",
            "\trb->aux_overwrite = overwrite;",
            "\trb->aux_watermark = watermark;",
            "",
            "out:",
            "\tif (!ret)",
            "\t\trb->aux_pgoff = pgoff;",
            "\telse",
            "\t\t__rb_free_aux(rb);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "perf_aux_output_skip, perf_output_copy_aux, rb_free_aux_page, __rb_free_aux, rb_alloc_aux",
          "description": "实现辅助数据通道的管理函数，包含数据跳过、页框回收及辅助内存分配逻辑，处理非覆盖模式下的数据迁移和资源释放操作。",
          "similarity": 0.5256375074386597
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 1,
          "end_line": 19,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Performance events ring-buffer code:",
            " *",
            " *  Copyright (C) 2008 Thomas Gleixner <tglx@linutronix.de>",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Ingo Molnar",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Peter Zijlstra",
            " *  Copyright  ©  2009 Paul Mackerras, IBM Corp. <paulus@au1.ibm.com>",
            " */",
            "",
            "#include <linux/perf_event.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/circ_buf.h>",
            "#include <linux/poll.h>",
            "#include <linux/nospec.h>",
            "",
            "#include \"internal.h\"",
            ""
          ],
          "function_name": null,
          "description": "该代码块为性能事件环形缓冲区的头文件，包含许可证声明和核心依赖头文件，定义了环形缓冲区模块的基础结构和接口。",
          "similarity": 0.4869273900985718
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 269,
          "end_line": 408,
          "content": [
            "int perf_output_begin_forward(struct perf_output_handle *handle,",
            "\t\t\t      struct perf_sample_data *data,",
            "\t\t\t      struct perf_event *event, unsigned int size)",
            "{",
            "\treturn __perf_output_begin(handle, data, event, size, false);",
            "}",
            "int perf_output_begin_backward(struct perf_output_handle *handle,",
            "\t\t\t       struct perf_sample_data *data,",
            "\t\t\t       struct perf_event *event, unsigned int size)",
            "{",
            "\treturn __perf_output_begin(handle, data, event, size, true);",
            "}",
            "int perf_output_begin(struct perf_output_handle *handle,",
            "\t\t      struct perf_sample_data *data,",
            "\t\t      struct perf_event *event, unsigned int size)",
            "{",
            "",
            "\treturn __perf_output_begin(handle, data, event, size,",
            "\t\t\t\t   unlikely(is_write_backward(event)));",
            "}",
            "unsigned int perf_output_copy(struct perf_output_handle *handle,",
            "\t\t      const void *buf, unsigned int len)",
            "{",
            "\treturn __output_copy(handle, buf, len);",
            "}",
            "unsigned int perf_output_skip(struct perf_output_handle *handle,",
            "\t\t\t      unsigned int len)",
            "{",
            "\treturn __output_skip(handle, NULL, len);",
            "}",
            "void perf_output_end(struct perf_output_handle *handle)",
            "{",
            "\tperf_output_put_handle(handle);",
            "\trcu_read_unlock();",
            "}",
            "static void",
            "ring_buffer_init(struct perf_buffer *rb, long watermark, int flags)",
            "{",
            "\tlong max_size = perf_data_size(rb);",
            "",
            "\tif (watermark)",
            "\t\trb->watermark = min(max_size, watermark);",
            "",
            "\tif (!rb->watermark)",
            "\t\trb->watermark = max_size / 2;",
            "",
            "\tif (flags & RING_BUFFER_WRITABLE)",
            "\t\trb->overwrite = 0;",
            "\telse",
            "\t\trb->overwrite = 1;",
            "",
            "\trefcount_set(&rb->refcount, 1);",
            "",
            "\tINIT_LIST_HEAD(&rb->event_list);",
            "\tspin_lock_init(&rb->event_lock);",
            "",
            "\t/*",
            "\t * perf_output_begin() only checks rb->paused, therefore",
            "\t * rb->paused must be true if we have no pages for output.",
            "\t */",
            "\tif (!rb->nr_pages)",
            "\t\trb->paused = 1;",
            "",
            "\tmutex_init(&rb->aux_mutex);",
            "}",
            "void perf_aux_output_flag(struct perf_output_handle *handle, u64 flags)",
            "{",
            "\t/*",
            "\t * OVERWRITE is determined by perf_aux_output_end() and can't",
            "\t * be passed in directly.",
            "\t */",
            "\tif (WARN_ON_ONCE(flags & PERF_AUX_FLAG_OVERWRITE))",
            "\t\treturn;",
            "",
            "\thandle->aux_flags |= flags;",
            "}",
            "static __always_inline bool rb_need_aux_wakeup(struct perf_buffer *rb)",
            "{",
            "\tif (rb->aux_overwrite)",
            "\t\treturn false;",
            "",
            "\tif (rb->aux_head - rb->aux_wakeup >= rb->aux_watermark) {",
            "\t\trb->aux_wakeup = rounddown(rb->aux_head, rb->aux_watermark);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "void perf_aux_output_end(struct perf_output_handle *handle, unsigned long size)",
            "{",
            "\tbool wakeup = !!(handle->aux_flags & PERF_AUX_FLAG_TRUNCATED);",
            "\tstruct perf_buffer *rb = handle->rb;",
            "\tunsigned long aux_head;",
            "",
            "\t/* in overwrite mode, driver provides aux_head via handle */",
            "\tif (rb->aux_overwrite) {",
            "\t\thandle->aux_flags |= PERF_AUX_FLAG_OVERWRITE;",
            "",
            "\t\taux_head = handle->head;",
            "\t\trb->aux_head = aux_head;",
            "\t} else {",
            "\t\thandle->aux_flags &= ~PERF_AUX_FLAG_OVERWRITE;",
            "",
            "\t\taux_head = rb->aux_head;",
            "\t\trb->aux_head += size;",
            "\t}",
            "",
            "\t/*",
            "\t * Only send RECORD_AUX if we have something useful to communicate",
            "\t *",
            "\t * Note: the OVERWRITE records by themselves are not considered",
            "\t * useful, as they don't communicate any *new* information,",
            "\t * aside from the short-lived offset, that becomes history at",
            "\t * the next event sched-in and therefore isn't useful.",
            "\t * The userspace that needs to copy out AUX data in overwrite",
            "\t * mode should know to use user_page::aux_head for the actual",
            "\t * offset. So, from now on we don't output AUX records that",
            "\t * have *only* OVERWRITE flag set.",
            "\t */",
            "\tif (size || (handle->aux_flags & ~(u64)PERF_AUX_FLAG_OVERWRITE))",
            "\t\tperf_event_aux_event(handle->event, aux_head, size,",
            "\t\t\t\t     handle->aux_flags);",
            "",
            "\tWRITE_ONCE(rb->user_page->aux_head, rb->aux_head);",
            "\tif (rb_need_aux_wakeup(rb))",
            "\t\twakeup = true;",
            "",
            "\tif (wakeup) {",
            "\t\tif (handle->aux_flags & PERF_AUX_FLAG_TRUNCATED)",
            "\t\t\tperf_event_disable_inatomic(handle->event);",
            "\t\tperf_output_wakeup(handle);",
            "\t}",
            "",
            "\thandle->event = NULL;",
            "",
            "\tWRITE_ONCE(rb->aux_nest, 0);",
            "\t/* can't be last */",
            "\trb_free_aux(rb);",
            "\tring_buffer_put(rb);",
            "}"
          ],
          "function_name": "perf_output_begin_forward, perf_output_begin_backward, perf_output_begin, perf_output_copy, perf_output_skip, perf_output_end, ring_buffer_init, perf_aux_output_flag, rb_need_aux_wakeup, perf_aux_output_end",
          "description": "封装数据写入接口并实现缓冲区初始化逻辑，管理覆盖模式切换、水位线监控及辅助输出标志位，支持双向写入模式选择和资源引用计数控制。",
          "similarity": 0.4855401813983917
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 20,
          "end_line": 125,
          "content": [
            "static void perf_output_wakeup(struct perf_output_handle *handle)",
            "{",
            "\tatomic_set(&handle->rb->poll, EPOLLIN | EPOLLRDNORM);",
            "",
            "\thandle->event->pending_wakeup = 1;",
            "\tirq_work_queue(&handle->event->pending_irq);",
            "}",
            "static void perf_output_get_handle(struct perf_output_handle *handle)",
            "{",
            "\tstruct perf_buffer *rb = handle->rb;",
            "",
            "\tpreempt_disable();",
            "",
            "\t/*",
            "\t * Avoid an explicit LOAD/STORE such that architectures with memops",
            "\t * can use them.",
            "\t */",
            "\t(*(volatile unsigned int *)&rb->nest)++;",
            "\thandle->wakeup = local_read(&rb->wakeup);",
            "}",
            "static void perf_output_put_handle(struct perf_output_handle *handle)",
            "{",
            "\tstruct perf_buffer *rb = handle->rb;",
            "\tunsigned long head;",
            "\tunsigned int nest;",
            "",
            "\t/*",
            "\t * If this isn't the outermost nesting, we don't have to update",
            "\t * @rb->user_page->data_head.",
            "\t */",
            "\tnest = READ_ONCE(rb->nest);",
            "\tif (nest > 1) {",
            "\t\tWRITE_ONCE(rb->nest, nest - 1);",
            "\t\tgoto out;",
            "\t}",
            "",
            "again:",
            "\t/*",
            "\t * In order to avoid publishing a head value that goes backwards,",
            "\t * we must ensure the load of @rb->head happens after we've",
            "\t * incremented @rb->nest.",
            "\t *",
            "\t * Otherwise we can observe a @rb->head value before one published",
            "\t * by an IRQ/NMI happening between the load and the increment.",
            "\t */",
            "\tbarrier();",
            "\thead = local_read(&rb->head);",
            "",
            "\t/*",
            "\t * IRQ/NMI can happen here and advance @rb->head, causing our",
            "\t * load above to be stale.",
            "\t */",
            "",
            "\t/*",
            "\t * Since the mmap() consumer (userspace) can run on a different CPU:",
            "\t *",
            "\t *   kernel\t\t\t\tuser",
            "\t *",
            "\t *   if (LOAD ->data_tail) {\t\tLOAD ->data_head",
            "\t *\t\t\t(A)\t\tsmp_rmb()\t(C)",
            "\t *\tSTORE $data\t\t\tLOAD $data",
            "\t *\tsmp_wmb()\t(B)\t\tsmp_mb()\t(D)",
            "\t *\tSTORE ->data_head\t\tSTORE ->data_tail",
            "\t *   }",
            "\t *",
            "\t * Where A pairs with D, and B pairs with C.",
            "\t *",
            "\t * In our case (A) is a control dependency that separates the load of",
            "\t * the ->data_tail and the stores of $data. In case ->data_tail",
            "\t * indicates there is no room in the buffer to store $data we do not.",
            "\t *",
            "\t * D needs to be a full barrier since it separates the data READ",
            "\t * from the tail WRITE.",
            "\t *",
            "\t * For B a WMB is sufficient since it separates two WRITEs, and for C",
            "\t * an RMB is sufficient since it separates two READs.",
            "\t *",
            "\t * See perf_output_begin().",
            "\t */",
            "\tsmp_wmb(); /* B, matches C */",
            "\tWRITE_ONCE(rb->user_page->data_head, head);",
            "",
            "\t/*",
            "\t * We must publish the head before decrementing the nest count,",
            "\t * otherwise an IRQ/NMI can publish a more recent head value and our",
            "\t * write will (temporarily) publish a stale value.",
            "\t */",
            "\tbarrier();",
            "\tWRITE_ONCE(rb->nest, 0);",
            "",
            "\t/*",
            "\t * Ensure we decrement @rb->nest before we validate the @rb->head.",
            "\t * Otherwise we cannot be sure we caught the 'last' nested update.",
            "\t */",
            "\tbarrier();",
            "\tif (unlikely(head != local_read(&rb->head))) {",
            "\t\tWRITE_ONCE(rb->nest, 1);",
            "\t\tgoto again;",
            "\t}",
            "",
            "\tif (handle->wakeup != local_read(&rb->wakeup))",
            "\t\tperf_output_wakeup(handle);",
            "",
            "out:",
            "\tpreempt_enable();",
            "}"
          ],
          "function_name": "perf_output_wakeup, perf_output_get_handle, perf_output_put_handle",
          "description": "实现环形缓冲区的唤醒机制和嵌套计数管理，通过原子操作和内存屏障保证多线程下的数据一致性，维护缓冲区状态转换过程中的竞态防护。",
          "similarity": 0.47664013504981995
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 137,
          "end_line": 266,
          "content": [
            "static __always_inline bool",
            "ring_buffer_has_space(unsigned long head, unsigned long tail,",
            "\t\t      unsigned long data_size, unsigned int size,",
            "\t\t      bool backward)",
            "{",
            "\tif (!backward)",
            "\t\treturn CIRC_SPACE(head, tail, data_size) >= size;",
            "\telse",
            "\t\treturn CIRC_SPACE(tail, head, data_size) >= size;",
            "}",
            "static __always_inline int",
            "__perf_output_begin(struct perf_output_handle *handle,",
            "\t\t    struct perf_sample_data *data,",
            "\t\t    struct perf_event *event, unsigned int size,",
            "\t\t    bool backward)",
            "{",
            "\tstruct perf_buffer *rb;",
            "\tunsigned long tail, offset, head;",
            "\tint have_lost, page_shift;",
            "\tstruct {",
            "\t\tstruct perf_event_header header;",
            "\t\tu64\t\t\t id;",
            "\t\tu64\t\t\t lost;",
            "\t} lost_event;",
            "",
            "\trcu_read_lock();",
            "\t/*",
            "\t * For inherited events we send all the output towards the parent.",
            "\t */",
            "\tif (event->parent)",
            "\t\tevent = event->parent;",
            "",
            "\trb = rcu_dereference(event->rb);",
            "\tif (unlikely(!rb))",
            "\t\tgoto out;",
            "",
            "\tif (unlikely(rb->paused)) {",
            "\t\tif (rb->nr_pages) {",
            "\t\t\tlocal_inc(&rb->lost);",
            "\t\t\tatomic64_inc(&event->lost_samples);",
            "\t\t}",
            "\t\tgoto out;",
            "\t}",
            "",
            "\thandle->rb    = rb;",
            "\thandle->event = event;",
            "\thandle->flags = 0;",
            "",
            "\thave_lost = local_read(&rb->lost);",
            "\tif (unlikely(have_lost)) {",
            "\t\tsize += sizeof(lost_event);",
            "\t\tif (event->attr.sample_id_all)",
            "\t\t\tsize += event->id_header_size;",
            "\t}",
            "",
            "\tperf_output_get_handle(handle);",
            "",
            "\toffset = local_read(&rb->head);",
            "\tdo {",
            "\t\thead = offset;",
            "\t\ttail = READ_ONCE(rb->user_page->data_tail);",
            "\t\tif (!rb->overwrite) {",
            "\t\t\tif (unlikely(!ring_buffer_has_space(head, tail,",
            "\t\t\t\t\t\t\t    perf_data_size(rb),",
            "\t\t\t\t\t\t\t    size, backward)))",
            "\t\t\t\tgoto fail;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * The above forms a control dependency barrier separating the",
            "\t\t * @tail load above from the data stores below. Since the @tail",
            "\t\t * load is required to compute the branch to fail below.",
            "\t\t *",
            "\t\t * A, matches D; the full memory barrier userspace SHOULD issue",
            "\t\t * after reading the data and before storing the new tail",
            "\t\t * position.",
            "\t\t *",
            "\t\t * See perf_output_put_handle().",
            "\t\t */",
            "",
            "\t\tif (!backward)",
            "\t\t\thead += size;",
            "\t\telse",
            "\t\t\thead -= size;",
            "\t} while (!local_try_cmpxchg(&rb->head, &offset, head));",
            "",
            "\tif (backward) {",
            "\t\toffset = head;",
            "\t\thead = (u64)(-head);",
            "\t}",
            "",
            "\t/*",
            "\t * We rely on the implied barrier() by local_cmpxchg() to ensure",
            "\t * none of the data stores below can be lifted up by the compiler.",
            "\t */",
            "",
            "\tif (unlikely(head - local_read(&rb->wakeup) > rb->watermark))",
            "\t\tlocal_add(rb->watermark, &rb->wakeup);",
            "",
            "\tpage_shift = PAGE_SHIFT + page_order(rb);",
            "",
            "\thandle->page = (offset >> page_shift) & (rb->nr_pages - 1);",
            "\toffset &= (1UL << page_shift) - 1;",
            "\thandle->addr = rb->data_pages[handle->page] + offset;",
            "\thandle->size = (1UL << page_shift) - offset;",
            "",
            "\tif (unlikely(have_lost)) {",
            "\t\tlost_event.header.size = sizeof(lost_event);",
            "\t\tlost_event.header.type = PERF_RECORD_LOST;",
            "\t\tlost_event.header.misc = 0;",
            "\t\tlost_event.id          = event->id;",
            "\t\tlost_event.lost        = local_xchg(&rb->lost, 0);",
            "",
            "\t\t/* XXX mostly redundant; @data is already fully initializes */",
            "\t\tperf_event_header__init_id(&lost_event.header, data, event);",
            "\t\tperf_output_put(handle, lost_event);",
            "\t\tperf_event__output_id_sample(event, handle, data);",
            "\t}",
            "",
            "\treturn 0;",
            "",
            "fail:",
            "\tlocal_inc(&rb->lost);",
            "\tatomic64_inc(&event->lost_samples);",
            "\tperf_output_put_handle(handle);",
            "out:",
            "\trcu_read_unlock();",
            "",
            "\treturn -ENOSPC;",
            "}"
          ],
          "function_name": "ring_buffer_has_space, __perf_output_begin",
          "description": "提供空间检测算法和数据写入入口点，通过循环缓冲区计算公式判断可用容量，在成功获取写入位置后进行实际数据填充并更新缓冲区状态。",
          "similarity": 0.4449214041233063
        }
      ]
    },
    {
      "source_file": "mm/kasan/kasan.h",
      "md_summary": "> 自动生成时间: 2025-12-07 16:15:42\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kasan\\kasan.h`\n\n---\n\n# `kasan/kasan.h` 技术文档\n\n## 1. 文件概述\n\n`kasan/kasan.h` 是 Linux 内核中 **Kernel Address Sanitizer (KASAN)** 子系统的核心头文件，用于定义 KASAN 的通用接口、数据结构和配置宏。该文件为三种 KASAN 模式（Generic、Software Tagging、Hardware Tagging）提供统一的抽象层，并根据编译配置条件性地启用特定功能。其主要作用包括：\n\n- 定义 KASAN 元数据布局和内存粒度\n- 提供堆栈跟踪、采样分配、故障模式判断等运行时辅助函数\n- 声明通用报告结构体和全局变量元数据格式\n- 实现不同 KASAN 模式下的行为差异（如是否需要元数据、影子内存映射等）\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数 | 功能说明 |\n|------|--------|\n| `kasan_stack_collection_enabled()` | 判断是否启用堆栈跟踪收集（受 `kasan.stacktrace` 启动参数控制） |\n| `kasan_vmalloc_enabled()` | （仅 HW_TAGS）判断是否对 vmalloc 区域启用 KASAN |\n| `kasan_async_fault_possible()` / `kasan_sync_fault_possible()` | 判断当前 KASAN 模式是否可能触发异步/同步错误报告 |\n| `kasan_sample_page_alloc(unsigned int order)` | （仅 HW_TAGS）基于采样率决定是否对指定阶数的页面分配进行检测 |\n| `kasan_requires_meta()` | 判断当前 KASAN 模式是否需要为每个对象存储元数据 |\n| `kasan_shadow_to_mem(const void *shadow_addr)` | 将影子内存地址转换回对应的原始内存地址 |\n| `addr_has_metadata(const void *addr)` | 判断给定地址是否位于具有 KASAN 元数据覆盖的内存区域 |\n\n### 主要数据结构\n\n| 结构体 | 用途 |\n|-------|------|\n| `struct kasan_track` | 记录内存分配/释放时的 PID 和调用栈（通过 stackdepot 存储） |\n| `struct kasan_report_info` | 统一的错误报告上下文，包含访问信息、对象元数据、错误类型等 |\n| `struct kasan_source_location` | 编译器生成的全局变量源码位置信息（ABI 兼容） |\n| `struct kasan_global` | 描述全局变量的 KASAN 元数据（由编译器插桩生成） |\n| `struct kasan_alloc_meta` / `struct kasan_free_meta` | （仅 GENERIC）存储 slab 对象的分配/释放元数据 |\n| `struct kasan_stack_ring_entry` / `struct kasan_stack_ring` | （SW/HW_TAGS）用于记录近期内存操作的环形缓冲区 |\n\n### 关键宏定义\n\n| 宏 | 说明 |\n|----|------|\n| `KASAN_GRANULE_SIZE` | KASAN 检测的基本内存粒度（Generic/SW_TAGS 为 8 字节，HW_TAGS 为 MTE 粒度） |\n| `KASAN_PAGE_FREE`, `KASAN_SLAB_REDZONE` 等 | 影子内存中的特殊标记值，表示不同类型的无效/红区内存 |\n| `KASAN_STACK_*`, `KASAN_ALLOCA_*` | （仅 GENERIC）栈和 alloca 红区的影子值（编译器 ABI） |\n| `META_*` 系列宏 | 定义元数据在调试输出中的显示格式（每行块数、字节数等） |\n\n## 3. 关键实现\n\n### 多模式支持机制\n文件通过 `#ifdef CONFIG_KASAN_*` 条件编译区分三种 KASAN 模式：\n- **Generic**：使用影子内存 + 每对象元数据，支持精确错误定位\n- **SW_TAGS**：使用软件生成的 8-bit 标签，无每对象元数据\n- **HW_TAGS**：利用 ARM MTE 硬件标签，依赖 CPU 特性\n\n### 堆栈跟踪控制\n通过 `static_key` 优化性能：\n```c\nDECLARE_STATIC_KEY_TRUE(kasan_flag_stacktrace);\n```\n默认启用堆栈收集，但可通过启动参数 `kasan.stacktrace=off` 动态关闭，减少运行时开销。\n\n### 页面分配采样（HW_TAGS 特有）\n为平衡性能与覆盖率，HW_TAGS 模式引入概率采样：\n- 小于 `kasan_page_alloc_sample_order` 的分配总是检测\n- 更大分配按 `1/kasan_page_alloc_sample` 概率检测\n- 使用 per-CPU 计数器 `kasan_page_alloc_skip` 实现无锁采样\n\n### 元数据管理差异\n- **Generic 模式**：在对象前后或 quarantine 中存储 `kasan_alloc_meta`/`free_meta`\n- **Tag-based 模式**：不使用每对象元数据，改用环形缓冲区 `kasan_stack_ring` 记录近期操作\n\n### 影子内存映射\n通过 `kasan_shadow_to_mem()` 实现影子地址到原始地址的转换，公式为：\n```\n原始地址 = (影子地址 - KASAN_SHADOW_OFFSET) << KASAN_SHADOW_SCALE_SHIFT\n```\n\n## 4. 依赖关系\n\n| 依赖模块 | 用途 |\n|---------|------|\n| `<linux/kasan.h>` | KASAN 公共 API（如 `kasan_enable/disable_current()`） |\n| `<linux/kasan-tags.h>` | 标签操作辅助函数（如 `kasan_reset_tag()`） |\n| `<linux/stackdepot.h>` | 调用栈压缩存储（`depot_stack_handle_t`） |\n| `<asm/mte-kasan.h>` | （HW_TAGS）ARM MTE 架构相关定义 |\n| `<linux/slab.h>` | （HW_TAGS）slab 分配器集成 |\n| `<linux/static_key.h>` | 静态分支优化（堆栈跟踪开关） |\n| `<linux/kfence.h>` | 与 KFENCE 内存检测器协同工作 |\n\n## 5. 使用场景\n\n1. **内存错误检测**  \n   在内核内存访问（读/写）时，KASAN 运行时通过此头文件定义的接口检查影子内存状态，捕获越界、释放后使用等错误。\n\n2. **错误报告生成**  \n   当检测到非法访问时，`kasan_report_info` 结构体被填充，结合 `kasan_track` 中的堆栈信息生成详细错误报告。\n\n3. **编译器插桩支持**  \n   Clang/GCC 在编译时生成对 `__asan_load*/store*` 的调用，这些函数内部使用本文件定义的宏（如 `KASAN_GRANULE_SIZE`）和地址转换逻辑。\n\n4. **全局变量保护**  \n   编译器为全局变量生成 `kasan_global` 结构体数组，在初始化阶段通过 `kasan_register_globals()` 注册红区。\n\n5. **动态配置调整**  \n   通过 `kasan.stacktrace`、`kasan.vmalloc` 等启动参数，可在运行时调整 KASAN 行为（如关闭堆栈收集以提升性能）。\n\n6. **硬件加速集成**  \n   在 ARM64 平台上，HW_TAGS 模式利用 MTE 指令自动验证内存标签，本文件提供与硬件特性的抽象层对接。",
      "similarity": 0.5092303156852722,
      "chunks": []
    }
  ]
}