{
  "query": "容器内存限制与 dirty page 管理的关系",
  "timestamp": "2025-12-26 01:50:27",
  "retrieved_files": [
    {
      "source_file": "mm/page-writeback.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:59:09\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `page-writeback.c`\n\n---\n\n# page-writeback.c 技术文档\n\n## 1. 文件概述\n\n`page-writeback.c` 是 Linux 内核内存管理子系统（MM）中的核心文件，负责实现**脏页回写（dirty page writeback）机制**。该机制用于控制和协调将修改过的页面（即“脏页”）从内存写回到持久化存储（如磁盘）的过程，以确保数据一致性、防止内存耗尽，并在系统负载与 I/O 带宽之间取得平衡。\n\n该文件主要提供以下功能：\n- 脏页数量的全局与每 BDI（Backing Device Info）级别的阈值管理\n- 脏页生成速率的动态限流（throttling）\n- 后台回写线程（如 `writeback` 线程）的触发逻辑\n- 支持基于 cgroup 的内存回写控制（当启用 `CONFIG_CGROUP_WRITEBACK` 时）\n- 与 `/proc/sys/vm` 中可调参数的交互接口\n\n## 2. 核心功能\n\n### 主要全局变量（可通过 sysctl 调整）\n| 变量名 | 默认值 | 说明 |\n|--------|--------|------|\n| `dirty_background_ratio` | 10 | 当脏页占可用内存比例达到此值时，启动后台回写 |\n| `vm_dirty_ratio` | 20 | 脏页比例硬上限，超过则阻塞写进程进行同步回写 |\n| `dirty_background_bytes` | 0 | 以字节为单位指定后台回写阈值（优先级高于 ratio） |\n| `vm_dirty_bytes` | 0 | 以字节为单位指定脏页硬上限（优先级高于 ratio） |\n| `dirty_writeback_interval` | 500 (5秒) | 后台回写线程的唤醒间隔（单位：厘秒） |\n| `dirty_expire_interval` | 3000 (30秒) | 脏页最大存活时间，超时强制回写 |\n| `laptop_mode` | 0 | 笔记本模式开关，减少磁盘活动以省电 |\n| `ratelimit_pages` | 32 | 每 CPU 脏页速率限制阈值 |\n\n### 关键数据结构\n- **`struct wb_domain`**  \n  回写域（writeback domain），用于聚合多个 BDI 的回写状态，支持全局或 per-memcg 的回写控制。\n  \n- **`struct dirty_throttle_control` (dtc)**  \n  脏页限流控制上下文，包含：\n  - `avail`：当前可脏化的内存总量\n  - `dirty`：当前脏页数量\n  - `thresh` / `bg_thresh`：硬/软回写阈值\n  - `wb_dirty` / `wb_thresh` / `wb_bg_thresh`：per-BDI 级别的对应值\n  - `pos_ratio`：用于计算回写速率的比例因子\n\n- **条件编译支持**  \n  通过 `CONFIG_CGROUP_WRITEBACK` 区分是否支持 memcg 级别的回写控制，提供 `GDTC_INIT`、`MDTC_INIT` 等宏及辅助函数（如 `mdtc_valid()`、`wb_min_max_ratio()`）。\n\n### 核心辅助函数（部分在截断代码中未完整显示）\n- `node_dirtyable_memory()`：计算指定 NUMA 节点中可用于脏页缓存的内存总量（包括空闲页 + 文件缓存页 - 保留页）。\n- `balance_dirty_pages()`：主限流函数，在进程写入时被调用，根据当前脏页水位决定是否休眠或触发回写。\n- `balance_dirty_pages_ratelimited()`：带速率限制的脏页平衡入口，避免频繁调用开销。\n\n## 3. 关键实现\n\n### 脏页阈值计算逻辑\n- 脏页上限基于 **“dirtyable memory”** 计算，即 `(free pages + file cache pages - kernel reserves)`。\n- 支持两种配置方式：**百分比（ratio）** 或 **绝对字节数（bytes）**，后者优先。\n- 当启用 `vm_highmem_is_dirtyable` 时，highmem 区域的空闲页也计入 dirtyable memory。\n\n### 动态限流机制\n- 使用 **`MAX_PAUSE`（最大 200ms）** 限制单次 `balance_dirty_pages()` 的休眠时间。\n- 引入 **`DIRTY_POLL_THRESH`（128KB）** 作为调用间隔优化阈值：若脏页增长过快，则提升休眠时间至最大值。\n- 通过 **`BANDWIDTH_INTERVAL`（200ms）** 动态估算存储设备的写入带宽，用于调整回写速率。\n\n### cgroup writeback 支持\n- 在 `CONFIG_CGROUP_WRITEBACK` 启用时：\n  - 每个 memcg 有独立的 `wb_domain`\n  - `dirty_throttle_control` 可关联全局（gdtc）或 memcg（mdtc）上下文\n  - BDI 的 min/max_ratio 根据其实际带宽动态缩放，实现公平分配\n\n### 老化与完成计数\n- 使用 `fprop_local_percpu` 结构跟踪每个 BDI 的回写完成情况。\n- `VM_COMPLETIONS_PERIOD_LEN`（3 秒）定义了回写完成率的老化周期，影响带宽估算的响应速度。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm.h>`、`<linux/swap.h>`、`<linux/pagevec.h>` 等，与页分配、回收机制紧密集成。\n- **VFS 层**：通过 `<linux/fs.h>`、`<linux/pagemap.h>` 与 address_space 和 inode 交互。\n- **块设备层**：通过 `<linux/blkdev.h>`、`<linux/backing-dev.h>` 获取 BDI 信息和 I/O 能力。\n- **调度与同步**：使用 `<linux/sched.h>`、`<linux/spinlock.h>`、`<linux/timer.h>` 实现休眠、锁和定时器。\n- **追踪系统**：集成 `<trace/events/writeback.h>` 提供回写事件追踪点。\n- **内部头文件**：包含 `\"internal.h\"` 获取 MM 子系统内部接口。\n\n## 5. 使用场景\n\n1. **用户空间写入文件**  \n   当进程通过 `write()` 修改文件页时，页被标记为脏，随后调用 `balance_dirty_pages_ratelimited()` 触发脏页控制。\n\n2. **内存压力下的页面回收**  \n   kswapd 或直接回收路径在需要释放内存时，可能调用回写逻辑清理脏页。\n\n3. **定期后台回写**  \n   `writeback` 内核线程按 `dirty_writeback_interval` 周期唤醒，检查并回写超过 `dirty_expire_interval` 的脏页。\n\n4. **系统关闭或 sync 调用**  \n   虽然主要同步逻辑在其他文件，但本文件提供的阈值和状态是决策基础。\n\n5. **容器环境中的资源隔离**  \n   启用 cgroup writeback 后，不同 memcg 的脏页回写相互隔离，避免一个容器的大量写入影响其他容器性能。\n\n6. **笔记本省电模式**  \n   当 `laptop_mode` 启用时，延迟回写以减少磁盘旋转时间，延长电池寿命。",
      "similarity": 0.5930551886558533,
      "chunks": [
        {
          "chunk_id": 9,
          "file_path": "mm/page-writeback.c",
          "start_line": 1662,
          "end_line": 1988,
          "content": [
            "static inline void wb_dirty_limits(struct dirty_throttle_control *dtc)",
            "{",
            "\tstruct bdi_writeback *wb = dtc->wb;",
            "\tunsigned long wb_reclaimable;",
            "",
            "\t/*",
            "\t * wb_thresh is not treated as some limiting factor as",
            "\t * dirty_thresh, due to reasons",
            "\t * - in JBOD setup, wb_thresh can fluctuate a lot",
            "\t * - in a system with HDD and USB key, the USB key may somehow",
            "\t *   go into state (wb_dirty >> wb_thresh) either because",
            "\t *   wb_dirty starts high, or because wb_thresh drops low.",
            "\t *   In this case we don't want to hard throttle the USB key",
            "\t *   dirtiers for 100 seconds until wb_dirty drops under",
            "\t *   wb_thresh. Instead the auxiliary wb control line in",
            "\t *   wb_position_ratio() will let the dirtier task progress",
            "\t *   at some rate <= (write_bw / 2) for bringing down wb_dirty.",
            "\t */",
            "\tdtc->wb_thresh = __wb_calc_thresh(dtc);",
            "\tdtc->wb_bg_thresh = dtc->thresh ?",
            "\t\tdiv_u64((u64)dtc->wb_thresh * dtc->bg_thresh, dtc->thresh) : 0;",
            "",
            "\t/*",
            "\t * In order to avoid the stacked BDI deadlock we need",
            "\t * to ensure we accurately count the 'dirty' pages when",
            "\t * the threshold is low.",
            "\t *",
            "\t * Otherwise it would be possible to get thresh+n pages",
            "\t * reported dirty, even though there are thresh-m pages",
            "\t * actually dirty; with m+n sitting in the percpu",
            "\t * deltas.",
            "\t */",
            "\tif (dtc->wb_thresh < 2 * wb_stat_error()) {",
            "\t\twb_reclaimable = wb_stat_sum(wb, WB_RECLAIMABLE);",
            "\t\tdtc->wb_dirty = wb_reclaimable + wb_stat_sum(wb, WB_WRITEBACK);",
            "\t} else {",
            "\t\twb_reclaimable = wb_stat(wb, WB_RECLAIMABLE);",
            "\t\tdtc->wb_dirty = wb_reclaimable + wb_stat(wb, WB_WRITEBACK);",
            "\t}",
            "}",
            "static int balance_dirty_pages(struct bdi_writeback *wb,",
            "\t\t\t       unsigned long pages_dirtied, unsigned int flags)",
            "{",
            "\tstruct dirty_throttle_control gdtc_stor = { GDTC_INIT(wb) };",
            "\tstruct dirty_throttle_control mdtc_stor = { MDTC_INIT(wb, &gdtc_stor) };",
            "\tstruct dirty_throttle_control * const gdtc = &gdtc_stor;",
            "\tstruct dirty_throttle_control * const mdtc = mdtc_valid(&mdtc_stor) ?",
            "\t\t\t\t\t\t     &mdtc_stor : NULL;",
            "\tstruct dirty_throttle_control *sdtc;",
            "\tunsigned long nr_dirty;",
            "\tlong period;",
            "\tlong pause;",
            "\tlong max_pause;",
            "\tlong min_pause;",
            "\tint nr_dirtied_pause;",
            "\tbool dirty_exceeded = false;",
            "\tunsigned long task_ratelimit;",
            "\tunsigned long dirty_ratelimit;",
            "\tstruct backing_dev_info *bdi = wb->bdi;",
            "\tbool strictlimit = bdi->capabilities & BDI_CAP_STRICTLIMIT;",
            "\tunsigned long start_time = jiffies;",
            "\tint ret = 0;",
            "",
            "\tfor (;;) {",
            "\t\tunsigned long now = jiffies;",
            "\t\tunsigned long dirty, thresh, bg_thresh;",
            "\t\tunsigned long m_dirty = 0;\t/* stop bogus uninit warnings */",
            "\t\tunsigned long m_thresh = 0;",
            "\t\tunsigned long m_bg_thresh = 0;",
            "",
            "\t\tnr_dirty = global_node_page_state(NR_FILE_DIRTY);",
            "\t\tgdtc->avail = global_dirtyable_memory();",
            "\t\tgdtc->dirty = nr_dirty + global_node_page_state(NR_WRITEBACK);",
            "",
            "\t\tdomain_dirty_limits(gdtc);",
            "",
            "\t\tif (unlikely(strictlimit)) {",
            "\t\t\twb_dirty_limits(gdtc);",
            "",
            "\t\t\tdirty = gdtc->wb_dirty;",
            "\t\t\tthresh = gdtc->wb_thresh;",
            "\t\t\tbg_thresh = gdtc->wb_bg_thresh;",
            "\t\t} else {",
            "\t\t\tdirty = gdtc->dirty;",
            "\t\t\tthresh = gdtc->thresh;",
            "\t\t\tbg_thresh = gdtc->bg_thresh;",
            "\t\t}",
            "",
            "\t\tif (mdtc) {",
            "\t\t\tunsigned long filepages, headroom, writeback;",
            "",
            "\t\t\t/*",
            "\t\t\t * If @wb belongs to !root memcg, repeat the same",
            "\t\t\t * basic calculations for the memcg domain.",
            "\t\t\t */",
            "\t\t\tmem_cgroup_wb_stats(wb, &filepages, &headroom,",
            "\t\t\t\t\t    &mdtc->dirty, &writeback);",
            "\t\t\tmdtc->dirty += writeback;",
            "\t\t\tmdtc_calc_avail(mdtc, filepages, headroom);",
            "",
            "\t\t\tdomain_dirty_limits(mdtc);",
            "",
            "\t\t\tif (unlikely(strictlimit)) {",
            "\t\t\t\twb_dirty_limits(mdtc);",
            "\t\t\t\tm_dirty = mdtc->wb_dirty;",
            "\t\t\t\tm_thresh = mdtc->wb_thresh;",
            "\t\t\t\tm_bg_thresh = mdtc->wb_bg_thresh;",
            "\t\t\t} else {",
            "\t\t\t\tm_dirty = mdtc->dirty;",
            "\t\t\t\tm_thresh = mdtc->thresh;",
            "\t\t\t\tm_bg_thresh = mdtc->bg_thresh;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * In laptop mode, we wait until hitting the higher threshold",
            "\t\t * before starting background writeout, and then write out all",
            "\t\t * the way down to the lower threshold.  So slow writers cause",
            "\t\t * minimal disk activity.",
            "\t\t *",
            "\t\t * In normal mode, we start background writeout at the lower",
            "\t\t * background_thresh, to keep the amount of dirty memory low.",
            "\t\t */",
            "\t\tif (!laptop_mode && nr_dirty > gdtc->bg_thresh &&",
            "\t\t    !writeback_in_progress(wb))",
            "\t\t\twb_start_background_writeback(wb);",
            "",
            "\t\t/*",
            "\t\t * Throttle it only when the background writeback cannot",
            "\t\t * catch-up. This avoids (excessively) small writeouts",
            "\t\t * when the wb limits are ramping up in case of !strictlimit.",
            "\t\t *",
            "\t\t * In strictlimit case make decision based on the wb counters",
            "\t\t * and limits. Small writeouts when the wb limits are ramping",
            "\t\t * up are the price we consciously pay for strictlimit-ing.",
            "\t\t *",
            "\t\t * If memcg domain is in effect, @dirty should be under",
            "\t\t * both global and memcg freerun ceilings.",
            "\t\t */",
            "\t\tif (dirty <= dirty_freerun_ceiling(thresh, bg_thresh) &&",
            "\t\t    (!mdtc ||",
            "\t\t     m_dirty <= dirty_freerun_ceiling(m_thresh, m_bg_thresh))) {",
            "\t\t\tunsigned long intv;",
            "\t\t\tunsigned long m_intv;",
            "",
            "free_running:",
            "\t\t\tintv = dirty_poll_interval(dirty, thresh);",
            "\t\t\tm_intv = ULONG_MAX;",
            "",
            "\t\t\tcurrent->dirty_paused_when = now;",
            "\t\t\tcurrent->nr_dirtied = 0;",
            "\t\t\tif (mdtc)",
            "\t\t\t\tm_intv = dirty_poll_interval(m_dirty, m_thresh);",
            "\t\t\tcurrent->nr_dirtied_pause = min(intv, m_intv);",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\t/* Start writeback even when in laptop mode */",
            "\t\tif (unlikely(!writeback_in_progress(wb)))",
            "\t\t\twb_start_background_writeback(wb);",
            "",
            "\t\tmem_cgroup_flush_foreign(wb);",
            "",
            "\t\t/*",
            "\t\t * Calculate global domain's pos_ratio and select the",
            "\t\t * global dtc by default.",
            "\t\t */",
            "\t\tif (!strictlimit) {",
            "\t\t\twb_dirty_limits(gdtc);",
            "",
            "\t\t\tif ((current->flags & PF_LOCAL_THROTTLE) &&",
            "\t\t\t    gdtc->wb_dirty <",
            "\t\t\t    dirty_freerun_ceiling(gdtc->wb_thresh,",
            "\t\t\t\t\t\t  gdtc->wb_bg_thresh))",
            "\t\t\t\t/*",
            "\t\t\t\t * LOCAL_THROTTLE tasks must not be throttled",
            "\t\t\t\t * when below the per-wb freerun ceiling.",
            "\t\t\t\t */",
            "\t\t\t\tgoto free_running;",
            "\t\t}",
            "",
            "\t\tdirty_exceeded = (gdtc->wb_dirty > gdtc->wb_thresh) &&",
            "\t\t\t((gdtc->dirty > gdtc->thresh) || strictlimit);",
            "",
            "\t\twb_position_ratio(gdtc);",
            "\t\tsdtc = gdtc;",
            "",
            "\t\tif (mdtc) {",
            "\t\t\t/*",
            "\t\t\t * If memcg domain is in effect, calculate its",
            "\t\t\t * pos_ratio.  @wb should satisfy constraints from",
            "\t\t\t * both global and memcg domains.  Choose the one",
            "\t\t\t * w/ lower pos_ratio.",
            "\t\t\t */",
            "\t\t\tif (!strictlimit) {",
            "\t\t\t\twb_dirty_limits(mdtc);",
            "",
            "\t\t\t\tif ((current->flags & PF_LOCAL_THROTTLE) &&",
            "\t\t\t\t    mdtc->wb_dirty <",
            "\t\t\t\t    dirty_freerun_ceiling(mdtc->wb_thresh,",
            "\t\t\t\t\t\t\t  mdtc->wb_bg_thresh))",
            "\t\t\t\t\t/*",
            "\t\t\t\t\t * LOCAL_THROTTLE tasks must not be",
            "\t\t\t\t\t * throttled when below the per-wb",
            "\t\t\t\t\t * freerun ceiling.",
            "\t\t\t\t\t */",
            "\t\t\t\t\tgoto free_running;",
            "\t\t\t}",
            "\t\t\tdirty_exceeded |= (mdtc->wb_dirty > mdtc->wb_thresh) &&",
            "\t\t\t\t((mdtc->dirty > mdtc->thresh) || strictlimit);",
            "",
            "\t\t\twb_position_ratio(mdtc);",
            "\t\t\tif (mdtc->pos_ratio < gdtc->pos_ratio)",
            "\t\t\t\tsdtc = mdtc;",
            "\t\t}",
            "",
            "\t\tif (dirty_exceeded != wb->dirty_exceeded)",
            "\t\t\twb->dirty_exceeded = dirty_exceeded;",
            "",
            "\t\tif (time_is_before_jiffies(READ_ONCE(wb->bw_time_stamp) +",
            "\t\t\t\t\t   BANDWIDTH_INTERVAL))",
            "\t\t\t__wb_update_bandwidth(gdtc, mdtc, true);",
            "",
            "\t\t/* throttle according to the chosen dtc */",
            "\t\tdirty_ratelimit = READ_ONCE(wb->dirty_ratelimit);",
            "\t\ttask_ratelimit = ((u64)dirty_ratelimit * sdtc->pos_ratio) >>",
            "\t\t\t\t\t\t\tRATELIMIT_CALC_SHIFT;",
            "\t\tmax_pause = wb_max_pause(wb, sdtc->wb_dirty);",
            "\t\tmin_pause = wb_min_pause(wb, max_pause,",
            "\t\t\t\t\t task_ratelimit, dirty_ratelimit,",
            "\t\t\t\t\t &nr_dirtied_pause);",
            "",
            "\t\tif (unlikely(task_ratelimit == 0)) {",
            "\t\t\tperiod = max_pause;",
            "\t\t\tpause = max_pause;",
            "\t\t\tgoto pause;",
            "\t\t}",
            "\t\tperiod = HZ * pages_dirtied / task_ratelimit;",
            "\t\tpause = period;",
            "\t\tif (current->dirty_paused_when)",
            "\t\t\tpause -= now - current->dirty_paused_when;",
            "\t\t/*",
            "\t\t * For less than 1s think time (ext3/4 may block the dirtier",
            "\t\t * for up to 800ms from time to time on 1-HDD; so does xfs,",
            "\t\t * however at much less frequency), try to compensate it in",
            "\t\t * future periods by updating the virtual time; otherwise just",
            "\t\t * do a reset, as it may be a light dirtier.",
            "\t\t */",
            "\t\tif (pause < min_pause) {",
            "\t\t\ttrace_balance_dirty_pages(wb,",
            "\t\t\t\t\t\t  sdtc->thresh,",
            "\t\t\t\t\t\t  sdtc->bg_thresh,",
            "\t\t\t\t\t\t  sdtc->dirty,",
            "\t\t\t\t\t\t  sdtc->wb_thresh,",
            "\t\t\t\t\t\t  sdtc->wb_dirty,",
            "\t\t\t\t\t\t  dirty_ratelimit,",
            "\t\t\t\t\t\t  task_ratelimit,",
            "\t\t\t\t\t\t  pages_dirtied,",
            "\t\t\t\t\t\t  period,",
            "\t\t\t\t\t\t  min(pause, 0L),",
            "\t\t\t\t\t\t  start_time);",
            "\t\t\tif (pause < -HZ) {",
            "\t\t\t\tcurrent->dirty_paused_when = now;",
            "\t\t\t\tcurrent->nr_dirtied = 0;",
            "\t\t\t} else if (period) {",
            "\t\t\t\tcurrent->dirty_paused_when += period;",
            "\t\t\t\tcurrent->nr_dirtied = 0;",
            "\t\t\t} else if (current->nr_dirtied_pause <= pages_dirtied)",
            "\t\t\t\tcurrent->nr_dirtied_pause += pages_dirtied;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tif (unlikely(pause > max_pause)) {",
            "\t\t\t/* for occasional dropped task_ratelimit */",
            "\t\t\tnow += min(pause - max_pause, max_pause);",
            "\t\t\tpause = max_pause;",
            "\t\t}",
            "",
            "pause:",
            "\t\ttrace_balance_dirty_pages(wb,",
            "\t\t\t\t\t  sdtc->thresh,",
            "\t\t\t\t\t  sdtc->bg_thresh,",
            "\t\t\t\t\t  sdtc->dirty,",
            "\t\t\t\t\t  sdtc->wb_thresh,",
            "\t\t\t\t\t  sdtc->wb_dirty,",
            "\t\t\t\t\t  dirty_ratelimit,",
            "\t\t\t\t\t  task_ratelimit,",
            "\t\t\t\t\t  pages_dirtied,",
            "\t\t\t\t\t  period,",
            "\t\t\t\t\t  pause,",
            "\t\t\t\t\t  start_time);",
            "\t\tif (flags & BDP_ASYNC) {",
            "\t\t\tret = -EAGAIN;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\t__set_current_state(TASK_KILLABLE);",
            "\t\tbdi->last_bdp_sleep = jiffies;",
            "\t\tio_schedule_timeout(pause);",
            "",
            "\t\tcurrent->dirty_paused_when = now + pause;",
            "\t\tcurrent->nr_dirtied = 0;",
            "\t\tcurrent->nr_dirtied_pause = nr_dirtied_pause;",
            "",
            "\t\t/*",
            "\t\t * This is typically equal to (dirty < thresh) and can also",
            "\t\t * keep \"1000+ dd on a slow USB stick\" under control.",
            "\t\t */",
            "\t\tif (task_ratelimit)",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * In the case of an unresponsive NFS server and the NFS dirty",
            "\t\t * pages exceeds dirty_thresh, give the other good wb's a pipe",
            "\t\t * to go through, so that tasks on them still remain responsive.",
            "\t\t *",
            "\t\t * In theory 1 page is enough to keep the consumer-producer",
            "\t\t * pipe going: the flusher cleans 1 page => the task dirties 1",
            "\t\t * more page. However wb_dirty has accounting errors.  So use",
            "\t\t * the larger and more IO friendly wb_stat_error.",
            "\t\t */",
            "\t\tif (sdtc->wb_dirty <= wb_stat_error())",
            "\t\t\tbreak;",
            "",
            "\t\tif (fatal_signal_pending(current))",
            "\t\t\tbreak;",
            "\t}",
            "\treturn ret;",
            "}"
          ],
          "function_name": "wb_dirty_limits, balance_dirty_pages",
          "description": "实现脏页管理核心逻辑，包含确定当前脏页限制的计算函数和脏页平衡主函数，通过多级阈值检测、动态速率限制、暂停时间控制等机制，在保证系统响应性的同时防止内存过载，支持严格限制模式下的特殊处理。",
          "similarity": 0.6101332902908325
        },
        {
          "chunk_id": 10,
          "file_path": "mm/page-writeback.c",
          "start_line": 2033,
          "end_line": 2145,
          "content": [
            "int balance_dirty_pages_ratelimited_flags(struct address_space *mapping,",
            "\t\t\t\t\tunsigned int flags)",
            "{",
            "\tstruct inode *inode = mapping->host;",
            "\tstruct backing_dev_info *bdi = inode_to_bdi(inode);",
            "\tstruct bdi_writeback *wb = NULL;",
            "\tint ratelimit;",
            "\tint ret = 0;",
            "\tint *p;",
            "",
            "\tif (!(bdi->capabilities & BDI_CAP_WRITEBACK))",
            "\t\treturn ret;",
            "",
            "\tif (inode_cgwb_enabled(inode))",
            "\t\twb = wb_get_create_current(bdi, GFP_KERNEL);",
            "\tif (!wb)",
            "\t\twb = &bdi->wb;",
            "",
            "\tratelimit = current->nr_dirtied_pause;",
            "\tif (wb->dirty_exceeded)",
            "\t\tratelimit = min(ratelimit, 32 >> (PAGE_SHIFT - 10));",
            "",
            "\tpreempt_disable();",
            "\t/*",
            "\t * This prevents one CPU to accumulate too many dirtied pages without",
            "\t * calling into balance_dirty_pages(), which can happen when there are",
            "\t * 1000+ tasks, all of them start dirtying pages at exactly the same",
            "\t * time, hence all honoured too large initial task->nr_dirtied_pause.",
            "\t */",
            "\tp =  this_cpu_ptr(&bdp_ratelimits);",
            "\tif (unlikely(current->nr_dirtied >= ratelimit))",
            "\t\t*p = 0;",
            "\telse if (unlikely(*p >= ratelimit_pages)) {",
            "\t\t*p = 0;",
            "\t\tratelimit = 0;",
            "\t}",
            "\t/*",
            "\t * Pick up the dirtied pages by the exited tasks. This avoids lots of",
            "\t * short-lived tasks (eg. gcc invocations in a kernel build) escaping",
            "\t * the dirty throttling and livelock other long-run dirtiers.",
            "\t */",
            "\tp = this_cpu_ptr(&dirty_throttle_leaks);",
            "\tif (*p > 0 && current->nr_dirtied < ratelimit) {",
            "\t\tunsigned long nr_pages_dirtied;",
            "\t\tnr_pages_dirtied = min(*p, ratelimit - current->nr_dirtied);",
            "\t\t*p -= nr_pages_dirtied;",
            "\t\tcurrent->nr_dirtied += nr_pages_dirtied;",
            "\t}",
            "\tpreempt_enable();",
            "",
            "\tif (unlikely(current->nr_dirtied >= ratelimit))",
            "\t\tret = balance_dirty_pages(wb, current->nr_dirtied, flags);",
            "",
            "\twb_put(wb);",
            "\treturn ret;",
            "}",
            "void balance_dirty_pages_ratelimited(struct address_space *mapping)",
            "{",
            "\tbalance_dirty_pages_ratelimited_flags(mapping, 0);",
            "}",
            "bool wb_over_bg_thresh(struct bdi_writeback *wb)",
            "{",
            "\tstruct dirty_throttle_control gdtc_stor = { GDTC_INIT(wb) };",
            "\tstruct dirty_throttle_control mdtc_stor = { MDTC_INIT(wb, &gdtc_stor) };",
            "\tstruct dirty_throttle_control * const gdtc = &gdtc_stor;",
            "\tstruct dirty_throttle_control * const mdtc = mdtc_valid(&mdtc_stor) ?",
            "\t\t\t\t\t\t     &mdtc_stor : NULL;",
            "\tunsigned long reclaimable;",
            "\tunsigned long thresh;",
            "",
            "\t/*",
            "\t * Similar to balance_dirty_pages() but ignores pages being written",
            "\t * as we're trying to decide whether to put more under writeback.",
            "\t */",
            "\tgdtc->avail = global_dirtyable_memory();",
            "\tgdtc->dirty = global_node_page_state(NR_FILE_DIRTY);",
            "\tdomain_dirty_limits(gdtc);",
            "",
            "\tif (gdtc->dirty > gdtc->bg_thresh)",
            "\t\treturn true;",
            "",
            "\tthresh = wb_calc_thresh(gdtc->wb, gdtc->bg_thresh);",
            "\tif (thresh < 2 * wb_stat_error())",
            "\t\treclaimable = wb_stat_sum(wb, WB_RECLAIMABLE);",
            "\telse",
            "\t\treclaimable = wb_stat(wb, WB_RECLAIMABLE);",
            "",
            "\tif (reclaimable > thresh)",
            "\t\treturn true;",
            "",
            "\tif (mdtc) {",
            "\t\tunsigned long filepages, headroom, writeback;",
            "",
            "\t\tmem_cgroup_wb_stats(wb, &filepages, &headroom, &mdtc->dirty,",
            "\t\t\t\t    &writeback);",
            "\t\tmdtc_calc_avail(mdtc, filepages, headroom);",
            "\t\tdomain_dirty_limits(mdtc);\t/* ditto, ignore writeback */",
            "",
            "\t\tif (mdtc->dirty > mdtc->bg_thresh)",
            "\t\t\treturn true;",
            "",
            "\t\tthresh = wb_calc_thresh(mdtc->wb, mdtc->bg_thresh);",
            "\t\tif (thresh < 2 * wb_stat_error())",
            "\t\t\treclaimable = wb_stat_sum(wb, WB_RECLAIMABLE);",
            "\t\telse",
            "\t\t\treclaimable = wb_stat(wb, WB_RECLAIMABLE);",
            "",
            "\t\tif (reclaimable > thresh)",
            "\t\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "balance_dirty_pages_ratelimited_flags, balance_dirty_pages_ratelimited, wb_over_bg_thresh",
          "description": "balance_dirty_pages_ratelimited_flags 函数用于控制脏页的速率限制和写回决策，通过检查当前脏页数量与速率限制阈值比较，决定是否触发writeback。wb_over_bg_thresh 判断是否超过背景写回阈值，用于决定是否允许更多脏页产生。",
          "similarity": 0.6098161935806274
        },
        {
          "chunk_id": 1,
          "file_path": "mm/page-writeback.c",
          "start_line": 164,
          "end_line": 268,
          "content": [
            "static bool mdtc_valid(struct dirty_throttle_control *dtc)",
            "{",
            "\treturn dtc->dom;",
            "}",
            "static void wb_min_max_ratio(struct bdi_writeback *wb,",
            "\t\t\t     unsigned long *minp, unsigned long *maxp)",
            "{",
            "\tunsigned long this_bw = READ_ONCE(wb->avg_write_bandwidth);",
            "\tunsigned long tot_bw = atomic_long_read(&wb->bdi->tot_write_bandwidth);",
            "\tunsigned long long min = wb->bdi->min_ratio;",
            "\tunsigned long long max = wb->bdi->max_ratio;",
            "",
            "\t/*",
            "\t * @wb may already be clean by the time control reaches here and",
            "\t * the total may not include its bw.",
            "\t */",
            "\tif (this_bw < tot_bw) {",
            "\t\tif (min) {",
            "\t\t\tmin *= this_bw;",
            "\t\t\tmin = div64_ul(min, tot_bw);",
            "\t\t}",
            "\t\tif (max < 100 * BDI_RATIO_SCALE) {",
            "\t\t\tmax *= this_bw;",
            "\t\t\tmax = div64_ul(max, tot_bw);",
            "\t\t}",
            "\t}",
            "",
            "\t*minp = min;",
            "\t*maxp = max;",
            "}",
            "static bool mdtc_valid(struct dirty_throttle_control *dtc)",
            "{",
            "\treturn false;",
            "}",
            "static void wb_min_max_ratio(struct bdi_writeback *wb,",
            "\t\t\t     unsigned long *minp, unsigned long *maxp)",
            "{",
            "\t*minp = wb->bdi->min_ratio;",
            "\t*maxp = wb->bdi->max_ratio;",
            "}",
            "static unsigned long node_dirtyable_memory(struct pglist_data *pgdat)",
            "{",
            "\tunsigned long nr_pages = 0;",
            "\tint z;",
            "",
            "\tfor (z = 0; z < MAX_NR_ZONES; z++) {",
            "\t\tstruct zone *zone = pgdat->node_zones + z;",
            "",
            "\t\tif (!populated_zone(zone))",
            "\t\t\tcontinue;",
            "",
            "\t\tnr_pages += zone_page_state(zone, NR_FREE_PAGES);",
            "\t}",
            "",
            "\t/*",
            "\t * Pages reserved for the kernel should not be considered",
            "\t * dirtyable, to prevent a situation where reclaim has to",
            "\t * clean pages in order to balance the zones.",
            "\t */",
            "\tnr_pages -= min(nr_pages, pgdat->totalreserve_pages);",
            "",
            "\tnr_pages += node_page_state(pgdat, NR_INACTIVE_FILE);",
            "\tnr_pages += node_page_state(pgdat, NR_ACTIVE_FILE);",
            "",
            "\treturn nr_pages;",
            "}",
            "static unsigned long highmem_dirtyable_memory(unsigned long total)",
            "{",
            "#ifdef CONFIG_HIGHMEM",
            "\tint node;",
            "\tunsigned long x = 0;",
            "\tint i;",
            "",
            "\tfor_each_node_state(node, N_HIGH_MEMORY) {",
            "\t\tfor (i = ZONE_NORMAL + 1; i < MAX_NR_ZONES; i++) {",
            "\t\t\tstruct zone *z;",
            "\t\t\tunsigned long nr_pages;",
            "",
            "\t\t\tif (!is_highmem_idx(i))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tz = &NODE_DATA(node)->node_zones[i];",
            "\t\t\tif (!populated_zone(z))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tnr_pages = zone_page_state(z, NR_FREE_PAGES);",
            "\t\t\t/* watch for underflows */",
            "\t\t\tnr_pages -= min(nr_pages, high_wmark_pages(z));",
            "\t\t\tnr_pages += zone_page_state(z, NR_ZONE_INACTIVE_FILE);",
            "\t\t\tnr_pages += zone_page_state(z, NR_ZONE_ACTIVE_FILE);",
            "\t\t\tx += nr_pages;",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * Make sure that the number of highmem pages is never larger",
            "\t * than the number of the total dirtyable memory. This can only",
            "\t * occur in very strange VM situations but we want to make sure",
            "\t * that this does not occur.",
            "\t */",
            "\treturn min(x, total);",
            "#else",
            "\treturn 0;",
            "#endif",
            "}"
          ],
          "function_name": "mdtc_valid, wb_min_max_ratio, mdtc_valid, wb_min_max_ratio, node_dirtyable_memory, highmem_dirtyable_memory",
          "description": "计算各节点可脏化内存大小，并基于当前写入带宽调整脏页限制的最小和最大比率，用于后续脏页阈值计算。",
          "similarity": 0.6011488437652588
        },
        {
          "chunk_id": 2,
          "file_path": "mm/page-writeback.c",
          "start_line": 345,
          "end_line": 459,
          "content": [
            "static unsigned long global_dirtyable_memory(void)",
            "{",
            "\tunsigned long x;",
            "",
            "\tx = global_zone_page_state(NR_FREE_PAGES);",
            "\t/*",
            "\t * Pages reserved for the kernel should not be considered",
            "\t * dirtyable, to prevent a situation where reclaim has to",
            "\t * clean pages in order to balance the zones.",
            "\t */",
            "\tx -= min(x, totalreserve_pages);",
            "",
            "\tx += global_node_page_state(NR_INACTIVE_FILE);",
            "\tx += global_node_page_state(NR_ACTIVE_FILE);",
            "",
            "\tif (!vm_highmem_is_dirtyable)",
            "\t\tx -= highmem_dirtyable_memory(x);",
            "",
            "\treturn x + 1;\t/* Ensure that we never return 0 */",
            "}",
            "static void domain_dirty_limits(struct dirty_throttle_control *dtc)",
            "{",
            "\tconst unsigned long available_memory = dtc->avail;",
            "\tstruct dirty_throttle_control *gdtc = mdtc_gdtc(dtc);",
            "\tunsigned long bytes = vm_dirty_bytes;",
            "\tunsigned long bg_bytes = dirty_background_bytes;",
            "\t/* convert ratios to per-PAGE_SIZE for higher precision */",
            "\tunsigned long ratio = (vm_dirty_ratio * PAGE_SIZE) / 100;",
            "\tunsigned long bg_ratio = (dirty_background_ratio * PAGE_SIZE) / 100;",
            "\tunsigned long thresh;",
            "\tunsigned long bg_thresh;",
            "\tstruct task_struct *tsk;",
            "",
            "\t/* gdtc is !NULL iff @dtc is for memcg domain */",
            "\tif (gdtc) {",
            "\t\tunsigned long global_avail = gdtc->avail;",
            "",
            "\t\t/*",
            "\t\t * The byte settings can't be applied directly to memcg",
            "\t\t * domains.  Convert them to ratios by scaling against",
            "\t\t * globally available memory.  As the ratios are in",
            "\t\t * per-PAGE_SIZE, they can be obtained by dividing bytes by",
            "\t\t * number of pages.",
            "\t\t */",
            "\t\tif (bytes)",
            "\t\t\tratio = min(DIV_ROUND_UP(bytes, global_avail),",
            "\t\t\t\t    PAGE_SIZE);",
            "\t\tif (bg_bytes)",
            "\t\t\tbg_ratio = min(DIV_ROUND_UP(bg_bytes, global_avail),",
            "\t\t\t\t       PAGE_SIZE);",
            "\t\tbytes = bg_bytes = 0;",
            "\t}",
            "",
            "\tif (bytes)",
            "\t\tthresh = DIV_ROUND_UP(bytes, PAGE_SIZE);",
            "\telse",
            "\t\tthresh = (ratio * available_memory) / PAGE_SIZE;",
            "",
            "\tif (bg_bytes)",
            "\t\tbg_thresh = DIV_ROUND_UP(bg_bytes, PAGE_SIZE);",
            "\telse",
            "\t\tbg_thresh = (bg_ratio * available_memory) / PAGE_SIZE;",
            "",
            "\ttsk = current;",
            "\tif (rt_or_dl_task(tsk)) {",
            "\t\tbg_thresh += bg_thresh / 4 + global_wb_domain.dirty_limit / 32;",
            "\t\tthresh += thresh / 4 + global_wb_domain.dirty_limit / 32;",
            "\t}",
            "\t/*",
            "\t * Dirty throttling logic assumes the limits in page units fit into",
            "\t * 32-bits. This gives 16TB dirty limits max which is hopefully enough.",
            "\t */",
            "\tif (thresh > UINT_MAX)",
            "\t\tthresh = UINT_MAX;",
            "\t/* This makes sure bg_thresh is within 32-bits as well */",
            "\tif (bg_thresh >= thresh)",
            "\t\tbg_thresh = thresh / 2;",
            "\tdtc->thresh = thresh;",
            "\tdtc->bg_thresh = bg_thresh;",
            "",
            "\t/* we should eventually report the domain in the TP */",
            "\tif (!gdtc)",
            "\t\ttrace_global_dirty_state(bg_thresh, thresh);",
            "}",
            "void global_dirty_limits(unsigned long *pbackground, unsigned long *pdirty)",
            "{",
            "\tstruct dirty_throttle_control gdtc = { GDTC_INIT_NO_WB };",
            "",
            "\tgdtc.avail = global_dirtyable_memory();",
            "\tdomain_dirty_limits(&gdtc);",
            "",
            "\t*pbackground = gdtc.bg_thresh;",
            "\t*pdirty = gdtc.thresh;",
            "}",
            "static unsigned long node_dirty_limit(struct pglist_data *pgdat)",
            "{",
            "\tunsigned long node_memory = node_dirtyable_memory(pgdat);",
            "\tstruct task_struct *tsk = current;",
            "\tunsigned long dirty;",
            "",
            "\tif (vm_dirty_bytes)",
            "\t\tdirty = DIV_ROUND_UP(vm_dirty_bytes, PAGE_SIZE) *",
            "\t\t\tnode_memory / global_dirtyable_memory();",
            "\telse",
            "\t\tdirty = vm_dirty_ratio * node_memory / 100;",
            "",
            "\tif (rt_or_dl_task(tsk))",
            "\t\tdirty += dirty / 4;",
            "",
            "\t/*",
            "\t * Dirty throttling logic assumes the limits in page units fit into",
            "\t * 32-bits. This gives 16TB dirty limits max which is hopefully enough.",
            "\t */",
            "\treturn min_t(unsigned long, dirty, UINT_MAX);",
            "}"
          ],
          "function_name": "global_dirtyable_memory, domain_dirty_limits, global_dirty_limits, node_dirty_limit",
          "description": "计算全局可用脏化内存并结合域级别参数确定脏页上限，根据实时任务特性调整阈值，提供全局和节点层级的脏页限制。",
          "similarity": 0.5927066802978516
        },
        {
          "chunk_id": 0,
          "file_path": "mm/page-writeback.c",
          "start_line": 1,
          "end_line": 163,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * mm/page-writeback.c",
            " *",
            " * Copyright (C) 2002, Linus Torvalds.",
            " * Copyright (C) 2007 Red Hat, Inc., Peter Zijlstra",
            " *",
            " * Contains functions related to writing back dirty pages at the",
            " * address_space level.",
            " *",
            " * 10Apr2002\tAndrew Morton",
            " *\t\tInitial version",
            " */",
            "",
            "#include <linux/kernel.h>",
            "#include <linux/math64.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/fs.h>",
            "#include <linux/mm.h>",
            "#include <linux/swap.h>",
            "#include <linux/slab.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/writeback.h>",
            "#include <linux/init.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/mpage.h>",
            "#include <linux/rmap.h>",
            "#include <linux/percpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/cpu.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/timer.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm_inline.h>",
            "#include <trace/events/writeback.h>",
            "",
            "#include \"internal.h\"",
            "",
            "/*",
            " * Sleep at most 200ms at a time in balance_dirty_pages().",
            " */",
            "#define MAX_PAUSE\t\tmax(HZ/5, 1)",
            "",
            "/*",
            " * Try to keep balance_dirty_pages() call intervals higher than this many pages",
            " * by raising pause time to max_pause when falls below it.",
            " */",
            "#define DIRTY_POLL_THRESH\t(128 >> (PAGE_SHIFT - 10))",
            "",
            "/*",
            " * Estimate write bandwidth at 200ms intervals.",
            " */",
            "#define BANDWIDTH_INTERVAL\tmax(HZ/5, 1)",
            "",
            "#define RATELIMIT_CALC_SHIFT\t10",
            "",
            "/*",
            " * After a CPU has dirtied this many pages, balance_dirty_pages_ratelimited",
            " * will look to see if it needs to force writeback or throttling.",
            " */",
            "static long ratelimit_pages = 32;",
            "",
            "/* The following parameters are exported via /proc/sys/vm */",
            "",
            "/*",
            " * Start background writeback (via writeback threads) at this percentage",
            " */",
            "static int dirty_background_ratio = 10;",
            "",
            "/*",
            " * dirty_background_bytes starts at 0 (disabled) so that it is a function of",
            " * dirty_background_ratio * the amount of dirtyable memory",
            " */",
            "static unsigned long dirty_background_bytes;",
            "",
            "/*",
            " * free highmem will not be subtracted from the total free memory",
            " * for calculating free ratios if vm_highmem_is_dirtyable is true",
            " */",
            "static int vm_highmem_is_dirtyable;",
            "",
            "/*",
            " * The generator of dirty data starts writeback at this percentage",
            " */",
            "static int vm_dirty_ratio = 20;",
            "",
            "/*",
            " * vm_dirty_bytes starts at 0 (disabled) so that it is a function of",
            " * vm_dirty_ratio * the amount of dirtyable memory",
            " */",
            "static unsigned long vm_dirty_bytes;",
            "",
            "/*",
            " * The interval between `kupdate'-style writebacks",
            " */",
            "unsigned int dirty_writeback_interval = 5 * 100; /* centiseconds */",
            "",
            "EXPORT_SYMBOL_GPL(dirty_writeback_interval);",
            "",
            "/*",
            " * The longest time for which data is allowed to remain dirty",
            " */",
            "unsigned int dirty_expire_interval = 30 * 100; /* centiseconds */",
            "",
            "/*",
            " * Flag that puts the machine in \"laptop mode\". Doubles as a timeout in jiffies:",
            " * a full sync is triggered after this time elapses without any disk activity.",
            " */",
            "int laptop_mode;",
            "",
            "EXPORT_SYMBOL(laptop_mode);",
            "",
            "/* End of sysctl-exported parameters */",
            "",
            "struct wb_domain global_wb_domain;",
            "",
            "/* consolidated parameters for balance_dirty_pages() and its subroutines */",
            "struct dirty_throttle_control {",
            "#ifdef CONFIG_CGROUP_WRITEBACK",
            "\tstruct wb_domain\t*dom;",
            "\tstruct dirty_throttle_control *gdtc;\t/* only set in memcg dtc's */",
            "#endif",
            "\tstruct bdi_writeback\t*wb;",
            "\tstruct fprop_local_percpu *wb_completions;",
            "",
            "\tunsigned long\t\tavail;\t\t/* dirtyable */",
            "\tunsigned long\t\tdirty;\t\t/* file_dirty + write + nfs */",
            "\tunsigned long\t\tthresh;\t\t/* dirty threshold */",
            "\tunsigned long\t\tbg_thresh;\t/* dirty background threshold */",
            "",
            "\tunsigned long\t\twb_dirty;\t/* per-wb counterparts */",
            "\tunsigned long\t\twb_thresh;",
            "\tunsigned long\t\twb_bg_thresh;",
            "",
            "\tunsigned long\t\tpos_ratio;",
            "};",
            "",
            "/*",
            " * Length of period for aging writeout fractions of bdis. This is an",
            " * arbitrarily chosen number. The longer the period, the slower fractions will",
            " * reflect changes in current writeout rate.",
            " */",
            "#define VM_COMPLETIONS_PERIOD_LEN (3*HZ)",
            "",
            "#ifdef CONFIG_CGROUP_WRITEBACK",
            "",
            "#define GDTC_INIT(__wb)\t\t.wb = (__wb),\t\t\t\t\\",
            "\t\t\t\t.dom = &global_wb_domain,\t\t\\",
            "\t\t\t\t.wb_completions = &(__wb)->completions",
            "",
            "#define GDTC_INIT_NO_WB\t\t.dom = &global_wb_domain",
            "",
            "#define MDTC_INIT(__wb, __gdtc)\t.wb = (__wb),\t\t\t\t\\",
            "\t\t\t\t.dom = mem_cgroup_wb_domain(__wb),\t\\",
            "\t\t\t\t.wb_completions = &(__wb)->memcg_completions, \\",
            "\t\t\t\t.gdtc = __gdtc",
            ""
          ],
          "function_name": null,
          "description": "定义与页面回写相关的全局参数和结构体，包括脏页背景写回阈值、脏页比例限制及内存组（cgroups）相关控制参数，用于管理内存中脏页的写回策略。",
          "similarity": 0.5840874910354614
        }
      ]
    },
    {
      "source_file": "mm/page_counter.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:00:45\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `page_counter.c`\n\n---\n\n# page_counter.c 技术文档\n\n## 1. 文件概述\n\n`page_counter.c` 实现了一个无锁（lockless）的分层页面计数与限制机制，用于在 Linux 内核中对内存资源进行层级化计量、保护和限制。该机制主要用于 cgroup 内存控制器（如 memcg）中，支持对内存使用量进行精确跟踪，并提供 `memory.min` 和 `memory.low` 两种级别的内存保护策略，同时支持设置硬性上限（`memory.max`）。所有操作均基于原子操作实现，避免了传统锁带来的性能开销。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct page_counter`：核心计数器结构体，包含以下关键字段：\n  - `usage`：当前已使用的页面数（原子变量）\n  - `max`：硬性内存上限（可配置）\n  - `min` / `low`：内存保护阈值（软性保障）\n  - `min_usage` / `low_usage`：实际受保护的内存量\n  - `children_min_usage` / `children_low_usage`：子节点受保护内存总量\n  - `watermark`：历史最大使用量（用于统计）\n  - `failcnt`：因超出限制而失败的尝试次数\n  - `parent`：指向父级计数器的指针，构成层级树\n  - `protection_support`：是否启用保护机制的标志\n\n### 主要函数\n| 函数 | 功能说明 |\n|------|--------|\n| `page_counter_charge()` | 无条件地向计数器及其所有祖先层级增加指定页数 |\n| `page_counter_uncharge()` | 向计数器及其祖先层级减少指定页数（调用 `cancel`） |\n| `page_counter_try_charge()` | 尝试充电，若任一层级超过 `max` 则回滚并返回失败 |\n| `page_counter_cancel()` | 从本地计数器减去页数，处理下溢并更新保护用量 |\n| `page_counter_set_max()` | 设置硬性内存上限，若当前用量已超限则返回 `-EBUSY` |\n| `page_counter_set_min()` / `page_counter_set_low()` | 设置内存保护阈值，并触发保护用量传播 |\n| `page_counter_memparse()` | 解析用户输入的字符串（如 \"1G\"）为页数，支持 \"max\" 关键字 |\n| `propagate_protected_usage()` | （内部）根据当前用量和 min/low 阈值，向上更新受保护内存量 |\n\n## 3. 关键实现\n\n### 无锁层级更新\n- 所有计数操作（charge/uncharge）通过 `atomic_long_add_return()` 和 `atomic_long_sub_return()` 实现，确保线程安全。\n- 在 `page_counter_try_charge()` 中采用“先加后检”策略：先原子增加用量，再检查是否超过 `max`。若超限则回退。此方法虽存在短暂超限窗口，但避免了昂贵的 CAS 循环，适用于 THP（透明大页）等场景。\n\n### 内存保护机制\n- 引入 `min` 和 `low` 两级软保护：\n  - `min`：强保障，通常用于关键服务\n  - `low`：弱保障，用于优先级稍低的内存预留\n- `propagate_protected_usage()` 计算每个节点的实际受保护量：`protected = min(usage, threshold)`，并通过 `min_usage`/`low_usage` 原子变量记录，并累加到父节点的 `children_*_usage` 中，供上层决策（如内存回收）使用。\n\n### 水位线与失败计数\n- `watermark` 记录历史峰值用量，用于监控和调优。\n- `failcnt` 统计因超限导致的充电失败次数，仅用于统计信息，允许轻微不一致。\n\n### 安全的 max 更新\n- `page_counter_set_max()` 使用 `xchg()` 原子交换新旧上限，并通过循环验证：若在设置过程中用量增长导致新上限仍不足，则恢复旧值并重试，确保不会将上限设为低于当前用量的值。\n\n### 字符串解析\n- `page_counter_memparse()` 封装 `memparse()`，将用户空间传入的字符串（如 \"512M\"）转换为页数，并支持特殊值 \"max\" 表示 `PAGE_COUNTER_MAX`（即 `ULONG_MAX`）。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/page_counter.h>`：定义 `struct page_counter` 及函数声明\n  - `<linux/atomic.h>`：提供原子操作原语\n  - `<asm/page.h>`：提供 `PAGE_SIZE` 定义\n  - `<linux/kernel.h>`、`<linux/string.h>` 等基础内核头文件\n- **配置依赖**：\n  - 主要服务于 `CONFIG_MEMCG`（内存 cgroup）和 `CONFIG_CGROUP_DMEM`（设备内存 cgroup）\n  - 文件末尾的 `#if IS_ENABLED(...)` 表明其设计初衷是为 cgroup 内存控制器提供底层支持\n- **运行时依赖**：\n  - 依赖内核的原子操作和内存屏障语义保证正确性\n  - 与内存回收（reclaim）逻辑紧密配合，保护用量信息用于决定回收顺序\n\n## 5. 使用场景\n\n- **cgroup v2 内存控制器**：作为 `memory.max`、`memory.min`、`memory.low` 等接口的底层实现，管理容器或进程组的内存限额与保障。\n- **内存服务质量（QoS）**：通过 `min`/`low` 机制为关键应用提供内存预留，防止被普通任务挤占。\n- **内存超售（Overcommit）管理**：在云环境或虚拟化平台中，精确控制各租户的内存使用边界。\n- **透明大页（THP）分配**：`try_charge` 的投机性设计特别优化了 THP（2MB/1GB 页）与普通页（4KB）并发分配时的性能。\n- **系统监控与调优**：通过 `watermark` 和 `failcnt` 提供内存使用峰值和限制冲突的统计信息，辅助系统管理员进行容量规划。",
      "similarity": 0.5650060772895813,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/page_counter.c",
          "start_line": 16,
          "end_line": 132,
          "content": [
            "static bool track_protection(struct page_counter *c)",
            "{",
            "\treturn c->protection_support;",
            "}",
            "static void propagate_protected_usage(struct page_counter *c,",
            "\t\t\t\t      unsigned long usage)",
            "{",
            "\tunsigned long protected, old_protected;",
            "\tlong delta;",
            "",
            "\tif (!c->parent)",
            "\t\treturn;",
            "",
            "\tprotected = min(usage, READ_ONCE(c->min));",
            "\told_protected = atomic_long_read(&c->min_usage);",
            "\tif (protected != old_protected) {",
            "\t\told_protected = atomic_long_xchg(&c->min_usage, protected);",
            "\t\tdelta = protected - old_protected;",
            "\t\tif (delta)",
            "\t\t\tatomic_long_add(delta, &c->parent->children_min_usage);",
            "\t}",
            "",
            "\tprotected = min(usage, READ_ONCE(c->low));",
            "\told_protected = atomic_long_read(&c->low_usage);",
            "\tif (protected != old_protected) {",
            "\t\told_protected = atomic_long_xchg(&c->low_usage, protected);",
            "\t\tdelta = protected - old_protected;",
            "\t\tif (delta)",
            "\t\t\tatomic_long_add(delta, &c->parent->children_low_usage);",
            "\t}",
            "}",
            "void page_counter_cancel(struct page_counter *counter, unsigned long nr_pages)",
            "{",
            "\tlong new;",
            "",
            "\tnew = atomic_long_sub_return(nr_pages, &counter->usage);",
            "\t/* More uncharges than charges? */",
            "\tif (WARN_ONCE(new < 0, \"page_counter underflow: %ld nr_pages=%lu\\n\",",
            "\t\t      new, nr_pages)) {",
            "\t\tnew = 0;",
            "\t\tatomic_long_set(&counter->usage, new);",
            "\t}",
            "\tif (track_protection(counter))",
            "\t\tpropagate_protected_usage(counter, new);",
            "}",
            "void page_counter_charge(struct page_counter *counter, unsigned long nr_pages)",
            "{",
            "\tstruct page_counter *c;",
            "\tbool protection = track_protection(counter);",
            "",
            "\tfor (c = counter; c; c = c->parent) {",
            "\t\tlong new;",
            "",
            "\t\tnew = atomic_long_add_return(nr_pages, &c->usage);",
            "\t\tif (protection)",
            "\t\t\tpropagate_protected_usage(c, new);",
            "\t\t/*",
            "\t\t * This is indeed racy, but we can live with some",
            "\t\t * inaccuracy in the watermark.",
            "\t\t */",
            "\t\tif (new > READ_ONCE(c->watermark))",
            "\t\t\tWRITE_ONCE(c->watermark, new);",
            "\t}",
            "}",
            "bool page_counter_try_charge(struct page_counter *counter,",
            "\t\t\t     unsigned long nr_pages,",
            "\t\t\t     struct page_counter **fail)",
            "{",
            "\tstruct page_counter *c;",
            "\tbool protection = track_protection(counter);",
            "",
            "\tfor (c = counter; c; c = c->parent) {",
            "\t\tlong new;",
            "\t\t/*",
            "\t\t * Charge speculatively to avoid an expensive CAS.  If",
            "\t\t * a bigger charge fails, it might falsely lock out a",
            "\t\t * racing smaller charge and send it into reclaim",
            "\t\t * early, but the error is limited to the difference",
            "\t\t * between the two sizes, which is less than 2M/4M in",
            "\t\t * case of a THP locking out a regular page charge.",
            "\t\t *",
            "\t\t * The atomic_long_add_return() implies a full memory",
            "\t\t * barrier between incrementing the count and reading",
            "\t\t * the limit.  When racing with page_counter_set_max(),",
            "\t\t * we either see the new limit or the setter sees the",
            "\t\t * counter has changed and retries.",
            "\t\t */",
            "\t\tnew = atomic_long_add_return(nr_pages, &c->usage);",
            "\t\tif (new > c->max) {",
            "\t\t\tatomic_long_sub(nr_pages, &c->usage);",
            "\t\t\t/*",
            "\t\t\t * This is racy, but we can live with some",
            "\t\t\t * inaccuracy in the failcnt which is only used",
            "\t\t\t * to report stats.",
            "\t\t\t */",
            "\t\t\tdata_race(c->failcnt++);",
            "\t\t\t*fail = c;",
            "\t\t\tgoto failed;",
            "\t\t}",
            "\t\tif (protection)",
            "\t\t\tpropagate_protected_usage(c, new);",
            "",
            "\t\t/*",
            "\t\t * Just like with failcnt, we can live with some",
            "\t\t * inaccuracy in the watermark.",
            "\t\t */",
            "\t\tif (new > READ_ONCE(c->watermark))",
            "\t\t\tWRITE_ONCE(c->watermark, new);",
            "\t}",
            "\treturn true;",
            "",
            "failed:",
            "\tfor (c = counter; c != *fail; c = c->parent)",
            "\t\tpage_counter_cancel(c, nr_pages);",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "track_protection, propagate_protected_usage, page_counter_cancel, page_counter_charge, page_counter_try_charge",
          "description": "实现页面使用量的追踪与传播逻辑，包含受保护使用量更新、充放电操作及限制检查，通过层级传播维护父子计数器间的最小/低水位线状态同步。",
          "similarity": 0.48715755343437195
        },
        {
          "chunk_id": 0,
          "file_path": "mm/page_counter.c",
          "start_line": 1,
          "end_line": 15,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Lockless hierarchical page accounting & limiting",
            " *",
            " * Copyright (C) 2014 Red Hat, Inc., Johannes Weiner",
            " */",
            "",
            "#include <linux/page_counter.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/string.h>",
            "#include <linux/sched.h>",
            "#include <linux/bug.h>",
            "#include <asm/page.h>",
            ""
          ],
          "function_name": null,
          "description": "定义页面计数器相关头文件及基础宏，提供锁无关的分层页面计数与限制机制框架，声明核心结构体和辅助函数原型，为后续实现提供基础设施。",
          "similarity": 0.45368149876594543
        },
        {
          "chunk_id": 2,
          "file_path": "mm/page_counter.c",
          "start_line": 164,
          "end_line": 312,
          "content": [
            "void page_counter_uncharge(struct page_counter *counter, unsigned long nr_pages)",
            "{",
            "\tstruct page_counter *c;",
            "",
            "\tfor (c = counter; c; c = c->parent)",
            "\t\tpage_counter_cancel(c, nr_pages);",
            "}",
            "int page_counter_set_max(struct page_counter *counter, unsigned long nr_pages)",
            "{",
            "\tfor (;;) {",
            "\t\tunsigned long old;",
            "\t\tlong usage;",
            "",
            "\t\t/*",
            "\t\t * Update the limit while making sure that it's not",
            "\t\t * below the concurrently-changing counter value.",
            "\t\t *",
            "\t\t * The xchg implies two full memory barriers before",
            "\t\t * and after, so the read-swap-read is ordered and",
            "\t\t * ensures coherency with page_counter_try_charge():",
            "\t\t * that function modifies the count before checking",
            "\t\t * the limit, so if it sees the old limit, we see the",
            "\t\t * modified counter and retry.",
            "\t\t */",
            "\t\tusage = page_counter_read(counter);",
            "",
            "\t\tif (usage > nr_pages)",
            "\t\t\treturn -EBUSY;",
            "",
            "\t\told = xchg(&counter->max, nr_pages);",
            "",
            "\t\tif (page_counter_read(counter) <= usage || nr_pages >= old)",
            "\t\t\treturn 0;",
            "",
            "\t\tcounter->max = old;",
            "\t\tcond_resched();",
            "\t}",
            "}",
            "void page_counter_set_min(struct page_counter *counter, unsigned long nr_pages)",
            "{",
            "\tstruct page_counter *c;",
            "",
            "\tWRITE_ONCE(counter->min, nr_pages);",
            "",
            "\tfor (c = counter; c; c = c->parent)",
            "\t\tpropagate_protected_usage(c, atomic_long_read(&c->usage));",
            "}",
            "void page_counter_set_low(struct page_counter *counter, unsigned long nr_pages)",
            "{",
            "\tstruct page_counter *c;",
            "",
            "\tWRITE_ONCE(counter->low, nr_pages);",
            "",
            "\tfor (c = counter; c; c = c->parent)",
            "\t\tpropagate_protected_usage(c, atomic_long_read(&c->usage));",
            "}",
            "int page_counter_memparse(const char *buf, const char *max,",
            "\t\t\t  unsigned long *nr_pages)",
            "{",
            "\tchar *end;",
            "\tu64 bytes;",
            "",
            "\tif (!strcmp(buf, max)) {",
            "\t\t*nr_pages = PAGE_COUNTER_MAX;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tbytes = memparse(buf, &end);",
            "\tif (*end != '\\0')",
            "\t\treturn -EINVAL;",
            "",
            "\t*nr_pages = min(bytes / PAGE_SIZE, (u64)PAGE_COUNTER_MAX);",
            "",
            "\treturn 0;",
            "}",
            "static unsigned long effective_protection(unsigned long usage,",
            "\t\t\t\t\t  unsigned long parent_usage,",
            "\t\t\t\t\t  unsigned long setting,",
            "\t\t\t\t\t  unsigned long parent_effective,",
            "\t\t\t\t\t  unsigned long siblings_protected,",
            "\t\t\t\t\t  bool recursive_protection)",
            "{",
            "\tunsigned long protected;",
            "\tunsigned long ep;",
            "",
            "\tprotected = min(usage, setting);",
            "\t/*",
            "\t * If all cgroups at this level combined claim and use more",
            "\t * protection than what the parent affords them, distribute",
            "\t * shares in proportion to utilization.",
            "\t *",
            "\t * We are using actual utilization rather than the statically",
            "\t * claimed protection in order to be work-conserving: claimed",
            "\t * but unused protection is available to siblings that would",
            "\t * otherwise get a smaller chunk than what they claimed.",
            "\t */",
            "\tif (siblings_protected > parent_effective)",
            "\t\treturn protected * parent_effective / siblings_protected;",
            "",
            "\t/*",
            "\t * Ok, utilized protection of all children is within what the",
            "\t * parent affords them, so we know whatever this child claims",
            "\t * and utilizes is effectively protected.",
            "\t *",
            "\t * If there is unprotected usage beyond this value, reclaim",
            "\t * will apply pressure in proportion to that amount.",
            "\t *",
            "\t * If there is unutilized protection, the cgroup will be fully",
            "\t * shielded from reclaim, but we do return a smaller value for",
            "\t * protection than what the group could enjoy in theory. This",
            "\t * is okay. With the overcommit distribution above, effective",
            "\t * protection is always dependent on how memory is actually",
            "\t * consumed among the siblings anyway.",
            "\t */",
            "\tep = protected;",
            "",
            "\t/*",
            "\t * If the children aren't claiming (all of) the protection",
            "\t * afforded to them by the parent, distribute the remainder in",
            "\t * proportion to the (unprotected) memory of each cgroup. That",
            "\t * way, cgroups that aren't explicitly prioritized wrt each",
            "\t * other compete freely over the allowance, but they are",
            "\t * collectively protected from neighboring trees.",
            "\t *",
            "\t * We're using unprotected memory for the weight so that if",
            "\t * some cgroups DO claim explicit protection, we don't protect",
            "\t * the same bytes twice.",
            "\t *",
            "\t * Check both usage and parent_usage against the respective",
            "\t * protected values. One should imply the other, but they",
            "\t * aren't read atomically - make sure the division is sane.",
            "\t */",
            "\tif (!recursive_protection)",
            "\t\treturn ep;",
            "",
            "\tif (parent_effective > siblings_protected &&",
            "\t    parent_usage > siblings_protected &&",
            "\t    usage > protected) {",
            "\t\tunsigned long unclaimed;",
            "",
            "\t\tunclaimed = parent_effective - siblings_protected;",
            "\t\tunclaimed *= usage - protected;",
            "\t\tunclaimed /= parent_usage - siblings_protected;",
            "",
            "\t\tep += unclaimed;",
            "\t}",
            "",
            "\treturn ep;",
            "}"
          ],
          "function_name": "page_counter_uncharge, page_counter_set_max, page_counter_set_min, page_counter_set_low, page_counter_memparse, effective_protection",
          "description": "提供计数器阈值配置接口及内存参数解析，包含最大值设置、最小/低水位线更新和有效保护计算，实现基于实际使用情况的动态保护分配算法。",
          "similarity": 0.4260026514530182
        },
        {
          "chunk_id": 3,
          "file_path": "mm/page_counter.c",
          "start_line": 409,
          "end_line": 449,
          "content": [
            "void page_counter_calculate_protection(struct page_counter *root,",
            "\t\t\t\t       struct page_counter *counter,",
            "\t\t\t\t       bool recursive_protection)",
            "{",
            "\tunsigned long usage, parent_usage;",
            "\tstruct page_counter *parent = counter->parent;",
            "",
            "\t/*",
            "\t * Effective values of the reclaim targets are ignored so they",
            "\t * can be stale. Have a look at mem_cgroup_protection for more",
            "\t * details.",
            "\t * TODO: calculation should be more robust so that we do not need",
            "\t * that special casing.",
            "\t */",
            "\tif (root == counter)",
            "\t\treturn;",
            "",
            "\tusage = page_counter_read(counter);",
            "\tif (!usage)",
            "\t\treturn;",
            "",
            "\tif (parent == root) {",
            "\t\tcounter->emin = READ_ONCE(counter->min);",
            "\t\tcounter->elow = READ_ONCE(counter->low);",
            "\t\treturn;",
            "\t}",
            "",
            "\tparent_usage = page_counter_read(parent);",
            "",
            "\tWRITE_ONCE(counter->emin, effective_protection(usage, parent_usage,",
            "\t\t\tREAD_ONCE(counter->min),",
            "\t\t\tREAD_ONCE(parent->emin),",
            "\t\t\tatomic_long_read(&parent->children_min_usage),",
            "\t\t\trecursive_protection));",
            "",
            "\tWRITE_ONCE(counter->elow, effective_protection(usage, parent_usage,",
            "\t\t\tREAD_ONCE(counter->low),",
            "\t\t\tREAD_ONCE(parent->elow),",
            "\t\t\tatomic_long_read(&parent->children_low_usage),",
            "\t\t\trecursive_protection));",
            "}"
          ],
          "function_name": "page_counter_calculate_protection",
          "description": "计算并设置计数器的有效保护值，通过递归遍历层级关系，结合父级保护策略和当前使用比例，动态调整子级的最小/低水位线保护范围。",
          "similarity": 0.39312469959259033
        }
      ]
    },
    {
      "source_file": "mm/hugetlb_cgroup.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:06:55\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `hugetlb_cgroup.c`\n\n---\n\n# hugetlb_cgroup.c 技术文档\n\n## 1. 文件概述\n\n`hugetlb_cgroup.c` 是 Linux 内核中用于实现 **HugeTLB（大页）内存资源控制组（cgroup）** 功能的核心文件。该文件通过 cgroup v1/v2 接口，对不同 HugeTLB 页面大小（如 2MB、1GB 等）的内存使用进行配额限制和统计追踪。它支持两种计费模式：普通分配（fault-based）和预留（reservation-based），并确保在 cgroup 被销毁时将资源正确迁移至父 cgroup，防止资源泄漏。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct hugetlb_cgroup`：每个 cgroup 实例对应的 HugeTLB 控制结构。\n  - 包含两个 `page_counter` 数组：`hugepage[]`（普通使用）和 `rsvd_hugepage[]`（预留使用），分别对应每种 HugeTLB 页面类型。\n  - 包含 per-node 信息 `nodeinfo[]`，用于 NUMA 感知。\n  - 包含事件计数器 `events[][]` 和 `events_local[][]`，用于触发 cgroup 通知。\n- `struct hugetlb_cgroup_per_node`：每个 NUMA 节点上的 HugeTLB cgroup 附加信息（当前未在代码片段中完整定义）。\n\n### 主要函数\n- `hugetlb_cgroup_css_alloc()` / `hugetlb_cgroup_css_free()`：cgroup 子系统实例的创建与销毁。\n- `hugetlb_cgroup_init()`：初始化新 cgroup 的 page_counter，设置最大限制为 `PAGE_COUNTER_MAX` 向下对齐到 HugeTLB 页面大小。\n- `__hugetlb_cgroup_charge_cgroup()` / `hugetlb_cgroup_charge_cgroup()`：对当前任务所属 cgroup 尝试 charge（计费）指定数量的 HugeTLB 页面。\n- `hugetlb_cgroup_move_parent()`：将属于某 cgroup 的 HugeTLB 页面迁移至其父 cgroup。\n- `hugetlb_cgroup_css_offline()`：在 cgroup 离线时，强制将其所有 HugeTLB 资源迁移至父级。\n- `hugetlb_event()`：向上冒泡记录 HugeTLB 事件（如达到限制 `HUGETLB_MAX`）并触发 cgroup 文件通知。\n- 辅助内联函数：\n  - `hugetlb_cgroup_from_css()` / `from_task()`：从 cgroup_subsys_state 或 task 获取 hugetlb_cgroup。\n  - `hugetlb_cgroup_counter_from_cgroup()` / `_rsvd()`：获取对应计费类型的 page_counter。\n  - `hugetlb_cgroup_is_root()` / `parent_hugetlb_cgroup()`：判断是否为根 cgroup 或获取父 cgroup。\n\n## 3. 关键实现\n\n### 资源计费机制\n- 使用 `page_counter` 子系统管理每种 HugeTLB 页面类型的用量和上限。\n- 支持两种独立的计费路径：\n  - **普通分配（fault）**：实际分配物理页面时计费。\n  - **预留（reservation）**：仅预留虚拟地址空间时计费（用于 mmap 等场景）。\n- 计费时通过 RCU 安全地获取当前任务的 cgroup，并使用 `css_tryget()` 确保引用有效性。\n- 若计费失败（超出限制），触发 `HUGETLB_MAX` 事件并通过 `cgroup_file_notify()` 通知用户空间。\n\n### cgroup 生命周期管理\n- **创建**：为每个在线 NUMA 节点分配 `hugetlb_cgroup_per_node` 结构；初始化所有 HugeTLB 类型的 page_counter，父子层级通过 `page_counter` 的 parent 字段建立级联关系。\n- **离线（offline）**：遍历所有 HugeTLB 页面的 active list，调用 `hugetlb_cgroup_move_parent()` 将页面所有权转移给父 cgroup。此过程循环执行直至当前 cgroup 无任何 HugeTLB 使用量，确保资源完全迁移。\n- **销毁**：释放 per-node 数据及主结构体。\n\n### 资源迁移（Reparenting）\n- `hugetlb_cgroup_move_parent()` 在持有 `hugetlb_lock` 时执行，确保页面不会被并发释放或迁移。\n- 仅处理属于目标 cgroup 的页面；若父 cgroup 为空（即目标为根），则 charge 到全局 root cgroup（无硬限制）。\n- 通过 `set_hugetlb_cgroup()` 更新页面所属的 cgroup。\n\n### 限制与优化\n- 对于 order 小于 `HUGETLB_CGROUP_MIN_ORDER`（通常为 3，即 8 个普通页 = 32KB）的 HugeTLB 页面，**不进行 cgroup 计费**，以减少小 HugeTLB 页面的开销。\n- 最大限制设为 `PAGE_COUNTER_MAX` 向下对齐到 HugeTLB 页面大小，避免跨页边界问题。\n- 当前 per-node 分配策略对 offline 节点也分配内存（使用 `NUMA_NO_NODE`），存在内存浪费，注释中指出未来可通过内存热插拔回调优化。\n\n## 4. 依赖关系\n\n- **核心依赖**：\n  - `<linux/cgroup.h>`：cgroup 基础框架。\n  - `<linux/page_counter.h>`：提供层次化内存计数和限制功能。\n  - `<linux/hugetlb.h>`：HugeTLB 核心数据结构（如 `hstate`, `hugepage_activelist`）和锁（`hugetlb_lock`）。\n  - `<linux/hugetlb_cgroup.h>`：HugeTLB cgroup 的公共接口和数据结构定义。\n- **交互模块**：\n  - **HugeTLB 子系统**：在页面分配/释放、预留/取消预留等路径中调用本文件的 charge/uncharge 函数。\n  - **Memory cgroup (memcg)**：共享部分设计思想（如 page_counter），但 HugeTLB cgroup 是独立子系统。\n  - **Scheduler**：通过 `current` 获取当前任务的 cgroup 上下文。\n\n## 5. 使用场景\n\n- **容器资源隔离**：在 Kubernetes/Docker 等容器运行时中，通过 cgroup v1 的 `hugetlb` 子系统或 cgroup v2 的 `hugetlb.` 控制器，限制容器可使用的 HugeTLB 内存总量，防止单个容器耗尽系统大页资源。\n- **高性能计算（HPC）**：为不同 HPC 作业分配专用的 HugeTLB 内存配额，确保关键应用获得确定性内存性能。\n- **数据库优化**：Oracle、MySQL 等数据库使用 HugeTLB 提升 TLB 效率，通过 cgroup 限制其大页使用量，避免影响其他服务。\n- **资源监控与告警**：用户空间可通过读取 cgroup 的 `hugetlb.events` 文件监控 `max` 事件，实现基于 HugeTLB 使用量的自动扩缩容或告警。",
      "similarity": 0.5576204061508179,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 242,
          "end_line": 368,
          "content": [
            "static inline void hugetlb_event(struct hugetlb_cgroup *hugetlb, int idx,",
            "\t\t\t\t enum hugetlb_memory_event event)",
            "{",
            "\tatomic_long_inc(&hugetlb->events_local[idx][event]);",
            "\tcgroup_file_notify(&hugetlb->events_local_file[idx]);",
            "",
            "\tdo {",
            "\t\tatomic_long_inc(&hugetlb->events[idx][event]);",
            "\t\tcgroup_file_notify(&hugetlb->events_file[idx]);",
            "\t} while ((hugetlb = parent_hugetlb_cgroup(hugetlb)) &&",
            "\t\t !hugetlb_cgroup_is_root(hugetlb));",
            "}",
            "static int __hugetlb_cgroup_charge_cgroup(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t  struct hugetlb_cgroup **ptr,",
            "\t\t\t\t\t  bool rsvd)",
            "{",
            "\tint ret = 0;",
            "\tstruct page_counter *counter;",
            "\tstruct hugetlb_cgroup *h_cg = NULL;",
            "",
            "\tif (hugetlb_cgroup_disabled())",
            "\t\tgoto done;",
            "\t/*",
            "\t * We don't charge any cgroup if the compound page have less",
            "\t * than 3 pages.",
            "\t */",
            "\tif (huge_page_order(&hstates[idx]) < HUGETLB_CGROUP_MIN_ORDER)",
            "\t\tgoto done;",
            "again:",
            "\trcu_read_lock();",
            "\th_cg = hugetlb_cgroup_from_task(current);",
            "\tif (!css_tryget(&h_cg->css)) {",
            "\t\trcu_read_unlock();",
            "\t\tgoto again;",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\tif (!page_counter_try_charge(",
            "\t\t    __hugetlb_cgroup_counter_from_cgroup(h_cg, idx, rsvd),",
            "\t\t    nr_pages, &counter)) {",
            "\t\tret = -ENOMEM;",
            "\t\thugetlb_event(h_cg, idx, HUGETLB_MAX);",
            "\t\tcss_put(&h_cg->css);",
            "\t\tgoto done;",
            "\t}",
            "\t/* Reservations take a reference to the css because they do not get",
            "\t * reparented.",
            "\t */",
            "\tif (!rsvd)",
            "\t\tcss_put(&h_cg->css);",
            "done:",
            "\t*ptr = h_cg;",
            "\treturn ret;",
            "}",
            "int hugetlb_cgroup_charge_cgroup(int idx, unsigned long nr_pages,",
            "\t\t\t\t struct hugetlb_cgroup **ptr)",
            "{",
            "\treturn __hugetlb_cgroup_charge_cgroup(idx, nr_pages, ptr, false);",
            "}",
            "int hugetlb_cgroup_charge_cgroup_rsvd(int idx, unsigned long nr_pages,",
            "\t\t\t\t      struct hugetlb_cgroup **ptr)",
            "{",
            "\treturn __hugetlb_cgroup_charge_cgroup(idx, nr_pages, ptr, true);",
            "}",
            "static void __hugetlb_cgroup_commit_charge(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t   struct hugetlb_cgroup *h_cg,",
            "\t\t\t\t\t   struct folio *folio, bool rsvd)",
            "{",
            "\tif (hugetlb_cgroup_disabled() || !h_cg)",
            "\t\treturn;",
            "",
            "\t__set_hugetlb_cgroup(folio, h_cg, rsvd);",
            "\tif (!rsvd) {",
            "\t\tunsigned long usage =",
            "\t\t\th_cg->nodeinfo[folio_nid(folio)]->usage[idx];",
            "\t\t/*",
            "\t\t * This write is not atomic due to fetching usage and writing",
            "\t\t * to it, but that's fine because we call this with",
            "\t\t * hugetlb_lock held anyway.",
            "\t\t */",
            "\t\tWRITE_ONCE(h_cg->nodeinfo[folio_nid(folio)]->usage[idx],",
            "\t\t\t   usage + nr_pages);",
            "\t}",
            "}",
            "void hugetlb_cgroup_commit_charge(int idx, unsigned long nr_pages,",
            "\t\t\t\t  struct hugetlb_cgroup *h_cg,",
            "\t\t\t\t  struct folio *folio)",
            "{",
            "\t__hugetlb_cgroup_commit_charge(idx, nr_pages, h_cg, folio, false);",
            "}",
            "void hugetlb_cgroup_commit_charge_rsvd(int idx, unsigned long nr_pages,",
            "\t\t\t\t       struct hugetlb_cgroup *h_cg,",
            "\t\t\t\t       struct folio *folio)",
            "{",
            "\t__hugetlb_cgroup_commit_charge(idx, nr_pages, h_cg, folio, true);",
            "}",
            "static void __hugetlb_cgroup_uncharge_folio(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t   struct folio *folio, bool rsvd)",
            "{",
            "\tstruct hugetlb_cgroup *h_cg;",
            "",
            "\tif (hugetlb_cgroup_disabled())",
            "\t\treturn;",
            "\tlockdep_assert_held(&hugetlb_lock);",
            "\th_cg = __hugetlb_cgroup_from_folio(folio, rsvd);",
            "\tif (unlikely(!h_cg))",
            "\t\treturn;",
            "\t__set_hugetlb_cgroup(folio, NULL, rsvd);",
            "",
            "\tpage_counter_uncharge(__hugetlb_cgroup_counter_from_cgroup(h_cg, idx,",
            "\t\t\t\t\t\t\t\t   rsvd),",
            "\t\t\t      nr_pages);",
            "",
            "\tif (rsvd)",
            "\t\tcss_put(&h_cg->css);",
            "\telse {",
            "\t\tunsigned long usage =",
            "\t\t\th_cg->nodeinfo[folio_nid(folio)]->usage[idx];",
            "\t\t/*",
            "\t\t * This write is not atomic due to fetching usage and writing",
            "\t\t * to it, but that's fine because we call this with",
            "\t\t * hugetlb_lock held anyway.",
            "\t\t */",
            "\t\tWRITE_ONCE(h_cg->nodeinfo[folio_nid(folio)]->usage[idx],",
            "\t\t\t   usage - nr_pages);",
            "\t}",
            "}"
          ],
          "function_name": "hugetlb_event, __hugetlb_cgroup_charge_cgroup, hugetlb_cgroup_charge_cgroup, hugetlb_cgroup_charge_cgroup_rsvd, __hugetlb_cgroup_commit_charge, hugetlb_cgroup_commit_charge, hugetlb_cgroup_commit_charge_rsvd, __hugetlb_cgroup_uncharge_folio",
          "description": "处理HugeTLB页面分配时的计费操作，包含事件记录、尝试充电、提交充电等流程，区分普通页与保留页的计数逻辑，并维护各层级cgroup的使用统计。",
          "similarity": 0.4925370216369629
        },
        {
          "chunk_id": 4,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 520,
          "end_line": 626,
          "content": [
            "static u64 hugetlb_cgroup_read_u64(struct cgroup_subsys_state *css,",
            "\t\t\t\t   struct cftype *cft)",
            "{",
            "\tstruct page_counter *counter;",
            "\tstruct page_counter *rsvd_counter;",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(css);",
            "",
            "\tcounter = &h_cg->hugepage[MEMFILE_IDX(cft->private)];",
            "\trsvd_counter = &h_cg->rsvd_hugepage[MEMFILE_IDX(cft->private)];",
            "",
            "\tswitch (MEMFILE_ATTR(cft->private)) {",
            "\tcase RES_USAGE:",
            "\t\treturn (u64)page_counter_read(counter) * PAGE_SIZE;",
            "\tcase RES_RSVD_USAGE:",
            "\t\treturn (u64)page_counter_read(rsvd_counter) * PAGE_SIZE;",
            "\tcase RES_LIMIT:",
            "\t\treturn (u64)counter->max * PAGE_SIZE;",
            "\tcase RES_RSVD_LIMIT:",
            "\t\treturn (u64)rsvd_counter->max * PAGE_SIZE;",
            "\tcase RES_MAX_USAGE:",
            "\t\treturn (u64)counter->watermark * PAGE_SIZE;",
            "\tcase RES_RSVD_MAX_USAGE:",
            "\t\treturn (u64)rsvd_counter->watermark * PAGE_SIZE;",
            "\tcase RES_FAILCNT:",
            "\t\treturn counter->failcnt;",
            "\tcase RES_RSVD_FAILCNT:",
            "\t\treturn rsvd_counter->failcnt;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "}",
            "static int hugetlb_cgroup_read_u64_max(struct seq_file *seq, void *v)",
            "{",
            "\tint idx;",
            "\tu64 val;",
            "\tstruct cftype *cft = seq_cft(seq);",
            "\tunsigned long limit;",
            "\tstruct page_counter *counter;",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(seq_css(seq));",
            "",
            "\tidx = MEMFILE_IDX(cft->private);",
            "\tcounter = &h_cg->hugepage[idx];",
            "",
            "\tlimit = round_down(PAGE_COUNTER_MAX,",
            "\t\t\t   pages_per_huge_page(&hstates[idx]));",
            "",
            "\tswitch (MEMFILE_ATTR(cft->private)) {",
            "\tcase RES_RSVD_USAGE:",
            "\t\tcounter = &h_cg->rsvd_hugepage[idx];",
            "\t\tfallthrough;",
            "\tcase RES_USAGE:",
            "\t\tval = (u64)page_counter_read(counter);",
            "\t\tseq_printf(seq, \"%llu\\n\", val * PAGE_SIZE);",
            "\t\tbreak;",
            "\tcase RES_RSVD_LIMIT:",
            "\t\tcounter = &h_cg->rsvd_hugepage[idx];",
            "\t\tfallthrough;",
            "\tcase RES_LIMIT:",
            "\t\tval = (u64)counter->max;",
            "\t\tif (val == limit)",
            "\t\t\tseq_puts(seq, \"max\\n\");",
            "\t\telse",
            "\t\t\tseq_printf(seq, \"%llu\\n\", val * PAGE_SIZE);",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static ssize_t hugetlb_cgroup_write(struct kernfs_open_file *of,",
            "\t\t\t\t    char *buf, size_t nbytes, loff_t off,",
            "\t\t\t\t    const char *max)",
            "{",
            "\tint ret, idx;",
            "\tunsigned long nr_pages;",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(of_css(of));",
            "\tbool rsvd = false;",
            "",
            "\tif (hugetlb_cgroup_is_root(h_cg)) /* Can't set limit on root */",
            "\t\treturn -EINVAL;",
            "",
            "\tbuf = strstrip(buf);",
            "\tret = page_counter_memparse(buf, max, &nr_pages);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tidx = MEMFILE_IDX(of_cft(of)->private);",
            "\tnr_pages = round_down(nr_pages, pages_per_huge_page(&hstates[idx]));",
            "",
            "\tswitch (MEMFILE_ATTR(of_cft(of)->private)) {",
            "\tcase RES_RSVD_LIMIT:",
            "\t\trsvd = true;",
            "\t\tfallthrough;",
            "\tcase RES_LIMIT:",
            "\t\tmutex_lock(&hugetlb_limit_mutex);",
            "\t\tret = page_counter_set_max(",
            "\t\t\t__hugetlb_cgroup_counter_from_cgroup(h_cg, idx, rsvd),",
            "\t\t\tnr_pages);",
            "\t\tmutex_unlock(&hugetlb_limit_mutex);",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tret = -EINVAL;",
            "\t\tbreak;",
            "\t}",
            "\treturn ret ?: nbytes;",
            "}"
          ],
          "function_name": "hugetlb_cgroup_read_u64, hugetlb_cgroup_read_u64_max, hugetlb_cgroup_write",
          "description": "提供HugeTLB cgroup的监控接口，实现读取当前使用量、限制等参数的功能，并支持通过接口设置内存限制参数。",
          "similarity": 0.4868055582046509
        },
        {
          "chunk_id": 5,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 632,
          "end_line": 766,
          "content": [
            "static ssize_t hugetlb_cgroup_write_legacy(struct kernfs_open_file *of,",
            "\t\t\t\t\t   char *buf, size_t nbytes, loff_t off)",
            "{",
            "\treturn hugetlb_cgroup_write(of, buf, nbytes, off, \"-1\");",
            "}",
            "static ssize_t hugetlb_cgroup_write_dfl(struct kernfs_open_file *of,",
            "\t\t\t\t\tchar *buf, size_t nbytes, loff_t off)",
            "{",
            "\treturn hugetlb_cgroup_write(of, buf, nbytes, off, \"max\");",
            "}",
            "static ssize_t hugetlb_cgroup_reset(struct kernfs_open_file *of,",
            "\t\t\t\t    char *buf, size_t nbytes, loff_t off)",
            "{",
            "\tint ret = 0;",
            "\tstruct page_counter *counter, *rsvd_counter;",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(of_css(of));",
            "",
            "\tcounter = &h_cg->hugepage[MEMFILE_IDX(of_cft(of)->private)];",
            "\trsvd_counter = &h_cg->rsvd_hugepage[MEMFILE_IDX(of_cft(of)->private)];",
            "",
            "\tswitch (MEMFILE_ATTR(of_cft(of)->private)) {",
            "\tcase RES_MAX_USAGE:",
            "\t\tpage_counter_reset_watermark(counter);",
            "\t\tbreak;",
            "\tcase RES_RSVD_MAX_USAGE:",
            "\t\tpage_counter_reset_watermark(rsvd_counter);",
            "\t\tbreak;",
            "\tcase RES_FAILCNT:",
            "\t\tcounter->failcnt = 0;",
            "\t\tbreak;",
            "\tcase RES_RSVD_FAILCNT:",
            "\t\trsvd_counter->failcnt = 0;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tret = -EINVAL;",
            "\t\tbreak;",
            "\t}",
            "\treturn ret ?: nbytes;",
            "}",
            "static int __hugetlb_events_show(struct seq_file *seq, bool local)",
            "{",
            "\tint idx;",
            "\tlong max;",
            "\tstruct cftype *cft = seq_cft(seq);",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(seq_css(seq));",
            "",
            "\tidx = MEMFILE_IDX(cft->private);",
            "",
            "\tif (local)",
            "\t\tmax = atomic_long_read(&h_cg->events_local[idx][HUGETLB_MAX]);",
            "\telse",
            "\t\tmax = atomic_long_read(&h_cg->events[idx][HUGETLB_MAX]);",
            "",
            "\tseq_printf(seq, \"max %lu\\n\", max);",
            "",
            "\treturn 0;",
            "}",
            "static int hugetlb_events_show(struct seq_file *seq, void *v)",
            "{",
            "\treturn __hugetlb_events_show(seq, false);",
            "}",
            "static int hugetlb_events_local_show(struct seq_file *seq, void *v)",
            "{",
            "\treturn __hugetlb_events_show(seq, true);",
            "}",
            "static void __init __hugetlb_cgroup_file_dfl_init(int idx)",
            "{",
            "\tchar buf[32];",
            "\tstruct cftype *cft;",
            "\tstruct hstate *h = &hstates[idx];",
            "",
            "\t/* format the size */",
            "\tmem_fmt(buf, sizeof(buf), huge_page_size(h));",
            "",
            "\t/* Add the limit file */",
            "\tcft = &h->cgroup_files_dfl[0];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.max\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_LIMIT);",
            "\tcft->seq_show = hugetlb_cgroup_read_u64_max;",
            "\tcft->write = hugetlb_cgroup_write_dfl;",
            "\tcft->flags = CFTYPE_NOT_ON_ROOT;",
            "",
            "\t/* Add the reservation limit file */",
            "\tcft = &h->cgroup_files_dfl[1];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.max\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_LIMIT);",
            "\tcft->seq_show = hugetlb_cgroup_read_u64_max;",
            "\tcft->write = hugetlb_cgroup_write_dfl;",
            "\tcft->flags = CFTYPE_NOT_ON_ROOT;",
            "",
            "\t/* Add the current usage file */",
            "\tcft = &h->cgroup_files_dfl[2];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.current\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_USAGE);",
            "\tcft->seq_show = hugetlb_cgroup_read_u64_max;",
            "\tcft->flags = CFTYPE_NOT_ON_ROOT;",
            "",
            "\t/* Add the current reservation usage file */",
            "\tcft = &h->cgroup_files_dfl[3];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.current\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_USAGE);",
            "\tcft->seq_show = hugetlb_cgroup_read_u64_max;",
            "\tcft->flags = CFTYPE_NOT_ON_ROOT;",
            "",
            "\t/* Add the events file */",
            "\tcft = &h->cgroup_files_dfl[4];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.events\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, 0);",
            "\tcft->seq_show = hugetlb_events_show;",
            "\tcft->file_offset = offsetof(struct hugetlb_cgroup, events_file[idx]);",
            "\tcft->flags = CFTYPE_NOT_ON_ROOT;",
            "",
            "\t/* Add the events.local file */",
            "\tcft = &h->cgroup_files_dfl[5];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.events.local\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, 0);",
            "\tcft->seq_show = hugetlb_events_local_show;",
            "\tcft->file_offset = offsetof(struct hugetlb_cgroup,",
            "\t\t\t\t    events_local_file[idx]);",
            "\tcft->flags = CFTYPE_NOT_ON_ROOT;",
            "",
            "\t/* Add the numa stat file */",
            "\tcft = &h->cgroup_files_dfl[6];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.numa_stat\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, 0);",
            "\tcft->seq_show = hugetlb_cgroup_read_numa_stat;",
            "\tcft->flags = CFTYPE_NOT_ON_ROOT;",
            "",
            "\t/* NULL terminate the last cft */",
            "\tcft = &h->cgroup_files_dfl[7];",
            "\tmemset(cft, 0, sizeof(*cft));",
            "",
            "\tWARN_ON(cgroup_add_dfl_cftypes(&hugetlb_cgrp_subsys,",
            "\t\t\t\t       h->cgroup_files_dfl));",
            "}"
          ],
          "function_name": "hugetlb_cgroup_write_legacy, hugetlb_cgroup_write_dfl, hugetlb_cgroup_reset, __hugetlb_events_show, hugetlb_events_show, hugetlb_events_local_show, __hugetlb_cgroup_file_dfl_init",
          "description": "定义并实现hugetlb cgroup的写操作函数，其中hugetlb_cgroup_write_legacy和hugetlb_cgroup_write_dfl分别处理传统模式和默认模式下的资源限制设置，hugetlb_cgroup_reset重置特定资源计数器的水位线，__hugetlb_cgroup_file_dfl_init初始化默认模式下的cgroup控制文件及事件统计接口",
          "similarity": 0.4701874852180481
        },
        {
          "chunk_id": 6,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 785,
          "end_line": 901,
          "content": [
            "static void __init __hugetlb_cgroup_file_legacy_init(int idx)",
            "{",
            "\tchar buf[32];",
            "\tstruct cftype *cft;",
            "\tstruct hstate *h = &hstates[idx];",
            "",
            "\t/* format the size */",
            "\tmem_fmt(buf, sizeof(buf), huge_page_size(h));",
            "",
            "\t/* Add the limit file */",
            "\tcft = &h->cgroup_files_legacy[0];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.limit_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_LIMIT);",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "\tcft->write = hugetlb_cgroup_write_legacy;",
            "",
            "\t/* Add the reservation limit file */",
            "\tcft = &h->cgroup_files_legacy[1];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.limit_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_LIMIT);",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "\tcft->write = hugetlb_cgroup_write_legacy;",
            "",
            "\t/* Add the usage file */",
            "\tcft = &h->cgroup_files_legacy[2];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.usage_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_USAGE);",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the reservation usage file */",
            "\tcft = &h->cgroup_files_legacy[3];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.usage_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_USAGE);",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the MAX usage file */",
            "\tcft = &h->cgroup_files_legacy[4];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.max_usage_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_MAX_USAGE);",
            "\tcft->write = hugetlb_cgroup_reset;",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the MAX reservation usage file */",
            "\tcft = &h->cgroup_files_legacy[5];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.max_usage_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_MAX_USAGE);",
            "\tcft->write = hugetlb_cgroup_reset;",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the failcntfile */",
            "\tcft = &h->cgroup_files_legacy[6];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.failcnt\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_FAILCNT);",
            "\tcft->write = hugetlb_cgroup_reset;",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the reservation failcntfile */",
            "\tcft = &h->cgroup_files_legacy[7];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.failcnt\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_FAILCNT);",
            "\tcft->write = hugetlb_cgroup_reset;",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the numa stat file */",
            "\tcft = &h->cgroup_files_legacy[8];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.numa_stat\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, 1);",
            "\tcft->seq_show = hugetlb_cgroup_read_numa_stat;",
            "",
            "\t/* NULL terminate the last cft */",
            "\tcft = &h->cgroup_files_legacy[9];",
            "\tmemset(cft, 0, sizeof(*cft));",
            "",
            "\tWARN_ON(cgroup_add_legacy_cftypes(&hugetlb_cgrp_subsys,",
            "\t\t\t\t\t  h->cgroup_files_legacy));",
            "}",
            "static void __init __hugetlb_cgroup_file_init(int idx)",
            "{",
            "\t__hugetlb_cgroup_file_dfl_init(idx);",
            "\t__hugetlb_cgroup_file_legacy_init(idx);",
            "}",
            "void __init hugetlb_cgroup_file_init(void)",
            "{",
            "\tstruct hstate *h;",
            "",
            "\tfor_each_hstate(h) {",
            "\t\t/*",
            "\t\t * Add cgroup control files only if the huge page consists",
            "\t\t * of more than two normal pages. This is because we use",
            "\t\t * page[2].private for storing cgroup details.",
            "\t\t */",
            "\t\tif (huge_page_order(h) >= HUGETLB_CGROUP_MIN_ORDER)",
            "\t\t\t__hugetlb_cgroup_file_init(hstate_index(h));",
            "\t}",
            "}",
            "void hugetlb_cgroup_migrate(struct folio *old_folio, struct folio *new_folio)",
            "{",
            "\tstruct hugetlb_cgroup *h_cg;",
            "\tstruct hugetlb_cgroup *h_cg_rsvd;",
            "\tstruct hstate *h = folio_hstate(old_folio);",
            "",
            "\tif (hugetlb_cgroup_disabled())",
            "\t\treturn;",
            "",
            "\tspin_lock_irq(&hugetlb_lock);",
            "\th_cg = hugetlb_cgroup_from_folio(old_folio);",
            "\th_cg_rsvd = hugetlb_cgroup_from_folio_rsvd(old_folio);",
            "\tset_hugetlb_cgroup(old_folio, NULL);",
            "\tset_hugetlb_cgroup_rsvd(old_folio, NULL);",
            "",
            "\t/* move the h_cg details to new cgroup */",
            "\tset_hugetlb_cgroup(new_folio, h_cg);",
            "\tset_hugetlb_cgroup_rsvd(new_folio, h_cg_rsvd);",
            "\tlist_move(&new_folio->lru, &h->hugepage_activelist);",
            "\tspin_unlock_irq(&hugetlb_lock);",
            "\treturn;",
            "}"
          ],
          "function_name": "__hugetlb_cgroup_file_legacy_init, __hugetlb_cgroup_file_init, hugetlb_cgroup_file_init, hugetlb_cgroup_migrate",
          "description": "初始化传统模式下的hugetlb cgroup文件系统接口，包含限额、使用量、最大使用量等监控文件，并实现页面迁移时的cgroup上下文切换逻辑，通过hugetlb_cgroup_migrate维护huge页面与cgroup的关联关系",
          "similarity": 0.4684099555015564
        },
        {
          "chunk_id": 3,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 381,
          "end_line": 500,
          "content": [
            "void hugetlb_cgroup_uncharge_folio(int idx, unsigned long nr_pages,",
            "\t\t\t\t  struct folio *folio)",
            "{",
            "\t__hugetlb_cgroup_uncharge_folio(idx, nr_pages, folio, false);",
            "}",
            "void hugetlb_cgroup_uncharge_folio_rsvd(int idx, unsigned long nr_pages,",
            "\t\t\t\t       struct folio *folio)",
            "{",
            "\t__hugetlb_cgroup_uncharge_folio(idx, nr_pages, folio, true);",
            "}",
            "static void __hugetlb_cgroup_uncharge_cgroup(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t     struct hugetlb_cgroup *h_cg,",
            "\t\t\t\t\t     bool rsvd)",
            "{",
            "\tif (hugetlb_cgroup_disabled() || !h_cg)",
            "\t\treturn;",
            "",
            "\tif (huge_page_order(&hstates[idx]) < HUGETLB_CGROUP_MIN_ORDER)",
            "\t\treturn;",
            "",
            "\tpage_counter_uncharge(__hugetlb_cgroup_counter_from_cgroup(h_cg, idx,",
            "\t\t\t\t\t\t\t\t   rsvd),",
            "\t\t\t      nr_pages);",
            "",
            "\tif (rsvd)",
            "\t\tcss_put(&h_cg->css);",
            "}",
            "void hugetlb_cgroup_uncharge_cgroup(int idx, unsigned long nr_pages,",
            "\t\t\t\t    struct hugetlb_cgroup *h_cg)",
            "{",
            "\t__hugetlb_cgroup_uncharge_cgroup(idx, nr_pages, h_cg, false);",
            "}",
            "void hugetlb_cgroup_uncharge_cgroup_rsvd(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t struct hugetlb_cgroup *h_cg)",
            "{",
            "\t__hugetlb_cgroup_uncharge_cgroup(idx, nr_pages, h_cg, true);",
            "}",
            "void hugetlb_cgroup_uncharge_counter(struct resv_map *resv, unsigned long start,",
            "\t\t\t\t     unsigned long end)",
            "{",
            "\tif (hugetlb_cgroup_disabled() || !resv || !resv->reservation_counter ||",
            "\t    !resv->css)",
            "\t\treturn;",
            "",
            "\tpage_counter_uncharge(resv->reservation_counter,",
            "\t\t\t      (end - start) * resv->pages_per_hpage);",
            "\tcss_put(resv->css);",
            "}",
            "void hugetlb_cgroup_uncharge_file_region(struct resv_map *resv,",
            "\t\t\t\t\t struct file_region *rg,",
            "\t\t\t\t\t unsigned long nr_pages,",
            "\t\t\t\t\t bool region_del)",
            "{",
            "\tif (hugetlb_cgroup_disabled() || !resv || !rg || !nr_pages)",
            "\t\treturn;",
            "",
            "\tif (rg->reservation_counter && resv->pages_per_hpage &&",
            "\t    !resv->reservation_counter) {",
            "\t\tpage_counter_uncharge(rg->reservation_counter,",
            "\t\t\t\t      nr_pages * resv->pages_per_hpage);",
            "\t\t/*",
            "\t\t * Only do css_put(rg->css) when we delete the entire region",
            "\t\t * because one file_region must hold exactly one css reference.",
            "\t\t */",
            "\t\tif (region_del)",
            "\t\t\tcss_put(rg->css);",
            "\t}",
            "}",
            "static int hugetlb_cgroup_read_numa_stat(struct seq_file *seq, void *dummy)",
            "{",
            "\tint nid;",
            "\tstruct cftype *cft = seq_cft(seq);",
            "\tint idx = MEMFILE_IDX(cft->private);",
            "\tbool legacy = MEMFILE_ATTR(cft->private);",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(seq_css(seq));",
            "\tstruct cgroup_subsys_state *css;",
            "\tunsigned long usage;",
            "",
            "\tif (legacy) {",
            "\t\t/* Add up usage across all nodes for the non-hierarchical total. */",
            "\t\tusage = 0;",
            "\t\tfor_each_node_state(nid, N_MEMORY)",
            "\t\t\tusage += READ_ONCE(h_cg->nodeinfo[nid]->usage[idx]);",
            "\t\tseq_printf(seq, \"total=%lu\", usage * PAGE_SIZE);",
            "",
            "\t\t/* Simply print the per-node usage for the non-hierarchical total. */",
            "\t\tfor_each_node_state(nid, N_MEMORY)",
            "\t\t\tseq_printf(seq, \" N%d=%lu\", nid,",
            "\t\t\t\t   READ_ONCE(h_cg->nodeinfo[nid]->usage[idx]) *",
            "\t\t\t\t\t   PAGE_SIZE);",
            "\t\tseq_putc(seq, '\\n');",
            "\t}",
            "",
            "\t/*",
            "\t * The hierarchical total is pretty much the value recorded by the",
            "\t * counter, so use that.",
            "\t */",
            "\tseq_printf(seq, \"%stotal=%lu\", legacy ? \"hierarchical_\" : \"\",",
            "\t\t   page_counter_read(&h_cg->hugepage[idx]) * PAGE_SIZE);",
            "",
            "\t/*",
            "\t * For each node, transverse the css tree to obtain the hierarchical",
            "\t * node usage.",
            "\t */",
            "\tfor_each_node_state(nid, N_MEMORY) {",
            "\t\tusage = 0;",
            "\t\trcu_read_lock();",
            "\t\tcss_for_each_descendant_pre(css, &h_cg->css) {",
            "\t\t\tusage += READ_ONCE(hugetlb_cgroup_from_css(css)",
            "\t\t\t\t\t\t   ->nodeinfo[nid]",
            "\t\t\t\t\t\t   ->usage[idx]);",
            "\t\t}",
            "\t\trcu_read_unlock();",
            "\t\tseq_printf(seq, \" N%d=%lu\", nid, usage * PAGE_SIZE);",
            "\t}",
            "",
            "\tseq_putc(seq, '\\n');",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "hugetlb_cgroup_uncharge_folio, hugetlb_cgroup_uncharge_folio_rsvd, __hugetlb_cgroup_uncharge_cgroup, hugetlb_cgroup_uncharge_cgroup, hugetlb_cgroup_uncharge_cgroup_rsvd, hugetlb_cgroup_uncharge_counter, hugetlb_cgroup_uncharge_file_region, hugetlb_cgroup_read_numa_stat",
          "description": "实现HugeTLB页面释放时的反向计费操作，包含对单个folio和整体cgroup的解除分配逻辑，以及读取NUMA节点统计信息的实现。",
          "similarity": 0.4459521770477295
        }
      ]
    }
  ]
}