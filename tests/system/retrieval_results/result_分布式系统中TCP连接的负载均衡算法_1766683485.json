{
  "query": "分布式系统中TCP连接的负载均衡算法",
  "timestamp": "2025-12-26 01:24:45",
  "retrieved_files": [
    {
      "source_file": "kernel/sched/pelt.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:13:26\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\pelt.c`\n\n---\n\n# `sched/pelt.c` 技术文档\n\n## 1. 文件概述\n\n`sched/pelt.c` 实现了 **Per-Entity Load Tracking（PELT）** 机制，这是 Linux 内核 CFS（Completely Fair Scheduler）调度器中用于精确跟踪每个调度实体（如任务或任务组）负载、可运行性和 CPU 利用率的核心算法。  \nPELT 将时间划分为约 1ms（1024ns）的周期段，使用指数衰减的几何级数对历史负载进行加权求和，使得近期负载权重更高，远期负载影响逐渐衰减。该机制为负载均衡、能效调度（如 EAS）和 CPU 频率调节等子系统提供关键的负载指标。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `decay_load(u64 val, u64 n)`  \n  计算负载值 `val` 经过 `n` 个时间单位后的衰减值，利用预计算的衰减系数表和位移优化实现高效指数衰减。\n\n- `__accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)`  \n  计算跨越多个完整周期时，负载贡献的三部分之和：上一周期剩余部分（d1）、中间完整周期总和（d2）、当前周期已过部分（d3）。\n\n- `accumulate_sum(u64 delta, struct sched_avg *sa, unsigned long load, unsigned long runnable, int running)`  \n  核心累加函数，根据时间增量 `delta` 更新 `load_sum`、`runnable_sum` 和 `util_sum`，处理跨周期衰减与新贡献累加。\n\n- `___update_load_sum(u64 now, struct sched_avg *sa, unsigned long load, unsigned long runnable, int running)`  \n  入口函数，计算自上次更新以来的时间差，调用 `accumulate_sum` 更新负载总和，并处理时间回退等异常情况。\n\n- `___update_load_avg(struct sched_avg *sa, unsigned long load)`  \n  根据当前 `*_sum` 值和动态除数（divider）计算并更新 `load_avg`、`runnable_avg` 和 `util_avg`。\n\n### 关键数据结构\n\n- `struct sched_avg`  \n  存储 PELT 相关状态，包括：\n  - `load_sum` / `runnable_sum` / `util_sum`：衰减加权后的负载总和\n  - `load_avg` / `runnable_avg` / `util_avg`：归一化后的平均负载值\n  - `last_update_time`：上次更新时间戳\n  - `period_contrib`：当前周期内已累积的时间（<1024ns）\n\n## 3. 关键实现\n\n### 时间分段与衰减模型\n- 时间以 **1024ns（≈1μs）** 为基本单位，每 **1024 单位（≈1ms）** 构成一个 PELT 周期。\n- 衰减因子 `y` 满足 `y^32 ≈ 0.5`，即约 32ms 前的负载贡献衰减至当前的一半。\n- 负载历史表示为几何级数：`u₀ + u₁·y + u₂·y² + ...`，其中 `uᵢ` 是第 `i` 个周期内的可运行比例。\n\n### 高效衰减计算\n- `decay_load()` 利用 `y^32 = 1/2` 的特性，将 `y^n` 拆分为 `1/2^(n/32) * y^(n%32)`。\n- 通过右移操作快速计算 `1/2^k` 部分，再查表 `runnable_avg_yN_inv[]` 获取 `y^(n%32)` 的倒数，结合 `mul_u64_u32_shr` 完成乘法。\n\n### 负载累加三段式\n当时间增量跨越多个周期时，负载贡献分为：\n1. **d1**：上一周期未完成部分（`1024 - period_contrib`）\n2. **d2**：中间完整周期的理论最大贡献（`LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024`）\n3. **d3**：当前周期已过部分（`delta % 1024`）\n\n### 动态归一化\n- 使用 `get_pelt_divider()` 获取当前周期位置对应的归一化除数，避免因周期未结束导致的平均值震荡。\n- 除数公式：`LOAD_AVG_MAX - 1024 + period_contrib`，确保最大负载值在 `[1002, 1024)` 区间稳定。\n\n### 状态一致性保障\n- 若 `load == 0`，强制 `runnable = running = 0`，避免已出队实体产生无效贡献。\n- 时间回退（如 TSC 切换）时直接重置 `last_update_time`，防止负时间差导致异常。\n\n## 4. 依赖关系\n\n- **头文件依赖**：  \n  依赖 `kernel/sched/sched.h` 中定义的 `struct sched_avg`、`SCHED_CAPACITY_SHIFT`、`LOAD_AVG_*` 常量及 `get_pelt_divider()` 等辅助函数。\n- **预计算表**：  \n  使用外部定义的 `runnable_avg_yN_inv[32]` 衰减系数表（通常在 `fair.c` 或 `pelt.h` 中初始化）。\n- **调度器集成**：  \n  被 `fair.c` 中的 CFS 调度实体（`sched_entity`）和 CFS 运行队列（`cfs_rq`）调用，用于更新任务/任务组的负载状态。\n- **能效调度**：  \n  为 Energy Aware Scheduling (EAS) 提供 `util_avg` 作为 CPU 需求预测依据。\n\n## 5. 使用场景\n\n- **任务负载跟踪**：  \n  每个 `task_struct` 的 `sched_entity` 通过 PELT 实时更新其 `load_avg` 和 `util_avg`，反映任务对 CPU 的历史需求。\n- **任务组调度**：  \n  CFS 任务组（`task_group`）的 `cfs_rq` 使用 PELT 聚合子任务的负载，实现层级化负载均衡。\n- **负载均衡决策**：  \n  `load_balance()` 等函数依据 `runnable_avg` 判断 CPU 间负载差异，触发任务迁移。\n- **CPU 频率调节**：  \n  CPUFreq 的 `schedutil` 调速器使用 `util_avg` 动态调整 CPU 频率，平衡性能与功耗。\n- **空闲负载处理**：  \n  在 `idle_balance()` 等场景中，即使任务已出队，仍需通过 PELT 正确衰减其历史负载贡献。",
      "similarity": 0.5746243596076965,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/pelt.c",
          "start_line": 31,
          "end_line": 178,
          "content": [
            "static u64 decay_load(u64 val, u64 n)",
            "{",
            "\tunsigned int local_n;",
            "",
            "\tif (unlikely(n > LOAD_AVG_PERIOD * 63))",
            "\t\treturn 0;",
            "",
            "\t/* after bounds checking we can collapse to 32-bit */",
            "\tlocal_n = n;",
            "",
            "\t/*",
            "\t * As y^PERIOD = 1/2, we can combine",
            "\t *    y^n = 1/2^(n/PERIOD) * y^(n%PERIOD)",
            "\t * With a look-up table which covers y^n (n<PERIOD)",
            "\t *",
            "\t * To achieve constant time decay_load.",
            "\t */",
            "\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {",
            "\t\tval >>= local_n / LOAD_AVG_PERIOD;",
            "\t\tlocal_n %= LOAD_AVG_PERIOD;",
            "\t}",
            "",
            "\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);",
            "\treturn val;",
            "}",
            "static u32 __accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)",
            "{",
            "\tu32 c1, c2, c3 = d3; /* y^0 == 1 */",
            "",
            "\t/*",
            "\t * c1 = d1 y^p",
            "\t */",
            "\tc1 = decay_load((u64)d1, periods);",
            "",
            "\t/*",
            "\t *            p-1",
            "\t * c2 = 1024 \\Sum y^n",
            "\t *            n=1",
            "\t *",
            "\t *              inf        inf",
            "\t *    = 1024 ( \\Sum y^n - \\Sum y^n - y^0 )",
            "\t *              n=0        n=p",
            "\t */",
            "\tc2 = LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024;",
            "",
            "\treturn c1 + c2 + c3;",
            "}",
            "static __always_inline u32",
            "accumulate_sum(u64 delta, struct sched_avg *sa,",
            "\t       unsigned long load, unsigned long runnable, int running)",
            "{",
            "\tu32 contrib = (u32)delta; /* p == 0 -> delta < 1024 */",
            "\tu64 periods;",
            "",
            "\tdelta += sa->period_contrib;",
            "\tperiods = delta / 1024; /* A period is 1024us (~1ms) */",
            "",
            "\t/*",
            "\t * Step 1: decay old *_sum if we crossed period boundaries.",
            "\t */",
            "\tif (periods) {",
            "\t\tsa->load_sum = decay_load(sa->load_sum, periods);",
            "\t\tsa->runnable_sum =",
            "\t\t\tdecay_load(sa->runnable_sum, periods);",
            "\t\tsa->util_sum = decay_load((u64)(sa->util_sum), periods);",
            "",
            "\t\t/*",
            "\t\t * Step 2",
            "\t\t */",
            "\t\tdelta %= 1024;",
            "\t\tif (load) {",
            "\t\t\t/*",
            "\t\t\t * This relies on the:",
            "\t\t\t *",
            "\t\t\t * if (!load)",
            "\t\t\t *\trunnable = running = 0;",
            "\t\t\t *",
            "\t\t\t * clause from ___update_load_sum(); this results in",
            "\t\t\t * the below usage of @contrib to disappear entirely,",
            "\t\t\t * so no point in calculating it.",
            "\t\t\t */",
            "\t\t\tcontrib = __accumulate_pelt_segments(periods,",
            "\t\t\t\t\t1024 - sa->period_contrib, delta);",
            "\t\t}",
            "\t}",
            "\tsa->period_contrib = delta;",
            "",
            "\tif (load)",
            "\t\tsa->load_sum += load * contrib;",
            "\tif (runnable)",
            "\t\tsa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;",
            "\tif (running)",
            "\t\tsa->util_sum += contrib << SCHED_CAPACITY_SHIFT;",
            "",
            "\treturn periods;",
            "}",
            "static __always_inline int",
            "___update_load_sum(u64 now, struct sched_avg *sa,",
            "\t\t  unsigned long load, unsigned long runnable, int running)",
            "{",
            "\tu64 delta;",
            "",
            "\tdelta = now - sa->last_update_time;",
            "\t/*",
            "\t * This should only happen when time goes backwards, which it",
            "\t * unfortunately does during sched clock init when we swap over to TSC.",
            "\t */",
            "\tif ((s64)delta < 0) {",
            "\t\tsa->last_update_time = now;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * Use 1024ns as the unit of measurement since it's a reasonable",
            "\t * approximation of 1us and fast to compute.",
            "\t */",
            "\tdelta >>= 10;",
            "\tif (!delta)",
            "\t\treturn 0;",
            "",
            "\tsa->last_update_time += delta << 10;",
            "",
            "\t/*",
            "\t * running is a subset of runnable (weight) so running can't be set if",
            "\t * runnable is clear. But there are some corner cases where the current",
            "\t * se has been already dequeued but cfs_rq->curr still points to it.",
            "\t * This means that weight will be 0 but not running for a sched_entity",
            "\t * but also for a cfs_rq if the latter becomes idle. As an example,",
            "\t * this happens during idle_balance() which calls",
            "\t * sched_balance_update_blocked_averages().",
            "\t *",
            "\t * Also see the comment in accumulate_sum().",
            "\t */",
            "\tif (!load)",
            "\t\trunnable = running = 0;",
            "",
            "\t/*",
            "\t * Now we know we crossed measurement unit boundaries. The *_avg",
            "\t * accrues by two steps:",
            "\t *",
            "\t * Step 1: accumulate *_sum since last_update_time. If we haven't",
            "\t * crossed period boundaries, finish.",
            "\t */",
            "\tif (!accumulate_sum(delta, sa, load, runnable, running))",
            "\t\treturn 0;",
            "",
            "\treturn 1;",
            "}"
          ],
          "function_name": "decay_load, __accumulate_pelt_segments, accumulate_sum, ___update_load_sum",
          "description": "实现PELT核心算法，包含四个关键函数：decay_load通过位移运算模拟指数衰减；__accumulate_pelt_segments计算周期性负载贡献；accumulate_sum根据时间差更新负载、运行时和利用率的加权总和；___update_load_sum处理时间边界穿越时的衰减逻辑并触发更新。所有函数共同维护调度实体的动态负载统计",
          "similarity": 0.5564374327659607
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/pelt.c",
          "start_line": 256,
          "end_line": 384,
          "content": [
            "static __always_inline void",
            "___update_load_avg(struct sched_avg *sa, unsigned long load)",
            "{",
            "\tu32 divider = get_pelt_divider(sa);",
            "",
            "\t/*",
            "\t * Step 2: update *_avg.",
            "\t */",
            "\tsa->load_avg = div_u64(load * sa->load_sum, divider);",
            "\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);",
            "\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);",
            "}",
            "int __update_load_avg_blocked_se(u64 now, struct sched_entity *se)",
            "{",
            "\tif (___update_load_sum(now, &se->avg, 0, 0, 0)) {",
            "\t\t___update_load_avg(&se->avg, se_weight(se));",
            "\t\ttrace_pelt_se_tp(se);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int __update_load_avg_se(u64 now, struct cfs_rq *cfs_rq, struct sched_entity *se)",
            "{",
            "\tif (___update_load_sum(now, &se->avg, !!se->on_rq, se_runnable(se),",
            "\t\t\t\tcfs_rq->curr == se)) {",
            "",
            "\t\t___update_load_avg(&se->avg, se_weight(se));",
            "\t\tcfs_se_util_change(&se->avg);",
            "\t\ttrace_pelt_se_tp(se);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int __update_load_avg_cfs_rq(u64 now, struct cfs_rq *cfs_rq)",
            "{",
            "\tif (___update_load_sum(now, &cfs_rq->avg,",
            "\t\t\t\tscale_load_down(cfs_rq->load.weight),",
            "\t\t\t\tcfs_rq->h_nr_running,",
            "\t\t\t\tcfs_rq->curr != NULL)) {",
            "",
            "\t\t___update_load_avg(&cfs_rq->avg, 1);",
            "\t\ttrace_pelt_cfs_tp(cfs_rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_rt_rq_load_avg(u64 now, struct rq *rq, int running)",
            "{",
            "\tif (___update_load_sum(now, &rq->avg_rt,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning)) {",
            "",
            "\t\t___update_load_avg(&rq->avg_rt, 1);",
            "\t\ttrace_pelt_rt_tp(rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_dl_rq_load_avg(u64 now, struct rq *rq, int running)",
            "{",
            "\tif (___update_load_sum(now, &rq->avg_dl,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning)) {",
            "",
            "\t\t___update_load_avg(&rq->avg_dl, 1);",
            "\t\ttrace_pelt_dl_tp(rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_hw_load_avg(u64 now, struct rq *rq, u64 capacity)",
            "{",
            "\tif (___update_load_sum(now, &rq->avg_hw,",
            "\t\t\t       capacity,",
            "\t\t\t       capacity,",
            "\t\t\t       capacity)) {",
            "\t\t___update_load_avg(&rq->avg_hw, 1);",
            "\t\ttrace_pelt_hw_tp(rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_irq_load_avg(struct rq *rq, u64 running)",
            "{",
            "\tint ret = 0;",
            "",
            "\t/*",
            "\t * We can't use clock_pelt because irq time is not accounted in",
            "\t * clock_task. Instead we directly scale the running time to",
            "\t * reflect the real amount of computation",
            "\t */",
            "\trunning = cap_scale(running, arch_scale_freq_capacity(cpu_of(rq)));",
            "\trunning = cap_scale(running, arch_scale_cpu_capacity(cpu_of(rq)));",
            "",
            "\t/*",
            "\t * We know the time that has been used by interrupt since last update",
            "\t * but we don't when. Let be pessimistic and assume that interrupt has",
            "\t * happened just before the update. This is not so far from reality",
            "\t * because interrupt will most probably wake up task and trig an update",
            "\t * of rq clock during which the metric is updated.",
            "\t * We start to decay with normal context time and then we add the",
            "\t * interrupt context time.",
            "\t * We can safely remove running from rq->clock because",
            "\t * rq->clock += delta with delta >= running",
            "\t */",
            "\tret = ___update_load_sum(rq->clock - running, &rq->avg_irq,",
            "\t\t\t\t0,",
            "\t\t\t\t0,",
            "\t\t\t\t0);",
            "\tret += ___update_load_sum(rq->clock, &rq->avg_irq,",
            "\t\t\t\t1,",
            "\t\t\t\t1,",
            "\t\t\t\t1);",
            "",
            "\tif (ret) {",
            "\t\t___update_load_avg(&rq->avg_irq, 1);",
            "\t\ttrace_pelt_irq_tp(rq);",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "___update_load_avg, __update_load_avg_blocked_se, __update_load_avg_se, __update_load_avg_cfs_rq, update_rt_rq_load_avg, update_dl_rq_load_avg, update_hw_load_avg, update_irq_load_avg",
          "description": "提供多场景下的负载平均值更新接口，包含六个函数：___update_load_avg计算负载平均值；__update_load_avg_blocked_se更新阻塞任务实体；__update_load_avg_se处理CFS队列中任务实体；__update_load_avg_cfs_rq更新CFS队列负载；update_rt_rq_load_avg/update_dl_rq_load_avg分别处理实时/延迟调度队列；update_hw_load_avg和update_irq_load_avg分别更新硬件资源及中断负载统计",
          "similarity": 0.5373022556304932
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/pelt.c",
          "start_line": 1,
          "end_line": 30,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Per Entity Load Tracking",
            " *",
            " *  Copyright (C) 2007 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>",
            " *",
            " *  Interactivity improvements by Mike Galbraith",
            " *  (C) 2007 Mike Galbraith <efault@gmx.de>",
            " *",
            " *  Various enhancements by Dmitry Adamushko.",
            " *  (C) 2007 Dmitry Adamushko <dmitry.adamushko@gmail.com>",
            " *",
            " *  Group scheduling enhancements by Srivatsa Vaddagiri",
            " *  Copyright IBM Corporation, 2007",
            " *  Author: Srivatsa Vaddagiri <vatsa@linux.vnet.ibm.com>",
            " *",
            " *  Scaled math optimizations by Thomas Gleixner",
            " *  Copyright (C) 2007, Thomas Gleixner <tglx@linutronix.de>",
            " *",
            " *  Adaptive scheduling granularity, math enhancements by Peter Zijlstra",
            " *  Copyright (C) 2007 Red Hat, Inc., Peter Zijlstra",
            " *",
            " *  Move PELT related code from fair.c into this pelt.c file",
            " *  Author: Vincent Guittot <vincent.guittot@linaro.org>",
            " */",
            "",
            "/*",
            " * Approximate:",
            " *   val * y^n,    where y^32 ~= 0.5 (~1 scheduling period)",
            " */"
          ],
          "function_name": null,
          "description": "此代码块为PELT（Per-entity Load Tracking）模块的头部注释，声明了该模块的版权信息、作者及主要贡献者，并概述了PELT算法的目标，即通过时间衰减模型精确跟踪调度实体的负载变化，支持交互性优化、分组调度等功能。上下文不完整",
          "similarity": 0.5018283724784851
        }
      ]
    },
    {
      "source_file": "kernel/irq/matrix.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:03:08\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\matrix.c`\n\n---\n\n# `irq/matrix.c` 技术文档\n\n## 1. 文件概述\n\n`irq/matrix.c` 实现了一个通用的中断位图（IRQ matrix）管理机制，用于在多 CPU 系统中高效地分配和管理中断向量（或中断位）。该机制支持两类中断分配：\n\n- **普通分配（allocated）**：由设备驱动等动态申请的中断。\n- **托管分配（managed）**：由内核子系统（如 MSI/MSI-X）预先保留、按需激活的中断。\n\n该文件通过 per-CPU 的位图结构，结合全局状态跟踪，实现了跨 CPU 的中断资源分配、预留、释放和在线/离线管理，特别适用于中断向量数量有限（如 x86 的 256 个向量）的架构。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct cpumap`**：每个 CPU 的本地中断位图状态\n  - `available`：当前 CPU 可用的中断数量\n  - `allocated`：已分配的普通中断数量\n  - `managed` / `managed_allocated`：预留和已激活的托管中断数量\n  - `alloc_map[]`：记录已分配的普通中断位\n  - `managed_map[]`：记录预留的托管中断位\n  - `initialized` / `online`：CPU 初始化和在线状态\n\n- **`struct irq_matrix`**：全局中断矩阵控制结构\n  - `matrix_bits`：总位图大小（≤ `IRQ_MATRIX_BITS`）\n  - `alloc_start` / `alloc_end`：可分配范围\n  - `global_available`：全局可用中断总数\n  - `system_map[]`：系统保留位（如 APIC 自身使用的向量）\n  - `maps`：指向 per-CPU `cpumap` 的指针\n  - `scratch_map[]`：临时位图，用于分配时的合并计算\n\n### 主要函数\n\n| 函数 | 功能 |\n|------|------|\n| `irq_alloc_matrix()` | 分配并初始化一个 `irq_matrix` 结构 |\n| `irq_matrix_online()` / `irq_matrix_offline()` | 将本地 CPU 的中断矩阵置为在线/离线状态 |\n| `irq_matrix_assign_system()` | 在矩阵中保留系统级中断位（如 APIC 向量） |\n| `irq_matrix_reserve_managed()` | 在指定 CPU 掩码上为托管中断预留位 |\n| `irq_matrix_remove_managed()` | 移除托管中断的预留位 |\n| `irq_matrix_alloc_managed()` | 从预留的托管中断中分配一个实际使用的中断 |\n| `matrix_alloc_area()` | 内部辅助函数：在合并位图中查找连续空闲区域 |\n| `matrix_find_best_cpu()` / `matrix_find_best_cpu_managed()` | 选择最优 CPU（基于可用数或托管分配数最少） |\n\n## 3. 关键实现\n\n### 位图合并分配策略\n- 在分配中断时，`matrix_alloc_area()` 会临时合并三个位图：\n  1. 当前 CPU 的 `managed_map`（托管预留）\n  2. 全局 `system_map`（系统保留）\n  3. 当前 CPU 的 `alloc_map`（已分配）\n- 使用 `bitmap_find_next_zero_area()` 在合并后的位图中查找连续空闲区域，确保不会重复分配。\n\n### 托管中断（Managed IRQ）机制\n- **两阶段分配**：\n  1. **预留（reserve）**：调用 `irq_matrix_reserve_managed()` 在多个 CPU 上各预留一个位（不一定对齐）。\n  2. **激活（alloc）**：调用 `irq_matrix_alloc_managed()` 从预留位中选择一个未使用的位进行实际分配。\n- **动态 CPU 选择**：`matrix_find_best_cpu_managed()` 优先选择 `managed_allocated` 最少的 CPU，实现负载均衡。\n\n### 系统中断保留\n- `irq_matrix_assign_system()` 用于保留如 x86 的 `IRQ0_VECTOR`（时钟中断）等关键系统向量。\n- 通过 `BUG_ON()` 强制保证：系统中断只能在单 CPU 初始化阶段分配，防止运行时冲突。\n\n### 在线/离线管理\n- CPU 上线时，将其 `available` 计数加入 `global_available`。\n- CPU 离线时，从全局计数中减去，但保留其位图数据（支持重新上线）。\n\n### 跟踪与调试\n- 集成 `trace/events/irq_matrix.h`，提供分配、预留、系统保留等关键操作的 tracepoint，便于调试中断分配问题。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/bitmap.h>`：位图操作（`bitmap_set`, `bitmap_find_next_zero_area` 等）\n  - `<linux/percpu.h>`：Per-CPU 变量支持\n  - `<linux/cpu.h>`：CPU 在线/离线状态\n  - `<linux/irq.h>`：中断子系统基础定义\n  - `<trace/events/irq_matrix.h>`：自定义 tracepoint\n\n- **内核子系统**：\n  - **中断子系统**：作为底层分配器，被 `irqdomain`、MSI/MSI-X 驱动等使用。\n  - **x86 APIC 驱动**：典型使用者，用于管理 256 个中断向量的分配（如 `kernel/irq/vector.c`）。\n\n## 5. 使用场景\n\n- **x86 中断向量管理**：在 `CONFIG_X86_IO_APIC` 或 `CONFIG_X86_LOCAL_APIC` 下，用于分配 IRQ 向量（0-255），区分系统向量、普通设备中断和 MSI 中断。\n- **MSI/MSI-X 中断分配**：PCIe 设备的 MSI 中断通过托管机制预留和分配，确保每个设备在多个 CPU 上有可用向量。\n- **CPU 热插拔**：支持 CPU 动态上线/下线时的中断资源重新平衡。\n- **中断负载均衡**：通过 `matrix_find_best_cpu*` 函数，在多 CPU 间均匀分配中断，避免单 CPU 向量耗尽。",
      "similarity": 0.564118504524231,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 251,
          "end_line": 365,
          "content": [
            "void irq_matrix_remove_managed(struct irq_matrix *m, const struct cpumask *msk)",
            "{",
            "\tunsigned int cpu;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "\t\tunsigned int bit, end = m->alloc_end;",
            "",
            "\t\tif (WARN_ON_ONCE(!cm->managed))",
            "\t\t\tcontinue;",
            "",
            "\t\t/* Get managed bit which are not allocated */",
            "\t\tbitmap_andnot(m->scratch_map, cm->managed_map, cm->alloc_map, end);",
            "",
            "\t\tbit = find_first_bit(m->scratch_map, end);",
            "\t\tif (WARN_ON_ONCE(bit >= end))",
            "\t\t\tcontinue;",
            "",
            "\t\tclear_bit(bit, cm->managed_map);",
            "",
            "\t\tcm->managed--;",
            "\t\tif (cm->online) {",
            "\t\t\tcm->available++;",
            "\t\t\tm->global_available++;",
            "\t\t}",
            "\t\ttrace_irq_matrix_remove_managed(bit, cpu, m, cm);",
            "\t}",
            "}",
            "int irq_matrix_alloc_managed(struct irq_matrix *m, const struct cpumask *msk,",
            "\t\t\t     unsigned int *mapped_cpu)",
            "{",
            "\tunsigned int bit, cpu, end;",
            "\tstruct cpumap *cm;",
            "",
            "\tif (cpumask_empty(msk))",
            "\t\treturn -EINVAL;",
            "",
            "\tcpu = matrix_find_best_cpu_managed(m, msk);",
            "\tif (cpu == UINT_MAX)",
            "\t\treturn -ENOSPC;",
            "",
            "\tcm = per_cpu_ptr(m->maps, cpu);",
            "\tend = m->alloc_end;",
            "\t/* Get managed bit which are not allocated */",
            "\tbitmap_andnot(m->scratch_map, cm->managed_map, cm->alloc_map, end);",
            "\tbit = find_first_bit(m->scratch_map, end);",
            "\tif (bit >= end)",
            "\t\treturn -ENOSPC;",
            "\tset_bit(bit, cm->alloc_map);",
            "\tcm->allocated++;",
            "\tcm->managed_allocated++;",
            "\tm->total_allocated++;",
            "\t*mapped_cpu = cpu;",
            "\ttrace_irq_matrix_alloc_managed(bit, cpu, m, cm);",
            "\treturn bit;",
            "}",
            "void irq_matrix_assign(struct irq_matrix *m, unsigned int bit)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tif (WARN_ON_ONCE(bit < m->alloc_start || bit >= m->alloc_end))",
            "\t\treturn;",
            "\tif (WARN_ON_ONCE(test_and_set_bit(bit, cm->alloc_map)))",
            "\t\treturn;",
            "\tcm->allocated++;",
            "\tm->total_allocated++;",
            "\tcm->available--;",
            "\tm->global_available--;",
            "\ttrace_irq_matrix_assign(bit, smp_processor_id(), m, cm);",
            "}",
            "void irq_matrix_reserve(struct irq_matrix *m)",
            "{",
            "\tif (m->global_reserved == m->global_available)",
            "\t\tpr_warn(\"Interrupt reservation exceeds available resources\\n\");",
            "",
            "\tm->global_reserved++;",
            "\ttrace_irq_matrix_reserve(m);",
            "}",
            "void irq_matrix_remove_reserved(struct irq_matrix *m)",
            "{",
            "\tm->global_reserved--;",
            "\ttrace_irq_matrix_remove_reserved(m);",
            "}",
            "int irq_matrix_alloc(struct irq_matrix *m, const struct cpumask *msk,",
            "\t\t     bool reserved, unsigned int *mapped_cpu)",
            "{",
            "\tunsigned int cpu, bit;",
            "\tstruct cpumap *cm;",
            "",
            "\t/*",
            "\t * Not required in theory, but matrix_find_best_cpu() uses",
            "\t * for_each_cpu() which ignores the cpumask on UP .",
            "\t */",
            "\tif (cpumask_empty(msk))",
            "\t\treturn -EINVAL;",
            "",
            "\tcpu = matrix_find_best_cpu(m, msk);",
            "\tif (cpu == UINT_MAX)",
            "\t\treturn -ENOSPC;",
            "",
            "\tcm = per_cpu_ptr(m->maps, cpu);",
            "\tbit = matrix_alloc_area(m, cm, 1, false);",
            "\tif (bit >= m->alloc_end)",
            "\t\treturn -ENOSPC;",
            "\tcm->allocated++;",
            "\tcm->available--;",
            "\tm->total_allocated++;",
            "\tm->global_available--;",
            "\tif (reserved)",
            "\t\tm->global_reserved--;",
            "\t*mapped_cpu = cpu;",
            "\ttrace_irq_matrix_alloc(bit, cpu, m, cm);",
            "\treturn bit;",
            "",
            "}"
          ],
          "function_name": "irq_matrix_remove_managed, irq_matrix_alloc_managed, irq_matrix_assign, irq_matrix_reserve, irq_matrix_remove_reserved, irq_matrix_alloc",
          "description": "实现中断位的分配/回收机制，包含保留中断位的管理、跨CPU的中断分配逻辑，以及根据预留状态进行资源分配的控制流程",
          "similarity": 0.559326708316803
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 78,
          "end_line": 205,
          "content": [
            "void irq_matrix_online(struct irq_matrix *m)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tBUG_ON(cm->online);",
            "",
            "\tif (!cm->initialized) {",
            "\t\tcm->available = m->alloc_size;",
            "\t\tcm->available -= cm->managed + m->systembits_inalloc;",
            "\t\tcm->initialized = true;",
            "\t}",
            "\tm->global_available += cm->available;",
            "\tcm->online = true;",
            "\tm->online_maps++;",
            "\ttrace_irq_matrix_online(m);",
            "}",
            "void irq_matrix_offline(struct irq_matrix *m)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\t/* Update the global available size */",
            "\tm->global_available -= cm->available;",
            "\tcm->online = false;",
            "\tm->online_maps--;",
            "\ttrace_irq_matrix_offline(m);",
            "}",
            "static unsigned int matrix_alloc_area(struct irq_matrix *m, struct cpumap *cm,",
            "\t\t\t\t      unsigned int num, bool managed)",
            "{",
            "\tunsigned int area, start = m->alloc_start;",
            "\tunsigned int end = m->alloc_end;",
            "",
            "\tbitmap_or(m->scratch_map, cm->managed_map, m->system_map, end);",
            "\tbitmap_or(m->scratch_map, m->scratch_map, cm->alloc_map, end);",
            "\tarea = bitmap_find_next_zero_area(m->scratch_map, end, start, num, 0);",
            "\tif (area >= end)",
            "\t\treturn area;",
            "\tif (managed)",
            "\t\tbitmap_set(cm->managed_map, area, num);",
            "\telse",
            "\t\tbitmap_set(cm->alloc_map, area, num);",
            "\treturn area;",
            "}",
            "static unsigned int matrix_find_best_cpu(struct irq_matrix *m,",
            "\t\t\t\t\tconst struct cpumask *msk)",
            "{",
            "\tunsigned int cpu, best_cpu, maxavl = 0;",
            "\tstruct cpumap *cm;",
            "",
            "\tbest_cpu = UINT_MAX;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tcm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\t\tif (!cm->online || cm->available <= maxavl)",
            "\t\t\tcontinue;",
            "",
            "\t\tbest_cpu = cpu;",
            "\t\tmaxavl = cm->available;",
            "\t}",
            "\treturn best_cpu;",
            "}",
            "static unsigned int matrix_find_best_cpu_managed(struct irq_matrix *m,",
            "\t\t\t\t\t\tconst struct cpumask *msk)",
            "{",
            "\tunsigned int cpu, best_cpu, allocated = UINT_MAX;",
            "\tstruct cpumap *cm;",
            "",
            "\tbest_cpu = UINT_MAX;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tcm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\t\tif (!cm->online || cm->managed_allocated > allocated)",
            "\t\t\tcontinue;",
            "",
            "\t\tbest_cpu = cpu;",
            "\t\tallocated = cm->managed_allocated;",
            "\t}",
            "\treturn best_cpu;",
            "}",
            "void irq_matrix_assign_system(struct irq_matrix *m, unsigned int bit,",
            "\t\t\t      bool replace)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tBUG_ON(bit > m->matrix_bits);",
            "\tBUG_ON(m->online_maps > 1 || (m->online_maps && !replace));",
            "",
            "\tset_bit(bit, m->system_map);",
            "\tif (replace) {",
            "\t\tBUG_ON(!test_and_clear_bit(bit, cm->alloc_map));",
            "\t\tcm->allocated--;",
            "\t\tm->total_allocated--;",
            "\t}",
            "\tif (bit >= m->alloc_start && bit < m->alloc_end)",
            "\t\tm->systembits_inalloc++;",
            "",
            "\ttrace_irq_matrix_assign_system(bit, m);",
            "}",
            "int irq_matrix_reserve_managed(struct irq_matrix *m, const struct cpumask *msk)",
            "{",
            "\tunsigned int cpu, failed_cpu;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "\t\tunsigned int bit;",
            "",
            "\t\tbit = matrix_alloc_area(m, cm, 1, true);",
            "\t\tif (bit >= m->alloc_end)",
            "\t\t\tgoto cleanup;",
            "\t\tcm->managed++;",
            "\t\tif (cm->online) {",
            "\t\t\tcm->available--;",
            "\t\t\tm->global_available--;",
            "\t\t}",
            "\t\ttrace_irq_matrix_reserve_managed(bit, cpu, m, cm);",
            "\t}",
            "\treturn 0;",
            "cleanup:",
            "\tfailed_cpu = cpu;",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tif (cpu == failed_cpu)",
            "\t\t\tbreak;",
            "\t\tirq_matrix_remove_managed(m, cpumask_of(cpu));",
            "\t}",
            "\treturn -ENOSPC;",
            "}"
          ],
          "function_name": "irq_matrix_online, irq_matrix_offline, matrix_alloc_area, matrix_find_best_cpu, matrix_find_best_cpu_managed, irq_matrix_assign_system, irq_matrix_reserve_managed",
          "description": "实现CPU矩阵的上线/下线操作，通过bitmap操作实现中断位的分配策略，包含寻找最佳CPU的逻辑，支持系统位管理和保留区域的分配与追踪",
          "similarity": 0.5544376373291016
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 418,
          "end_line": 483,
          "content": [
            "void irq_matrix_free(struct irq_matrix *m, unsigned int cpu,",
            "\t\t     unsigned int bit, bool managed)",
            "{",
            "\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\tif (WARN_ON_ONCE(bit < m->alloc_start || bit >= m->alloc_end))",
            "\t\treturn;",
            "",
            "\tif (WARN_ON_ONCE(!test_and_clear_bit(bit, cm->alloc_map)))",
            "\t\treturn;",
            "",
            "\tcm->allocated--;",
            "\tif(managed)",
            "\t\tcm->managed_allocated--;",
            "",
            "\tif (cm->online)",
            "\t\tm->total_allocated--;",
            "",
            "\tif (!managed) {",
            "\t\tcm->available++;",
            "\t\tif (cm->online)",
            "\t\t\tm->global_available++;",
            "\t}",
            "\ttrace_irq_matrix_free(bit, cpu, m, cm);",
            "}",
            "unsigned int irq_matrix_available(struct irq_matrix *m, bool cpudown)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tif (!cpudown)",
            "\t\treturn m->global_available;",
            "\treturn m->global_available - cm->available;",
            "}",
            "unsigned int irq_matrix_reserved(struct irq_matrix *m)",
            "{",
            "\treturn m->global_reserved;",
            "}",
            "unsigned int irq_matrix_allocated(struct irq_matrix *m)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\treturn cm->allocated - cm->managed_allocated;",
            "}",
            "void irq_matrix_debug_show(struct seq_file *sf, struct irq_matrix *m, int ind)",
            "{",
            "\tunsigned int nsys = bitmap_weight(m->system_map, m->matrix_bits);",
            "\tint cpu;",
            "",
            "\tseq_printf(sf, \"Online bitmaps:   %6u\\n\", m->online_maps);",
            "\tseq_printf(sf, \"Global available: %6u\\n\", m->global_available);",
            "\tseq_printf(sf, \"Global reserved:  %6u\\n\", m->global_reserved);",
            "\tseq_printf(sf, \"Total allocated:  %6u\\n\", m->total_allocated);",
            "\tseq_printf(sf, \"System: %u: %*pbl\\n\", nsys, m->matrix_bits,",
            "\t\t   m->system_map);",
            "\tseq_printf(sf, \"%*s| CPU | avl | man | mac | act | vectors\\n\", ind, \" \");",
            "\tcpus_read_lock();",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\t\tseq_printf(sf, \"%*s %4d  %4u  %4u  %4u %4u  %*pbl\\n\", ind, \" \",",
            "\t\t\t   cpu, cm->available, cm->managed,",
            "\t\t\t   cm->managed_allocated, cm->allocated,",
            "\t\t\t   m->matrix_bits, cm->alloc_map);",
            "\t}",
            "\tcpus_read_unlock();",
            "}"
          ],
          "function_name": "irq_matrix_free, irq_matrix_available, irq_matrix_reserved, irq_matrix_allocated, irq_matrix_debug_show",
          "description": "提供中断资源的释放接口，实现全局和CPU级的资源使用统计查询，包含调试信息展示功能，通过位图操作维护系统中断位的使用状态",
          "similarity": 0.5097573399543762
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 1,
          "end_line": 77,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "// Copyright (C) 2017 Thomas Gleixner <tglx@linutronix.de>",
            "",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpu.h>",
            "#include <linux/irq.h>",
            "",
            "#define IRQ_MATRIX_SIZE\t(BITS_TO_LONGS(IRQ_MATRIX_BITS))",
            "",
            "struct cpumap {",
            "\tunsigned int\t\tavailable;",
            "\tunsigned int\t\tallocated;",
            "\tunsigned int\t\tmanaged;",
            "\tunsigned int\t\tmanaged_allocated;",
            "\tbool\t\t\tinitialized;",
            "\tbool\t\t\tonline;",
            "\tunsigned long\t\talloc_map[IRQ_MATRIX_SIZE];",
            "\tunsigned long\t\tmanaged_map[IRQ_MATRIX_SIZE];",
            "};",
            "",
            "struct irq_matrix {",
            "\tunsigned int\t\tmatrix_bits;",
            "\tunsigned int\t\talloc_start;",
            "\tunsigned int\t\talloc_end;",
            "\tunsigned int\t\talloc_size;",
            "\tunsigned int\t\tglobal_available;",
            "\tunsigned int\t\tglobal_reserved;",
            "\tunsigned int\t\tsystembits_inalloc;",
            "\tunsigned int\t\ttotal_allocated;",
            "\tunsigned int\t\tonline_maps;",
            "\tstruct cpumap __percpu\t*maps;",
            "\tunsigned long\t\tscratch_map[IRQ_MATRIX_SIZE];",
            "\tunsigned long\t\tsystem_map[IRQ_MATRIX_SIZE];",
            "};",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/irq_matrix.h>",
            "",
            "/**",
            " * irq_alloc_matrix - Allocate a irq_matrix structure and initialize it",
            " * @matrix_bits:\tNumber of matrix bits must be <= IRQ_MATRIX_BITS",
            " * @alloc_start:\tFrom which bit the allocation search starts",
            " * @alloc_end:\t\tAt which bit the allocation search ends, i.e first",
            " *\t\t\tinvalid bit",
            " */",
            "__init struct irq_matrix *irq_alloc_matrix(unsigned int matrix_bits,",
            "\t\t\t\t\t   unsigned int alloc_start,",
            "\t\t\t\t\t   unsigned int alloc_end)",
            "{",
            "\tstruct irq_matrix *m;",
            "",
            "\tif (matrix_bits > IRQ_MATRIX_BITS)",
            "\t\treturn NULL;",
            "",
            "\tm = kzalloc(sizeof(*m), GFP_KERNEL);",
            "\tif (!m)",
            "\t\treturn NULL;",
            "",
            "\tm->matrix_bits = matrix_bits;",
            "\tm->alloc_start = alloc_start;",
            "\tm->alloc_end = alloc_end;",
            "\tm->alloc_size = alloc_end - alloc_start;",
            "\tm->maps = alloc_percpu(*m->maps);",
            "\tif (!m->maps) {",
            "\t\tkfree(m);",
            "\t\treturn NULL;",
            "\t}",
            "\treturn m;",
            "}",
            "",
            "/**",
            " * irq_matrix_online - Bring the local CPU matrix online",
            " * @m:\t\tMatrix pointer",
            " */"
          ],
          "function_name": null,
          "description": "定义irq_matrix结构体和相关辅助数据结构，提供irq_alloc_matrix函数用于初始化并分配irq_matrix实例，设置矩阵大小、起始结束位置等参数，并分配per-CPU的cpumap数组",
          "similarity": 0.47591033577919006
        }
      ]
    },
    {
      "source_file": "kernel/sched/sched-pelt.h",
      "md_summary": "> 自动生成时间: 2025-10-25 16:15:27\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\sched-pelt.h`\n\n---\n\n# `sched/sched-pelt.h` 技术文档\n\n## 1. 文件概述\n\n`sched/sched-pelt.h` 是 Linux 内核调度器中用于实现 **PELT（Per-Entity Load Tracking，每实体负载跟踪）** 机制的头文件。该文件定义了 PELT 算法所需的关键常量和预计算的衰减系数表，用于高效计算任务和运行队列的负载贡献。PELT 是 CFS（完全公平调度器）中用于准确跟踪 CPU 负载和利用率的核心机制，支持负载均衡、能效调度（如 EAS）等高级调度功能。\n\n## 2. 核心功能\n\n本文件不包含函数定义，主要提供以下数据结构和宏定义：\n\n- **`runnable_avg_yN_inv[]`**：一个预计算的 32 位无符号整型数组，存储 PELT 算法中用于指数衰减计算的倒数系数。\n- **`LOAD_AVG_PERIOD`**：定义 PELT 负载计算的基本周期长度（单位为调度周期数），值为 32。\n- **`LOAD_AVG_MAX`**：表示 PELT 负载值的理论最大值（约为 47742），用于归一化和防止溢出。\n\n## 3. 关键实现\n\n### PELT 衰减模型\nPELT 将时间划分为 1ms 的调度周期（`SCHED_CAPACITY_SCALE` 相关），并假设负载在每个周期内呈指数衰减。负载贡献按如下方式累积：\n\n$$\nL(t) = L_0 \\cdot y + L_1 \\cdot y^2 + L_2 \\cdot y^3 + \\cdots\n$$\n\n其中 $ y = e^{-\\Delta t / T} $，$ T $ 为时间常数（通常为 32ms），$ \\Delta t $ 为周期长度（1ms）。因此 $ y \\approx 0.96875 $。\n\n### 预计算系数表\n`runnable_avg_yN_inv[]` 数组存储的是 $ 1 / y^n $ 的 32 位定点数近似值（Q31 格式），用于在运行时通过乘法代替除法，加速衰减计算。例如：\n- `runnable_avg_yN_inv[0] = 0xffffffff` 对应 $ 1 / y^0 = 1 $\n- 后续项依次对应 $ 1 / y^1, 1 / y^2, \\dots, 1 / y^{31} $\n\n该表由脚本 `Documentation/scheduler/sched-pelt` 自动生成，确保精度与性能平衡。\n\n### 负载归一化\n- `LOAD_AVG_PERIOD = 32` 表示每 32 个调度周期（约 32ms）构成一个完整的衰减窗口。\n- `LOAD_AVG_MAX = 47742` 是当实体持续 100% 可运行时，PELT 累积负载的稳态最大值，计算公式为：\n\n$$\n\\text{LOAD\\_AVG\\_MAX} = \\sum_{i=0}^{\\infty} y^i \\cdot \\text{period\\_contrib} \\approx \\frac{1024 - 1024 \\cdot y^{32}}{1 - y}\n$$\n\n该值用于将原始负载值映射到 [0, 1024] 或 [0, SCHED_CAPACITY_SCALE] 的标准化范围。\n\n## 4. 依赖关系\n\n- **调度核心模块**：被 `kernel/sched/pelt.c` 和 `kernel/sched/fair.c` 包含，用于实现 `___update_load_avg()` 等负载更新函数。\n- **调度类**：CFS 调度类（`struct sched_class` 的 `fair_sched_class`）依赖此文件进行任务和运行队列的负载跟踪。\n- **能效调度（EAS）**：EAS 使用 PELT 提供的利用率信号进行 CPU 频率选择和任务放置。\n- **负载均衡器**：`load_balance()` 等函数利用 PELT 负载值评估 CPU 间负载差异。\n\n## 5. 使用场景\n\n- **任务负载跟踪**：每个 `struct sched_entity` 使用 PELT 计算其对 CPU 的负载贡献。\n- **运行队列负载聚合**：`struct cfs_rq` 聚合其下所有任务的 PELT 负载，用于负载均衡决策。\n- **CPU 利用率估计**：为 CPUFreq 的 schedutil 调频策略提供实时利用率输入。\n- **能效感知调度**：在异构多核系统（如 big.LITTLE）中，基于 PELT 利用率进行任务迁移以优化能效。\n- **热插拔与 CPU 疲劳管理**：系统根据 PELT 负载动态启停 CPU 核心。",
      "similarity": 0.5486516952514648,
      "chunks": []
    }
  ]
}