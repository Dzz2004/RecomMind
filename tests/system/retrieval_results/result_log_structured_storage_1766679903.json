{
  "query": "log structured storage",
  "timestamp": "2025-12-26 00:25:03",
  "retrieved_files": [
    {
      "source_file": "mm/list_lru.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:35:23\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `list_lru.c`\n\n---\n\n# list_lru.c 技术文档\n\n## 1. 文件概述\n\n`list_lru.c` 实现了 Linux 内核中通用的 **List-based LRU（Least Recently Used）基础设施**，用于管理可回收对象的双向链表。该机制支持按 NUMA 节点（node）和内存控制组（memcg）进行细粒度组织，便于内存压力下的高效回收。主要服务于 slab 分配器等子系统，作为 shrinker 框架的一部分，在内存紧张时协助释放非活跃对象。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct list_lru`：顶层 LRU 管理结构，包含 per-node 的 `list_lru_node`\n- `struct list_lru_node`：每个 NUMA 节点对应的 LRU 节点，含自旋锁和总项数\n- `struct list_lru_one`：实际存储对象链表和计数的单元（per-memcg per-node）\n- `struct list_lru_memcg`：当启用 `CONFIG_MEMCG` 时，为每个 memcg 存储 per-node 的 `list_lru_one`\n\n### 主要导出函数\n- `list_lru_add()` / `list_lru_add_obj()`：向 LRU 添加对象\n- `list_lru_del()` / `list_lru_del_obj()`：从 LRU 删除对象\n- `list_lru_isolate()` / `list_lru_isolate_move()`：在回收过程中隔离对象\n- `list_lru_count_one()` / `list_lru_count_node()`：查询 LRU 中对象数量\n- `list_lru_walk_one()` / `list_lru_walk_node()`：遍历并处理 LRU 中的对象（用于 shrinker 回调）\n\n### 内部辅助函数\n- `list_lru_from_memcg_idx()`：根据 memcg ID 获取对应的 `list_lru_one`\n- `__list_lru_walk_one()`：带锁的 LRU 遍历核心逻辑\n- `list_lru_register()` / `list_lru_unregister()`：注册/注销 memcg-aware 的 LRU（用于全局追踪）\n\n## 3. 关键实现\n\n### 内存控制组（memcg）支持\n- 通过 `CONFIG_MEMCG` 条件编译控制 memcg 相关逻辑\n- 使用 XArray (`lru->xa`) 动态存储每个 memcg 对应的 `list_lru_memcg` 结构\n- 每个 memcg 在每个 NUMA 节点上拥有独立的 `list_lru_one`，实现资源隔离\n- 全局 `memcg_list_lrus` 链表和 `list_lrus_mutex` 用于跟踪所有 memcg-aware 的 LRU 实例\n\n### 并发控制\n- 每个 NUMA 节点 (`list_lru_node`) 拥有独立的自旋锁 (`nlru->lock`)\n- 所有对 LRU 链表的操作（增、删、遍历）均在对应节点锁保护下进行\n- 提供 `_irq` 版本的遍历函数（`list_lru_walk_one_irq`）用于中断上下文\n\n### 回收遍历机制\n- `list_lru_walk_*` 函数接受回调函数 `isolate`，由调用者定义回收策略\n- 回调返回值控制遍历行为：\n  - `LRU_REMOVED`：成功移除\n  - `LRU_REMOVED_RETRY`：移除后需重新开始遍历（锁曾被释放）\n  - `LRU_RETRY`：未移除但需重新开始遍历\n  - `LRU_ROTATE`：将对象移到链表尾部（标记为最近使用）\n  - `LRU_SKIP`：跳过当前对象\n  - `LRU_STOP`：立即停止遍历\n- 通过 `nr_to_walk` 限制单次遍历的最大对象数，防止长时间持锁\n\n### Shrinker 集成\n- 当向空的 `list_lru_one` 添加首个对象时，调用 `set_shrinker_bit()` 标记该 memcg/node 需要被 shrinker 处理\n- `lru_shrinker_id()` 返回关联的 shrinker ID，用于通知内存回收子系统\n\n### 对象归属识别\n- `list_lru_add_obj()` / `list_lru_del_obj()` 通过 `mem_cgroup_from_slab_obj()` 自动获取对象所属的 memcg\n- 使用 `page_to_nid(virt_to_page(item))` 确定对象所在的 NUMA 节点\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/list_lru.h>`：定义核心数据结构和 API\n  - `<linux/memcontrol.h>`：memcg 相关接口（如 `memcg_kmem_id`）\n  - `\"slab.h\"` 和 `\"internal.h\"`：slab 分配器内部接口（如 `mem_cgroup_from_slab_obj`）\n- **配置依赖**：\n  - `CONFIG_MEMCG`：决定是否编译 memcg 相关代码\n  - `CONFIG_NUMA`：影响 per-node 数据结构的大小（通过 `nr_node_ids`）\n- **子系统依赖**：\n  - Slab 分配器：作为主要使用者，管理可回收 slab 对象\n  - Memory Control Group (memcg)：提供内存隔离和记账\n  - Shrinker 框架：通过 shrinker 回调触发 LRU 遍历回收\n\n## 5. 使用场景\n\n- **Slab 对象回收**：当系统内存压力大时，shrinker 通过 `list_lru_walk_*` 遍历 inactive slab 对象链表，释放可回收对象\n- **Per-memcg 内存限制**：在 cgroup 内存超限时，仅遍历该 memcg 对应的 LRU 部分，实现精确回收\n- **NUMA 感知管理**：按 NUMA 节点分离 LRU 链表，减少远程内存访问，提升性能\n- **通用 LRU 容器**：任何需要按 LRU 策略管理可回收对象的内核子系统均可使用此基础设施（如 dentry、inode 缓存等）",
      "similarity": 0.5353028774261475,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "mm/list_lru.c",
          "start_line": 425,
          "end_line": 551,
          "content": [
            "static void memcg_reparent_list_lru(struct list_lru *lru,",
            "\t\t\t\t    int src_idx, struct mem_cgroup *dst_memcg)",
            "{",
            "\tint i;",
            "",
            "\tfor_each_node(i)",
            "\t\tmemcg_reparent_list_lru_node(lru, i, src_idx, dst_memcg);",
            "",
            "\tmemcg_list_lru_free(lru, src_idx);",
            "}",
            "void memcg_reparent_list_lrus(struct mem_cgroup *memcg, struct mem_cgroup *parent)",
            "{",
            "\tstruct cgroup_subsys_state *css;",
            "\tstruct list_lru *lru;",
            "\tint src_idx = memcg->kmemcg_id;",
            "",
            "\t/*",
            "\t * Change kmemcg_id of this cgroup and all its descendants to the",
            "\t * parent's id, and then move all entries from this cgroup's list_lrus",
            "\t * to ones of the parent.",
            "\t *",
            "\t * After we have finished, all list_lrus corresponding to this cgroup",
            "\t * are guaranteed to remain empty. So we can safely free this cgroup's",
            "\t * list lrus in memcg_list_lru_free().",
            "\t *",
            "\t * Changing ->kmemcg_id to the parent can prevent memcg_list_lru_alloc()",
            "\t * from allocating list lrus for this cgroup after memcg_list_lru_free()",
            "\t * call.",
            "\t */",
            "\trcu_read_lock();",
            "\tcss_for_each_descendant_pre(css, &memcg->css) {",
            "\t\tstruct mem_cgroup *child;",
            "",
            "\t\tchild = mem_cgroup_from_css(css);",
            "\t\tWRITE_ONCE(child->kmemcg_id, parent->kmemcg_id);",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\tmutex_lock(&list_lrus_mutex);",
            "\tlist_for_each_entry(lru, &memcg_list_lrus, list)",
            "\t\tmemcg_reparent_list_lru(lru, src_idx, parent);",
            "\tmutex_unlock(&list_lrus_mutex);",
            "}",
            "static inline bool memcg_list_lru_allocated(struct mem_cgroup *memcg,",
            "\t\t\t\t\t    struct list_lru *lru)",
            "{",
            "\tint idx = memcg->kmemcg_id;",
            "",
            "\treturn idx < 0 || xa_load(&lru->xa, idx);",
            "}",
            "int memcg_list_lru_alloc(struct mem_cgroup *memcg, struct list_lru *lru,",
            "\t\t\t gfp_t gfp)",
            "{",
            "\tint i;",
            "\tunsigned long flags;",
            "\tstruct list_lru_memcg_table {",
            "\t\tstruct list_lru_memcg *mlru;",
            "\t\tstruct mem_cgroup *memcg;",
            "\t} *table;",
            "\tXA_STATE(xas, &lru->xa, 0);",
            "",
            "\tif (!list_lru_memcg_aware(lru) || memcg_list_lru_allocated(memcg, lru))",
            "\t\treturn 0;",
            "",
            "\tgfp &= GFP_RECLAIM_MASK;",
            "\ttable = kmalloc_array(memcg->css.cgroup->level, sizeof(*table), gfp);",
            "\tif (!table)",
            "\t\treturn -ENOMEM;",
            "",
            "\t/*",
            "\t * Because the list_lru can be reparented to the parent cgroup's",
            "\t * list_lru, we should make sure that this cgroup and all its",
            "\t * ancestors have allocated list_lru_memcg.",
            "\t */",
            "\tfor (i = 0; memcg; memcg = parent_mem_cgroup(memcg), i++) {",
            "\t\tif (memcg_list_lru_allocated(memcg, lru))",
            "\t\t\tbreak;",
            "",
            "\t\ttable[i].memcg = memcg;",
            "\t\ttable[i].mlru = memcg_init_list_lru_one(gfp);",
            "\t\tif (!table[i].mlru) {",
            "\t\t\twhile (i--)",
            "\t\t\t\tkfree(table[i].mlru);",
            "\t\t\tkfree(table);",
            "\t\t\treturn -ENOMEM;",
            "\t\t}",
            "\t}",
            "",
            "\txas_lock_irqsave(&xas, flags);",
            "\twhile (i--) {",
            "\t\tint index = READ_ONCE(table[i].memcg->kmemcg_id);",
            "\t\tstruct list_lru_memcg *mlru = table[i].mlru;",
            "",
            "\t\txas_set(&xas, index);",
            "retry:",
            "\t\tif (unlikely(index < 0 || xas_error(&xas) || xas_load(&xas))) {",
            "\t\t\tkfree(mlru);",
            "\t\t} else {",
            "\t\t\txas_store(&xas, mlru);",
            "\t\t\tif (xas_error(&xas) == -ENOMEM) {",
            "\t\t\t\txas_unlock_irqrestore(&xas, flags);",
            "\t\t\t\tif (xas_nomem(&xas, gfp))",
            "\t\t\t\t\txas_set_err(&xas, 0);",
            "\t\t\t\txas_lock_irqsave(&xas, flags);",
            "\t\t\t\t/*",
            "\t\t\t\t * The xas lock has been released, this memcg",
            "\t\t\t\t * can be reparented before us. So reload",
            "\t\t\t\t * memcg id. More details see the comments",
            "\t\t\t\t * in memcg_reparent_list_lrus().",
            "\t\t\t\t */",
            "\t\t\t\tindex = READ_ONCE(table[i].memcg->kmemcg_id);",
            "\t\t\t\tif (index < 0)",
            "\t\t\t\t\txas_set_err(&xas, 0);",
            "\t\t\t\telse if (!xas_error(&xas) && index != xas.xa_index)",
            "\t\t\t\t\txas_set(&xas, index);",
            "\t\t\t\tgoto retry;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "\t/* xas_nomem() is used to free memory instead of memory allocation. */",
            "\tif (xas.xa_alloc)",
            "\t\txas_nomem(&xas, gfp);",
            "\txas_unlock_irqrestore(&xas, flags);",
            "\tkfree(table);",
            "",
            "\treturn xas_error(&xas);",
            "}"
          ],
          "function_name": "memcg_reparent_list_lru, memcg_reparent_list_lrus, memcg_list_lru_allocated, memcg_list_lru_alloc",
          "description": "实现内存组层级间的LRU列表迁移与分配机制，包含递归子组处理、动态分配/释放LRU结构体及冲突解决逻辑。",
          "similarity": 0.5379145741462708
        },
        {
          "chunk_id": 1,
          "file_path": "mm/list_lru.c",
          "start_line": 22,
          "end_line": 129,
          "content": [
            "static inline bool list_lru_memcg_aware(struct list_lru *lru)",
            "{",
            "\treturn lru->memcg_aware;",
            "}",
            "static void list_lru_register(struct list_lru *lru)",
            "{",
            "\tif (!list_lru_memcg_aware(lru))",
            "\t\treturn;",
            "",
            "\tmutex_lock(&list_lrus_mutex);",
            "\tlist_add(&lru->list, &memcg_list_lrus);",
            "\tmutex_unlock(&list_lrus_mutex);",
            "}",
            "static void list_lru_unregister(struct list_lru *lru)",
            "{",
            "\tif (!list_lru_memcg_aware(lru))",
            "\t\treturn;",
            "",
            "\tmutex_lock(&list_lrus_mutex);",
            "\tlist_del(&lru->list);",
            "\tmutex_unlock(&list_lrus_mutex);",
            "}",
            "static int lru_shrinker_id(struct list_lru *lru)",
            "{",
            "\treturn lru->shrinker_id;",
            "}",
            "static void list_lru_register(struct list_lru *lru)",
            "{",
            "}",
            "static void list_lru_unregister(struct list_lru *lru)",
            "{",
            "}",
            "static int lru_shrinker_id(struct list_lru *lru)",
            "{",
            "\treturn -1;",
            "}",
            "static inline bool list_lru_memcg_aware(struct list_lru *lru)",
            "{",
            "\treturn false;",
            "}",
            "bool list_lru_add(struct list_lru *lru, struct list_head *item, int nid,",
            "\t\t    struct mem_cgroup *memcg)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tstruct list_lru_one *l;",
            "",
            "\tspin_lock(&nlru->lock);",
            "\tif (list_empty(item)) {",
            "\t\tl = list_lru_from_memcg_idx(lru, nid, memcg_kmem_id(memcg));",
            "\t\tlist_add_tail(item, &l->list);",
            "\t\t/* Set shrinker bit if the first element was added */",
            "\t\tif (!l->nr_items++)",
            "\t\t\tset_shrinker_bit(memcg, nid, lru_shrinker_id(lru));",
            "\t\tnlru->nr_items++;",
            "\t\tspin_unlock(&nlru->lock);",
            "\t\treturn true;",
            "\t}",
            "\tspin_unlock(&nlru->lock);",
            "\treturn false;",
            "}",
            "bool list_lru_add_obj(struct list_lru *lru, struct list_head *item)",
            "{",
            "\tbool ret;",
            "\tint nid = page_to_nid(virt_to_page(item));",
            "",
            "\tif (list_lru_memcg_aware(lru)) {",
            "\t\trcu_read_lock();",
            "\t\tret = list_lru_add(lru, item, nid, mem_cgroup_from_slab_obj(item));",
            "\t\trcu_read_unlock();",
            "\t} else {",
            "\t\tret = list_lru_add(lru, item, nid, NULL);",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "bool list_lru_del(struct list_lru *lru, struct list_head *item, int nid,",
            "\t\t    struct mem_cgroup *memcg)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tstruct list_lru_one *l;",
            "",
            "\tspin_lock(&nlru->lock);",
            "\tif (!list_empty(item)) {",
            "\t\tl = list_lru_from_memcg_idx(lru, nid, memcg_kmem_id(memcg));",
            "\t\tlist_del_init(item);",
            "\t\tl->nr_items--;",
            "\t\tnlru->nr_items--;",
            "\t\tspin_unlock(&nlru->lock);",
            "\t\treturn true;",
            "\t}",
            "\tspin_unlock(&nlru->lock);",
            "\treturn false;",
            "}",
            "bool list_lru_del_obj(struct list_lru *lru, struct list_head *item)",
            "{",
            "\tbool ret;",
            "\tint nid = page_to_nid(virt_to_page(item));",
            "",
            "\tif (list_lru_memcg_aware(lru)) {",
            "\t\trcu_read_lock();",
            "\t\tret = list_lru_del(lru, item, nid, mem_cgroup_from_slab_obj(item));",
            "\t\trcu_read_unlock();",
            "\t} else {",
            "\t\tret = list_lru_del(lru, item, nid, NULL);",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "list_lru_memcg_aware, list_lru_register, list_lru_unregister, lru_shrinker_id, list_lru_register, list_lru_unregister, lru_shrinker_id, list_lru_memcg_aware, list_lru_add, list_lru_add_obj, list_lru_del, list_lru_del_obj",
          "description": "实现了LRU列表的添加/删除操作，支持MemCG感知的节点和内存组粒度管理，包含处理多核、内存组切换及RCU安全访问的逻辑。",
          "similarity": 0.5141637921333313
        },
        {
          "chunk_id": 5,
          "file_path": "mm/list_lru.c",
          "start_line": 556,
          "end_line": 605,
          "content": [
            "static inline void memcg_init_list_lru(struct list_lru *lru, bool memcg_aware)",
            "{",
            "}",
            "static void memcg_destroy_list_lru(struct list_lru *lru)",
            "{",
            "}",
            "int __list_lru_init(struct list_lru *lru, bool memcg_aware,",
            "\t\t    struct lock_class_key *key, struct shrinker *shrinker)",
            "{",
            "\tint i;",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tif (shrinker)",
            "\t\tlru->shrinker_id = shrinker->id;",
            "\telse",
            "\t\tlru->shrinker_id = -1;",
            "#endif",
            "",
            "\tlru->node = kcalloc(nr_node_ids, sizeof(*lru->node), GFP_KERNEL);",
            "\tif (!lru->node)",
            "\t\treturn -ENOMEM;",
            "",
            "\tfor_each_node(i) {",
            "\t\tspin_lock_init(&lru->node[i].lock);",
            "\t\tif (key)",
            "\t\t\tlockdep_set_class(&lru->node[i].lock, key);",
            "\t\tinit_one_lru(&lru->node[i].lru);",
            "\t}",
            "",
            "\tmemcg_init_list_lru(lru, memcg_aware);",
            "\tlist_lru_register(lru);",
            "",
            "\treturn 0;",
            "}",
            "void list_lru_destroy(struct list_lru *lru)",
            "{",
            "\t/* Already destroyed or not yet initialized? */",
            "\tif (!lru->node)",
            "\t\treturn;",
            "",
            "\tlist_lru_unregister(lru);",
            "",
            "\tmemcg_destroy_list_lru(lru);",
            "\tkfree(lru->node);",
            "\tlru->node = NULL;",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tlru->shrinker_id = -1;",
            "#endif",
            "}"
          ],
          "function_name": "memcg_init_list_lru, memcg_destroy_list_lru, __list_lru_init, list_lru_destroy",
          "description": "该代码段实现了基于内存控制组（MEMCG）的LRU列表管理功能。  \n`__list_lru_init` 初始化 `list_lru` 结构体并注册到系统，其中包含 MEMCG 相关的 shrinker ID 设置及节点锁初始化；`list_lru_destroy` 反向清理资源，但 `memcg_init_list_lru` 和 `memcg_destroy_list_lru` 的具体实现缺失，上下文不完整。",
          "similarity": 0.5016803741455078
        },
        {
          "chunk_id": 0,
          "file_path": "mm/list_lru.c",
          "start_line": 1,
          "end_line": 21,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Copyright (c) 2013 Red Hat, Inc. and Parallels Inc. All rights reserved.",
            " * Authors: David Chinner and Glauber Costa",
            " *",
            " * Generic LRU infrastructure",
            " */",
            "#include <linux/kernel.h>",
            "#include <linux/module.h>",
            "#include <linux/mm.h>",
            "#include <linux/list_lru.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/memcontrol.h>",
            "#include \"slab.h\"",
            "#include \"internal.h\"",
            "",
            "#ifdef CONFIG_MEMCG",
            "static LIST_HEAD(memcg_list_lrus);",
            "static DEFINE_MUTEX(list_lrus_mutex);",
            ""
          ],
          "function_name": null,
          "description": "定义了支持内存控制组（MemCG）的LRU基础设施，声明了全局链表头memcg_list_lrus和互斥锁list_lrus_mutex，用于管理MemCG环境下的LRU列表注册与注销操作。",
          "similarity": 0.4991145730018616
        },
        {
          "chunk_id": 3,
          "file_path": "mm/list_lru.c",
          "start_line": 289,
          "end_line": 400,
          "content": [
            "unsigned long",
            "list_lru_walk_one_irq(struct list_lru *lru, int nid, struct mem_cgroup *memcg,",
            "\t\t      list_lru_walk_cb isolate, void *cb_arg,",
            "\t\t      unsigned long *nr_to_walk)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tunsigned long ret;",
            "",
            "\tspin_lock_irq(&nlru->lock);",
            "\tret = __list_lru_walk_one(lru, nid, memcg_kmem_id(memcg), isolate,",
            "\t\t\t\t  cb_arg, nr_to_walk);",
            "\tspin_unlock_irq(&nlru->lock);",
            "\treturn ret;",
            "}",
            "unsigned long list_lru_walk_node(struct list_lru *lru, int nid,",
            "\t\t\t\t list_lru_walk_cb isolate, void *cb_arg,",
            "\t\t\t\t unsigned long *nr_to_walk)",
            "{",
            "\tlong isolated = 0;",
            "",
            "\tisolated += list_lru_walk_one(lru, nid, NULL, isolate, cb_arg,",
            "\t\t\t\t      nr_to_walk);",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tif (*nr_to_walk > 0 && list_lru_memcg_aware(lru)) {",
            "\t\tstruct list_lru_memcg *mlru;",
            "\t\tunsigned long index;",
            "",
            "\t\txa_for_each(&lru->xa, index, mlru) {",
            "\t\t\tstruct list_lru_node *nlru = &lru->node[nid];",
            "",
            "\t\t\tspin_lock(&nlru->lock);",
            "\t\t\tisolated += __list_lru_walk_one(lru, nid, index,",
            "\t\t\t\t\t\t\tisolate, cb_arg,",
            "\t\t\t\t\t\t\tnr_to_walk);",
            "\t\t\tspin_unlock(&nlru->lock);",
            "",
            "\t\t\tif (*nr_to_walk <= 0)",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "#endif",
            "",
            "\treturn isolated;",
            "}",
            "static void init_one_lru(struct list_lru_one *l)",
            "{",
            "\tINIT_LIST_HEAD(&l->list);",
            "\tl->nr_items = 0;",
            "}",
            "static void memcg_list_lru_free(struct list_lru *lru, int src_idx)",
            "{",
            "\tstruct list_lru_memcg *mlru = xa_erase_irq(&lru->xa, src_idx);",
            "",
            "\t/*",
            "\t * The __list_lru_walk_one() can walk the list of this node.",
            "\t * We need kvfree_rcu() here. And the walking of the list",
            "\t * is under lru->node[nid]->lock, which can serve as a RCU",
            "\t * read-side critical section.",
            "\t */",
            "\tif (mlru)",
            "\t\tkvfree_rcu(mlru, rcu);",
            "}",
            "static inline void memcg_init_list_lru(struct list_lru *lru, bool memcg_aware)",
            "{",
            "\tif (memcg_aware)",
            "\t\txa_init_flags(&lru->xa, XA_FLAGS_LOCK_IRQ);",
            "\tlru->memcg_aware = memcg_aware;",
            "}",
            "static void memcg_destroy_list_lru(struct list_lru *lru)",
            "{",
            "\tXA_STATE(xas, &lru->xa, 0);",
            "\tstruct list_lru_memcg *mlru;",
            "",
            "\tif (!list_lru_memcg_aware(lru))",
            "\t\treturn;",
            "",
            "\txas_lock_irq(&xas);",
            "\txas_for_each(&xas, mlru, ULONG_MAX) {",
            "\t\tkfree(mlru);",
            "\t\txas_store(&xas, NULL);",
            "\t}",
            "\txas_unlock_irq(&xas);",
            "}",
            "static void memcg_reparent_list_lru_node(struct list_lru *lru, int nid,",
            "\t\t\t\t\t int src_idx, struct mem_cgroup *dst_memcg)",
            "{",
            "\tstruct list_lru_node *nlru = &lru->node[nid];",
            "\tint dst_idx = dst_memcg->kmemcg_id;",
            "\tstruct list_lru_one *src, *dst;",
            "",
            "\t/*",
            "\t * Since list_lru_{add,del} may be called under an IRQ-safe lock,",
            "\t * we have to use IRQ-safe primitives here to avoid deadlock.",
            "\t */",
            "\tspin_lock_irq(&nlru->lock);",
            "",
            "\tsrc = list_lru_from_memcg_idx(lru, nid, src_idx);",
            "\tif (!src)",
            "\t\tgoto out;",
            "\tdst = list_lru_from_memcg_idx(lru, nid, dst_idx);",
            "",
            "\tlist_splice_init(&src->list, &dst->list);",
            "",
            "\tif (src->nr_items) {",
            "\t\tdst->nr_items += src->nr_items;",
            "\t\tset_shrinker_bit(dst_memcg, nid, lru_shrinker_id(lru));",
            "\t\tsrc->nr_items = 0;",
            "\t}",
            "out:",
            "\tspin_unlock_irq(&nlru->lock);",
            "}"
          ],
          "function_name": "list_lru_walk_one_irq, list_lru_walk_node, init_one_lru, memcg_list_lru_free, memcg_init_list_lru, memcg_destroy_list_lru, memcg_reparent_list_lru_node",
          "description": "包含LRU节点初始化、内存组间列表迁移、资源释放等高级操作，涉及XA表管理、中断安全锁操作及内存组重新归属处理。",
          "similarity": 0.4792962372303009
        }
      ]
    },
    {
      "source_file": "mm/slab.h",
      "md_summary": "> 自动生成时间: 2025-12-07 17:22:03\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `slab.h`\n\n---\n\n# `slab.h` 技术文档\n\n## 1. 文件概述\n\n`slab.h` 是 Linux 内核内存管理子系统中 SLAB/SLUB 分配器的核心内部头文件，定义了 slab 分配器所使用的底层数据结构（如 `struct slab` 和 `struct kmem_cache`）、关键宏和辅助函数。该文件主要用于在页（`struct page`）与 slab 表示之间进行安全转换，并提供对 slab 元数据的原子访问机制，以支持高性能、可扩展的对象缓存分配。\n\n此头文件专供内核内存管理内部使用，不对外暴露给模块开发者，是实现 SLUB（默认）或 SLAB 分配器的关键基础设施。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`freelist_aba_t`**  \n  联合体，将空闲对象指针（`freelist`）与计数器（`counter`）打包为一个原子单元，用于避免 ABA 问题（Compare-and-Swap 中因值重复导致的逻辑错误）。\n\n- **`struct slab`**  \n  slab 的内部表示，复用 `struct page` 的内存布局。包含：\n  - 所属的 `kmem_cache`\n  - 空闲对象链表（`freelist`）\n  - 对象使用计数（`inuse`）、总对象数（`objects`）\n  - 冻结状态（`frozen`，用于调试）\n  - RCU 回收头（`rcu_head`）\n  - 引用计数（`__page_refcount`）\n  - 可选的 per-object 扩展数据（`obj_exts`）\n\n- **`struct kmem_cache_order_objects`**  \n  封装 slab 阶数（order）与对象数量的复合值，支持原子读写。\n\n- **`struct kmem_cache`**  \n  slab 缓存描述符，包含：\n  - 每 CPU 缓存（`cpu_slab`）\n  - 对象大小（`size`, `object_size`）\n  - 构造函数（`ctor`）\n  - 对齐要求（`align`）\n  - 分配标志（`allocflags`）\n  - NUMA 相关参数（如 `remote_node_defrag_ratio`）\n  - 安全特性（如 `random` 用于 freelist 加固）\n\n### 主要宏与辅助函数\n\n- **类型安全转换宏**：\n  - `folio_slab()` / `slab_folio()`：在 `folio` 与 `slab` 之间安全转换\n  - `page_slab()` / `slab_page()`：兼容旧代码，在 `page` 与 `slab` 之间转换\n\n- **slab 属性访问函数**：\n  - `slab_address()`：获取 slab 起始虚拟地址\n  - `slab_nid()` / `slab_pgdat()`：获取所属 NUMA 节点和内存域\n  - `slab_order()` / `slab_size()`：获取分配阶数和总字节数\n\n- **pfmemalloc 标志操作**：\n  - `slab_test_pfmemalloc()` / `slab_set_pfmemalloc()` 等：标记 slab 是否来自紧急内存预留区（用于网络交换等场景）\n\n- **每 CPU partial slab 支持（`CONFIG_SLUB_CPU_PARTIAL`）**：\n  - `slub_percpu_partial()` 等宏：管理每 CPU 的 partial slab 链表\n\n## 3. 关键实现\n\n### 内存布局复用与静态断言\n\n- `struct slab` 并非独立分配，而是直接复用 `struct page` 的内存空间。通过 `static_assert` 确保关键字段偏移一致（如 `flags` ↔ `__page_flags`），保证类型转换安全。\n- 整个 `struct slab` 大小不超过 `struct page`，确保无越界访问。\n\n### ABA 问题防护\n\n- 在支持 `cmpxchg128`（64 位）或 `cmpxchg64`（32 位）的架构上，启用 `freelist_aba_t` 结构，将 `freelist` 指针与递增计数器打包为单个原子单元。\n- 使用 `try_cmpxchg_freelist` 进行原子更新，防止因指针值循环重用导致的 ABA 错误。\n- 若系统不支持对齐的 `struct page`（`!CONFIG_HAVE_ALIGNED_STRUCT_PAGE`），则禁用此优化。\n\n### 类型安全转换\n\n- 使用 C11 `_Generic` 实现类型安全的 `folio`/`slab`/`page` 转换，避免强制类型转换带来的风险，并为未来重构（如完全迁移到 folio）预留接口。\n\n### pfmemalloc 标志复用\n\n- 利用 `folio` 的 `PG_active` 位存储 `pfmemalloc` 标志，指示该 slab 是否从紧急内存池分配，用于网络子系统在内存压力下仍能分配 skb 等关键结构。\n\n## 4. 依赖关系\n\n- **核心依赖**：\n  - `<linux/page.h>` / `<linux/folio.h>`：通过 `folio_*` 系列函数操作底层内存\n  - `<linux/reciprocal_div.h>`：用于快速除法（计算对象索引）\n  - `<linux/rcupdate.h>`：通过 `rcu_head` 支持 RCU 安全的 slab 回收\n\n- **可选依赖（由 Kconfig 控制）**：\n  - `CONFIG_SLUB_CPU_PARTIAL`：每 CPU partial slab 优化\n  - `CONFIG_SLAB_OBJ_EXT`：per-object 扩展元数据\n  - `CONFIG_SLAB_FREELIST_HARDENED`：freelist 指针随机化加固\n  - `CONFIG_NUMA`：NUMA 感知分配与碎片整理\n  - `CONFIG_KASAN` / `CONFIG_KFENCE`：内存错误检测集成\n\n- **与内存控制器集成**：\n  - 通过 `memcg_data` 字段（复用 `obj_exts`）支持 memcg 内存统计\n\n## 5. 使用场景\n\n- **SLUB 分配器内部**：作为 `slub.c` 的核心数据结构定义，用于管理 slab 生命周期、对象分配/释放。\n- **内存回收路径**：在 direct reclaim 或 kswapd 中，通过 `slab_folio` 获取 folio 信息以决策回收策略。\n- **调试与监控**：sysfs (`kobj`)、KASAN/KFENCE 集成依赖此结构获取 slab 元数据。\n- **网络子系统**：通过 `pfmemalloc` 标志识别紧急内存分配，确保高优先级数据包处理不被阻塞。\n- **NUMA 优化**：在远程节点分配时使用 `remote_node_defrag_ratio` 参数控制跨节点分配行为。\n- **安全加固**：`SLAB_FREELIST_HARDENED` 利用 `random` 字段混淆 freelist 指针，防止堆利用攻击。",
      "similarity": 0.5233091115951538,
      "chunks": []
    },
    {
      "source_file": "mm/zbud.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:36:35\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `zbud.c`\n\n---\n\n# zbud.c 技术文档\n\n## 1. 文件概述\n\n`zbud.c` 实现了一个专用于存储压缩页面（compressed pages）的特殊用途内存分配器——**zbud**。尽管名称中包含“buddy”，但它并非传统的伙伴系统分配器，而是通过将两个压缩页面（称为“zpages”）配对存放在同一个物理内存页（称为“zbud page”）中来实现高效管理。\n\n该设计在牺牲一定存储密度的前提下，提供了简单且可预测的内存回收特性，特别适用于需要频繁进行内存回收（reclaim）的场景（如 zswap、zcache 等压缩交换子系统）。zbud 保证其空间利用率不会低于 1:1（即不会比直接使用未压缩页面占用更多物理页），从而确保“不会造成损害”。\n\n此外，zbud 的 API 与传统分配器不同：`zbud_alloc()` 返回一个不透明句柄（handle），用户必须通过 `zbud_map()` 映射该句柄才能获得可访问的数据指针，并在操作完成后调用 `zbud_unmap()` 解除映射。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct zbud_pool`**  \n  表示一个 zbud 内存池，包含：\n  - `lock`：自旋锁，保护池内所有字段及其中 zbud 页面的元数据。\n  - `unbuddied[NCHUNKS]`：数组，每个元素是一个链表头，用于管理仅包含一个 buddy（单配对）的 zbud 页面；索引表示页面中空闲块的数量。\n  - `buddied`：链表头，管理已包含两个 buddy（满配对）的 zbud 页面（复用 `unbuddied[0]`）。\n  - `pages_nr`：池中 zbud 页面的总数。\n\n- **`struct zbud_header`**  \n  位于每个 zbud 页面的第一个 chunk 中，作为页面元数据，包含：\n  - `buddy`：用于将页面链接到 `unbuddied` 或 `buddied` 链表。\n  - `first_chunks`：第一个 buddy 占用的 chunk 数（为 0 表示空闲）。\n  - `last_chunks`：最后一个 buddy 占用的 chunk 数（为 0 表示空闲）。\n\n### 主要函数\n\n- **`zbud_create_pool(gfp_t gfp)`**  \n  创建并初始化一个新的 zbud 内存池。\n\n- **`zbud_destroy_pool(struct zbud_pool *pool)`**  \n  销毁指定的 zbud 内存池（要求池已清空）。\n\n- **`zbud_alloc(struct zbud_pool *pool, size_t size, gfp_t gfp, unsigned long *handle)`**  \n  在池中分配指定大小的内存区域，返回不透明句柄。\n\n- **`zbud_free(struct zbud_pool *pool, unsigned long handle)`**  \n  释放由句柄标识的分配区域。\n\n- **`zbud_map(struct zbud_pool *pool, unsigned long handle)`**  \n  将句柄映射为可访问的虚拟地址指针。\n\n- **`zbud_unmap(struct zbud_pool *pool, unsigned long handle)`**  \n  解除句柄的映射。\n\n- **辅助函数**：\n  - `size_to_chunks()`：将字节大小转换为 chunk 数量。\n  - `init_zbud_page()` / `free_zbud_page()`：初始化/释放 zbud 页面。\n  - `encode_handle()` / `handle_to_zbud_header()`：句柄编码与解码。\n  - `num_free_chunks()`：计算 zbud 页面中的空闲 chunk 数。\n\n## 3. 关键实现\n\n### 内存布局与配对机制\n\n- 每个 **zbud 页面**（物理页）被划分为固定大小的 **chunks**（默认 `PAGE_SIZE / 64`，由 `NCHUNKS_ORDER=6` 决定）。\n- 第一个 chunk 被 `zbud_header` 占用，剩余 `NCHUNKS = 63` 个 chunks 可用于存储数据。\n- **First buddy** 从页面起始位置（跳过 header）向右分配（左对齐）。\n- **Last buddy** 从页面末尾向左分配（右对齐）。\n- 当任一 buddy 被释放时，其空间会与中间的 slack space 合并，形成页面内最大的连续空闲区域，便于后续分配。\n\n### 空闲管理策略\n\n- 使用 **`unbuddied[NCHUNKS]` 数组** 管理单配对页面：\n  - 索引 `i` 对应空闲 chunk 数为 `i` 的页面。\n  - 分配时优先遍历满足需求的最小空闲列表（best-fit 策略）。\n- **`buddied` 链表** 管理已满（双配对）的页面，无法再分配。\n\n### 句柄机制\n\n- 句柄本质是数据在页面内的虚拟地址，但通过 `encode_handle()` 封装：\n  - First buddy 句柄 = `zhdr 地址 + ZHDR_SIZE_ALIGNED`\n  - Last buddy 句柄 = `页面起始地址 + PAGE_SIZE - (last_chunks << CHUNK_SHIFT)`\n- 通过 `handle & PAGE_MASK` 可快速还原出 `zbud_header` 指针。\n\n### 密度保证\n\n- 由于每个 zbud 页面至少可容纳一个压缩页，因此 **zpages : zbud pages ≥ 1**，确保不会因压缩反而增加内存消耗。\n\n## 4. 依赖关系\n\n- **内核头文件**：\n  - `<linux/atomic.h>`、`<linux/spinlock.h>`：提供原子操作和自旋锁支持。\n  - `<linux/list.h>`：链表操作。\n  - `<linux/mm.h>`、`<linux/slab.h>`：内存页和 slab 分配器接口。\n  - `<linux/zpool.h>`：zbud 作为 zpool API 的一种后端实现，需符合其接口规范。\n- **架构依赖**：使用 `PAGE_SHIFT`、`PAGE_MASK` 等与页大小相关的宏，依赖体系结构定义。\n- **内存属性限制**：分配时禁止使用 `__GFP_HIGHMEM`，因高内存页无法直接映射访问。\n\n## 5. 使用场景\n\n- **zswap**：Linux 内核的交换页压缩缓存机制，使用 zbud（或 z3fold/zsmalloc）作为后端分配器存储压缩后的交换页。\n- **zcache**（历史项目）：早期基于 transcendent memory 的压缩缓存，zbud 最初为其设计。\n- **其他需要确定性回收行为的压缩内存池**：适用于对内存回收延迟敏感、且能接受较低存储密度的场景。\n- **作为 zpool 的注册后端**：通过 `zpool_register_driver()` 注册，供上层子系统按需选择。",
      "similarity": 0.5216492414474487,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "mm/zbud.c",
          "start_line": 1,
          "end_line": 126,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * zbud.c",
            " *",
            " * Copyright (C) 2013, Seth Jennings, IBM",
            " *",
            " * Concepts based on zcache internal zbud allocator by Dan Magenheimer.",
            " *",
            " * zbud is an special purpose allocator for storing compressed pages.  Contrary",
            " * to what its name may suggest, zbud is not a buddy allocator, but rather an",
            " * allocator that \"buddies\" two compressed pages together in a single memory",
            " * page.",
            " *",
            " * While this design limits storage density, it has simple and deterministic",
            " * reclaim properties that make it preferable to a higher density approach when",
            " * reclaim will be used.",
            " *",
            " * zbud works by storing compressed pages, or \"zpages\", together in pairs in a",
            " * single memory page called a \"zbud page\".  The first buddy is \"left",
            " * justified\" at the beginning of the zbud page, and the last buddy is \"right",
            " * justified\" at the end of the zbud page.  The benefit is that if either",
            " * buddy is freed, the freed buddy space, coalesced with whatever slack space",
            " * that existed between the buddies, results in the largest possible free region",
            " * within the zbud page.",
            " *",
            " * zbud also provides an attractive lower bound on density. The ratio of zpages",
            " * to zbud pages can not be less than 1.  This ensures that zbud can never \"do",
            " * harm\" by using more pages to store zpages than the uncompressed zpages would",
            " * have used on their own.",
            " *",
            " * zbud pages are divided into \"chunks\".  The size of the chunks is fixed at",
            " * compile time and determined by NCHUNKS_ORDER below.  Dividing zbud pages",
            " * into chunks allows organizing unbuddied zbud pages into a manageable number",
            " * of unbuddied lists according to the number of free chunks available in the",
            " * zbud page.",
            " *",
            " * The zbud API differs from that of conventional allocators in that the",
            " * allocation function, zbud_alloc(), returns an opaque handle to the user,",
            " * not a dereferenceable pointer.  The user must map the handle using",
            " * zbud_map() in order to get a usable pointer by which to access the",
            " * allocation data and unmap the handle with zbud_unmap() when operations",
            " * on the allocation data are complete.",
            " */",
            "",
            "#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt",
            "",
            "#include <linux/atomic.h>",
            "#include <linux/list.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/preempt.h>",
            "#include <linux/slab.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/zpool.h>",
            "",
            "/*****************",
            " * Structures",
            "*****************/",
            "/*",
            " * NCHUNKS_ORDER determines the internal allocation granularity, effectively",
            " * adjusting internal fragmentation.  It also determines the number of",
            " * freelists maintained in each pool. NCHUNKS_ORDER of 6 means that the",
            " * allocation granularity will be in chunks of size PAGE_SIZE/64. As one chunk",
            " * in allocated page is occupied by zbud header, NCHUNKS will be calculated to",
            " * 63 which shows the max number of free chunks in zbud page, also there will be",
            " * 63 freelists per pool.",
            " */",
            "#define NCHUNKS_ORDER\t6",
            "",
            "#define CHUNK_SHIFT\t(PAGE_SHIFT - NCHUNKS_ORDER)",
            "#define CHUNK_SIZE\t(1 << CHUNK_SHIFT)",
            "#define ZHDR_SIZE_ALIGNED CHUNK_SIZE",
            "#define NCHUNKS\t\t((PAGE_SIZE - ZHDR_SIZE_ALIGNED) >> CHUNK_SHIFT)",
            "",
            "struct zbud_pool;",
            "",
            "/**",
            " * struct zbud_pool - stores metadata for each zbud pool",
            " * @lock:\tprotects all pool fields and first|last_chunk fields of any",
            " *\t\tzbud page in the pool",
            " * @unbuddied:\tarray of lists tracking zbud pages that only contain one buddy;",
            " *\t\tthe lists each zbud page is added to depends on the size of",
            " *\t\tits free region.",
            " * @buddied:\tlist tracking the zbud pages that contain two buddies;",
            " *\t\tthese zbud pages are full",
            " * @pages_nr:\tnumber of zbud pages in the pool.",
            " *",
            " * This structure is allocated at pool creation time and maintains metadata",
            " * pertaining to a particular zbud pool.",
            " */",
            "struct zbud_pool {",
            "\tspinlock_t lock;",
            "\tunion {",
            "\t\t/*",
            "\t\t * Reuse unbuddied[0] as buddied on the ground that",
            "\t\t * unbuddied[0] is unused.",
            "\t\t */",
            "\t\tstruct list_head buddied;",
            "\t\tstruct list_head unbuddied[NCHUNKS];",
            "\t};",
            "\tu64 pages_nr;",
            "};",
            "",
            "/*",
            " * struct zbud_header - zbud page metadata occupying the first chunk of each",
            " *\t\t\tzbud page.",
            " * @buddy:\tlinks the zbud page into the unbuddied/buddied lists in the pool",
            " * @first_chunks:\tthe size of the first buddy in chunks, 0 if free",
            " * @last_chunks:\tthe size of the last buddy in chunks, 0 if free",
            " */",
            "struct zbud_header {",
            "\tstruct list_head buddy;",
            "\tunsigned int first_chunks;",
            "\tunsigned int last_chunks;",
            "};",
            "",
            "/*****************",
            " * Helpers",
            "*****************/",
            "/* Just to make the code easier to read */",
            "enum buddy {",
            "\tFIRST,",
            "\tLAST",
            "};",
            "",
            "/* Converts an allocation size in bytes to size in zbud chunks */"
          ],
          "function_name": null,
          "description": "定义了zbud内存分配器的核心结构体和宏，其中NCHUNKS_ORDER决定分配粒度，struct zbud_pool维护池元数据及空闲列表，struct zbud_header存储页元信息，为后续分配和回收提供基础数据结构。",
          "similarity": 0.5386306047439575
        },
        {
          "chunk_id": 1,
          "file_path": "mm/zbud.c",
          "start_line": 127,
          "end_line": 252,
          "content": [
            "static int size_to_chunks(size_t size)",
            "{",
            "\treturn (size + CHUNK_SIZE - 1) >> CHUNK_SHIFT;",
            "}",
            "static void free_zbud_page(struct zbud_header *zhdr)",
            "{",
            "\t__free_page(virt_to_page(zhdr));",
            "}",
            "static unsigned long encode_handle(struct zbud_header *zhdr, enum buddy bud)",
            "{",
            "\tunsigned long handle;",
            "",
            "\t/*",
            "\t * For now, the encoded handle is actually just the pointer to the data",
            "\t * but this might not always be the case.  A little information hiding.",
            "\t * Add CHUNK_SIZE to the handle if it is the first allocation to jump",
            "\t * over the zbud header in the first chunk.",
            "\t */",
            "\thandle = (unsigned long)zhdr;",
            "\tif (bud == FIRST)",
            "\t\t/* skip over zbud header */",
            "\t\thandle += ZHDR_SIZE_ALIGNED;",
            "\telse /* bud == LAST */",
            "\t\thandle += PAGE_SIZE - (zhdr->last_chunks  << CHUNK_SHIFT);",
            "\treturn handle;",
            "}",
            "static int num_free_chunks(struct zbud_header *zhdr)",
            "{",
            "\t/*",
            "\t * Rather than branch for different situations, just use the fact that",
            "\t * free buddies have a length of zero to simplify everything.",
            "\t */",
            "\treturn NCHUNKS - zhdr->first_chunks - zhdr->last_chunks;",
            "}",
            "static void zbud_destroy_pool(struct zbud_pool *pool)",
            "{",
            "\tkfree(pool);",
            "}",
            "static int zbud_alloc(struct zbud_pool *pool, size_t size, gfp_t gfp,",
            "\t\t\tunsigned long *handle)",
            "{",
            "\tint chunks, i, freechunks;",
            "\tstruct zbud_header *zhdr = NULL;",
            "\tenum buddy bud;",
            "\tstruct page *page;",
            "",
            "\tif (!size || (gfp & __GFP_HIGHMEM))",
            "\t\treturn -EINVAL;",
            "\tif (size > PAGE_SIZE - ZHDR_SIZE_ALIGNED - CHUNK_SIZE)",
            "\t\treturn -ENOSPC;",
            "\tchunks = size_to_chunks(size);",
            "\tspin_lock(&pool->lock);",
            "",
            "\t/* First, try to find an unbuddied zbud page. */",
            "\tfor_each_unbuddied_list(i, chunks) {",
            "\t\tif (!list_empty(&pool->unbuddied[i])) {",
            "\t\t\tzhdr = list_first_entry(&pool->unbuddied[i],",
            "\t\t\t\t\tstruct zbud_header, buddy);",
            "\t\t\tlist_del(&zhdr->buddy);",
            "\t\t\tif (zhdr->first_chunks == 0)",
            "\t\t\t\tbud = FIRST;",
            "\t\t\telse",
            "\t\t\t\tbud = LAST;",
            "\t\t\tgoto found;",
            "\t\t}",
            "\t}",
            "",
            "\t/* Couldn't find unbuddied zbud page, create new one */",
            "\tspin_unlock(&pool->lock);",
            "\tpage = alloc_page(gfp);",
            "\tif (!page)",
            "\t\treturn -ENOMEM;",
            "\tspin_lock(&pool->lock);",
            "\tpool->pages_nr++;",
            "\tzhdr = init_zbud_page(page);",
            "\tbud = FIRST;",
            "",
            "found:",
            "\tif (bud == FIRST)",
            "\t\tzhdr->first_chunks = chunks;",
            "\telse",
            "\t\tzhdr->last_chunks = chunks;",
            "",
            "\tif (zhdr->first_chunks == 0 || zhdr->last_chunks == 0) {",
            "\t\t/* Add to unbuddied list */",
            "\t\tfreechunks = num_free_chunks(zhdr);",
            "\t\tlist_add(&zhdr->buddy, &pool->unbuddied[freechunks]);",
            "\t} else {",
            "\t\t/* Add to buddied list */",
            "\t\tlist_add(&zhdr->buddy, &pool->buddied);",
            "\t}",
            "",
            "\t*handle = encode_handle(zhdr, bud);",
            "\tspin_unlock(&pool->lock);",
            "",
            "\treturn 0;",
            "}",
            "static void zbud_free(struct zbud_pool *pool, unsigned long handle)",
            "{",
            "\tstruct zbud_header *zhdr;",
            "\tint freechunks;",
            "",
            "\tspin_lock(&pool->lock);",
            "\tzhdr = handle_to_zbud_header(handle);",
            "",
            "\t/* If first buddy, handle will be page aligned */",
            "\tif ((handle - ZHDR_SIZE_ALIGNED) & ~PAGE_MASK)",
            "\t\tzhdr->last_chunks = 0;",
            "\telse",
            "\t\tzhdr->first_chunks = 0;",
            "",
            "\t/* Remove from existing buddy list */",
            "\tlist_del(&zhdr->buddy);",
            "",
            "\tif (zhdr->first_chunks == 0 && zhdr->last_chunks == 0) {",
            "\t\t/* zbud page is empty, free */",
            "\t\tfree_zbud_page(zhdr);",
            "\t\tpool->pages_nr--;",
            "\t} else {",
            "\t\t/* Add to unbuddied list */",
            "\t\tfreechunks = num_free_chunks(zhdr);",
            "\t\tlist_add(&zhdr->buddy, &pool->unbuddied[freechunks]);",
            "\t}",
            "",
            "\tspin_unlock(&pool->lock);",
            "}"
          ],
          "function_name": "size_to_chunks, free_zbud_page, encode_handle, num_free_chunks, zbud_destroy_pool, zbud_alloc, zbud_free",
          "description": "实现了zbud分配器的关键功能，包含大小转块计算、页面释放、句柄编码、空闲块统计等辅助函数，核心函数zbud_alloc尝试从空闲列表获取页或新建页面并分割存储，zbud_free处理释放逻辑并重新加入空闲列表。",
          "similarity": 0.4696403741836548
        },
        {
          "chunk_id": 2,
          "file_path": "mm/zbud.c",
          "start_line": 363,
          "end_line": 405,
          "content": [
            "static void zbud_unmap(struct zbud_pool *pool, unsigned long handle)",
            "{",
            "}",
            "static u64 zbud_get_pool_size(struct zbud_pool *pool)",
            "{",
            "\treturn pool->pages_nr;",
            "}",
            "static void zbud_zpool_destroy(void *pool)",
            "{",
            "\tzbud_destroy_pool(pool);",
            "}",
            "static int zbud_zpool_malloc(void *pool, size_t size, gfp_t gfp,",
            "\t\t\tunsigned long *handle)",
            "{",
            "\treturn zbud_alloc(pool, size, gfp, handle);",
            "}",
            "static void zbud_zpool_free(void *pool, unsigned long handle)",
            "{",
            "\tzbud_free(pool, handle);",
            "}",
            "static void zbud_zpool_unmap(void *pool, unsigned long handle)",
            "{",
            "\tzbud_unmap(pool, handle);",
            "}",
            "static u64 zbud_zpool_total_size(void *pool)",
            "{",
            "\treturn zbud_get_pool_size(pool) * PAGE_SIZE;",
            "}",
            "static int __init init_zbud(void)",
            "{",
            "\t/* Make sure the zbud header will fit in one chunk */",
            "\tBUILD_BUG_ON(sizeof(struct zbud_header) > ZHDR_SIZE_ALIGNED);",
            "\tpr_info(\"loaded\\n\");",
            "",
            "\tzpool_register_driver(&zbud_zpool_driver);",
            "",
            "\treturn 0;",
            "}",
            "static void __exit exit_zbud(void)",
            "{",
            "\tzpool_unregister_driver(&zbud_zpool_driver);",
            "\tpr_info(\"unloaded\\n\");",
            "}"
          ],
          "function_name": "zbud_unmap, zbud_get_pool_size, zbud_zpool_destroy, zbud_zpool_malloc, zbud_zpool_free, zbud_zpool_unmap, zbud_zpool_total_size, init_zbud, exit_zbud",
          "description": "提供了zpool驱动接口实现，包含池大小查询、内存释放、句柄解码等操作，通过zpool_register_driver注册驱动，init_zbud和exit_zbud分别负责模块加载时的初始化和卸载清理工作。",
          "similarity": 0.43988412618637085
        }
      ]
    }
  ]
}