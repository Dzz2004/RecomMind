{
  "query": "process vs thread",
  "timestamp": "2025-12-25 23:30:56",
  "retrieved_files": [
    {
      "source_file": "kernel/trace/trace_events_filter.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:18:57\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `trace\\trace_events_filter.c`\n\n---\n\n# trace_events_filter.c 技术文档\n\n## 1. 文件概述\n\n`trace_events_filter.c` 是 Linux 内核中用于实现通用事件过滤（event filtering）功能的核心文件。它为 ftrace 事件跟踪系统提供了一套灵活的表达式解析和执行机制，允许用户通过逻辑表达式（支持 `&&`、`||`、`!` 等操作符）对跟踪事件进行动态过滤。该模块支持对事件字段进行数值比较、字符串匹配、位运算以及 CPU 掩码过滤等多种操作，广泛应用于性能分析、调试和系统监控场景。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct filter_pred`**  \n  表示一个过滤谓词（predicate），包含：\n  - 字段指针（`field`）\n  - 比较值（`val`, `val2`）\n  - 操作符（`op`，如 `==`, `<`, `&` 等）\n  - 谓词执行函数类型（`fn_num`）\n  - 正则表达式（`regex`）或 CPU 掩码（`mask`）\n  - 取反标志（`not`）\n\n- **`struct prog_entry`**  \n  表示过滤程序中的一个指令条目，用于构建基于跳转的执行逻辑：\n  - `pred`：关联的谓词\n  - `when_to_branch`：分支条件（0 或 1）\n  - `target`：跳转目标索引\n\n- **`struct filter_parse_error`**  \n  用于记录表达式解析过程中的错误类型和位置。\n\n- **`enum filter_op_ids` 和 `enum filter_pred_fn`**  \n  定义支持的操作符（如 `OP_EQ`, `OP_GT`）和谓词执行函数类型（如 `FILTER_PRED_FN_U64`, `FILTER_PRED_FN_STRING`）。\n\n- **错误码枚举（`FILT_ERR_*`）**  \n  定义了 20 余种解析和语义错误，如 `FIELD_NOT_FOUND`、`INVALID_OP`、`MISSING_QUOTE` 等。\n\n### 关键函数/逻辑\n\n- **`is_not()`**  \n  判断 `!` 是否表示逻辑取反（排除 `!=` 和 `!~` 的情况）。\n\n- **`update_preds()`**  \n  在构建过滤程序时动态更新跳转目标，用于处理 `&&` 和 `||` 的优先级和短路求值。\n\n- **`free_predicate()`**  \n  释放谓词结构及其关联资源（正则、CPU 掩码等）。\n\n- **表达式解析器框架**  \n  支持回调函数 `parse_pred_fn`，允许不同事件类型自定义谓词解析逻辑。\n\n## 3. 关键实现\n\n### 表达式解析与程序生成\n\n该文件实现了一个两阶段的逻辑表达式处理机制：\n\n1. **词法与语法解析**：将用户输入的字符串（如 `\"pid > 100 && comm == 'bash'\"`）解析为操作符、字段名和值的序列。\n2. **程序生成**：将逻辑表达式转换为线性“程序”（`prog_entry` 数组），通过条件跳转模拟 `&&`（短路与）和 `||`（短路或）的语义。\n\n例如，表达式 `a && !b || c` 被编译为类似以下的跳转逻辑：\n```text\neval a; if false goto L2\neval b; if true  goto L2\nreturn true\nL2: eval c; if false goto FAIL\nreturn true\nFAIL: return false\n```\n\n### 操作符优先级处理\n\n通过宏 `OPS` 定义操作符顺序，特别要求 `<=` 在 `<` 之前、`>=` 在 `>` 之前，以确保词法分析时长操作符优先匹配。\n\n### 取反逻辑（`!`）处理\n\n使用栈和 `invert` 标志跟踪当前作用域内的取反层数。每遇到一个 `!` 就翻转 `invert`，括号会将当前 `invert` 值压栈，确保作用域隔离。\n\n### 多类型谓词支持\n\n通过 `filter_pred_fn` 枚举区分不同数据类型的比较函数（如 8/16/32/64 位有无符号整数、字符串、CPU 掩码、函数指针等），实现类型安全的字段比较。\n\n### 错误报告机制\n\n提供详细的错误码和位置信息（`filter_parse_error`），便于用户调试无效过滤表达式。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `trace.h` / `trace_output.h`：ftrace 核心接口和事件定义\n  - `linux/slab.h`：内存分配（`kmalloc`/`kfree`）\n  - `linux/ctype.h`：字符处理\n  - `linux/perf_event.h`：与 perf 事件子系统集成\n  - `linux/uaccess.h`：用户空间数据访问\n\n- **模块依赖**：\n  - 依赖 ftrace 事件注册机制（`ftrace_event_field`）\n  - 与 `trace_events.c` 协同工作，提供过滤能力\n  - 被 perf 和 ftrace 用户接口（如 `/sys/kernel/debug/tracing/events/.../filter`）调用\n\n## 5. 使用场景\n\n- **动态事件过滤**：用户通过写入 `/sys/kernel/debug/tracing/events/<subsys>/<event>/filter` 设置过滤条件，仅记录满足条件的事件。\n- **全局过滤**：通过 `set_event_filter` 设置跨多个事件的统一过滤规则。\n- **性能分析**：在高负载系统中减少无关事件的记录开销，提升跟踪效率。\n- **调试特定行为**：例如 `filter='pid == 1234'` 仅跟踪指定进程的事件，或 `filter='latency > 1000'` 捕获高延迟操作。\n- **安全与审计**：结合字段值过滤实现细粒度的系统行为监控。",
      "similarity": 0.5520410537719727,
      "chunks": [
        {
          "chunk_id": 11,
          "file_path": "kernel/trace/trace_events_filter.c",
          "start_line": 2543,
          "end_line": 2647,
          "content": [
            "static int ftrace_function_set_filter_pred(struct filter_pred *pred,",
            "\t\t\t\t\t   struct function_filter_data *data)",
            "{",
            "\tint ret;",
            "",
            "\t/* Checking the node is valid for function trace. */",
            "\tret = ftrace_function_check_pred(pred);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\treturn __ftrace_function_set_filter(pred->op == OP_EQ,",
            "\t\t\t\t\t    pred->regex->pattern,",
            "\t\t\t\t\t    pred->regex->len,",
            "\t\t\t\t\t    data);",
            "}",
            "static bool is_or(struct prog_entry *prog, int i)",
            "{",
            "\tint target;",
            "",
            "\t/*",
            "\t * Only \"||\" is allowed for function events, thus,",
            "\t * all true branches should jump to true, and any",
            "\t * false branch should jump to false.",
            "\t */",
            "\ttarget = prog[i].target + 1;",
            "\t/* True and false have NULL preds (all prog entries should jump to one */",
            "\tif (prog[target].pred)",
            "\t\treturn false;",
            "",
            "\t/* prog[target].target is 1 for TRUE, 0 for FALSE */",
            "\treturn prog[i].when_to_branch == prog[target].target;",
            "}",
            "static int ftrace_function_set_filter(struct perf_event *event,",
            "\t\t\t\t      struct event_filter *filter)",
            "{",
            "\tstruct prog_entry *prog = rcu_dereference_protected(filter->prog,",
            "\t\t\t\t\t\tlockdep_is_held(&event_mutex));",
            "\tstruct function_filter_data data = {",
            "\t\t.first_filter  = 1,",
            "\t\t.first_notrace = 1,",
            "\t\t.ops           = &event->ftrace_ops,",
            "\t};",
            "\tint i;",
            "",
            "\tfor (i = 0; prog[i].pred; i++) {",
            "\t\tstruct filter_pred *pred = prog[i].pred;",
            "",
            "\t\tif (!is_or(prog, i))",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\tif (ftrace_function_set_filter_pred(pred, &data) < 0)",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int ftrace_function_set_filter(struct perf_event *event,",
            "\t\t\t\t      struct event_filter *filter)",
            "{",
            "\treturn -ENODEV;",
            "}",
            "int ftrace_profile_set_filter(struct perf_event *event, int event_id,",
            "\t\t\t      char *filter_str)",
            "{",
            "\tint err;",
            "\tstruct event_filter *filter = NULL;",
            "\tstruct trace_event_call *call;",
            "",
            "\tmutex_lock(&event_mutex);",
            "",
            "\tcall = event->tp_event;",
            "",
            "\terr = -EINVAL;",
            "\tif (!call)",
            "\t\tgoto out_unlock;",
            "",
            "\terr = -EEXIST;",
            "\tif (event->filter)",
            "\t\tgoto out_unlock;",
            "",
            "\terr = create_filter(NULL, call, filter_str, false, &filter);",
            "\tif (err)",
            "\t\tgoto free_filter;",
            "",
            "\tif (ftrace_event_is_function(call))",
            "\t\terr = ftrace_function_set_filter(event, filter);",
            "\telse",
            "\t\tevent->filter = filter;",
            "",
            "free_filter:",
            "\tif (err || ftrace_event_is_function(call))",
            "\t\t__free_filter(filter);",
            "",
            "out_unlock:",
            "\tmutex_unlock(&event_mutex);",
            "",
            "\treturn err;",
            "}",
            "static int test_pred_visited_fn(struct filter_pred *pred, void *event)",
            "{",
            "\tstruct ftrace_event_field *field = pred->field;",
            "",
            "\ttest_pred_visited = 1;",
            "\tprintk(KERN_INFO \"\\npred visited %s\\n\", field->name);",
            "\treturn 1;",
            "}"
          ],
          "function_name": "ftrace_function_set_filter_pred, is_or, ftrace_function_set_filter, ftrace_function_set_filter, ftrace_profile_set_filter, test_pred_visited_fn",
          "description": "ftrace_function_set_filter_pred 将谓词转换为正则表达式并调用底层设置函数；is_or 检查程序流图中节点是否为OR逻辑分支；ftrace_function_set_filter 遍历过滤器谓词链表，校验逻辑结构后应用到函数跟踪；ftrace_profile_set_filter 创建事件过滤器并根据事件类型选择设置方式；test_pred_visited_fn 标记谓词访问状态用于测试",
          "similarity": 0.5039914846420288
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/trace/trace_events_filter.c",
          "start_line": 862,
          "end_line": 968,
          "content": [
            "static int filter_pred_pchar(struct filter_pred *pred, void *event)",
            "{",
            "\tchar **addr = (char **)(event + pred->offset);",
            "\tchar *str;",
            "",
            "\tstr = test_string(*addr);",
            "\tif (!str)",
            "\t\treturn 0;",
            "",
            "\treturn filter_pchar(pred, str);",
            "}",
            "static int filter_pred_pchar_user(struct filter_pred *pred, void *event)",
            "{",
            "\tchar **addr = (char **)(event + pred->offset);",
            "\tchar *str;",
            "",
            "\tstr = test_ustring(*addr);",
            "\tif (!str)",
            "\t\treturn 0;",
            "",
            "\treturn filter_pchar(pred, str);",
            "}",
            "static int filter_pred_strloc(struct filter_pred *pred, void *event)",
            "{",
            "\tu32 str_item = *(u32 *)(event + pred->offset);",
            "\tint str_loc = str_item & 0xffff;",
            "\tint str_len = str_item >> 16;",
            "\tchar *addr = (char *)(event + str_loc);",
            "\tint cmp, match;",
            "",
            "\tcmp = pred->regex->match(addr, pred->regex, str_len);",
            "",
            "\tmatch = cmp ^ pred->not;",
            "",
            "\treturn match;",
            "}",
            "static int filter_pred_strrelloc(struct filter_pred *pred, void *event)",
            "{",
            "\tu32 *item = (u32 *)(event + pred->offset);",
            "\tu32 str_item = *item;",
            "\tint str_loc = str_item & 0xffff;",
            "\tint str_len = str_item >> 16;",
            "\tchar *addr = (char *)(&item[1]) + str_loc;",
            "\tint cmp, match;",
            "",
            "\tcmp = pred->regex->match(addr, pred->regex, str_len);",
            "",
            "\tmatch = cmp ^ pred->not;",
            "",
            "\treturn match;",
            "}",
            "static int filter_pred_cpu(struct filter_pred *pred, void *event)",
            "{",
            "\tint cpu, cmp;",
            "",
            "\tcpu = raw_smp_processor_id();",
            "\tcmp = pred->val;",
            "",
            "\tswitch (pred->op) {",
            "\tcase OP_EQ:",
            "\t\treturn cpu == cmp;",
            "\tcase OP_NE:",
            "\t\treturn cpu != cmp;",
            "\tcase OP_LT:",
            "\t\treturn cpu < cmp;",
            "\tcase OP_LE:",
            "\t\treturn cpu <= cmp;",
            "\tcase OP_GT:",
            "\t\treturn cpu > cmp;",
            "\tcase OP_GE:",
            "\t\treturn cpu >= cmp;",
            "\tdefault:",
            "\t\treturn 0;",
            "\t}",
            "}",
            "static int filter_pred_cpu_cpumask(struct filter_pred *pred, void *event)",
            "{",
            "\tint cpu = raw_smp_processor_id();",
            "",
            "\treturn do_filter_scalar_cpumask(pred->op, cpu, pred->mask);",
            "}",
            "static int filter_pred_cpumask(struct filter_pred *pred, void *event)",
            "{",
            "\tu32 item = *(u32 *)(event + pred->offset);",
            "\tint loc = item & 0xffff;",
            "\tconst struct cpumask *mask = (event + loc);",
            "\tconst struct cpumask *cmp = pred->mask;",
            "",
            "\treturn do_filter_cpumask(pred->op, mask, cmp);",
            "}",
            "static int filter_pred_cpumask_cpu(struct filter_pred *pred, void *event)",
            "{",
            "\tu32 item = *(u32 *)(event + pred->offset);",
            "\tint loc = item & 0xffff;",
            "\tconst struct cpumask *mask = (event + loc);",
            "\tunsigned int cpu = pred->val;",
            "",
            "\treturn do_filter_cpumask_scalar(pred->op, mask, cpu);",
            "}",
            "static int filter_pred_comm(struct filter_pred *pred, void *event)",
            "{",
            "\tint cmp;",
            "",
            "\tcmp = pred->regex->match(current->comm, pred->regex,",
            "\t\t\t\tTASK_COMM_LEN);",
            "\treturn cmp ^ pred->not;",
            "}"
          ],
          "function_name": "filter_pred_pchar, filter_pred_pchar_user, filter_pred_strloc, filter_pred_strrelloc, filter_pred_cpu, filter_pred_cpu_cpumask, filter_pred_cpumask, filter_pred_cpumask_cpu, filter_pred_comm",
          "description": "提供针对字符串、位置、进程名等特殊数据类型的过滤实现，处理指针解引用和内存地址匹配。",
          "similarity": 0.5024742484092712
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/trace/trace_events_filter.c",
          "start_line": 1281,
          "end_line": 1422,
          "content": [
            "static void free_prog(struct event_filter *filter)",
            "{",
            "\tstruct prog_entry *prog;",
            "\tint i;",
            "",
            "\tprog = rcu_access_pointer(filter->prog);",
            "\tif (!prog)",
            "\t\treturn;",
            "",
            "\tfor (i = 0; prog[i].pred; i++)",
            "\t\tfree_predicate(prog[i].pred);",
            "\tkfree(prog);",
            "}",
            "static void filter_disable(struct trace_event_file *file)",
            "{",
            "\tunsigned long old_flags = file->flags;",
            "",
            "\tfile->flags &= ~EVENT_FILE_FL_FILTERED;",
            "",
            "\tif (old_flags != file->flags)",
            "\t\ttrace_buffered_event_disable();",
            "}",
            "static void __free_filter(struct event_filter *filter)",
            "{",
            "\tif (!filter)",
            "\t\treturn;",
            "",
            "\tfree_prog(filter);",
            "\tkfree(filter->filter_string);",
            "\tkfree(filter);",
            "}",
            "void free_event_filter(struct event_filter *filter)",
            "{",
            "\t__free_filter(filter);",
            "}",
            "static inline void __remove_filter(struct trace_event_file *file)",
            "{",
            "\tfilter_disable(file);",
            "\tremove_filter_string(file->filter);",
            "}",
            "static void filter_free_subsystem_preds(struct trace_subsystem_dir *dir,",
            "\t\t\t\t\tstruct trace_array *tr)",
            "{",
            "\tstruct trace_event_file *file;",
            "",
            "\tlist_for_each_entry(file, &tr->events, list) {",
            "\t\tif (file->system != dir)",
            "\t\t\tcontinue;",
            "\t\t__remove_filter(file);",
            "\t}",
            "}",
            "static inline void __free_subsystem_filter(struct trace_event_file *file)",
            "{",
            "\t__free_filter(file->filter);",
            "\tfile->filter = NULL;",
            "}",
            "static void filter_free_subsystem_filters(struct trace_subsystem_dir *dir,",
            "\t\t\t\t\t  struct trace_array *tr)",
            "{",
            "\tstruct trace_event_file *file;",
            "",
            "\tlist_for_each_entry(file, &tr->events, list) {",
            "\t\tif (file->system != dir)",
            "\t\t\tcontinue;",
            "\t\t__free_subsystem_filter(file);",
            "\t}",
            "}",
            "int filter_assign_type(const char *type)",
            "{",
            "\tif (strstr(type, \"__data_loc\")) {",
            "\t\tif (strstr(type, \"char\"))",
            "\t\t\treturn FILTER_DYN_STRING;",
            "\t\tif (strstr(type, \"cpumask_t\"))",
            "\t\t\treturn FILTER_CPUMASK;",
            "\t}",
            "",
            "\tif (strstr(type, \"__rel_loc\") && strstr(type, \"char\"))",
            "\t\treturn FILTER_RDYN_STRING;",
            "",
            "\tif (strchr(type, '[') && strstr(type, \"char\"))",
            "\t\treturn FILTER_STATIC_STRING;",
            "",
            "\tif (strcmp(type, \"char *\") == 0 || strcmp(type, \"const char *\") == 0)",
            "\t\treturn FILTER_PTR_STRING;",
            "",
            "\treturn FILTER_OTHER;",
            "}",
            "static enum filter_pred_fn select_comparison_fn(enum filter_op_ids op,",
            "\t\t\t\t\t\tint field_size, int field_is_signed)",
            "{",
            "\tenum filter_pred_fn fn = FILTER_PRED_FN_NOP;",
            "\tint pred_func_index = -1;",
            "",
            "\tswitch (op) {",
            "\tcase OP_EQ:",
            "\tcase OP_NE:",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tif (WARN_ON_ONCE(op < PRED_FUNC_START))",
            "\t\t\treturn fn;",
            "\t\tpred_func_index = op - PRED_FUNC_START;",
            "\t\tif (WARN_ON_ONCE(pred_func_index > PRED_FUNC_MAX))",
            "\t\t\treturn fn;",
            "\t}",
            "",
            "\tswitch (field_size) {",
            "\tcase 8:",
            "\t\tif (pred_func_index < 0)",
            "\t\t\tfn = FILTER_PRED_FN_64;",
            "\t\telse if (field_is_signed)",
            "\t\t\tfn = FILTER_PRED_FN_S64;",
            "\t\telse",
            "\t\t\tfn = FILTER_PRED_FN_U64;",
            "\t\tbreak;",
            "\tcase 4:",
            "\t\tif (pred_func_index < 0)",
            "\t\t\tfn = FILTER_PRED_FN_32;",
            "\t\telse if (field_is_signed)",
            "\t\t\tfn = FILTER_PRED_FN_S32;",
            "\t\telse",
            "\t\t\tfn = FILTER_PRED_FN_U32;",
            "\t\tbreak;",
            "\tcase 2:",
            "\t\tif (pred_func_index < 0)",
            "\t\t\tfn = FILTER_PRED_FN_16;",
            "\t\telse if (field_is_signed)",
            "\t\t\tfn = FILTER_PRED_FN_S16;",
            "\t\telse",
            "\t\t\tfn = FILTER_PRED_FN_U16;",
            "\t\tbreak;",
            "\tcase 1:",
            "\t\tif (pred_func_index < 0)",
            "\t\t\tfn = FILTER_PRED_FN_8;",
            "\t\telse if (field_is_signed)",
            "\t\t\tfn = FILTER_PRED_FN_S8;",
            "\t\telse",
            "\t\t\tfn = FILTER_PRED_FN_U8;",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn fn;",
            "}"
          ],
          "function_name": "free_prog, filter_disable, __free_filter, free_event_filter, __remove_filter, filter_free_subsystem_preds, __free_subsystem_filter, filter_free_subsystem_filters, filter_assign_type, select_comparison_fn",
          "description": "实现事件过滤器资源释放逻辑，包括释放predicate、过滤字符串和过滤器结构体，处理子系统过滤器的遍历和销毁，定义字段类型判断函数及比较函数选择逻辑",
          "similarity": 0.4933249354362488
        },
        {
          "chunk_id": 12,
          "file_path": "kernel/trace/trace_events_filter.c",
          "start_line": 2741,
          "end_line": 2822,
          "content": [
            "static void update_pred_fn(struct event_filter *filter, char *fields)",
            "{",
            "\tstruct prog_entry *prog = rcu_dereference_protected(filter->prog,",
            "\t\t\t\t\t\tlockdep_is_held(&event_mutex));",
            "\tint i;",
            "",
            "\tfor (i = 0; prog[i].pred; i++) {",
            "\t\tstruct filter_pred *pred = prog[i].pred;",
            "\t\tstruct ftrace_event_field *field = pred->field;",
            "",
            "\t\tWARN_ON_ONCE(pred->fn_num == FILTER_PRED_FN_NOP);",
            "",
            "\t\tif (!field) {",
            "\t\t\tWARN_ONCE(1, \"all leafs should have field defined %d\", i);",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tif (!strchr(fields, *field->name))",
            "\t\t\tcontinue;",
            "",
            "\t\tpred->fn_num = FILTER_PRED_TEST_VISITED;",
            "\t}",
            "}",
            "static __init int ftrace_test_event_filter(void)",
            "{",
            "\tint i;",
            "",
            "\tprintk(KERN_INFO \"Testing ftrace filter: \");",
            "",
            "\tfor (i = 0; i < DATA_CNT; i++) {",
            "\t\tstruct event_filter *filter = NULL;",
            "\t\tstruct test_filter_data_t *d = &test_filter_data[i];",
            "\t\tint err;",
            "",
            "\t\terr = create_filter(NULL, &event_ftrace_test_filter,",
            "\t\t\t\t    d->filter, false, &filter);",
            "\t\tif (err) {",
            "\t\t\tprintk(KERN_INFO",
            "\t\t\t       \"Failed to get filter for '%s', err %d\\n\",",
            "\t\t\t       d->filter, err);",
            "\t\t\t__free_filter(filter);",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\t/* Needed to dereference filter->prog */",
            "\t\tmutex_lock(&event_mutex);",
            "\t\t/*",
            "\t\t * The preemption disabling is not really needed for self",
            "\t\t * tests, but the rcu dereference will complain without it.",
            "\t\t */",
            "\t\tpreempt_disable();",
            "\t\tif (*d->not_visited)",
            "\t\t\tupdate_pred_fn(filter, d->not_visited);",
            "",
            "\t\ttest_pred_visited = 0;",
            "\t\terr = filter_match_preds(filter, &d->rec);",
            "\t\tpreempt_enable();",
            "",
            "\t\tmutex_unlock(&event_mutex);",
            "",
            "\t\t__free_filter(filter);",
            "",
            "\t\tif (test_pred_visited) {",
            "\t\t\tprintk(KERN_INFO",
            "\t\t\t       \"Failed, unwanted pred visited for filter %s\\n\",",
            "\t\t\t       d->filter);",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tif (err != d->match) {",
            "\t\t\tprintk(KERN_INFO",
            "\t\t\t       \"Failed to match filter '%s', expected %d\\n\",",
            "\t\t\t       d->filter, d->match);",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "",
            "\tif (i == DATA_CNT)",
            "\t\tprintk(KERN_CONT \"OK\\n\");",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "update_pred_fn, ftrace_test_event_filter",
          "description": "update_pred_fn 更新谓词节点的函数号标记已访问字段；ftrace_test_event_filter 自动测试过滤器匹配逻辑，通过创建过滤器、遍历谓词节点并验证匹配结果判断测试是否通过",
          "similarity": 0.4894578456878662
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/trace/trace_events_filter.c",
          "start_line": 2400,
          "end_line": 2508,
          "content": [
            "int apply_subsystem_event_filter(struct trace_subsystem_dir *dir,",
            "\t\t\t\t char *filter_string)",
            "{",
            "\tstruct event_subsystem *system = dir->subsystem;",
            "\tstruct trace_array *tr = dir->tr;",
            "\tstruct event_filter *filter = NULL;",
            "\tint err = 0;",
            "",
            "\tmutex_lock(&event_mutex);",
            "",
            "\t/* Make sure the system still has events */",
            "\tif (!dir->nr_events) {",
            "\t\terr = -ENODEV;",
            "\t\tgoto out_unlock;",
            "\t}",
            "",
            "\tif (!strcmp(strstrip(filter_string), \"0\")) {",
            "\t\tfilter_free_subsystem_preds(dir, tr);",
            "\t\tremove_filter_string(system->filter);",
            "\t\tfilter = system->filter;",
            "\t\tsystem->filter = NULL;",
            "\t\t/* Ensure all filters are no longer used */",
            "\t\ttracepoint_synchronize_unregister();",
            "\t\tfilter_free_subsystem_filters(dir, tr);",
            "\t\t__free_filter(filter);",
            "\t\tgoto out_unlock;",
            "\t}",
            "",
            "\terr = create_system_filter(dir, filter_string, &filter);",
            "\tif (filter) {",
            "\t\t/*",
            "\t\t * No event actually uses the system filter",
            "\t\t * we can free it without synchronize_rcu().",
            "\t\t */",
            "\t\t__free_filter(system->filter);",
            "\t\tsystem->filter = filter;",
            "\t}",
            "out_unlock:",
            "\tmutex_unlock(&event_mutex);",
            "",
            "\treturn err;",
            "}",
            "void ftrace_profile_free_filter(struct perf_event *event)",
            "{",
            "\tstruct event_filter *filter = event->filter;",
            "",
            "\tevent->filter = NULL;",
            "\t__free_filter(filter);",
            "}",
            "static int ftrace_function_set_regexp(struct ftrace_ops *ops, int filter,",
            "\t\t\t\t      int reset, char *re, int len)",
            "{",
            "\tint ret;",
            "",
            "\tif (filter)",
            "\t\tret = ftrace_set_filter(ops, re, len, reset);",
            "\telse",
            "\t\tret = ftrace_set_notrace(ops, re, len, reset);",
            "",
            "\treturn ret;",
            "}",
            "static int __ftrace_function_set_filter(int filter, char *buf, int len,",
            "\t\t\t\t\tstruct function_filter_data *data)",
            "{",
            "\tint i, re_cnt, ret = -EINVAL;",
            "\tint *reset;",
            "\tchar **re;",
            "",
            "\treset = filter ? &data->first_filter : &data->first_notrace;",
            "",
            "\t/*",
            "\t * The 'ip' field could have multiple filters set, separated",
            "\t * either by space or comma. We first cut the filter and apply",
            "\t * all pieces separately.",
            "\t */",
            "\tre = ftrace_function_filter_re(buf, len, &re_cnt);",
            "\tif (!re)",
            "\t\treturn -EINVAL;",
            "",
            "\tfor (i = 0; i < re_cnt; i++) {",
            "\t\tret = ftrace_function_set_regexp(data->ops, filter, *reset,",
            "\t\t\t\t\t\t re[i], strlen(re[i]));",
            "\t\tif (ret)",
            "\t\t\tbreak;",
            "",
            "\t\tif (*reset)",
            "\t\t\t*reset = 0;",
            "\t}",
            "",
            "\targv_free(re);",
            "\treturn ret;",
            "}",
            "static int ftrace_function_check_pred(struct filter_pred *pred)",
            "{",
            "\tstruct ftrace_event_field *field = pred->field;",
            "",
            "\t/*",
            "\t * Check the predicate for function trace, verify:",
            "\t *  - only '==' and '!=' is used",
            "\t *  - the 'ip' field is used",
            "\t */",
            "\tif ((pred->op != OP_EQ) && (pred->op != OP_NE))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (strcmp(field->name, \"ip\"))",
            "\t\treturn -EINVAL;",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "apply_subsystem_event_filter, ftrace_profile_free_filter, ftrace_function_set_regexp, __ftrace_function_set_filter, ftrace_function_check_pred",
          "description": "apply_subsystem_event_filter 根据过滤字符串设置子系统级事件过滤器，处理过滤器创建、释放及错误返回；ftrace_profile_free_filter 释放perf_event的过滤器指针；__ftrace_function_set_filter 将过滤字符串分割后依次应用正则表达式到函数跟踪操作；ftrace_function_check_pred 验证谓词操作类型和字段是否符合函数跟踪要求",
          "similarity": 0.48834484815597534
        }
      ]
    },
    {
      "source_file": "kernel/kthread.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:30:24\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kthread.c`\n\n---\n\n# kthread.c 技术文档\n\n## 文件概述\n\n`kthread.c` 是 Linux 内核中实现内核线程（kernel thread, kthread）管理机制的核心文件。它提供了创建、控制、同步和销毁内核线程的基础设施，确保内核线程在干净、受控的环境中运行，即使是从用户空间（如 modprobe、CPU 热插拔等）触发创建也能保证一致性。该文件实现了 kthread 的生命周期管理、状态控制（如停止、暂停）、数据访问接口以及与调度器、cgroup、freezer 等子系统的集成。\n\n## 核心功能\n\n### 主要数据结构\n\n- **`struct kthread_create_info`**  \n  用于在 `kthread_create()` 和后台守护线程 `kthreadd` 之间传递创建参数和结果，包含线程函数、数据、节点信息、任务结构体指针和完成量。\n\n- **`struct kthread`**  \n  内核线程的私有控制块，挂载在 `task_struct->worker_private` 上，包含：\n  - 状态标志位（`KTHREAD_IS_PER_CPU`, `KTHREAD_SHOULD_STOP`, `KTHREAD_SHOULD_PARK`）\n  - CPU 绑定信息\n  - 线程函数指针和用户数据\n  - 用于同步的 `parked` 和 `exited` 完成量\n  - 完整线程名（当 `task->comm` 被截断时使用）\n  - （可选）块设备 cgroup 上下文（`blkcg_css`）\n\n- **全局变量**\n  - `kthread_create_lock`：保护 `kthread_create_list` 的自旋锁\n  - `kthread_create_list`：待创建内核线程的请求队列\n  - `kthreadd_task`：负责实际创建内核线程的守护进程任务结构体\n\n### 主要函数\n\n- **状态查询函数**\n  - `kthread_should_stop()`：检查是否应停止线程（由 `kthread_stop()` 触发）\n  - `kthread_should_park()`：检查是否应暂停线程（由 `kthread_park()` 触发）\n  - `kthread_should_stop_or_park()`：同时检查停止或暂停请求\n  - `kthread_freezable_should_stop()`：支持冻结的 kthread 停止检查，集成 freezer 机制\n\n- **数据访问函数**\n  - `kthread_func()`：获取线程创建时指定的函数指针\n  - `kthread_data()`：获取线程创建时传入的私有数据\n  - `kthread_probe_data()`：安全地探测可能的 kthread 数据（使用 `copy_from_kernel_nofault` 避免崩溃）\n  - `get_kthread_comm()`：获取完整的线程名称（优先使用 `full_name`）\n\n- **生命周期管理**\n  - `set_kthread_struct()`：为新任务分配并初始化 `struct kthread`\n  - `free_kthread_struct()`：释放 `struct kthread` 及其资源\n  - `kthread_parkme()`：将当前线程置于 `TASK_PARKED` 状态并等待唤醒\n  - `kthread_exit()`：终止当前 kthread 并返回结果（未在代码片段中完整显示）\n\n- **辅助函数**\n  - `to_kthread()` / `__to_kthread()`：从 `task_struct` 安全转换为 `struct kthread`，后者不假设任务一定是 kthread\n\n## 关键实现\n\n### kthread 私有数据管理\n- 每个 kthread 通过 `task_struct->worker_private` 指向其 `struct kthread` 实例。\n- `to_kthread()` 在访问前验证 `PF_KTHREAD` 标志，确保类型安全。\n- `__to_kthread()` 更加保守，仅在同时满足 `worker_private != NULL` 且 `PF_KTHREAD` 时才返回有效指针，以应对 `kernel_thread()` 可能执行 `exec()` 导致标志失效的情况。\n\n### 线程暂停机制（Parking）\n- 使用 `TASK_PARKED` 特殊任务状态，避免与常规调度状态冲突。\n- 在设置状态和检查标志之间使用原子操作，防止唤醒丢失。\n- 调用 `schedule_preempt_disabled()` 禁用抢占，确保 `kthread_park()` 调用者能可靠检测到线程已暂停。\n\n### 安全数据访问\n- `kthread_probe_data()` 使用 `copy_from_kernel_nofault()` 安全读取数据指针，即使目标内存无效也不会导致内核 oops，适用于调试或不确定上下文。\n\n### 冻结集成\n- `kthread_freezable_should_stop()` 在检查停止标志前先处理冻结请求，调用 `__refrigerator()` 进入冻结状态，避免 freezer 与 kthread_stop 死锁。\n\n### 名称管理\n- 当线程名超过 `TASK_COMM_LEN` 时，原始名称存储在 `kthread->full_name` 中，`get_kthread_comm()` 优先返回完整名称。\n\n## 依赖关系\n\n- **调度子系统**：依赖 `sched.h` 提供任务状态管理、调度原语（`schedule()`）、CPU 隔离等。\n- **内存管理**：使用 `slab.h` 分配 `kthread` 结构，`mm.h` 处理内存上下文。\n- **同步机制**：依赖 `completion.h` 实现线程创建和状态同步。\n- **cgroup 子系统**：条件编译支持 `CONFIG_BLK_CGROUP`，集成块设备 cgroup 控制。\n- **冻结子系统**：通过 `freezer.h` 与系统 suspend/hibernate 机制协作。\n- **追踪系统**：集成 `trace/events/sched.h` 提供调度事件追踪。\n- **用户空间接口**：通过 `uaccess.h` 支持安全内核空间访问（用于 `kthread_probe_data`）。\n\n## 使用场景\n\n- **内核模块加载**：`modprobe` 触发的模块可能创建 kthread，需通过 `kthreadd` 确保干净环境。\n- **设备驱动**：驱动程序使用 `kthread_run()` 创建工作线程处理中断下半部或轮询任务。\n- **系统服务线程**：如 `kswapd`（内存回收）、`kcompactd`（内存压缩）等核心内核线程。\n- **CPU 热插拔**：在 CPU 上下线时创建或迁移 per-CPU kthread。\n- **电源管理**：通过 `kthread_freezable_should_stop()` 支持系统 suspend 时冻结 kthread。\n- **动态资源管理**：使用 `kthread_park/unpark` 暂停/恢复线程以节省资源（如空闲时暂停工作线程）。\n- **调试与监控**：工具通过 `kthread_func()` 和 `kthread_data()` 获取线程上下文信息。",
      "similarity": 0.5506833791732788,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/kthread.c",
          "start_line": 299,
          "end_line": 413,
          "content": [
            "void kthread_parkme(void)",
            "{",
            "\t__kthread_parkme(to_kthread(current));",
            "}",
            "void __noreturn kthread_exit(long result)",
            "{",
            "\tstruct kthread *kthread = to_kthread(current);",
            "\tkthread->result = result;",
            "\tdo_exit(0);",
            "}",
            "void __noreturn kthread_complete_and_exit(struct completion *comp, long code)",
            "{",
            "\tif (comp)",
            "\t\tcomplete(comp);",
            "",
            "\tkthread_exit(code);",
            "}",
            "static int kthread(void *_create)",
            "{",
            "\tstatic const struct sched_param param = { .sched_priority = 0 };",
            "\t/* Copy data: it's on kthread's stack */",
            "\tstruct kthread_create_info *create = _create;",
            "\tint (*threadfn)(void *data) = create->threadfn;",
            "\tvoid *data = create->data;",
            "\tstruct completion *done;",
            "\tstruct kthread *self;",
            "\tint ret;",
            "",
            "\tself = to_kthread(current);",
            "",
            "\t/* Release the structure when caller killed by a fatal signal. */",
            "\tdone = xchg(&create->done, NULL);",
            "\tif (!done) {",
            "\t\tkfree(create->full_name);",
            "\t\tkfree(create);",
            "\t\tkthread_exit(-EINTR);",
            "\t}",
            "",
            "\tself->full_name = create->full_name;",
            "\tself->threadfn = threadfn;",
            "\tself->data = data;",
            "",
            "\t/*",
            "\t * The new thread inherited kthreadd's priority and CPU mask. Reset",
            "\t * back to default in case they have been changed.",
            "\t */",
            "\tsched_setscheduler_nocheck(current, SCHED_NORMAL, &param);",
            "\tset_cpus_allowed_ptr(current, housekeeping_cpumask(HK_TYPE_KTHREAD));",
            "",
            "\t/* OK, tell user we're spawned, wait for stop or wakeup */",
            "\t__set_current_state(TASK_UNINTERRUPTIBLE);",
            "\tcreate->result = current;",
            "\t/*",
            "\t * Thread is going to call schedule(), do not preempt it,",
            "\t * or the creator may spend more time in wait_task_inactive().",
            "\t */",
            "\tpreempt_disable();",
            "\tcomplete(done);",
            "\tschedule_preempt_disabled();",
            "\tpreempt_enable();",
            "",
            "\tret = -EINTR;",
            "\tif (!test_bit(KTHREAD_SHOULD_STOP, &self->flags)) {",
            "\t\tcgroup_kthread_ready();",
            "\t\t__kthread_parkme(self);",
            "\t\tret = threadfn(data);",
            "\t}",
            "\tkthread_exit(ret);",
            "}",
            "int tsk_fork_get_node(struct task_struct *tsk)",
            "{",
            "#ifdef CONFIG_NUMA",
            "\tif (tsk == kthreadd_task)",
            "\t\treturn tsk->pref_node_fork;",
            "#endif",
            "\treturn NUMA_NO_NODE;",
            "}",
            "static void create_kthread(struct kthread_create_info *create)",
            "{",
            "\tint pid;",
            "",
            "#ifdef CONFIG_NUMA",
            "\tcurrent->pref_node_fork = create->node;",
            "#endif",
            "\t/* We want our own signal handler (we take no signals by default). */",
            "\tpid = kernel_thread(kthread, create, create->full_name,",
            "\t\t\t    CLONE_FS | CLONE_FILES | SIGCHLD);",
            "\tif (pid < 0) {",
            "\t\t/* Release the structure when caller killed by a fatal signal. */",
            "\t\tstruct completion *done = xchg(&create->done, NULL);",
            "",
            "\t\tkfree(create->full_name);",
            "\t\tif (!done) {",
            "\t\t\tkfree(create);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\tcreate->result = ERR_PTR(pid);",
            "\t\tcomplete(done);",
            "\t}",
            "}",
            "static void __kthread_bind_mask(struct task_struct *p, const struct cpumask *mask, unsigned int state)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tif (!wait_task_inactive(p, state)) {",
            "\t\tWARN_ON(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* It's safe because the task is inactive. */",
            "\traw_spin_lock_irqsave(&p->pi_lock, flags);",
            "\tdo_set_cpus_allowed(p, mask);",
            "\tp->flags |= PF_NO_SETAFFINITY;",
            "\traw_spin_unlock_irqrestore(&p->pi_lock, flags);",
            "}"
          ],
          "function_name": "kthread_parkme, kthread_exit, kthread_complete_and_exit, kthread, tsk_fork_get_node, create_kthread, __kthread_bind_mask",
          "description": "处理线程执行流程、节点绑定及异常退出，kthread作为内核线程入口执行指定函数，create_kthread创建新线程并绑定CPU，__kthread_bind_mask调整线程CPU亲和性。",
          "similarity": 0.5726369619369507
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/kthread.c",
          "start_line": 982,
          "end_line": 1095,
          "content": [
            "static inline bool queuing_blocked(struct kthread_worker *worker,",
            "\t\t\t\t   struct kthread_work *work)",
            "{",
            "\tlockdep_assert_held(&worker->lock);",
            "",
            "\treturn !list_empty(&work->node) || work->canceling;",
            "}",
            "static void kthread_insert_work_sanity_check(struct kthread_worker *worker,",
            "\t\t\t\t\t     struct kthread_work *work)",
            "{",
            "\tlockdep_assert_held(&worker->lock);",
            "\tWARN_ON_ONCE(!list_empty(&work->node));",
            "\t/* Do not use a work with >1 worker, see kthread_queue_work() */",
            "\tWARN_ON_ONCE(work->worker && work->worker != worker);",
            "}",
            "static void kthread_insert_work(struct kthread_worker *worker,",
            "\t\t\t\tstruct kthread_work *work,",
            "\t\t\t\tstruct list_head *pos)",
            "{",
            "\tkthread_insert_work_sanity_check(worker, work);",
            "",
            "\ttrace_sched_kthread_work_queue_work(worker, work);",
            "",
            "\tlist_add_tail(&work->node, pos);",
            "\twork->worker = worker;",
            "\tif (!worker->current_work && likely(worker->task))",
            "\t\twake_up_process(worker->task);",
            "}",
            "bool kthread_queue_work(struct kthread_worker *worker,",
            "\t\t\tstruct kthread_work *work)",
            "{",
            "\tbool ret = false;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&worker->lock, flags);",
            "\tif (!queuing_blocked(worker, work)) {",
            "\t\tkthread_insert_work(worker, work, &worker->work_list);",
            "\t\tret = true;",
            "\t}",
            "\traw_spin_unlock_irqrestore(&worker->lock, flags);",
            "\treturn ret;",
            "}",
            "void kthread_delayed_work_timer_fn(struct timer_list *t)",
            "{",
            "\tstruct kthread_delayed_work *dwork = from_timer(dwork, t, timer);",
            "\tstruct kthread_work *work = &dwork->work;",
            "\tstruct kthread_worker *worker = work->worker;",
            "\tunsigned long flags;",
            "",
            "\t/*",
            "\t * This might happen when a pending work is reinitialized.",
            "\t * It means that it is used a wrong way.",
            "\t */",
            "\tif (WARN_ON_ONCE(!worker))",
            "\t\treturn;",
            "",
            "\traw_spin_lock_irqsave(&worker->lock, flags);",
            "\t/* Work must not be used with >1 worker, see kthread_queue_work(). */",
            "\tWARN_ON_ONCE(work->worker != worker);",
            "",
            "\t/* Move the work from worker->delayed_work_list. */",
            "\tWARN_ON_ONCE(list_empty(&work->node));",
            "\tlist_del_init(&work->node);",
            "\tif (!work->canceling)",
            "\t\tkthread_insert_work(worker, work, &worker->work_list);",
            "",
            "\traw_spin_unlock_irqrestore(&worker->lock, flags);",
            "}",
            "static void __kthread_queue_delayed_work(struct kthread_worker *worker,",
            "\t\t\t\t\t struct kthread_delayed_work *dwork,",
            "\t\t\t\t\t unsigned long delay)",
            "{",
            "\tstruct timer_list *timer = &dwork->timer;",
            "\tstruct kthread_work *work = &dwork->work;",
            "",
            "\tWARN_ON_ONCE(timer->function != kthread_delayed_work_timer_fn);",
            "",
            "\t/*",
            "\t * If @delay is 0, queue @dwork->work immediately.  This is for",
            "\t * both optimization and correctness.  The earliest @timer can",
            "\t * expire is on the closest next tick and delayed_work users depend",
            "\t * on that there's no such delay when @delay is 0.",
            "\t */",
            "\tif (!delay) {",
            "\t\tkthread_insert_work(worker, work, &worker->work_list);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* Be paranoid and try to detect possible races already now. */",
            "\tkthread_insert_work_sanity_check(worker, work);",
            "",
            "\tlist_add(&work->node, &worker->delayed_work_list);",
            "\twork->worker = worker;",
            "\ttimer->expires = jiffies + delay;",
            "\tadd_timer(timer);",
            "}",
            "bool kthread_queue_delayed_work(struct kthread_worker *worker,",
            "\t\t\t\tstruct kthread_delayed_work *dwork,",
            "\t\t\t\tunsigned long delay)",
            "{",
            "\tstruct kthread_work *work = &dwork->work;",
            "\tunsigned long flags;",
            "\tbool ret = false;",
            "",
            "\traw_spin_lock_irqsave(&worker->lock, flags);",
            "",
            "\tif (!queuing_blocked(worker, work)) {",
            "\t\t__kthread_queue_delayed_work(worker, dwork, delay);",
            "\t\tret = true;",
            "\t}",
            "",
            "\traw_spin_unlock_irqrestore(&worker->lock, flags);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "queuing_blocked, kthread_insert_work_sanity_check, kthread_insert_work, kthread_queue_work, kthread_delayed_work_timer_fn, __kthread_queue_delayed_work, kthread_queue_delayed_work",
          "description": "实现kthread_worker与kthread_work的队列管理，包含插入/延迟插入逻辑、锁保护及任务唤醒机制，处理工作项状态校验和延迟定时器回调",
          "similarity": 0.5678578019142151
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/kthread.c",
          "start_line": 731,
          "end_line": 846,
          "content": [
            "int kthread_stop_put(struct task_struct *k)",
            "{",
            "\tint ret;",
            "",
            "\tret = kthread_stop(k);",
            "\tput_task_struct(k);",
            "\treturn ret;",
            "}",
            "int kthreadd(void *unused)",
            "{",
            "\tstruct task_struct *tsk = current;",
            "",
            "\t/* Setup a clean context for our children to inherit. */",
            "\tset_task_comm(tsk, \"kthreadd\");",
            "\tignore_signals(tsk);",
            "\tset_cpus_allowed_ptr(tsk, housekeeping_cpumask(HK_TYPE_KTHREAD));",
            "\tset_mems_allowed(node_states[N_MEMORY]);",
            "",
            "\tcurrent->flags |= PF_NOFREEZE;",
            "\tcgroup_init_kthreadd();",
            "",
            "\tfor (;;) {",
            "\t\tset_current_state(TASK_INTERRUPTIBLE);",
            "\t\tif (list_empty(&kthread_create_list))",
            "\t\t\tschedule();",
            "\t\t__set_current_state(TASK_RUNNING);",
            "",
            "\t\tspin_lock(&kthread_create_lock);",
            "\t\twhile (!list_empty(&kthread_create_list)) {",
            "\t\t\tstruct kthread_create_info *create;",
            "",
            "\t\t\tcreate = list_entry(kthread_create_list.next,",
            "\t\t\t\t\t    struct kthread_create_info, list);",
            "\t\t\tlist_del_init(&create->list);",
            "\t\t\tspin_unlock(&kthread_create_lock);",
            "",
            "\t\t\tcreate_kthread(create);",
            "",
            "\t\t\tspin_lock(&kthread_create_lock);",
            "\t\t}",
            "\t\tspin_unlock(&kthread_create_lock);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void __kthread_init_worker(struct kthread_worker *worker,",
            "\t\t\t\tconst char *name,",
            "\t\t\t\tstruct lock_class_key *key)",
            "{",
            "\tmemset(worker, 0, sizeof(struct kthread_worker));",
            "\traw_spin_lock_init(&worker->lock);",
            "\tlockdep_set_class_and_name(&worker->lock, key, name);",
            "\tINIT_LIST_HEAD(&worker->work_list);",
            "\tINIT_LIST_HEAD(&worker->delayed_work_list);",
            "}",
            "int kthread_worker_fn(void *worker_ptr)",
            "{",
            "\tstruct kthread_worker *worker = worker_ptr;",
            "\tstruct kthread_work *work;",
            "",
            "\t/*",
            "\t * FIXME: Update the check and remove the assignment when all kthread",
            "\t * worker users are created using kthread_create_worker*() functions.",
            "\t */",
            "\tWARN_ON(worker->task && worker->task != current);",
            "\tworker->task = current;",
            "",
            "\tif (worker->flags & KTW_FREEZABLE)",
            "\t\tset_freezable();",
            "",
            "repeat:",
            "\tset_current_state(TASK_INTERRUPTIBLE);\t/* mb paired w/ kthread_stop */",
            "",
            "\tif (kthread_should_stop()) {",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t\traw_spin_lock_irq(&worker->lock);",
            "\t\tworker->task = NULL;",
            "\t\traw_spin_unlock_irq(&worker->lock);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\twork = NULL;",
            "\traw_spin_lock_irq(&worker->lock);",
            "\tif (!list_empty(&worker->work_list)) {",
            "\t\twork = list_first_entry(&worker->work_list,",
            "\t\t\t\t\tstruct kthread_work, node);",
            "\t\tlist_del_init(&work->node);",
            "\t}",
            "\tworker->current_work = work;",
            "\traw_spin_unlock_irq(&worker->lock);",
            "",
            "\tif (work) {",
            "\t\tkthread_work_func_t func = work->func;",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t\ttrace_sched_kthread_work_execute_start(work);",
            "\t\twork->func(work);",
            "\t\t/*",
            "\t\t * Avoid dereferencing work after this point.  The trace",
            "\t\t * event only cares about the address.",
            "\t\t */",
            "\t\ttrace_sched_kthread_work_execute_end(work, func);",
            "\t} else if (!freezing(current)) {",
            "\t\tschedule();",
            "\t} else {",
            "\t\t/*",
            "\t\t * Handle the case where the current remains",
            "\t\t * TASK_INTERRUPTIBLE. try_to_freeze() expects",
            "\t\t * the current to be TASK_RUNNING.",
            "\t\t */",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t}",
            "",
            "\ttry_to_freeze();",
            "\tcond_resched();",
            "\tgoto repeat;",
            "}"
          ],
          "function_name": "kthread_stop_put, kthreadd, __kthread_init_worker, kthread_worker_fn",
          "description": "实现kthreadd主线程逻辑及工作队列管理，kthreadd持续处理线程创建请求，kthread_worker_fn作为工作队列执行入口，支持可冻结状态下的任务调度。",
          "similarity": 0.5244226455688477
        },
        {
          "chunk_id": 8,
          "file_path": "kernel/kthread.c",
          "start_line": 1490,
          "end_line": 1539,
          "content": [
            "void kthread_unuse_mm(struct mm_struct *mm)",
            "{",
            "\tstruct task_struct *tsk = current;",
            "",
            "\tWARN_ON_ONCE(!(tsk->flags & PF_KTHREAD));",
            "\tWARN_ON_ONCE(!tsk->mm);",
            "",
            "\ttask_lock(tsk);",
            "\t/*",
            "\t * When a kthread stops operating on an address space, the loop",
            "\t * in membarrier_{private,global}_expedited() may not observe",
            "\t * that tsk->mm, and not issue an IPI. Membarrier requires a",
            "\t * memory barrier after accessing user-space memory, before",
            "\t * clearing tsk->mm.",
            "\t */",
            "\tsmp_mb__after_spinlock();",
            "\tsync_mm_rss(mm);",
            "\tlocal_irq_disable();",
            "\ttsk->mm = NULL;",
            "\tmembarrier_update_current_mm(NULL);",
            "\t#ifdef CONFIG_IEE",
            "\tiee_set_token_pgd(tsk, NULL);",
            "\t#endif",
            "\tmmgrab_lazy_tlb(mm);",
            "\t/* active_mm is still 'mm' */",
            "\tenter_lazy_tlb(mm, tsk);",
            "\tlocal_irq_enable();",
            "\ttask_unlock(tsk);",
            "",
            "\tmmdrop(mm);",
            "}",
            "void kthread_associate_blkcg(struct cgroup_subsys_state *css)",
            "{",
            "\tstruct kthread *kthread;",
            "",
            "\tif (!(current->flags & PF_KTHREAD))",
            "\t\treturn;",
            "\tkthread = to_kthread(current);",
            "\tif (!kthread)",
            "\t\treturn;",
            "",
            "\tif (kthread->blkcg_css) {",
            "\t\tcss_put(kthread->blkcg_css);",
            "\t\tkthread->blkcg_css = NULL;",
            "\t}",
            "\tif (css) {",
            "\t\tcss_get(css);",
            "\t\tkthread->blkcg_css = css;",
            "\t}",
            "}"
          ],
          "function_name": "kthread_unuse_mm, kthread_associate_blkcg",
          "description": "管理kthread的地址空间切换，包含内存屏障同步、TLB更新及块控制组绑定操作，确保上下文切换安全性",
          "similarity": 0.5123224854469299
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/kthread.c",
          "start_line": 538,
          "end_line": 639,
          "content": [
            "static void __kthread_bind(struct task_struct *p, unsigned int cpu, unsigned int state)",
            "{",
            "\t__kthread_bind_mask(p, cpumask_of(cpu), state);",
            "}",
            "void kthread_bind_mask(struct task_struct *p, const struct cpumask *mask)",
            "{",
            "\t__kthread_bind_mask(p, mask, TASK_UNINTERRUPTIBLE);",
            "}",
            "void kthread_bind(struct task_struct *p, unsigned int cpu)",
            "{",
            "\t__kthread_bind(p, cpu, TASK_UNINTERRUPTIBLE);",
            "}",
            "void kthread_set_per_cpu(struct task_struct *k, int cpu)",
            "{",
            "\tstruct kthread *kthread = to_kthread(k);",
            "\tif (!kthread)",
            "\t\treturn;",
            "",
            "\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));",
            "",
            "\tif (cpu < 0) {",
            "\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);",
            "\t\treturn;",
            "\t}",
            "",
            "\tkthread->cpu = cpu;",
            "\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);",
            "}",
            "bool kthread_is_per_cpu(struct task_struct *p)",
            "{",
            "\tstruct kthread *kthread = __to_kthread(p);",
            "\tif (!kthread)",
            "\t\treturn false;",
            "",
            "\treturn test_bit(KTHREAD_IS_PER_CPU, &kthread->flags);",
            "}",
            "void kthread_unpark(struct task_struct *k)",
            "{",
            "\tstruct kthread *kthread = to_kthread(k);",
            "",
            "\tif (!test_bit(KTHREAD_SHOULD_PARK, &kthread->flags))",
            "\t\treturn;",
            "\t/*",
            "\t * Newly created kthread was parked when the CPU was offline.",
            "\t * The binding was lost and we need to set it again.",
            "\t */",
            "\tif (test_bit(KTHREAD_IS_PER_CPU, &kthread->flags))",
            "\t\t__kthread_bind(k, kthread->cpu, TASK_PARKED);",
            "",
            "\tclear_bit(KTHREAD_SHOULD_PARK, &kthread->flags);",
            "\t/*",
            "\t * __kthread_parkme() will either see !SHOULD_PARK or get the wakeup.",
            "\t */",
            "\twake_up_state(k, TASK_PARKED);",
            "}",
            "int kthread_park(struct task_struct *k)",
            "{",
            "\tstruct kthread *kthread = to_kthread(k);",
            "",
            "\tif (WARN_ON(k->flags & PF_EXITING))",
            "\t\treturn -ENOSYS;",
            "",
            "\tif (WARN_ON_ONCE(test_bit(KTHREAD_SHOULD_PARK, &kthread->flags)))",
            "\t\treturn -EBUSY;",
            "",
            "\tset_bit(KTHREAD_SHOULD_PARK, &kthread->flags);",
            "\tif (k != current) {",
            "\t\twake_up_process(k);",
            "\t\t/*",
            "\t\t * Wait for __kthread_parkme() to complete(), this means we",
            "\t\t * _will_ have TASK_PARKED and are about to call schedule().",
            "\t\t */",
            "\t\twait_for_completion(&kthread->parked);",
            "\t\t/*",
            "\t\t * Now wait for that schedule() to complete and the task to",
            "\t\t * get scheduled out.",
            "\t\t */",
            "\t\tWARN_ON_ONCE(!wait_task_inactive(k, TASK_PARKED));",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int kthread_stop(struct task_struct *k)",
            "{",
            "\tstruct kthread *kthread;",
            "\tint ret;",
            "",
            "\ttrace_sched_kthread_stop(k);",
            "",
            "\tget_task_struct(k);",
            "\tkthread = to_kthread(k);",
            "\tset_bit(KTHREAD_SHOULD_STOP, &kthread->flags);",
            "\tkthread_unpark(k);",
            "\tset_tsk_thread_flag(k, TIF_NOTIFY_SIGNAL);",
            "\twake_up_process(k);",
            "\twait_for_completion(&kthread->exited);",
            "\tret = kthread->result;",
            "\tput_task_struct(k);",
            "",
            "\ttrace_sched_kthread_stop_ret(ret);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__kthread_bind, kthread_bind_mask, kthread_bind, kthread_set_per_cpu, kthread_is_per_cpu, kthread_unpark, kthread_park, kthread_stop",
          "description": "提供线程CPU绑定、停放/终止控制接口，kthread_park/kthread_stop修改线程状态标志并触发唤醒，kthread_is_per_cpu检测线程是否固定CPU运行。",
          "similarity": 0.5068835020065308
        }
      ]
    },
    {
      "source_file": "kernel/sched/pelt.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:13:26\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\pelt.c`\n\n---\n\n# `sched/pelt.c` 技术文档\n\n## 1. 文件概述\n\n`sched/pelt.c` 实现了 **Per-Entity Load Tracking（PELT）** 机制，这是 Linux 内核 CFS（Completely Fair Scheduler）调度器中用于精确跟踪每个调度实体（如任务或任务组）负载、可运行性和 CPU 利用率的核心算法。  \nPELT 将时间划分为约 1ms（1024ns）的周期段，使用指数衰减的几何级数对历史负载进行加权求和，使得近期负载权重更高，远期负载影响逐渐衰减。该机制为负载均衡、能效调度（如 EAS）和 CPU 频率调节等子系统提供关键的负载指标。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `decay_load(u64 val, u64 n)`  \n  计算负载值 `val` 经过 `n` 个时间单位后的衰减值，利用预计算的衰减系数表和位移优化实现高效指数衰减。\n\n- `__accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)`  \n  计算跨越多个完整周期时，负载贡献的三部分之和：上一周期剩余部分（d1）、中间完整周期总和（d2）、当前周期已过部分（d3）。\n\n- `accumulate_sum(u64 delta, struct sched_avg *sa, unsigned long load, unsigned long runnable, int running)`  \n  核心累加函数，根据时间增量 `delta` 更新 `load_sum`、`runnable_sum` 和 `util_sum`，处理跨周期衰减与新贡献累加。\n\n- `___update_load_sum(u64 now, struct sched_avg *sa, unsigned long load, unsigned long runnable, int running)`  \n  入口函数，计算自上次更新以来的时间差，调用 `accumulate_sum` 更新负载总和，并处理时间回退等异常情况。\n\n- `___update_load_avg(struct sched_avg *sa, unsigned long load)`  \n  根据当前 `*_sum` 值和动态除数（divider）计算并更新 `load_avg`、`runnable_avg` 和 `util_avg`。\n\n### 关键数据结构\n\n- `struct sched_avg`  \n  存储 PELT 相关状态，包括：\n  - `load_sum` / `runnable_sum` / `util_sum`：衰减加权后的负载总和\n  - `load_avg` / `runnable_avg` / `util_avg`：归一化后的平均负载值\n  - `last_update_time`：上次更新时间戳\n  - `period_contrib`：当前周期内已累积的时间（<1024ns）\n\n## 3. 关键实现\n\n### 时间分段与衰减模型\n- 时间以 **1024ns（≈1μs）** 为基本单位，每 **1024 单位（≈1ms）** 构成一个 PELT 周期。\n- 衰减因子 `y` 满足 `y^32 ≈ 0.5`，即约 32ms 前的负载贡献衰减至当前的一半。\n- 负载历史表示为几何级数：`u₀ + u₁·y + u₂·y² + ...`，其中 `uᵢ` 是第 `i` 个周期内的可运行比例。\n\n### 高效衰减计算\n- `decay_load()` 利用 `y^32 = 1/2` 的特性，将 `y^n` 拆分为 `1/2^(n/32) * y^(n%32)`。\n- 通过右移操作快速计算 `1/2^k` 部分，再查表 `runnable_avg_yN_inv[]` 获取 `y^(n%32)` 的倒数，结合 `mul_u64_u32_shr` 完成乘法。\n\n### 负载累加三段式\n当时间增量跨越多个周期时，负载贡献分为：\n1. **d1**：上一周期未完成部分（`1024 - period_contrib`）\n2. **d2**：中间完整周期的理论最大贡献（`LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024`）\n3. **d3**：当前周期已过部分（`delta % 1024`）\n\n### 动态归一化\n- 使用 `get_pelt_divider()` 获取当前周期位置对应的归一化除数，避免因周期未结束导致的平均值震荡。\n- 除数公式：`LOAD_AVG_MAX - 1024 + period_contrib`，确保最大负载值在 `[1002, 1024)` 区间稳定。\n\n### 状态一致性保障\n- 若 `load == 0`，强制 `runnable = running = 0`，避免已出队实体产生无效贡献。\n- 时间回退（如 TSC 切换）时直接重置 `last_update_time`，防止负时间差导致异常。\n\n## 4. 依赖关系\n\n- **头文件依赖**：  \n  依赖 `kernel/sched/sched.h` 中定义的 `struct sched_avg`、`SCHED_CAPACITY_SHIFT`、`LOAD_AVG_*` 常量及 `get_pelt_divider()` 等辅助函数。\n- **预计算表**：  \n  使用外部定义的 `runnable_avg_yN_inv[32]` 衰减系数表（通常在 `fair.c` 或 `pelt.h` 中初始化）。\n- **调度器集成**：  \n  被 `fair.c` 中的 CFS 调度实体（`sched_entity`）和 CFS 运行队列（`cfs_rq`）调用，用于更新任务/任务组的负载状态。\n- **能效调度**：  \n  为 Energy Aware Scheduling (EAS) 提供 `util_avg` 作为 CPU 需求预测依据。\n\n## 5. 使用场景\n\n- **任务负载跟踪**：  \n  每个 `task_struct` 的 `sched_entity` 通过 PELT 实时更新其 `load_avg` 和 `util_avg`，反映任务对 CPU 的历史需求。\n- **任务组调度**：  \n  CFS 任务组（`task_group`）的 `cfs_rq` 使用 PELT 聚合子任务的负载，实现层级化负载均衡。\n- **负载均衡决策**：  \n  `load_balance()` 等函数依据 `runnable_avg` 判断 CPU 间负载差异，触发任务迁移。\n- **CPU 频率调节**：  \n  CPUFreq 的 `schedutil` 调速器使用 `util_avg` 动态调整 CPU 频率，平衡性能与功耗。\n- **空闲负载处理**：  \n  在 `idle_balance()` 等场景中，即使任务已出队，仍需通过 PELT 正确衰减其历史负载贡献。",
      "similarity": 0.5278342366218567,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/pelt.c",
          "start_line": 31,
          "end_line": 178,
          "content": [
            "static u64 decay_load(u64 val, u64 n)",
            "{",
            "\tunsigned int local_n;",
            "",
            "\tif (unlikely(n > LOAD_AVG_PERIOD * 63))",
            "\t\treturn 0;",
            "",
            "\t/* after bounds checking we can collapse to 32-bit */",
            "\tlocal_n = n;",
            "",
            "\t/*",
            "\t * As y^PERIOD = 1/2, we can combine",
            "\t *    y^n = 1/2^(n/PERIOD) * y^(n%PERIOD)",
            "\t * With a look-up table which covers y^n (n<PERIOD)",
            "\t *",
            "\t * To achieve constant time decay_load.",
            "\t */",
            "\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {",
            "\t\tval >>= local_n / LOAD_AVG_PERIOD;",
            "\t\tlocal_n %= LOAD_AVG_PERIOD;",
            "\t}",
            "",
            "\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);",
            "\treturn val;",
            "}",
            "static u32 __accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)",
            "{",
            "\tu32 c1, c2, c3 = d3; /* y^0 == 1 */",
            "",
            "\t/*",
            "\t * c1 = d1 y^p",
            "\t */",
            "\tc1 = decay_load((u64)d1, periods);",
            "",
            "\t/*",
            "\t *            p-1",
            "\t * c2 = 1024 \\Sum y^n",
            "\t *            n=1",
            "\t *",
            "\t *              inf        inf",
            "\t *    = 1024 ( \\Sum y^n - \\Sum y^n - y^0 )",
            "\t *              n=0        n=p",
            "\t */",
            "\tc2 = LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024;",
            "",
            "\treturn c1 + c2 + c3;",
            "}",
            "static __always_inline u32",
            "accumulate_sum(u64 delta, struct sched_avg *sa,",
            "\t       unsigned long load, unsigned long runnable, int running)",
            "{",
            "\tu32 contrib = (u32)delta; /* p == 0 -> delta < 1024 */",
            "\tu64 periods;",
            "",
            "\tdelta += sa->period_contrib;",
            "\tperiods = delta / 1024; /* A period is 1024us (~1ms) */",
            "",
            "\t/*",
            "\t * Step 1: decay old *_sum if we crossed period boundaries.",
            "\t */",
            "\tif (periods) {",
            "\t\tsa->load_sum = decay_load(sa->load_sum, periods);",
            "\t\tsa->runnable_sum =",
            "\t\t\tdecay_load(sa->runnable_sum, periods);",
            "\t\tsa->util_sum = decay_load((u64)(sa->util_sum), periods);",
            "",
            "\t\t/*",
            "\t\t * Step 2",
            "\t\t */",
            "\t\tdelta %= 1024;",
            "\t\tif (load) {",
            "\t\t\t/*",
            "\t\t\t * This relies on the:",
            "\t\t\t *",
            "\t\t\t * if (!load)",
            "\t\t\t *\trunnable = running = 0;",
            "\t\t\t *",
            "\t\t\t * clause from ___update_load_sum(); this results in",
            "\t\t\t * the below usage of @contrib to disappear entirely,",
            "\t\t\t * so no point in calculating it.",
            "\t\t\t */",
            "\t\t\tcontrib = __accumulate_pelt_segments(periods,",
            "\t\t\t\t\t1024 - sa->period_contrib, delta);",
            "\t\t}",
            "\t}",
            "\tsa->period_contrib = delta;",
            "",
            "\tif (load)",
            "\t\tsa->load_sum += load * contrib;",
            "\tif (runnable)",
            "\t\tsa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;",
            "\tif (running)",
            "\t\tsa->util_sum += contrib << SCHED_CAPACITY_SHIFT;",
            "",
            "\treturn periods;",
            "}",
            "static __always_inline int",
            "___update_load_sum(u64 now, struct sched_avg *sa,",
            "\t\t  unsigned long load, unsigned long runnable, int running)",
            "{",
            "\tu64 delta;",
            "",
            "\tdelta = now - sa->last_update_time;",
            "\t/*",
            "\t * This should only happen when time goes backwards, which it",
            "\t * unfortunately does during sched clock init when we swap over to TSC.",
            "\t */",
            "\tif ((s64)delta < 0) {",
            "\t\tsa->last_update_time = now;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * Use 1024ns as the unit of measurement since it's a reasonable",
            "\t * approximation of 1us and fast to compute.",
            "\t */",
            "\tdelta >>= 10;",
            "\tif (!delta)",
            "\t\treturn 0;",
            "",
            "\tsa->last_update_time += delta << 10;",
            "",
            "\t/*",
            "\t * running is a subset of runnable (weight) so running can't be set if",
            "\t * runnable is clear. But there are some corner cases where the current",
            "\t * se has been already dequeued but cfs_rq->curr still points to it.",
            "\t * This means that weight will be 0 but not running for a sched_entity",
            "\t * but also for a cfs_rq if the latter becomes idle. As an example,",
            "\t * this happens during idle_balance() which calls",
            "\t * sched_balance_update_blocked_averages().",
            "\t *",
            "\t * Also see the comment in accumulate_sum().",
            "\t */",
            "\tif (!load)",
            "\t\trunnable = running = 0;",
            "",
            "\t/*",
            "\t * Now we know we crossed measurement unit boundaries. The *_avg",
            "\t * accrues by two steps:",
            "\t *",
            "\t * Step 1: accumulate *_sum since last_update_time. If we haven't",
            "\t * crossed period boundaries, finish.",
            "\t */",
            "\tif (!accumulate_sum(delta, sa, load, runnable, running))",
            "\t\treturn 0;",
            "",
            "\treturn 1;",
            "}"
          ],
          "function_name": "decay_load, __accumulate_pelt_segments, accumulate_sum, ___update_load_sum",
          "description": "实现PELT核心算法，包含四个关键函数：decay_load通过位移运算模拟指数衰减；__accumulate_pelt_segments计算周期性负载贡献；accumulate_sum根据时间差更新负载、运行时和利用率的加权总和；___update_load_sum处理时间边界穿越时的衰减逻辑并触发更新。所有函数共同维护调度实体的动态负载统计",
          "similarity": 0.47421082854270935
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/pelt.c",
          "start_line": 1,
          "end_line": 30,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Per Entity Load Tracking",
            " *",
            " *  Copyright (C) 2007 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>",
            " *",
            " *  Interactivity improvements by Mike Galbraith",
            " *  (C) 2007 Mike Galbraith <efault@gmx.de>",
            " *",
            " *  Various enhancements by Dmitry Adamushko.",
            " *  (C) 2007 Dmitry Adamushko <dmitry.adamushko@gmail.com>",
            " *",
            " *  Group scheduling enhancements by Srivatsa Vaddagiri",
            " *  Copyright IBM Corporation, 2007",
            " *  Author: Srivatsa Vaddagiri <vatsa@linux.vnet.ibm.com>",
            " *",
            " *  Scaled math optimizations by Thomas Gleixner",
            " *  Copyright (C) 2007, Thomas Gleixner <tglx@linutronix.de>",
            " *",
            " *  Adaptive scheduling granularity, math enhancements by Peter Zijlstra",
            " *  Copyright (C) 2007 Red Hat, Inc., Peter Zijlstra",
            " *",
            " *  Move PELT related code from fair.c into this pelt.c file",
            " *  Author: Vincent Guittot <vincent.guittot@linaro.org>",
            " */",
            "",
            "/*",
            " * Approximate:",
            " *   val * y^n,    where y^32 ~= 0.5 (~1 scheduling period)",
            " */"
          ],
          "function_name": null,
          "description": "此代码块为PELT（Per-entity Load Tracking）模块的头部注释，声明了该模块的版权信息、作者及主要贡献者，并概述了PELT算法的目标，即通过时间衰减模型精确跟踪调度实体的负载变化，支持交互性优化、分组调度等功能。上下文不完整",
          "similarity": 0.46042370796203613
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/pelt.c",
          "start_line": 256,
          "end_line": 384,
          "content": [
            "static __always_inline void",
            "___update_load_avg(struct sched_avg *sa, unsigned long load)",
            "{",
            "\tu32 divider = get_pelt_divider(sa);",
            "",
            "\t/*",
            "\t * Step 2: update *_avg.",
            "\t */",
            "\tsa->load_avg = div_u64(load * sa->load_sum, divider);",
            "\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);",
            "\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);",
            "}",
            "int __update_load_avg_blocked_se(u64 now, struct sched_entity *se)",
            "{",
            "\tif (___update_load_sum(now, &se->avg, 0, 0, 0)) {",
            "\t\t___update_load_avg(&se->avg, se_weight(se));",
            "\t\ttrace_pelt_se_tp(se);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int __update_load_avg_se(u64 now, struct cfs_rq *cfs_rq, struct sched_entity *se)",
            "{",
            "\tif (___update_load_sum(now, &se->avg, !!se->on_rq, se_runnable(se),",
            "\t\t\t\tcfs_rq->curr == se)) {",
            "",
            "\t\t___update_load_avg(&se->avg, se_weight(se));",
            "\t\tcfs_se_util_change(&se->avg);",
            "\t\ttrace_pelt_se_tp(se);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int __update_load_avg_cfs_rq(u64 now, struct cfs_rq *cfs_rq)",
            "{",
            "\tif (___update_load_sum(now, &cfs_rq->avg,",
            "\t\t\t\tscale_load_down(cfs_rq->load.weight),",
            "\t\t\t\tcfs_rq->h_nr_running,",
            "\t\t\t\tcfs_rq->curr != NULL)) {",
            "",
            "\t\t___update_load_avg(&cfs_rq->avg, 1);",
            "\t\ttrace_pelt_cfs_tp(cfs_rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_rt_rq_load_avg(u64 now, struct rq *rq, int running)",
            "{",
            "\tif (___update_load_sum(now, &rq->avg_rt,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning)) {",
            "",
            "\t\t___update_load_avg(&rq->avg_rt, 1);",
            "\t\ttrace_pelt_rt_tp(rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_dl_rq_load_avg(u64 now, struct rq *rq, int running)",
            "{",
            "\tif (___update_load_sum(now, &rq->avg_dl,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning,",
            "\t\t\t\trunning)) {",
            "",
            "\t\t___update_load_avg(&rq->avg_dl, 1);",
            "\t\ttrace_pelt_dl_tp(rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_hw_load_avg(u64 now, struct rq *rq, u64 capacity)",
            "{",
            "\tif (___update_load_sum(now, &rq->avg_hw,",
            "\t\t\t       capacity,",
            "\t\t\t       capacity,",
            "\t\t\t       capacity)) {",
            "\t\t___update_load_avg(&rq->avg_hw, 1);",
            "\t\ttrace_pelt_hw_tp(rq);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int update_irq_load_avg(struct rq *rq, u64 running)",
            "{",
            "\tint ret = 0;",
            "",
            "\t/*",
            "\t * We can't use clock_pelt because irq time is not accounted in",
            "\t * clock_task. Instead we directly scale the running time to",
            "\t * reflect the real amount of computation",
            "\t */",
            "\trunning = cap_scale(running, arch_scale_freq_capacity(cpu_of(rq)));",
            "\trunning = cap_scale(running, arch_scale_cpu_capacity(cpu_of(rq)));",
            "",
            "\t/*",
            "\t * We know the time that has been used by interrupt since last update",
            "\t * but we don't when. Let be pessimistic and assume that interrupt has",
            "\t * happened just before the update. This is not so far from reality",
            "\t * because interrupt will most probably wake up task and trig an update",
            "\t * of rq clock during which the metric is updated.",
            "\t * We start to decay with normal context time and then we add the",
            "\t * interrupt context time.",
            "\t * We can safely remove running from rq->clock because",
            "\t * rq->clock += delta with delta >= running",
            "\t */",
            "\tret = ___update_load_sum(rq->clock - running, &rq->avg_irq,",
            "\t\t\t\t0,",
            "\t\t\t\t0,",
            "\t\t\t\t0);",
            "\tret += ___update_load_sum(rq->clock, &rq->avg_irq,",
            "\t\t\t\t1,",
            "\t\t\t\t1,",
            "\t\t\t\t1);",
            "",
            "\tif (ret) {",
            "\t\t___update_load_avg(&rq->avg_irq, 1);",
            "\t\ttrace_pelt_irq_tp(rq);",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "___update_load_avg, __update_load_avg_blocked_se, __update_load_avg_se, __update_load_avg_cfs_rq, update_rt_rq_load_avg, update_dl_rq_load_avg, update_hw_load_avg, update_irq_load_avg",
          "description": "提供多场景下的负载平均值更新接口，包含六个函数：___update_load_avg计算负载平均值；__update_load_avg_blocked_se更新阻塞任务实体；__update_load_avg_se处理CFS队列中任务实体；__update_load_avg_cfs_rq更新CFS队列负载；update_rt_rq_load_avg/update_dl_rq_load_avg分别处理实时/延迟调度队列；update_hw_load_avg和update_irq_load_avg分别更新硬件资源及中断负载统计",
          "similarity": 0.43609708547592163
        }
      ]
    }
  ]
}