{
  "query": "预取策略",
  "timestamp": "2025-12-26 01:44:42",
  "retrieved_files": [
    {
      "source_file": "mm/mempolicy.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:44:01\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `mempolicy.c`\n\n---\n\n# mempolicy.c 技术文档\n\n## 1. 文件概述\n\n`mempolicy.c` 实现了 Linux 内核中的 NUMA（Non-Uniform Memory Access）内存策略机制，允许用户通过系统调用为进程或虚拟内存区域（VMA）指定内存分配偏好。该机制支持多种内存分配策略，包括本地优先、绑定节点、轮询交错和基于权重的交错分配等，以优化多节点 NUMA 系统上的内存访问性能。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct mempolicy`：表示内存策略的核心结构，包含策略模式（如 MPOL_INTERLEAVE、MPOL_BIND、MPOL_PREFERRED 等）、节点掩码（nodemask）和引用计数。\n- `struct weighted_interleave_state`：用于实现加权交错分配策略，包含每个节点的权重表（iw_table）和自动模式标志。\n- `default_policy`：全局默认内存策略，初始为 MPOL_LOCAL（本地节点优先）。\n- `preferred_node_policy[MAX_NUMNODES]`：为每个节点预定义的首选策略数组。\n\n### 主要函数与接口\n- `get_il_weight(int node)`：获取指定节点在加权交错策略中的权重。\n- `reduce_interleave_weights(unsigned int *bw, u8 *new_iw)`：将带宽值转换为归一化的交错权重。\n- `mempolicy_set_node_perf(unsigned int node, struct access_coordinate *coords)`：根据节点性能坐标（读/写带宽）动态更新加权交错策略。\n- 多个辅助函数用于策略创建、复制、合并、验证及与 VMA 和进程上下文的集成。\n\n### 全局变量\n- `policy_cache` / `sn_cache`：用于高效分配 mempolicy 和相关子结构的 slab 缓存。\n- `policy_zone`：标识受策略控制的最高内存区域类型（zone_type），低区域（如 GFP_DMA）不应用策略。\n- `wi_state`：RCU 保护的加权交错状态指针。\n- `node_bw_table`：存储各节点带宽信息，用于动态权重计算。\n- `weightiness`：权重归一化常量（值为 32），平衡权重精度与分配公平性。\n\n## 3. 关键实现\n\n### 策略优先级与作用域\n- **VMA 策略优先于进程策略**：页错误处理时，若 VMA 有策略则使用 VMA 策略，否则回退到当前进程的策略。\n- **中断上下文忽略策略**：所有中断相关的内存分配始终尝试在本地 CPU 节点分配。\n- **策略不跨 swap 保留**：进程策略在页面换出/换入时不被保留。\n\n### 加权交错分配（Weighted Interleave）\n- 基于各 NUMA 节点的读/写带宽动态计算分配权重。\n- 使用 `weightiness=32` 对带宽进行缩放，并通过 GCD（最大公约数）约简权重以减少分配周期长度。\n- 权重状态通过 RCU 机制安全更新，读路径无锁，写路径由 `wi_state_lock` 互斥锁保护。\n\n### 策略类型详解\n- **interleave**：按偏移量（VMA）或进程计数器（进程）在节点集上轮询分配。\n- **weighted interleave**：按节点权重比例分配（如权重 [2,1] 表示节点0:节点1 = 2:1）。\n- **bind**：严格限制在指定节点集分配，无回退（当前实现按节点顺序分配，非最优）。\n- **preferred / preferred many**：优先在指定单个/多个节点分配，失败后回退到默认策略。\n- **default / local**：优先本地节点分配，VMA 中则继承进程策略。\n\n### 内存区域限制\n- 仅对 **最高 zone 层级**（如 NORMAL 或 MOVABLE）应用策略，GFP_DMA、HIGHMEM 等低层级分配忽略策略。\n\n### 特殊共享内存处理\n- **shmem/tmpfs**：策略在所有映射进程间共享，即使无活跃映射也持久保存。\n\n## 4. 依赖关系\n\n- **内存管理子系统**：依赖 `<linux/mm.h>`、`<linux/vm_area_struct.h>`、`<linux/page-flags.h>` 等进行页分配、VMA 操作和页表遍历。\n- **NUMA 感知调度**：与 `<linux/sched/numa_balancing.h>` 协同，支持自动 NUMA 迁移。\n- **CPUSET 子系统**：通过 `<linux/cpuset.h>` 集成节点可用性约束。\n- **Slab 分配器**：使用 kmem_cache 管理 mempolicy 对象生命周期。\n- **RCU 机制**：用于加权交错状态的无锁读取。\n- **系统调用接口**：通过 `sys_mbind()`、`sys_set_mempolicy()` 等提供用户空间配置入口。\n- **安全模块**：调用 LSM hooks（`security_task_movememory()`）进行权限检查。\n\n## 5. 使用场景\n\n- **高性能计算（HPC）应用**：通过 `mbind()` 将关键数据结构绑定到特定 NUMA 节点，减少远程内存访问延迟。\n- **数据库系统**：使用交错策略均衡多节点内存带宽，提升吞吐量。\n- **虚拟化环境**：VMM 可为不同虚拟机设置独立内存策略，隔离资源并优化性能。\n- **自动 NUMA 优化**：内核 NUMA balancing 机制结合默认策略，自动迁移热点页面至访问 CPU 所在节点。\n- **实时系统**：通过 `MPOL_BIND` 严格限制内存位置，确保确定性访问延迟。\n- **大页（HugeTLB）分配**：策略同样适用于透明大页和显式 HugeTLB 页面分配。",
      "similarity": 0.5370121598243713,
      "chunks": [
        {
          "chunk_id": 15,
          "file_path": "mm/mempolicy.c",
          "start_line": 2631,
          "end_line": 2732,
          "content": [
            "static unsigned long alloc_pages_bulk_array_preferred_many(gfp_t gfp, int nid,",
            "\t\tstruct mempolicy *pol, unsigned long nr_pages,",
            "\t\tstruct page **page_array)",
            "{",
            "\tgfp_t preferred_gfp;",
            "\tunsigned long nr_allocated = 0;",
            "",
            "\tpreferred_gfp = gfp | __GFP_NOWARN;",
            "\tpreferred_gfp &= ~(__GFP_DIRECT_RECLAIM | __GFP_NOFAIL);",
            "",
            "\tnr_allocated  = alloc_pages_bulk_noprof(preferred_gfp, nid, &pol->nodes,",
            "\t\t\t\t\t   nr_pages, NULL, page_array);",
            "",
            "\tif (nr_allocated < nr_pages)",
            "\t\tnr_allocated += alloc_pages_bulk_noprof(gfp, numa_node_id(), NULL,",
            "\t\t\t\tnr_pages - nr_allocated, NULL,",
            "\t\t\t\tpage_array + nr_allocated);",
            "\treturn nr_allocated;",
            "}",
            "unsigned long alloc_pages_bulk_array_mempolicy_noprof(gfp_t gfp,",
            "\t\tunsigned long nr_pages, struct page **page_array)",
            "{",
            "\tstruct mempolicy *pol = &default_policy;",
            "\tnodemask_t *nodemask;",
            "\tint nid;",
            "",
            "\tif (!in_interrupt() && !(gfp & __GFP_THISNODE))",
            "\t\tpol = get_task_policy(current);",
            "",
            "\tif (pol->mode == MPOL_INTERLEAVE)",
            "\t\treturn alloc_pages_bulk_array_interleave(gfp, pol,",
            "\t\t\t\t\t\t\t nr_pages, page_array);",
            "",
            "\tif (pol->mode == MPOL_WEIGHTED_INTERLEAVE)",
            "\t\treturn alloc_pages_bulk_array_weighted_interleave(",
            "\t\t\t\t  gfp, pol, nr_pages, page_array);",
            "",
            "\tif (pol->mode == MPOL_PREFERRED_MANY)",
            "\t\treturn alloc_pages_bulk_array_preferred_many(gfp,",
            "\t\t\t\tnuma_node_id(), pol, nr_pages, page_array);",
            "",
            "\tnid = numa_node_id();",
            "\tnodemask = policy_nodemask(gfp, pol, NO_INTERLEAVE_INDEX, &nid);",
            "\treturn alloc_pages_bulk_noprof(gfp, nid, nodemask,",
            "\t\t\t\t       nr_pages, NULL, page_array);",
            "}",
            "int vma_dup_policy(struct vm_area_struct *src, struct vm_area_struct *dst)",
            "{",
            "\tstruct mempolicy *pol = mpol_dup(src->vm_policy);",
            "",
            "\tif (IS_ERR(pol))",
            "\t\treturn PTR_ERR(pol);",
            "\tdst->vm_policy = pol;",
            "\treturn 0;",
            "}",
            "bool __mpol_equal(struct mempolicy *a, struct mempolicy *b)",
            "{",
            "\tif (!a || !b)",
            "\t\treturn false;",
            "\tif (a->mode != b->mode)",
            "\t\treturn false;",
            "\tif (a->flags != b->flags)",
            "\t\treturn false;",
            "\tif (a->home_node != b->home_node)",
            "\t\treturn false;",
            "\tif (mpol_store_user_nodemask(a))",
            "\t\tif (!nodes_equal(a->w.user_nodemask, b->w.user_nodemask))",
            "\t\t\treturn false;",
            "",
            "\tswitch (a->mode) {",
            "\tcase MPOL_BIND:",
            "\tcase MPOL_INTERLEAVE:",
            "\tcase MPOL_PREFERRED:",
            "\tcase MPOL_PREFERRED_MANY:",
            "\tcase MPOL_WEIGHTED_INTERLEAVE:",
            "\t\treturn !!nodes_equal(a->nodes, b->nodes);",
            "\tcase MPOL_LOCAL:",
            "\t\treturn true;",
            "\tdefault:",
            "\t\tBUG();",
            "\t\treturn false;",
            "\t}",
            "}",
            "static void sp_insert(struct shared_policy *sp, struct sp_node *new)",
            "{",
            "\tstruct rb_node **p = &sp->root.rb_node;",
            "\tstruct rb_node *parent = NULL;",
            "\tstruct sp_node *nd;",
            "",
            "\twhile (*p) {",
            "\t\tparent = *p;",
            "\t\tnd = rb_entry(parent, struct sp_node, nd);",
            "\t\tif (new->start < nd->start)",
            "\t\t\tp = &(*p)->rb_left;",
            "\t\telse if (new->end > nd->end)",
            "\t\t\tp = &(*p)->rb_right;",
            "\t\telse",
            "\t\t\tBUG();",
            "\t}",
            "\trb_link_node(&new->nd, parent, p);",
            "\trb_insert_color(&new->nd, &sp->root);",
            "}"
          ],
          "function_name": "alloc_pages_bulk_array_preferred_many, alloc_pages_bulk_array_mempolicy_noprof, vma_dup_policy, __mpol_equal, sp_insert",
          "description": "实现带优先节点策略的批量页面分配，根据当前节点和策略节点掩码尝试分配内存，优先满足首选节点需求。vma_dup_policy复制VMA内存策略，__mpol_equal比较两个内存策略是否相同，sp_insert将共享策略节点插入RB树。",
          "similarity": 0.5680652856826782
        },
        {
          "chunk_id": 5,
          "file_path": "mm/mempolicy.c",
          "start_line": 880,
          "end_line": 996,
          "content": [
            "static long",
            "queue_pages_range(struct mm_struct *mm, unsigned long start, unsigned long end,",
            "\t\tnodemask_t *nodes, unsigned long flags,",
            "\t\tstruct list_head *pagelist)",
            "{",
            "\tint err;",
            "\tstruct queue_pages qp = {",
            "\t\t.pagelist = pagelist,",
            "\t\t.flags = flags,",
            "\t\t.nmask = nodes,",
            "\t\t.start = start,",
            "\t\t.end = end,",
            "\t\t.first = NULL,",
            "\t};",
            "\tconst struct mm_walk_ops *ops = (flags & MPOL_MF_WRLOCK) ?",
            "\t\t\t&queue_pages_lock_vma_walk_ops : &queue_pages_walk_ops;",
            "",
            "\terr = walk_page_range(mm, start, end, ops, &qp);",
            "",
            "\tif (!qp.first)",
            "\t\t/* whole range in hole */",
            "\t\terr = -EFAULT;",
            "",
            "\treturn err ? : qp.nr_failed;",
            "}",
            "static int vma_replace_policy(struct vm_area_struct *vma,",
            "\t\t\t\tstruct mempolicy *pol)",
            "{",
            "\tint err;",
            "\tstruct mempolicy *old;",
            "\tstruct mempolicy *new;",
            "",
            "\tvma_assert_write_locked(vma);",
            "",
            "\tnew = mpol_dup(pol);",
            "\tif (IS_ERR(new))",
            "\t\treturn PTR_ERR(new);",
            "",
            "\tif (vma->vm_ops && vma->vm_ops->set_policy) {",
            "\t\terr = vma->vm_ops->set_policy(vma, new);",
            "\t\tif (err)",
            "\t\t\tgoto err_out;",
            "\t}",
            "",
            "\told = vma->vm_policy;",
            "\tvma->vm_policy = new; /* protected by mmap_lock */",
            "\tmpol_put(old);",
            "",
            "\treturn 0;",
            " err_out:",
            "\tmpol_put(new);",
            "\treturn err;",
            "}",
            "static int mbind_range(struct vma_iterator *vmi, struct vm_area_struct *vma,",
            "\t\tstruct vm_area_struct **prev, unsigned long start,",
            "\t\tunsigned long end, struct mempolicy *new_pol)",
            "{",
            "\tunsigned long vmstart, vmend;",
            "",
            "\tvmend = min(end, vma->vm_end);",
            "\tif (start > vma->vm_start) {",
            "\t\t*prev = vma;",
            "\t\tvmstart = start;",
            "\t} else {",
            "\t\tvmstart = vma->vm_start;",
            "\t}",
            "",
            "\tif (mpol_equal(vma->vm_policy, new_pol)) {",
            "\t\t*prev = vma;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tvma =  vma_modify_policy(vmi, *prev, vma, vmstart, vmend, new_pol);",
            "\tif (IS_ERR(vma))",
            "\t\treturn PTR_ERR(vma);",
            "",
            "\t*prev = vma;",
            "\treturn vma_replace_policy(vma, new_pol);",
            "}",
            "static long do_set_mempolicy(unsigned short mode, unsigned short flags,",
            "\t\t\t     nodemask_t *nodes)",
            "{",
            "\tstruct mempolicy *new, *old;",
            "\tNODEMASK_SCRATCH(scratch);",
            "\tint ret;",
            "",
            "\tif (!scratch)",
            "\t\treturn -ENOMEM;",
            "",
            "\tnew = mpol_new(mode, flags, nodes);",
            "\tif (IS_ERR(new)) {",
            "\t\tret = PTR_ERR(new);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\ttask_lock(current);",
            "\tret = mpol_set_nodemask(new, nodes, scratch);",
            "\tif (ret) {",
            "\t\ttask_unlock(current);",
            "\t\tmpol_put(new);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\told = current->mempolicy;",
            "\tcurrent->mempolicy = new;",
            "\tif (new && (new->mode == MPOL_INTERLEAVE ||",
            "\t\t    new->mode == MPOL_WEIGHTED_INTERLEAVE)) {",
            "\t\tcurrent->il_prev = MAX_NUMNODES-1;",
            "\t\tcurrent->il_weight = 0;",
            "\t}",
            "\ttask_unlock(current);",
            "\tmpol_put(old);",
            "\tret = 0;",
            "out:",
            "\tNODEMASK_SCRATCH_FREE(scratch);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "queue_pages_range, vma_replace_policy, mbind_range, do_set_mempolicy",
          "description": "实现内存策略设置，通过queue_pages_range队列页面，vma_replace_policy替换VMA策略，mbind_range绑定指定范围策略，do_set_mempolicy设置当前进程全局内存策略",
          "similarity": 0.5584412813186646
        },
        {
          "chunk_id": 6,
          "file_path": "mm/mempolicy.c",
          "start_line": 1012,
          "end_line": 1144,
          "content": [
            "static void get_policy_nodemask(struct mempolicy *pol, nodemask_t *nodes)",
            "{",
            "\tnodes_clear(*nodes);",
            "\tif (pol == &default_policy)",
            "\t\treturn;",
            "",
            "\tswitch (pol->mode) {",
            "\tcase MPOL_BIND:",
            "\tcase MPOL_INTERLEAVE:",
            "\tcase MPOL_PREFERRED:",
            "\tcase MPOL_PREFERRED_MANY:",
            "\tcase MPOL_WEIGHTED_INTERLEAVE:",
            "\t\t*nodes = pol->nodes;",
            "\t\tbreak;",
            "\tcase MPOL_LOCAL:",
            "\t\t/* return empty node mask for local allocation */",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "}",
            "static int lookup_node(struct mm_struct *mm, unsigned long addr)",
            "{",
            "\tstruct page *p = NULL;",
            "\tint ret;",
            "",
            "\tret = get_user_pages_fast(addr & PAGE_MASK, 1, 0, &p);",
            "\tif (ret > 0) {",
            "\t\tret = page_to_nid(p);",
            "\t\tput_page(p);",
            "\t}",
            "\treturn ret;",
            "}",
            "static long do_get_mempolicy(int *policy, nodemask_t *nmask,",
            "\t\t\t     unsigned long addr, unsigned long flags)",
            "{",
            "\tint err;",
            "\tstruct mm_struct *mm = current->mm;",
            "\tstruct vm_area_struct *vma = NULL;",
            "\tstruct mempolicy *pol = current->mempolicy, *pol_refcount = NULL;",
            "",
            "\tif (flags &",
            "\t\t~(unsigned long)(MPOL_F_NODE|MPOL_F_ADDR|MPOL_F_MEMS_ALLOWED))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (flags & MPOL_F_MEMS_ALLOWED) {",
            "\t\tif (flags & (MPOL_F_NODE|MPOL_F_ADDR))",
            "\t\t\treturn -EINVAL;",
            "\t\t*policy = 0;\t/* just so it's initialized */",
            "\t\ttask_lock(current);",
            "\t\t*nmask  = cpuset_current_mems_allowed;",
            "\t\ttask_unlock(current);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tif (flags & MPOL_F_ADDR) {",
            "\t\tpgoff_t ilx;\t\t/* ignored here */",
            "\t\t/*",
            "\t\t * Do NOT fall back to task policy if the",
            "\t\t * vma/shared policy at addr is NULL.  We",
            "\t\t * want to return MPOL_DEFAULT in this case.",
            "\t\t */",
            "\t\tmmap_read_lock(mm);",
            "\t\tvma = vma_lookup(mm, addr);",
            "\t\tif (!vma) {",
            "\t\t\tmmap_read_unlock(mm);",
            "\t\t\treturn -EFAULT;",
            "\t\t}",
            "\t\tpol = __get_vma_policy(vma, addr, &ilx);",
            "\t} else if (addr)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (!pol)",
            "\t\tpol = &default_policy;\t/* indicates default behavior */",
            "",
            "\tif (flags & MPOL_F_NODE) {",
            "\t\tif (flags & MPOL_F_ADDR) {",
            "\t\t\t/*",
            "\t\t\t * Take a refcount on the mpol, because we are about to",
            "\t\t\t * drop the mmap_lock, after which only \"pol\" remains",
            "\t\t\t * valid, \"vma\" is stale.",
            "\t\t\t */",
            "\t\t\tpol_refcount = pol;",
            "\t\t\tvma = NULL;",
            "\t\t\tmpol_get(pol);",
            "\t\t\tmmap_read_unlock(mm);",
            "\t\t\terr = lookup_node(mm, addr);",
            "\t\t\tif (err < 0)",
            "\t\t\t\tgoto out;",
            "\t\t\t*policy = err;",
            "\t\t} else if (pol == current->mempolicy &&",
            "\t\t\t\tpol->mode == MPOL_INTERLEAVE) {",
            "\t\t\t*policy = next_node_in(current->il_prev, pol->nodes);",
            "\t\t} else if (pol == current->mempolicy &&",
            "\t\t\t\tpol->mode == MPOL_WEIGHTED_INTERLEAVE) {",
            "\t\t\tif (current->il_weight)",
            "\t\t\t\t*policy = current->il_prev;",
            "\t\t\telse",
            "\t\t\t\t*policy = next_node_in(current->il_prev,",
            "\t\t\t\t\t\t       pol->nodes);",
            "\t\t} else {",
            "\t\t\terr = -EINVAL;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t} else {",
            "\t\t*policy = pol == &default_policy ? MPOL_DEFAULT :",
            "\t\t\t\t\t\tpol->mode;",
            "\t\t/*",
            "\t\t * Internal mempolicy flags must be masked off before exposing",
            "\t\t * the policy to userspace.",
            "\t\t */",
            "\t\t*policy |= (pol->flags & MPOL_MODE_FLAGS);",
            "\t}",
            "",
            "\terr = 0;",
            "\tif (nmask) {",
            "\t\tif (mpol_store_user_nodemask(pol)) {",
            "\t\t\t*nmask = pol->w.user_nodemask;",
            "\t\t} else {",
            "\t\t\ttask_lock(current);",
            "\t\t\tget_policy_nodemask(pol, nmask);",
            "\t\t\ttask_unlock(current);",
            "\t\t}",
            "\t}",
            "",
            " out:",
            "\tmpol_cond_put(pol);",
            "\tif (vma)",
            "\t\tmmap_read_unlock(mm);",
            "\tif (pol_refcount)",
            "\t\tmpol_put(pol_refcount);",
            "\treturn err;",
            "}"
          ],
          "function_name": "get_policy_nodemask, lookup_node, do_get_mempolicy",
          "description": "获取内存策略节点掩码，lookup_node查询页面所属节点，do_get_mempolicy根据地址或标志获取当前/VA内存策略并返回节点掩码",
          "similarity": 0.5458260774612427
        },
        {
          "chunk_id": 17,
          "file_path": "mm/mempolicy.c",
          "start_line": 2969,
          "end_line": 3093,
          "content": [
            "void mpol_put_task_policy(struct task_struct *task)",
            "{",
            "\tstruct mempolicy *pol;",
            "",
            "\ttask_lock(task);",
            "\tpol = task->mempolicy;",
            "\ttask->mempolicy = NULL;",
            "\ttask_unlock(task);",
            "\tmpol_put(pol);",
            "}",
            "static void sp_delete(struct shared_policy *sp, struct sp_node *n)",
            "{",
            "\trb_erase(&n->nd, &sp->root);",
            "\tsp_free(n);",
            "}",
            "static void sp_node_init(struct sp_node *node, unsigned long start,",
            "\t\t\tunsigned long end, struct mempolicy *pol)",
            "{",
            "\tnode->start = start;",
            "\tnode->end = end;",
            "\tnode->policy = pol;",
            "}",
            "static int shared_policy_replace(struct shared_policy *sp, pgoff_t start,",
            "\t\t\t\t pgoff_t end, struct sp_node *new)",
            "{",
            "\tstruct sp_node *n;",
            "\tstruct sp_node *n_new = NULL;",
            "\tstruct mempolicy *mpol_new = NULL;",
            "\tint ret = 0;",
            "",
            "restart:",
            "\twrite_lock(&sp->lock);",
            "\tn = sp_lookup(sp, start, end);",
            "\t/* Take care of old policies in the same range. */",
            "\twhile (n && n->start < end) {",
            "\t\tstruct rb_node *next = rb_next(&n->nd);",
            "\t\tif (n->start >= start) {",
            "\t\t\tif (n->end <= end)",
            "\t\t\t\tsp_delete(sp, n);",
            "\t\t\telse",
            "\t\t\t\tn->start = end;",
            "\t\t} else {",
            "\t\t\t/* Old policy spanning whole new range. */",
            "\t\t\tif (n->end > end) {",
            "\t\t\t\tif (!n_new)",
            "\t\t\t\t\tgoto alloc_new;",
            "",
            "\t\t\t\t*mpol_new = *n->policy;",
            "\t\t\t\tatomic_set(&mpol_new->refcnt, 1);",
            "\t\t\t\tsp_node_init(n_new, end, n->end, mpol_new);",
            "\t\t\t\tn->end = start;",
            "\t\t\t\tsp_insert(sp, n_new);",
            "\t\t\t\tn_new = NULL;",
            "\t\t\t\tmpol_new = NULL;",
            "\t\t\t\tbreak;",
            "\t\t\t} else",
            "\t\t\t\tn->end = start;",
            "\t\t}",
            "\t\tif (!next)",
            "\t\t\tbreak;",
            "\t\tn = rb_entry(next, struct sp_node, nd);",
            "\t}",
            "\tif (new)",
            "\t\tsp_insert(sp, new);",
            "\twrite_unlock(&sp->lock);",
            "\tret = 0;",
            "",
            "err_out:",
            "\tif (mpol_new)",
            "\t\tmpol_put(mpol_new);",
            "\tif (n_new)",
            "\t\tkmem_cache_free(sn_cache, n_new);",
            "",
            "\treturn ret;",
            "",
            "alloc_new:",
            "\twrite_unlock(&sp->lock);",
            "\tret = -ENOMEM;",
            "\tn_new = kmem_cache_alloc(sn_cache, GFP_KERNEL);",
            "\tif (!n_new)",
            "\t\tgoto err_out;",
            "\tmpol_new = kmem_cache_alloc(policy_cache, GFP_KERNEL);",
            "\tif (!mpol_new)",
            "\t\tgoto err_out;",
            "\tatomic_set(&mpol_new->refcnt, 1);",
            "\tgoto restart;",
            "}",
            "void mpol_shared_policy_init(struct shared_policy *sp, struct mempolicy *mpol)",
            "{",
            "\tint ret;",
            "",
            "\tsp->root = RB_ROOT;\t\t/* empty tree == default mempolicy */",
            "\trwlock_init(&sp->lock);",
            "",
            "\tif (mpol) {",
            "\t\tstruct sp_node *sn;",
            "\t\tstruct mempolicy *npol;",
            "\t\tNODEMASK_SCRATCH(scratch);",
            "",
            "\t\tif (!scratch)",
            "\t\t\tgoto put_mpol;",
            "",
            "\t\t/* contextualize the tmpfs mount point mempolicy to this file */",
            "\t\tnpol = mpol_new(mpol->mode, mpol->flags, &mpol->w.user_nodemask);",
            "\t\tif (IS_ERR(npol))",
            "\t\t\tgoto free_scratch; /* no valid nodemask intersection */",
            "",
            "\t\ttask_lock(current);",
            "\t\tret = mpol_set_nodemask(npol, &mpol->w.user_nodemask, scratch);",
            "\t\ttask_unlock(current);",
            "\t\tif (ret)",
            "\t\t\tgoto put_npol;",
            "",
            "\t\t/* alloc node covering entire file; adds ref to file's npol */",
            "\t\tsn = sp_alloc(0, MAX_LFS_FILESIZE >> PAGE_SHIFT, npol);",
            "\t\tif (sn)",
            "\t\t\tsp_insert(sp, sn);",
            "put_npol:",
            "\t\tmpol_put(npol);\t/* drop initial ref on file's npol */",
            "free_scratch:",
            "\t\tNODEMASK_SCRATCH_FREE(scratch);",
            "put_mpol:",
            "\t\tmpol_put(mpol);\t/* drop our incoming ref on sb mpol */",
            "\t}",
            "}"
          ],
          "function_name": "mpol_put_task_policy, sp_delete, sp_node_init, shared_policy_replace, mpol_shared_policy_init",
          "description": "mpol_put_task_policy释放任务级内存策略引用，sp_delete从RB树删除节点并回收资源，sp_node_init初始化共享策略节点，shared_policy_replace替换共享策略区间并处理节点分裂，mpol_shared_policy_init初始化共享策略结构体并设置初始策略。",
          "similarity": 0.5457813143730164
        },
        {
          "chunk_id": 11,
          "file_path": "mm/mempolicy.c",
          "start_line": 1855,
          "end_line": 1971,
          "content": [
            "static int kernel_get_mempolicy(int __user *policy,",
            "\t\t\t\tunsigned long __user *nmask,",
            "\t\t\t\tunsigned long maxnode,",
            "\t\t\t\tunsigned long addr,",
            "\t\t\t\tunsigned long flags)",
            "{",
            "\tint err;",
            "\tint pval;",
            "\tnodemask_t nodes;",
            "",
            "\tif (nmask != NULL && maxnode < nr_node_ids)",
            "\t\treturn -EINVAL;",
            "",
            "\taddr = untagged_addr(addr);",
            "",
            "\terr = do_get_mempolicy(&pval, &nodes, addr, flags);",
            "",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tif (policy && put_user(pval, policy))",
            "\t\treturn -EFAULT;",
            "",
            "\tif (nmask)",
            "\t\terr = copy_nodes_to_user(nmask, maxnode, &nodes);",
            "",
            "\treturn err;",
            "}",
            "bool vma_migratable(struct vm_area_struct *vma)",
            "{",
            "\tif (vma->vm_flags & (VM_IO | VM_PFNMAP))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * DAX device mappings require predictable access latency, so avoid",
            "\t * incurring periodic faults.",
            "\t */",
            "\tif (vma_is_dax(vma))",
            "\t\treturn false;",
            "",
            "\tif (is_vm_hugetlb_page(vma) &&",
            "\t\t!hugepage_migration_supported(hstate_vma(vma)))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Migration allocates pages in the highest zone. If we cannot",
            "\t * do so then migration (at least from node to node) is not",
            "\t * possible.",
            "\t */",
            "\tif (vma->vm_file &&",
            "\t\tgfp_zone(mapping_gfp_mask(vma->vm_file->f_mapping))",
            "\t\t\t< policy_zone)",
            "\t\treturn false;",
            "\treturn true;",
            "}",
            "bool vma_policy_mof(struct vm_area_struct *vma)",
            "{",
            "\tstruct mempolicy *pol;",
            "",
            "\tif (vma->vm_ops && vma->vm_ops->get_policy) {",
            "\t\tbool ret = false;",
            "\t\tpgoff_t ilx;\t\t/* ignored here */",
            "",
            "\t\tpol = vma->vm_ops->get_policy(vma, vma->vm_start, &ilx);",
            "\t\tif (pol && (pol->flags & MPOL_F_MOF))",
            "\t\t\tret = true;",
            "\t\tmpol_cond_put(pol);",
            "",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tpol = vma->vm_policy;",
            "\tif (!pol)",
            "\t\tpol = get_task_policy(current);",
            "",
            "\treturn pol->flags & MPOL_F_MOF;",
            "}",
            "bool apply_policy_zone(struct mempolicy *policy, enum zone_type zone)",
            "{",
            "\tenum zone_type dynamic_policy_zone = policy_zone;",
            "",
            "\tBUG_ON(dynamic_policy_zone == ZONE_MOVABLE);",
            "",
            "\t/*",
            "\t * if policy->nodes has movable memory only,",
            "\t * we apply policy when gfp_zone(gfp) = ZONE_MOVABLE only.",
            "\t *",
            "\t * policy->nodes is intersect with node_states[N_MEMORY].",
            "\t * so if the following test fails, it implies",
            "\t * policy->nodes has movable memory only.",
            "\t */",
            "\tif (!nodes_intersects(policy->nodes, node_states[N_HIGH_MEMORY]))",
            "\t\tdynamic_policy_zone = ZONE_MOVABLE;",
            "",
            "\treturn zone >= dynamic_policy_zone;",
            "}",
            "static unsigned int weighted_interleave_nodes(struct mempolicy *policy)",
            "{",
            "\tunsigned int node;",
            "\tunsigned int cpuset_mems_cookie;",
            "",
            "retry:",
            "\t/* to prevent miscount use tsk->mems_allowed_seq to detect rebind */",
            "\tcpuset_mems_cookie = read_mems_allowed_begin();",
            "\tnode = current->il_prev;",
            "\tif (!current->il_weight || !node_isset(node, policy->nodes)) {",
            "\t\tnode = next_node_in(node, policy->nodes);",
            "\t\tif (read_mems_allowed_retry(cpuset_mems_cookie))",
            "\t\t\tgoto retry;",
            "\t\tif (node == MAX_NUMNODES)",
            "\t\t\treturn node;",
            "\t\tcurrent->il_prev = node;",
            "\t\tcurrent->il_weight = get_il_weight(node);",
            "\t}",
            "\tcurrent->il_weight--;",
            "\treturn node;",
            "}"
          ],
          "function_name": "kernel_get_mempolicy, vma_migratable, vma_policy_mof, apply_policy_zone, weighted_interleave_nodes",
          "description": "kernel_get_mempolicy 获取当前内存策略参数并复制到用户空间；vma_migratable 判断虚拟内存区域是否支持迁移；vma_policy_mof 检查VMA是否启用了MOF（Migration On Fault）策略；apply_policy_zone 确定当前zone是否满足策略要求；weighted_interleave_nodes 计算加权交错分配的目标节点。",
          "similarity": 0.5436145067214966
        }
      ]
    },
    {
      "source_file": "mm/damon/reclaim.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:50:20\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `damon\\reclaim.c`\n\n---\n\n# `damon/reclaim.c` 技术文档\n\n## 1. 文件概述\n\n`damon/reclaim.c` 是 Linux 内核中基于 **DAMON（Data Access MONitor）** 框架实现的**自动内存回收模块**。该模块通过监控物理内存区域的访问模式，识别长时间未被访问的“冷”内存页，并主动将其回收（page-out），从而释放系统内存资源。其核心目标是在不影响系统性能的前提下，智能地回收低价值内存，提升内存利用率。\n\n该模块以可加载内核模块（LKM）形式存在，通过一组可调参数控制其行为，并支持基于水位线（watermarks）的条件激活机制，避免在内存充足时进行不必要的回收操作。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`enabled`**: 全局开关，控制 DAMON_RECLAIM 功能是否启用。\n- **`commit_inputs`**: 触发参数重载的标志位，用于运行时动态更新配置（除 `enabled` 外）。\n- **`min_age`**: 冷内存判定阈值（微秒），默认 120 秒。\n- **`damon_reclaim_quota`**: 回收配额控制结构，限制单位时间内的最大回收量（默认每秒最多 128 MiB）和 CPU 时间开销（默认最多 10 ms）。\n- **`damon_reclaim_wmarks`**: 水位线配置，基于空闲内存比率决定是否激活回收（高/中/低水位分别为 50%/40%/20%）。\n- **`damon_reclaim_mon_attrs`**: DAMON 监控属性，定义采样间隔（5ms）、聚合间隔（100ms）等。\n- **`monitor_region_start/end`**: 目标监控内存区域的物理地址范围，默认为系统最大连续 RAM 区域。\n- **`skip_anon`**: 布尔标志，若为真则跳过匿名页（anonymous pages）的回收。\n- **`kdamond_pid`**: DAMON 工作线程的 PID，未启用时为 -1。\n- **`damon_reclaim_stat`**: 统计信息结构，记录尝试回收区域数、成功回收区域数及配额超限次数。\n\n### 主要函数\n\n- **`damon_reclaim_new_scheme()`**: 创建 DAMOS（DAMON Operation Scheme）策略，定义“冷内存”模式（大小 ≥ PAGE_SIZE、访问次数为 0、年龄 ≥ `min_age`）并指定操作为 `DAMOS_PAGEOUT`。\n- **`damon_reclaim_apply_parameters()`**: 应用所有用户配置参数到 DAMON 上下文（`ctx`），包括监控属性、回收策略、过滤器（如 `skip_anon`）和监控区域。\n- **`damon_reclaim_turn()`**: 启动或停止 DAMON_RECLAIM 的核心监控与回收逻辑。\n- **`damon_reclaim_enabled_store()`**: `enabled` 参数的 setter 回调，处理启用/禁用逻辑。\n- **`damon_reclaim_handle_commit_inputs()`**: 处理 `commit_inputs` 标志，触发运行时参数重载。\n- **`damon_reclaim_after_aggregation()` / `damon_reclaim_after_wmarks_check()`**: DAMON 回调函数，在聚合后和水位检查后更新统计信息并处理参数提交。\n- **`damon_reclaim_init()`**: 模块初始化函数，创建 DAMON 上下文和目标，注册回调，并根据初始 `enabled` 状态决定是否启动。\n\n## 3. 关键实现\n\n### 冷内存识别与回收策略\n- 通过 `damon_reclaim_new_scheme()` 定义 DAMOS 策略：\n  - **访问模式匹配**：区域大小 ≥ `PAGE_SIZE`、访问次数 = 0、年龄 ≥ `min_age / aggr_interval`（转换为聚合周期单位）。\n  - **操作类型**：`DAMOS_PAGEOUT`，即对匹配区域执行页面回收。\n  - **配额控制**：使用 `damon_reclaim_quota` 限制回收速度和 CPU 开销，确保系统稳定性。\n  - **水位激活**：仅当空闲内存比率低于 `high` 水位（50%）时激活策略，高于 `low` 水位（20%）时停用。\n\n### 动态参数更新机制\n- 用户可通过写入 `commit_inputs=Y` 触发运行时参数重载（`min_age`、配额、水位、监控区域等）。\n- `damon_reclaim_handle_commit_inputs()` 在 DAMON 的聚合后或水位检查后回调中执行重载，确保线程安全。\n- 重载时保留旧策略的配额状态（如已消耗的配额），避免统计中断。\n\n### 匿名页过滤\n- 若 `skip_anon=Y`，通过 `DAMOS_FILTER_TYPE_ANON` 过滤器排除匿名页（如进程堆栈、堆内存），仅回收文件缓存等页面。\n\n### 监控区域自动配置\n- 默认使用 `damon_set_region_biggest_system_ram_default()` 自动选择系统中最大的连续物理 RAM 区域作为监控目标，用户也可通过 `monitor_region_start/end` 手动指定。\n\n## 4. 依赖关系\n\n- **DAMON 核心框架** (`<linux/damon.h>`): 依赖 DAMON 提供的内存访问监控、策略引擎（DAMOS）、配额管理、水位控制等基础设施。\n- **内核模块通用接口** (`modules-common.h`): 使用 `DEFINE_DAMON_MODULES_*` 宏简化参数声明和统计暴露。\n- **内存管理子系统**: 通过 `DAMOS_PAGEOUT` 操作与 MM 子系统交互，实际执行页面回收。\n- **参数解析工具** (`<linux/kstrtox.h>`): 用于解析用户输入的布尔值和数值参数。\n\n## 5. 使用场景\n\n- **内存压力缓解**: 在内存紧张但尚未触发传统 LRU 回收或 OOM Killer 之前，提前回收长期未使用的冷内存，延缓内存压力。\n- **容器/虚拟机内存优化**: 在容器或 VM 中部署，自动回收应用未使用的缓存内存，提高宿主机内存密度。\n- **大内存系统调优**: 在 TB 级内存服务器上，减少因缓存膨胀导致的内存浪费，提升整体内存效率。\n- **低延迟敏感场景**: 通过配额限制（`ms=10`）确保回收操作不会显著影响关键任务的延迟。\n- **调试与监控**: 通过 `kdamond_pid` 和统计参数（`reclaim_tried_regions` 等）监控 DAMON_RECLAIM 的运行状态和效果。",
      "similarity": 0.5018824934959412,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/damon/reclaim.c",
          "start_line": 269,
          "end_line": 298,
          "content": [
            "static int damon_reclaim_after_aggregation(struct damon_ctx *c)",
            "{",
            "\tstruct damos *s;",
            "",
            "\t/* update the stats parameter */",
            "\tdamon_for_each_scheme(s, c)",
            "\t\tdamon_reclaim_stat = s->stat;",
            "",
            "\treturn damon_reclaim_handle_commit_inputs();",
            "}",
            "static int damon_reclaim_after_wmarks_check(struct damon_ctx *c)",
            "{",
            "\treturn damon_reclaim_handle_commit_inputs();",
            "}",
            "static int __init damon_reclaim_init(void)",
            "{",
            "\tint err = damon_modules_new_paddr_ctx_target(&ctx, &target);",
            "",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tctx->callback.after_wmarks_check = damon_reclaim_after_wmarks_check;",
            "\tctx->callback.after_aggregation = damon_reclaim_after_aggregation;",
            "",
            "\t/* 'enabled' has set before this function, probably via command line */",
            "\tif (enabled)",
            "\t\terr = damon_reclaim_turn(true);",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "damon_reclaim_after_aggregation, damon_reclaim_after_wmarks_check, damon_reclaim_init",
          "description": "注册DAMON框架的回调函数以实现回收策略的动态调整，初始化阶段绑定自定义回调至上下文，确保在监控周期关键节点触发参数重载和回收策略更新。",
          "similarity": 0.49903175234794617
        },
        {
          "chunk_id": 1,
          "file_path": "mm/damon/reclaim.c",
          "start_line": 153,
          "end_line": 254,
          "content": [
            "static void damon_reclaim_copy_quota_status(struct damos_quota *dst,",
            "\t\tstruct damos_quota *src)",
            "{",
            "\tdst->total_charged_sz = src->total_charged_sz;",
            "\tdst->total_charged_ns = src->total_charged_ns;",
            "\tdst->charged_sz = src->charged_sz;",
            "\tdst->charged_from = src->charged_from;",
            "\tdst->charge_target_from = src->charge_target_from;",
            "\tdst->charge_addr_from = src->charge_addr_from;",
            "}",
            "static int damon_reclaim_apply_parameters(void)",
            "{",
            "\tstruct damos *scheme, *old_scheme;",
            "\tstruct damos_filter *filter;",
            "\tint err = 0;",
            "",
            "\terr = damon_set_attrs(ctx, &damon_reclaim_mon_attrs);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\t/* Will be freed by next 'damon_set_schemes()' below */",
            "\tscheme = damon_reclaim_new_scheme();",
            "\tif (!scheme)",
            "\t\treturn -ENOMEM;",
            "\tif (!list_empty(&ctx->schemes)) {",
            "\t\tdamon_for_each_scheme(old_scheme, ctx)",
            "\t\t\tdamon_reclaim_copy_quota_status(&scheme->quota,",
            "\t\t\t\t\t&old_scheme->quota);",
            "\t}",
            "\tif (skip_anon) {",
            "\t\tfilter = damos_new_filter(DAMOS_FILTER_TYPE_ANON, true);",
            "\t\tif (!filter) {",
            "\t\t\t/* Will be freed by next 'damon_set_schemes()' below */",
            "\t\t\tdamon_destroy_scheme(scheme);",
            "\t\t\treturn -ENOMEM;",
            "\t\t}",
            "\t\tdamos_add_filter(scheme, filter);",
            "\t}",
            "\tdamon_set_schemes(ctx, &scheme, 1);",
            "",
            "\treturn damon_set_region_biggest_system_ram_default(target,",
            "\t\t\t\t\t&monitor_region_start,",
            "\t\t\t\t\t&monitor_region_end);",
            "}",
            "static int damon_reclaim_turn(bool on)",
            "{",
            "\tint err;",
            "",
            "\tif (!on) {",
            "\t\terr = damon_stop(&ctx, 1);",
            "\t\tif (!err)",
            "\t\t\tkdamond_pid = -1;",
            "\t\treturn err;",
            "\t}",
            "",
            "\terr = damon_reclaim_apply_parameters();",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\terr = damon_start(&ctx, 1, true);",
            "\tif (err)",
            "\t\treturn err;",
            "\tkdamond_pid = ctx->kdamond->pid;",
            "\treturn 0;",
            "}",
            "static int damon_reclaim_enabled_store(const char *val,",
            "\t\tconst struct kernel_param *kp)",
            "{",
            "\tbool is_enabled = enabled;",
            "\tbool enable;",
            "\tint err;",
            "",
            "\terr = kstrtobool(val, &enable);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tif (is_enabled == enable)",
            "\t\treturn 0;",
            "",
            "\t/* Called before init function.  The function will handle this. */",
            "\tif (!ctx)",
            "\t\tgoto set_param_out;",
            "",
            "\terr = damon_reclaim_turn(enable);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "set_param_out:",
            "\tenabled = enable;",
            "\treturn err;",
            "}",
            "static int damon_reclaim_handle_commit_inputs(void)",
            "{",
            "\tint err;",
            "",
            "\tif (!commit_inputs)",
            "\t\treturn 0;",
            "",
            "\terr = damon_reclaim_apply_parameters();",
            "\tcommit_inputs = false;",
            "\treturn err;",
            "}"
          ],
          "function_name": "damon_reclaim_copy_quota_status, damon_reclaim_apply_parameters, damon_reclaim_turn, damon_reclaim_enabled_store, damon_reclaim_handle_commit_inputs",
          "description": "实现DAMON_RECLAIM参数动态应用、启停切换及配额状态复制逻辑，通过回调机制协调监控上下文与回收策略，支持运行时参数更新和资源回收操作。",
          "similarity": 0.49885258078575134
        },
        {
          "chunk_id": 0,
          "file_path": "mm/damon/reclaim.c",
          "start_line": 1,
          "end_line": 152,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * DAMON-based page reclamation",
            " *",
            " * Author: SeongJae Park <sj@kernel.org>",
            " */",
            "",
            "#define pr_fmt(fmt) \"damon-reclaim: \" fmt",
            "",
            "#include <linux/damon.h>",
            "#include <linux/kstrtox.h>",
            "#include <linux/module.h>",
            "",
            "#include \"modules-common.h\"",
            "",
            "#ifdef MODULE_PARAM_PREFIX",
            "#undef MODULE_PARAM_PREFIX",
            "#endif",
            "#define MODULE_PARAM_PREFIX \"damon_reclaim.\"",
            "",
            "/*",
            " * Enable or disable DAMON_RECLAIM.",
            " *",
            " * You can enable DAMON_RCLAIM by setting the value of this parameter as ``Y``.",
            " * Setting it as ``N`` disables DAMON_RECLAIM.  Note that DAMON_RECLAIM could",
            " * do no real monitoring and reclamation due to the watermarks-based activation",
            " * condition.  Refer to below descriptions for the watermarks parameter for",
            " * this.",
            " */",
            "static bool enabled __read_mostly;",
            "",
            "/*",
            " * Make DAMON_RECLAIM reads the input parameters again, except ``enabled``.",
            " *",
            " * Input parameters that updated while DAMON_RECLAIM is running are not applied",
            " * by default.  Once this parameter is set as ``Y``, DAMON_RECLAIM reads values",
            " * of parametrs except ``enabled`` again.  Once the re-reading is done, this",
            " * parameter is set as ``N``.  If invalid parameters are found while the",
            " * re-reading, DAMON_RECLAIM will be disabled.",
            " */",
            "static bool commit_inputs __read_mostly;",
            "module_param(commit_inputs, bool, 0600);",
            "",
            "/*",
            " * Time threshold for cold memory regions identification in microseconds.",
            " *",
            " * If a memory region is not accessed for this or longer time, DAMON_RECLAIM",
            " * identifies the region as cold, and reclaims.  120 seconds by default.",
            " */",
            "static unsigned long min_age __read_mostly = 120000000;",
            "module_param(min_age, ulong, 0600);",
            "",
            "static struct damos_quota damon_reclaim_quota = {",
            "\t/* use up to 10 ms time, reclaim up to 128 MiB per 1 sec by default */",
            "\t.ms = 10,",
            "\t.sz = 128 * 1024 * 1024,",
            "\t.reset_interval = 1000,",
            "\t/* Within the quota, page out older regions first. */",
            "\t.weight_sz = 0,",
            "\t.weight_nr_accesses = 0,",
            "\t.weight_age = 1",
            "};",
            "DEFINE_DAMON_MODULES_DAMOS_QUOTAS(damon_reclaim_quota);",
            "",
            "static struct damos_watermarks damon_reclaim_wmarks = {",
            "\t.metric = DAMOS_WMARK_FREE_MEM_RATE,",
            "\t.interval = 5000000,\t/* 5 seconds */",
            "\t.high = 500,\t\t/* 50 percent */",
            "\t.mid = 400,\t\t/* 40 percent */",
            "\t.low = 200,\t\t/* 20 percent */",
            "};",
            "DEFINE_DAMON_MODULES_WMARKS_PARAMS(damon_reclaim_wmarks);",
            "",
            "static struct damon_attrs damon_reclaim_mon_attrs = {",
            "\t.sample_interval = 5000,\t/* 5 ms */",
            "\t.aggr_interval = 100000,\t/* 100 ms */",
            "\t.ops_update_interval = 0,",
            "\t.min_nr_regions = 10,",
            "\t.max_nr_regions = 1000,",
            "};",
            "DEFINE_DAMON_MODULES_MON_ATTRS_PARAMS(damon_reclaim_mon_attrs);",
            "",
            "/*",
            " * Start of the target memory region in physical address.",
            " *",
            " * The start physical address of memory region that DAMON_RECLAIM will do work",
            " * against.  By default, biggest System RAM is used as the region.",
            " */",
            "static unsigned long monitor_region_start __read_mostly;",
            "module_param(monitor_region_start, ulong, 0600);",
            "",
            "/*",
            " * End of the target memory region in physical address.",
            " *",
            " * The end physical address of memory region that DAMON_RECLAIM will do work",
            " * against.  By default, biggest System RAM is used as the region.",
            " */",
            "static unsigned long monitor_region_end __read_mostly;",
            "module_param(monitor_region_end, ulong, 0600);",
            "",
            "/*",
            " * Skip anonymous pages reclamation.",
            " *",
            " * If this parameter is set as ``Y``, DAMON_RECLAIM does not reclaim anonymous",
            " * pages.  By default, ``N``.",
            " */",
            "static bool skip_anon __read_mostly;",
            "module_param(skip_anon, bool, 0600);",
            "",
            "/*",
            " * PID of the DAMON thread",
            " *",
            " * If DAMON_RECLAIM is enabled, this becomes the PID of the worker thread.",
            " * Else, -1.",
            " */",
            "static int kdamond_pid __read_mostly = -1;",
            "module_param(kdamond_pid, int, 0400);",
            "",
            "static struct damos_stat damon_reclaim_stat;",
            "DEFINE_DAMON_MODULES_DAMOS_STATS_PARAMS(damon_reclaim_stat,",
            "\t\treclaim_tried_regions, reclaimed_regions, quota_exceeds);",
            "",
            "static struct damon_ctx *ctx;",
            "static struct damon_target *target;",
            "",
            "static struct damos *damon_reclaim_new_scheme(void)",
            "{",
            "\tstruct damos_access_pattern pattern = {",
            "\t\t/* Find regions having PAGE_SIZE or larger size */",
            "\t\t.min_sz_region = PAGE_SIZE,",
            "\t\t.max_sz_region = ULONG_MAX,",
            "\t\t/* and not accessed at all */",
            "\t\t.min_nr_accesses = 0,",
            "\t\t.max_nr_accesses = 0,",
            "\t\t/* for min_age or more micro-seconds */",
            "\t\t.min_age_region = min_age /",
            "\t\t\tdamon_reclaim_mon_attrs.aggr_interval,",
            "\t\t.max_age_region = UINT_MAX,",
            "\t};",
            "",
            "\treturn damon_new_scheme(",
            "\t\t\t&pattern,",
            "\t\t\t/* page out those, as soon as found */",
            "\t\t\tDAMOS_PAGEOUT,",
            "\t\t\t/* for each aggregation interval */",
            "\t\t\t0,",
            "\t\t\t/* under the quota. */",
            "\t\t\t&damon_reclaim_quota,",
            "\t\t\t/* (De)activate this according to the watermarks. */",
            "\t\t\t&damon_reclaim_wmarks);",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义DAMON_RECLAIM模块的全局参数和配置，包括启用状态、冷内存识别时间阈值、配额限制、水印条件及监控属性，用于控制基于DAMON的页面回收行为。",
          "similarity": 0.4380885064601898
        }
      ]
    },
    {
      "source_file": "mm/kasan/quarantine.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:17:26\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kasan\\quarantine.c`\n\n---\n\n# kasan/quarantine.c 技术文档\n\n## 1. 文件概述\n\n`kasan/quarantine.c` 实现了 KASAN（Kernel Address Sanitizer）的隔离区（Quarantine）机制。该机制用于延迟释放已释放但可能仍被非法访问的内存对象，从而提高检测 Use-After-Free（UAF）错误的能力。通过将释放的对象暂时放入隔离队列而非立即归还给内存分配器，KASAN 能在后续访问这些“已释放”内存时捕获违规行为。\n\n隔离区由每个 CPU 的本地队列和一个全局循环批次队列组成，并支持动态调整大小以适应系统内存压力，防止因隔离区过大导致 OOM（Out-Of-Memory）。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct qlist_head`**  \n  表示一个单向链表队列，包含头指针、尾指针、总字节数和离线标志。\n  \n- **`cpu_quarantine`**（per-CPU）  \n  每个 CPU 的本地隔离队列，用于暂存刚释放的对象。\n\n- **`global_quarantine[QUARANTINE_BATCHES]`**  \n  全局隔离批次数组，采用循环 FIFO 结构，存储从各 CPU 队列转移过来的批量对象。\n\n- **`shrink_qlist`**（per-CPU）  \n  用于内存回收路径的辅助队列，带自旋锁保护。\n\n- **`remove_cache_srcu`**  \n  SRCU（Sleepable RCU）同步机制，用于安全地移除特定 slab 缓存的所有隔离对象。\n\n### 主要函数\n\n- **`kasan_quarantine_put()`**  \n  将指定对象放入当前 CPU 的隔离队列；若队列超过阈值，则批量转移到全局隔离区。\n\n- **`kasan_quarantine_reduce()`**  \n  当全局隔离区总大小超过限制时，释放最早一批对象以回收内存。\n\n- **`qlist_free_all()`**  \n  遍历并实际释放队列中所有对象回 slab 分配器。\n\n- **`qlink_free()`**  \n  执行单个隔离对象的实际释放操作，包括清除 KASAN 元数据和 shadow 内存标记。\n\n- **`qlist_move_cache()`**（未完成）  \n  （代码截断）预期用于将特定缓存类型的所有对象从一个队列迁移到另一个队列，通常用于缓存销毁时清理隔离对象。\n\n## 3. 关键实现\n\n### 隔离队列结构\n- 使用轻量级单向链表 `qlist_head` 管理对象，每个节点为 `struct qlist_node`（嵌入在 `kasan_free_meta` 中）。\n- 每个 CPU 维护一个本地队列（`cpu_quarantine`），避免锁竞争，提升性能。\n- 全局隔离区由 `QUARANTINE_BATCHES` 个批次组成环形缓冲区，通过 `quarantine_head` 和 `quarantine_tail` 实现 FIFO。\n\n### 内存管理策略\n- 单个 CPU 队列最大为 `QUARANTINE_PERCPU_SIZE`（1MB）。\n- 全局隔离区最大容量为系统物理内存的 `1/QUARANTINE_FRACTION`（即 1/32），再减去所有 CPU 队列的上限总和。\n- 批次大小 `quarantine_batch_size` 动态计算，至少为 `QUARANTINE_PERCPU_SIZE`，确保高效批量处理。\n\n### 并发与同步\n- CPU 本地操作使用 `local_irq_save/restore` 禁用中断，保证原子性。\n- 全局队列操作受 `quarantine_lock`（raw spinlock）保护。\n- 使用 `SRCU`（`remove_cache_srcu`）协调 `kasan_quarantine_remove_cache()` 与隔离对象释放之间的同步，确保在缓存销毁时不会遗漏隔离中的对象。\n\n### 安全释放机制\n- 对象释放前会将对应的 KASAN shadow 字节设为 `KASAN_SLAB_FREE`，使后续访问触发 KASAN 报告。\n- 若启用了 `init_on_free` 且 free metadata 存储在对象内部，则在释放前显式清零元数据，避免残留敏感信息。\n\n## 4. 依赖关系\n\n- **KASAN 核心模块**：依赖 `kasan.h` 中定义的元数据结构（如 `kasan_free_meta`）、shadow 内存操作和 `kasan_get_free_meta()` 等接口。\n- **Slab 分配器**：通过 `___cache_free()` 将对象归还给底层 slab（SLAB/SLUB）；使用 `virt_to_slab()` 和 `slab_want_init_on_free()` 等 slab 内部接口。\n- **内存管理子系统**：调用 `totalram_pages()` 获取系统内存总量，用于动态调整隔离区大小。\n- **CPU 热插拔**：通过 `num_online_cpus()` 适配 CPU 数量变化。\n- **同步原语**：使用 `percpu`、`raw_spinlock`、`SRCU` 和 `local_irq_*` 实现并发控制。\n- **内存回收**：虽未直接注册 shrinker（注释提及 SLAB 不支持），但 `kasan_quarantine_reduce()` 可被外部调用以响应内存压力。\n\n## 5. 使用场景\n\n- **Use-After-Free 检测增强**：当内核启用 KASAN（特别是 `CONFIG_KASAN_GENERIC` 或 `CONFIG_KASAN_SW_TAGS`）时，`kfree()` 或 `kmem_cache_free()` 调用会先将对象放入隔离区而非立即释放，延长 UAF 检测窗口。\n- **内存压力下的自动回收**：当系统内存紧张或隔离区超过阈值时，调用 `kasan_quarantine_reduce()` 释放最早隔离的一批对象，防止内存耗尽。\n- **Slab 缓存销毁**：当某个 `kmem_cache` 被销毁时，需调用未在本文件中完整实现的 `kasan_quarantine_remove_cache()`（依赖 `qlist_move_cache`），将该缓存的所有隔离对象立即释放，避免悬空引用。\n- **调试与测试**：在内核开发和测试阶段，隔离机制显著提升内存错误的可复现性和诊断能力。",
      "similarity": 0.4855796694755554,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/kasan/quarantine.c",
          "start_line": 238,
          "end_line": 375,
          "content": [
            "void kasan_quarantine_reduce(void)",
            "{",
            "\tsize_t total_size, new_quarantine_size, percpu_quarantines;",
            "\tunsigned long flags;",
            "\tint srcu_idx;",
            "\tstruct qlist_head to_free = QLIST_INIT;",
            "",
            "\tif (likely(READ_ONCE(quarantine_size) <=",
            "\t\t   READ_ONCE(quarantine_max_size)))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * srcu critical section ensures that kasan_quarantine_remove_cache()",
            "\t * will not miss objects belonging to the cache while they are in our",
            "\t * local to_free list. srcu is chosen because (1) it gives us private",
            "\t * grace period domain that does not interfere with anything else,",
            "\t * and (2) it allows synchronize_srcu() to return without waiting",
            "\t * if there are no pending read critical sections (which is the",
            "\t * expected case).",
            "\t */",
            "\tsrcu_idx = srcu_read_lock(&remove_cache_srcu);",
            "\traw_spin_lock_irqsave(&quarantine_lock, flags);",
            "",
            "\t/*",
            "\t * Update quarantine size in case of hotplug. Allocate a fraction of",
            "\t * the installed memory to quarantine minus per-cpu queue limits.",
            "\t */",
            "\ttotal_size = (totalram_pages() << PAGE_SHIFT) /",
            "\t\tQUARANTINE_FRACTION;",
            "\tpercpu_quarantines = QUARANTINE_PERCPU_SIZE * num_online_cpus();",
            "\tnew_quarantine_size = (total_size < percpu_quarantines) ?",
            "\t\t0 : total_size - percpu_quarantines;",
            "\tWRITE_ONCE(quarantine_max_size, new_quarantine_size);",
            "\t/* Aim at consuming at most 1/2 of slots in quarantine. */",
            "\tWRITE_ONCE(quarantine_batch_size, max((size_t)QUARANTINE_PERCPU_SIZE,",
            "\t\t2 * total_size / QUARANTINE_BATCHES));",
            "",
            "\tif (likely(quarantine_size > quarantine_max_size)) {",
            "\t\tqlist_move_all(&global_quarantine[quarantine_head], &to_free);",
            "\t\tWRITE_ONCE(quarantine_size, quarantine_size - to_free.bytes);",
            "\t\tquarantine_head++;",
            "\t\tif (quarantine_head == QUARANTINE_BATCHES)",
            "\t\t\tquarantine_head = 0;",
            "\t}",
            "",
            "\traw_spin_unlock_irqrestore(&quarantine_lock, flags);",
            "",
            "\tqlist_free_all(&to_free, NULL);",
            "\tsrcu_read_unlock(&remove_cache_srcu, srcu_idx);",
            "}",
            "static void qlist_move_cache(struct qlist_head *from,",
            "\t\t\t\t   struct qlist_head *to,",
            "\t\t\t\t   struct kmem_cache *cache)",
            "{",
            "\tstruct qlist_node *curr;",
            "",
            "\tif (unlikely(qlist_empty(from)))",
            "\t\treturn;",
            "",
            "\tcurr = from->head;",
            "\tqlist_init(from);",
            "\twhile (curr) {",
            "\t\tstruct qlist_node *next = curr->next;",
            "\t\tstruct kmem_cache *obj_cache = qlink_to_cache(curr);",
            "",
            "\t\tif (obj_cache == cache)",
            "\t\t\tqlist_put(to, curr, obj_cache->size);",
            "\t\telse",
            "\t\t\tqlist_put(from, curr, obj_cache->size);",
            "",
            "\t\tcurr = next;",
            "\t}",
            "}",
            "static void __per_cpu_remove_cache(struct qlist_head *q, void *arg)",
            "{",
            "\tstruct kmem_cache *cache = arg;",
            "\tunsigned long flags;",
            "\tstruct cpu_shrink_qlist *sq;",
            "",
            "\tsq = this_cpu_ptr(&shrink_qlist);",
            "\traw_spin_lock_irqsave(&sq->lock, flags);",
            "\tqlist_move_cache(q, &sq->qlist, cache);",
            "\traw_spin_unlock_irqrestore(&sq->lock, flags);",
            "}",
            "static void per_cpu_remove_cache(void *arg)",
            "{",
            "\tstruct qlist_head *q;",
            "",
            "\tq = this_cpu_ptr(&cpu_quarantine);",
            "\t/*",
            "\t * Ensure the ordering between the writing to q->offline and",
            "\t * per_cpu_remove_cache.  Prevent cpu_quarantine from being corrupted",
            "\t * by interrupt.",
            "\t */",
            "\tif (READ_ONCE(q->offline))",
            "\t\treturn;",
            "\t__per_cpu_remove_cache(q, arg);",
            "}",
            "void kasan_quarantine_remove_cache(struct kmem_cache *cache)",
            "{",
            "\tunsigned long flags, i;",
            "\tstruct qlist_head to_free = QLIST_INIT;",
            "\tint cpu;",
            "\tstruct cpu_shrink_qlist *sq;",
            "",
            "\t/*",
            "\t * Must be careful to not miss any objects that are being moved from",
            "\t * per-cpu list to the global quarantine in kasan_quarantine_put(),",
            "\t * nor objects being freed in kasan_quarantine_reduce(). on_each_cpu()",
            "\t * achieves the first goal, while synchronize_srcu() achieves the",
            "\t * second.",
            "\t */",
            "\ton_each_cpu(per_cpu_remove_cache, cache, 1);",
            "",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tsq = per_cpu_ptr(&shrink_qlist, cpu);",
            "\t\traw_spin_lock_irqsave(&sq->lock, flags);",
            "\t\tqlist_move_cache(&sq->qlist, &to_free, cache);",
            "\t\traw_spin_unlock_irqrestore(&sq->lock, flags);",
            "\t}",
            "\tqlist_free_all(&to_free, cache);",
            "",
            "\traw_spin_lock_irqsave(&quarantine_lock, flags);",
            "\tfor (i = 0; i < QUARANTINE_BATCHES; i++) {",
            "\t\tif (qlist_empty(&global_quarantine[i]))",
            "\t\t\tcontinue;",
            "\t\tqlist_move_cache(&global_quarantine[i], &to_free, cache);",
            "\t\t/* Scanning whole quarantine can take a while. */",
            "\t\traw_spin_unlock_irqrestore(&quarantine_lock, flags);",
            "\t\tcond_resched();",
            "\t\traw_spin_lock_irqsave(&quarantine_lock, flags);",
            "\t}",
            "\traw_spin_unlock_irqrestore(&quarantine_lock, flags);",
            "",
            "\tqlist_free_all(&to_free, cache);",
            "",
            "\tsynchronize_srcu(&remove_cache_srcu);",
            "}"
          ],
          "function_name": "kasan_quarantine_reduce, qlist_move_cache, __per_cpu_remove_cache, per_cpu_remove_cache, kasan_quarantine_remove_cache",
          "description": "提供隔离区缩减机制(kasan_quarantine_reduce)，通过srcu同步和跨CPU遍历清除指定缓存对象，利用qlist_move_cache实现基于缓存类型的对象转移与释放。",
          "similarity": 0.4937950372695923
        },
        {
          "chunk_id": 1,
          "file_path": "mm/kasan/quarantine.c",
          "start_line": 42,
          "end_line": 172,
          "content": [
            "static bool qlist_empty(struct qlist_head *q)",
            "{",
            "\treturn !q->head;",
            "}",
            "static void qlist_init(struct qlist_head *q)",
            "{",
            "\tq->head = q->tail = NULL;",
            "\tq->bytes = 0;",
            "}",
            "static void qlist_put(struct qlist_head *q, struct qlist_node *qlink,",
            "\t\tsize_t size)",
            "{",
            "\tif (unlikely(qlist_empty(q)))",
            "\t\tq->head = qlink;",
            "\telse",
            "\t\tq->tail->next = qlink;",
            "\tq->tail = qlink;",
            "\tqlink->next = NULL;",
            "\tq->bytes += size;",
            "}",
            "static void qlist_move_all(struct qlist_head *from, struct qlist_head *to)",
            "{",
            "\tif (unlikely(qlist_empty(from)))",
            "\t\treturn;",
            "",
            "\tif (qlist_empty(to)) {",
            "\t\t*to = *from;",
            "\t\tqlist_init(from);",
            "\t\treturn;",
            "\t}",
            "",
            "\tto->tail->next = from->head;",
            "\tto->tail = from->tail;",
            "\tto->bytes += from->bytes;",
            "",
            "\tqlist_init(from);",
            "}",
            "static void qlink_free(struct qlist_node *qlink, struct kmem_cache *cache)",
            "{",
            "\tvoid *object = qlink_to_object(qlink, cache);",
            "\tstruct kasan_free_meta *meta = kasan_get_free_meta(cache, object);",
            "",
            "\t/*",
            "\t * If init_on_free is enabled and KASAN's free metadata is stored in",
            "\t * the object, zero the metadata. Otherwise, the object's memory will",
            "\t * not be properly zeroed, as KASAN saves the metadata after the slab",
            "\t * allocator zeroes the object.",
            "\t */",
            "\tif (slab_want_init_on_free(cache) &&",
            "\t    cache->kasan_info.free_meta_offset == 0)",
            "\t\tmemzero_explicit(meta, sizeof(*meta));",
            "",
            "\t/*",
            "\t * As the object now gets freed from the quarantine, assume that its",
            "\t * free track is no longer valid.",
            "\t */",
            "\t*(u8 *)kasan_mem_to_shadow(object) = KASAN_SLAB_FREE;",
            "",
            "\t___cache_free(cache, object, _THIS_IP_);",
            "}",
            "static void qlist_free_all(struct qlist_head *q, struct kmem_cache *cache)",
            "{",
            "\tstruct qlist_node *qlink;",
            "",
            "\tif (unlikely(qlist_empty(q)))",
            "\t\treturn;",
            "",
            "\tqlink = q->head;",
            "\twhile (qlink) {",
            "\t\tstruct kmem_cache *obj_cache =",
            "\t\t\tcache ? cache :\tqlink_to_cache(qlink);",
            "\t\tstruct qlist_node *next = qlink->next;",
            "",
            "\t\tqlink_free(qlink, obj_cache);",
            "\t\tqlink = next;",
            "\t}",
            "\tqlist_init(q);",
            "}",
            "bool kasan_quarantine_put(struct kmem_cache *cache, void *object)",
            "{",
            "\tunsigned long flags;",
            "\tstruct qlist_head *q;",
            "\tstruct qlist_head temp = QLIST_INIT;",
            "\tstruct kasan_free_meta *meta = kasan_get_free_meta(cache, object);",
            "",
            "\t/*",
            "\t * If there's no metadata for this object, don't put it into",
            "\t * quarantine.",
            "\t */",
            "\tif (!meta)",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Note: irq must be disabled until after we move the batch to the",
            "\t * global quarantine. Otherwise kasan_quarantine_remove_cache() can",
            "\t * miss some objects belonging to the cache if they are in our local",
            "\t * temp list. kasan_quarantine_remove_cache() executes on_each_cpu()",
            "\t * at the beginning which ensures that it either sees the objects in",
            "\t * per-cpu lists or in the global quarantine.",
            "\t */",
            "\tlocal_irq_save(flags);",
            "",
            "\tq = this_cpu_ptr(&cpu_quarantine);",
            "\tif (q->offline) {",
            "\t\tlocal_irq_restore(flags);",
            "\t\treturn false;",
            "\t}",
            "\tqlist_put(q, &meta->quarantine_link, cache->size);",
            "\tif (unlikely(q->bytes > QUARANTINE_PERCPU_SIZE)) {",
            "\t\tqlist_move_all(q, &temp);",
            "",
            "\t\traw_spin_lock(&quarantine_lock);",
            "\t\tWRITE_ONCE(quarantine_size, quarantine_size + temp.bytes);",
            "\t\tqlist_move_all(&temp, &global_quarantine[quarantine_tail]);",
            "\t\tif (global_quarantine[quarantine_tail].bytes >=",
            "\t\t\t\tREAD_ONCE(quarantine_batch_size)) {",
            "\t\t\tint new_tail;",
            "",
            "\t\t\tnew_tail = quarantine_tail + 1;",
            "\t\t\tif (new_tail == QUARANTINE_BATCHES)",
            "\t\t\t\tnew_tail = 0;",
            "\t\t\tif (new_tail != quarantine_head)",
            "\t\t\t\tquarantine_tail = new_tail;",
            "\t\t}",
            "\t\traw_spin_unlock(&quarantine_lock);",
            "\t}",
            "",
            "\tlocal_irq_restore(flags);",
            "",
            "\treturn true;",
            "}"
          ],
          "function_name": "qlist_empty, qlist_init, qlist_put, qlist_move_all, qlink_free, qlist_free_all, kasan_quarantine_put",
          "description": "实现了隔离区队列的基本操作（空判断、初始化、插入、转移和释放），kasan_quarantine_put将对象加入当前CPU隔离队列并触发全局隔离区迁移，通过中断屏蔽保证并发安全性。",
          "similarity": 0.4386465549468994
        },
        {
          "chunk_id": 3,
          "file_path": "mm/kasan/quarantine.c",
          "start_line": 382,
          "end_line": 410,
          "content": [
            "static int kasan_cpu_online(unsigned int cpu)",
            "{",
            "\tthis_cpu_ptr(&cpu_quarantine)->offline = false;",
            "\treturn 0;",
            "}",
            "static int kasan_cpu_offline(unsigned int cpu)",
            "{",
            "\tstruct qlist_head *q;",
            "",
            "\tq = this_cpu_ptr(&cpu_quarantine);",
            "\t/* Ensure the ordering between the writing to q->offline and",
            "\t * qlist_free_all. Otherwise, cpu_quarantine may be corrupted",
            "\t * by interrupt.",
            "\t */",
            "\tWRITE_ONCE(q->offline, true);",
            "\tbarrier();",
            "\tqlist_free_all(q, NULL);",
            "\treturn 0;",
            "}",
            "static int __init kasan_cpu_quarantine_init(void)",
            "{",
            "\tint ret = 0;",
            "",
            "\tret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, \"mm/kasan:online\",",
            "\t\t\t\tkasan_cpu_online, kasan_cpu_offline);",
            "\tif (ret < 0)",
            "\t\tpr_err(\"kasan cpu quarantine register failed [%d]\\n\", ret);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "kasan_cpu_online, kasan_cpu_offline, kasan_cpu_quarantine_init",
          "description": "实现CPU热插拔时隔离区状态管理，kasan_cpu_online/kasan_cpu_offline控制隔离区可用性，kasan_cpu_quarantine_init注册CPU状态回调接口。",
          "similarity": 0.4113010764122009
        },
        {
          "chunk_id": 0,
          "file_path": "mm/kasan/quarantine.c",
          "start_line": 1,
          "end_line": 41,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * KASAN quarantine.",
            " *",
            " * Author: Alexander Potapenko <glider@google.com>",
            " * Copyright (C) 2016 Google, Inc.",
            " *",
            " * Based on code by Dmitry Chernenkov.",
            " */",
            "",
            "#include <linux/gfp.h>",
            "#include <linux/hash.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mm.h>",
            "#include <linux/percpu.h>",
            "#include <linux/printk.h>",
            "#include <linux/shrinker.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/cpuhotplug.h>",
            "",
            "#include \"../slab.h\"",
            "#include \"kasan.h\"",
            "",
            "/* Data structure and operations for quarantine queues. */",
            "",
            "/*",
            " * Each queue is a single-linked list, which also stores the total size of",
            " * objects inside of it.",
            " */",
            "struct qlist_head {",
            "\tstruct qlist_node *head;",
            "\tstruct qlist_node *tail;",
            "\tsize_t bytes;",
            "\tbool offline;",
            "};",
            "",
            "#define QLIST_INIT { NULL, NULL, 0 }",
            ""
          ],
          "function_name": null,
          "description": "定义了KASAN隔离区队列的数据结构qlist_head，包含头尾指针、总字节数和离线标志位，用于管理隔离对象的链表队列。",
          "similarity": 0.4099079966545105
        }
      ]
    }
  ]
}