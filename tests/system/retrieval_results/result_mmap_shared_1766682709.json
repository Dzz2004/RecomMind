{
  "query": "mmap_shared",
  "timestamp": "2025-12-26 01:11:49",
  "retrieved_files": [
    {
      "source_file": "mm/mmap.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:51:22\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `mmap.c`\n\n---\n\n# mmap.c 技术文档\n\n## 1. 文件概述\n\n`mm/mmap.c` 是 Linux 内核内存管理子系统的核心源文件之一，主要负责虚拟内存区域（VMA, Virtual Memory Area）的创建、修改、删除以及与用户空间 `mmap()` 和 `brk()` 系统调用相关的逻辑实现。该文件实现了进程地址空间的动态扩展（如堆的 `brk` 调整）、文件映射、匿名映射、VMA 结构的生命周期管理、页表保护属性更新等关键功能，并为内核其他子系统（如安全模块、性能分析、内存压缩等）提供底层支持。\n\n## 2. 核心功能\n\n### 主要函数\n- `vma_set_page_prot()`：根据 VMA 的标志位（`vm_flags`）更新其页表保护属性（`vm_page_prot`），并处理写时通知（writenotify）逻辑。\n- `unlink_file_vma()`：从文件的地址空间映射树（`i_mmap`）中移除一个基于文件的 VMA，用于在释放前隐藏 VMA。\n- `unlink_file_vma_batch_*()` 系列函数：批量处理多个 VMA 从同一文件映射树中的移除操作，提升性能。\n- `remove_vma()`：关闭并释放一个 VMA 结构，包括调用 `vma_close()`、释放关联文件引用和内存策略。\n- `check_brk_limits()`：检查 `brk` 扩展请求是否满足地址空间分配和内存锁定限制。\n- `SYSCALL_DEFINE1(brk, ...)`：实现 `brk()` 系统调用，用于调整进程数据段（堆）的结束地址。\n- `do_brk_flags()`（声明）：实际执行 `brk` 扩展逻辑的内部函数（定义在其他位置）。\n\n### 关键数据结构\n- `struct vm_area_struct`（VMA）：表示进程地址空间中的一段连续虚拟内存区域，包含起始/结束地址、访问权限、映射文件、操作函数指针等。\n- `struct unlink_vma_file_batch`：用于批量处理文件 VMA 解链操作的临时结构。\n- `struct vma_iterator`：用于高效遍历 VMA 树的迭代器（基于 Maple Tree）。\n\n### 全局变量\n- `mmap_rnd_bits` / `mmap_rnd_compat_bits`：控制 ASLR（地址空间布局随机化）中 mmap 基址随机化位数的可调参数。\n- `ignore_rlimit_data`：内核启动参数，用于忽略 `RLIMIT_DATA` 资源限制（调试用途）。\n\n## 3. 关键实现\n\n### VMA 页表保护属性更新\n`vma_set_page_prot()` 函数通过 `vm_pgprot_modify()` 将 VMA 的标志位（如 `VM_READ`、`VM_WRITE`、`VM_EXEC`、`VM_SHARED`）转换为底层架构相关的页表项保护位（`pgprot_t`）。特别地，当 VMA 需要写时通知（例如用于 COW 或跟踪）时，会临时清除 `VM_SHARED` 标志以生成非共享的写保护页表项，确保写操作能触发缺页异常。\n\n### 文件 VMA 批量解链优化\n为避免频繁加锁/解锁文件地址空间的 `i_mmap_rwsem`，内核引入了批量解链机制。`unlink_file_vma_batch_add()` 将待处理的 VMA 缓存到批次结构中，仅当遇到不同文件或批次满时才批量处理，显著减少锁竞争开销。\n\n### `brk()` 系统调用实现\n`brk()` 系统调用处理进程堆的扩展或收缩：\n- **收缩**：直接调用 `do_vma_munmap()` 释放多余内存区域。\n- **扩展**：\n  1. 检查是否超出 `RLIMIT_DATA` 限制；\n  2. 验证新堆顶与栈之间保留足够的安全间隙（`stack_guard_gap`）；\n  3. 调用 `do_brk_flags()` 创建新的匿名 VMA；\n  4. 更新 `mm->brk` 指针。\n- 支持 `CONFIG_COMPAT_BRK` 选项以兼容旧版 ABI 的堆起始地址行为。\n\n### 地址空间随机化（ASLR）\n通过 `mmap_rnd_bits` 等全局变量，内核允许动态调整 mmap 区域基址的随机化熵值，增强系统安全性。这些值受架构配置（`CONFIG_ARCH_MMAP_RND_BITS*`）约束，并可通过 `/proc/sys/kernel/` 接口运行时调整。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm.h>`、`<linux/vmalloc.h>`、`\"internal.h\"` 等提供的 VMA 操作、页表管理、内存分配接口。\n- **文件系统**：通过 `struct file` 和 `address_space` 与 VFS 层交互，处理文件映射（`shmem_fs.h` 用于 tmpfs/shm）。\n- **安全子系统**：集成 LSM（`<linux/security.h>`）钩子，支持安全策略检查。\n- **硬件架构**：依赖 `<asm/mmu_context.h>`、`<asm/tlb.h>` 等架构相关头文件处理 TLB 刷新和页表格式。\n- **其他子系统**：\n  - 用户态缺页处理（`userfaultfd_k.h`）\n  - 内存压缩（`ksm.h`）\n  - 大页支持（`hugetlb.h`）\n  - 性能事件（`perf_event.h`）\n  - OOM Killer（`oom.h`）\n\n## 5. 使用场景\n\n- **用户程序调用 `mmap()`/`munmap()`**：创建/销毁内存映射（文件映射、匿名映射、共享内存等）。\n- **动态内存分配**：`malloc()` 等库函数通过 `brk()` 或 `mmap()` 向内核申请堆内存。\n- **进程加载**：ELF 加载器使用 `mmap()` 映射可执行文件段和共享库。\n- **IPC 通信**：POSIX 共享内存（`shm_open` + `mmap`）和 System V 共享内存依赖此模块。\n- **内核子系统协作**：\n  - KSM（Kernel Samepage Merging）扫描 VMA 进行内存去重；\n  - userfaultfd 监控 VMA 的缺页事件；\n  - perf 工具通过 VMA 信息关联性能采样到代码位置；\n  - 安全模块（如 SELinux）在映射时实施访问控制。",
      "similarity": 0.4948601722717285,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "mm/mmap.c",
          "start_line": 1433,
          "end_line": 1540,
          "content": [
            "unsigned long ksys_mmap_pgoff(unsigned long addr, unsigned long len,",
            "\t\t\t      unsigned long prot, unsigned long flags,",
            "\t\t\t      unsigned long fd, unsigned long pgoff)",
            "{",
            "\tstruct file *file = NULL;",
            "\tunsigned long retval;",
            "",
            "\tif (!(flags & MAP_ANONYMOUS)) {",
            "\t\taudit_mmap_fd(fd, flags);",
            "\t\tfile = fget(fd);",
            "\t\tif (!file)",
            "\t\t\treturn -EBADF;",
            "\t\tif (is_file_hugepages(file)) {",
            "\t\t\tlen = ALIGN(len, huge_page_size(hstate_file(file)));",
            "\t\t} else if (unlikely(flags & MAP_HUGETLB)) {",
            "\t\t\tretval = -EINVAL;",
            "\t\t\tgoto out_fput;",
            "\t\t}",
            "\t} else if (flags & MAP_HUGETLB) {",
            "\t\tstruct hstate *hs;",
            "",
            "\t\ths = hstate_sizelog((flags >> MAP_HUGE_SHIFT) & MAP_HUGE_MASK);",
            "\t\tif (!hs)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\tlen = ALIGN(len, huge_page_size(hs));",
            "\t\t/*",
            "\t\t * VM_NORESERVE is used because the reservations will be",
            "\t\t * taken when vm_ops->mmap() is called",
            "\t\t */",
            "\t\tfile = hugetlb_file_setup(HUGETLB_ANON_FILE, len,",
            "\t\t\t\tVM_NORESERVE,",
            "\t\t\t\tHUGETLB_ANONHUGE_INODE,",
            "\t\t\t\t(flags >> MAP_HUGE_SHIFT) & MAP_HUGE_MASK);",
            "\t\tif (IS_ERR(file))",
            "\t\t\treturn PTR_ERR(file);",
            "\t}",
            "",
            "\tretval = vm_mmap_pgoff(file, addr, len, prot, flags, pgoff);",
            "out_fput:",
            "\tif (file)",
            "\t\tfput(file);",
            "\treturn retval;",
            "}",
            "static bool vm_ops_needs_writenotify(const struct vm_operations_struct *vm_ops)",
            "{",
            "\treturn vm_ops && (vm_ops->page_mkwrite || vm_ops->pfn_mkwrite);",
            "}",
            "static bool vma_is_shared_writable(struct vm_area_struct *vma)",
            "{",
            "\treturn (vma->vm_flags & (VM_WRITE | VM_SHARED)) ==",
            "\t\t(VM_WRITE | VM_SHARED);",
            "}",
            "static bool vma_fs_can_writeback(struct vm_area_struct *vma)",
            "{",
            "\t/* No managed pages to writeback. */",
            "\tif (vma->vm_flags & VM_PFNMAP)",
            "\t\treturn false;",
            "",
            "\treturn vma->vm_file && vma->vm_file->f_mapping &&",
            "\t\tmapping_can_writeback(vma->vm_file->f_mapping);",
            "}",
            "bool vma_needs_dirty_tracking(struct vm_area_struct *vma)",
            "{",
            "\t/* Only shared, writable VMAs require dirty tracking. */",
            "\tif (!vma_is_shared_writable(vma))",
            "\t\treturn false;",
            "",
            "\t/* Does the filesystem need to be notified? */",
            "\tif (vm_ops_needs_writenotify(vma->vm_ops))",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * Even if the filesystem doesn't indicate a need for writenotify, if it",
            "\t * can writeback, dirty tracking is still required.",
            "\t */",
            "\treturn vma_fs_can_writeback(vma);",
            "}",
            "bool vma_wants_writenotify(struct vm_area_struct *vma, pgprot_t vm_page_prot)",
            "{",
            "\t/* If it was private or non-writable, the write bit is already clear */",
            "\tif (!vma_is_shared_writable(vma))",
            "\t\treturn false;",
            "",
            "\t/* The backer wishes to know when pages are first written to? */",
            "\tif (vm_ops_needs_writenotify(vma->vm_ops))",
            "\t\treturn true;",
            "",
            "\t/* The open routine did something to the protections that pgprot_modify",
            "\t * won't preserve? */",
            "\tif (pgprot_val(vm_page_prot) !=",
            "\t    pgprot_val(vm_pgprot_modify(vm_page_prot, vma->vm_flags)))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Do we need to track softdirty? hugetlb does not support softdirty",
            "\t * tracking yet.",
            "\t */",
            "\tif (vma_soft_dirty_enabled(vma) && !is_vm_hugetlb_page(vma))",
            "\t\treturn true;",
            "",
            "\t/* Do we need write faults for uffd-wp tracking? */",
            "\tif (userfaultfd_wp(vma))",
            "\t\treturn true;",
            "",
            "\t/* Can the mapping track the dirty pages? */",
            "\treturn vma_fs_can_writeback(vma);",
            "}"
          ],
          "function_name": "ksys_mmap_pgoff, vm_ops_needs_writenotify, vma_is_shared_writable, vma_fs_can_writeback, vma_needs_dirty_tracking, vma_wants_writenotify",
          "description": "ksys_mmap_pgoff创建huge pages映射并调用vm_mmap_pgoff；vm_ops_needs_writenotify检测是否需要写通知；vma_is_shared_writable判断共享可写VMA；vma_needs_dirty_tracking决定是否需要脏页跟踪；vma_wants_writenotify综合判断是否触发写通知。",
          "similarity": 0.5014608502388
        },
        {
          "chunk_id": 19,
          "file_path": "mm/mmap.c",
          "start_line": 4054,
          "end_line": 4060,
          "content": [
            "static int __meminit init_reserve_notifier(void)",
            "{",
            "\tif (hotplug_memory_notifier(reserve_mem_notifier, DEFAULT_CALLBACK_PRI))",
            "\t\tpr_err(\"Failed registering memory add/remove notifier for admin reserve\\n\");",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "init_reserve_notifier",
          "description": "该代码段定义于`mm/mmap.c`，核心功能是注册内存预留相关通知回调。函数通过`hotplug_memory_notifier`注册`reserve_mem_notifier`回调至内存热插拔事件链表，用于跟踪内存预留状态变化。由于`reserve_mem_notifier`结构体定义缺失，上下文不完整。",
          "similarity": 0.4855743944644928
        },
        {
          "chunk_id": 7,
          "file_path": "mm/mmap.c",
          "start_line": 1592,
          "end_line": 1696,
          "content": [
            "static inline bool accountable_mapping(struct file *file, vm_flags_t vm_flags)",
            "{",
            "\t/*",
            "\t * hugetlb has its own accounting separate from the core VM",
            "\t * VM_HUGETLB may not be set yet so we cannot check for that flag.",
            "\t */",
            "\tif (file && is_file_hugepages(file))",
            "\t\treturn false;",
            "",
            "\treturn (vm_flags & (VM_NORESERVE | VM_SHARED | VM_WRITE)) == VM_WRITE;",
            "}",
            "static unsigned long unmapped_area(struct vm_unmapped_area_info *info)",
            "{",
            "\tunsigned long length, gap;",
            "\tunsigned long low_limit, high_limit;",
            "\tstruct vm_area_struct *tmp;",
            "",
            "\tMA_STATE(mas, &current->mm->mm_mt, 0, 0);",
            "",
            "\t/* Adjust search length to account for worst case alignment overhead */",
            "\tlength = info->length + info->align_mask;",
            "\tif (length < info->length)",
            "\t\treturn -ENOMEM;",
            "",
            "\tlow_limit = info->low_limit;",
            "\tif (low_limit < mmap_min_addr)",
            "\t\tlow_limit = mmap_min_addr;",
            "\thigh_limit = info->high_limit;",
            "retry:",
            "\tif (mas_empty_area(&mas, low_limit, high_limit - 1, length))",
            "\t\treturn -ENOMEM;",
            "",
            "\tgap = mas.index;",
            "\tgap += (info->align_offset - gap) & info->align_mask;",
            "\ttmp = mas_next(&mas, ULONG_MAX);",
            "\tif (tmp && (tmp->vm_flags & VM_STARTGAP_FLAGS)) { /* Avoid prev check if possible */",
            "\t\tif (vm_start_gap(tmp) < gap + length - 1) {",
            "\t\t\tlow_limit = tmp->vm_end;",
            "\t\t\tmas_reset(&mas);",
            "\t\t\tgoto retry;",
            "\t\t}",
            "\t} else {",
            "\t\ttmp = mas_prev(&mas, 0);",
            "\t\tif (tmp && vm_end_gap(tmp) > gap) {",
            "\t\t\tlow_limit = vm_end_gap(tmp);",
            "\t\t\tmas_reset(&mas);",
            "\t\t\tgoto retry;",
            "\t\t}",
            "\t}",
            "",
            "\treturn gap;",
            "}",
            "static unsigned long unmapped_area_topdown(struct vm_unmapped_area_info *info)",
            "{",
            "\tunsigned long length, gap, gap_end;",
            "\tunsigned long low_limit, high_limit;",
            "\tstruct vm_area_struct *tmp;",
            "",
            "\tMA_STATE(mas, &current->mm->mm_mt, 0, 0);",
            "\t/* Adjust search length to account for worst case alignment overhead */",
            "\tlength = info->length + info->align_mask;",
            "\tif (length < info->length)",
            "\t\treturn -ENOMEM;",
            "",
            "\tlow_limit = info->low_limit;",
            "\tif (low_limit < mmap_min_addr)",
            "\t\tlow_limit = mmap_min_addr;",
            "\thigh_limit = info->high_limit;",
            "retry:",
            "\tif (mas_empty_area_rev(&mas, low_limit, high_limit - 1, length))",
            "\t\treturn -ENOMEM;",
            "",
            "\tgap = mas.last + 1 - info->length;",
            "\tgap -= (gap - info->align_offset) & info->align_mask;",
            "\tgap_end = mas.last;",
            "\ttmp = mas_next(&mas, ULONG_MAX);",
            "\tif (tmp && (tmp->vm_flags & VM_STARTGAP_FLAGS)) { /* Avoid prev check if possible */",
            "\t\tif (vm_start_gap(tmp) <= gap_end) {",
            "\t\t\thigh_limit = vm_start_gap(tmp);",
            "\t\t\tmas_reset(&mas);",
            "\t\t\tgoto retry;",
            "\t\t}",
            "\t} else {",
            "\t\ttmp = mas_prev(&mas, 0);",
            "\t\tif (tmp && vm_end_gap(tmp) > gap) {",
            "\t\t\thigh_limit = tmp->vm_start;",
            "\t\t\tmas_reset(&mas);",
            "\t\t\tgoto retry;",
            "\t\t}",
            "\t}",
            "",
            "\treturn gap;",
            "}",
            "unsigned long vm_unmapped_area(struct vm_unmapped_area_info *info)",
            "{",
            "\tunsigned long addr;",
            "",
            "\tif (info->flags & VM_UNMAPPED_AREA_TOPDOWN)",
            "\t\taddr = unmapped_area_topdown(info);",
            "\telse",
            "\t\taddr = unmapped_area(info);",
            "",
            "\ttrace_vm_unmapped_area(addr, info);",
            "\treturn addr;",
            "}"
          ],
          "function_name": "accountable_mapping, unmapped_area, unmapped_area_topdown, vm_unmapped_area",
          "description": "accountable_mapping判断映射是否计入内存账本；unmapped_area和unmapped_area_topdown查找空闲地址区间，处理对齐和间隙约束；vm_unmapped_area根据标志选择搜索策略返回可用地址。",
          "similarity": 0.48243290185928345
        },
        {
          "chunk_id": 0,
          "file_path": "mm/mmap.c",
          "start_line": 1,
          "end_line": 83,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * mm/mmap.c",
            " *",
            " * Written by obz.",
            " *",
            " * Address space accounting code\t<alan@lxorguk.ukuu.org.uk>",
            " */",
            "",
            "#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt",
            "",
            "#include <linux/kernel.h>",
            "#include <linux/slab.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/mm.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/shm.h>",
            "#include <linux/mman.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/swap.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/capability.h>",
            "#include <linux/init.h>",
            "#include <linux/file.h>",
            "#include <linux/fs.h>",
            "#include <linux/personality.h>",
            "#include <linux/security.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/profile.h>",
            "#include <linux/export.h>",
            "#include <linux/mount.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/rmap.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/mmdebug.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/audit.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/notifier.h>",
            "#include <linux/memory.h>",
            "#include <linux/printk.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/pkeys.h>",
            "#include <linux/oom.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/ksm.h>",
            "",
            "#include <linux/uaccess.h>",
            "#include <asm/cacheflush.h>",
            "#include <asm/tlb.h>",
            "#include <asm/mmu_context.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/mmap.h>",
            "",
            "#include \"internal.h\"",
            "",
            "#ifndef arch_mmap_check",
            "#define arch_mmap_check(addr, len, flags)\t(0)",
            "#endif",
            "",
            "#ifdef CONFIG_HAVE_ARCH_MMAP_RND_BITS",
            "const int mmap_rnd_bits_min = CONFIG_ARCH_MMAP_RND_BITS_MIN;",
            "const int mmap_rnd_bits_max = CONFIG_ARCH_MMAP_RND_BITS_MAX;",
            "int mmap_rnd_bits __read_mostly = CONFIG_ARCH_MMAP_RND_BITS;",
            "#endif",
            "#ifdef CONFIG_HAVE_ARCH_MMAP_RND_COMPAT_BITS",
            "const int mmap_rnd_compat_bits_min = CONFIG_ARCH_MMAP_RND_COMPAT_BITS_MIN;",
            "const int mmap_rnd_compat_bits_max = CONFIG_ARCH_MMAP_RND_COMPAT_BITS_MAX;",
            "int mmap_rnd_compat_bits __read_mostly = CONFIG_ARCH_MMAP_RND_COMPAT_BITS;",
            "#endif",
            "",
            "static bool ignore_rlimit_data;",
            "core_param(ignore_rlimit_data, ignore_rlimit_data, bool, 0644);",
            "",
            "static void unmap_region(struct mm_struct *mm, struct ma_state *mas,",
            "\t\tstruct vm_area_struct *vma, struct vm_area_struct *prev,",
            "\t\tstruct vm_area_struct *next, unsigned long start,",
            "\t\tunsigned long end, unsigned long tree_end, bool mm_wr_locked);",
            ""
          ],
          "function_name": null,
          "description": "此代码块为mm/mmap.c文件的头部，包含必要的头文件和全局变量定义，声明了unmap_region函数原型，用于后续内存映射相关操作的上下文初始化，由于代码不完整，需注意上下文完整性。",
          "similarity": 0.4725431203842163
        },
        {
          "chunk_id": 14,
          "file_path": "mm/mmap.c",
          "start_line": 3029,
          "end_line": 3138,
          "content": [
            "static int __vm_munmap(unsigned long start, size_t len, bool unlock)",
            "{",
            "\tint ret;",
            "\tstruct mm_struct *mm = current->mm;",
            "\tLIST_HEAD(uf);",
            "\tVMA_ITERATOR(vmi, mm, start);",
            "",
            "\tif (mmap_write_lock_killable(mm))",
            "\t\treturn -EINTR;",
            "",
            "\tret = do_vmi_munmap(&vmi, mm, start, len, &uf, unlock);",
            "\tif (ret || !unlock)",
            "\t\tmmap_write_unlock(mm);",
            "",
            "\tuserfaultfd_unmap_complete(mm, &uf);",
            "\treturn ret;",
            "}",
            "int vm_munmap(unsigned long start, size_t len)",
            "{",
            "\treturn __vm_munmap(start, len, false);",
            "}",
            "int do_vma_munmap(struct vma_iterator *vmi, struct vm_area_struct *vma,",
            "\t\tunsigned long start, unsigned long end, struct list_head *uf,",
            "\t\tbool unlock)",
            "{",
            "\tstruct mm_struct *mm = vma->vm_mm;",
            "",
            "\tarch_unmap(mm, start, end);",
            "\treturn do_vmi_align_munmap(vmi, vma, mm, start, end, uf, unlock);",
            "}",
            "static int do_brk_flags(struct vma_iterator *vmi, struct vm_area_struct *vma,",
            "\t\tunsigned long addr, unsigned long len, unsigned long flags)",
            "{",
            "\tstruct mm_struct *mm = current->mm;",
            "\tstruct vma_prepare vp;",
            "",
            "\t/*",
            "\t * Check against address space limits by the changed size",
            "\t * Note: This happens *after* clearing old mappings in some code paths.",
            "\t */",
            "\tflags |= VM_DATA_DEFAULT_FLAGS | VM_ACCOUNT | mm->def_flags;",
            "\tif (!may_expand_vm(mm, flags, len >> PAGE_SHIFT))",
            "\t\treturn -ENOMEM;",
            "",
            "\tif (mm->map_count > sysctl_max_map_count)",
            "\t\treturn -ENOMEM;",
            "",
            "\tif (security_vm_enough_memory_mm(mm, len >> PAGE_SHIFT))",
            "\t\treturn -ENOMEM;",
            "",
            "\t/*",
            "\t * Expand the existing vma if possible; Note that singular lists do not",
            "\t * occur after forking, so the expand will only happen on new VMAs.",
            "\t */",
            "\tif (vma && vma->vm_end == addr && !vma_policy(vma) &&",
            "\t    can_vma_merge_after(vma, flags, NULL, NULL,",
            "\t\t\t\taddr >> PAGE_SHIFT, NULL_VM_UFFD_CTX, NULL)) {",
            "\t\tvma_iter_config(vmi, vma->vm_start, addr + len);",
            "\t\tif (vma_iter_prealloc(vmi, vma))",
            "\t\t\tgoto unacct_fail;",
            "",
            "\t\tvma_start_write(vma);",
            "",
            "\t\tinit_vma_prep(&vp, vma);",
            "\t\tvma_prepare(&vp);",
            "\t\tvma_adjust_trans_huge(vma, vma->vm_start, addr + len, 0);",
            "\t\tvma->vm_end = addr + len;",
            "\t\tvm_flags_set(vma, VM_SOFTDIRTY);",
            "\t\tvma_iter_store(vmi, vma);",
            "",
            "\t\tvma_complete(&vp, vmi, mm);",
            "\t\tkhugepaged_enter_vma(vma, flags);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (vma)",
            "\t\tvma_iter_next_range(vmi);",
            "\t/* create a vma struct for an anonymous mapping */",
            "\tvma = vm_area_alloc(mm);",
            "\tif (!vma)",
            "\t\tgoto unacct_fail;",
            "",
            "\tvma_set_anonymous(vma);",
            "\tvma->vm_start = addr;",
            "\tvma->vm_end = addr + len;",
            "\tvma->vm_pgoff = addr >> PAGE_SHIFT;",
            "\tvm_flags_init(vma, flags);",
            "\tvma->vm_page_prot = vm_get_page_prot(flags);",
            "\tvma_start_write(vma);",
            "\tif (vma_iter_store_gfp(vmi, vma, GFP_KERNEL))",
            "\t\tgoto mas_store_fail;",
            "",
            "\tmm->map_count++;",
            "\tvalidate_mm(mm);",
            "\tksm_add_vma(vma);",
            "out:",
            "\tperf_event_mmap(vma);",
            "\tmm->total_vm += len >> PAGE_SHIFT;",
            "\tmm->data_vm += len >> PAGE_SHIFT;",
            "\tif (flags & VM_LOCKED)",
            "\t\tmm->locked_vm += (len >> PAGE_SHIFT);",
            "\tvm_flags_set(vma, VM_SOFTDIRTY);",
            "\treturn 0;",
            "",
            "mas_store_fail:",
            "\tvm_area_free(vma);",
            "unacct_fail:",
            "\tvm_unacct_memory(len >> PAGE_SHIFT);",
            "\treturn -ENOMEM;",
            "}"
          ],
          "function_name": "__vm_munmap, vm_munmap, do_vma_munmap, do_brk_flags",
          "description": "__vm_munmap通过持有mmap锁执行解除映射操作，do_brk_flags用于调整堆大小，尝试扩展现有VMA或新建匿名区域，包含地址空间限制检查、VMA合并尝试以及失败时的资源回滚逻辑",
          "similarity": 0.46521174907684326
        }
      ]
    },
    {
      "source_file": "kernel/dma/ops_helpers.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:14:54\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `dma\\ops_helpers.c`\n\n---\n\n# `dma/ops_helpers.c` 技术文档\n\n## 1. 文件概述\n\n`dma/ops_helpers.c` 是 Linux 内核中为 DMA（Direct Memory Access）操作提供通用辅助功能的实现文件。该文件封装了多个通用的 DMA 操作辅助函数，用于简化不同架构或设备驱动中 DMA 映射、内存分配、用户空间映射及 scatter-gather 表构建等常见任务。这些函数假设所分配的内存位于内核直接映射区域（normal pages in the direct kernel mapping），并依赖底层 `dma_map_ops` 操作集完成实际的硬件相关操作。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `dma_common_vaddr_to_page(void *cpu_addr)`  \n  将内核虚拟地址转换为对应的 `struct page *`，支持 `vmalloc` 区域和直接映射区域。\n\n- `dma_common_get_sgtable(struct device *dev, struct sg_table *sgt, void *cpu_addr, dma_addr_t dma_addr, size_t size, unsigned long attrs)`  \n  为已分配的 DMA 缓冲区创建单页 scatter-gather 表（`sg_table`）。\n\n- `dma_common_mmap(struct device *dev, struct vm_area_struct *vma, void *cpu_addr, dma_addr_t dma_addr, size_t size, unsigned long attrs)`  \n  为 DMA 一致性内存创建用户空间 mmap 映射。\n\n- `dma_common_alloc_pages(struct device *dev, size_t size, dma_addr_t *dma_handle, enum dma_data_direction dir, gfp_t gfp)`  \n  分配物理连续（或通过 CMA）的页面，并通过 DMA 映射操作获取设备可访问的总线地址。\n\n- `dma_common_free_pages(struct device *dev, size_t size, struct page *page, dma_addr_t dma_handle, enum dma_data_direction dir)`  \n  释放由 `dma_common_alloc_pages` 分配的页面，并取消 DMA 映射。\n\n### 数据结构\n\n- 无定义新的数据结构，主要使用内核通用结构：\n  - `struct page`\n  - `struct sg_table`\n  - `struct vm_area_struct`\n  - `struct device`\n\n## 3. 关键实现\n\n### 地址到页面转换\n`dma_common_vaddr_to_page` 函数首先判断传入的 CPU 虚拟地址是否属于 `vmalloc` 区域。若是，则调用 `vmalloc_to_page`；否则使用 `virt_to_page`。这确保了对内核不同内存区域的兼容性。\n\n### Scatter-Gather 表构建\n`dma_common_get_sgtable` 假设 DMA 缓冲区由单个物理页面（或连续页面）组成，因此只分配一个 scatterlist 条目，并通过 `sg_set_page` 设置页面、长度（按页对齐）和偏移（0）。\n\n### 用户空间 mmap 支持\n`dma_common_mmap` 函数：\n- 仅在 `CONFIG_MMU` 配置下有效；\n- 首先尝试通过 `dma_mmap_from_dev_coherent` 处理设备特定的一致性内存映射；\n- 若失败，则使用通用路径：将内核页面的 PFN（页帧号）加上 `vma->vm_pgoff`，通过 `remap_pfn_range` 映射到用户空间；\n- 映射前进行边界检查，防止越界访问；\n- 使用 `dma_pgprot` 根据设备属性调整页保护标志。\n\n### 页面分配与释放\n- `dma_common_alloc_pages` 优先尝试通过 CMA（Contiguous Memory Allocator）分配连续物理内存（`dma_alloc_contiguous`），失败后回退到 `alloc_pages_node`；\n- 分配成功后，调用设备的 `map_page` 操作获取 DMA 地址，并跳过 CPU 缓存同步（`DMA_ATTR_SKIP_CPU_SYNC`）；\n- 分配的内存会被清零；\n- 释放时先调用 `unmap_page`（若存在），再通过 `dma_free_contiguous` 释放物理页面。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/dma-map-ops.h>`：提供 `dma_map_ops`、`get_dma_ops`、`dma_alloc_contiguous` 等核心 DMA 操作接口。\n- **内核子系统依赖**：\n  - **内存管理子系统**：依赖 `vmalloc`、`page`、`pfn`、`remap_pfn_range` 等 MMU 相关机制；\n  - **CMA（Contiguous Memory Allocator）**：用于分配大块连续物理内存；\n  - **设备模型**：通过 `struct device` 获取 NUMA 节点（`dev_to_node`）和 DMA 操作集；\n  - **DMA 映射框架**：依赖各架构或平台实现的 `dma_map_ops`（如 `map_page`/`unmap_page`）。\n\n## 5. 使用场景\n\n- **设备驱动开发**：当驱动需要实现自定义的 `dma_map_ops` 时，可复用本文件中的通用函数，避免重复实现 scatterlist 构建、mmap 或页面分配逻辑。\n- **一致性 DMA 内存管理**：适用于需要分配一致性（coherent）DMA 内存并映射到用户空间的场景（如音视频、网络设备驱动）。\n- **简化 DMA 编程模型**：为不支持复杂 IOMMU 或 scatter-gather 的简单设备提供轻量级 DMA 操作封装。\n- **跨架构兼容性**：通过抽象底层差异，使驱动代码在不同架构（如 ARM、x86）上保持一致行为。",
      "similarity": 0.48795628547668457,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/dma/ops_helpers.c",
          "start_line": 18,
          "end_line": 65,
          "content": [
            "int dma_common_get_sgtable(struct device *dev, struct sg_table *sgt,",
            "\t\t void *cpu_addr, dma_addr_t dma_addr, size_t size,",
            "\t\t unsigned long attrs)",
            "{",
            "\tstruct page *page = dma_common_vaddr_to_page(cpu_addr);",
            "\tint ret;",
            "",
            "\tret = sg_alloc_table(sgt, 1, GFP_KERNEL);",
            "\tif (!ret)",
            "\t\tsg_set_page(sgt->sgl, page, PAGE_ALIGN(size), 0);",
            "\treturn ret;",
            "}",
            "int dma_common_mmap(struct device *dev, struct vm_area_struct *vma,",
            "\t\tvoid *cpu_addr, dma_addr_t dma_addr, size_t size,",
            "\t\tunsigned long attrs)",
            "{",
            "#ifdef CONFIG_MMU",
            "\tunsigned long user_count = vma_pages(vma);",
            "\tunsigned long count = PAGE_ALIGN(size) >> PAGE_SHIFT;",
            "\tunsigned long off = vma->vm_pgoff;",
            "\tstruct page *page = dma_common_vaddr_to_page(cpu_addr);",
            "\tint ret = -ENXIO;",
            "",
            "\tvma->vm_page_prot = dma_pgprot(dev, vma->vm_page_prot, attrs);",
            "",
            "\tif (dma_mmap_from_dev_coherent(dev, vma, cpu_addr, size, &ret))",
            "\t\treturn ret;",
            "",
            "\tif (off >= count || user_count > count - off)",
            "\t\treturn -ENXIO;",
            "",
            "\treturn remap_pfn_range(vma, vma->vm_start,",
            "\t\t\tpage_to_pfn(page) + vma->vm_pgoff,",
            "\t\t\tuser_count << PAGE_SHIFT, vma->vm_page_prot);",
            "#else",
            "\treturn -ENXIO;",
            "#endif /* CONFIG_MMU */",
            "}",
            "void dma_common_free_pages(struct device *dev, size_t size, struct page *page,",
            "\t\tdma_addr_t dma_handle, enum dma_data_direction dir)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (ops->unmap_page)",
            "\t\tops->unmap_page(dev, dma_handle, size, dir,",
            "\t\t\t\tDMA_ATTR_SKIP_CPU_SYNC);",
            "\tdma_free_contiguous(dev, page, size);",
            "}"
          ],
          "function_name": "dma_common_get_sgtable, dma_common_mmap, dma_common_free_pages",
          "description": "该代码块实现了三个DMA操作辅助函数，dma_common_get_sgtable构建单页SG表用于DMA传输，dma_common_mmap处理设备内存映射并支持MMU配置，dma_common_free_pages负责解除页面映射并释放连续内存资源",
          "similarity": 0.4780907928943634
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/dma/ops_helpers.c",
          "start_line": 1,
          "end_line": 17,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Helpers for DMA ops implementations.  These generally rely on the fact that",
            " * the allocated memory contains normal pages in the direct kernel mapping.",
            " */",
            "#include <linux/dma-map-ops.h>",
            "",
            "static struct page *dma_common_vaddr_to_page(void *cpu_addr)",
            "{",
            "\tif (is_vmalloc_addr(cpu_addr))",
            "\t\treturn vmalloc_to_page(cpu_addr);",
            "\treturn virt_to_page(cpu_addr);",
            "}",
            "",
            "/*",
            " * Create scatter-list for the already allocated DMA buffer.",
            " */"
          ],
          "function_name": null,
          "description": "该代码块定义了dma_common_vaddr_to_page函数，用于将CPU虚拟地址转换为对应的物理页面结构，通过判断地址是否属于vmalloc区域选择不同的转换方式。后续未展示的代码可能包含与DMA操作相关的辅助函数声明，当前上下文不完整",
          "similarity": 0.38777828216552734
        }
      ]
    },
    {
      "source_file": "kernel/dma/pool.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:15:49\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `dma\\pool.c`\n\n---\n\n# `dma/pool.c` 技术文档\n\n## 1. 文件概述\n\n`dma/pool.c` 实现了 Linux 内核中的 **DMA 原子内存池（atomic DMA pools）** 机制，用于在无法睡眠的上下文（如中断处理、原子上下文）中分配一致性（coherent）DMA 内存。该机制通过预分配多个按内存区域（ZONE_DMA、ZONE_DMA32、普通内核内存）划分的通用内存池（`gen_pool`），并在池空间不足时通过工作队列异步扩展，从而支持在 GFP_ATOMIC 等限制性分配标志下安全地分配 DMA 内存。\n\n该文件主要用于支持 `dma-direct` 子系统中的原子 DMA 分配路径，确保即使在内存压力大或无法睡眠的场景下，设备驱动仍能获得满足地址限制（如 32 位或 24 位寻址）的一致性 DMA 缓冲区。\n\n## 2. 核心功能\n\n### 全局变量\n- `atomic_pool_dma` / `pool_size_dma`：用于 `GFP_DMA` 区域的原子 DMA 池及其已分配大小。\n- `atomic_pool_dma32` / `pool_size_dma32`：用于 `GFP_DMA32` 区域的原子 DMA 池及其已分配大小。\n- `atomic_pool_kernel` / `pool_size_kernel`：用于普通内核区域（无特殊 DMA 限制）的原子 DMA 池及其已分配大小。\n- `atomic_pool_size`：每个池的初始目标大小，可通过内核命令行参数 `coherent_pool=` 设置。\n- `atomic_pool_work`：用于后台动态扩展内存池的工作项。\n\n### 主要函数\n- `early_coherent_pool()`：解析内核命令行参数 `coherent_pool`，设置 `atomic_pool_size`。\n- `dma_atomic_pool_init()`：初始化所有原子 DMA 池（postcore 阶段调用）。\n- `__dma_atomic_pool_init()`：创建并填充指定 GFP 标志的原子池。\n- `atomic_pool_expand()`：向指定池中添加一块连续物理内存。\n- `atomic_pool_resize()` / `atomic_pool_work_fn()`：检查池剩余空间，若不足则触发扩展。\n- `dma_alloc_from_pool()`：从合适的原子池中分配指定大小的 DMA 内存。\n- `dma_free_from_pool()`：将内存归还到对应的原子池。\n- `dma_guess_pool()`：根据 GFP 标志和尝试顺序选择合适的内存池。\n- `cma_in_zone()`：判断 CMA 区域是否位于指定 DMA 区域内，以决定是否优先从 CMA 分配。\n- `dma_atomic_pool_debugfs_init()`：在 debugfs 中导出各池的当前大小。\n\n## 3. 关键实现\n\n### 内存池初始化策略\n- 若未通过 `coherent_pool=` 指定大小，则默认按 **每 1GB 物理内存分配 128KB** 原子池，最小 128KB，最大不超过 `MAX_ORDER_NR_PAGES` 对应的内存。\n- 每个池使用 `gen_pool` 管理，分配算法为 `gen_pool_first_fit_order_align`，保证分配地址按页对齐。\n- 初始化时调用 `atomic_pool_expand()` 预分配内存。\n\n### 内存分配来源\n- 优先尝试从 **CMA（Contiguous Memory Allocator）** 区域分配（若 CMA 区域位于目标 DMA zone 内）。\n- 若 CMA 不可用或不在目标 zone，则回退到 `alloc_pages()`。\n- 分配的内存块大小不超过 `MAX_PAGE_ORDER`，通过降序尝试（从大到小）提高分配成功率。\n\n### 内存属性处理\n- 调用 `arch_dma_prep_coherent()` 通知架构层准备一致性内存。\n- 在支持内存加密（如 AMD SEV、Intel TDX）的系统上，显式调用 `set_memory_decrypted()` 确保 DMA 内存为 **未加密状态**，因为设备无法访问加密内存。\n- 若启用了 `CONFIG_DMA_DIRECT_REMAP`，则通过 `dma_common_contiguous_remap()` 建立非缓存或设备专用的页表映射。\n\n### 动态扩展机制\n- 每次从池中分配内存后，检查剩余空间是否小于 `atomic_pool_size`。\n- 若不足，则调度 `atomic_pool_work` 工作项，在进程上下文中异步扩展对应池。\n- 扩展时尝试分配与当前池总大小相当的新内存块，避免频繁小量扩展。\n\n### 多池选择逻辑\n- `dma_guess_pool()` 实现池选择策略：\n  1. 首选与 GFP 标志匹配的池（DMA32 > DMA > 普通内核）。\n  2. 若首次分配失败，按 `kernel → dma32 → dma` 顺序尝试其他池（fallback 机制）。\n- 释放时遍历所有池，通过 `gen_pool_has_addr()` 确定内存归属。\n\n## 4. 依赖关系\n\n- **内存管理子系统**：\n  - 依赖 `genalloc`（`gen_pool`）实现内存池管理。\n  - 使用 `alloc_pages()`、`__free_pages()` 进行底层页分配。\n  - 依赖 CMA 接口（`dma_alloc_from_contiguous()`）获取大块连续内存。\n- **DMA 子系统**：\n  - 与 `dma-direct.c` 紧密集成，为其提供 `___dma_direct_alloc_pages()` 中的原子分配路径。\n  - 使用 `dma-map-ops.h` 和 `dma-direct.h` 中的辅助函数。\n- **架构相关支持**：\n  - 调用 `arch_dma_prep_coherent()`（架构可选实现）。\n  - 使用 `set_memory_decrypted()`/`set_memory_encrypted()`（x86/ARM64 等支持内存加密的架构）。\n  - 依赖 `DMA_BIT_MASK()` 和 `zone_dma_bits` 判断 DMA 地址范围。\n- **其他**：\n  - 使用 `debugfs` 导出调试信息。\n  - 依赖 `workqueue` 实现异步扩展。\n  - 使用 `slab.h` 中的内存分配器（间接）。\n\n## 5. 使用场景\n\n- **原子上下文 DMA 分配**：当设备驱动在中断处理程序、自旋锁保护区域或使用 `GFP_ATOMIC` 标志调用 `dma_alloc_coherent()` 时，若常规页分配器无法满足（如内存碎片），内核会回退到从原子池分配。\n- **满足地址限制的 DMA 缓冲区**：对于需要 24 位（ISA 设备）或 32 位（旧 PCIe 设备）寻址能力的设备，驱动使用 `DMA_BIT_MASK(24)` 或 `DMA_BIT_MASK(32)` 限制 DMA 地址范围，原子池确保分配的内存物理地址符合要求。\n- **一致性内存需求**：适用于需要 CPU 与设备之间缓存一致性的场景（如网络数据包缓冲区、音频流缓冲区），原子池分配的内存经过 `arch_dma_prep_coherent()` 处理，保证一致性。\n- **内存加密环境**：在启用内存加密的系统中，确保分配给设备的 DMA 内存处于解密状态，使设备能正常访问。",
      "similarity": 0.46983635425567627,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/dma/pool.c",
          "start_line": 29,
          "end_line": 138,
          "content": [
            "static int __init early_coherent_pool(char *p)",
            "{",
            "\tatomic_pool_size = memparse(p, &p);",
            "\treturn 0;",
            "}",
            "static void __init dma_atomic_pool_debugfs_init(void)",
            "{",
            "\tstruct dentry *root;",
            "",
            "\troot = debugfs_create_dir(\"dma_pools\", NULL);",
            "\tdebugfs_create_ulong(\"pool_size_dma\", 0400, root, &pool_size_dma);",
            "\tdebugfs_create_ulong(\"pool_size_dma32\", 0400, root, &pool_size_dma32);",
            "\tdebugfs_create_ulong(\"pool_size_kernel\", 0400, root, &pool_size_kernel);",
            "}",
            "static void dma_atomic_pool_size_add(gfp_t gfp, size_t size)",
            "{",
            "\tif (gfp & __GFP_DMA)",
            "\t\tpool_size_dma += size;",
            "\telse if (gfp & __GFP_DMA32)",
            "\t\tpool_size_dma32 += size;",
            "\telse",
            "\t\tpool_size_kernel += size;",
            "}",
            "static bool cma_in_zone(gfp_t gfp)",
            "{",
            "\tunsigned long size;",
            "\tphys_addr_t end;",
            "\tstruct cma *cma;",
            "",
            "\tcma = dev_get_cma_area(NULL);",
            "\tif (!cma)",
            "\t\treturn false;",
            "",
            "\tsize = cma_get_size(cma);",
            "\tif (!size)",
            "\t\treturn false;",
            "",
            "\t/* CMA can't cross zone boundaries, see cma_activate_area() */",
            "\tend = cma_get_base(cma) + size - 1;",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA) && (gfp & GFP_DMA))",
            "\t\treturn end <= DMA_BIT_MASK(zone_dma_bits);",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA32) && (gfp & GFP_DMA32))",
            "\t\treturn end <= DMA_BIT_MASK(32);",
            "\treturn true;",
            "}",
            "static int atomic_pool_expand(struct gen_pool *pool, size_t pool_size,",
            "\t\t\t      gfp_t gfp)",
            "{",
            "\tunsigned int order;",
            "\tstruct page *page = NULL;",
            "\tvoid *addr;",
            "\tint ret = -ENOMEM;",
            "",
            "\t/* Cannot allocate larger than MAX_PAGE_ORDER */",
            "\torder = min(get_order(pool_size), MAX_PAGE_ORDER);",
            "",
            "\tdo {",
            "\t\tpool_size = 1 << (PAGE_SHIFT + order);",
            "\t\tif (cma_in_zone(gfp))",
            "\t\t\tpage = dma_alloc_from_contiguous(NULL, 1 << order,",
            "\t\t\t\t\t\t\t order, false);",
            "\t\tif (!page)",
            "\t\t\tpage = alloc_pages(gfp, order);",
            "\t} while (!page && order-- > 0);",
            "\tif (!page)",
            "\t\tgoto out;",
            "",
            "\tarch_dma_prep_coherent(page, pool_size);",
            "",
            "#ifdef CONFIG_DMA_DIRECT_REMAP",
            "\taddr = dma_common_contiguous_remap(page, pool_size,",
            "\t\t\tpgprot_decrypted(pgprot_dmacoherent(PAGE_KERNEL)),",
            "\t\t\t__builtin_return_address(0));",
            "\tif (!addr)",
            "\t\tgoto free_page;",
            "#else",
            "\taddr = page_to_virt(page);",
            "#endif",
            "\t/*",
            "\t * Memory in the atomic DMA pools must be unencrypted, the pools do not",
            "\t * shrink so no re-encryption occurs in dma_direct_free().",
            "\t */",
            "\tret = set_memory_decrypted((unsigned long)page_to_virt(page),",
            "\t\t\t\t   1 << order);",
            "\tif (ret)",
            "\t\tgoto remove_mapping;",
            "\tret = gen_pool_add_virt(pool, (unsigned long)addr, page_to_phys(page),",
            "\t\t\t\tpool_size, NUMA_NO_NODE);",
            "\tif (ret)",
            "\t\tgoto encrypt_mapping;",
            "",
            "\tdma_atomic_pool_size_add(gfp, pool_size);",
            "\treturn 0;",
            "",
            "encrypt_mapping:",
            "\tret = set_memory_encrypted((unsigned long)page_to_virt(page),",
            "\t\t\t\t   1 << order);",
            "\tif (WARN_ON_ONCE(ret)) {",
            "\t\t/* Decrypt succeeded but encrypt failed, purposely leak */",
            "\t\tgoto out;",
            "\t}",
            "remove_mapping:",
            "#ifdef CONFIG_DMA_DIRECT_REMAP",
            "\tdma_common_free_remap(addr, pool_size);",
            "free_page:",
            "\t__free_pages(page, order);",
            "#endif",
            "out:",
            "\treturn ret;",
            "}"
          ],
          "function_name": "early_coherent_pool, dma_atomic_pool_debugfs_init, dma_atomic_pool_size_add, cma_in_zone, atomic_pool_expand",
          "description": "实现DMA内存池的动态扩展逻辑，包含解析命令行参数、调试接口注册、内存分配策略选择、CMA区域有效性检测及池扩容操作，支持加密/解密内存映射管理。",
          "similarity": 0.42077895998954773
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/dma/pool.c",
          "start_line": 145,
          "end_line": 207,
          "content": [
            "static void atomic_pool_resize(struct gen_pool *pool, gfp_t gfp)",
            "{",
            "\tif (pool && gen_pool_avail(pool) < atomic_pool_size)",
            "\t\tatomic_pool_expand(pool, gen_pool_size(pool), gfp);",
            "}",
            "static void atomic_pool_work_fn(struct work_struct *work)",
            "{",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA))",
            "\t\tatomic_pool_resize(atomic_pool_dma,",
            "\t\t\t\t   GFP_KERNEL | GFP_DMA);",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA32))",
            "\t\tatomic_pool_resize(atomic_pool_dma32,",
            "\t\t\t\t   GFP_KERNEL | GFP_DMA32);",
            "\tatomic_pool_resize(atomic_pool_kernel, GFP_KERNEL);",
            "}",
            "static int __init dma_atomic_pool_init(void)",
            "{",
            "\tint ret = 0;",
            "",
            "\t/*",
            "\t * If coherent_pool was not used on the command line, default the pool",
            "\t * sizes to 128KB per 1GB of memory, min 128KB, max MAX_PAGE_ORDER.",
            "\t */",
            "\tif (!atomic_pool_size) {",
            "\t\tunsigned long pages = totalram_pages() / (SZ_1G / SZ_128K);",
            "\t\tpages = min_t(unsigned long, pages, MAX_ORDER_NR_PAGES);",
            "\t\tatomic_pool_size = max_t(size_t, pages << PAGE_SHIFT, SZ_128K);",
            "\t}",
            "\tINIT_WORK(&atomic_pool_work, atomic_pool_work_fn);",
            "",
            "\tatomic_pool_kernel = __dma_atomic_pool_init(atomic_pool_size,",
            "\t\t\t\t\t\t    GFP_KERNEL);",
            "\tif (!atomic_pool_kernel)",
            "\t\tret = -ENOMEM;",
            "\tif (has_managed_dma()) {",
            "\t\tatomic_pool_dma = __dma_atomic_pool_init(atomic_pool_size,",
            "\t\t\t\t\t\tGFP_KERNEL | GFP_DMA);",
            "\t\tif (!atomic_pool_dma)",
            "\t\t\tret = -ENOMEM;",
            "\t}",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA32)) {",
            "\t\tatomic_pool_dma32 = __dma_atomic_pool_init(atomic_pool_size,",
            "\t\t\t\t\t\tGFP_KERNEL | GFP_DMA32);",
            "\t\tif (!atomic_pool_dma32)",
            "\t\t\tret = -ENOMEM;",
            "\t}",
            "",
            "\tdma_atomic_pool_debugfs_init();",
            "\treturn ret;",
            "}",
            "bool dma_free_from_pool(struct device *dev, void *start, size_t size)",
            "{",
            "\tstruct gen_pool *pool = NULL;",
            "",
            "\twhile ((pool = dma_guess_pool(pool, 0))) {",
            "\t\tif (!gen_pool_has_addr(pool, (unsigned long)start, size))",
            "\t\t\tcontinue;",
            "\t\tgen_pool_free(pool, (unsigned long)start, size);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "atomic_pool_resize, atomic_pool_work_fn, dma_atomic_pool_init, dma_free_from_pool",
          "description": "实现内存池的初始化与维护机制，包含池大小自动调节逻辑、后台扩展任务调度、默认尺寸计算及内存释放查找功能，提供设备内存池的统一管理接口。",
          "similarity": 0.3761932849884033
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/dma/pool.c",
          "start_line": 1,
          "end_line": 28,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 2012 ARM Ltd.",
            " * Copyright (C) 2020 Google LLC",
            " */",
            "#include <linux/cma.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/dma-map-ops.h>",
            "#include <linux/dma-direct.h>",
            "#include <linux/init.h>",
            "#include <linux/genalloc.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "",
            "static struct gen_pool *atomic_pool_dma __ro_after_init;",
            "static unsigned long pool_size_dma;",
            "static struct gen_pool *atomic_pool_dma32 __ro_after_init;",
            "static unsigned long pool_size_dma32;",
            "static struct gen_pool *atomic_pool_kernel __ro_after_init;",
            "static unsigned long pool_size_kernel;",
            "",
            "/* Size can be defined by the coherent_pool command line */",
            "static size_t atomic_pool_size;",
            "",
            "/* Dynamic background expansion when the atomic pool is near capacity */",
            "static struct work_struct atomic_pool_work;",
            ""
          ],
          "function_name": null,
          "description": "定义并初始化用于管理DMA内存池的全局变量，包括针对不同架构（DMA/DMA32/内核）的通用池指针、尺寸参数及动态扩展的工作队列。",
          "similarity": 0.36202192306518555
        }
      ]
    }
  ]
}