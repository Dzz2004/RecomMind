{
  "query": "容器技术在微内核架构中的应用",
  "timestamp": "2025-12-26 01:52:39",
  "retrieved_files": [
    {
      "source_file": "mm/memblock.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:38:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memblock.c`\n\n---\n\n# memblock.c 技术文档\n\n## 1. 文件概述\n\n`memblock.c` 实现了 Linux 内核早期启动阶段的内存管理机制——**memblock**。该机制用于在常规内存分配器（如 buddy allocator）尚未初始化之前，对物理内存进行粗粒度的区域管理。它将系统内存抽象为若干连续的内存区域（regions），支持“可用内存”（memory）、“保留内存”（reserved）和“物理内存”（physmem，部分架构支持）三种类型，为内核早期初始化提供内存添加、查询和分配能力。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct memblock_region`：表示一个连续的物理内存区域，包含基地址（base）、大小（size）、NUMA 节点 ID 和属性标志。\n- `struct memblock_type`：管理一类内存区域的集合，包含区域数组、当前数量（cnt）、最大容量（max）和名称。\n- `struct memblock`：全局 memblock 管理结构，包含 `memory` 和 `reserved` 两种类型的 `memblock_type`，以及分配方向（bottom_up）和当前分配上限（current_limit）。\n- `physmem`（条件编译）：描述不受 `mem=` 参数限制的实际物理内存布局。\n\n### 主要函数与变量\n- `memblock_add()` / `memblock_add_node()`：向 memblock 添加可用内存区域。\n- `memblock_reserve()`：标记内存区域为保留（不可用于动态分配）。\n- `memblock_phys_alloc*()` / `memblock_alloc*()`：分配物理或虚拟地址的内存。\n- `memblock_overlaps_region()`：判断指定区域是否与某类 memblock 区域重叠。\n- `__memblock_find_range_bottom_up()`：从低地址向高地址查找满足条件的空闲内存范围。\n- 全局变量 `memblock`：静态初始化的主 memblock 结构体。\n- `max_low_pfn`, `min_low_pfn`, `max_pfn`, `max_possible_pfn`：记录 PFN（页帧号）边界信息。\n\n### 配置宏\n- `INIT_MEMBLOCK_REGIONS`：初始内存/保留区域数组大小（默认 128）。\n- `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 类型支持。\n- `CONFIG_MEMBLOCK_KHO_SCRATCH`：支持仅从特定标记（KHO_SCRATCH）区域分配内存。\n- `CONFIG_ARCH_KEEP_MEMBLOCK`：决定是否在初始化完成后保留 memblock 数据结构。\n\n## 3. 关键实现\n\n### 初始化与存储\n- `memblock` 结构体在编译时静态初始化，其 `memory` 和 `reserved` 的区域数组分别使用 `memblock_memory_init_regions` 和 `memblock_reserved_init_regions`，初始容量由 `INIT_MEMBLOCK_*_REGIONS` 定义。\n- 每个 `memblock_type` 的 `cnt` 初始设为 1，但实际第一个条目为空的占位符，有效区域从索引 1 开始（后续代码处理）。\n- 支持通过 `memblock_allow_resize()` 动态扩容区域数组，但需谨慎避免与 initrd 等关键区域冲突。\n\n### 内存区域管理\n- 使用 `for_each_memblock_type` 宏遍历指定类型的区域。\n- `memblock_addrs_overlap()` 通过比较区间端点判断两个物理内存区域是否重叠。\n- `memblock_overlaps_region()` 封装了对某类所有区域的重叠检测。\n\n### 分配策略\n- 默认采用 **top-down**（从高地址向低地址）分配策略，可通过 `memblock_set_bottom_up(true)` 切换为 **bottom-up**。\n- 分配时受 `current_limit` 限制（默认 `MEMBLOCK_ALLOC_ANYWHERE` 表示无限制）。\n- 支持基于 NUMA 节点、对齐要求、内存属性（如 `MEMBLOCK_MIRROR`、`MEMBLOCK_KHO_SCRATCH`）的精细控制。\n- `choose_memblock_flags()` 根据 `kho_scratch_only` 和镜像内存存在性动态选择分配标志。\n\n### 安全与调试\n- `memblock_cap_size()` 防止地址计算溢出（确保 `base + size <= PHYS_ADDR_MAX`）。\n- 条件编译的 `memblock_dbg()` 宏用于调试输出（需开启 `memblock_debug`）。\n- 使用 `__initdata_memblock` 属性标记仅在初始化阶段使用的数据，便于后续释放。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memblock.h>`：定义 memblock API 和数据结构。\n  - `<linux/kernel.h>`, `<linux/init.h>`：提供基础内核功能和初始化宏。\n  - `<linux/pfn.h>`：PFN 相关操作。\n  - `<asm/sections.h>`：访问内核链接段信息。\n  - 架构相关头文件（如 `internal.h`）。\n- **配置依赖**：\n  - `CONFIG_NUMA`：影响 `contig_page_data` 的定义。\n  - `CONFIG_KEXEC_HANDOVER`：引入 kexec 相关头文件。\n  - `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 支持。\n- **后续移交**：在 `mem_init()` 中，memblock 管理的内存会被释放给 buddy allocator，完成内存管理权移交。\n\n## 5. 使用场景\n\n- **内核早期初始化**：在 `start_kernel()` 初期，架构代码（如 `setup_arch()`）调用 `memblock_add()` 注册可用物理内存，调用 `memblock_reserve()` 保留内核镜像、设备树、initrd 等关键区域。\n- **早期内存分配**：在 slab/buddy 分配器就绪前，使用 `memblock_alloc()` 分配大块连续内存（如页表、中断向量表、ACPI 表解析缓冲区）。\n- **内存布局查询**：通过 `for_each_memblock()` 等宏遍历内存区域，用于构建 e820 表、EFI 内存映射或 NUMA 拓扑。\n- **特殊分配需求**：支持从镜像内存（`MEMBLOCK_MIRROR`）或 KHO scratch 区域分配，满足安全启动或崩溃转储等场景。\n- **调试与分析**：通过 debugfs 接口（未在片段中体现）导出 memblock 布局，辅助内存问题诊断。",
      "similarity": 0.5515042543411255,
      "chunks": [
        {
          "chunk_id": 10,
          "file_path": "mm/memblock.c",
          "start_line": 1954,
          "end_line": 2057,
          "content": [
            "void __init memblock_mem_limit_remove_map(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr;",
            "",
            "\tif (!limit)",
            "\t\treturn;",
            "",
            "\tmax_addr = __find_max_addr(limit);",
            "",
            "\t/* @limit exceeds the total size of the memory, do nothing */",
            "\tif (max_addr == PHYS_ADDR_MAX)",
            "\t\treturn;",
            "",
            "\tmemblock_cap_memory_range(0, max_addr);",
            "}",
            "static int __init_memblock memblock_search(struct memblock_type *type, phys_addr_t addr)",
            "{",
            "\tunsigned int left = 0, right = type->cnt;",
            "",
            "\tdo {",
            "\t\tunsigned int mid = (right + left) / 2;",
            "",
            "\t\tif (addr < type->regions[mid].base)",
            "\t\t\tright = mid;",
            "\t\telse if (addr >= (type->regions[mid].base +",
            "\t\t\t\t  type->regions[mid].size))",
            "\t\t\tleft = mid + 1;",
            "\t\telse",
            "\t\t\treturn mid;",
            "\t} while (left < right);",
            "\treturn -1;",
            "}",
            "bool __init_memblock memblock_is_reserved(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.reserved, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_memory(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.memory, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_map_memory(phys_addr_t addr)",
            "{",
            "\tint i = memblock_search(&memblock.memory, addr);",
            "",
            "\tif (i == -1)",
            "\t\treturn false;",
            "\treturn !memblock_is_nomap(&memblock.memory.regions[i]);",
            "}",
            "int __init_memblock memblock_search_pfn_nid(unsigned long pfn,",
            "\t\t\t unsigned long *start_pfn, unsigned long *end_pfn)",
            "{",
            "\tstruct memblock_type *type = &memblock.memory;",
            "\tint mid = memblock_search(type, PFN_PHYS(pfn));",
            "",
            "\tif (mid == -1)",
            "\t\treturn -1;",
            "",
            "\t*start_pfn = PFN_DOWN(type->regions[mid].base);",
            "\t*end_pfn = PFN_DOWN(type->regions[mid].base + type->regions[mid].size);",
            "",
            "\treturn memblock_get_region_node(&type->regions[mid]);",
            "}",
            "bool __init_memblock memblock_is_region_memory(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tint idx = memblock_search(&memblock.memory, base);",
            "\tphys_addr_t end = base + memblock_cap_size(base, &size);",
            "",
            "\tif (idx == -1)",
            "\t\treturn false;",
            "\treturn (memblock.memory.regions[idx].base +",
            "\t\t memblock.memory.regions[idx].size) >= end;",
            "}",
            "bool __init_memblock memblock_is_region_reserved(phys_addr_t base, phys_addr_t size)",
            "{",
            "\treturn memblock_overlaps_region(&memblock.reserved, base, size);",
            "}",
            "void __init_memblock memblock_trim_memory(phys_addr_t align)",
            "{",
            "\tphys_addr_t start, end, orig_start, orig_end;",
            "\tstruct memblock_region *r;",
            "",
            "\tfor_each_mem_region(r) {",
            "\t\torig_start = r->base;",
            "\t\torig_end = r->base + r->size;",
            "\t\tstart = round_up(orig_start, align);",
            "\t\tend = round_down(orig_end, align);",
            "",
            "\t\tif (start == orig_start && end == orig_end)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (start < end) {",
            "\t\t\tr->base = start;",
            "\t\t\tr->size = end - start;",
            "\t\t} else {",
            "\t\t\tmemblock_remove_region(&memblock.memory,",
            "\t\t\t\t\t       r - memblock.memory.regions);",
            "\t\t\tr--;",
            "\t\t}",
            "\t}",
            "}",
            "void __init_memblock memblock_set_current_limit(phys_addr_t limit)",
            "{",
            "\tmemblock.current_limit = limit;",
            "}"
          ],
          "function_name": "memblock_mem_limit_remove_map, memblock_search, memblock_is_reserved, memblock_is_memory, memblock_is_map_memory, memblock_search_pfn_nid, memblock_is_region_memory, memblock_is_region_reserved, memblock_trim_memory, memblock_set_current_limit",
          "description": "实现内存块限制移除、搜索和区域判断逻辑，用于管理内存和保留区域的地址范围查询及修剪操作",
          "similarity": 0.5401743650436401
        },
        {
          "chunk_id": 1,
          "file_path": "mm/memblock.c",
          "start_line": 192,
          "end_line": 297,
          "content": [
            "static inline phys_addr_t memblock_cap_size(phys_addr_t base, phys_addr_t *size)",
            "{",
            "\treturn *size = min(*size, PHYS_ADDR_MAX - base);",
            "}",
            "unsigned long __init_memblock",
            "memblock_addrs_overlap(phys_addr_t base1, phys_addr_t size1, phys_addr_t base2,",
            "\t\t       phys_addr_t size2)",
            "{",
            "\treturn ((base1 < (base2 + size2)) && (base2 < (base1 + size1)));",
            "}",
            "bool __init_memblock memblock_overlaps_region(struct memblock_type *type,",
            "\t\t\t\t\tphys_addr_t base, phys_addr_t size)",
            "{",
            "\tunsigned long i;",
            "",
            "\tmemblock_cap_size(base, &size);",
            "",
            "\tfor (i = 0; i < type->cnt; i++)",
            "\t\tif (memblock_addrs_overlap(base, size, type->regions[i].base,",
            "\t\t\t\t\t   type->regions[i].size))",
            "\t\t\tbreak;",
            "\treturn i < type->cnt;",
            "}",
            "static phys_addr_t __init_memblock",
            "__memblock_find_range_bottom_up(phys_addr_t start, phys_addr_t end,",
            "\t\t\t\tphys_addr_t size, phys_addr_t align, int nid,",
            "\t\t\t\tenum memblock_flags flags)",
            "{",
            "\tphys_addr_t this_start, this_end, cand;",
            "\tu64 i;",
            "",
            "\tfor_each_free_mem_range(i, nid, flags, &this_start, &this_end, NULL) {",
            "\t\tthis_start = clamp(this_start, start, end);",
            "\t\tthis_end = clamp(this_end, start, end);",
            "",
            "\t\tcand = round_up(this_start, align);",
            "\t\tif (cand < this_end && this_end - cand >= size)",
            "\t\t\treturn cand;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static phys_addr_t __init_memblock",
            "__memblock_find_range_top_down(phys_addr_t start, phys_addr_t end,",
            "\t\t\t       phys_addr_t size, phys_addr_t align, int nid,",
            "\t\t\t       enum memblock_flags flags)",
            "{",
            "\tphys_addr_t this_start, this_end, cand;",
            "\tu64 i;",
            "",
            "\tfor_each_free_mem_range_reverse(i, nid, flags, &this_start, &this_end,",
            "\t\t\t\t\tNULL) {",
            "\t\tthis_start = clamp(this_start, start, end);",
            "\t\tthis_end = clamp(this_end, start, end);",
            "",
            "\t\tif (this_end < size)",
            "\t\t\tcontinue;",
            "",
            "\t\tcand = round_down(this_end - size, align);",
            "\t\tif (cand >= this_start)",
            "\t\t\treturn cand;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static phys_addr_t __init_memblock memblock_find_in_range_node(phys_addr_t size,",
            "\t\t\t\t\tphys_addr_t align, phys_addr_t start,",
            "\t\t\t\t\tphys_addr_t end, int nid,",
            "\t\t\t\t\tenum memblock_flags flags)",
            "{",
            "\t/* pump up @end */",
            "\tif (end == MEMBLOCK_ALLOC_ACCESSIBLE ||",
            "\t    end == MEMBLOCK_ALLOC_NOLEAKTRACE)",
            "\t\tend = memblock.current_limit;",
            "",
            "\t/* avoid allocating the first page */",
            "\tstart = max_t(phys_addr_t, start, PAGE_SIZE);",
            "\tend = max(start, end);",
            "",
            "\tif (memblock_bottom_up())",
            "\t\treturn __memblock_find_range_bottom_up(start, end, size, align,",
            "\t\t\t\t\t\t       nid, flags);",
            "\telse",
            "\t\treturn __memblock_find_range_top_down(start, end, size, align,",
            "\t\t\t\t\t\t      nid, flags);",
            "}",
            "static phys_addr_t __init_memblock memblock_find_in_range(phys_addr_t start,",
            "\t\t\t\t\tphys_addr_t end, phys_addr_t size,",
            "\t\t\t\t\tphys_addr_t align)",
            "{",
            "\tphys_addr_t ret;",
            "\tenum memblock_flags flags = choose_memblock_flags();",
            "",
            "again:",
            "\tret = memblock_find_in_range_node(size, align, start, end,",
            "\t\t\t\t\t    NUMA_NO_NODE, flags);",
            "",
            "\tif (!ret && (flags & MEMBLOCK_MIRROR)) {",
            "\t\tpr_warn_ratelimited(\"Could not allocate %pap bytes of mirrored memory\\n\",",
            "\t\t\t&size);",
            "\t\tflags &= ~MEMBLOCK_MIRROR;",
            "\t\tgoto again;",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "memblock_cap_size, memblock_addrs_overlap, memblock_overlaps_region, __memblock_find_range_bottom_up, __memblock_find_range_top_down, memblock_find_in_range_node, memblock_find_in_range",
          "description": "实现内存区域地址重叠检测与分配策略选择逻辑，包含范围查找算法（底向顶/顶向底）及镜像内存分配失败回退机制。",
          "similarity": 0.5400821566581726
        },
        {
          "chunk_id": 4,
          "file_path": "mm/memblock.c",
          "start_line": 730,
          "end_line": 842,
          "content": [
            "int __init_memblock memblock_add_node(phys_addr_t base, phys_addr_t size,",
            "\t\t\t\t      int nid, enum memblock_flags flags)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] nid=%d flags=%x %pS\\n\", __func__,",
            "\t\t     &base, &end, nid, flags, (void *)_RET_IP_);",
            "",
            "\treturn memblock_add_range(&memblock.memory, base, size, nid, flags);",
            "}",
            "int __init_memblock memblock_add(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\", __func__,",
            "\t\t     &base, &end, (void *)_RET_IP_);",
            "",
            "\treturn memblock_add_range(&memblock.memory, base, size, MAX_NUMNODES, 0);",
            "}",
            "bool __init_memblock memblock_validate_numa_coverage(unsigned long threshold_bytes)",
            "{",
            "\tunsigned long nr_pages = 0;",
            "\tunsigned long start_pfn, end_pfn, mem_size_mb;",
            "\tint nid, i;",
            "",
            "\t/* calculate lose page */",
            "\tfor_each_mem_pfn_range(i, MAX_NUMNODES, &start_pfn, &end_pfn, &nid) {",
            "\t\tif (!numa_valid_node(nid))",
            "\t\t\tnr_pages += end_pfn - start_pfn;",
            "\t}",
            "",
            "\tif ((nr_pages << PAGE_SHIFT) > threshold_bytes) {",
            "\t\tmem_size_mb = memblock_phys_mem_size() >> 20;",
            "\t\tpr_err(\"NUMA: no nodes coverage for %luMB of %luMB RAM\\n\",",
            "\t\t       (nr_pages << PAGE_SHIFT) >> 20, mem_size_mb);",
            "\t\treturn false;",
            "\t}",
            "",
            "\treturn true;",
            "}",
            "static int __init_memblock memblock_isolate_range(struct memblock_type *type,",
            "\t\t\t\t\tphys_addr_t base, phys_addr_t size,",
            "\t\t\t\t\tint *start_rgn, int *end_rgn)",
            "{",
            "\tphys_addr_t end = base + memblock_cap_size(base, &size);",
            "\tint idx;",
            "\tstruct memblock_region *rgn;",
            "",
            "\t*start_rgn = *end_rgn = 0;",
            "",
            "\tif (!size)",
            "\t\treturn 0;",
            "",
            "\t/* we'll create at most two more regions */",
            "\twhile (type->cnt + 2 > type->max)",
            "\t\tif (memblock_double_array(type, base, size) < 0)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\tfor_each_memblock_type(idx, type, rgn) {",
            "\t\tphys_addr_t rbase = rgn->base;",
            "\t\tphys_addr_t rend = rbase + rgn->size;",
            "",
            "\t\tif (rbase >= end)",
            "\t\t\tbreak;",
            "\t\tif (rend <= base)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (rbase < base) {",
            "\t\t\t/*",
            "\t\t\t * @rgn intersects from below.  Split and continue",
            "\t\t\t * to process the next region - the new top half.",
            "\t\t\t */",
            "\t\t\trgn->base = base;",
            "\t\t\trgn->size -= base - rbase;",
            "\t\t\ttype->total_size -= base - rbase;",
            "\t\t\tmemblock_insert_region(type, idx, rbase, base - rbase,",
            "\t\t\t\t\t       memblock_get_region_node(rgn),",
            "\t\t\t\t\t       rgn->flags);",
            "\t\t} else if (rend > end) {",
            "\t\t\t/*",
            "\t\t\t * @rgn intersects from above.  Split and redo the",
            "\t\t\t * current region - the new bottom half.",
            "\t\t\t */",
            "\t\t\trgn->base = end;",
            "\t\t\trgn->size -= end - rbase;",
            "\t\t\ttype->total_size -= end - rbase;",
            "\t\t\tmemblock_insert_region(type, idx--, rbase, end - rbase,",
            "\t\t\t\t\t       memblock_get_region_node(rgn),",
            "\t\t\t\t\t       rgn->flags);",
            "\t\t} else {",
            "\t\t\t/* @rgn is fully contained, record it */",
            "\t\t\tif (!*end_rgn)",
            "\t\t\t\t*start_rgn = idx;",
            "\t\t\t*end_rgn = idx + 1;",
            "\t\t}",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int __init_memblock memblock_remove_range(struct memblock_type *type,",
            "\t\t\t\t\t  phys_addr_t base, phys_addr_t size)",
            "{",
            "\tint start_rgn, end_rgn;",
            "\tint i, ret;",
            "",
            "\tret = memblock_isolate_range(type, base, size, &start_rgn, &end_rgn);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tfor (i = end_rgn - 1; i >= start_rgn; i--)",
            "\t\tmemblock_remove_region(type, i);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "memblock_add_node, memblock_add, memblock_validate_numa_coverage, memblock_isolate_range, memblock_remove_range",
          "description": "实现节点内存添加（add_node/add）、NUMA覆盖率校验（validate_numa_coverage）及内存范围隔离（isolate_range/remove_range）功能。",
          "similarity": 0.5371363162994385
        },
        {
          "chunk_id": 12,
          "file_path": "mm/memblock.c",
          "start_line": 2233,
          "end_line": 2340,
          "content": [
            "static void __init __free_pages_memory(unsigned long start, unsigned long end)",
            "{",
            "\tint order;",
            "",
            "\twhile (start < end) {",
            "\t\t/*",
            "\t\t * Free the pages in the largest chunks alignment allows.",
            "\t\t *",
            "\t\t * __ffs() behaviour is undefined for 0. start == 0 is",
            "\t\t * MAX_PAGE_ORDER-aligned, set order to MAX_PAGE_ORDER for",
            "\t\t * the case.",
            "\t\t */",
            "\t\tif (start)",
            "\t\t\torder = min_t(int, MAX_PAGE_ORDER, __ffs(start));",
            "\t\telse",
            "\t\t\torder = MAX_PAGE_ORDER;",
            "",
            "\t\twhile (start + (1UL << order) > end)",
            "\t\t\torder--;",
            "",
            "\t\tmemblock_free_pages(pfn_to_page(start), start, order);",
            "",
            "\t\tstart += (1UL << order);",
            "\t}",
            "}",
            "static unsigned long __init __free_memory_core(phys_addr_t start,",
            "\t\t\t\t phys_addr_t end)",
            "{",
            "\tunsigned long start_pfn = PFN_UP(start);",
            "\tunsigned long end_pfn = min_t(unsigned long,",
            "\t\t\t\t      PFN_DOWN(end), max_low_pfn);",
            "",
            "\tif (start_pfn >= end_pfn)",
            "\t\treturn 0;",
            "",
            "\t__free_pages_memory(start_pfn, end_pfn);",
            "",
            "\treturn end_pfn - start_pfn;",
            "}",
            "static void __init memmap_init_reserved_pages(void)",
            "{",
            "\tstruct memblock_region *region;",
            "\tphys_addr_t start, end;",
            "\tint nid;",
            "\tunsigned long max_reserved;",
            "",
            "\t/*",
            "\t * set nid on all reserved pages and also treat struct",
            "\t * pages for the NOMAP regions as PageReserved",
            "\t */",
            "repeat:",
            "\tmax_reserved = memblock.reserved.max;",
            "\tfor_each_mem_region(region) {",
            "\t\tnid = memblock_get_region_node(region);",
            "\t\tstart = region->base;",
            "\t\tend = start + region->size;",
            "",
            "\t\tif (memblock_is_nomap(region))",
            "\t\t\treserve_bootmem_region(start, end, nid);",
            "",
            "\t\tmemblock_set_node(start, region->size, &memblock.reserved, nid);",
            "\t}",
            "\t/*",
            "\t * 'max' is changed means memblock.reserved has been doubled its",
            "\t * array, which may result a new reserved region before current",
            "\t * 'start'. Now we should repeat the procedure to set its node id.",
            "\t */",
            "\tif (max_reserved != memblock.reserved.max)",
            "\t\tgoto repeat;",
            "",
            "\t/*",
            "\t * initialize struct pages for reserved regions that don't have",
            "\t * the MEMBLOCK_RSRV_NOINIT flag set",
            "\t */",
            "\tfor_each_reserved_mem_region(region) {",
            "\t\tif (!memblock_is_reserved_noinit(region)) {",
            "\t\t\tnid = memblock_get_region_node(region);",
            "\t\t\tstart = region->base;",
            "\t\t\tend = start + region->size;",
            "",
            "\t\t\tif (!numa_valid_node(nid))",
            "\t\t\t\tnid = early_pfn_to_nid(PFN_DOWN(start));",
            "",
            "\t\t\treserve_bootmem_region(start, end, nid);",
            "\t\t}",
            "\t}",
            "}",
            "static unsigned long __init free_low_memory_core_early(void)",
            "{",
            "\tunsigned long count = 0;",
            "\tphys_addr_t start, end;",
            "\tu64 i;",
            "",
            "\tmemblock_clear_hotplug(0, -1);",
            "",
            "\tmemmap_init_reserved_pages();",
            "",
            "\t/*",
            "\t * We need to use NUMA_NO_NODE instead of NODE_DATA(0)->node_id",
            "\t *  because in some case like Node0 doesn't have RAM installed",
            "\t *  low ram will be on Node1",
            "\t */",
            "\tfor_each_free_mem_range(i, NUMA_NO_NODE, MEMBLOCK_NONE, &start, &end,",
            "\t\t\t\tNULL)",
            "\t\tcount += __free_memory_core(start, end);",
            "",
            "\treturn count;",
            "}"
          ],
          "function_name": "__free_pages_memory, __free_memory_core, memmap_init_reserved_pages, free_low_memory_core_early",
          "description": "核心实现内存页面释放逻辑，初始化保留区域页结构并处理低内存核心区域的提前释放操作",
          "similarity": 0.5370004177093506
        },
        {
          "chunk_id": 11,
          "file_path": "mm/memblock.c",
          "start_line": 2094,
          "end_line": 2203,
          "content": [
            "static void __init_memblock memblock_dump(struct memblock_type *type)",
            "{",
            "\tphys_addr_t base, end, size;",
            "\tenum memblock_flags flags;",
            "\tint idx;",
            "\tstruct memblock_region *rgn;",
            "",
            "\tpr_info(\" %s.cnt  = 0x%lx\\n\", type->name, type->cnt);",
            "",
            "\tfor_each_memblock_type(idx, type, rgn) {",
            "\t\tchar nid_buf[32] = \"\";",
            "",
            "\t\tbase = rgn->base;",
            "\t\tsize = rgn->size;",
            "\t\tend = base + size - 1;",
            "\t\tflags = rgn->flags;",
            "#ifdef CONFIG_NUMA",
            "\t\tif (numa_valid_node(memblock_get_region_node(rgn)))",
            "\t\t\tsnprintf(nid_buf, sizeof(nid_buf), \" on node %d\",",
            "\t\t\t\t memblock_get_region_node(rgn));",
            "#endif",
            "\t\tpr_info(\" %s[%#x]\\t[%pa-%pa], %pa bytes%s flags: %#x\\n\",",
            "\t\t\ttype->name, idx, &base, &end, &size, nid_buf, flags);",
            "\t}",
            "}",
            "void __init memblock_allow_resize(void)",
            "{",
            "\tmemblock_can_resize = 1;",
            "}",
            "static int __init early_memblock(char *p)",
            "{",
            "\tif (p && strstr(p, \"debug\"))",
            "\t\tmemblock_debug = 1;",
            "\treturn 0;",
            "}",
            "static void __init free_memmap(unsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tstruct page *start_pg, *end_pg;",
            "\tphys_addr_t pg, pgend;",
            "",
            "\t/*",
            "\t * Convert start_pfn/end_pfn to a struct page pointer.",
            "\t */",
            "\tstart_pg = pfn_to_page(start_pfn - 1) + 1;",
            "\tend_pg = pfn_to_page(end_pfn - 1) + 1;",
            "",
            "\t/*",
            "\t * Convert to physical addresses, and round start upwards and end",
            "\t * downwards.",
            "\t */",
            "\tpg = PAGE_ALIGN(__pa(start_pg));",
            "\tpgend = __pa(end_pg) & PAGE_MASK;",
            "",
            "\t/*",
            "\t * If there are free pages between these, free the section of the",
            "\t * memmap array.",
            "\t */",
            "\tif (pg < pgend)",
            "\t\tmemblock_phys_free(pg, pgend - pg);",
            "}",
            "static void __init free_unused_memmap(void)",
            "{",
            "\tunsigned long start, end, prev_end = 0;",
            "\tint i;",
            "",
            "\tif (!IS_ENABLED(CONFIG_HAVE_ARCH_PFN_VALID) ||",
            "\t    IS_ENABLED(CONFIG_SPARSEMEM_VMEMMAP))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * This relies on each bank being in address order.",
            "\t * The banks are sorted previously in bootmem_init().",
            "\t */",
            "\tfor_each_mem_pfn_range(i, MAX_NUMNODES, &start, &end, NULL) {",
            "#ifdef CONFIG_SPARSEMEM",
            "\t\t/*",
            "\t\t * Take care not to free memmap entries that don't exist",
            "\t\t * due to SPARSEMEM sections which aren't present.",
            "\t\t */",
            "\t\tstart = min(start, ALIGN(prev_end, PAGES_PER_SECTION));",
            "#endif",
            "\t\t/*",
            "\t\t * Align down here since many operations in VM subsystem",
            "\t\t * presume that there are no holes in the memory map inside",
            "\t\t * a pageblock",
            "\t\t */",
            "\t\tstart = pageblock_start_pfn(start);",
            "",
            "\t\t/*",
            "\t\t * If we had a previous bank, and there is a space",
            "\t\t * between the current bank and the previous, free it.",
            "\t\t */",
            "\t\tif (prev_end && prev_end < start)",
            "\t\t\tfree_memmap(prev_end, start);",
            "",
            "\t\t/*",
            "\t\t * Align up here since many operations in VM subsystem",
            "\t\t * presume that there are no holes in the memory map inside",
            "\t\t * a pageblock",
            "\t\t */",
            "\t\tprev_end = pageblock_align(end);",
            "\t}",
            "",
            "#ifdef CONFIG_SPARSEMEM",
            "\tif (!IS_ALIGNED(prev_end, PAGES_PER_SECTION)) {",
            "\t\tprev_end = pageblock_align(end);",
            "\t\tfree_memmap(prev_end, ALIGN(prev_end, PAGES_PER_SECTION));",
            "\t}",
            "#endif",
            "}"
          ],
          "function_name": "memblock_dump, memblock_allow_resize, early_memblock, free_memmap, free_unused_memmap",
          "description": "提供内存块状态调试、调整支持、早期内存处理及未使用memmap释放功能，用于优化内存映射管理",
          "similarity": 0.5366609692573547
        }
      ]
    },
    {
      "source_file": "mm/mempool.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:44:48\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `mempool.c`\n\n---\n\n# mempool.c 技术文档\n\n## 1. 文件概述\n\n`mempool.c` 实现了 Linux 内核中的内存池（memory pool）机制，用于在极端虚拟内存（VM）压力下提供**有保证的、无死锁风险的内存分配能力**。内存池预先分配一定数量的内存元素，在常规分配器（如 slab 或页分配器）因内存紧张而无法满足分配请求时，可从池中直接获取预分配的内存，从而避免系统关键路径因内存不足而阻塞或失败。\n\n该机制特别适用于中断上下文、持有自旋锁或处于不可睡眠状态等不能容忍分配失败的场景。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `mempool_t`：内存池核心结构体，包含：\n  - `min_nr`：池中保证保留的最小元素数量\n  - `curr_nr`：当前池中实际元素数量\n  - `elements`：指向预分配元素指针数组的指针\n  - `alloc/free`：用户自定义的分配/释放函数指针\n  - `pool_data`：传递给分配/释放函数的私有数据\n  - `lock`：保护池操作的自旋锁\n  - `wait`：等待队列（用于阻塞式分配）\n\n### 主要函数\n| 函数 | 功能 |\n|------|------|\n| `mempool_init_node()` | 在指定 NUMA 节点上初始化一个已分配的内存池 |\n| `mempool_init_noprof()` | 使用默认参数（GFP_KERNEL, 任意节点）初始化内存池 |\n| `mempool_create_node_noprof()` | 创建并初始化一个新的内存池对象 |\n| `mempool_destroy()` | 销毁内存池，释放所有元素和池结构本身 |\n| `mempool_exit()` | 清理内存池内容（不释放池结构本身） |\n| `add_element()` / `remove_element()` | 向池中添加/从池中移除元素（内部使用） |\n\n### 辅助调试函数（仅当 `CONFIG_SLUB_DEBUG_ON` 启用时）\n- `check_element()`：验证从池中取出的元素未被意外修改（通过毒化字节检查）\n- `poison_element()`：在元素归还池前写入毒化模式（POISON_FREE/POISON_END）\n- `kasan_poison_element()` / `kasan_unpoison_element()`：与 KASAN 集成，标记内存使用状态\n\n## 3. 关键实现\n\n### 内存池初始化流程\n1. 分配 `mempool_t` 结构体（`mempool_create_node_noprof`）或使用已有结构体（`mempool_init_node`）\n2. 分配 `elements` 指针数组（大小为 `min_nr * sizeof(void*)`）\n3. **预分配 `min_nr` 个元素**：循环调用用户提供的 `alloc_fn`，将成功分配的元素通过 `add_element()` 加入池中\n4. 若预分配失败，调用 `mempool_exit()` 回滚已分配资源\n\n### 元素管理机制\n- **添加元素** (`add_element`)：\n  - 检查池未满（`BUG_ON`）\n  - 对元素进行**毒化**（debug 模式）和 **KASAN poison**（标记为未使用）\n  - 存入 `elements[]` 数组\n- **移除元素** (`remove_element`)：\n  - 从数组末尾弹出元素\n  - 执行 **KASAN unpoison**（标记为使用中）\n  - **毒化检查**（debug 模式）：验证元素未被意外修改\n\n### 调试支持\n- **毒化机制**：使用 `POISON_FREE`（0x6b）填充元素内容，末尾字节设为 `POISON_END`（0xa5）\n- **错误检测**：若从池中取出的元素毒化字节被修改，打印详细错误信息及堆栈\n- **KASAN 集成**：根据分配器类型（slab/page）调用对应的 KASAN poison/unpoison 接口\n\n### 内存分配器适配\n支持三种内置分配器：\n- **Slab 分配器**：`mempool_alloc_slab` / `mempool_free_slab`\n- **通用 kmalloc**：`mempool_kmalloc` / `mempool_kfree`\n- **页分配器**：`mempool_alloc_pages` / `mempool_free_pages`（支持 order > 0）\n\n## 4. 依赖关系\n\n### 头文件依赖\n- `<linux/mm.h>`：内存管理基础接口\n- `<linux/slab.h>`：Slab 分配器接口\n- `<linux/highmem.h>`：高内存页映射（`kmap_atomic`）\n- `<linux/kasan.h>`：KASAN 内存错误检测\n- `<linux/kmemleak.h>`：内存泄漏检测\n- `<linux/mempool.h>`：内存池公共 API 定义\n- `\"slab.h\"`：Slab 内部头文件（获取 `kmem_cache_size`）\n\n### 功能依赖\n- **Slab 分配器**：用于基于 cache 的内存池\n- **页分配器**：用于大块连续物理内存分配\n- **KASAN**：运行时内存安全检测\n- **NUMA 支持**：通过 `kmalloc_node` 实现节点亲和性\n\n## 5. 使用场景\n\n### 典型应用场景\n1. **块设备 I/O 子系统**：\n   - 为 bio 结构体分配提供后备内存池\n   - 确保在内存压力下仍能完成关键 I/O 请求\n2. **网络子系统**：\n   - SKB（socket buffer）分配后备池\n   - 避免网络中断处理因内存不足而丢包\n3. **文件系统**：\n   - 关键元数据操作的内存保障（如 journal 提交）\n4. **内核关键路径**：\n   - 中断上下文、软中断、持有自旋锁时的内存分配\n   - 不能睡眠或不能失败的内存请求\n\n### 使用约束\n- **分配/释放函数限制**：\n  - `alloc_fn` 和 `free_fn` **可能睡眠**，因此 `mempool_alloc()` **不能在原子上下文调用**\n  - 但内存池的存在使得即使 `alloc_fn` 失败，仍可从池中获取内存（非原子上下文）\n- **性能考量**：\n  - 内存池占用常驻内存（`min_nr` 个元素）\n  - 仅应在**确实需要分配保证**的场景使用，避免过度预留内存",
      "similarity": 0.5336825847625732,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/mempool.c",
          "start_line": 156,
          "end_line": 271,
          "content": [
            "void mempool_exit(mempool_t *pool)",
            "{",
            "\twhile (pool->curr_nr) {",
            "\t\tvoid *element = remove_element(pool);",
            "\t\tpool->free(element, pool->pool_data);",
            "\t}",
            "\tkfree(pool->elements);",
            "\tpool->elements = NULL;",
            "}",
            "void mempool_destroy(mempool_t *pool)",
            "{",
            "\tif (unlikely(!pool))",
            "\t\treturn;",
            "",
            "\tmempool_exit(pool);",
            "\tkfree(pool);",
            "}",
            "int mempool_init_node(mempool_t *pool, int min_nr, mempool_alloc_t *alloc_fn,",
            "\t\t      mempool_free_t *free_fn, void *pool_data,",
            "\t\t      gfp_t gfp_mask, int node_id)",
            "{",
            "\tspin_lock_init(&pool->lock);",
            "\tpool->min_nr\t= min_nr;",
            "\tpool->pool_data = pool_data;",
            "\tpool->alloc\t= alloc_fn;",
            "\tpool->free\t= free_fn;",
            "\tinit_waitqueue_head(&pool->wait);",
            "",
            "\tpool->elements = kmalloc_array_node(min_nr, sizeof(void *),",
            "\t\t\t\t\t    gfp_mask, node_id);",
            "\tif (!pool->elements)",
            "\t\treturn -ENOMEM;",
            "",
            "\t/*",
            "\t * First pre-allocate the guaranteed number of buffers.",
            "\t */",
            "\twhile (pool->curr_nr < pool->min_nr) {",
            "\t\tvoid *element;",
            "",
            "\t\telement = pool->alloc(gfp_mask, pool->pool_data);",
            "\t\tif (unlikely(!element)) {",
            "\t\t\tmempool_exit(pool);",
            "\t\t\treturn -ENOMEM;",
            "\t\t}",
            "\t\tadd_element(pool, element);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int mempool_init_noprof(mempool_t *pool, int min_nr, mempool_alloc_t *alloc_fn,",
            "\t\t\tmempool_free_t *free_fn, void *pool_data)",
            "{",
            "\treturn mempool_init_node(pool, min_nr, alloc_fn, free_fn,",
            "\t\t\t\t pool_data, GFP_KERNEL, NUMA_NO_NODE);",
            "",
            "}",
            "int mempool_resize(mempool_t *pool, int new_min_nr)",
            "{",
            "\tvoid *element;",
            "\tvoid **new_elements;",
            "\tunsigned long flags;",
            "",
            "\tBUG_ON(new_min_nr <= 0);",
            "\tmight_sleep();",
            "",
            "\tspin_lock_irqsave(&pool->lock, flags);",
            "\tif (new_min_nr <= pool->min_nr) {",
            "\t\twhile (new_min_nr < pool->curr_nr) {",
            "\t\t\telement = remove_element(pool);",
            "\t\t\tspin_unlock_irqrestore(&pool->lock, flags);",
            "\t\t\tpool->free(element, pool->pool_data);",
            "\t\t\tspin_lock_irqsave(&pool->lock, flags);",
            "\t\t}",
            "\t\tpool->min_nr = new_min_nr;",
            "\t\tgoto out_unlock;",
            "\t}",
            "\tspin_unlock_irqrestore(&pool->lock, flags);",
            "",
            "\t/* Grow the pool */",
            "\tnew_elements = kmalloc_array(new_min_nr, sizeof(*new_elements),",
            "\t\t\t\t     GFP_KERNEL);",
            "\tif (!new_elements)",
            "\t\treturn -ENOMEM;",
            "",
            "\tspin_lock_irqsave(&pool->lock, flags);",
            "\tif (unlikely(new_min_nr <= pool->min_nr)) {",
            "\t\t/* Raced, other resize will do our work */",
            "\t\tspin_unlock_irqrestore(&pool->lock, flags);",
            "\t\tkfree(new_elements);",
            "\t\tgoto out;",
            "\t}",
            "\tmemcpy(new_elements, pool->elements,",
            "\t\t\tpool->curr_nr * sizeof(*new_elements));",
            "\tkfree(pool->elements);",
            "\tpool->elements = new_elements;",
            "\tpool->min_nr = new_min_nr;",
            "",
            "\twhile (pool->curr_nr < pool->min_nr) {",
            "\t\tspin_unlock_irqrestore(&pool->lock, flags);",
            "\t\telement = pool->alloc(GFP_KERNEL, pool->pool_data);",
            "\t\tif (!element)",
            "\t\t\tgoto out;",
            "\t\tspin_lock_irqsave(&pool->lock, flags);",
            "\t\tif (pool->curr_nr < pool->min_nr) {",
            "\t\t\tadd_element(pool, element);",
            "\t\t} else {",
            "\t\t\tspin_unlock_irqrestore(&pool->lock, flags);",
            "\t\t\tpool->free(element, pool->pool_data);\t/* Raced */",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t}",
            "out_unlock:",
            "\tspin_unlock_irqrestore(&pool->lock, flags);",
            "out:",
            "\treturn 0;",
            "}"
          ],
          "function_name": "mempool_exit, mempool_destroy, mempool_init_node, mempool_init_noprof, mempool_resize",
          "description": "提供内存池初始化、销毁及动态扩容接口，管理元素存储数组和最小容量控制",
          "similarity": 0.5863168239593506
        },
        {
          "chunk_id": 1,
          "file_path": "mm/mempool.c",
          "start_line": 24,
          "end_line": 124,
          "content": [
            "static void poison_error(mempool_t *pool, void *element, size_t size,",
            "\t\t\t size_t byte)",
            "{",
            "\tconst int nr = pool->curr_nr;",
            "\tconst int start = max_t(int, byte - (BITS_PER_LONG / 8), 0);",
            "\tconst int end = min_t(int, byte + (BITS_PER_LONG / 8), size);",
            "\tint i;",
            "",
            "\tpr_err(\"BUG: mempool element poison mismatch\\n\");",
            "\tpr_err(\"Mempool %p size %zu\\n\", pool, size);",
            "\tpr_err(\" nr=%d @ %p: %s0x\", nr, element, start > 0 ? \"... \" : \"\");",
            "\tfor (i = start; i < end; i++)",
            "\t\tpr_cont(\"%x \", *(u8 *)(element + i));",
            "\tpr_cont(\"%s\\n\", end < size ? \"...\" : \"\");",
            "\tdump_stack();",
            "}",
            "static void __check_element(mempool_t *pool, void *element, size_t size)",
            "{",
            "\tu8 *obj = element;",
            "\tsize_t i;",
            "",
            "\tfor (i = 0; i < size; i++) {",
            "\t\tu8 exp = (i < size - 1) ? POISON_FREE : POISON_END;",
            "",
            "\t\tif (obj[i] != exp) {",
            "\t\t\tpoison_error(pool, element, size, i);",
            "\t\t\treturn;",
            "\t\t}",
            "\t}",
            "\tmemset(obj, POISON_INUSE, size);",
            "}",
            "static void check_element(mempool_t *pool, void *element)",
            "{",
            "\t/* Mempools backed by slab allocator */",
            "\tif (pool->free == mempool_kfree) {",
            "\t\t__check_element(pool, element, (size_t)pool->pool_data);",
            "\t} else if (pool->free == mempool_free_slab) {",
            "\t\t__check_element(pool, element, kmem_cache_size(pool->pool_data));",
            "\t} else if (pool->free == mempool_free_pages) {",
            "\t\t/* Mempools backed by page allocator */",
            "\t\tint order = (int)(long)pool->pool_data;",
            "\t\tvoid *addr = kmap_atomic((struct page *)element);",
            "",
            "\t\t__check_element(pool, addr, 1UL << (PAGE_SHIFT + order));",
            "\t\tkunmap_atomic(addr);",
            "\t}",
            "}",
            "static void __poison_element(void *element, size_t size)",
            "{",
            "\tu8 *obj = element;",
            "",
            "\tmemset(obj, POISON_FREE, size - 1);",
            "\tobj[size - 1] = POISON_END;",
            "}",
            "static void poison_element(mempool_t *pool, void *element)",
            "{",
            "\t/* Mempools backed by slab allocator */",
            "\tif (pool->alloc == mempool_kmalloc) {",
            "\t\t__poison_element(element, (size_t)pool->pool_data);",
            "\t} else if (pool->alloc == mempool_alloc_slab) {",
            "\t\t__poison_element(element, kmem_cache_size(pool->pool_data));",
            "\t} else if (pool->alloc == mempool_alloc_pages) {",
            "\t\t/* Mempools backed by page allocator */",
            "\t\tint order = (int)(long)pool->pool_data;",
            "\t\tvoid *addr = kmap_atomic((struct page *)element);",
            "",
            "\t\t__poison_element(addr, 1UL << (PAGE_SHIFT + order));",
            "\t\tkunmap_atomic(addr);",
            "\t}",
            "}",
            "static inline void check_element(mempool_t *pool, void *element)",
            "{",
            "}",
            "static inline void poison_element(mempool_t *pool, void *element)",
            "{",
            "}",
            "static __always_inline void kasan_poison_element(mempool_t *pool, void *element)",
            "{",
            "\tif (pool->alloc == mempool_alloc_slab || pool->alloc == mempool_kmalloc)",
            "\t\tkasan_slab_free_mempool(element);",
            "\telse if (pool->alloc == mempool_alloc_pages)",
            "\t\tkasan_poison_pages(element, (unsigned long)pool->pool_data,",
            "\t\t\t\t   false);",
            "}",
            "static void kasan_unpoison_element(mempool_t *pool, void *element)",
            "{",
            "\tif (pool->alloc == mempool_kmalloc)",
            "\t\tkasan_unpoison_range(element, (size_t)pool->pool_data);",
            "\telse if (pool->alloc == mempool_alloc_slab)",
            "\t\tkasan_unpoison_range(element, kmem_cache_size(pool->pool_data));",
            "\telse if (pool->alloc == mempool_alloc_pages)",
            "\t\tkasan_unpoison_pages(element, (unsigned long)pool->pool_data,",
            "\t\t\t\t     false);",
            "}",
            "static __always_inline void add_element(mempool_t *pool, void *element)",
            "{",
            "\tBUG_ON(pool->curr_nr >= pool->min_nr);",
            "\tpoison_element(pool, element);",
            "\tkasan_poison_element(pool, element);",
            "\tpool->elements[pool->curr_nr++] = element;",
            "}"
          ],
          "function_name": "poison_error, __check_element, check_element, __poison_element, poison_element, check_element, poison_element, kasan_poison_element, kasan_unpoison_element, add_element",
          "description": "实现内存池元素毒化校验逻辑，用于检测内存泄漏和非法访问，包含毒化标记设置与验证函数",
          "similarity": 0.5039087533950806
        },
        {
          "chunk_id": 0,
          "file_path": "mm/mempool.c",
          "start_line": 1,
          "end_line": 23,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " *  linux/mm/mempool.c",
            " *",
            " *  memory buffer pool support. Such pools are mostly used",
            " *  for guaranteed, deadlock-free memory allocations during",
            " *  extreme VM load.",
            " *",
            " *  started by Ingo Molnar, Copyright (C) 2001",
            " *  debugging by David Rientjes, Copyright (C) 2015",
            " */",
            "",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/highmem.h>",
            "#include <linux/kasan.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/export.h>",
            "#include <linux/mempool.h>",
            "#include <linux/writeback.h>",
            "#include \"slab.h\"",
            "",
            "#ifdef CONFIG_SLUB_DEBUG_ON"
          ],
          "function_name": null,
          "description": "声明内存池支持模块，包含核心头文件并初始化SLUB调试相关配置",
          "similarity": 0.4909653961658478
        },
        {
          "chunk_id": 3,
          "file_path": "mm/mempool.c",
          "start_line": 488,
          "end_line": 557,
          "content": [
            "void mempool_free(void *element, mempool_t *pool)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tif (unlikely(element == NULL))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Paired with the wmb in mempool_alloc().  The preceding read is",
            "\t * for @element and the following @pool->curr_nr.  This ensures",
            "\t * that the visible value of @pool->curr_nr is from after the",
            "\t * allocation of @element.  This is necessary for fringe cases",
            "\t * where @element was passed to this task without going through",
            "\t * barriers.",
            "\t *",
            "\t * For example, assume @p is %NULL at the beginning and one task",
            "\t * performs \"p = mempool_alloc(...);\" while another task is doing",
            "\t * \"while (!p) cpu_relax(); mempool_free(p, ...);\".  This function",
            "\t * may end up using curr_nr value which is from before allocation",
            "\t * of @p without the following rmb.",
            "\t */",
            "\tsmp_rmb();",
            "",
            "\t/*",
            "\t * For correctness, we need a test which is guaranteed to trigger",
            "\t * if curr_nr + #allocated == min_nr.  Testing curr_nr < min_nr",
            "\t * without locking achieves that and refilling as soon as possible",
            "\t * is desirable.",
            "\t *",
            "\t * Because curr_nr visible here is always a value after the",
            "\t * allocation of @element, any task which decremented curr_nr below",
            "\t * min_nr is guaranteed to see curr_nr < min_nr unless curr_nr gets",
            "\t * incremented to min_nr afterwards.  If curr_nr gets incremented",
            "\t * to min_nr after the allocation of @element, the elements",
            "\t * allocated after that are subject to the same guarantee.",
            "\t *",
            "\t * Waiters happen iff curr_nr is 0 and the above guarantee also",
            "\t * ensures that there will be frees which return elements to the",
            "\t * pool waking up the waiters.",
            "\t */",
            "\tif (unlikely(READ_ONCE(pool->curr_nr) < pool->min_nr)) {",
            "\t\tspin_lock_irqsave(&pool->lock, flags);",
            "\t\tif (likely(pool->curr_nr < pool->min_nr)) {",
            "\t\t\tadd_element(pool, element);",
            "\t\t\tspin_unlock_irqrestore(&pool->lock, flags);",
            "\t\t\twake_up(&pool->wait);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\tspin_unlock_irqrestore(&pool->lock, flags);",
            "\t}",
            "\tpool->free(element, pool->pool_data);",
            "}",
            "void mempool_free_slab(void *element, void *pool_data)",
            "{",
            "\tstruct kmem_cache *mem = pool_data;",
            "\tkmem_cache_free(mem, element);",
            "}",
            "void mempool_kfree(void *element, void *pool_data)",
            "{",
            "\tkfree(element);",
            "}",
            "void mempool_kvfree(void *element, void *pool_data)",
            "{",
            "\tkvfree(element);",
            "}",
            "void mempool_free_pages(void *element, void *pool_data)",
            "{",
            "\tint order = (int)(long)pool_data;",
            "\t__free_pages(element, order);",
            "}"
          ],
          "function_name": "mempool_free, mempool_free_slab, mempool_kfree, mempool_kvfree, mempool_free_pages",
          "description": "实现通用元素释放接口及针对slab/页分配的专用释放函数，包含并发安全的回收逻辑",
          "similarity": 0.4587257206439972
        }
      ]
    },
    {
      "source_file": "kernel/pid_namespace.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:16:50\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `pid_namespace.c`\n\n---\n\n# `pid_namespace.c` 技术文档\n\n## 1. 文件概述\n\n`pid_namespace.c` 是 Linux 内核中实现 **PID 命名空间（PID Namespace）** 的核心源文件。PID 命名空间是 Linux 容器技术（如 Docker、LXC）的关键基础组件之一，用于为不同进程组提供隔离的进程 ID 视图。每个 PID 命名空间拥有独立的 PID 分配空间，使得不同命名空间中的进程可以拥有相同的 PID 而互不干扰。\n\n该文件负责 PID 命名空间的创建、销毁、引用计数管理、资源回收以及命名空间内进程的批量终止（如容器退出时清理所有子进程）等核心功能。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct pid_namespace`：表示一个 PID 命名空间，包含：\n  - `level`：命名空间层级（init_pid_ns 为 0，子命名空间依次递增）\n  - `parent`：指向父命名空间的指针\n  - `user_ns`：关联的用户命名空间\n  - `idr`：用于分配和管理 PID 的 IDR（整数到指针映射）结构\n  - `pid_cachep`：用于分配 `struct pid` 对象的 slab 缓存\n  - `pid_allocated`：当前命名空间中已分配的 PID 数量\n  - `ucounts`：用于限制用户命名空间下 PID 命名空间数量的计数器\n\n### 主要函数\n- `create_pid_cachep(unsigned int level)`  \n  为指定层级的 PID 命名空间创建专用的 `struct pid` slab 缓存。\n  \n- `create_pid_namespace(struct user_namespace *user_ns, struct pid_namespace *parent_pid_ns)`  \n  创建一个新的 PID 命名空间，设置层级、父命名空间、用户命名空间等属性，并初始化 IDR 和引用计数。\n\n- `copy_pid_ns(unsigned long flags, struct user_namespace *user_ns, struct pid_namespace *old_ns)`  \n  在 `clone()` 或 `unshare()` 系统调用中被调用，根据 `CLONE_NEWPID` 标志决定是否创建新的 PID 命名空间。\n\n- `put_pid_ns(struct pid_namespace *ns)`  \n  递减 PID 命名空间的引用计数，若引用计数归零则递归销毁该命名空间及其子命名空间。\n\n- `zap_pid_ns_processes(struct pid_namespace *pid_ns)`  \n  在 PID 命名空间的 init 进程退出时调用，向命名空间内所有剩余进程发送 `SIGKILL`，并等待其全部退出，确保命名空间干净回收。\n\n- `delayed_free_pidns(struct rcu_head *p)`  \n  通过 RCU 机制延迟释放 PID 命名空间结构体，确保所有并发读取完成后再释放内存。\n\n## 3. 关键实现\n\n### PID 命名空间层级与缓存管理\n- PID 命名空间支持嵌套，最大深度由 `MAX_PID_NS_LEVEL` 限制（通常为 32）。\n- 每个层级使用独立的 slab 缓存（`pid_cache[level - 1]`）来分配 `struct pid`，因为 `struct pid` 中的 `numbers[]` 数组大小依赖于命名空间层级（`level + 1`）。\n- 缓存创建通过 `create_pid_cachep()` 实现，使用互斥锁 `pid_caches_mutex` 避免并发创建冲突。\n\n### 引用计数与生命周期管理\n- 使用 `refcount_t` 管理命名空间引用计数。\n- `put_pid_ns()` 采用**尾递归方式**向上遍历父命名空间链，逐级释放无引用的命名空间。\n- 实际内存释放通过 RCU 回调 `delayed_free_pidns()` 延迟执行，保证并发安全。\n\n### 命名空间退出清理机制（`zap_pid_ns_processes`）\n- **禁用新 PID 分配**：调用 `disable_pid_allocation()` 阻止新进程加入。\n- **忽略 SIGCHLD**：使 init 进程自动回收僵尸子进程，避免阻塞。\n- **批量 SIGKILL**：遍历 IDR 中所有 PID，向对应进程发送 `SIGKILL`。\n- **等待所有进程退出**：通过 `kernel_wait4()` 回收直接子进程，并通过检查 `pid_allocated == init_pids` 确保所有进程（包括跨命名空间 fork 的僵尸进程）均已退出。\n- **RCU 安全调度**：在等待循环中调用 `exit_tasks_rcu_stop/start()` 避免与 `synchronize_rcu_tasks()` 死锁。\n\n### 资源限制\n- 通过 `inc_pid_namespaces()` / `dec_pid_namespaces()` 调用 `ucounts` 机制，限制每个用户命名空间可创建的 PID 命名空间数量，防止资源耗尽。\n\n## 4. 依赖关系\n\n- **`<linux/pid.h>` / `<linux/pid_namespace.h>`**：定义 `struct pid` 和 `struct pid_namespace`。\n- **`<linux/user_namespace.h>`**：依赖用户命名空间进行权限和资源限制。\n- **`<linux/idr.h>`**：使用 IDR 数据结构管理 PID 分配。\n- **`<linux/slab.h>`**：使用 kmem_cache 管理内存分配。\n- **`<linux/sched/*.h>`**：访问任务结构、信号处理、RCU 任务同步等。\n- **`<linux/proc_ns.h>`**：支持 `/proc/[pid]/ns/pid` 接口。\n- **`\"pid_sysctl.h\"`**：提供 sysctl 配置（如 `memfd_noexec_scope`）。\n- **`<linux/acct.h>`**：在命名空间销毁时清理进程会计信息。\n\n## 5. 使用场景\n\n- **容器启动**：当执行 `unshare(CLONE_NEWPID)` 或 `clone(CLONE_NEWPID)` 时，内核调用 `copy_pid_ns()` 创建新的 PID 命名空间，使容器内进程拥有独立的 PID 视图（容器内 PID 1 对应宿主机某个高 PID）。\n- **容器退出**：当容器的 init 进程（PID 1）退出时，内核自动调用 `zap_pid_ns_processes()` 终止命名空间内所有剩余进程，防止孤儿进程泄漏。\n- **命名空间嵌套**：支持多层容器或 sandbox 场景，如 systemd-nspawn 嵌套运行容器。\n- **资源隔离与限制**：结合用户命名空间，限制非特权用户创建过多 PID 命名空间，提升系统安全性。\n- **进程迁移与检查点**：配合 CRIU（Checkpoint/Restore in Userspace）等工具，通过 sysctl 接口控制命名空间行为（如 memfd 执行权限）。",
      "similarity": 0.5328511595726013,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/pid_namespace.c",
          "start_line": 1,
          "end_line": 67,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Pid namespaces",
            " *",
            " * Authors:",
            " *    (C) 2007 Pavel Emelyanov <xemul@openvz.org>, OpenVZ, SWsoft Inc.",
            " *    (C) 2007 Sukadev Bhattiprolu <sukadev@us.ibm.com>, IBM",
            " *     Many thanks to Oleg Nesterov for comments and help",
            " *",
            " */",
            "",
            "#include <linux/pid.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/cred.h>",
            "#include <linux/err.h>",
            "#include <linux/acct.h>",
            "#include <linux/slab.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/reboot.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/idr.h>",
            "#include <uapi/linux/wait.h>",
            "#include \"pid_sysctl.h\"",
            "",
            "static DEFINE_MUTEX(pid_caches_mutex);",
            "static struct kmem_cache *pid_ns_cachep;",
            "/* Write once array, filled from the beginning. */",
            "static struct kmem_cache *pid_cache[MAX_PID_NS_LEVEL];",
            "",
            "/*",
            " * creates the kmem cache to allocate pids from.",
            " * @level: pid namespace level",
            " */",
            "",
            "static struct kmem_cache *create_pid_cachep(unsigned int level)",
            "{",
            "\t/* Level 0 is init_pid_ns.pid_cachep */",
            "\tstruct kmem_cache **pkc = &pid_cache[level - 1];",
            "\tstruct kmem_cache *kc;",
            "\tchar name[4 + 10 + 1];",
            "\tunsigned int len;",
            "",
            "\tkc = READ_ONCE(*pkc);",
            "\tif (kc)",
            "\t\treturn kc;",
            "",
            "\tsnprintf(name, sizeof(name), \"pid_%u\", level + 1);",
            "\tlen = struct_size_t(struct pid, numbers, level + 1);",
            "\tmutex_lock(&pid_caches_mutex);",
            "\t/* Name collision forces to do allocation under mutex. */",
            "\tif (!*pkc)",
            "\t\t*pkc = kmem_cache_create(name, len, 0,",
            "\t\t\t\t\t SLAB_HWCACHE_ALIGN | SLAB_ACCOUNT, NULL);",
            "\tmutex_unlock(&pid_caches_mutex);",
            "\t/* current can fail, but someone else can succeed. */",
            "\treturn READ_ONCE(*pkc);",
            "}",
            "",
            "static struct ucounts *inc_pid_namespaces(struct user_namespace *ns)",
            "{",
            "\treturn inc_ucount(ns, current_euid(), UCOUNT_PID_NAMESPACES);",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义用于管理pid命名空间的kmem缓存创建函数create_pid_cachep，根据层级参数为不同pid命名空间级别创建专用内存池；inc_pid_namespaces函数用于增加用户命名空间的使用计数",
          "similarity": 0.4974445104598999
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/pid_namespace.c",
          "start_line": 281,
          "end_line": 379,
          "content": [
            "static int pid_ns_ctl_handler(struct ctl_table *table, int write,",
            "\t\tvoid *buffer, size_t *lenp, loff_t *ppos)",
            "{",
            "\tstruct pid_namespace *pid_ns = task_active_pid_ns(current);",
            "\tstruct ctl_table tmp = *table;",
            "\tint ret, next;",
            "",
            "\tif (write && !checkpoint_restore_ns_capable(pid_ns->user_ns))",
            "\t\treturn -EPERM;",
            "",
            "\t/*",
            "\t * Writing directly to ns' last_pid field is OK, since this field",
            "\t * is volatile in a living namespace anyway and a code writing to",
            "\t * it should synchronize its usage with external means.",
            "\t */",
            "",
            "\tnext = idr_get_cursor(&pid_ns->idr) - 1;",
            "",
            "\ttmp.data = &next;",
            "\tret = proc_dointvec_minmax(&tmp, write, buffer, lenp, ppos);",
            "\tif (!ret && write)",
            "\t\tidr_set_cursor(&pid_ns->idr, next + 1);",
            "",
            "\treturn ret;",
            "}",
            "int reboot_pid_ns(struct pid_namespace *pid_ns, int cmd)",
            "{",
            "\tif (pid_ns == &init_pid_ns)",
            "\t\treturn 0;",
            "",
            "\tswitch (cmd) {",
            "\tcase LINUX_REBOOT_CMD_RESTART2:",
            "\tcase LINUX_REBOOT_CMD_RESTART:",
            "\t\tpid_ns->reboot = SIGHUP;",
            "\t\tbreak;",
            "",
            "\tcase LINUX_REBOOT_CMD_POWER_OFF:",
            "\tcase LINUX_REBOOT_CMD_HALT:",
            "\t\tpid_ns->reboot = SIGINT;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tread_lock(&tasklist_lock);",
            "\tsend_sig(SIGKILL, pid_ns->child_reaper, 1);",
            "\tread_unlock(&tasklist_lock);",
            "",
            "\tdo_exit(0);",
            "",
            "\t/* Not reached */",
            "\treturn 0;",
            "}",
            "static void pidns_put(struct ns_common *ns)",
            "{",
            "\tput_pid_ns(to_pid_ns(ns));",
            "}",
            "static int pidns_install(struct nsset *nsset, struct ns_common *ns)",
            "{",
            "\tstruct nsproxy *nsproxy = nsset->nsproxy;",
            "\tstruct pid_namespace *active = task_active_pid_ns(current);",
            "\tstruct pid_namespace *ancestor, *new = to_pid_ns(ns);",
            "",
            "\tif (!ns_capable(new->user_ns, CAP_SYS_ADMIN) ||",
            "\t    !ns_capable(nsset->cred->user_ns, CAP_SYS_ADMIN))",
            "\t\treturn -EPERM;",
            "",
            "\t/*",
            "\t * Only allow entering the current active pid namespace",
            "\t * or a child of the current active pid namespace.",
            "\t *",
            "\t * This is required for fork to return a usable pid value and",
            "\t * this maintains the property that processes and their",
            "\t * children can not escape their current pid namespace.",
            "\t */",
            "\tif (new->level < active->level)",
            "\t\treturn -EINVAL;",
            "",
            "\tancestor = new;",
            "\twhile (ancestor->level > active->level)",
            "\t\tancestor = ancestor->parent;",
            "\tif (ancestor != active)",
            "\t\treturn -EINVAL;",
            "",
            "\tput_pid_ns(nsproxy->pid_ns_for_children);",
            "\tnsproxy->pid_ns_for_children = get_pid_ns(new);",
            "\treturn 0;",
            "}",
            "static __init int pid_namespaces_init(void)",
            "{",
            "\tpid_ns_cachep = KMEM_CACHE(pid_namespace, SLAB_PANIC | SLAB_ACCOUNT);",
            "",
            "#ifdef CONFIG_CHECKPOINT_RESTORE",
            "\tregister_sysctl_init(\"kernel\", pid_ns_ctl_table);",
            "#endif",
            "",
            "\tregister_pid_ns_sysctl_table_vm();",
            "\treturn 0;",
            "}"
          ],
          "function_name": "pid_ns_ctl_handler, reboot_pid_ns, pidns_put, pidns_install, pid_namespaces_init",
          "description": "包含pid命名空间控制接口处理函数pid_ns_ctl_handler，reboot_pid_ns设置命名空间重启信号，pidns_install验证命名空间层级权限并进行安装操作，pid_namespaces_init完成核心数据结构初始化和sysctl注册",
          "similarity": 0.4370211362838745
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/pid_namespace.c",
          "start_line": 68,
          "end_line": 208,
          "content": [
            "static void dec_pid_namespaces(struct ucounts *ucounts)",
            "{",
            "\tdec_ucount(ucounts, UCOUNT_PID_NAMESPACES);",
            "}",
            "static void delayed_free_pidns(struct rcu_head *p)",
            "{",
            "\tstruct pid_namespace *ns = container_of(p, struct pid_namespace, rcu);",
            "",
            "\tdec_pid_namespaces(ns->ucounts);",
            "\tput_user_ns(ns->user_ns);",
            "",
            "\tkmem_cache_free(pid_ns_cachep, ns);",
            "}",
            "static void destroy_pid_namespace(struct pid_namespace *ns)",
            "{",
            "\tns_free_inum(&ns->ns);",
            "",
            "\tidr_destroy(&ns->idr);",
            "\tcall_rcu(&ns->rcu, delayed_free_pidns);",
            "}",
            "void put_pid_ns(struct pid_namespace *ns)",
            "{",
            "\tstruct pid_namespace *parent;",
            "",
            "\twhile (ns != &init_pid_ns) {",
            "\t\tparent = ns->parent;",
            "\t\tif (!refcount_dec_and_test(&ns->ns.count))",
            "\t\t\tbreak;",
            "\t\tdestroy_pid_namespace(ns);",
            "\t\tns = parent;",
            "\t}",
            "}",
            "void zap_pid_ns_processes(struct pid_namespace *pid_ns)",
            "{",
            "\tint nr;",
            "\tint rc;",
            "\tstruct task_struct *task, *me = current;",
            "\tint init_pids = thread_group_leader(me) ? 1 : 2;",
            "\tstruct pid *pid;",
            "",
            "\t/* Don't allow any more processes into the pid namespace */",
            "\tdisable_pid_allocation(pid_ns);",
            "",
            "\t/*",
            "\t * Ignore SIGCHLD causing any terminated children to autoreap.",
            "\t * This speeds up the namespace shutdown, plus see the comment",
            "\t * below.",
            "\t */",
            "\tspin_lock_irq(&me->sighand->siglock);",
            "\tme->sighand->action[SIGCHLD - 1].sa.sa_handler = SIG_IGN;",
            "\tspin_unlock_irq(&me->sighand->siglock);",
            "",
            "\t/*",
            "\t * The last thread in the cgroup-init thread group is terminating.",
            "\t * Find remaining pid_ts in the namespace, signal and wait for them",
            "\t * to exit.",
            "\t *",
            "\t * Note:  This signals each threads in the namespace - even those that",
            "\t * \t  belong to the same thread group, To avoid this, we would have",
            "\t * \t  to walk the entire tasklist looking a processes in this",
            "\t * \t  namespace, but that could be unnecessarily expensive if the",
            "\t * \t  pid namespace has just a few processes. Or we need to",
            "\t * \t  maintain a tasklist for each pid namespace.",
            "\t *",
            "\t */",
            "\trcu_read_lock();",
            "\tread_lock(&tasklist_lock);",
            "\tnr = 2;",
            "\tidr_for_each_entry_continue(&pid_ns->idr, pid, nr) {",
            "\t\ttask = pid_task(pid, PIDTYPE_PID);",
            "\t\tif (task && !__fatal_signal_pending(task))",
            "\t\t\tgroup_send_sig_info(SIGKILL, SEND_SIG_PRIV, task, PIDTYPE_MAX);",
            "\t}",
            "\tread_unlock(&tasklist_lock);",
            "\trcu_read_unlock();",
            "",
            "\t/*",
            "\t * Reap the EXIT_ZOMBIE children we had before we ignored SIGCHLD.",
            "\t * kernel_wait4() will also block until our children traced from the",
            "\t * parent namespace are detached and become EXIT_DEAD.",
            "\t */",
            "\tdo {",
            "\t\tclear_thread_flag(TIF_SIGPENDING);",
            "\t\tclear_thread_flag(TIF_NOTIFY_SIGNAL);",
            "\t\trc = kernel_wait4(-1, NULL, __WALL, NULL);",
            "\t} while (rc != -ECHILD);",
            "",
            "\t/*",
            "\t * kernel_wait4() misses EXIT_DEAD children, and EXIT_ZOMBIE",
            "\t * process whose parents processes are outside of the pid",
            "\t * namespace.  Such processes are created with setns()+fork().",
            "\t *",
            "\t * If those EXIT_ZOMBIE processes are not reaped by their",
            "\t * parents before their parents exit, they will be reparented",
            "\t * to pid_ns->child_reaper.  Thus pidns->child_reaper needs to",
            "\t * stay valid until they all go away.",
            "\t *",
            "\t * The code relies on the pid_ns->child_reaper ignoring",
            "\t * SIGCHILD to cause those EXIT_ZOMBIE processes to be",
            "\t * autoreaped if reparented.",
            "\t *",
            "\t * Semantically it is also desirable to wait for EXIT_ZOMBIE",
            "\t * processes before allowing the child_reaper to be reaped, as",
            "\t * that gives the invariant that when the init process of a",
            "\t * pid namespace is reaped all of the processes in the pid",
            "\t * namespace are gone.",
            "\t *",
            "\t * Once all of the other tasks are gone from the pid_namespace",
            "\t * free_pid() will awaken this task.",
            "\t */",
            "\tfor (;;) {",
            "\t\tset_current_state(TASK_INTERRUPTIBLE);",
            "\t\tif (pid_ns->pid_allocated == init_pids)",
            "\t\t\tbreak;",
            "\t\t/*",
            "\t\t * Release tasks_rcu_exit_srcu to avoid following deadlock:",
            "\t\t *",
            "\t\t * 1) TASK A unshare(CLONE_NEWPID)",
            "\t\t * 2) TASK A fork() twice -> TASK B (child reaper for new ns)",
            "\t\t *    and TASK C",
            "\t\t * 3) TASK B exits, kills TASK C, waits for TASK A to reap it",
            "\t\t * 4) TASK A calls synchronize_rcu_tasks()",
            "\t\t *                   -> synchronize_srcu(tasks_rcu_exit_srcu)",
            "\t\t * 5) *DEADLOCK*",
            "\t\t *",
            "\t\t * It is considered safe to release tasks_rcu_exit_srcu here",
            "\t\t * because we assume the current task can not be concurrently",
            "\t\t * reaped at this point.",
            "\t\t */",
            "\t\texit_tasks_rcu_stop();",
            "\t\tschedule();",
            "\t\texit_tasks_rcu_start();",
            "\t}",
            "\t__set_current_state(TASK_RUNNING);",
            "",
            "\tif (pid_ns->reboot)",
            "\t\tcurrent->signal->group_exit_code = pid_ns->reboot;",
            "",
            "\tacct_exit_ns(pid_ns);",
            "\treturn;",
            "}"
          ],
          "function_name": "dec_pid_namespaces, delayed_free_pidns, destroy_pid_namespace, put_pid_ns, zap_pid_ns_processes",
          "description": "包含销毁pid命名空间相关函数，其中destroy_pid_namespace通过RCU机制延迟释放资源，zap_pid_ns_processes强制终止命名空间内所有进程并回收资源，put_pid_ns管理命名空间引用计数",
          "similarity": 0.43563568592071533
        }
      ]
    }
  ]
}