{
  "query": "memory pressure",
  "timestamp": "2025-12-26 00:02:32",
  "retrieved_files": [
    {
      "source_file": "mm/vmpressure.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:33:01\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `vmpressure.c`\n\n---\n\n# vmpressure.c 技术文档\n\n## 1. 文件概述\n\n`vmpressure.c` 实现了 Linux 内核中的虚拟内存压力（VM pressure）监控机制。该机制通过跟踪页面扫描（scanned）与回收（reclaimed）的比率，评估系统或特定内存控制组（memcg）所面临的内存压力程度，并在达到预设阈值时向用户空间发送通知。此功能主要用于支持 cgroup v2 的 memory.pressure 接口，使用户空间程序（如容器运行时）能够感知内存紧张状况并作出响应（如释放缓存、限制内存使用等），从而避免系统进入 OOM（Out-Of-Memory）状态。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct vmpressure`**  \n  表示一个内存控制组的 VM 压力状态，包含：\n  - `tree_scanned` / `tree_reclaimed`：累积的扫描和回收页数（用于子树模式）\n  - `sr_lock`：保护上述计数器的自旋锁\n  - `events_lock`：保护事件监听列表的互斥锁\n  - `events`：注册的事件监听器链表（`struct vmpressure_event`）\n  - `work`：延迟处理工作项（`struct work_struct`）\n\n- **`struct vmpressure_event`**  \n  表示一个用户空间注册的压力事件监听器，包含：\n  - `efd`：关联的 eventfd 上下文，用于通知\n  - `level`：触发通知的最低压力等级（low/medium/critical）\n  - `mode`：通知模式（default/hierarchy/local）\n  - `node`：链表节点\n\n### 主要函数\n\n- **`vmpressure()`**  \n  核心接口函数，由内存回收路径（vmscan）调用，传入当前扫描和回收的页数，更新压力统计并可能调度异步处理。\n\n- **`vmpressure_work_fn()`**  \n  工作队列回调函数，负责计算压力等级、触发事件通知，并向上遍历内存控制组层级（支持层次化通知）。\n\n- **`vmpressure_calc_level()`**  \n  根据 `scanned` 和 `reclaimed` 计算压力百分比，并映射到离散的压力等级（low/medium/critical）。\n\n- **`vmpressure_event()`**  \n  遍历当前 memcg 注册的所有事件监听器，根据压力等级、通知模式和层级关系决定是否触发 eventfd 信号。\n\n- **辅助函数**  \n  - `vmpressure_parent()`：获取父级 memcg 对应的 `vmpressure` 结构\n  - `vmpressure_level()`：将压力百分比映射为枚举等级\n  - `work_to_vmpressure()`：从 work_struct 转换为 vmpressure 指针\n\n### 关键常量\n\n- **`vmpressure_win`**：压力计算窗口大小（512 页），用于速率限制和平均\n- **`vmpressure_level_med`**（60）和 **`vmpressure_level_critical`**（95）：中等和严重压力的百分比阈值\n- **`vmpressure_level_critical_prio`**：基于扫描优先级判断严重压力的备用机制\n\n## 3. 关键实现\n\n### 压力等级计算\n压力通过公式 `pressure = (scanned - reclaimed) * 100 / scanned` 计算（实际实现考虑了 `reclaimed > scanned` 的边界情况）。该值反映回收效率：值越高表示回收越困难，内存压力越大。\n\n### 异步处理机制\n`vmpressure()` 函数仅累加计数器并调度 `vmpressure_work_fn` 工作项，避免在内存回收关键路径上执行复杂逻辑。工作项在后台执行压力计算和通知。\n\n### 层级化通知（Hierarchy）\n支持三种通知模式：\n- **`local`**：仅当前 memcg 触发\n- **`hierarchy`**：当前及所有祖先 memcg 均可触发\n- **`default`（no passthrough）**：当前 memcg 触发后，阻止向祖先传递（避免重复通知）\n\n### 窗口与速率限制\n使用固定窗口（`vmpressure_win`）累积扫描/回收页数，确保压力评估具有时间局部性，同时防止高频通知。\n\n### 与 vmscan 集成\n直接接收 vmscan 传递的 `scanned` 和 `reclaimed` 参数，紧密耦合内存回收行为，提供实时压力反馈。\n\n## 4. 依赖关系\n\n- **内存控制组（memcg）**：通过 `mem_cgroup` 结构关联 `vmpressure` 实例，依赖 cgroup 子系统（`memory_cgrp_subsys`）\n- **内存管理核心（mm）**：依赖 `vmscan` 回收路径调用 `vmpressure()`，使用 `SWAP_CLUSTER_MAX` 常量\n- **事件通知机制**：使用 `eventfd` 向用户空间发送信号\n- **内核同步原语**：使用 `spinlock`（`sr_lock`）和 `mutex`（`events_lock`）保护数据\n- **通用内核组件**：依赖 `workqueue`（延迟处理）、`slab`（内存分配）、`printk`（调试）\n\n## 5. 使用场景\n\n1. **容器内存管理**  \n   容器运行时（如 Docker、systemd-nspawn）通过监听 cgroup v2 的 `memory.pressure` 文件，在内存压力升高时主动释放缓存或限制应用内存使用，避免被 OOM killer 终止。\n\n2. **系统级内存优化**  \n   用户空间守护进程（如 earlyoom、nohang）利用压力事件提前干预，例如在 `critical` 压力下终止低优先级进程。\n\n3. **内核子系统集成**  \n   其他内核模块可通过注册 `vmpressure` 事件监听器，在内存紧张时调整自身行为（如降低缓存占用）。\n\n4. **传统 cgroup v1 支持**  \n   通过 `tree` 参数兼容旧版 subtree 压力报告模式（尽管主要面向 cgroup v2 设计）。",
      "similarity": 0.5403438806533813,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/vmpressure.c",
          "start_line": 111,
          "end_line": 290,
          "content": [
            "static enum vmpressure_levels vmpressure_level(unsigned long pressure)",
            "{",
            "\tif (pressure >= vmpressure_level_critical)",
            "\t\treturn VMPRESSURE_CRITICAL;",
            "\telse if (pressure >= vmpressure_level_med)",
            "\t\treturn VMPRESSURE_MEDIUM;",
            "\treturn VMPRESSURE_LOW;",
            "}",
            "static enum vmpressure_levels vmpressure_calc_level(unsigned long scanned,",
            "\t\t\t\t\t\t    unsigned long reclaimed)",
            "{",
            "\tunsigned long scale = scanned + reclaimed;",
            "\tunsigned long pressure = 0;",
            "",
            "\t/*",
            "\t * reclaimed can be greater than scanned for things such as reclaimed",
            "\t * slab pages. shrink_node() just adds reclaimed pages without a",
            "\t * related increment to scanned pages.",
            "\t */",
            "\tif (reclaimed >= scanned)",
            "\t\tgoto out;",
            "\t/*",
            "\t * We calculate the ratio (in percents) of how many pages were",
            "\t * scanned vs. reclaimed in a given time frame (window). Note that",
            "\t * time is in VM reclaimer's \"ticks\", i.e. number of pages",
            "\t * scanned. This makes it possible to set desired reaction time",
            "\t * and serves as a ratelimit.",
            "\t */",
            "\tpressure = scale - (reclaimed * scale / scanned);",
            "\tpressure = pressure * 100 / scale;",
            "",
            "out:",
            "\tpr_debug(\"%s: %3lu  (s: %lu  r: %lu)\\n\", __func__, pressure,",
            "\t\t scanned, reclaimed);",
            "",
            "\treturn vmpressure_level(pressure);",
            "}",
            "static bool vmpressure_event(struct vmpressure *vmpr,",
            "\t\t\t     const enum vmpressure_levels level,",
            "\t\t\t     bool ancestor, bool signalled)",
            "{",
            "\tstruct vmpressure_event *ev;",
            "\tbool ret = false;",
            "",
            "\tmutex_lock(&vmpr->events_lock);",
            "\tlist_for_each_entry(ev, &vmpr->events, node) {",
            "\t\tif (ancestor && ev->mode == VMPRESSURE_LOCAL)",
            "\t\t\tcontinue;",
            "\t\tif (signalled && ev->mode == VMPRESSURE_NO_PASSTHROUGH)",
            "\t\t\tcontinue;",
            "\t\tif (level < ev->level)",
            "\t\t\tcontinue;",
            "\t\teventfd_signal(ev->efd);",
            "\t\tret = true;",
            "\t}",
            "\tmutex_unlock(&vmpr->events_lock);",
            "",
            "\treturn ret;",
            "}",
            "static void vmpressure_work_fn(struct work_struct *work)",
            "{",
            "\tstruct vmpressure *vmpr = work_to_vmpressure(work);",
            "\tunsigned long scanned;",
            "\tunsigned long reclaimed;",
            "\tenum vmpressure_levels level;",
            "\tbool ancestor = false;",
            "\tbool signalled = false;",
            "",
            "\tspin_lock(&vmpr->sr_lock);",
            "\t/*",
            "\t * Several contexts might be calling vmpressure(), so it is",
            "\t * possible that the work was rescheduled again before the old",
            "\t * work context cleared the counters. In that case we will run",
            "\t * just after the old work returns, but then scanned might be zero",
            "\t * here. No need for any locks here since we don't care if",
            "\t * vmpr->reclaimed is in sync.",
            "\t */",
            "\tscanned = vmpr->tree_scanned;",
            "\tif (!scanned) {",
            "\t\tspin_unlock(&vmpr->sr_lock);",
            "\t\treturn;",
            "\t}",
            "",
            "\treclaimed = vmpr->tree_reclaimed;",
            "\tvmpr->tree_scanned = 0;",
            "\tvmpr->tree_reclaimed = 0;",
            "\tspin_unlock(&vmpr->sr_lock);",
            "",
            "\tlevel = vmpressure_calc_level(scanned, reclaimed);",
            "",
            "\tdo {",
            "\t\tif (vmpressure_event(vmpr, level, ancestor, signalled))",
            "\t\t\tsignalled = true;",
            "\t\tancestor = true;",
            "\t} while ((vmpr = vmpressure_parent(vmpr)));",
            "}",
            "void vmpressure(gfp_t gfp, struct mem_cgroup *memcg, bool tree,",
            "\t\tunsigned long scanned, unsigned long reclaimed)",
            "{",
            "\tstruct vmpressure *vmpr;",
            "",
            "\tif (mem_cgroup_disabled())",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * The in-kernel users only care about the reclaim efficiency",
            "\t * for this @memcg rather than the whole subtree, and there",
            "\t * isn't and won't be any in-kernel user in a legacy cgroup.",
            "\t */",
            "\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys) && !tree)",
            "\t\treturn;",
            "",
            "\tvmpr = memcg_to_vmpressure(memcg);",
            "",
            "\t/*",
            "\t * Here we only want to account pressure that userland is able to",
            "\t * help us with. For example, suppose that DMA zone is under",
            "\t * pressure; if we notify userland about that kind of pressure,",
            "\t * then it will be mostly a waste as it will trigger unnecessary",
            "\t * freeing of memory by userland (since userland is more likely to",
            "\t * have HIGHMEM/MOVABLE pages instead of the DMA fallback). That",
            "\t * is why we include only movable, highmem and FS/IO pages.",
            "\t * Indirect reclaim (kswapd) sets sc->gfp_mask to GFP_KERNEL, so",
            "\t * we account it too.",
            "\t */",
            "\tif (!(gfp & (__GFP_HIGHMEM | __GFP_MOVABLE | __GFP_IO | __GFP_FS)))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If we got here with no pages scanned, then that is an indicator",
            "\t * that reclaimer was unable to find any shrinkable LRUs at the",
            "\t * current scanning depth. But it does not mean that we should",
            "\t * report the critical pressure, yet. If the scanning priority",
            "\t * (scanning depth) goes too high (deep), we will be notified",
            "\t * through vmpressure_prio(). But so far, keep calm.",
            "\t */",
            "\tif (!scanned)",
            "\t\treturn;",
            "",
            "\tif (tree) {",
            "\t\tspin_lock(&vmpr->sr_lock);",
            "\t\tscanned = vmpr->tree_scanned += scanned;",
            "\t\tvmpr->tree_reclaimed += reclaimed;",
            "\t\tspin_unlock(&vmpr->sr_lock);",
            "",
            "\t\tif (scanned < vmpressure_win)",
            "\t\t\treturn;",
            "\t\tschedule_work(&vmpr->work);",
            "\t} else {",
            "\t\tenum vmpressure_levels level;",
            "",
            "\t\t/* For now, no users for root-level efficiency */",
            "\t\tif (!memcg || mem_cgroup_is_root(memcg))",
            "\t\t\treturn;",
            "",
            "\t\tspin_lock(&vmpr->sr_lock);",
            "\t\tscanned = vmpr->scanned += scanned;",
            "\t\treclaimed = vmpr->reclaimed += reclaimed;",
            "\t\tif (scanned < vmpressure_win) {",
            "\t\t\tspin_unlock(&vmpr->sr_lock);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\tvmpr->scanned = vmpr->reclaimed = 0;",
            "\t\tspin_unlock(&vmpr->sr_lock);",
            "",
            "\t\tlevel = vmpressure_calc_level(scanned, reclaimed);",
            "",
            "\t\tif (level > VMPRESSURE_LOW) {",
            "\t\t\t/*",
            "\t\t\t * Let the socket buffer allocator know that",
            "\t\t\t * we are having trouble reclaiming LRU pages.",
            "\t\t\t *",
            "\t\t\t * For hysteresis keep the pressure state",
            "\t\t\t * asserted for a second in which subsequent",
            "\t\t\t * pressure events can occur.",
            "\t\t\t */",
            "\t\t\tWRITE_ONCE(memcg->socket_pressure, jiffies + HZ);",
            "\t\t}",
            "\t}",
            "}"
          ],
          "function_name": "vmpressure_level, vmpressure_calc_level, vmpressure_event, vmpressure_work_fn, vmpressure",
          "description": "实现内存压力计算和事件触发逻辑，vmpressure_level计算压力等级，vmpressure_calc_level基于扫描与回收比确定压力值，vmpressure_event处理事件通知，vmpressure_work_fn执行压力分析并触发相应操作",
          "similarity": 0.5684287548065186
        },
        {
          "chunk_id": 0,
          "file_path": "mm/vmpressure.c",
          "start_line": 1,
          "end_line": 110,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Linux VM pressure",
            " *",
            " * Copyright 2012 Linaro Ltd.",
            " *\t\t  Anton Vorontsov <anton.vorontsov@linaro.org>",
            " *",
            " * Based on ideas from Andrew Morton, David Rientjes, KOSAKI Motohiro,",
            " * Leonid Moiseichuk, Mel Gorman, Minchan Kim and Pekka Enberg.",
            " */",
            "",
            "#include <linux/cgroup.h>",
            "#include <linux/fs.h>",
            "#include <linux/log2.h>",
            "#include <linux/sched.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/eventfd.h>",
            "#include <linux/slab.h>",
            "#include <linux/swap.h>",
            "#include <linux/printk.h>",
            "#include <linux/vmpressure.h>",
            "",
            "/*",
            " * The window size (vmpressure_win) is the number of scanned pages before",
            " * we try to analyze scanned/reclaimed ratio. So the window is used as a",
            " * rate-limit tunable for the \"low\" level notification, and also for",
            " * averaging the ratio for medium/critical levels. Using small window",
            " * sizes can cause lot of false positives, but too big window size will",
            " * delay the notifications.",
            " *",
            " * As the vmscan reclaimer logic works with chunks which are multiple of",
            " * SWAP_CLUSTER_MAX, it makes sense to use it for the window size as well.",
            " *",
            " * TODO: Make the window size depend on machine size, as we do for vmstat",
            " * thresholds. Currently we set it to 512 pages (2MB for 4KB pages).",
            " */",
            "static const unsigned long vmpressure_win = SWAP_CLUSTER_MAX * 16;",
            "",
            "/*",
            " * These thresholds are used when we account memory pressure through",
            " * scanned/reclaimed ratio. The current values were chosen empirically. In",
            " * essence, they are percents: the higher the value, the more number",
            " * unsuccessful reclaims there were.",
            " */",
            "static const unsigned int vmpressure_level_med = 60;",
            "static const unsigned int vmpressure_level_critical = 95;",
            "",
            "/*",
            " * When there are too little pages left to scan, vmpressure() may miss the",
            " * critical pressure as number of pages will be less than \"window size\".",
            " * However, in that case the vmscan priority will raise fast as the",
            " * reclaimer will try to scan LRUs more deeply.",
            " *",
            " * The vmscan logic considers these special priorities:",
            " *",
            " * prio == DEF_PRIORITY (12): reclaimer starts with that value",
            " * prio <= DEF_PRIORITY - 2 : kswapd becomes somewhat overwhelmed",
            " * prio == 0                : close to OOM, kernel scans every page in an lru",
            " *",
            " * Any value in this range is acceptable for this tunable (i.e. from 12 to",
            " * 0). Current value for the vmpressure_level_critical_prio is chosen",
            " * empirically, but the number, in essence, means that we consider",
            " * critical level when scanning depth is ~10% of the lru size (vmscan",
            " * scans 'lru_size >> prio' pages, so it is actually 12.5%, or one",
            " * eights).",
            " */",
            "static const unsigned int vmpressure_level_critical_prio = ilog2(100 / 10);",
            "",
            "static struct vmpressure *work_to_vmpressure(struct work_struct *work)",
            "{",
            "\treturn container_of(work, struct vmpressure, work);",
            "}",
            "",
            "static struct vmpressure *vmpressure_parent(struct vmpressure *vmpr)",
            "{",
            "\tstruct mem_cgroup *memcg = vmpressure_to_memcg(vmpr);",
            "",
            "\tmemcg = parent_mem_cgroup(memcg);",
            "\tif (!memcg)",
            "\t\treturn NULL;",
            "\treturn memcg_to_vmpressure(memcg);",
            "}",
            "",
            "enum vmpressure_levels {",
            "\tVMPRESSURE_LOW = 0,",
            "\tVMPRESSURE_MEDIUM,",
            "\tVMPRESSURE_CRITICAL,",
            "\tVMPRESSURE_NUM_LEVELS,",
            "};",
            "",
            "enum vmpressure_modes {",
            "\tVMPRESSURE_NO_PASSTHROUGH = 0,",
            "\tVMPRESSURE_HIERARCHY,",
            "\tVMPRESSURE_LOCAL,",
            "\tVMPRESSURE_NUM_MODES,",
            "};",
            "",
            "static const char * const vmpressure_str_levels[] = {",
            "\t[VMPRESSURE_LOW] = \"low\",",
            "\t[VMPRESSURE_MEDIUM] = \"medium\",",
            "\t[VMPRESSURE_CRITICAL] = \"critical\",",
            "};",
            "",
            "static const char * const vmpressure_str_modes[] = {",
            "\t[VMPRESSURE_NO_PASSTHROUGH] = \"default\",",
            "\t[VMPRESSURE_HIERARCHY] = \"hierarchy\",",
            "\t[VMPRESSURE_LOCAL] = \"local\",",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义内存压力监控的相关常量和枚举类型，其中vmpressure_win设置扫描窗口大小，vmpressure_level_med和vmpressure_level_critical定义压力阈值，枚举类型表示压力等级和模式，用于后续压力检测逻辑",
          "similarity": 0.5321115255355835
        },
        {
          "chunk_id": 2,
          "file_path": "mm/vmpressure.c",
          "start_line": 335,
          "end_line": 432,
          "content": [
            "void vmpressure_prio(gfp_t gfp, struct mem_cgroup *memcg, int prio)",
            "{",
            "\t/*",
            "\t * We only use prio for accounting critical level. For more info",
            "\t * see comment for vmpressure_level_critical_prio variable above.",
            "\t */",
            "\tif (prio > vmpressure_level_critical_prio)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * OK, the prio is below the threshold, updating vmpressure",
            "\t * information before shrinker dives into long shrinking of long",
            "\t * range vmscan. Passing scanned = vmpressure_win, reclaimed = 0",
            "\t * to the vmpressure() basically means that we signal 'critical'",
            "\t * level.",
            "\t */",
            "\tvmpressure(gfp, memcg, true, vmpressure_win, 0);",
            "}",
            "int vmpressure_register_event(struct mem_cgroup *memcg,",
            "\t\t\t      struct eventfd_ctx *eventfd, const char *args)",
            "{",
            "\tstruct vmpressure *vmpr = memcg_to_vmpressure(memcg);",
            "\tstruct vmpressure_event *ev;",
            "\tenum vmpressure_modes mode = VMPRESSURE_NO_PASSTHROUGH;",
            "\tenum vmpressure_levels level;",
            "\tchar *spec, *spec_orig;",
            "\tchar *token;",
            "\tint ret = 0;",
            "",
            "\tspec_orig = spec = kstrndup(args, MAX_VMPRESSURE_ARGS_LEN, GFP_KERNEL);",
            "\tif (!spec)",
            "\t\treturn -ENOMEM;",
            "",
            "\t/* Find required level */",
            "\ttoken = strsep(&spec, \",\");",
            "\tret = match_string(vmpressure_str_levels, VMPRESSURE_NUM_LEVELS, token);",
            "\tif (ret < 0)",
            "\t\tgoto out;",
            "\tlevel = ret;",
            "",
            "\t/* Find optional mode */",
            "\ttoken = strsep(&spec, \",\");",
            "\tif (token) {",
            "\t\tret = match_string(vmpressure_str_modes, VMPRESSURE_NUM_MODES, token);",
            "\t\tif (ret < 0)",
            "\t\t\tgoto out;",
            "\t\tmode = ret;",
            "\t}",
            "",
            "\tev = kzalloc(sizeof(*ev), GFP_KERNEL);",
            "\tif (!ev) {",
            "\t\tret = -ENOMEM;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tev->efd = eventfd;",
            "\tev->level = level;",
            "\tev->mode = mode;",
            "",
            "\tmutex_lock(&vmpr->events_lock);",
            "\tlist_add(&ev->node, &vmpr->events);",
            "\tmutex_unlock(&vmpr->events_lock);",
            "\tret = 0;",
            "out:",
            "\tkfree(spec_orig);",
            "\treturn ret;",
            "}",
            "void vmpressure_unregister_event(struct mem_cgroup *memcg,",
            "\t\t\t\t struct eventfd_ctx *eventfd)",
            "{",
            "\tstruct vmpressure *vmpr = memcg_to_vmpressure(memcg);",
            "\tstruct vmpressure_event *ev;",
            "",
            "\tmutex_lock(&vmpr->events_lock);",
            "\tlist_for_each_entry(ev, &vmpr->events, node) {",
            "\t\tif (ev->efd != eventfd)",
            "\t\t\tcontinue;",
            "\t\tlist_del(&ev->node);",
            "\t\tkfree(ev);",
            "\t\tbreak;",
            "\t}",
            "\tmutex_unlock(&vmpr->events_lock);",
            "}",
            "void vmpressure_init(struct vmpressure *vmpr)",
            "{",
            "\tspin_lock_init(&vmpr->sr_lock);",
            "\tmutex_init(&vmpr->events_lock);",
            "\tINIT_LIST_HEAD(&vmpr->events);",
            "\tINIT_WORK(&vmpr->work, vmpressure_work_fn);",
            "}",
            "void vmpressure_cleanup(struct vmpressure *vmpr)",
            "{",
            "\t/*",
            "\t * Make sure there is no pending work before eventfd infrastructure",
            "\t * goes away.",
            "\t */",
            "\tflush_work(&vmpr->work);",
            "}"
          ],
          "function_name": "vmpressure_prio, vmpressure_register_event, vmpressure_unregister_event, vmpressure_init, vmpressure_cleanup",
          "description": "提供压力优先级处理、事件注册注销及资源初始化清理功能，vmpressure_prio根据优先级触发压力检测，注册事件接口用于订阅压力状态变化，初始化函数配置锁和工作队列，清理函数确保资源正确释放",
          "similarity": 0.51658034324646
        }
      ]
    },
    {
      "source_file": "mm/memory_hotplug.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:43:14\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memory_hotplug.c`\n\n---\n\n# memory_hotplug.c 技术文档\n\n## 1. 文件概述\n\n`memory_hotplug.c` 是 Linux 内核中实现内存热插拔（Memory Hotplug）功能的核心源文件，位于 `mm/` 子系统目录下。该文件提供了在系统运行时动态添加或移除物理内存区域的能力，包括内存资源注册、页表映射管理、内存上线策略控制、以及与 NUMA 架构的协同支持。它主要处理热添加内存时的初始化、内存块（memory block）管理、vmemmap 映射优化、以及在线策略配置等关键逻辑。\n\n## 2. 核心功能\n\n### 主要全局变量与参数\n- `memmap_mode`：控制是否启用“内存上的 memmap”（memmap on memory）特性，支持 `disable`、`enable` 和 `force` 三种模式。\n- `online_policy`：定义内存上线时的默认区域分配策略，可选 `contig-zones`（保持区域连续）或 `auto-movable`（自动分配到 ZONE_MOVABLE）。\n- `auto_movable_ratio`：在 `auto-movable` 策略下，系统允许的 MOVABLE 与 KERNEL 内存的最大百分比比例（默认 301%，即约 3:1）。\n- `auto_movable_numa_aware`（仅 CONFIG_NUMA）：是否在 `auto-movable` 策略中考虑 NUMA 节点级别的内存统计。\n- `mhp_default_online_type`：内存热插拔时的默认上线类型（如 `MMOP_ONLINE_KERNEL`、`MMOP_ONLINE_MOVABLE` 等）。\n- `movable_node_enabled`：标志是否启用了可移动节点（movable node）功能。\n- `max_mem_size`：系统允许的最大内存大小上限（默认为 `U64_MAX`）。\n\n### 主要函数与接口\n- `get_online_mems()` / `put_online_mems()`：获取/释放内存热插拔读锁，用于保护内存上线/下线操作。\n- `mem_hotplug_begin()` / `mem_hotplug_done()`：执行内存热插拔写操作前后的同步原语，同时持有 CPU 热插拔读锁和内存热插拔写锁。\n- `mhp_get_default_online_type()` / `mhp_set_default_online_type()`：获取或设置内存热插拔的默认上线类型。\n- `register_memory_resource()`：将新添加的内存区域注册为 I/O 资源（`System RAM` 类型），并检查是否超出 `max_mem_size` 限制。\n- `mhp_memmap_on_memory()`：判断当前是否启用了 memmap on memory 特性。\n- `memory_block_memmap_on_memory_pages()`：计算在 memmap on memory 模式下，每个内存块所需的额外页数（可能因对齐而浪费内存）。\n\n### 回调机制\n- `online_page_callback`：指向当前用于上线单个页面的回调函数，默认为 `generic_online_page`。\n- `set_online_page_callback()` / `restore_online_page_callback()`（声明未在片段中，但有注释说明）：用于动态替换或恢复页面上线回调。\n\n### 内核参数（module_param）\n- `memmap_on_memory`：启用 memmap on memory 功能（Y/N/force）。\n- `online_policy`：设置默认上线策略。\n- `auto_movable_ratio`：设置 MOVABLE/KERNEL 内存比例上限。\n- `auto_movable_numa_aware`：是否在 NUMA 感知下应用 auto-movable 策略。\n- 启动参数 `memhp_default_state=`：通过内核命令行设置默认上线状态。\n\n## 3. 关键实现\n\n### Memmap on Memory 机制\n当启用 `CONFIG_MHP_MEMMAP_ON_MEMORY` 时，内核尝试将描述物理页的 `struct page` 数组（即 vmemmap）直接放置在待热插拔的内存区域内，而非依赖预先保留的虚拟地址空间。这减少了对固定 vmemmap 区域的依赖，提升灵活性：\n- **ENABLE 模式**：仅当 vmemmap 大小能被页块（pageblock）整除时才启用。\n- **FORCE 模式**：强制对齐到页块边界，即使造成内存浪费（通过 `pageblock_align()` 实现），确保总能使用该内存区域存放 memmap。\n\n### 内存上线策略\n- **contig-zones（默认）**：将新内存添加到现有内存区域末尾，保持 ZONE_NORMAL 等区域的物理连续性。\n- **auto-movable**：根据全局（及 NUMA 节点）的 KERNEL 与 MOVABLE 内存比例，智能决定是否将新内存加入 ZONE_MOVABLE，以提高内存可迁移性和碎片整理效率。比例由 `auto_movable_ratio` 控制。\n\n### 并发控制\n使用 `percpu_rwsem mem_hotplug_lock` 作为内存热插拔操作的主同步机制：\n- 读操作（如内存访问路径）调用 `get/put_online_mems()` 获取读锁。\n- 写操作（如 add_memory）调用 `mem_hotplug_begin/done()` 获取写锁，并同时持有 `cpus_read_lock()` 防止 CPU 热插拔干扰。\n\n### 资源与大小限制\n- 通过 `mhp_range_allowed()` 检查待添加内存是否超出 `max_mem_size`。\n- 使用 `register_memory_resource()` 将内存注册为 `IORESOURCE_SYSTEM_RAM` 资源，若资源名非 \"System RAM\" 则标记为驱动管理（`IORESOURCE_SYSRAM_DRIVER_MANAGED`）。\n\n## 4. 依赖关系\n\n- **内存管理子系统**：依赖 `mm.h`、`page-isolation.h`、`migrate.h`、`compaction.h` 等，用于页面分配、隔离、迁移和压缩。\n- **体系结构相关**：包含 `asm/tlbflush.h` 用于 TLB 刷新；依赖 `pfn.h`、`memblock.h` 处理物理页帧和启动内存布局。\n- **设备模型与 sysfs**：通过 `memory.h` 与用户空间交互（如 `/sys/devices/system/memory/`）。\n- **NUMA 支持**：在 `CONFIG_NUMA` 下使用节点感知策略。\n- **虚拟内存**：依赖 `vmalloc.h` 和 `memremap.h` 管理 vmemmap 映射。\n- **电源管理**：包含 `suspend.h`，可能与休眠/唤醒流程协调。\n- **固件接口**：使用 `firmware-map.h` 与平台固件交互内存布局信息。\n\n## 5. 使用场景\n\n- **物理内存热添加**：在支持内存热插拔的服务器（如 IBM Power、x86 ACPI 系统）上，动态增加 DIMM 或内存模块后，内核通过此文件完成内存初始化和上线。\n- **虚拟化环境**：KVM、Xen 等 hypervisor 向客户机热添加内存时，客户机内核调用此模块处理新增内存。\n- **内存故障恢复**：在某些 RAS（Reliability, Availability, Serviceability）场景中，隔离坏页后重新上线备用内存。\n- **测试与开发**：通过 sysfs 接口（如 `echo online > /sys/devices/system/memory/memoryX/state`）手动上线内存块，配合 `online_policy` 和 `memmap_on_memory` 参数进行功能验证。\n- **容器与云平台**：支持弹性内存扩展，按需分配物理内存资源。",
      "similarity": 0.5367620587348938,
      "chunks": [
        {
          "chunk_id": 9,
          "file_path": "mm/memory_hotplug.c",
          "start_line": 1529,
          "end_line": 1660,
          "content": [
            "int __ref __add_memory(int nid, u64 start, u64 size, mhp_t mhp_flags)",
            "{",
            "\tstruct resource *res;",
            "\tint ret;",
            "",
            "\tres = register_memory_resource(start, size, \"System RAM\");",
            "\tif (IS_ERR(res))",
            "\t\treturn PTR_ERR(res);",
            "",
            "\tret = add_memory_resource(nid, res, mhp_flags);",
            "\tif (ret < 0)",
            "\t\trelease_memory_resource(res);",
            "\treturn ret;",
            "}",
            "int add_memory(int nid, u64 start, u64 size, mhp_t mhp_flags)",
            "{",
            "\tint rc;",
            "",
            "\tlock_device_hotplug();",
            "\trc = __add_memory(nid, start, size, mhp_flags);",
            "\tunlock_device_hotplug();",
            "",
            "\treturn rc;",
            "}",
            "int add_memory_driver_managed(int nid, u64 start, u64 size,",
            "\t\t\t      const char *resource_name, mhp_t mhp_flags)",
            "{",
            "\tstruct resource *res;",
            "\tint rc;",
            "",
            "\tif (!resource_name ||",
            "\t    strstr(resource_name, \"System RAM (\") != resource_name ||",
            "\t    resource_name[strlen(resource_name) - 1] != ')')",
            "\t\treturn -EINVAL;",
            "",
            "\tlock_device_hotplug();",
            "",
            "\tres = register_memory_resource(start, size, resource_name);",
            "\tif (IS_ERR(res)) {",
            "\t\trc = PTR_ERR(res);",
            "\t\tgoto out_unlock;",
            "\t}",
            "",
            "\trc = add_memory_resource(nid, res, mhp_flags);",
            "\tif (rc < 0)",
            "\t\trelease_memory_resource(res);",
            "",
            "out_unlock:",
            "\tunlock_device_hotplug();",
            "\treturn rc;",
            "}",
            "struct range __weak arch_get_mappable_range(void)",
            "{",
            "\tstruct range mhp_range = {",
            "\t\t.start = 0UL,",
            "\t\t.end = -1ULL,",
            "\t};",
            "\treturn mhp_range;",
            "}",
            "struct range mhp_get_pluggable_range(bool need_mapping)",
            "{",
            "\tconst u64 max_phys = PHYSMEM_END;",
            "\tstruct range mhp_range;",
            "",
            "\tif (need_mapping) {",
            "\t\tmhp_range = arch_get_mappable_range();",
            "\t\tif (mhp_range.start > max_phys) {",
            "\t\t\tmhp_range.start = 0;",
            "\t\t\tmhp_range.end = 0;",
            "\t\t}",
            "\t\tmhp_range.end = min_t(u64, mhp_range.end, max_phys);",
            "\t} else {",
            "\t\tmhp_range.start = 0;",
            "\t\tmhp_range.end = max_phys;",
            "\t}",
            "\treturn mhp_range;",
            "}",
            "bool mhp_range_allowed(u64 start, u64 size, bool need_mapping)",
            "{",
            "\tstruct range mhp_range = mhp_get_pluggable_range(need_mapping);",
            "\tu64 end = start + size;",
            "",
            "\tif (start < end && start >= mhp_range.start && (end - 1) <= mhp_range.end)",
            "\t\treturn true;",
            "",
            "\tpr_warn(\"Hotplug memory [%#llx-%#llx] exceeds maximum addressable range [%#llx-%#llx]\\n\",",
            "\t\tstart, end, mhp_range.start, mhp_range.end);",
            "\treturn false;",
            "}",
            "static int scan_movable_pages(unsigned long start, unsigned long end,",
            "\t\t\t      unsigned long *movable_pfn)",
            "{",
            "\tunsigned long pfn;",
            "",
            "\tfor_each_valid_pfn(pfn, start, end) {",
            "\t\tstruct page *page;",
            "\t\tstruct folio *folio;",
            "",
            "\t\tpage = pfn_to_page(pfn);",
            "\t\tif (PageLRU(page))",
            "\t\t\tgoto found;",
            "\t\tif (__PageMovable(page))",
            "\t\t\tgoto found;",
            "",
            "\t\t/*",
            "\t\t * PageOffline() pages that are not marked __PageMovable() and",
            "\t\t * have a reference count > 0 (after MEM_GOING_OFFLINE) are",
            "\t\t * definitely unmovable. If their reference count would be 0,",
            "\t\t * they could at least be skipped when offlining memory.",
            "\t\t */",
            "\t\tif (PageOffline(page) && page_count(page))",
            "\t\t\treturn -EBUSY;",
            "",
            "\t\tif (!PageHuge(page))",
            "\t\t\tcontinue;",
            "\t\tfolio = page_folio(page);",
            "\t\t/*",
            "\t\t * This test is racy as we hold no reference or lock.  The",
            "\t\t * hugetlb page could have been free'ed and head is no longer",
            "\t\t * a hugetlb page before the following check.  In such unlikely",
            "\t\t * cases false positives and negatives are possible.  Calling",
            "\t\t * code must deal with these scenarios.",
            "\t\t */",
            "\t\tif (folio_test_hugetlb_migratable(folio))",
            "\t\t\tgoto found;",
            "\t\tpfn |= folio_nr_pages(folio) - 1;",
            "\t}",
            "\treturn -ENOENT;",
            "found:",
            "\t*movable_pfn = pfn;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "__add_memory, add_memory, add_memory_driver_managed, arch_get_mappable_range, mhp_get_pluggable_range, mhp_range_allowed, scan_movable_pages",
          "description": "__add_memory 和 add_memory 添加内存资源；add_memory_driver_managed 处理驱动管理内存资源；arch_get_mappable_range 获取可映射范围；mhp_get_pluggable_range 确定可插入内存范围；mhp_range_allowed 检查地址有效性；scan_movable_pages 扫描可移动页面",
          "similarity": 0.5172167420387268
        },
        {
          "chunk_id": 1,
          "file_path": "mm/memory_hotplug.c",
          "start_line": 52,
          "end_line": 153,
          "content": [
            "static inline unsigned long memory_block_memmap_size(void)",
            "{",
            "\treturn PHYS_PFN(memory_block_size_bytes()) * sizeof(struct page);",
            "}",
            "static inline unsigned long memory_block_memmap_on_memory_pages(void)",
            "{",
            "\tunsigned long nr_pages = PFN_UP(memory_block_memmap_size());",
            "",
            "\t/*",
            "\t * In \"forced\" memmap_on_memory mode, we add extra pages to align the",
            "\t * vmemmap size to cover full pageblocks. That way, we can add memory",
            "\t * even if the vmemmap size is not properly aligned, however, we might waste",
            "\t * memory.",
            "\t */",
            "\tif (memmap_mode == MEMMAP_ON_MEMORY_FORCE)",
            "\t\treturn pageblock_align(nr_pages);",
            "\treturn nr_pages;",
            "}",
            "static int set_memmap_mode(const char *val, const struct kernel_param *kp)",
            "{",
            "\tint ret, mode;",
            "\tbool enabled;",
            "",
            "\tif (sysfs_streq(val, \"force\") ||  sysfs_streq(val, \"FORCE\")) {",
            "\t\tmode = MEMMAP_ON_MEMORY_FORCE;",
            "\t} else {",
            "\t\tret = kstrtobool(val, &enabled);",
            "\t\tif (ret < 0)",
            "\t\t\treturn ret;",
            "\t\tif (enabled)",
            "\t\t\tmode = MEMMAP_ON_MEMORY_ENABLE;",
            "\t\telse",
            "\t\t\tmode = MEMMAP_ON_MEMORY_DISABLE;",
            "\t}",
            "\t*((int *)kp->arg) = mode;",
            "\tif (mode == MEMMAP_ON_MEMORY_FORCE) {",
            "\t\tunsigned long memmap_pages = memory_block_memmap_on_memory_pages();",
            "",
            "\t\tpr_info_once(\"Memory hotplug will waste %ld pages in each memory block\\n\",",
            "\t\t\t     memmap_pages - PFN_UP(memory_block_memmap_size()));",
            "\t}",
            "\treturn 0;",
            "}",
            "static int get_memmap_mode(char *buffer, const struct kernel_param *kp)",
            "{",
            "\tint mode = *((int *)kp->arg);",
            "",
            "\tif (mode == MEMMAP_ON_MEMORY_FORCE)",
            "\t\treturn sprintf(buffer, \"force\\n\");",
            "\treturn sprintf(buffer, \"%c\\n\", mode ? 'Y' : 'N');",
            "}",
            "static inline bool mhp_memmap_on_memory(void)",
            "{",
            "\treturn memmap_mode != MEMMAP_ON_MEMORY_DISABLE;",
            "}",
            "static inline bool mhp_memmap_on_memory(void)",
            "{",
            "\treturn false;",
            "}",
            "static int set_online_policy(const char *val, const struct kernel_param *kp)",
            "{",
            "\tint ret = sysfs_match_string(online_policy_to_str, val);",
            "",
            "\tif (ret < 0)",
            "\t\treturn ret;",
            "\t*((int *)kp->arg) = ret;",
            "\treturn 0;",
            "}",
            "static int get_online_policy(char *buffer, const struct kernel_param *kp)",
            "{",
            "\treturn sprintf(buffer, \"%s\\n\", online_policy_to_str[*((int *)kp->arg)]);",
            "}",
            "void get_online_mems(void)",
            "{",
            "\tpercpu_down_read(&mem_hotplug_lock);",
            "}",
            "void put_online_mems(void)",
            "{",
            "\tpercpu_up_read(&mem_hotplug_lock);",
            "}",
            "int mhp_get_default_online_type(void)",
            "{",
            "\tif (mhp_default_online_type >= 0)",
            "\t\treturn mhp_default_online_type;",
            "",
            "\tif (IS_ENABLED(CONFIG_MHP_DEFAULT_ONLINE_TYPE_OFFLINE))",
            "\t\tmhp_default_online_type = MMOP_OFFLINE;",
            "\telse if (IS_ENABLED(CONFIG_MHP_DEFAULT_ONLINE_TYPE_ONLINE_AUTO))",
            "\t\tmhp_default_online_type = MMOP_ONLINE;",
            "\telse if (IS_ENABLED(CONFIG_MHP_DEFAULT_ONLINE_TYPE_ONLINE_KERNEL))",
            "\t\tmhp_default_online_type = MMOP_ONLINE_KERNEL;",
            "\telse if (IS_ENABLED(CONFIG_MHP_DEFAULT_ONLINE_TYPE_ONLINE_MOVABLE))",
            "\t\tmhp_default_online_type = MMOP_ONLINE_MOVABLE;",
            "\telse",
            "\t\tmhp_default_online_type = MMOP_OFFLINE;",
            "",
            "\treturn mhp_default_online_type;",
            "}",
            "void mhp_set_default_online_type(int online_type)",
            "{",
            "\tmhp_default_online_type = online_type;",
            "}"
          ],
          "function_name": "memory_block_memmap_size, memory_block_memmap_on_memory_pages, set_memmap_mode, get_memmap_mode, mhp_memmap_on_memory, mhp_memmap_on_memory, set_online_policy, get_online_policy, get_online_mems, put_online_mems, mhp_get_default_online_type, mhp_set_default_online_type",
          "description": "提供内存映射模式配置接口(set/get)，实现memmap_on_memory策略判断逻辑，包含在线策略设置与获取函数及默认类型处理逻辑。",
          "similarity": 0.504078209400177
        },
        {
          "chunk_id": 13,
          "file_path": "mm/memory_hotplug.c",
          "start_line": 2233,
          "end_line": 2352,
          "content": [
            "void __remove_memory(u64 start, u64 size)",
            "{",
            "",
            "\t/*",
            "\t * trigger BUG() if some memory is not offlined prior to calling this",
            "\t * function",
            "\t */",
            "\tif (try_remove_memory(start, size))",
            "\t\tBUG();",
            "}",
            "int remove_memory(u64 start, u64 size)",
            "{",
            "\tint rc;",
            "",
            "\tlock_device_hotplug();",
            "\trc = try_remove_memory(start, size);",
            "\tunlock_device_hotplug();",
            "",
            "\treturn rc;",
            "}",
            "static int try_offline_memory_block(struct memory_block *mem, void *arg)",
            "{",
            "\tuint8_t online_type = MMOP_ONLINE_KERNEL;",
            "\tuint8_t **online_types = arg;",
            "\tstruct page *page;",
            "\tint rc;",
            "",
            "\t/*",
            "\t * Sense the online_type via the zone of the memory block. Offlining",
            "\t * with multiple zones within one memory block will be rejected",
            "\t * by offlining code ... so we don't care about that.",
            "\t */",
            "\tpage = pfn_to_online_page(section_nr_to_pfn(mem->start_section_nr));",
            "\tif (page && zone_idx(page_zone(page)) == ZONE_MOVABLE)",
            "\t\tonline_type = MMOP_ONLINE_MOVABLE;",
            "",
            "\trc = device_offline(&mem->dev);",
            "\t/*",
            "\t * Default is MMOP_OFFLINE - change it only if offlining succeeded,",
            "\t * so try_reonline_memory_block() can do the right thing.",
            "\t */",
            "\tif (!rc)",
            "\t\t**online_types = online_type;",
            "",
            "\t(*online_types)++;",
            "\t/* Ignore if already offline. */",
            "\treturn rc < 0 ? rc : 0;",
            "}",
            "static int try_reonline_memory_block(struct memory_block *mem, void *arg)",
            "{",
            "\tuint8_t **online_types = arg;",
            "\tint rc;",
            "",
            "\tif (**online_types != MMOP_OFFLINE) {",
            "\t\tmem->online_type = **online_types;",
            "\t\trc = device_online(&mem->dev);",
            "\t\tif (rc < 0)",
            "\t\t\tpr_warn(\"%s: Failed to re-online memory: %d\",",
            "\t\t\t\t__func__, rc);",
            "\t}",
            "",
            "\t/* Continue processing all remaining memory blocks. */",
            "\t(*online_types)++;",
            "\treturn 0;",
            "}",
            "int offline_and_remove_memory(u64 start, u64 size)",
            "{",
            "\tconst unsigned long mb_count = size / memory_block_size_bytes();",
            "\tuint8_t *online_types, *tmp;",
            "\tint rc;",
            "",
            "\tif (!IS_ALIGNED(start, memory_block_size_bytes()) ||",
            "\t    !IS_ALIGNED(size, memory_block_size_bytes()) || !size)",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * We'll remember the old online type of each memory block, so we can",
            "\t * try to revert whatever we did when offlining one memory block fails",
            "\t * after offlining some others succeeded.",
            "\t */",
            "\tonline_types = kmalloc_array(mb_count, sizeof(*online_types),",
            "\t\t\t\t     GFP_KERNEL);",
            "\tif (!online_types)",
            "\t\treturn -ENOMEM;",
            "\t/*",
            "\t * Initialize all states to MMOP_OFFLINE, so when we abort processing in",
            "\t * try_offline_memory_block(), we'll skip all unprocessed blocks in",
            "\t * try_reonline_memory_block().",
            "\t */",
            "\tmemset(online_types, MMOP_OFFLINE, mb_count);",
            "",
            "\tlock_device_hotplug();",
            "",
            "\ttmp = online_types;",
            "\trc = walk_memory_blocks(start, size, &tmp, try_offline_memory_block);",
            "",
            "\t/*",
            "\t * In case we succeeded to offline all memory, remove it.",
            "\t * This cannot fail as it cannot get onlined in the meantime.",
            "\t */",
            "\tif (!rc) {",
            "\t\trc = try_remove_memory(start, size);",
            "\t\tif (rc)",
            "\t\t\tpr_err(\"%s: Failed to remove memory: %d\", __func__, rc);",
            "\t}",
            "",
            "\t/*",
            "\t * Rollback what we did. While memory onlining might theoretically fail",
            "\t * (nacked by a notifier), it barely ever happens.",
            "\t */",
            "\tif (rc) {",
            "\t\ttmp = online_types;",
            "\t\twalk_memory_blocks(start, size, &tmp,",
            "\t\t\t\t   try_reonline_memory_block);",
            "\t}",
            "\tunlock_device_hotplug();",
            "",
            "\tkfree(online_types);",
            "\treturn rc;",
            "}"
          ],
          "function_name": "__remove_memory, remove_memory, try_offline_memory_block, try_reonline_memory_block, offline_and_remove_memory",
          "description": "offline_and_remove_memory 管理内存块的离线与移除流程，记录各内存块原始在线类型，在部分失败时回滚操作；try_offline_memory_block 和 try_reonline_memory_block 分别用于设置内存块离线状态及恢复在线状态",
          "similarity": 0.49114862084388733
        },
        {
          "chunk_id": 0,
          "file_path": "mm/memory_hotplug.c",
          "start_line": 1,
          "end_line": 51,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " *  linux/mm/memory_hotplug.c",
            " *",
            " *  Copyright (C)",
            " */",
            "",
            "#include <linux/stddef.h>",
            "#include <linux/mm.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/swap.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/compiler.h>",
            "#include <linux/export.h>",
            "#include <linux/writeback.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/cpu.h>",
            "#include <linux/memory.h>",
            "#include <linux/memremap.h>",
            "#include <linux/memory_hotplug.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/ioport.h>",
            "#include <linux/delay.h>",
            "#include <linux/migrate.h>",
            "#include <linux/page-isolation.h>",
            "#include <linux/pfn.h>",
            "#include <linux/suspend.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/firmware-map.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/memblock.h>",
            "#include <linux/compaction.h>",
            "#include <linux/rmap.h>",
            "#include <linux/module.h>",
            "",
            "#include <asm/tlbflush.h>",
            "",
            "#include \"internal.h\"",
            "#include \"shuffle.h\"",
            "",
            "enum {",
            "\tMEMMAP_ON_MEMORY_DISABLE = 0,",
            "\tMEMMAP_ON_MEMORY_ENABLE,",
            "\tMEMMAP_ON_MEMORY_FORCE,",
            "};",
            "",
            "static int memmap_mode __read_mostly = MEMMAP_ON_MEMORY_DISABLE;",
            ""
          ],
          "function_name": null,
          "description": "声明内存热插拔相关枚举常量和全局变量，定义memmap_mode控制内存映射策略，包含必要的内核头文件和模块化实现依赖项。",
          "similarity": 0.4901905059814453
        },
        {
          "chunk_id": 2,
          "file_path": "mm/memory_hotplug.c",
          "start_line": 247,
          "end_line": 355,
          "content": [
            "static int __init setup_memhp_default_state(char *str)",
            "{",
            "\tconst int online_type = mhp_online_type_from_str(str);",
            "",
            "\tif (online_type >= 0)",
            "\t\tmhp_default_online_type = online_type;",
            "",
            "\treturn 1;",
            "}",
            "void mem_hotplug_begin(void)",
            "{",
            "\tcpus_read_lock();",
            "\tpercpu_down_write(&mem_hotplug_lock);",
            "}",
            "void mem_hotplug_done(void)",
            "{",
            "\tpercpu_up_write(&mem_hotplug_lock);",
            "\tcpus_read_unlock();",
            "}",
            "static void release_memory_resource(struct resource *res)",
            "{",
            "\tif (!res)",
            "\t\treturn;",
            "\trelease_resource(res);",
            "\tkfree(res);",
            "}",
            "static int check_pfn_span(unsigned long pfn, unsigned long nr_pages)",
            "{",
            "\t/*",
            "\t * Disallow all operations smaller than a sub-section and only",
            "\t * allow operations smaller than a section for",
            "\t * SPARSEMEM_VMEMMAP. Note that check_hotplug_memory_range()",
            "\t * enforces a larger memory_block_size_bytes() granularity for",
            "\t * memory that will be marked online, so this check should only",
            "\t * fire for direct arch_{add,remove}_memory() users outside of",
            "\t * add_memory_resource().",
            "\t */",
            "\tunsigned long min_align;",
            "",
            "\tif (IS_ENABLED(CONFIG_SPARSEMEM_VMEMMAP))",
            "\t\tmin_align = PAGES_PER_SUBSECTION;",
            "\telse",
            "\t\tmin_align = PAGES_PER_SECTION;",
            "\tif (!IS_ALIGNED(pfn | nr_pages, min_align))",
            "\t\treturn -EINVAL;",
            "\treturn 0;",
            "}",
            "int __ref __add_pages(int nid, unsigned long pfn, unsigned long nr_pages,",
            "\t\tstruct mhp_params *params)",
            "{",
            "\tconst unsigned long end_pfn = pfn + nr_pages;",
            "\tunsigned long cur_nr_pages;",
            "\tint err;",
            "\tstruct vmem_altmap *altmap = params->altmap;",
            "",
            "\tif (WARN_ON_ONCE(!pgprot_val(params->pgprot)))",
            "\t\treturn -EINVAL;",
            "",
            "\tVM_BUG_ON(!mhp_range_allowed(PFN_PHYS(pfn), nr_pages * PAGE_SIZE, false));",
            "",
            "\tif (altmap) {",
            "\t\t/*",
            "\t\t * Validate altmap is within bounds of the total request",
            "\t\t */",
            "\t\tif (altmap->base_pfn != pfn",
            "\t\t\t\t|| vmem_altmap_offset(altmap) > nr_pages) {",
            "\t\t\tpr_warn_once(\"memory add fail, invalid altmap\\n\");",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "\t\taltmap->alloc = 0;",
            "\t}",
            "",
            "\tif (check_pfn_span(pfn, nr_pages)) {",
            "\t\tWARN(1, \"Misaligned %s start: %#lx end: %#lx\\n\", __func__, pfn, pfn + nr_pages - 1);",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tfor (; pfn < end_pfn; pfn += cur_nr_pages) {",
            "\t\t/* Select all remaining pages up to the next section boundary */",
            "\t\tcur_nr_pages = min(end_pfn - pfn,",
            "\t\t\t\t   SECTION_ALIGN_UP(pfn + 1) - pfn);",
            "\t\terr = sparse_add_section(nid, pfn, cur_nr_pages, altmap,",
            "\t\t\t\t\t params->pgmap);",
            "\t\tif (err)",
            "\t\t\tbreak;",
            "\t\tcond_resched();",
            "\t}",
            "\tvmemmap_populate_print_last();",
            "\treturn err;",
            "}",
            "static unsigned long find_smallest_section_pfn(int nid, struct zone *zone,",
            "\t\t\t\t     unsigned long start_pfn,",
            "\t\t\t\t     unsigned long end_pfn)",
            "{",
            "\tfor (; start_pfn < end_pfn; start_pfn += PAGES_PER_SUBSECTION) {",
            "\t\tif (unlikely(!pfn_to_online_page(start_pfn)))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (unlikely(pfn_to_nid(start_pfn) != nid))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (zone != page_zone(pfn_to_page(start_pfn)))",
            "\t\t\tcontinue;",
            "",
            "\t\treturn start_pfn;",
            "\t}",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "setup_memhp_default_state, mem_hotplug_begin, mem_hotplug_done, release_memory_resource, check_pfn_span, __add_pages, find_smallest_section_pfn",
          "description": "初始化内存热插拔默认状态，实现内存热插拔锁操作，验证PFN对齐有效性，执行内存添加操作并处理替代映射信息。",
          "similarity": 0.47936755418777466
        }
      ]
    },
    {
      "source_file": "kernel/sched/psi.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:14:11\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\psi.c`\n\n---\n\n# `sched/psi.c` 技术文档\n\n## 1. 文件概述\n\n`sched/psi.c` 实现了 **压力失速信息**（Pressure Stall Information, PSI）机制，用于监控和量化系统在 CPU、内存和 I/O 资源上的争用压力。该机制通过测量任务因资源不足而延迟执行的时间比例，提供两类关键指标：\n\n- **SOME**：表示至少有一个任务因资源争用而延迟，反映工作负载性能下降。\n- **FULL**：表示所有非空闲任务均被阻塞，导致 CPU 完全无法推进工作，反映资源利用率损失。\n\nPSI 为系统管理员和容器运行时（如 cgroup）提供细粒度的资源压力感知能力，用于负载调度、自动扩缩容和性能调优。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct psi_group`  \n  表示一个 PSI 监控组（如系统级或 cgroup 级），包含：\n  - 每 CPU 的状态统计（`pcpu`）\n  - 压力平均值（10s/60s/300s）\n  - 触发器列表（用于通知用户空间）\n  - 定时器与工作队列（用于周期性更新）\n\n- `struct psi_group_cpu`  \n  每 CPU 的 PSI 状态快照，记录：\n  - 延迟任务数（`nr_delayed`）\n  - 有效任务数（`nr_productive`）\n  - 非空闲任务数（`nr_nonidle`）\n  - 各状态的累计时间（`tstamp`、`state_start` 等）\n\n- `psi_system`  \n  全局系统级 PSI 组实例。\n\n### 主要函数与机制\n\n- `psi_write_begin()` / `psi_write_end()`  \n  使用 `seqcount_t` 保护每 CPU PSI 状态写入，确保读取一致性。\n\n- `psi_read_begin()` / `psi_read_retry()`  \n  提供无锁读取接口，配合 seqcount 实现安全的跨 CPU 状态聚合。\n\n- `group_init()`  \n  初始化 PSI 组，包括锁、触发器链表、延迟工作队列等。\n\n- `psi_avgs_work()`  \n  延迟工作函数，用于计算并更新滑动窗口下的压力平均值（10s/60s/300s）。\n\n- `poll_timer_fn()`  \n  轮询定时器回调，支持用户空间通过轮询方式获取 PSI 更新。\n\n- `setup_psi()`  \n  内核启动参数 `psi=` 的解析函数，用于动态启用/禁用 PSI。\n\n### 全局变量\n\n- `psi_disabled` / `psi_cgroups_enabled`  \n  静态分支预测键，用于在编译时或运行时优化 PSI 路径。\n\n- `psi_enable`  \n  控制 PSI 是否默认启用（受 `CONFIG_PSI_DEFAULT_DISABLED` 影响）。\n\n- `psi_period`  \n  PSI 采样周期（单位：纳秒），默认为 2 秒（`PSI_FREQ = 2*HZ+1`）。\n\n- `EXP_10s` / `EXP_60s` / `EXP_300s`  \n  指数加权移动平均（EWMA）的衰减系数，用于计算不同时间窗口的压力均值。\n\n## 3. 关键实现\n\n### 压力模型\n\nPSI 基于 **执行潜力损失** 模型：\n- **SOME** = `min(nr_delayed / threads, 1)`  \n- **FULL** = `(threads - min(nr_productive, threads)) / threads`  \n其中 `threads = min(nr_nonidle_tasks, nr_cpus)`，反映系统实际可并行执行的线程数。\n\n### 多 CPU 聚合策略\n\n为避免全局锁开销，PSI 采用 **每 CPU 局部统计 + 周期性聚合** 策略：\n- 每个 runqueue 独立记录 `tSOME[cpu]`、`tFULL[cpu]` 和 `tNONIDLE[cpu]`\n- 聚合时加权平均：  \n  `tSOME = Σ(tSOME[i] * tNONIDLE[i]) / Σ(tNONIDLE[i])`  \n  该方法在低开销下逼近真实全局压力。\n\n### 无锁读取与一致性\n\n使用 `seqcount_t` 机制：\n- 写入时调用 `write_seqcount_begin/end()`\n- 读取时通过 `read_seqcount_begin/retry()` 检测写冲突，必要时重试\n- 避免读写锁，提升高并发下的性能\n\n### 平均值计算\n\n采用 **指数加权移动平均**（EWMA）计算 10s/60s/300s 压力均值：\n- 每 2 秒更新一次（`PSI_FREQ`）\n- 衰减因子预计算为定点整数（如 `EXP_10s = 1677` 对应 `1/exp(2/10)`）\n\n### 触发器支持\n\n支持两类触发器：\n- **平均值触发器**（`avg_triggers`）：当某窗口平均压力超过阈值时通知\n- **实时轮询触发器**（`rtpoll_triggers`）：支持用户空间高效轮询\n\n## 4. 依赖关系\n\n- **调度器核心**（`kernel/sched/`）  \n  PSI 深度集成于 CFS 调度器，在任务入队/出队、睡眠/唤醒等路径调用 PSI 接口更新状态。\n\n- **cgroup 子系统**  \n  PSI 为每个支持的 cgroup（如 cpu、memory）创建独立的 `psi_group`，实现容器级资源压力监控。\n\n- **时间子系统**  \n  依赖 `sched_clock()` 获取高精度时间戳，用于状态持续时间计算。\n\n- **工作队列与定时器**  \n  使用 `delayed_work` 和 `timer_list` 实现异步平均值更新和轮询通知。\n\n- **配置选项**  \n  由 `CONFIG_PSI` 控制编译，`CONFIG_PSI_DEFAULT_DISABLED` 控制默认启用状态。\n\n## 5. 使用场景\n\n- **系统监控工具**（如 `pressure` 文件）  \n  用户可通过 `/proc/pressure/{cpu,memory,io}` 读取系统级 PSI 数据。\n\n- **容器运行时**（如 Docker、Kubernetes）  \n  通过 cgroup v2 的 `memory.pressure`、`cpu.pressure` 等接口获取容器内压力指标，用于弹性伸缩或驱逐决策。\n\n- **内核自适应调度**  \n  PSI 数据可被其他子系统（如内存回收、负载均衡）用作反馈信号，优化资源分配。\n\n- **性能分析与调优**  \n  开发者利用 PSI 识别资源瓶颈（如内存回收导致的 FULL stall），定位性能下降根因。",
      "similarity": 0.5241402387619019,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/psi.c",
          "start_line": 338,
          "end_line": 442,
          "content": [
            "static void calc_avgs(unsigned long avg[3], int missed_periods,",
            "\t\t      u64 time, u64 period)",
            "{",
            "\tunsigned long pct;",
            "",
            "\t/* Fill in zeroes for periods of no activity */",
            "\tif (missed_periods) {",
            "\t\tavg[0] = calc_load_n(avg[0], EXP_10s, 0, missed_periods);",
            "\t\tavg[1] = calc_load_n(avg[1], EXP_60s, 0, missed_periods);",
            "\t\tavg[2] = calc_load_n(avg[2], EXP_300s, 0, missed_periods);",
            "\t}",
            "",
            "\t/* Sample the most recent active period */",
            "\tpct = div_u64(time * 100, period);",
            "\tpct *= FIXED_1;",
            "\tavg[0] = calc_load(avg[0], EXP_10s, pct);",
            "\tavg[1] = calc_load(avg[1], EXP_60s, pct);",
            "\tavg[2] = calc_load(avg[2], EXP_300s, pct);",
            "}",
            "static void collect_percpu_times(struct psi_group *group,",
            "\t\t\t\t enum psi_aggregators aggregator,",
            "\t\t\t\t u32 *pchanged_states)",
            "{",
            "\tu64 deltas[NR_PSI_STATES - 1] = { 0, };",
            "\tunsigned long nonidle_total = 0;",
            "\tu32 changed_states = 0;",
            "\tint cpu;",
            "\tint s;",
            "",
            "\t/*",
            "\t * Collect the per-cpu time buckets and average them into a",
            "\t * single time sample that is normalized to wallclock time.",
            "\t *",
            "\t * For averaging, each CPU is weighted by its non-idle time in",
            "\t * the sampling period. This eliminates artifacts from uneven",
            "\t * loading, or even entirely idle CPUs.",
            "\t */",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tu32 times[NR_PSI_STATES];",
            "\t\tu32 nonidle;",
            "\t\tu32 cpu_changed_states;",
            "",
            "\t\tget_recent_times(group, cpu, aggregator, times,",
            "\t\t\t\t&cpu_changed_states);",
            "\t\tchanged_states |= cpu_changed_states;",
            "",
            "\t\tnonidle = nsecs_to_jiffies(times[PSI_NONIDLE]);",
            "\t\tnonidle_total += nonidle;",
            "",
            "\t\tfor (s = 0; s < PSI_NONIDLE; s++)",
            "\t\t\tdeltas[s] += (u64)times[s] * nonidle;",
            "\t}",
            "",
            "\t/*",
            "\t * Integrate the sample into the running statistics that are",
            "\t * reported to userspace: the cumulative stall times and the",
            "\t * decaying averages.",
            "\t *",
            "\t * Pressure percentages are sampled at PSI_FREQ. We might be",
            "\t * called more often when the user polls more frequently than",
            "\t * that; we might be called less often when there is no task",
            "\t * activity, thus no data, and clock ticks are sporadic. The",
            "\t * below handles both.",
            "\t */",
            "",
            "\t/* total= */",
            "\tfor (s = 0; s < NR_PSI_STATES - 1; s++)",
            "\t\tgroup->total[aggregator][s] +=",
            "\t\t\t\tdiv_u64(deltas[s], max(nonidle_total, 1UL));",
            "",
            "\tif (pchanged_states)",
            "\t\t*pchanged_states = changed_states;",
            "}",
            "static void window_reset(struct psi_window *win, u64 now, u64 value,",
            "\t\t\t u64 prev_growth)",
            "{",
            "\twin->start_time = now;",
            "\twin->start_value = value;",
            "\twin->prev_growth = prev_growth;",
            "}",
            "static u64 window_update(struct psi_window *win, u64 now, u64 value)",
            "{",
            "\tu64 elapsed;",
            "\tu64 growth;",
            "",
            "\telapsed = now - win->start_time;",
            "\tgrowth = value - win->start_value;",
            "\t/*",
            "\t * After each tracking window passes win->start_value and",
            "\t * win->start_time get reset and win->prev_growth stores",
            "\t * the average per-window growth of the previous window.",
            "\t * win->prev_growth is then used to interpolate additional",
            "\t * growth from the previous window assuming it was linear.",
            "\t */",
            "\tif (elapsed > win->size)",
            "\t\twindow_reset(win, now, value, growth);",
            "\telse {",
            "\t\tu32 remaining;",
            "",
            "\t\tremaining = win->size - elapsed;",
            "\t\tgrowth += div64_u64(win->prev_growth * remaining, win->size);",
            "\t}",
            "",
            "\treturn growth;",
            "}"
          ],
          "function_name": "calc_avgs, collect_percpu_times, window_reset, window_update",
          "description": "计算加权平均压力值，汇总各CPU的统计时间并归一化到总时间，维护时间窗口增长记录以防止数据溢出。",
          "similarity": 0.5883059501647949
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/sched/psi.c",
          "start_line": 459,
          "end_line": 582,
          "content": [
            "static u64 update_triggers(struct psi_group *group, u64 now, bool *update_total,",
            "\t\t\t\t\t\t   enum psi_aggregators aggregator)",
            "{",
            "\tstruct psi_trigger *t;",
            "\tu64 *total = group->total[aggregator];",
            "\tstruct list_head *triggers;",
            "\tu64 *aggregator_total;",
            "\t*update_total = false;",
            "",
            "\tif (aggregator == PSI_AVGS) {",
            "\t\ttriggers = &group->avg_triggers;",
            "\t\taggregator_total = group->avg_total;",
            "\t} else {",
            "\t\ttriggers = &group->rtpoll_triggers;",
            "\t\taggregator_total = group->rtpoll_total;",
            "\t}",
            "",
            "\t/*",
            "\t * On subsequent updates, calculate growth deltas and let",
            "\t * watchers know when their specified thresholds are exceeded.",
            "\t */",
            "\tlist_for_each_entry(t, triggers, node) {",
            "\t\tu64 growth;",
            "\t\tbool new_stall;",
            "",
            "\t\tnew_stall = aggregator_total[t->state] != total[t->state];",
            "",
            "\t\t/* Check for stall activity or a previous threshold breach */",
            "\t\tif (!new_stall && !t->pending_event)",
            "\t\t\tcontinue;",
            "\t\t/*",
            "\t\t * Check for new stall activity, as well as deferred",
            "\t\t * events that occurred in the last window after the",
            "\t\t * trigger had already fired (we want to ratelimit",
            "\t\t * events without dropping any).",
            "\t\t */",
            "\t\tif (new_stall) {",
            "\t\t\t/*",
            "\t\t\t * Multiple triggers might be looking at the same state,",
            "\t\t\t * remember to update group->polling_total[] once we've",
            "\t\t\t * been through all of them. Also remember to extend the",
            "\t\t\t * polling time if we see new stall activity.",
            "\t\t\t */",
            "\t\t\t*update_total = true;",
            "",
            "\t\t\t/* Calculate growth since last update */",
            "\t\t\tgrowth = window_update(&t->win, now, total[t->state]);",
            "\t\t\tif (!t->pending_event) {",
            "\t\t\t\tif (growth < t->threshold)",
            "\t\t\t\t\tcontinue;",
            "",
            "\t\t\t\tt->pending_event = true;",
            "\t\t\t}",
            "\t\t}",
            "\t\t/* Limit event signaling to once per window */",
            "\t\tif (now < t->last_event_time + t->win.size)",
            "\t\t\tcontinue;",
            "",
            "\t\t/* Generate an event */",
            "\t\tif (cmpxchg(&t->event, 0, 1) == 0) {",
            "\t\t\tif (t->of)",
            "\t\t\t\tkernfs_notify(t->of->kn);",
            "\t\t\telse",
            "\t\t\t\twake_up_interruptible(&t->event_wait);",
            "\t\t}",
            "\t\tt->last_event_time = now;",
            "\t\t/* Reset threshold breach flag once event got generated */",
            "\t\tt->pending_event = false;",
            "\t}",
            "",
            "\treturn now + group->rtpoll_min_period;",
            "}",
            "static u64 update_averages(struct psi_group *group, u64 now)",
            "{",
            "\tunsigned long missed_periods = 0;",
            "\tu64 expires, period;",
            "\tu64 avg_next_update;",
            "\tint s;",
            "",
            "\t/* avgX= */",
            "\texpires = group->avg_next_update;",
            "\tif (now - expires >= psi_period)",
            "\t\tmissed_periods = div_u64(now - expires, psi_period);",
            "",
            "\t/*",
            "\t * The periodic clock tick can get delayed for various",
            "\t * reasons, especially on loaded systems. To avoid clock",
            "\t * drift, we schedule the clock in fixed psi_period intervals.",
            "\t * But the deltas we sample out of the per-cpu buckets above",
            "\t * are based on the actual time elapsing between clock ticks.",
            "\t */",
            "\tavg_next_update = expires + ((1 + missed_periods) * psi_period);",
            "\tperiod = now - (group->avg_last_update + (missed_periods * psi_period));",
            "\tgroup->avg_last_update = now;",
            "",
            "\tfor (s = 0; s < NR_PSI_STATES - 1; s++) {",
            "\t\tu32 sample;",
            "",
            "\t\tsample = group->total[PSI_AVGS][s] - group->avg_total[s];",
            "\t\t/*",
            "\t\t * Due to the lockless sampling of the time buckets,",
            "\t\t * recorded time deltas can slip into the next period,",
            "\t\t * which under full pressure can result in samples in",
            "\t\t * excess of the period length.",
            "\t\t *",
            "\t\t * We don't want to report non-sensical pressures in",
            "\t\t * excess of 100%, nor do we want to drop such events",
            "\t\t * on the floor. Instead we punt any overage into the",
            "\t\t * future until pressure subsides. By doing this we",
            "\t\t * don't underreport the occurring pressure curve, we",
            "\t\t * just report it delayed by one period length.",
            "\t\t *",
            "\t\t * The error isn't cumulative. As soon as another",
            "\t\t * delta slips from a period P to P+1, by definition",
            "\t\t * it frees up its time T in P.",
            "\t\t */",
            "\t\tif (sample > period)",
            "\t\t\tsample = period;",
            "\t\tgroup->avg_total[s] += sample;",
            "\t\tcalc_avgs(group->avg[s], missed_periods, sample, period);",
            "\t}",
            "",
            "\treturn avg_next_update;",
            "}"
          ],
          "function_name": "update_triggers, update_averages",
          "description": "更新压力触发器阈值检测状态，同步压力数据至全局统计数组，修正因时间偏差导致的异常压力值，保持数值在合理范围内。",
          "similarity": 0.5152188539505005
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/psi.c",
          "start_line": 150,
          "end_line": 302,
          "content": [
            "static int __init setup_psi(char *str)",
            "{",
            "\treturn kstrtobool(str, &psi_enable) == 0;",
            "}",
            "static inline void psi_write_begin(int cpu)",
            "{",
            "\twrite_seqcount_begin(per_cpu_ptr(&psi_seq, cpu));",
            "}",
            "static inline void psi_write_end(int cpu)",
            "{",
            "\twrite_seqcount_end(per_cpu_ptr(&psi_seq, cpu));",
            "}",
            "static inline u32 psi_read_begin(int cpu)",
            "{",
            "\treturn read_seqcount_begin(per_cpu_ptr(&psi_seq, cpu));",
            "}",
            "static inline bool psi_read_retry(int cpu, u32 seq)",
            "{",
            "\treturn read_seqcount_retry(per_cpu_ptr(&psi_seq, cpu), seq);",
            "}",
            "static void group_init(struct psi_group *group)",
            "{",
            "\tgroup->enabled = true;",
            "\tgroup->avg_last_update = sched_clock();",
            "\tgroup->avg_next_update = group->avg_last_update + psi_period;",
            "\tmutex_init(&group->avgs_lock);",
            "",
            "\t/* Init avg trigger-related members */",
            "\tINIT_LIST_HEAD(&group->avg_triggers);",
            "\tmemset(group->avg_nr_triggers, 0, sizeof(group->avg_nr_triggers));",
            "\tINIT_DELAYED_WORK(&group->avgs_work, psi_avgs_work);",
            "",
            "\t/* Init rtpoll trigger-related members */",
            "\tatomic_set(&group->rtpoll_scheduled, 0);",
            "\tmutex_init(&group->rtpoll_trigger_lock);",
            "\tINIT_LIST_HEAD(&group->rtpoll_triggers);",
            "\tgroup->rtpoll_min_period = U32_MAX;",
            "\tgroup->rtpoll_next_update = ULLONG_MAX;",
            "\tinit_waitqueue_head(&group->rtpoll_wait);",
            "\ttimer_setup(&group->rtpoll_timer, poll_timer_fn, 0);",
            "\trcu_assign_pointer(group->rtpoll_task, NULL);",
            "}",
            "void __init psi_init(void)",
            "{",
            "\tif (!psi_enable) {",
            "\t\tstatic_branch_enable(&psi_disabled);",
            "\t\tstatic_branch_disable(&psi_cgroups_enabled);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (!cgroup_psi_enabled())",
            "\t\tstatic_branch_disable(&psi_cgroups_enabled);",
            "",
            "\tpsi_period = jiffies_to_nsecs(PSI_FREQ);",
            "\tgroup_init(&psi_system);",
            "}",
            "static u32 test_states(unsigned int *tasks, u32 state_mask)",
            "{",
            "\tconst bool oncpu = state_mask & PSI_ONCPU;",
            "",
            "\tif (tasks[NR_IOWAIT]) {",
            "\t\tstate_mask |= BIT(PSI_IO_SOME);",
            "\t\tif (!tasks[NR_RUNNING])",
            "\t\t\tstate_mask |= BIT(PSI_IO_FULL);",
            "\t}",
            "",
            "\tif (tasks[NR_MEMSTALL]) {",
            "\t\tstate_mask |= BIT(PSI_MEM_SOME);",
            "\t\tif (tasks[NR_RUNNING] == tasks[NR_MEMSTALL_RUNNING])",
            "\t\t\tstate_mask |= BIT(PSI_MEM_FULL);",
            "\t}",
            "",
            "\tif (tasks[NR_RUNNING] > oncpu)",
            "\t\tstate_mask |= BIT(PSI_CPU_SOME);",
            "",
            "\tif (tasks[NR_RUNNING] && !oncpu)",
            "\t\tstate_mask |= BIT(PSI_CPU_FULL);",
            "",
            "\tif (tasks[NR_IOWAIT] || tasks[NR_MEMSTALL] || tasks[NR_RUNNING])",
            "\t\tstate_mask |= BIT(PSI_NONIDLE);",
            "",
            "\treturn state_mask;",
            "}",
            "static void get_recent_times(struct psi_group *group, int cpu,",
            "\t\t\t     enum psi_aggregators aggregator, u32 *times,",
            "\t\t\t     u32 *pchanged_states)",
            "{",
            "\tstruct psi_group_cpu *groupc = per_cpu_ptr(group->pcpu, cpu);",
            "\tint current_cpu = raw_smp_processor_id();",
            "\tunsigned int tasks[NR_PSI_TASK_COUNTS];",
            "\tu64 now, state_start;",
            "\tenum psi_states s;",
            "\tunsigned int seq;",
            "\tu32 state_mask;",
            "",
            "\t*pchanged_states = 0;",
            "",
            "\t/* Snapshot a coherent view of the CPU state */",
            "\tdo {",
            "\t\tseq = psi_read_begin(cpu);",
            "\t\tnow = cpu_clock(cpu);",
            "\t\tmemcpy(times, groupc->times, sizeof(groupc->times));",
            "\t\tstate_mask = groupc->state_mask;",
            "\t\tstate_start = groupc->state_start;",
            "\t\tif (cpu == current_cpu)",
            "\t\t\tmemcpy(tasks, groupc->tasks, sizeof(groupc->tasks));",
            "\t} while (psi_read_retry(cpu, seq));",
            "",
            "\t/* Calculate state time deltas against the previous snapshot */",
            "\tfor (s = 0; s < NR_PSI_STATES; s++) {",
            "\t\tu32 delta;",
            "\t\t/*",
            "\t\t * In addition to already concluded states, we also",
            "\t\t * incorporate currently active states on the CPU,",
            "\t\t * since states may last for many sampling periods.",
            "\t\t *",
            "\t\t * This way we keep our delta sampling buckets small",
            "\t\t * (u32) and our reported pressure close to what's",
            "\t\t * actually happening.",
            "\t\t */",
            "\t\tif (state_mask & (1 << s))",
            "\t\t\ttimes[s] += now - state_start;",
            "",
            "\t\tdelta = times[s] - groupc->times_prev[aggregator][s];",
            "\t\tgroupc->times_prev[aggregator][s] = times[s];",
            "",
            "\t\ttimes[s] = delta;",
            "\t\tif (delta)",
            "\t\t\t*pchanged_states |= (1 << s);",
            "\t}",
            "",
            "\t/*",
            "\t * When collect_percpu_times() from the avgs_work, we don't want to",
            "\t * re-arm avgs_work when all CPUs are IDLE. But the current CPU running",
            "\t * this avgs_work is never IDLE, cause avgs_work can't be shut off.",
            "\t * So for the current CPU, we need to re-arm avgs_work only when",
            "\t * (NR_RUNNING > 1 || NR_IOWAIT > 0 || NR_MEMSTALL > 0), for other CPUs",
            "\t * we can just check PSI_NONIDLE delta.",
            "\t */",
            "\tif (current_work() == &group->avgs_work.work) {",
            "\t\tbool reschedule;",
            "",
            "\t\tif (cpu == current_cpu)",
            "\t\t\treschedule = tasks[NR_RUNNING] +",
            "\t\t\t\t     tasks[NR_IOWAIT] +",
            "\t\t\t\t     tasks[NR_MEMSTALL] > 1;",
            "\t\telse",
            "\t\t\treschedule = *pchanged_states & (1 << PSI_NONIDLE);",
            "",
            "\t\tif (reschedule)",
            "\t\t\t*pchanged_states |= PSI_STATE_RESCHEDULE;",
            "\t}",
            "}"
          ],
          "function_name": "setup_psi, psi_write_begin, psi_write_end, psi_read_begin, psi_read_retry, group_init, psi_init, test_states, get_recent_times",
          "description": "初始化PSI组结构体，注册回调函数处理压力状态变化，通过遍历任务状态计算压力掩码并收集各CPU的压力时间数据。",
          "similarity": 0.495405912399292
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/sched/psi.c",
          "start_line": 1506,
          "end_line": 1607,
          "content": [
            "static int psi_io_show(struct seq_file *m, void *v)",
            "{",
            "\treturn psi_show(m, &psi_system, PSI_IO);",
            "}",
            "static int psi_memory_show(struct seq_file *m, void *v)",
            "{",
            "\treturn psi_show(m, &psi_system, PSI_MEM);",
            "}",
            "static int psi_cpu_show(struct seq_file *m, void *v)",
            "{",
            "\treturn psi_show(m, &psi_system, PSI_CPU);",
            "}",
            "static int psi_io_open(struct inode *inode, struct file *file)",
            "{",
            "\treturn single_open(file, psi_io_show, NULL);",
            "}",
            "static int psi_memory_open(struct inode *inode, struct file *file)",
            "{",
            "\treturn single_open(file, psi_memory_show, NULL);",
            "}",
            "static int psi_cpu_open(struct inode *inode, struct file *file)",
            "{",
            "\treturn single_open(file, psi_cpu_show, NULL);",
            "}",
            "static ssize_t psi_write(struct file *file, const char __user *user_buf,",
            "\t\t\t size_t nbytes, enum psi_res res)",
            "{",
            "\tchar buf[32];",
            "\tsize_t buf_size;",
            "\tstruct seq_file *seq;",
            "\tstruct psi_trigger *new;",
            "",
            "\tif (static_branch_likely(&psi_disabled))",
            "\t\treturn -EOPNOTSUPP;",
            "",
            "\tif (!nbytes)",
            "\t\treturn -EINVAL;",
            "",
            "\tbuf_size = min(nbytes, sizeof(buf));",
            "\tif (copy_from_user(buf, user_buf, buf_size))",
            "\t\treturn -EFAULT;",
            "",
            "\tbuf[buf_size - 1] = '\\0';",
            "",
            "\tseq = file->private_data;",
            "",
            "\t/* Take seq->lock to protect seq->private from concurrent writes */",
            "\tmutex_lock(&seq->lock);",
            "",
            "\t/* Allow only one trigger per file descriptor */",
            "\tif (seq->private) {",
            "\t\tmutex_unlock(&seq->lock);",
            "\t\treturn -EBUSY;",
            "\t}",
            "",
            "\tnew = psi_trigger_create(&psi_system, buf, res, file, NULL);",
            "\tif (IS_ERR(new)) {",
            "\t\tmutex_unlock(&seq->lock);",
            "\t\treturn PTR_ERR(new);",
            "\t}",
            "",
            "\tsmp_store_release(&seq->private, new);",
            "\tmutex_unlock(&seq->lock);",
            "",
            "\treturn nbytes;",
            "}",
            "static ssize_t psi_io_write(struct file *file, const char __user *user_buf,",
            "\t\t\t    size_t nbytes, loff_t *ppos)",
            "{",
            "\treturn psi_write(file, user_buf, nbytes, PSI_IO);",
            "}",
            "static ssize_t psi_memory_write(struct file *file, const char __user *user_buf,",
            "\t\t\t\tsize_t nbytes, loff_t *ppos)",
            "{",
            "\treturn psi_write(file, user_buf, nbytes, PSI_MEM);",
            "}",
            "static ssize_t psi_cpu_write(struct file *file, const char __user *user_buf,",
            "\t\t\t     size_t nbytes, loff_t *ppos)",
            "{",
            "\treturn psi_write(file, user_buf, nbytes, PSI_CPU);",
            "}",
            "static __poll_t psi_fop_poll(struct file *file, poll_table *wait)",
            "{",
            "\tstruct seq_file *seq = file->private_data;",
            "",
            "\treturn psi_trigger_poll(&seq->private, file, wait);",
            "}",
            "static int psi_fop_release(struct inode *inode, struct file *file)",
            "{",
            "\tstruct seq_file *seq = file->private_data;",
            "",
            "\tpsi_trigger_destroy(seq->private);",
            "\treturn single_release(inode, file);",
            "}",
            "static int psi_irq_show(struct seq_file *m, void *v)",
            "{",
            "\treturn psi_show(m, &psi_system, PSI_IRQ);",
            "}",
            "static int psi_irq_open(struct inode *inode, struct file *file)",
            "{",
            "\treturn single_open(file, psi_irq_show, NULL);",
            "}"
          ],
          "function_name": "psi_io_show, psi_memory_show, psi_cpu_show, psi_io_open, psi_memory_open, psi_cpu_open, psi_write, psi_io_write, psi_memory_write, psi_cpu_write, psi_fop_poll, psi_fop_release, psi_irq_show, psi_irq_open",
          "description": "该代码段实现了PSI（Pressure Stall Information）子系统的文件操作接口，用于暴露和操控不同维度（IO、Memory、CPU、IRQ）的压力状态。各_show函数通过psi_show生成对应类型的统计信息，_open函数注册了单次打开逻辑以支持序列化读取，_write系列函数接收用户输入并创建psi_trigger对象以触发电压事件。由于缺少psi_show及psi_trigger相关实现，上下文存在缺失。",
          "similarity": 0.48911815881729126
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/sched/psi.c",
          "start_line": 585,
          "end_line": 739,
          "content": [
            "static void psi_avgs_work(struct work_struct *work)",
            "{",
            "\tstruct delayed_work *dwork;",
            "\tstruct psi_group *group;",
            "\tu32 changed_states;",
            "\tbool update_total;",
            "\tu64 now;",
            "",
            "\tdwork = to_delayed_work(work);",
            "\tgroup = container_of(dwork, struct psi_group, avgs_work);",
            "",
            "\tmutex_lock(&group->avgs_lock);",
            "",
            "\tnow = sched_clock();",
            "",
            "\tcollect_percpu_times(group, PSI_AVGS, &changed_states);",
            "\t/*",
            "\t * If there is task activity, periodically fold the per-cpu",
            "\t * times and feed samples into the running averages. If things",
            "\t * are idle and there is no data to process, stop the clock.",
            "\t * Once restarted, we'll catch up the running averages in one",
            "\t * go - see calc_avgs() and missed_periods.",
            "\t */",
            "\tif (now >= group->avg_next_update) {",
            "\t\tupdate_triggers(group, now, &update_total, PSI_AVGS);",
            "\t\tgroup->avg_next_update = update_averages(group, now);",
            "\t}",
            "",
            "\tif (changed_states & PSI_STATE_RESCHEDULE) {",
            "\t\tschedule_delayed_work(dwork, nsecs_to_jiffies(",
            "\t\t\t\tgroup->avg_next_update - now) + 1);",
            "\t}",
            "",
            "\tmutex_unlock(&group->avgs_lock);",
            "}",
            "static void init_rtpoll_triggers(struct psi_group *group, u64 now)",
            "{",
            "\tstruct psi_trigger *t;",
            "",
            "\tlist_for_each_entry(t, &group->rtpoll_triggers, node)",
            "\t\twindow_reset(&t->win, now,",
            "\t\t\t\tgroup->total[PSI_POLL][t->state], 0);",
            "\tmemcpy(group->rtpoll_total, group->total[PSI_POLL],",
            "\t\t   sizeof(group->rtpoll_total));",
            "\tgroup->rtpoll_next_update = now + group->rtpoll_min_period;",
            "}",
            "static void psi_schedule_rtpoll_work(struct psi_group *group, unsigned long delay,",
            "\t\t\t\t   bool force)",
            "{",
            "\tstruct task_struct *task;",
            "",
            "\t/*",
            "\t * atomic_xchg should be called even when !force to provide a",
            "\t * full memory barrier (see the comment inside psi_rtpoll_work).",
            "\t */",
            "\tif (atomic_xchg(&group->rtpoll_scheduled, 1) && !force)",
            "\t\treturn;",
            "",
            "\trcu_read_lock();",
            "",
            "\ttask = rcu_dereference(group->rtpoll_task);",
            "\t/*",
            "\t * kworker might be NULL in case psi_trigger_destroy races with",
            "\t * psi_task_change (hotpath) which can't use locks",
            "\t */",
            "\tif (likely(task))",
            "\t\tmod_timer(&group->rtpoll_timer, jiffies + delay);",
            "\telse",
            "\t\tatomic_set(&group->rtpoll_scheduled, 0);",
            "",
            "\trcu_read_unlock();",
            "}",
            "static void psi_rtpoll_work(struct psi_group *group)",
            "{",
            "\tbool force_reschedule = false;",
            "\tu32 changed_states;",
            "\tbool update_total;",
            "\tu64 now;",
            "",
            "\tmutex_lock(&group->rtpoll_trigger_lock);",
            "",
            "\tnow = sched_clock();",
            "",
            "\tif (now > group->rtpoll_until) {",
            "\t\t/*",
            "\t\t * We are either about to start or might stop polling if no",
            "\t\t * state change was recorded. Resetting poll_scheduled leaves",
            "\t\t * a small window for psi_group_change to sneak in and schedule",
            "\t\t * an immediate poll_work before we get to rescheduling. One",
            "\t\t * potential extra wakeup at the end of the polling window",
            "\t\t * should be negligible and polling_next_update still keeps",
            "\t\t * updates correctly on schedule.",
            "\t\t */",
            "\t\tatomic_set(&group->rtpoll_scheduled, 0);",
            "\t\t/*",
            "\t\t * A task change can race with the poll worker that is supposed to",
            "\t\t * report on it. To avoid missing events, ensure ordering between",
            "\t\t * poll_scheduled and the task state accesses, such that if the poll",
            "\t\t * worker misses the state update, the task change is guaranteed to",
            "\t\t * reschedule the poll worker:",
            "\t\t *",
            "\t\t * poll worker:",
            "\t\t *   atomic_set(poll_scheduled, 0)",
            "\t\t *   smp_mb()",
            "\t\t *   LOAD states",
            "\t\t *",
            "\t\t * task change:",
            "\t\t *   STORE states",
            "\t\t *   if atomic_xchg(poll_scheduled, 1) == 0:",
            "\t\t *     schedule poll worker",
            "\t\t *",
            "\t\t * The atomic_xchg() implies a full barrier.",
            "\t\t */",
            "\t\tsmp_mb();",
            "\t} else {",
            "\t\t/* Polling window is not over, keep rescheduling */",
            "\t\tforce_reschedule = true;",
            "\t}",
            "",
            "",
            "\tcollect_percpu_times(group, PSI_POLL, &changed_states);",
            "",
            "\tif (changed_states & group->rtpoll_states) {",
            "\t\t/* Initialize trigger windows when entering polling mode */",
            "\t\tif (now > group->rtpoll_until)",
            "\t\t\tinit_rtpoll_triggers(group, now);",
            "",
            "\t\t/*",
            "\t\t * Keep the monitor active for at least the duration of the",
            "\t\t * minimum tracking window as long as monitor states are",
            "\t\t * changing.",
            "\t\t */",
            "\t\tgroup->rtpoll_until = now +",
            "\t\t\tgroup->rtpoll_min_period * UPDATES_PER_WINDOW;",
            "\t}",
            "",
            "\tif (now > group->rtpoll_until) {",
            "\t\tgroup->rtpoll_next_update = ULLONG_MAX;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (now >= group->rtpoll_next_update) {",
            "\t\tgroup->rtpoll_next_update = update_triggers(group, now, &update_total, PSI_POLL);",
            "\t\tif (update_total)",
            "\t\t\tmemcpy(group->rtpoll_total, group->total[PSI_POLL],",
            "\t\t\t\t   sizeof(group->rtpoll_total));",
            "\t}",
            "",
            "\tpsi_schedule_rtpoll_work(group,",
            "\t\tnsecs_to_jiffies(group->rtpoll_next_update - now) + 1,",
            "\t\tforce_reschedule);",
            "",
            "out:",
            "\tmutex_unlock(&group->rtpoll_trigger_lock);",
            "}"
          ],
          "function_name": "psi_avgs_work, init_rtpoll_triggers, psi_schedule_rtpoll_work, psi_rtpoll_work",
          "description": "调度周期性压力检测任务，通过工作队列收集实时压力数据，根据状态变更重新安排下一次检测时机，确保持续监控系统压力状况。",
          "similarity": 0.484846293926239
        }
      ]
    }
  ]
}