{
  "query": "并发资源锁与权限管理",
  "timestamp": "2025-12-26 01:32:14",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/ww_mutex.h",
      "md_summary": "> 自动生成时间: 2025-10-25 14:56:40\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\ww_mutex.h`\n\n---\n\n# `locking/ww_mutex.h` 技术文档\n\n## 1. 文件概述\n\n`ww_mutex.h` 是 Linux 内核中用于实现 **Wound-Wait (WW) 互斥锁**（`ww_mutex`）的头文件。该机制主要用于解决 **死锁问题**，特别是在图形子系统（如 DRM/KMS）和资源管理场景中，多个事务（transactions）需要以特定顺序获取多个锁时。  \nWW 互斥锁通过为每个锁请求关联一个 **获取上下文**（`ww_acquire_ctx`），并基于事务的优先级或时间戳实现 **Wait-Die** 或 **Wound-Wait** 死锁避免策略。\n\n该文件通过条件编译（`WW_RT` 宏）支持两种底层锁实现：\n- **普通互斥锁**（`mutex`）：用于非实时（non-RT）内核配置。\n- **实时互斥锁**（`rt_mutex`）：用于实时（RT）内核补丁配置，支持优先级继承。\n\n## 2. 核心功能\n\n### 2.1 主要宏定义\n- `MUTEX` / `MUTEX_WAITER`：根据 `WW_RT` 宏分别映射到 `mutex`/`rt_mutex` 及其等待者结构。\n\n### 2.2 等待者链表/红黑树操作函数（抽象接口）\n- `__ww_waiter_first()`：获取等待队列中的第一个等待者。\n- `__ww_waiter_next()` / `__ww_waiter_prev()`：获取下一个/上一个等待者。\n- `__ww_waiter_last()`：获取等待队列中的最后一个等待者。\n- `__ww_waiter_add()`：将等待者插入到指定位置（普通 mutex 使用链表，RT 使用红黑树）。\n\n### 2.3 锁状态查询函数\n- `__ww_mutex_owner()`：获取当前锁的持有者任务。\n- `__ww_mutex_has_waiters()`：检查锁是否有等待者。\n- `lock_wait_lock()` / `unlock_wait_lock()`：获取/释放锁的等待队列自旋锁（`wait_lock`）。\n- `lockdep_assert_wait_lock_held()`：调试时断言 `wait_lock` 已被持有。\n\n### 2.4 WW 互斥锁核心逻辑函数\n- `ww_mutex_lock_acquired()`：在成功获取 `ww_mutex` 后，将其与获取上下文（`ww_ctx`）关联，并执行调试检查。\n- `__ww_ctx_less()`：比较两个获取上下文的优先级（用于决定谁应“等待”或“死亡/被抢占”）。\n- `__ww_mutex_die()`：**Wait-Die 策略**实现：若当前请求者（新事务）发现等待队列中有更老的事务持有其他锁，则唤醒该老事务使其“死亡”（回滚）。\n- `__ww_mutex_wound()`：**Wound-Wait 策略**实现：若当前请求者（老事务）发现锁持有者是更年轻的事务，则“刺伤”（标记 `wounded=1`）该年轻事务，迫使其回滚。\n\n## 3. 关键实现\n\n### 3.1 死锁避免策略\n- **Wait-Die**（`is_wait_die=1`）：\n  - **新事务**请求**老事务**持有的锁 → **新事务等待**。\n  - **新事务**请求**老事务**等待的锁 → **新事务死亡**（回滚）。\n- **Wound-Wait**（`is_wait_die=0`）：\n  - **老事务**请求**新事务**持有的锁 → **新事务被刺伤**（回滚）。\n  - **老事务**请求**新事务**等待的锁 → **老事务等待**。\n\n### 3.2 上下文比较 (`__ww_ctx_less`)\n- **非 RT 模式**：仅基于时间戳（`stamp`），值越大表示事务越新。\n- **RT 模式**：\n  1. 优先比较 **实时优先级**（`prio`），数值越小优先级越高。\n  2. 若均为 **Deadline 调度类**，比较 **截止时间**（`deadline`），越早截止优先级越高。\n  3. 若优先级相同，回退到时间戳比较。\n\n### 3.3 RT 与非 RT 差异\n- **数据结构**：\n  - 非 RT：等待者使用 **双向链表**（`list_head`）。\n  - RT：等待者使用 **红黑树**（`rb_root`），按优先级排序。\n- **插入逻辑**：\n  - 非 RT：`__ww_waiter_add` 显式插入到指定位置。\n  - RT：`__ww_waiter_add` 为空（RT 互斥锁内部自动处理插入）。\n\n### 3.4 调试支持 (`DEBUG_WW_MUTEXES`)\n- 检查 `ww_mutex` 是否被错误地用普通 `mutex_unlock` 释放。\n- 验证上下文一致性（如 `ww_class` 匹配、`contending_lock` 状态等）。\n\n## 4. 依赖关系\n\n- **基础锁机制**：\n  - 非 RT 模式依赖 `<linux/mutex.h>`。\n  - RT 模式依赖 `<linux/rtmutex.h>`。\n- **调度器**：依赖任务结构（`task_struct`）、优先级（`prio`）、调度类（如 `dl_prio`）。\n- **调试框架**：依赖 `lockdep`（`lockdep_assert_held`）和 `DEBUG_LOCKS_WARN_ON`。\n- **原子操作**：使用 `atomic_long_read` 检查锁状态标志（`MUTEX_FLAG_WAITERS`）。\n\n## 5. 使用场景\n\n- **图形子系统**（DRM/KMS）：  \n  多个 GPU 作业（如渲染、合成）需按顺序获取多个缓冲区（buffer）或 CRTC 锁，避免死锁。\n- **资源分配器**：  \n  当多个客户端竞争一组有限资源（如内存区域、I/O 端口）时，通过 WW 互斥锁确保无死锁的分配顺序。\n- **实时系统**（RT 补丁）：  \n  在需要确定性延迟的场景中，结合优先级继承（PI）避免优先级反转，同时通过 WW 策略解决多锁死锁。\n- **文件系统**：  \n  某些文件系统（如 Btrfs）在元数据操作中使用 WW 互斥锁管理多个 extent 锁。",
      "similarity": 0.5567508339881897,
      "chunks": []
    },
    {
      "source_file": "kernel/locking/mutex.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:42:50\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\mutex.c`\n\n---\n\n# Linux 内核互斥锁（mutex）实现文档\n\n## 1. 文件概述\n\n`locking/mutex.c` 是 Linux 内核中互斥锁（mutex）的核心实现文件，提供了基于阻塞的互斥同步原语。该文件实现了高效、可睡眠的互斥锁机制，支持自旋优化、锁移交（handoff）、调试功能以及与调度器、死锁检测等子系统的深度集成。互斥锁用于保护临界区，确保同一时间只有一个任务可以持有锁，适用于需要长时间持有锁或可能睡眠的场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `__mutex_init()`：初始化互斥锁对象\n- `mutex_is_locked()`：检查互斥锁是否已被持有\n- `mutex_get_owner()`：获取当前锁持有者的任务指针（仅用于调试）\n- `__mutex_trylock()`：尝试获取互斥锁（非阻塞）\n- `__mutex_trylock_fast()`：快速路径尝试获取未竞争的锁\n- `__mutex_unlock_fast()`：快速路径释放锁\n- `__mutex_lock_slowpath()`：慢速路径获取锁（包含睡眠和等待逻辑）\n- `__mutex_handoff()`：将锁所有权移交给指定任务\n- `__mutex_add_waiter()` / `__mutex_remove_waiter()`：管理等待队列\n\n### 关键数据结构\n\n- `struct mutex`：互斥锁核心结构体\n  - `atomic_long_t owner`：原子存储锁持有者指针和状态标志\n  - `raw_spinlock_t wait_lock`：保护等待队列的自旋锁\n  - `struct list_head wait_list`：等待获取锁的任务队列\n  - `struct optimistic_spin_queue osq`：用于自旋优化的队列（CONFIG_MUTEX_SPIN_ON_OWNER）\n\n### 状态标志位\n\n- `MUTEX_FLAG_WAITERS (0x01)`：表示存在等待者，解锁时需唤醒\n- `MUTEX_FLAG_HANDOFF (0x02)`：表示需要将锁移交给队首等待者\n- `MUTEX_FLAG_PICKUP (0x04)`：表示锁已被移交给特定任务，等待其获取\n\n## 3. 关键实现\n\n### 锁状态编码\n互斥锁的 `owner` 字段采用指针-标志位混合编码：利用 `task_struct` 指针的低 3 位（因内存对齐保证为 0）存储状态标志。这种设计避免了额外的内存访问，提高了原子操作效率。\n\n### 快慢路径分离\n- **快速路径**：针对无竞争场景，直接通过原子比较交换（cmpxchg）获取/释放锁，避免函数调用开销\n- **慢速路径**：处理竞争情况，包含自旋等待、任务阻塞、唤醒等复杂逻辑\n\n### 自适应自旋（Adaptive Spinning）\n在 `CONFIG_MUTEX_SPIN_ON_OWNER` 配置下，当检测到锁持有者正在运行时，当前任务会先自旋等待而非立即睡眠，减少上下文切换开销。使用 OSQ（Optimistic Spin Queue）机制协调多个自旋任务。\n\n### 锁移交机制（Handoff）\n通过 `MUTEX_FLAG_HANDOFF` 和 `MUTEX_FLAG_PICKUP` 标志实现高效的锁移交：\n1. 解锁者设置 `HANDOFF` 标志并唤醒队首等待者\n2. 被唤醒任务在获取锁时检测到 `HANDOFF`，设置 `PICKUP` 标志\n3. 解锁者通过 `__mutex_handoff()` 直接将所有权转移给指定任务\n避免了唤醒后再次竞争的问题，提高实时性。\n\n### 调试支持\n- `CONFIG_DEBUG_MUTEXES`：提供锁状态验证、死锁检测\n- `CONFIG_DETECT_HUNG_TASK_BLOCKER`：集成 hung task 检测，记录阻塞源\n- `lockdep`：通过 `debug_mutex_*` 函数集成锁依赖验证\n\n## 4. 依赖关系\n\n### 头文件依赖\n- `<linux/mutex.h>` / `<linux/ww_mutex.h>`：互斥锁接口定义\n- `<linux/sched/*.h>`：调度器相关功能（睡眠、唤醒、实时任务）\n- `<linux/spinlock.h>`：底层自旋锁实现\n- `<linux/osq_lock.h>`：乐观自旋队列支持\n- `<linux/hung_task.h>`：hung task 检测集成\n- `<trace/events/lock.h>`：锁事件跟踪点\n\n### 子系统交互\n- **调度器**：通过 `schedule()` 实现任务阻塞，`wake_q` 机制批量唤醒\n- **内存管理**：依赖 `task_struct` 的内存对齐特性\n- **实时补丁（PREEMPT_RT）**：非 RT 配置下编译此文件（`#ifndef CONFIG_PREEMPT_RT`）\n- **调试子系统**：与 lockdep、hung task detector 深度集成\n\n## 5. 使用场景\n\n### 典型应用场景\n- **长临界区保护**：当临界区执行时间较长或包含可能睡眠的操作（如内存分配、I/O）\n- **驱动程序同步**：设备驱动中保护硬件寄存器访问或共享数据结构\n- **文件系统操作**：保护 inode、dentry 等元数据结构\n- **内核子系统互斥**：如网络协议栈、块设备层等需要互斥访问的场景\n\n### 使用约束\n- **不可递归**：同一任务重复获取会导致死锁\n- **必须配对使用**：获取锁的任务必须负责释放\n- **禁止中断上下文使用**：因可能睡眠，只能在进程上下文使用\n- **内存生命周期**：锁对象内存不能在持有锁时释放\n\n### 性能考量\n- 无竞争场景：纳秒级延迟（快速路径原子操作）\n- 有竞争场景：微秒级延迟（自旋优化）或毫秒级（任务切换）\n- 适用于中低频竞争场景，高频竞争建议使用读写锁或 RCU",
      "similarity": 0.5558129549026489,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 455,
          "end_line": 722,
          "content": [
            "static __always_inline bool",
            "mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t      struct mutex_waiter *waiter)",
            "{",
            "\tif (!waiter) {",
            "\t\t/*",
            "\t\t * The purpose of the mutex_can_spin_on_owner() function is",
            "\t\t * to eliminate the overhead of osq_lock() and osq_unlock()",
            "\t\t * in case spinning isn't possible. As a waiter-spinner",
            "\t\t * is not going to take OSQ lock anyway, there is no need",
            "\t\t * to call mutex_can_spin_on_owner().",
            "\t\t */",
            "\t\tif (!mutex_can_spin_on_owner(lock))",
            "\t\t\tgoto fail;",
            "",
            "\t\t/*",
            "\t\t * In order to avoid a stampede of mutex spinners trying to",
            "\t\t * acquire the mutex all at once, the spinners need to take a",
            "\t\t * MCS (queued) lock first before spinning on the owner field.",
            "\t\t */",
            "\t\tif (!osq_lock(&lock->osq))",
            "\t\t\tgoto fail;",
            "\t}",
            "",
            "\tfor (;;) {",
            "\t\tstruct task_struct *owner;",
            "",
            "\t\t/* Try to acquire the mutex... */",
            "\t\towner = __mutex_trylock_or_owner(lock);",
            "\t\tif (!owner)",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * There's an owner, wait for it to either",
            "\t\t * release the lock or go to sleep.",
            "\t\t */",
            "\t\tif (!mutex_spin_on_owner(lock, owner, ww_ctx, waiter))",
            "\t\t\tgoto fail_unlock;",
            "",
            "\t\t/*",
            "\t\t * The cpu_relax() call is a compiler barrier which forces",
            "\t\t * everything in this loop to be re-loaded. We don't need",
            "\t\t * memory barriers as we'll eventually observe the right",
            "\t\t * values at the cost of a few extra spins.",
            "\t\t */",
            "\t\tcpu_relax();",
            "\t}",
            "",
            "\tif (!waiter)",
            "\t\tosq_unlock(&lock->osq);",
            "",
            "\treturn true;",
            "",
            "",
            "fail_unlock:",
            "\tif (!waiter)",
            "\t\tosq_unlock(&lock->osq);",
            "",
            "fail:",
            "\t/*",
            "\t * If we fell out of the spin path because of need_resched(),",
            "\t * reschedule now, before we try-lock the mutex. This avoids getting",
            "\t * scheduled out right after we obtained the mutex.",
            "\t */",
            "\tif (need_resched()) {",
            "\t\t/*",
            "\t\t * We _should_ have TASK_RUNNING here, but just in case",
            "\t\t * we do not, make it so, otherwise we might get stuck.",
            "\t\t */",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t\tschedule_preempt_disabled();",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static __always_inline bool",
            "mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t      struct mutex_waiter *waiter)",
            "{",
            "\treturn false;",
            "}",
            "void __sched mutex_unlock(struct mutex *lock)",
            "{",
            "#ifndef CONFIG_DEBUG_LOCK_ALLOC",
            "\tif (__mutex_unlock_fast(lock))",
            "\t\treturn;",
            "#endif",
            "\t__mutex_unlock_slowpath(lock, _RET_IP_);",
            "}",
            "void __sched ww_mutex_unlock(struct ww_mutex *lock)",
            "{",
            "\t__ww_mutex_unlock(lock);",
            "\tmutex_unlock(&lock->base);",
            "}",
            "static __always_inline int __sched",
            "__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t\t    struct lockdep_map *nest_lock, unsigned long ip,",
            "\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)",
            "{",
            "\tstruct mutex_waiter waiter;",
            "\tstruct ww_mutex *ww;",
            "\tint ret;",
            "",
            "\tif (!use_ww_ctx)",
            "\t\tww_ctx = NULL;",
            "",
            "\tmight_sleep();",
            "",
            "\tMUTEX_WARN_ON(lock->magic != lock);",
            "",
            "\tww = container_of(lock, struct ww_mutex, base);",
            "\tif (ww_ctx) {",
            "\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))",
            "\t\t\treturn -EALREADY;",
            "",
            "\t\t/*",
            "\t\t * Reset the wounded flag after a kill. No other process can",
            "\t\t * race and wound us here since they can't have a valid owner",
            "\t\t * pointer if we don't have any locks held.",
            "\t\t */",
            "\t\tif (ww_ctx->acquired == 0)",
            "\t\t\tww_ctx->wounded = 0;",
            "",
            "#ifdef CONFIG_DEBUG_LOCK_ALLOC",
            "\t\tnest_lock = &ww_ctx->dep_map;",
            "#endif",
            "\t}",
            "",
            "\tpreempt_disable();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);",
            "",
            "\ttrace_contention_begin(lock, LCB_F_MUTEX | LCB_F_SPIN);",
            "\tif (__mutex_trylock(lock) ||",
            "\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {",
            "\t\t/* got the lock, yay! */",
            "\t\tlock_acquired(&lock->dep_map, ip);",
            "\t\tif (ww_ctx)",
            "\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);",
            "\t\ttrace_contention_end(lock, 0);",
            "\t\tpreempt_enable();",
            "\t\treturn 0;",
            "\t}",
            "",
            "\traw_spin_lock(&lock->wait_lock);",
            "\t/*",
            "\t * After waiting to acquire the wait_lock, try again.",
            "\t */",
            "\tif (__mutex_trylock(lock)) {",
            "\t\tif (ww_ctx)",
            "\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);",
            "",
            "\t\tgoto skip_wait;",
            "\t}",
            "",
            "\tdebug_mutex_lock_common(lock, &waiter);",
            "\twaiter.task = current;",
            "\tif (use_ww_ctx)",
            "\t\twaiter.ww_ctx = ww_ctx;",
            "",
            "\tlock_contended(&lock->dep_map, ip);",
            "",
            "\tif (!use_ww_ctx) {",
            "\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */",
            "\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);",
            "\t} else {",
            "\t\t/*",
            "\t\t * Add in stamp order, waking up waiters that must kill",
            "\t\t * themselves.",
            "\t\t */",
            "\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);",
            "\t\tif (ret)",
            "\t\t\tgoto err_early_kill;",
            "\t}",
            "",
            "\tset_current_state(state);",
            "\ttrace_contention_begin(lock, LCB_F_MUTEX);",
            "\tfor (;;) {",
            "\t\tbool first;",
            "",
            "\t\t/*",
            "\t\t * Once we hold wait_lock, we're serialized against",
            "\t\t * mutex_unlock() handing the lock off to us, do a trylock",
            "\t\t * before testing the error conditions to make sure we pick up",
            "\t\t * the handoff.",
            "\t\t */",
            "\t\tif (__mutex_trylock(lock))",
            "\t\t\tgoto acquired;",
            "",
            "\t\t/*",
            "\t\t * Check for signals and kill conditions while holding",
            "\t\t * wait_lock. This ensures the lock cancellation is ordered",
            "\t\t * against mutex_unlock() and wake-ups do not go missing.",
            "\t\t */",
            "\t\tif (signal_pending_state(state, current)) {",
            "\t\t\tret = -EINTR;",
            "\t\t\tgoto err;",
            "\t\t}",
            "",
            "\t\tif (ww_ctx) {",
            "\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);",
            "\t\t\tif (ret)",
            "\t\t\t\tgoto err;",
            "\t\t}",
            "",
            "\t\traw_spin_unlock(&lock->wait_lock);",
            "\t\tschedule_preempt_disabled();",
            "",
            "\t\tfirst = __mutex_waiter_is_first(lock, &waiter);",
            "",
            "\t\tset_current_state(state);",
            "\t\t/*",
            "\t\t * Here we order against unlock; we must either see it change",
            "\t\t * state back to RUNNING and fall through the next schedule(),",
            "\t\t * or we must see its unlock and acquire.",
            "\t\t */",
            "\t\tif (__mutex_trylock_or_handoff(lock, first))",
            "\t\t\tbreak;",
            "",
            "\t\tif (first) {",
            "\t\t\ttrace_contention_begin(lock, LCB_F_MUTEX | LCB_F_SPIN);",
            "\t\t\tif (mutex_optimistic_spin(lock, ww_ctx, &waiter))",
            "\t\t\t\tbreak;",
            "\t\t\ttrace_contention_begin(lock, LCB_F_MUTEX);",
            "\t\t}",
            "",
            "\t\traw_spin_lock(&lock->wait_lock);",
            "\t}",
            "\traw_spin_lock(&lock->wait_lock);",
            "acquired:",
            "\t__set_current_state(TASK_RUNNING);",
            "",
            "\tif (ww_ctx) {",
            "\t\t/*",
            "\t\t * Wound-Wait; we stole the lock (!first_waiter), check the",
            "\t\t * waiters as anyone might want to wound us.",
            "\t\t */",
            "\t\tif (!ww_ctx->is_wait_die &&",
            "\t\t    !__mutex_waiter_is_first(lock, &waiter))",
            "\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);",
            "\t}",
            "",
            "\t__mutex_remove_waiter(lock, &waiter);",
            "",
            "\tdebug_mutex_free_waiter(&waiter);",
            "",
            "skip_wait:",
            "\t/* got the lock - cleanup and rejoice! */",
            "\tlock_acquired(&lock->dep_map, ip);",
            "\ttrace_contention_end(lock, 0);",
            "",
            "\tif (ww_ctx)",
            "\t\tww_mutex_lock_acquired(ww, ww_ctx);",
            "",
            "\traw_spin_unlock(&lock->wait_lock);",
            "\tpreempt_enable();",
            "\treturn 0;",
            "",
            "err:",
            "\t__set_current_state(TASK_RUNNING);",
            "\t__mutex_remove_waiter(lock, &waiter);",
            "err_early_kill:",
            "\ttrace_contention_end(lock, ret);",
            "\traw_spin_unlock(&lock->wait_lock);",
            "\tdebug_mutex_free_waiter(&waiter);",
            "\tmutex_release(&lock->dep_map, ip);",
            "\tpreempt_enable();",
            "\treturn ret;",
            "}"
          ],
          "function_name": "mutex_optimistic_spin, mutex_optimistic_spin, mutex_unlock, ww_mutex_unlock, __mutex_lock_common",
          "description": "实现乐观自旋逻辑和锁解除操作，通过原子操作和同步机制管理锁竞争，支持带资源检查的锁操作。",
          "similarity": 0.6188544034957886
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 1059,
          "end_line": 1129,
          "content": [
            "static noinline int __sched",
            "__mutex_lock_interruptible_slowpath(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "static noinline int __sched",
            "__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0,",
            "\t\t\t       _RET_IP_, ctx);",
            "}",
            "static noinline int __sched",
            "__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,",
            "\t\t\t\t\t    struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0,",
            "\t\t\t       _RET_IP_, ctx);",
            "}",
            "int __sched mutex_trylock(struct mutex *lock)",
            "{",
            "\tbool locked;",
            "",
            "\tMUTEX_WARN_ON(lock->magic != lock);",
            "",
            "\tlocked = __mutex_trylock(lock);",
            "\tif (locked)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn locked;",
            "}",
            "int __sched",
            "ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(&lock->base)) {",
            "\t\tif (ctx)",
            "\t\t\tww_mutex_set_context_fastpath(lock, ctx);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn __ww_mutex_lock_slowpath(lock, ctx);",
            "}",
            "int __sched",
            "ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(&lock->base)) {",
            "\t\tif (ctx)",
            "\t\t\tww_mutex_set_context_fastpath(lock, ctx);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn __ww_mutex_lock_interruptible_slowpath(lock, ctx);",
            "}",
            "int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock)",
            "{",
            "\t/* dec if we can't possibly hit 0 */",
            "\tif (atomic_add_unless(cnt, -1, 1))",
            "\t\treturn 0;",
            "\t/* we might hit 0, so take the lock */",
            "\tmutex_lock(lock);",
            "\tif (!atomic_dec_and_test(cnt)) {",
            "\t\t/* when we actually did the dec, we didn't hit 0 */",
            "\t\tmutex_unlock(lock);",
            "\t\treturn 0;",
            "\t}",
            "\t/* we hit 0, and we hold the lock */",
            "\treturn 1;",
            "}"
          ],
          "function_name": "__mutex_lock_interruptible_slowpath, __ww_mutex_lock_slowpath, __ww_mutex_lock_interruptible_slowpath, mutex_trylock, ww_mutex_lock, ww_mutex_lock_interruptible, atomic_dec_and_mutex_lock",
          "description": "提供互斥锁快速路径与慢速路径切换支持，包含原子计数器递减与锁获取协同机制",
          "similarity": 0.594551682472229
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 758,
          "end_line": 862,
          "content": [
            "static int __sched",
            "__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t     struct lockdep_map *nest_lock, unsigned long ip)",
            "{",
            "\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);",
            "}",
            "static int __sched",
            "__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)",
            "{",
            "\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);",
            "}",
            "int ww_mutex_trylock(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)",
            "{",
            "\tif (!ww_ctx)",
            "\t\treturn mutex_trylock(&ww->base);",
            "",
            "\tMUTEX_WARN_ON(ww->base.magic != &ww->base);",
            "",
            "\t/*",
            "\t * Reset the wounded flag after a kill. No other process can",
            "\t * race and wound us here, since they can't have a valid owner",
            "\t * pointer if we don't have any locks held.",
            "\t */",
            "\tif (ww_ctx->acquired == 0)",
            "\t\tww_ctx->wounded = 0;",
            "",
            "\tif (__mutex_trylock(&ww->base)) {",
            "\t\tww_mutex_set_context_fastpath(ww, ww_ctx);",
            "\t\tmutex_acquire_nest(&ww->base.dep_map, 0, 1, &ww_ctx->dep_map, _RET_IP_);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void __sched",
            "mutex_lock_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched",
            "_mutex_lock_nest_lock(struct mutex *lock, struct lockdep_map *nest)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, nest, _RET_IP_);",
            "}",
            "int __sched",
            "mutex_lock_killable_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\treturn __mutex_lock(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);",
            "}",
            "int __sched",
            "mutex_lock_interruptible_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched",
            "mutex_lock_io_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\tint token;",
            "",
            "\tmight_sleep();",
            "",
            "\ttoken = io_schedule_prepare();",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE,",
            "\t\t\t    subclass, NULL, _RET_IP_, NULL, 0);",
            "\tio_schedule_finish(token);",
            "}",
            "static inline int",
            "ww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH",
            "\tunsigned tmp;",
            "",
            "\tif (ctx->deadlock_inject_countdown-- == 0) {",
            "\t\ttmp = ctx->deadlock_inject_interval;",
            "\t\tif (tmp > UINT_MAX/4)",
            "\t\t\ttmp = UINT_MAX;",
            "\t\telse",
            "\t\t\ttmp = tmp*2 + tmp + tmp/2;",
            "",
            "\t\tctx->deadlock_inject_interval = tmp;",
            "\t\tctx->deadlock_inject_countdown = tmp;",
            "\t\tctx->contending_lock = lock;",
            "",
            "\t\tww_mutex_unlock(lock);",
            "",
            "\t\treturn -EDEADLK;",
            "\t}",
            "#endif",
            "",
            "\treturn 0;",
            "}",
            "int __sched",
            "ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tret =  __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE,",
            "\t\t\t       0, _RET_IP_, ctx);",
            "\tif (!ret && ctx && ctx->acquired > 1)",
            "\t\treturn ww_mutex_deadlock_injection(lock, ctx);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__mutex_lock, __ww_mutex_lock, ww_mutex_trylock, mutex_lock_nested, _mutex_lock_nest_lock, mutex_lock_killable_nested, mutex_lock_interruptible_nested, mutex_lock_io_nested, ww_mutex_deadlock_injection, ww_mutex_lock",
          "description": "封装多种锁获取接口，处理嵌套锁、可中断锁及死锁注入逻辑，协调锁持有者与等待者的交互关系。",
          "similarity": 0.5929575562477112
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 1,
          "end_line": 45,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * kernel/locking/mutex.c",
            " *",
            " * Mutexes: blocking mutual exclusion locks",
            " *",
            " * Started by Ingo Molnar:",
            " *",
            " *  Copyright (C) 2004, 2005, 2006 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>",
            " *",
            " * Many thanks to Arjan van de Ven, Thomas Gleixner, Steven Rostedt and",
            " * David Howells for suggestions and improvements.",
            " *",
            " *  - Adaptive spinning for mutexes by Peter Zijlstra. (Ported to mainline",
            " *    from the -rt tree, where it was originally implemented for rtmutexes",
            " *    by Steven Rostedt, based on work by Gregory Haskins, Peter Morreale",
            " *    and Sven Dietrich.",
            " *",
            " * Also see Documentation/locking/mutex-design.rst.",
            " */",
            "#include <linux/mutex.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/osq_lock.h>",
            "#include <linux/hung_task.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/lock.h>",
            "",
            "#ifndef CONFIG_PREEMPT_RT",
            "#include \"mutex.h\"",
            "",
            "#ifdef CONFIG_DEBUG_MUTEXES",
            "# define MUTEX_WARN_ON(cond) DEBUG_LOCKS_WARN_ON(cond)",
            "#else",
            "# define MUTEX_WARN_ON(cond)",
            "#endif",
            ""
          ],
          "function_name": null,
          "description": "声明互斥锁模块的头文件和基本配置，初始化互斥锁结构体并设置等待队列及调试信息。",
          "similarity": 0.5646389722824097
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 46,
          "end_line": 151,
          "content": [
            "void",
            "__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)",
            "{",
            "\tatomic_long_set(&lock->owner, 0);",
            "\traw_spin_lock_init(&lock->wait_lock);",
            "\tINIT_LIST_HEAD(&lock->wait_list);",
            "#ifdef CONFIG_MUTEX_SPIN_ON_OWNER",
            "\tosq_lock_init(&lock->osq);",
            "#endif",
            "",
            "\tdebug_mutex_init(lock, name, key);",
            "}",
            "bool mutex_is_locked(struct mutex *lock)",
            "{",
            "\treturn __mutex_owner(lock) != NULL;",
            "}",
            "static inline unsigned long __owner_flags(unsigned long owner)",
            "{",
            "\treturn owner & MUTEX_FLAGS;",
            "}",
            "unsigned long mutex_get_owner(struct mutex *lock)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\treturn (unsigned long)__owner_task(owner);",
            "}",
            "static inline bool __mutex_trylock_or_handoff(struct mutex *lock, bool handoff)",
            "{",
            "\treturn !__mutex_trylock_common(lock, handoff);",
            "}",
            "static inline bool __mutex_trylock(struct mutex *lock)",
            "{",
            "\treturn !__mutex_trylock_common(lock, false);",
            "}",
            "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "\tunsigned long zero = 0UL;",
            "",
            "\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "static __always_inline bool __mutex_unlock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "",
            "\treturn atomic_long_try_cmpxchg_release(&lock->owner, &curr, 0UL);",
            "}",
            "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_or(flag, &lock->owner);",
            "}",
            "static inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_andnot(flag, &lock->owner);",
            "}",
            "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;",
            "}",
            "static void",
            "__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,",
            "\t\t   struct list_head *list)",
            "{",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_set_blocker(lock, BLOCKER_TYPE_MUTEX);",
            "#endif",
            "\tdebug_mutex_add_waiter(lock, waiter, current);",
            "",
            "\tlist_add_tail(&waiter->list, list);",
            "\tif (__mutex_waiter_is_first(lock, waiter))",
            "\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);",
            "}",
            "static void",
            "__mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\tlist_del(&waiter->list);",
            "\tif (likely(list_empty(&lock->wait_list)))",
            "\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);",
            "",
            "\tdebug_mutex_remove_waiter(lock, waiter, current);",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_clear_blocker();",
            "#endif",
            "}",
            "static void __mutex_handoff(struct mutex *lock, struct task_struct *task)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\tfor (;;) {",
            "\t\tunsigned long new;",
            "",
            "\t\tMUTEX_WARN_ON(__owner_task(owner) != current);",
            "\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);",
            "",
            "\t\tnew = (owner & MUTEX_FLAG_WAITERS);",
            "\t\tnew |= (unsigned long)task;",
            "\t\tif (task)",
            "\t\t\tnew |= MUTEX_FLAG_PICKUP;",
            "",
            "\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, new))",
            "\t\t\tbreak;",
            "\t}",
            "}"
          ],
          "function_name": "__mutex_init, mutex_is_locked, __owner_flags, mutex_get_owner, __mutex_trylock_or_handoff, __mutex_trylock, __mutex_trylock_fast, __mutex_unlock_fast, __mutex_set_flag, __mutex_clear_flag, __mutex_waiter_is_first, __mutex_add_waiter, __mutex_remove_waiter, __mutex_handoff",
          "description": "实现互斥锁核心操作，包括初始化、状态检查、快速尝试加锁、标志位操作及等待者链表管理。",
          "similarity": 0.5586954951286316
        }
      ]
    },
    {
      "source_file": "kernel/power/wakelock.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:29:10\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `power\\wakelock.c`\n\n---\n\n# `power/wakelock.c` 技术文档\n\n## 1. 文件概述\n\n`power/wakelock.c` 实现了 Linux 内核中面向用户空间的 **wakelock（唤醒锁）机制**，允许用户空间程序通过 sysfs 接口创建、激活和释放唤醒锁，以防止系统在特定任务执行期间进入低功耗状态（如 suspend）。该实现借鉴了 Android 系统中的 wakelock 接口，但基于标准 Linux 内核的 `wakeup_source` 基础设施，提供更安全、可配置的用户空间电源管理能力。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct wakelock`**  \n  表示一个用户空间可操作的唤醒锁对象：\n  - `name`：唤醒锁名称（用户指定）\n  - `node`：用于在红黑树 `wakelocks_tree` 中组织所有 wakelock\n  - `ws`：指向内核 `wakeup_source` 对象，实际执行电源管理逻辑\n  - `lru`（条件编译）：用于垃圾回收（GC）机制的 LRU 链表节点（当 `CONFIG_PM_WAKELOCKS_GC` 启用时）\n\n### 主要函数\n\n- **`pm_show_wakelocks(char *buf, bool show_active)`**  \n  将当前所有（活跃或非活跃）wakelock 名称输出到缓冲区，供 sysfs 读取（如 `/sys/power/wake_lock` 或 `/sys/power/wake_unlock`）。\n\n- **`pm_wake_lock(const char *buf)`**  \n  用户空间通过写入 `/sys/power/wake_lock` 触发此函数，用于**获取**指定名称的 wakelock。支持可选超时参数（单位：纳秒）。\n\n- **`pm_wake_unlock(const char *buf)`**  \n  用户空间通过写入 `/sys/power/wake_unlock` 触发此函数，用于**释放**指定名称的 wakelock。\n\n- **`wakelock_lookup_add(const char *name, size_t len, bool add_if_not_found)`**  \n  在全局红黑树中查找或创建 wakelock 对象，是 `pm_wake_lock` 和 `pm_wake_unlock` 的核心辅助函数。\n\n- **`__wakelocks_gc(struct work_struct *work)`**（条件编译）  \n  垃圾回收工作函数，定期清理长时间未使用且非活跃的 wakelock 对象（当 `CONFIG_PM_WAKELOCKS_GC` 启用时）。\n\n### 辅助机制\n\n- **数量限制**：通过 `CONFIG_PM_WAKELOCKS_LIMIT` 控制系统中 wakelock 的最大数量。\n- **LRU 管理**：通过 `wakelocks_lru_add` / `wakelocks_lru_most_recent` 维护最近使用顺序。\n- **自动回收**：通过 `wakelocks_gc()` 触发异步 GC 工作队列。\n\n## 3. 关键实现\n\n### 红黑树管理\n所有 `wakelock` 对象通过名称作为键，存储在全局红黑树 `wakelocks_tree` 中，确保 O(log n) 时间复杂度的查找、插入和删除操作。\n\n### 唤醒源集成\n每个 `wakelock` 封装一个 `wakeup_source`（通过 `wakeup_source_register()` 创建），实际的电源阻止逻辑由内核 PM 子系统的 `wakeup_source` 机制处理：\n- `__pm_stay_awake(ws)`：永久保持唤醒（直到显式释放）\n- `__pm_wakeup_event(ws, timeout_ms)`：带超时的唤醒\n- `__pm_relax(ws)`：释放唤醒锁\n\n### 安全与权限控制\n- 仅具备 `CAP_BLOCK_SUSPEND` 能力的进程可操作 wakelock（防止普通用户滥用导致无法休眠）。\n- 名称解析严格处理空格和换行符，防止注入或解析错误。\n\n### 垃圾回收机制（可选）\n当启用 `CONFIG_PM_WAKELOCKS_GC`：\n- 每次访问 wakelock 时将其移至 LRU 链表头部（`wakelocks_lru_most_recent`）。\n- 每进行 `WL_GC_COUNT_MAX`（默认 100）次操作后，调度 GC 工作。\n- GC 遍历 LRU 链表（从最旧开始），删除满足以下条件的对象：\n  - 非活跃（`!active`）\n  - 空闲时间超过 `WL_GC_TIME_SEC`（默认 300 秒）\n\n### 数量限制（可选）\n当 `CONFIG_PM_WAKELOCKS_LIMIT > 0` 时，系统维护 `number_of_wakelocks` 计数器，防止用户空间创建过多 wakelock 耗尽内存。\n\n## 4. 依赖关系\n\n- **内核头文件**：\n  - `<linux/wakeup_source.h>`（通过 `\"power.h\"` 间接包含）：提供 `wakeup_source` 相关 API\n  - `<linux/sysfs.h>`：通过 `sysfs_emit_at` 实现 sysfs 输出\n  - `<linux/workqueue.h>`：用于 GC 异步任务调度\n  - `<linux/rbtree.h>`：红黑树数据结构支持\n  - `<linux/capability.h>`：权限检查\n\n- **内核子系统**：\n  - **电源管理 (PM) 子系统**：依赖 `wakeup_source` 基础设施实现实际的 suspend 阻止逻辑。\n  - **sysfs**：通过 sysfs 文件（如 `/sys/power/wake_lock`）暴露用户接口。\n  - **内存管理**：使用 `kzalloc`/`kstrndup`/`kfree` 管理动态内存。\n\n- **配置选项**：\n  - `CONFIG_PM_WAKELOCKS`：主开关\n  - `CONFIG_PM_WAKELOCKS_LIMIT`：限制最大数量\n  - `CONFIG_PM_WAKELOCKS_GC`：启用自动垃圾回收\n\n## 5. 使用场景\n\n- **Android 兼容层**：为基于 Android 的系统提供标准 Linux 内核上的 wakelock 支持，无需修改用户空间应用。\n- **用户空间电源控制**：允许特权应用（如媒体播放器、下载管理器）在执行关键任务时阻止系统休眠。\n- **调试与监控**：通过读取 `/sys/power/wake_lock` 查看当前活跃的 wakelock，辅助电源问题诊断。\n- **资源受限设备**：通过 `CONFIG_PM_WAKELOCKS_LIMIT` 和 GC 机制防止内存泄漏，适用于嵌入式或移动设备。",
      "similarity": 0.5536249279975891,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/power/wakelock.c",
          "start_line": 38,
          "end_line": 172,
          "content": [
            "ssize_t pm_show_wakelocks(char *buf, bool show_active)",
            "{",
            "\tstruct rb_node *node;",
            "\tstruct wakelock *wl;",
            "\tint len = 0;",
            "",
            "\tmutex_lock(&wakelocks_lock);",
            "",
            "\tfor (node = rb_first(&wakelocks_tree); node; node = rb_next(node)) {",
            "\t\twl = rb_entry(node, struct wakelock, node);",
            "\t\tif (wl->ws->active == show_active)",
            "\t\t\tlen += sysfs_emit_at(buf, len, \"%s \", wl->name);",
            "\t}",
            "",
            "\tif (len > 0)",
            "\t\t--len;",
            "",
            "\tlen += sysfs_emit_at(buf, len, \"\\n\");",
            "",
            "\tmutex_unlock(&wakelocks_lock);",
            "\treturn len;",
            "}",
            "static inline bool wakelocks_limit_exceeded(void)",
            "{",
            "\treturn number_of_wakelocks > CONFIG_PM_WAKELOCKS_LIMIT;",
            "}",
            "static inline void increment_wakelocks_number(void)",
            "{",
            "\tnumber_of_wakelocks++;",
            "}",
            "static inline void decrement_wakelocks_number(void)",
            "{",
            "\tnumber_of_wakelocks--;",
            "}",
            "static inline bool wakelocks_limit_exceeded(void) { return false; }",
            "static inline void increment_wakelocks_number(void) {}",
            "static inline void decrement_wakelocks_number(void) {}",
            "static inline void wakelocks_lru_add(struct wakelock *wl)",
            "{",
            "\tlist_add(&wl->lru, &wakelocks_lru_list);",
            "}",
            "static inline void wakelocks_lru_most_recent(struct wakelock *wl)",
            "{",
            "\tlist_move(&wl->lru, &wakelocks_lru_list);",
            "}",
            "static void __wakelocks_gc(struct work_struct *work)",
            "{",
            "\tstruct wakelock *wl, *aux;",
            "\tktime_t now;",
            "",
            "\tmutex_lock(&wakelocks_lock);",
            "",
            "\tnow = ktime_get();",
            "\tlist_for_each_entry_safe_reverse(wl, aux, &wakelocks_lru_list, lru) {",
            "\t\tu64 idle_time_ns;",
            "\t\tbool active;",
            "",
            "\t\tspin_lock_irq(&wl->ws->lock);",
            "\t\tidle_time_ns = ktime_to_ns(ktime_sub(now, wl->ws->last_time));",
            "\t\tactive = wl->ws->active;",
            "\t\tspin_unlock_irq(&wl->ws->lock);",
            "",
            "\t\tif (idle_time_ns < ((u64)WL_GC_TIME_SEC * NSEC_PER_SEC))",
            "\t\t\tbreak;",
            "",
            "\t\tif (!active) {",
            "\t\t\twakeup_source_unregister(wl->ws);",
            "\t\t\trb_erase(&wl->node, &wakelocks_tree);",
            "\t\t\tlist_del(&wl->lru);",
            "\t\t\tkfree(wl->name);",
            "\t\t\tkfree(wl);",
            "\t\t\tdecrement_wakelocks_number();",
            "\t\t}",
            "\t}",
            "\twakelocks_gc_count = 0;",
            "",
            "\tmutex_unlock(&wakelocks_lock);",
            "}",
            "static void wakelocks_gc(void)",
            "{",
            "\tif (++wakelocks_gc_count <= WL_GC_COUNT_MAX)",
            "\t\treturn;",
            "",
            "\tschedule_work(&wakelock_work);",
            "}",
            "static inline void wakelocks_lru_add(struct wakelock *wl) {}",
            "static inline void wakelocks_lru_most_recent(struct wakelock *wl) {}",
            "static inline void wakelocks_gc(void) {}",
            "int pm_wake_lock(const char *buf)",
            "{",
            "\tconst char *str = buf;",
            "\tstruct wakelock *wl;",
            "\tu64 timeout_ns = 0;",
            "\tsize_t len;",
            "\tint ret = 0;",
            "",
            "\tif (!capable(CAP_BLOCK_SUSPEND))",
            "\t\treturn -EPERM;",
            "",
            "\twhile (*str && !isspace(*str))",
            "\t\tstr++;",
            "",
            "\tlen = str - buf;",
            "\tif (!len)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (*str && *str != '\\n') {",
            "\t\t/* Find out if there's a valid timeout string appended. */",
            "\t\tret = kstrtou64(skip_spaces(str), 10, &timeout_ns);",
            "\t\tif (ret)",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tmutex_lock(&wakelocks_lock);",
            "",
            "\twl = wakelock_lookup_add(buf, len, true);",
            "\tif (IS_ERR(wl)) {",
            "\t\tret = PTR_ERR(wl);",
            "\t\tgoto out;",
            "\t}",
            "\tif (timeout_ns) {",
            "\t\tu64 timeout_ms = timeout_ns + NSEC_PER_MSEC - 1;",
            "",
            "\t\tdo_div(timeout_ms, NSEC_PER_MSEC);",
            "\t\t__pm_wakeup_event(wl->ws, timeout_ms);",
            "\t} else {",
            "\t\t__pm_stay_awake(wl->ws);",
            "\t}",
            "",
            "\twakelocks_lru_most_recent(wl);",
            "",
            " out:",
            "\tmutex_unlock(&wakelocks_lock);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "pm_show_wakelocks, wakelocks_limit_exceeded, increment_wakelocks_number, decrement_wakelocks_number, wakelocks_limit_exceeded, increment_wakelocks_number, decrement_wakelocks_number, wakelocks_lru_add, wakelocks_lru_most_recent, __wakelocks_gc, wakelocks_gc, wakelocks_lru_add, wakelocks_lru_most_recent, wakelocks_gc, pm_wake_lock",
          "description": "实现唤醒锁状态展示、计数控制、LRU列表维护及垃圾回收逻辑，包含唤醒锁激活/释放接口，通过工作队列异步清理闲置唤醒源",
          "similarity": 0.5657628774642944
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/power/wakelock.c",
          "start_line": 254,
          "end_line": 288,
          "content": [
            "int pm_wake_unlock(const char *buf)",
            "{",
            "\tstruct wakelock *wl;",
            "\tsize_t len;",
            "\tint ret = 0;",
            "",
            "\tif (!capable(CAP_BLOCK_SUSPEND))",
            "\t\treturn -EPERM;",
            "",
            "\tlen = strlen(buf);",
            "\tif (!len)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (buf[len-1] == '\\n')",
            "\t\tlen--;",
            "",
            "\tif (!len)",
            "\t\treturn -EINVAL;",
            "",
            "\tmutex_lock(&wakelocks_lock);",
            "",
            "\twl = wakelock_lookup_add(buf, len, false);",
            "\tif (IS_ERR(wl)) {",
            "\t\tret = PTR_ERR(wl);",
            "\t\tgoto out;",
            "\t}",
            "\t__pm_relax(wl->ws);",
            "",
            "\twakelocks_lru_most_recent(wl);",
            "\twakelocks_gc();",
            "",
            " out:",
            "\tmutex_unlock(&wakelocks_lock);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "pm_wake_unlock",
          "description": "提供唤醒锁解除接口，通过名称匹配目标唤醒锁并调用__pm_relax释放，同步更新LRU顺序并触发动态垃圾回收机制",
          "similarity": 0.5635524988174438
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/power/wakelock.c",
          "start_line": 1,
          "end_line": 37,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * kernel/power/wakelock.c",
            " *",
            " * User space wakeup sources support.",
            " *",
            " * Copyright (C) 2012 Rafael J. Wysocki <rjw@sisk.pl>",
            " *",
            " * This code is based on the analogous interface allowing user space to",
            " * manipulate wakelocks on Android.",
            " */",
            "",
            "#include <linux/capability.h>",
            "#include <linux/ctype.h>",
            "#include <linux/device.h>",
            "#include <linux/err.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/list.h>",
            "#include <linux/rbtree.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "",
            "#include \"power.h\"",
            "",
            "static DEFINE_MUTEX(wakelocks_lock);",
            "",
            "struct wakelock {",
            "\tchar\t\t\t*name;",
            "\tstruct rb_node\t\tnode;",
            "\tstruct wakeup_source\t*ws;",
            "#ifdef CONFIG_PM_WAKELOCKS_GC",
            "\tstruct list_head\tlru;",
            "#endif",
            "};",
            "",
            "static struct rb_root wakelocks_tree = RB_ROOT;",
            ""
          ],
          "function_name": null,
          "description": "定义唤醒锁数据结构及其红黑树管理基础，包含名称字段、RB节点、唤醒源指针及LRU链表节点（CONFIG_PM_WAKELOCKS_GC启用时），并初始化红黑树根节点",
          "similarity": 0.5492312908172607
        }
      ]
    }
  ]
}