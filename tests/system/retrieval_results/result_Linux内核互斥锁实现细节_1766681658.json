{
  "query": "Linux内核互斥锁实现细节",
  "timestamp": "2025-12-26 00:54:18",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/mutex.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:42:50\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\mutex.c`\n\n---\n\n# Linux 内核互斥锁（mutex）实现文档\n\n## 1. 文件概述\n\n`locking/mutex.c` 是 Linux 内核中互斥锁（mutex）的核心实现文件，提供了基于阻塞的互斥同步原语。该文件实现了高效、可睡眠的互斥锁机制，支持自旋优化、锁移交（handoff）、调试功能以及与调度器、死锁检测等子系统的深度集成。互斥锁用于保护临界区，确保同一时间只有一个任务可以持有锁，适用于需要长时间持有锁或可能睡眠的场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `__mutex_init()`：初始化互斥锁对象\n- `mutex_is_locked()`：检查互斥锁是否已被持有\n- `mutex_get_owner()`：获取当前锁持有者的任务指针（仅用于调试）\n- `__mutex_trylock()`：尝试获取互斥锁（非阻塞）\n- `__mutex_trylock_fast()`：快速路径尝试获取未竞争的锁\n- `__mutex_unlock_fast()`：快速路径释放锁\n- `__mutex_lock_slowpath()`：慢速路径获取锁（包含睡眠和等待逻辑）\n- `__mutex_handoff()`：将锁所有权移交给指定任务\n- `__mutex_add_waiter()` / `__mutex_remove_waiter()`：管理等待队列\n\n### 关键数据结构\n\n- `struct mutex`：互斥锁核心结构体\n  - `atomic_long_t owner`：原子存储锁持有者指针和状态标志\n  - `raw_spinlock_t wait_lock`：保护等待队列的自旋锁\n  - `struct list_head wait_list`：等待获取锁的任务队列\n  - `struct optimistic_spin_queue osq`：用于自旋优化的队列（CONFIG_MUTEX_SPIN_ON_OWNER）\n\n### 状态标志位\n\n- `MUTEX_FLAG_WAITERS (0x01)`：表示存在等待者，解锁时需唤醒\n- `MUTEX_FLAG_HANDOFF (0x02)`：表示需要将锁移交给队首等待者\n- `MUTEX_FLAG_PICKUP (0x04)`：表示锁已被移交给特定任务，等待其获取\n\n## 3. 关键实现\n\n### 锁状态编码\n互斥锁的 `owner` 字段采用指针-标志位混合编码：利用 `task_struct` 指针的低 3 位（因内存对齐保证为 0）存储状态标志。这种设计避免了额外的内存访问，提高了原子操作效率。\n\n### 快慢路径分离\n- **快速路径**：针对无竞争场景，直接通过原子比较交换（cmpxchg）获取/释放锁，避免函数调用开销\n- **慢速路径**：处理竞争情况，包含自旋等待、任务阻塞、唤醒等复杂逻辑\n\n### 自适应自旋（Adaptive Spinning）\n在 `CONFIG_MUTEX_SPIN_ON_OWNER` 配置下，当检测到锁持有者正在运行时，当前任务会先自旋等待而非立即睡眠，减少上下文切换开销。使用 OSQ（Optimistic Spin Queue）机制协调多个自旋任务。\n\n### 锁移交机制（Handoff）\n通过 `MUTEX_FLAG_HANDOFF` 和 `MUTEX_FLAG_PICKUP` 标志实现高效的锁移交：\n1. 解锁者设置 `HANDOFF` 标志并唤醒队首等待者\n2. 被唤醒任务在获取锁时检测到 `HANDOFF`，设置 `PICKUP` 标志\n3. 解锁者通过 `__mutex_handoff()` 直接将所有权转移给指定任务\n避免了唤醒后再次竞争的问题，提高实时性。\n\n### 调试支持\n- `CONFIG_DEBUG_MUTEXES`：提供锁状态验证、死锁检测\n- `CONFIG_DETECT_HUNG_TASK_BLOCKER`：集成 hung task 检测，记录阻塞源\n- `lockdep`：通过 `debug_mutex_*` 函数集成锁依赖验证\n\n## 4. 依赖关系\n\n### 头文件依赖\n- `<linux/mutex.h>` / `<linux/ww_mutex.h>`：互斥锁接口定义\n- `<linux/sched/*.h>`：调度器相关功能（睡眠、唤醒、实时任务）\n- `<linux/spinlock.h>`：底层自旋锁实现\n- `<linux/osq_lock.h>`：乐观自旋队列支持\n- `<linux/hung_task.h>`：hung task 检测集成\n- `<trace/events/lock.h>`：锁事件跟踪点\n\n### 子系统交互\n- **调度器**：通过 `schedule()` 实现任务阻塞，`wake_q` 机制批量唤醒\n- **内存管理**：依赖 `task_struct` 的内存对齐特性\n- **实时补丁（PREEMPT_RT）**：非 RT 配置下编译此文件（`#ifndef CONFIG_PREEMPT_RT`）\n- **调试子系统**：与 lockdep、hung task detector 深度集成\n\n## 5. 使用场景\n\n### 典型应用场景\n- **长临界区保护**：当临界区执行时间较长或包含可能睡眠的操作（如内存分配、I/O）\n- **驱动程序同步**：设备驱动中保护硬件寄存器访问或共享数据结构\n- **文件系统操作**：保护 inode、dentry 等元数据结构\n- **内核子系统互斥**：如网络协议栈、块设备层等需要互斥访问的场景\n\n### 使用约束\n- **不可递归**：同一任务重复获取会导致死锁\n- **必须配对使用**：获取锁的任务必须负责释放\n- **禁止中断上下文使用**：因可能睡眠，只能在进程上下文使用\n- **内存生命周期**：锁对象内存不能在持有锁时释放\n\n### 性能考量\n- 无竞争场景：纳秒级延迟（快速路径原子操作）\n- 有竞争场景：微秒级延迟（自旋优化）或毫秒级（任务切换）\n- 适用于中低频竞争场景，高频竞争建议使用读写锁或 RCU",
      "similarity": 0.6850554347038269,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 46,
          "end_line": 151,
          "content": [
            "void",
            "__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)",
            "{",
            "\tatomic_long_set(&lock->owner, 0);",
            "\traw_spin_lock_init(&lock->wait_lock);",
            "\tINIT_LIST_HEAD(&lock->wait_list);",
            "#ifdef CONFIG_MUTEX_SPIN_ON_OWNER",
            "\tosq_lock_init(&lock->osq);",
            "#endif",
            "",
            "\tdebug_mutex_init(lock, name, key);",
            "}",
            "bool mutex_is_locked(struct mutex *lock)",
            "{",
            "\treturn __mutex_owner(lock) != NULL;",
            "}",
            "static inline unsigned long __owner_flags(unsigned long owner)",
            "{",
            "\treturn owner & MUTEX_FLAGS;",
            "}",
            "unsigned long mutex_get_owner(struct mutex *lock)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\treturn (unsigned long)__owner_task(owner);",
            "}",
            "static inline bool __mutex_trylock_or_handoff(struct mutex *lock, bool handoff)",
            "{",
            "\treturn !__mutex_trylock_common(lock, handoff);",
            "}",
            "static inline bool __mutex_trylock(struct mutex *lock)",
            "{",
            "\treturn !__mutex_trylock_common(lock, false);",
            "}",
            "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "\tunsigned long zero = 0UL;",
            "",
            "\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "static __always_inline bool __mutex_unlock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "",
            "\treturn atomic_long_try_cmpxchg_release(&lock->owner, &curr, 0UL);",
            "}",
            "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_or(flag, &lock->owner);",
            "}",
            "static inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_andnot(flag, &lock->owner);",
            "}",
            "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;",
            "}",
            "static void",
            "__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,",
            "\t\t   struct list_head *list)",
            "{",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_set_blocker(lock, BLOCKER_TYPE_MUTEX);",
            "#endif",
            "\tdebug_mutex_add_waiter(lock, waiter, current);",
            "",
            "\tlist_add_tail(&waiter->list, list);",
            "\tif (__mutex_waiter_is_first(lock, waiter))",
            "\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);",
            "}",
            "static void",
            "__mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\tlist_del(&waiter->list);",
            "\tif (likely(list_empty(&lock->wait_list)))",
            "\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);",
            "",
            "\tdebug_mutex_remove_waiter(lock, waiter, current);",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_clear_blocker();",
            "#endif",
            "}",
            "static void __mutex_handoff(struct mutex *lock, struct task_struct *task)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\tfor (;;) {",
            "\t\tunsigned long new;",
            "",
            "\t\tMUTEX_WARN_ON(__owner_task(owner) != current);",
            "\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);",
            "",
            "\t\tnew = (owner & MUTEX_FLAG_WAITERS);",
            "\t\tnew |= (unsigned long)task;",
            "\t\tif (task)",
            "\t\t\tnew |= MUTEX_FLAG_PICKUP;",
            "",
            "\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, new))",
            "\t\t\tbreak;",
            "\t}",
            "}"
          ],
          "function_name": "__mutex_init, mutex_is_locked, __owner_flags, mutex_get_owner, __mutex_trylock_or_handoff, __mutex_trylock, __mutex_trylock_fast, __mutex_unlock_fast, __mutex_set_flag, __mutex_clear_flag, __mutex_waiter_is_first, __mutex_add_waiter, __mutex_remove_waiter, __mutex_handoff",
          "description": "实现互斥锁核心操作，包括初始化、状态检查、快速尝试加锁、标志位操作及等待者链表管理。",
          "similarity": 0.7171521186828613
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 1,
          "end_line": 45,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * kernel/locking/mutex.c",
            " *",
            " * Mutexes: blocking mutual exclusion locks",
            " *",
            " * Started by Ingo Molnar:",
            " *",
            " *  Copyright (C) 2004, 2005, 2006 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>",
            " *",
            " * Many thanks to Arjan van de Ven, Thomas Gleixner, Steven Rostedt and",
            " * David Howells for suggestions and improvements.",
            " *",
            " *  - Adaptive spinning for mutexes by Peter Zijlstra. (Ported to mainline",
            " *    from the -rt tree, where it was originally implemented for rtmutexes",
            " *    by Steven Rostedt, based on work by Gregory Haskins, Peter Morreale",
            " *    and Sven Dietrich.",
            " *",
            " * Also see Documentation/locking/mutex-design.rst.",
            " */",
            "#include <linux/mutex.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/osq_lock.h>",
            "#include <linux/hung_task.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/lock.h>",
            "",
            "#ifndef CONFIG_PREEMPT_RT",
            "#include \"mutex.h\"",
            "",
            "#ifdef CONFIG_DEBUG_MUTEXES",
            "# define MUTEX_WARN_ON(cond) DEBUG_LOCKS_WARN_ON(cond)",
            "#else",
            "# define MUTEX_WARN_ON(cond)",
            "#endif",
            ""
          ],
          "function_name": null,
          "description": "声明互斥锁模块的头文件和基本配置，初始化互斥锁结构体并设置等待队列及调试信息。",
          "similarity": 0.6944472193717957
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 1059,
          "end_line": 1129,
          "content": [
            "static noinline int __sched",
            "__mutex_lock_interruptible_slowpath(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "static noinline int __sched",
            "__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0,",
            "\t\t\t       _RET_IP_, ctx);",
            "}",
            "static noinline int __sched",
            "__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,",
            "\t\t\t\t\t    struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0,",
            "\t\t\t       _RET_IP_, ctx);",
            "}",
            "int __sched mutex_trylock(struct mutex *lock)",
            "{",
            "\tbool locked;",
            "",
            "\tMUTEX_WARN_ON(lock->magic != lock);",
            "",
            "\tlocked = __mutex_trylock(lock);",
            "\tif (locked)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn locked;",
            "}",
            "int __sched",
            "ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(&lock->base)) {",
            "\t\tif (ctx)",
            "\t\t\tww_mutex_set_context_fastpath(lock, ctx);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn __ww_mutex_lock_slowpath(lock, ctx);",
            "}",
            "int __sched",
            "ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(&lock->base)) {",
            "\t\tif (ctx)",
            "\t\t\tww_mutex_set_context_fastpath(lock, ctx);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn __ww_mutex_lock_interruptible_slowpath(lock, ctx);",
            "}",
            "int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock)",
            "{",
            "\t/* dec if we can't possibly hit 0 */",
            "\tif (atomic_add_unless(cnt, -1, 1))",
            "\t\treturn 0;",
            "\t/* we might hit 0, so take the lock */",
            "\tmutex_lock(lock);",
            "\tif (!atomic_dec_and_test(cnt)) {",
            "\t\t/* when we actually did the dec, we didn't hit 0 */",
            "\t\tmutex_unlock(lock);",
            "\t\treturn 0;",
            "\t}",
            "\t/* we hit 0, and we hold the lock */",
            "\treturn 1;",
            "}"
          ],
          "function_name": "__mutex_lock_interruptible_slowpath, __ww_mutex_lock_slowpath, __ww_mutex_lock_interruptible_slowpath, mutex_trylock, ww_mutex_lock, ww_mutex_lock_interruptible, atomic_dec_and_mutex_lock",
          "description": "提供互斥锁快速路径与慢速路径切换支持，包含原子计数器递减与锁获取协同机制",
          "similarity": 0.6844576597213745
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 895,
          "end_line": 996,
          "content": [
            "int __sched",
            "ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tret = __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE,",
            "\t\t\t      0, _RET_IP_, ctx);",
            "",
            "\tif (!ret && ctx && ctx->acquired > 1)",
            "\t\treturn ww_mutex_deadlock_injection(lock, ctx);",
            "",
            "\treturn ret;",
            "}",
            "static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)",
            "{",
            "\tstruct task_struct *next = NULL;",
            "\tDEFINE_WAKE_Q(wake_q);",
            "\tunsigned long owner;",
            "",
            "\tmutex_release(&lock->dep_map, ip);",
            "",
            "\t/*",
            "\t * Release the lock before (potentially) taking the spinlock such that",
            "\t * other contenders can get on with things ASAP.",
            "\t *",
            "\t * Except when HANDOFF, in that case we must not clear the owner field,",
            "\t * but instead set it to the top waiter.",
            "\t */",
            "\towner = atomic_long_read(&lock->owner);",
            "\tfor (;;) {",
            "\t\tMUTEX_WARN_ON(__owner_task(owner) != current);",
            "\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);",
            "",
            "\t\tif (owner & MUTEX_FLAG_HANDOFF)",
            "\t\t\tbreak;",
            "",
            "\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, __owner_flags(owner))) {",
            "\t\t\tif (owner & MUTEX_FLAG_WAITERS)",
            "\t\t\t\tbreak;",
            "",
            "\t\t\treturn;",
            "\t\t}",
            "\t}",
            "",
            "\traw_spin_lock(&lock->wait_lock);",
            "\tdebug_mutex_unlock(lock);",
            "\tif (!list_empty(&lock->wait_list)) {",
            "\t\t/* get the first entry from the wait-list: */",
            "\t\tstruct mutex_waiter *waiter =",
            "\t\t\tlist_first_entry(&lock->wait_list,",
            "\t\t\t\t\t struct mutex_waiter, list);",
            "",
            "\t\tnext = waiter->task;",
            "",
            "\t\tdebug_mutex_wake_waiter(lock, waiter);",
            "\t\twake_q_add(&wake_q, next);",
            "\t}",
            "",
            "\tif (owner & MUTEX_FLAG_HANDOFF)",
            "\t\t__mutex_handoff(lock, next);",
            "",
            "\traw_spin_unlock(&lock->wait_lock);",
            "",
            "\twake_up_q(&wake_q);",
            "}",
            "int __sched mutex_lock_interruptible(struct mutex *lock)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(lock))",
            "\t\treturn 0;",
            "",
            "\treturn __mutex_lock_interruptible_slowpath(lock);",
            "}",
            "int __sched mutex_lock_killable(struct mutex *lock)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(lock))",
            "\t\treturn 0;",
            "",
            "\treturn __mutex_lock_killable_slowpath(lock);",
            "}",
            "void __sched mutex_lock_io(struct mutex *lock)",
            "{",
            "\tint token;",
            "",
            "\ttoken = io_schedule_prepare();",
            "\tmutex_lock(lock);",
            "\tio_schedule_finish(token);",
            "}",
            "static noinline void __sched",
            "__mutex_lock_slowpath(struct mutex *lock)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "static noinline int __sched",
            "__mutex_lock_killable_slowpath(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);",
            "}"
          ],
          "function_name": "ww_mutex_lock_interruptible, __mutex_unlock_slowpath, mutex_lock_interruptible, mutex_lock_killable, mutex_lock_io, __mutex_lock_slowpath, __mutex_lock_killable_slowpath",
          "description": "实现带死锁检测的递归互斥锁中断获取逻辑，处理锁状态转换、唤醒等待线程及异常注入场景",
          "similarity": 0.6397470235824585
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 758,
          "end_line": 862,
          "content": [
            "static int __sched",
            "__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t     struct lockdep_map *nest_lock, unsigned long ip)",
            "{",
            "\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);",
            "}",
            "static int __sched",
            "__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)",
            "{",
            "\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);",
            "}",
            "int ww_mutex_trylock(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)",
            "{",
            "\tif (!ww_ctx)",
            "\t\treturn mutex_trylock(&ww->base);",
            "",
            "\tMUTEX_WARN_ON(ww->base.magic != &ww->base);",
            "",
            "\t/*",
            "\t * Reset the wounded flag after a kill. No other process can",
            "\t * race and wound us here, since they can't have a valid owner",
            "\t * pointer if we don't have any locks held.",
            "\t */",
            "\tif (ww_ctx->acquired == 0)",
            "\t\tww_ctx->wounded = 0;",
            "",
            "\tif (__mutex_trylock(&ww->base)) {",
            "\t\tww_mutex_set_context_fastpath(ww, ww_ctx);",
            "\t\tmutex_acquire_nest(&ww->base.dep_map, 0, 1, &ww_ctx->dep_map, _RET_IP_);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void __sched",
            "mutex_lock_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched",
            "_mutex_lock_nest_lock(struct mutex *lock, struct lockdep_map *nest)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, nest, _RET_IP_);",
            "}",
            "int __sched",
            "mutex_lock_killable_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\treturn __mutex_lock(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);",
            "}",
            "int __sched",
            "mutex_lock_interruptible_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched",
            "mutex_lock_io_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\tint token;",
            "",
            "\tmight_sleep();",
            "",
            "\ttoken = io_schedule_prepare();",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE,",
            "\t\t\t    subclass, NULL, _RET_IP_, NULL, 0);",
            "\tio_schedule_finish(token);",
            "}",
            "static inline int",
            "ww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH",
            "\tunsigned tmp;",
            "",
            "\tif (ctx->deadlock_inject_countdown-- == 0) {",
            "\t\ttmp = ctx->deadlock_inject_interval;",
            "\t\tif (tmp > UINT_MAX/4)",
            "\t\t\ttmp = UINT_MAX;",
            "\t\telse",
            "\t\t\ttmp = tmp*2 + tmp + tmp/2;",
            "",
            "\t\tctx->deadlock_inject_interval = tmp;",
            "\t\tctx->deadlock_inject_countdown = tmp;",
            "\t\tctx->contending_lock = lock;",
            "",
            "\t\tww_mutex_unlock(lock);",
            "",
            "\t\treturn -EDEADLK;",
            "\t}",
            "#endif",
            "",
            "\treturn 0;",
            "}",
            "int __sched",
            "ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tret =  __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE,",
            "\t\t\t       0, _RET_IP_, ctx);",
            "\tif (!ret && ctx && ctx->acquired > 1)",
            "\t\treturn ww_mutex_deadlock_injection(lock, ctx);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__mutex_lock, __ww_mutex_lock, ww_mutex_trylock, mutex_lock_nested, _mutex_lock_nest_lock, mutex_lock_killable_nested, mutex_lock_interruptible_nested, mutex_lock_io_nested, ww_mutex_deadlock_injection, ww_mutex_lock",
          "description": "封装多种锁获取接口，处理嵌套锁、可中断锁及死锁注入逻辑，协调锁持有者与等待者的交互关系。",
          "similarity": 0.5892238020896912
        }
      ]
    },
    {
      "source_file": "kernel/locking/rtmutex.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:48:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\rtmutex.c`\n\n---\n\n# `locking/rtmutex.c` 技术文档\n\n## 1. 文件概述\n\n`rtmutex.c` 是 Linux 内核中实现实时互斥锁（RT-Mutex）的核心文件，提供支持优先级继承（Priority Inheritance, PI）的阻塞型互斥锁机制。该机制主要用于解决优先级反转问题，确保高优先级任务不会因低优先级任务持有锁而被长时间阻塞。RT-Mutex 在 PREEMPT_RT 补丁集和实时调度场景中尤为关键，同时也被普通内核用于某些需要 PI 语义的同步原语（如 `mutex` 和 `ww_mutex`）。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct rt_mutex_base`：RT-Mutex 的基础结构，包含 `owner` 字段（编码持有者和等待者状态）和 `wait_lock`（保护内部状态的自旋锁）。\n- `struct rt_mutex_waiter`：表示等待锁的任务，用于构建等待队列（红黑树）。\n- `struct ww_mutex`（条件编译）：基于 RT-Mutex 实现的 Wound/Wait 互斥锁，用于避免死锁。\n\n### 关键函数与内联函数\n- `rt_mutex_owner_encode()`：将任务指针与等待者标志位（`RT_MUTEX_HAS_WAITERS`）编码为 `owner` 值。\n- `rt_mutex_set_owner()` / `rt_mutex_clear_owner()`：安全设置/清除锁的持有者，使用 `xchg_acquire` 或 `WRITE_ONCE` 保证内存序。\n- `fixup_rt_mutex_waiters()`：在等待队列为空时清除 `owner` 中的等待者标志位，防止竞态导致的错误释放。\n- `rt_mutex_cmpxchg_acquire()` / `rt_mutex_cmpxchg_release()`：基于原子比较交换（cmpxchg）的快速路径加锁/解锁。\n- `rt_mutex_try_acquire()`：尝试无竞争地获取锁（快速路径）。\n- `mark_rt_mutex_waiters()`：在进入慢速路径前，原子地设置 `owner` 的等待者标志位。\n- `unlock_rt_mutex_safe()`：安全解锁流程，先清除等待者标志，再尝试原子释放锁。\n- `__ww_mutex_*` 系列函数（条件编译）：Wound/Wait 互斥锁的特定逻辑。\n\n## 3. 关键实现\n\n### 锁状态编码\n`lock->owner` 字段使用最低位（bit 0）作为 `RT_MUTEX_HAS_WAITERS` 标志：\n- `NULL + 0`：锁空闲，无等待者（可快速获取）。\n- `NULL + 1`：锁空闲但有等待者（过渡状态）。\n- `task_ptr + 0`：锁被持有，无等待者（可快速释放）。\n- `task_ptr + 1`：锁被持有且有等待者。\n\n该编码允许在无竞争时通过原子 `cmpxchg` 实现快速加锁/解锁，避免获取 `wait_lock`。\n\n### 快速路径与慢速路径\n- **快速路径**：通过 `rt_mutex_try_acquire()` 使用 `try_cmpxchg_acquire` 尝试直接获取空闲锁。\n- **慢速路径**：当快速路径失败时，获取 `wait_lock`，将当前任务加入等待队列（红黑树，按优先级排序），并可能触发优先级继承。\n\n### 优先级继承（PI）\n当高优先级任务因锁被低优先级任务阻塞时，低优先级任务临时继承高优先级，防止中优先级任务抢占导致优先级反转。PI 逻辑在 `rtmutex.c` 的慢速路径函数（如 `__rt_mutex_slowlock`）中实现，但本文件主要提供基础状态管理和快速路径支持。\n\n### 等待者标志位管理\n- **设置**：在进入慢速路径前调用 `mark_rt_mutex_waiters()`，原子设置 `owner` 的等待者标志。\n- **清除**：在 `fixup_rt_mutex_waiters()` 中，若等待队列为空且标志位仍置位，则清除该标志。此操作需区分加锁/解锁上下文以选择合适的内存序（`xchg_acquire` vs `WRITE_ONCE`）。\n\n### 安全解锁流程 (`unlock_rt_mutex_safe`)\n1. 在持有 `wait_lock` 时清除 `owner` 的等待者标志。\n2. 释放 `wait_lock`。\n3. 使用 `try_cmpxchg_release` 尝试将 `owner` 从当前任务置为 `NULL`。\n此流程确保即使在解锁过程中有新等待者加入，也不会导致锁状态不一致。\n\n### Wound/Wait 互斥锁支持\n通过条件编译（`WW_RT`）集成 `ww_mutex` 逻辑，提供死锁避免机制。相关函数（如 `__ww_mutex_add_waiter`）在非 `WW_RT` 模式下为空操作。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/sched.h>` 及相关调度子系统头文件：用于任务结构、优先级、调度策略。\n  - `<linux/ww_mutex.h>`：Wound/Wait 互斥锁接口。\n  - `\"rtmutex_common.h\"`：RT-Mutex 公共定义（如 `RT_MUTEX_HAS_WAITERS`）。\n- **内核子系统**：\n  - **调度器**：依赖任务优先级、PI 机制、任务唤醒（`wake_q`）。\n  - **锁调试**：`CONFIG_DEBUG_RT_MUTEXES` 启用时提供额外检查。\n  - **跟踪系统**：通过 `trace/events/lock.h` 提供锁事件跟踪。\n- **架构依赖**：使用 `xchg_acquire`、`try_cmpxchg_acquire/release` 等原子操作，依赖底层架构的内存模型支持。\n\n## 5. 使用场景\n\n- **实时任务同步**：在 PREEMPT_RT 内核中，`mutex` 原语底层使用 RT-Mutex 实现，确保实时任务的确定性响应。\n- **优先级继承需求**：任何需要避免优先级反转的场景，如设备驱动、内核子系统间的互斥访问。\n- **Wound/Wait 死锁避免**：图形子系统（如 DRM）使用 `ww_mutex` 管理资源锁，防止循环等待。\n- **内核通用互斥**：即使在非实时内核中，部分子系统（如 `futex`）也可能使用 RT-Mutex 的 PI 特性。",
      "similarity": 0.6399019956588745,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "kernel/locking/rtmutex.c",
          "start_line": 1199,
          "end_line": 1299,
          "content": [
            "static int __sched task_blocks_on_rt_mutex(struct rt_mutex_base *lock,",
            "\t\t\t\t\t   struct rt_mutex_waiter *waiter,",
            "\t\t\t\t\t   struct task_struct *task,",
            "\t\t\t\t\t   struct ww_acquire_ctx *ww_ctx,",
            "\t\t\t\t\t   enum rtmutex_chainwalk chwalk)",
            "{",
            "\tstruct task_struct *owner = rt_mutex_owner(lock);",
            "\tstruct rt_mutex_waiter *top_waiter = waiter;",
            "\tstruct rt_mutex_base *next_lock;",
            "\tint chain_walk = 0, res;",
            "",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\t/*",
            "\t * Early deadlock detection. We really don't want the task to",
            "\t * enqueue on itself just to untangle the mess later. It's not",
            "\t * only an optimization. We drop the locks, so another waiter",
            "\t * can come in before the chain walk detects the deadlock. So",
            "\t * the other will detect the deadlock and return -EDEADLOCK,",
            "\t * which is wrong, as the other waiter is not in a deadlock",
            "\t * situation.",
            "\t *",
            "\t * Except for ww_mutex, in that case the chain walk must already deal",
            "\t * with spurious cycles, see the comments at [3] and [6].",
            "\t */",
            "\tif (owner == task && !(build_ww_mutex() && ww_ctx))",
            "\t\treturn -EDEADLK;",
            "",
            "\traw_spin_lock(&task->pi_lock);",
            "\twaiter->task = task;",
            "\twaiter->lock = lock;",
            "\twaiter_update_prio(waiter, task);",
            "\twaiter_clone_prio(waiter, task);",
            "",
            "\t/* Get the top priority waiter on the lock */",
            "\tif (rt_mutex_has_waiters(lock))",
            "\t\ttop_waiter = rt_mutex_top_waiter(lock);",
            "\trt_mutex_enqueue(lock, waiter);",
            "",
            "\ttask->pi_blocked_on = waiter;",
            "",
            "\traw_spin_unlock(&task->pi_lock);",
            "",
            "\tif (build_ww_mutex() && ww_ctx) {",
            "\t\tstruct rt_mutex *rtm;",
            "",
            "\t\t/* Check whether the waiter should back out immediately */",
            "\t\trtm = container_of(lock, struct rt_mutex, rtmutex);",
            "\t\tres = __ww_mutex_add_waiter(waiter, rtm, ww_ctx);",
            "\t\tif (res) {",
            "\t\t\traw_spin_lock(&task->pi_lock);",
            "\t\t\trt_mutex_dequeue(lock, waiter);",
            "\t\t\ttask->pi_blocked_on = NULL;",
            "\t\t\traw_spin_unlock(&task->pi_lock);",
            "\t\t\treturn res;",
            "\t\t}",
            "\t}",
            "",
            "\tif (!owner)",
            "\t\treturn 0;",
            "",
            "\traw_spin_lock(&owner->pi_lock);",
            "\tif (waiter == rt_mutex_top_waiter(lock)) {",
            "\t\trt_mutex_dequeue_pi(owner, top_waiter);",
            "\t\trt_mutex_enqueue_pi(owner, waiter);",
            "",
            "\t\trt_mutex_adjust_prio(lock, owner);",
            "\t\tif (owner->pi_blocked_on)",
            "\t\t\tchain_walk = 1;",
            "\t} else if (rt_mutex_cond_detect_deadlock(waiter, chwalk)) {",
            "\t\tchain_walk = 1;",
            "\t}",
            "",
            "\t/* Store the lock on which owner is blocked or NULL */",
            "\tnext_lock = task_blocked_on_lock(owner);",
            "",
            "\traw_spin_unlock(&owner->pi_lock);",
            "\t/*",
            "\t * Even if full deadlock detection is on, if the owner is not",
            "\t * blocked itself, we can avoid finding this out in the chain",
            "\t * walk.",
            "\t */",
            "\tif (!chain_walk || !next_lock)",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * The owner can't disappear while holding a lock,",
            "\t * so the owner struct is protected by wait_lock.",
            "\t * Gets dropped in rt_mutex_adjust_prio_chain()!",
            "\t */",
            "\tget_task_struct(owner);",
            "",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\tres = rt_mutex_adjust_prio_chain(owner, chwalk, lock,",
            "\t\t\t\t\t next_lock, waiter, task);",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "",
            "\treturn res;",
            "}"
          ],
          "function_name": "task_blocks_on_rt_mutex",
          "description": "task_blocks_on_rt_mutex 处理任务阻塞到实时互斥锁的逻辑，检查是否形成死锁（自身阻塞），更新等待者优先级信息并将其加入锁等待队列。若锁拥有者存在且当前等待者为最高优先级，则调整优先级链表，触发链式死锁检测以防止循环依赖。",
          "similarity": 0.5595607757568359
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/locking/rtmutex.c",
          "start_line": 1082,
          "end_line": 1190,
          "content": [
            "static int __sched",
            "try_to_take_rt_mutex(struct rt_mutex_base *lock, struct task_struct *task,",
            "\t\t     struct rt_mutex_waiter *waiter)",
            "{",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\t/*",
            "\t * Before testing whether we can acquire @lock, we set the",
            "\t * RT_MUTEX_HAS_WAITERS bit in @lock->owner. This forces all",
            "\t * other tasks which try to modify @lock into the slow path",
            "\t * and they serialize on @lock->wait_lock.",
            "\t *",
            "\t * The RT_MUTEX_HAS_WAITERS bit can have a transitional state",
            "\t * as explained at the top of this file if and only if:",
            "\t *",
            "\t * - There is a lock owner. The caller must fixup the",
            "\t *   transient state if it does a trylock or leaves the lock",
            "\t *   function due to a signal or timeout.",
            "\t *",
            "\t * - @task acquires the lock and there are no other",
            "\t *   waiters. This is undone in rt_mutex_set_owner(@task) at",
            "\t *   the end of this function.",
            "\t */",
            "\tmark_rt_mutex_waiters(lock);",
            "",
            "\t/*",
            "\t * If @lock has an owner, give up.",
            "\t */",
            "\tif (rt_mutex_owner(lock))",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * If @waiter != NULL, @task has already enqueued the waiter",
            "\t * into @lock waiter tree. If @waiter == NULL then this is a",
            "\t * trylock attempt.",
            "\t */",
            "\tif (waiter) {",
            "\t\tstruct rt_mutex_waiter *top_waiter = rt_mutex_top_waiter(lock);",
            "",
            "\t\t/*",
            "\t\t * If waiter is the highest priority waiter of @lock,",
            "\t\t * or allowed to steal it, take it over.",
            "\t\t */",
            "\t\tif (waiter == top_waiter || rt_mutex_steal(waiter, top_waiter)) {",
            "\t\t\t/*",
            "\t\t\t * We can acquire the lock. Remove the waiter from the",
            "\t\t\t * lock waiters tree.",
            "\t\t\t */",
            "\t\t\trt_mutex_dequeue(lock, waiter);",
            "\t\t} else {",
            "\t\t\treturn 0;",
            "\t\t}",
            "\t} else {",
            "\t\t/*",
            "\t\t * If the lock has waiters already we check whether @task is",
            "\t\t * eligible to take over the lock.",
            "\t\t *",
            "\t\t * If there are no other waiters, @task can acquire",
            "\t\t * the lock.  @task->pi_blocked_on is NULL, so it does",
            "\t\t * not need to be dequeued.",
            "\t\t */",
            "\t\tif (rt_mutex_has_waiters(lock)) {",
            "\t\t\t/* Check whether the trylock can steal it. */",
            "\t\t\tif (!rt_mutex_steal(task_to_waiter(task),",
            "\t\t\t\t\t    rt_mutex_top_waiter(lock)))",
            "\t\t\t\treturn 0;",
            "",
            "\t\t\t/*",
            "\t\t\t * The current top waiter stays enqueued. We",
            "\t\t\t * don't have to change anything in the lock",
            "\t\t\t * waiters order.",
            "\t\t\t */",
            "\t\t} else {",
            "\t\t\t/*",
            "\t\t\t * No waiters. Take the lock without the",
            "\t\t\t * pi_lock dance.@task->pi_blocked_on is NULL",
            "\t\t\t * and we have no waiters to enqueue in @task",
            "\t\t\t * pi waiters tree.",
            "\t\t\t */",
            "\t\t\tgoto takeit;",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * Clear @task->pi_blocked_on. Requires protection by",
            "\t * @task->pi_lock. Redundant operation for the @waiter == NULL",
            "\t * case, but conditionals are more expensive than a redundant",
            "\t * store.",
            "\t */",
            "\traw_spin_lock(&task->pi_lock);",
            "\ttask->pi_blocked_on = NULL;",
            "\t/*",
            "\t * Finish the lock acquisition. @task is the new owner. If",
            "\t * other waiters exist we have to insert the highest priority",
            "\t * waiter into @task->pi_waiters tree.",
            "\t */",
            "\tif (rt_mutex_has_waiters(lock))",
            "\t\trt_mutex_enqueue_pi(task, rt_mutex_top_waiter(lock));",
            "\traw_spin_unlock(&task->pi_lock);",
            "",
            "takeit:",
            "\t/*",
            "\t * This either preserves the RT_MUTEX_HAS_WAITERS bit if there",
            "\t * are still waiters or clears it.",
            "\t */",
            "\trt_mutex_set_owner(lock, task);",
            "",
            "\treturn 1;",
            "}"
          ],
          "function_name": "try_to_take_rt_mutex",
          "description": "try_to_take_rt_mutex 函数尝试获取实时互斥锁，设置RT_MUTEX_HAS_WAITERS标志位，检查是否存在锁拥有者，若有则返回失败；若无，则判断是否存在等待者，若存在则尝试窃取最高优先级等待者，成功后清除标志位并设置当前任务为锁拥有者，最终返回获取结果。",
          "similarity": 0.5574008226394653
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/rtmutex.c",
          "start_line": 475,
          "end_line": 965,
          "content": [
            "static __always_inline void",
            "rt_mutex_enqueue(struct rt_mutex_base *lock, struct rt_mutex_waiter *waiter)",
            "{",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\trb_add_cached(&waiter->tree.entry, &lock->waiters, __waiter_less);",
            "}",
            "static __always_inline void",
            "rt_mutex_dequeue(struct rt_mutex_base *lock, struct rt_mutex_waiter *waiter)",
            "{",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tif (RB_EMPTY_NODE(&waiter->tree.entry))",
            "\t\treturn;",
            "",
            "\trb_erase_cached(&waiter->tree.entry, &lock->waiters);",
            "\tRB_CLEAR_NODE(&waiter->tree.entry);",
            "}",
            "static __always_inline bool __pi_waiter_less(struct rb_node *a, const struct rb_node *b)",
            "{",
            "\treturn rt_waiter_node_less(__node_2_rt_node(a), __node_2_rt_node(b));",
            "}",
            "static __always_inline void",
            "rt_mutex_enqueue_pi(struct task_struct *task, struct rt_mutex_waiter *waiter)",
            "{",
            "\tlockdep_assert_held(&task->pi_lock);",
            "",
            "\trb_add_cached(&waiter->pi_tree.entry, &task->pi_waiters, __pi_waiter_less);",
            "}",
            "static __always_inline void",
            "rt_mutex_dequeue_pi(struct task_struct *task, struct rt_mutex_waiter *waiter)",
            "{",
            "\tlockdep_assert_held(&task->pi_lock);",
            "",
            "\tif (RB_EMPTY_NODE(&waiter->pi_tree.entry))",
            "\t\treturn;",
            "",
            "\trb_erase_cached(&waiter->pi_tree.entry, &task->pi_waiters);",
            "\tRB_CLEAR_NODE(&waiter->pi_tree.entry);",
            "}",
            "static __always_inline void rt_mutex_adjust_prio(struct rt_mutex_base *lock,",
            "\t\t\t\t\t\t struct task_struct *p)",
            "{",
            "\tstruct task_struct *pi_task = NULL;",
            "",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "\tlockdep_assert(rt_mutex_owner(lock) == p);",
            "\tlockdep_assert_held(&p->pi_lock);",
            "",
            "\tif (task_has_pi_waiters(p))",
            "\t\tpi_task = task_top_pi_waiter(p)->task;",
            "",
            "\trt_mutex_setprio(p, pi_task);",
            "}",
            "static __always_inline void rt_mutex_wake_q_add_task(struct rt_wake_q_head *wqh,",
            "\t\t\t\t\t\t     struct task_struct *task,",
            "\t\t\t\t\t\t     unsigned int wake_state)",
            "{",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wake_state == TASK_RTLOCK_WAIT) {",
            "\t\tif (IS_ENABLED(CONFIG_PROVE_LOCKING))",
            "\t\t\tWARN_ON_ONCE(wqh->rtlock_task);",
            "\t\tget_task_struct(task);",
            "\t\twqh->rtlock_task = task;",
            "\t} else {",
            "\t\twake_q_add(&wqh->head, task);",
            "\t}",
            "}",
            "static __always_inline void rt_mutex_wake_q_add(struct rt_wake_q_head *wqh,",
            "\t\t\t\t\t\tstruct rt_mutex_waiter *w)",
            "{",
            "\trt_mutex_wake_q_add_task(wqh, w->task, w->wake_state);",
            "}",
            "static __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)",
            "{",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {",
            "\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);",
            "\t\tput_task_struct(wqh->rtlock_task);",
            "\t\twqh->rtlock_task = NULL;",
            "\t}",
            "",
            "\tif (!wake_q_empty(&wqh->head))",
            "\t\twake_up_q(&wqh->head);",
            "",
            "\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */",
            "\tpreempt_enable();",
            "}",
            "static __always_inline bool",
            "rt_mutex_cond_detect_deadlock(struct rt_mutex_waiter *waiter,",
            "\t\t\t      enum rtmutex_chainwalk chwalk)",
            "{",
            "\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES))",
            "\t\treturn waiter != NULL;",
            "\treturn chwalk == RT_MUTEX_FULL_CHAINWALK;",
            "}",
            "static int __sched rt_mutex_adjust_prio_chain(struct task_struct *task,",
            "\t\t\t\t\t      enum rtmutex_chainwalk chwalk,",
            "\t\t\t\t\t      struct rt_mutex_base *orig_lock,",
            "\t\t\t\t\t      struct rt_mutex_base *next_lock,",
            "\t\t\t\t\t      struct rt_mutex_waiter *orig_waiter,",
            "\t\t\t\t\t      struct task_struct *top_task)",
            "{",
            "\tstruct rt_mutex_waiter *waiter, *top_waiter = orig_waiter;",
            "\tstruct rt_mutex_waiter *prerequeue_top_waiter;",
            "\tint ret = 0, depth = 0;",
            "\tstruct rt_mutex_base *lock;",
            "\tbool detect_deadlock;",
            "\tbool requeue = true;",
            "",
            "\tdetect_deadlock = rt_mutex_cond_detect_deadlock(orig_waiter, chwalk);",
            "",
            "\t/*",
            "\t * The (de)boosting is a step by step approach with a lot of",
            "\t * pitfalls. We want this to be preemptible and we want hold a",
            "\t * maximum of two locks per step. So we have to check",
            "\t * carefully whether things change under us.",
            "\t */",
            " again:",
            "\t/*",
            "\t * We limit the lock chain length for each invocation.",
            "\t */",
            "\tif (++depth > max_lock_depth) {",
            "\t\tstatic int prev_max;",
            "",
            "\t\t/*",
            "\t\t * Print this only once. If the admin changes the limit,",
            "\t\t * print a new message when reaching the limit again.",
            "\t\t */",
            "\t\tif (prev_max != max_lock_depth) {",
            "\t\t\tprev_max = max_lock_depth;",
            "\t\t\tprintk(KERN_WARNING \"Maximum lock depth %d reached \"",
            "\t\t\t       \"task: %s (%d)\\n\", max_lock_depth,",
            "\t\t\t       top_task->comm, task_pid_nr(top_task));",
            "\t\t}",
            "\t\tput_task_struct(task);",
            "",
            "\t\treturn -EDEADLK;",
            "\t}",
            "",
            "\t/*",
            "\t * We are fully preemptible here and only hold the refcount on",
            "\t * @task. So everything can have changed under us since the",
            "\t * caller or our own code below (goto retry/again) dropped all",
            "\t * locks.",
            "\t */",
            " retry:",
            "\t/*",
            "\t * [1] Task cannot go away as we did a get_task() before !",
            "\t */",
            "\traw_spin_lock_irq(&task->pi_lock);",
            "",
            "\t/*",
            "\t * [2] Get the waiter on which @task is blocked on.",
            "\t */",
            "\twaiter = task->pi_blocked_on;",
            "",
            "\t/*",
            "\t * [3] check_exit_conditions_1() protected by task->pi_lock.",
            "\t */",
            "",
            "\t/*",
            "\t * Check whether the end of the boosting chain has been",
            "\t * reached or the state of the chain has changed while we",
            "\t * dropped the locks.",
            "\t */",
            "\tif (!waiter)",
            "\t\tgoto out_unlock_pi;",
            "",
            "\t/*",
            "\t * Check the orig_waiter state. After we dropped the locks,",
            "\t * the previous owner of the lock might have released the lock.",
            "\t */",
            "\tif (orig_waiter && !rt_mutex_owner(orig_lock))",
            "\t\tgoto out_unlock_pi;",
            "",
            "\t/*",
            "\t * We dropped all locks after taking a refcount on @task, so",
            "\t * the task might have moved on in the lock chain or even left",
            "\t * the chain completely and blocks now on an unrelated lock or",
            "\t * on @orig_lock.",
            "\t *",
            "\t * We stored the lock on which @task was blocked in @next_lock,",
            "\t * so we can detect the chain change.",
            "\t */",
            "\tif (next_lock != waiter->lock)",
            "\t\tgoto out_unlock_pi;",
            "",
            "\t/*",
            "\t * There could be 'spurious' loops in the lock graph due to ww_mutex,",
            "\t * consider:",
            "\t *",
            "\t *   P1: A, ww_A, ww_B",
            "\t *   P2: ww_B, ww_A",
            "\t *   P3: A",
            "\t *",
            "\t * P3 should not return -EDEADLK because it gets trapped in the cycle",
            "\t * created by P1 and P2 (which will resolve -- and runs into",
            "\t * max_lock_depth above). Therefore disable detect_deadlock such that",
            "\t * the below termination condition can trigger once all relevant tasks",
            "\t * are boosted.",
            "\t *",
            "\t * Even when we start with ww_mutex we can disable deadlock detection,",
            "\t * since we would supress a ww_mutex induced deadlock at [6] anyway.",
            "\t * Supressing it here however is not sufficient since we might still",
            "\t * hit [6] due to adjustment driven iteration.",
            "\t *",
            "\t * NOTE: if someone were to create a deadlock between 2 ww_classes we'd",
            "\t * utterly fail to report it; lockdep should.",
            "\t */",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && waiter->ww_ctx && detect_deadlock)",
            "\t\tdetect_deadlock = false;",
            "",
            "\t/*",
            "\t * Drop out, when the task has no waiters. Note,",
            "\t * top_waiter can be NULL, when we are in the deboosting",
            "\t * mode!",
            "\t */",
            "\tif (top_waiter) {",
            "\t\tif (!task_has_pi_waiters(task))",
            "\t\t\tgoto out_unlock_pi;",
            "\t\t/*",
            "\t\t * If deadlock detection is off, we stop here if we",
            "\t\t * are not the top pi waiter of the task. If deadlock",
            "\t\t * detection is enabled we continue, but stop the",
            "\t\t * requeueing in the chain walk.",
            "\t\t */",
            "\t\tif (top_waiter != task_top_pi_waiter(task)) {",
            "\t\t\tif (!detect_deadlock)",
            "\t\t\t\tgoto out_unlock_pi;",
            "\t\t\telse",
            "\t\t\t\trequeue = false;",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * If the waiter priority is the same as the task priority",
            "\t * then there is no further priority adjustment necessary.  If",
            "\t * deadlock detection is off, we stop the chain walk. If its",
            "\t * enabled we continue, but stop the requeueing in the chain",
            "\t * walk.",
            "\t */",
            "\tif (rt_waiter_node_equal(&waiter->tree, task_to_waiter_node(task))) {",
            "\t\tif (!detect_deadlock)",
            "\t\t\tgoto out_unlock_pi;",
            "\t\telse",
            "\t\t\trequeue = false;",
            "\t}",
            "",
            "\t/*",
            "\t * [4] Get the next lock; per holding task->pi_lock we can't unblock",
            "\t * and guarantee @lock's existence.",
            "\t */",
            "\tlock = waiter->lock;",
            "\t/*",
            "\t * [5] We need to trylock here as we are holding task->pi_lock,",
            "\t * which is the reverse lock order versus the other rtmutex",
            "\t * operations.",
            "\t *",
            "\t * Per the above, holding task->pi_lock guarantees lock exists, so",
            "\t * inverting this lock order is infeasible from a life-time",
            "\t * perspective.",
            "\t */",
            "\tif (!raw_spin_trylock(&lock->wait_lock)) {",
            "\t\traw_spin_unlock_irq(&task->pi_lock);",
            "\t\tcpu_relax();",
            "\t\tgoto retry;",
            "\t}",
            "",
            "\t/*",
            "\t * [6] check_exit_conditions_2() protected by task->pi_lock and",
            "\t * lock->wait_lock.",
            "\t *",
            "\t * Deadlock detection. If the lock is the same as the original",
            "\t * lock which caused us to walk the lock chain or if the",
            "\t * current lock is owned by the task which initiated the chain",
            "\t * walk, we detected a deadlock.",
            "\t */",
            "\tif (lock == orig_lock || rt_mutex_owner(lock) == top_task) {",
            "\t\tret = -EDEADLK;",
            "",
            "\t\t/*",
            "\t\t * When the deadlock is due to ww_mutex; also see above. Don't",
            "\t\t * report the deadlock and instead let the ww_mutex wound/die",
            "\t\t * logic pick which of the contending threads gets -EDEADLK.",
            "\t\t *",
            "\t\t * NOTE: assumes the cycle only contains a single ww_class; any",
            "\t\t * other configuration and we fail to report; also, see",
            "\t\t * lockdep.",
            "\t\t */",
            "\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && orig_waiter && orig_waiter->ww_ctx)",
            "\t\t\tret = 0;",
            "",
            "\t\traw_spin_unlock(&lock->wait_lock);",
            "\t\tgoto out_unlock_pi;",
            "\t}",
            "",
            "\t/*",
            "\t * If we just follow the lock chain for deadlock detection, no",
            "\t * need to do all the requeue operations. To avoid a truckload",
            "\t * of conditionals around the various places below, just do the",
            "\t * minimum chain walk checks.",
            "\t */",
            "\tif (!requeue) {",
            "\t\t/*",
            "\t\t * No requeue[7] here. Just release @task [8]",
            "\t\t */",
            "\t\traw_spin_unlock(&task->pi_lock);",
            "\t\tput_task_struct(task);",
            "",
            "\t\t/*",
            "\t\t * [9] check_exit_conditions_3 protected by lock->wait_lock.",
            "\t\t * If there is no owner of the lock, end of chain.",
            "\t\t */",
            "\t\tif (!rt_mutex_owner(lock)) {",
            "\t\t\traw_spin_unlock_irq(&lock->wait_lock);",
            "\t\t\treturn 0;",
            "\t\t}",
            "",
            "\t\t/* [10] Grab the next task, i.e. owner of @lock */",
            "\t\ttask = get_task_struct(rt_mutex_owner(lock));",
            "\t\traw_spin_lock(&task->pi_lock);",
            "",
            "\t\t/*",
            "\t\t * No requeue [11] here. We just do deadlock detection.",
            "\t\t *",
            "\t\t * [12] Store whether owner is blocked",
            "\t\t * itself. Decision is made after dropping the locks",
            "\t\t */",
            "\t\tnext_lock = task_blocked_on_lock(task);",
            "\t\t/*",
            "\t\t * Get the top waiter for the next iteration",
            "\t\t */",
            "\t\ttop_waiter = rt_mutex_top_waiter(lock);",
            "",
            "\t\t/* [13] Drop locks */",
            "\t\traw_spin_unlock(&task->pi_lock);",
            "\t\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\t\t/* If owner is not blocked, end of chain. */",
            "\t\tif (!next_lock)",
            "\t\t\tgoto out_put_task;",
            "\t\tgoto again;",
            "\t}",
            "",
            "\t/*",
            "\t * Store the current top waiter before doing the requeue",
            "\t * operation on @lock. We need it for the boost/deboost",
            "\t * decision below.",
            "\t */",
            "\tprerequeue_top_waiter = rt_mutex_top_waiter(lock);",
            "",
            "\t/* [7] Requeue the waiter in the lock waiter tree. */",
            "\trt_mutex_dequeue(lock, waiter);",
            "",
            "\t/*",
            "\t * Update the waiter prio fields now that we're dequeued.",
            "\t *",
            "\t * These values can have changed through either:",
            "\t *",
            "\t *   sys_sched_set_scheduler() / sys_sched_setattr()",
            "\t *",
            "\t * or",
            "\t *",
            "\t *   DL CBS enforcement advancing the effective deadline.",
            "\t */",
            "\twaiter_update_prio(waiter, task);",
            "",
            "\trt_mutex_enqueue(lock, waiter);",
            "",
            "\t/*",
            "\t * [8] Release the (blocking) task in preparation for",
            "\t * taking the owner task in [10].",
            "\t *",
            "\t * Since we hold lock->waiter_lock, task cannot unblock, even if we",
            "\t * release task->pi_lock.",
            "\t */",
            "\traw_spin_unlock(&task->pi_lock);",
            "\tput_task_struct(task);",
            "",
            "\t/*",
            "\t * [9] check_exit_conditions_3 protected by lock->wait_lock.",
            "\t *",
            "\t * We must abort the chain walk if there is no lock owner even",
            "\t * in the dead lock detection case, as we have nothing to",
            "\t * follow here. This is the end of the chain we are walking.",
            "\t */",
            "\tif (!rt_mutex_owner(lock)) {",
            "\t\t/*",
            "\t\t * If the requeue [7] above changed the top waiter,",
            "\t\t * then we need to wake the new top waiter up to try",
            "\t\t * to get the lock.",
            "\t\t */",
            "\t\ttop_waiter = rt_mutex_top_waiter(lock);",
            "\t\tif (prerequeue_top_waiter != top_waiter)",
            "\t\t\twake_up_state(top_waiter->task, top_waiter->wake_state);",
            "\t\traw_spin_unlock_irq(&lock->wait_lock);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * [10] Grab the next task, i.e. the owner of @lock",
            "\t *",
            "\t * Per holding lock->wait_lock and checking for !owner above, there",
            "\t * must be an owner and it cannot go away.",
            "\t */",
            "\ttask = get_task_struct(rt_mutex_owner(lock));",
            "\traw_spin_lock(&task->pi_lock);",
            "",
            "\t/* [11] requeue the pi waiters if necessary */",
            "\tif (waiter == rt_mutex_top_waiter(lock)) {",
            "\t\t/*",
            "\t\t * The waiter became the new top (highest priority)",
            "\t\t * waiter on the lock. Replace the previous top waiter",
            "\t\t * in the owner tasks pi waiters tree with this waiter",
            "\t\t * and adjust the priority of the owner.",
            "\t\t */",
            "\t\trt_mutex_dequeue_pi(task, prerequeue_top_waiter);",
            "\t\twaiter_clone_prio(waiter, task);",
            "\t\trt_mutex_enqueue_pi(task, waiter);",
            "\t\trt_mutex_adjust_prio(lock, task);",
            "",
            "\t} else if (prerequeue_top_waiter == waiter) {",
            "\t\t/*",
            "\t\t * The waiter was the top waiter on the lock, but is",
            "\t\t * no longer the top priority waiter. Replace waiter in",
            "\t\t * the owner tasks pi waiters tree with the new top",
            "\t\t * (highest priority) waiter and adjust the priority",
            "\t\t * of the owner.",
            "\t\t * The new top waiter is stored in @waiter so that",
            "\t\t * @waiter == @top_waiter evaluates to true below and",
            "\t\t * we continue to deboost the rest of the chain.",
            "\t\t */",
            "\t\trt_mutex_dequeue_pi(task, waiter);",
            "\t\twaiter = rt_mutex_top_waiter(lock);",
            "\t\twaiter_clone_prio(waiter, task);",
            "\t\trt_mutex_enqueue_pi(task, waiter);",
            "\t\trt_mutex_adjust_prio(lock, task);",
            "\t} else {",
            "\t\t/*",
            "\t\t * Nothing changed. No need to do any priority",
            "\t\t * adjustment.",
            "\t\t */",
            "\t}",
            "",
            "\t/*",
            "\t * [12] check_exit_conditions_4() protected by task->pi_lock",
            "\t * and lock->wait_lock. The actual decisions are made after we",
            "\t * dropped the locks.",
            "\t *",
            "\t * Check whether the task which owns the current lock is pi",
            "\t * blocked itself. If yes we store a pointer to the lock for",
            "\t * the lock chain change detection above. After we dropped",
            "\t * task->pi_lock next_lock cannot be dereferenced anymore.",
            "\t */",
            "\tnext_lock = task_blocked_on_lock(task);",
            "\t/*",
            "\t * Store the top waiter of @lock for the end of chain walk",
            "\t * decision below.",
            "\t */",
            "\ttop_waiter = rt_mutex_top_waiter(lock);",
            "",
            "\t/* [13] Drop the locks */",
            "\traw_spin_unlock(&task->pi_lock);",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\t/*",
            "\t * Make the actual exit decisions [12], based on the stored",
            "\t * values.",
            "\t *",
            "\t * We reached the end of the lock chain. Stop right here. No",
            "\t * point to go back just to figure that out.",
            "\t */",
            "\tif (!next_lock)",
            "\t\tgoto out_put_task;",
            "",
            "\t/*",
            "\t * If the current waiter is not the top waiter on the lock,",
            "\t * then we can stop the chain walk here if we are not in full",
            "\t * deadlock detection mode.",
            "\t */",
            "\tif (!detect_deadlock && waiter != top_waiter)",
            "\t\tgoto out_put_task;",
            "",
            "\tgoto again;",
            "",
            " out_unlock_pi:",
            "\traw_spin_unlock_irq(&task->pi_lock);",
            " out_put_task:",
            "\tput_task_struct(task);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "rt_mutex_enqueue, rt_mutex_dequeue, __pi_waiter_less, rt_mutex_enqueue_pi, rt_mutex_dequeue_pi, rt_mutex_adjust_prio, rt_mutex_wake_q_add_task, rt_mutex_wake_q_add, rt_mutex_wake_up_q, rt_mutex_cond_detect_deadlock, rt_mutex_adjust_prio_chain",
          "description": "提供锁等待队列操作接口，包含优先级调整链式处理逻辑，实现死锁检测与任务唤醒机制。",
          "similarity": 0.5523623824119568
        },
        {
          "chunk_id": 11,
          "file_path": "kernel/locking/rtmutex.c",
          "start_line": 1856,
          "end_line": 1863,
          "content": [
            "static __always_inline void __sched rtlock_slowlock(struct rt_mutex_base *lock)",
            "{",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&lock->wait_lock, flags);",
            "\trtlock_slowlock_locked(lock);",
            "\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);",
            "}"
          ],
          "function_name": "rtlock_slowlock",
          "description": "封装rtlock_slowlock_locked函数，通过持有wait_lock保证并发安全性，提供对外部调用的线程安全接口",
          "similarity": 0.5522318482398987
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/locking/rtmutex.c",
          "start_line": 1730,
          "end_line": 1835,
          "content": [
            "static inline int __rt_mutex_slowlock_locked(struct rt_mutex_base *lock,",
            "\t\t\t\t\t     struct ww_acquire_ctx *ww_ctx,",
            "\t\t\t\t\t     unsigned int state)",
            "{",
            "\tstruct rt_mutex_waiter waiter;",
            "\tint ret;",
            "",
            "\trt_mutex_init_waiter(&waiter);",
            "\twaiter.ww_ctx = ww_ctx;",
            "",
            "\tret = __rt_mutex_slowlock(lock, ww_ctx, state, RT_MUTEX_MIN_CHAINWALK,",
            "\t\t\t\t  &waiter);",
            "",
            "\tdebug_rt_mutex_free_waiter(&waiter);",
            "\treturn ret;",
            "}",
            "static int __sched rt_mutex_slowlock(struct rt_mutex_base *lock,",
            "\t\t\t\t     struct ww_acquire_ctx *ww_ctx,",
            "\t\t\t\t     unsigned int state)",
            "{",
            "\tunsigned long flags;",
            "\tint ret;",
            "",
            "\t/*",
            "\t * Do all pre-schedule work here, before we queue a waiter and invoke",
            "\t * PI -- any such work that trips on rtlock (PREEMPT_RT spinlock) would",
            "\t * otherwise recurse back into task_blocks_on_rt_mutex() through",
            "\t * rtlock_slowlock() and will then enqueue a second waiter for this",
            "\t * same task and things get really confusing real fast.",
            "\t */",
            "\trt_mutex_pre_schedule();",
            "",
            "\t/*",
            "\t * Technically we could use raw_spin_[un]lock_irq() here, but this can",
            "\t * be called in early boot if the cmpxchg() fast path is disabled",
            "\t * (debug, no architecture support). In this case we will acquire the",
            "\t * rtmutex with lock->wait_lock held. But we cannot unconditionally",
            "\t * enable interrupts in that early boot case. So we need to use the",
            "\t * irqsave/restore variants.",
            "\t */",
            "\traw_spin_lock_irqsave(&lock->wait_lock, flags);",
            "\tret = __rt_mutex_slowlock_locked(lock, ww_ctx, state);",
            "\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);",
            "\trt_mutex_post_schedule();",
            "",
            "\treturn ret;",
            "}",
            "static __always_inline int __rt_mutex_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t\t   unsigned int state)",
            "{",
            "\tlockdep_assert(!current->pi_blocked_on);",
            "",
            "\tif (likely(rt_mutex_try_acquire(lock)))",
            "\t\treturn 0;",
            "",
            "\treturn rt_mutex_slowlock(lock, NULL, state);",
            "}",
            "static void __sched rtlock_slowlock_locked(struct rt_mutex_base *lock)",
            "{",
            "\tstruct rt_mutex_waiter waiter;",
            "\tstruct task_struct *owner;",
            "",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tif (try_to_take_rt_mutex(lock, current, NULL))",
            "\t\treturn;",
            "",
            "\trt_mutex_init_rtlock_waiter(&waiter);",
            "",
            "\t/* Save current state and set state to TASK_RTLOCK_WAIT */",
            "\tcurrent_save_and_set_rtlock_wait_state();",
            "",
            "\ttrace_contention_begin(lock, LCB_F_RT);",
            "",
            "\ttask_blocks_on_rt_mutex(lock, &waiter, current, NULL, RT_MUTEX_MIN_CHAINWALK);",
            "",
            "\tfor (;;) {",
            "\t\t/* Try to acquire the lock again */",
            "\t\tif (try_to_take_rt_mutex(lock, current, &waiter))",
            "\t\t\tbreak;",
            "",
            "\t\tif (&waiter == rt_mutex_top_waiter(lock))",
            "\t\t\towner = rt_mutex_owner(lock);",
            "\t\telse",
            "\t\t\towner = NULL;",
            "\t\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\t\tif (!owner || !rtmutex_spin_on_owner(lock, &waiter, owner))",
            "\t\t\tschedule_rtlock();",
            "",
            "\t\traw_spin_lock_irq(&lock->wait_lock);",
            "\t\tset_current_state(TASK_RTLOCK_WAIT);",
            "\t}",
            "",
            "\t/* Restore the task state */",
            "\tcurrent_restore_rtlock_saved_state();",
            "",
            "\t/*",
            "\t * try_to_take_rt_mutex() sets the waiter bit unconditionally.",
            "\t * We might have to fix that up:",
            "\t */",
            "\tfixup_rt_mutex_waiters(lock, true);",
            "\tdebug_rt_mutex_free_waiter(&waiter);",
            "",
            "\ttrace_contention_end(lock, 0);",
            "}"
          ],
          "function_name": "__rt_mutex_slowlock_locked, rt_mutex_slowlock, __rt_mutex_lock, rtlock_slowlock_locked",
          "description": "实现RT Mutex的慢速获取路径，通过初始化等待者结构体并调用底层slowlock逻辑，处理锁竞争时的等待队列管理与优先级继承检测",
          "similarity": 0.5342376232147217
        }
      ]
    },
    {
      "source_file": "kernel/locking/ww_rt_mutex.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:57:15\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\ww_rt_mutex.c`\n\n---\n\n# `locking/ww_rt_mutex.c` 技术文档\n\n## 1. 文件概述\n\n`ww_rt_mutex.c` 是 Linux 内核中实现 **Wound/Wait 语义的实时互斥锁（ww_mutex）** 的核心文件之一。该文件基于通用的 `rtmutex.c` 实时互斥锁机制，通过宏定义 `WW_RT` 和 `RT_MUTEX_BUILD_MUTEX` 复用 `rtmutex.c` 的代码，专门构建支持 **Wound/Wait 死锁避免协议** 的实时互斥锁变体。其主要作用是在支持优先级继承（Priority Inheritance）的实时调度环境中，提供一种可避免死锁的锁获取机制，特别适用于图形子系统（如 DRM）等需要复杂锁排序的场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `ww_mutex_trylock(struct ww_mutex *lock, struct ww_acquire_ctx *ww_ctx)`  \n  尝试非阻塞地获取一个 ww_mutex 锁。若提供 `ww_ctx`，则参与 Wound/Wait 协议。\n\n- `ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)`  \n  以不可中断方式阻塞获取 ww_mutex 锁，参与 Wound/Wait 死锁避免协议。\n\n- `ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)`  \n  以可中断方式阻塞获取 ww_mutex 锁，支持信号中断。\n\n- `ww_mutex_unlock(struct ww_mutex *lock)`  \n  释放已持有的 ww_mutex 锁，并更新锁依赖跟踪信息。\n\n- `__ww_rt_mutex_lock(...)`（静态辅助函数）  \n  上述两个 `lock` 函数的通用实现，封装了锁获取的公共逻辑。\n\n### 关键数据结构（引用自其他头文件）\n\n- `struct ww_mutex`：包含底层 `struct rt_mutex base` 和 Wound/Wait 上下文指针 `ctx`。\n- `struct ww_acquire_ctx`：Wound/Wait 获取上下文，记录已获取锁数量（`acquired`）、是否被“刺伤”（`wounded`）等状态，用于死锁检测与避免。\n\n## 3. 关键实现\n\n### Wound/Wait 协议集成\n- 所有锁操作均通过 `ww_ctx` 参与 Wound/Wait 协议。当 `ww_ctx->acquired == 0`（即尚未持有任何锁）时，重置 `wounded` 标志，确保上下文处于干净状态。\n- 在 `__ww_rt_mutex_lock` 中，若检测到当前线程试图重复获取同一把锁（`ww_ctx == lock->ctx`），立即返回 `-EALREADY`，防止自死锁。\n\n### 锁获取路径\n1. **快速路径**：首先尝试 `rt_mutex_try_acquire()` 非阻塞获取锁。成功则通过 `ww_mutex_set_context_fastpath()` 绑定锁与上下文，并记录锁依赖。\n2. **慢速路径**：若快速路径失败，调用 `rt_mutex_slowlock()` 进入阻塞等待，该函数内部处理优先级继承、Wound/Wait 死锁检测及“刺伤”逻辑。\n\n### 锁释放路径\n- 调用 `__ww_mutex_unlock()` 清理 ww_mutex 特定状态（如从上下文移除该锁）。\n- 通过 `mutex_release()` 通知锁依赖验证器（Lockdep）。\n- 最终调用 `__rt_mutex_unlock()` 释放底层实时互斥锁，可能触发优先级恢复或唤醒等待者。\n\n### 锁依赖跟踪（Lockdep）\n- 使用 `mutex_acquire_nest()` 和 `mutex_release()` 与内核 Lockdep 子系统交互，支持嵌套锁依赖分析，其中 `nest_lock` 指向 `ww_ctx->dep_map` 以正确建模 Wound/Wait 上下文的锁序。\n\n### 代码复用机制\n- 通过定义 `WW_RT` 和 `RT_MUTEX_BUILD_MUTEX` 宏，包含 `rtmutex.c` 文件，使其在编译时生成专用于 ww_mutex 的 rtmutex 实现，避免代码重复。\n\n## 4. 依赖关系\n\n- **`rtmutex.c`**：核心实时互斥锁实现，本文件通过宏包含方式复用其逻辑。\n- **`<linux/spinlock.h>`**：提供底层自旋锁原语，用于 rtmutex 内部同步。\n- **`<linux/export.h>`**：导出符号供其他内核模块使用（如 DRM 驱动）。\n- **Lockdep 子系统**：通过 `mutex_acquire_nest()`、`mutex_release()` 等接口集成运行时锁依赖验证。\n- **调度器**：依赖 `might_sleep()`、`TASK_UNINTERRUPTIBLE`、`TASK_INTERRUPTIBLE` 等调度原语实现可睡眠锁语义。\n\n## 5. 使用场景\n\n- **图形驱动（DRM/KMS）**：在需要获取多个资源锁（如 CRTCs、planes、buffers）时，使用 ww_mutex 避免因锁序不一致导致的死锁。\n- **实时任务调度环境**：在启用 `CONFIG_PREEMPT_RT` 的系统中，替代普通 mutex 以获得优先级继承和确定性延迟。\n- **复杂资源管理子系统**：任何需要动态获取多个互斥资源且无法静态确定锁序的内核子系统，均可利用 Wound/Wait 协议实现安全的并发控制。",
      "similarity": 0.6311900019645691,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/ww_rt_mutex.c",
          "start_line": 12,
          "end_line": 93,
          "content": [
            "int ww_mutex_trylock(struct ww_mutex *lock, struct ww_acquire_ctx *ww_ctx)",
            "{",
            "\tstruct rt_mutex *rtm = &lock->base;",
            "",
            "\tif (!ww_ctx)",
            "\t\treturn rt_mutex_trylock(rtm);",
            "",
            "\t/*",
            "\t * Reset the wounded flag after a kill. No other process can",
            "\t * race and wound us here, since they can't have a valid owner",
            "\t * pointer if we don't have any locks held.",
            "\t */",
            "\tif (ww_ctx->acquired == 0)",
            "\t\tww_ctx->wounded = 0;",
            "",
            "\tif (__rt_mutex_trylock(&rtm->rtmutex)) {",
            "\t\tww_mutex_set_context_fastpath(lock, ww_ctx);",
            "\t\tmutex_acquire_nest(&rtm->dep_map, 0, 1, &ww_ctx->dep_map, _RET_IP_);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int __sched",
            "__ww_rt_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t   unsigned int state, unsigned long ip)",
            "{",
            "\tstruct lockdep_map __maybe_unused *nest_lock = NULL;",
            "\tstruct rt_mutex *rtm = &lock->base;",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "",
            "\tif (ww_ctx) {",
            "\t\tif (unlikely(ww_ctx == READ_ONCE(lock->ctx)))",
            "\t\t\treturn -EALREADY;",
            "",
            "\t\t/*",
            "\t\t * Reset the wounded flag after a kill. No other process can",
            "\t\t * race and wound us here, since they can't have a valid owner",
            "\t\t * pointer if we don't have any locks held.",
            "\t\t */",
            "\t\tif (ww_ctx->acquired == 0)",
            "\t\t\tww_ctx->wounded = 0;",
            "",
            "#ifdef CONFIG_DEBUG_LOCK_ALLOC",
            "\t\tnest_lock = &ww_ctx->dep_map;",
            "#endif",
            "\t}",
            "\tmutex_acquire_nest(&rtm->dep_map, 0, 0, nest_lock, ip);",
            "",
            "\tif (likely(rt_mutex_try_acquire(&rtm->rtmutex))) {",
            "\t\tif (ww_ctx)",
            "\t\t\tww_mutex_set_context_fastpath(lock, ww_ctx);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tret = rt_mutex_slowlock(&rtm->rtmutex, ww_ctx, state);",
            "",
            "\tif (ret)",
            "\t\tmutex_release(&rtm->dep_map, ip);",
            "\treturn ret;",
            "}",
            "int __sched",
            "ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_rt_mutex_lock(lock, ctx, TASK_UNINTERRUPTIBLE, _RET_IP_);",
            "}",
            "int __sched",
            "ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_rt_mutex_lock(lock, ctx, TASK_INTERRUPTIBLE, _RET_IP_);",
            "}",
            "void __sched ww_mutex_unlock(struct ww_mutex *lock)",
            "{",
            "\tstruct rt_mutex *rtm = &lock->base;",
            "",
            "\t__ww_mutex_unlock(lock);",
            "",
            "\tmutex_release(&rtm->dep_map, _RET_IP_);",
            "\t__rt_mutex_unlock(&rtm->rtmutex);",
            "}"
          ],
          "function_name": "ww_mutex_trylock, __ww_rt_mutex_lock, ww_mutex_lock, ww_mutex_lock_interruptible, ww_mutex_unlock",
          "description": "实现WW互斥锁的获取/释放逻辑，包含非阻塞尝试获取、阻塞等待、死锁检测上下文管理及锁状态同步，通过组合rt_mutex核心实现提供带优先级继承的重量级互斥锁机制",
          "similarity": 0.6796956062316895
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/ww_rt_mutex.c",
          "start_line": 1,
          "end_line": 11,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * rtmutex API",
            " */",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "",
            "#define RT_MUTEX_BUILD_MUTEX",
            "#define WW_RT",
            "#include \"rtmutex.c\"",
            ""
          ],
          "function_name": null,
          "description": "定义RT_MUTEX_BUILD_MUTEX和WW_RT宏，引入rtmutex.c源码，用于构建基于实时互斥锁（RT Mutex）的WW（Wait-Wound）互斥锁结构体及其相关实现",
          "similarity": 0.5427412390708923
        }
      ]
    }
  ]
}