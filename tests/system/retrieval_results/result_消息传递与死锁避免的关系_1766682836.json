{
  "query": "消息传递与死锁避免的关系",
  "timestamp": "2025-12-26 01:13:56",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/ww_mutex.h",
      "md_summary": "> 自动生成时间: 2025-10-25 14:56:40\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\ww_mutex.h`\n\n---\n\n# `locking/ww_mutex.h` 技术文档\n\n## 1. 文件概述\n\n`ww_mutex.h` 是 Linux 内核中用于实现 **Wound-Wait (WW) 互斥锁**（`ww_mutex`）的头文件。该机制主要用于解决 **死锁问题**，特别是在图形子系统（如 DRM/KMS）和资源管理场景中，多个事务（transactions）需要以特定顺序获取多个锁时。  \nWW 互斥锁通过为每个锁请求关联一个 **获取上下文**（`ww_acquire_ctx`），并基于事务的优先级或时间戳实现 **Wait-Die** 或 **Wound-Wait** 死锁避免策略。\n\n该文件通过条件编译（`WW_RT` 宏）支持两种底层锁实现：\n- **普通互斥锁**（`mutex`）：用于非实时（non-RT）内核配置。\n- **实时互斥锁**（`rt_mutex`）：用于实时（RT）内核补丁配置，支持优先级继承。\n\n## 2. 核心功能\n\n### 2.1 主要宏定义\n- `MUTEX` / `MUTEX_WAITER`：根据 `WW_RT` 宏分别映射到 `mutex`/`rt_mutex` 及其等待者结构。\n\n### 2.2 等待者链表/红黑树操作函数（抽象接口）\n- `__ww_waiter_first()`：获取等待队列中的第一个等待者。\n- `__ww_waiter_next()` / `__ww_waiter_prev()`：获取下一个/上一个等待者。\n- `__ww_waiter_last()`：获取等待队列中的最后一个等待者。\n- `__ww_waiter_add()`：将等待者插入到指定位置（普通 mutex 使用链表，RT 使用红黑树）。\n\n### 2.3 锁状态查询函数\n- `__ww_mutex_owner()`：获取当前锁的持有者任务。\n- `__ww_mutex_has_waiters()`：检查锁是否有等待者。\n- `lock_wait_lock()` / `unlock_wait_lock()`：获取/释放锁的等待队列自旋锁（`wait_lock`）。\n- `lockdep_assert_wait_lock_held()`：调试时断言 `wait_lock` 已被持有。\n\n### 2.4 WW 互斥锁核心逻辑函数\n- `ww_mutex_lock_acquired()`：在成功获取 `ww_mutex` 后，将其与获取上下文（`ww_ctx`）关联，并执行调试检查。\n- `__ww_ctx_less()`：比较两个获取上下文的优先级（用于决定谁应“等待”或“死亡/被抢占”）。\n- `__ww_mutex_die()`：**Wait-Die 策略**实现：若当前请求者（新事务）发现等待队列中有更老的事务持有其他锁，则唤醒该老事务使其“死亡”（回滚）。\n- `__ww_mutex_wound()`：**Wound-Wait 策略**实现：若当前请求者（老事务）发现锁持有者是更年轻的事务，则“刺伤”（标记 `wounded=1`）该年轻事务，迫使其回滚。\n\n## 3. 关键实现\n\n### 3.1 死锁避免策略\n- **Wait-Die**（`is_wait_die=1`）：\n  - **新事务**请求**老事务**持有的锁 → **新事务等待**。\n  - **新事务**请求**老事务**等待的锁 → **新事务死亡**（回滚）。\n- **Wound-Wait**（`is_wait_die=0`）：\n  - **老事务**请求**新事务**持有的锁 → **新事务被刺伤**（回滚）。\n  - **老事务**请求**新事务**等待的锁 → **老事务等待**。\n\n### 3.2 上下文比较 (`__ww_ctx_less`)\n- **非 RT 模式**：仅基于时间戳（`stamp`），值越大表示事务越新。\n- **RT 模式**：\n  1. 优先比较 **实时优先级**（`prio`），数值越小优先级越高。\n  2. 若均为 **Deadline 调度类**，比较 **截止时间**（`deadline`），越早截止优先级越高。\n  3. 若优先级相同，回退到时间戳比较。\n\n### 3.3 RT 与非 RT 差异\n- **数据结构**：\n  - 非 RT：等待者使用 **双向链表**（`list_head`）。\n  - RT：等待者使用 **红黑树**（`rb_root`），按优先级排序。\n- **插入逻辑**：\n  - 非 RT：`__ww_waiter_add` 显式插入到指定位置。\n  - RT：`__ww_waiter_add` 为空（RT 互斥锁内部自动处理插入）。\n\n### 3.4 调试支持 (`DEBUG_WW_MUTEXES`)\n- 检查 `ww_mutex` 是否被错误地用普通 `mutex_unlock` 释放。\n- 验证上下文一致性（如 `ww_class` 匹配、`contending_lock` 状态等）。\n\n## 4. 依赖关系\n\n- **基础锁机制**：\n  - 非 RT 模式依赖 `<linux/mutex.h>`。\n  - RT 模式依赖 `<linux/rtmutex.h>`。\n- **调度器**：依赖任务结构（`task_struct`）、优先级（`prio`）、调度类（如 `dl_prio`）。\n- **调试框架**：依赖 `lockdep`（`lockdep_assert_held`）和 `DEBUG_LOCKS_WARN_ON`。\n- **原子操作**：使用 `atomic_long_read` 检查锁状态标志（`MUTEX_FLAG_WAITERS`）。\n\n## 5. 使用场景\n\n- **图形子系统**（DRM/KMS）：  \n  多个 GPU 作业（如渲染、合成）需按顺序获取多个缓冲区（buffer）或 CRTC 锁，避免死锁。\n- **资源分配器**：  \n  当多个客户端竞争一组有限资源（如内存区域、I/O 端口）时，通过 WW 互斥锁确保无死锁的分配顺序。\n- **实时系统**（RT 补丁）：  \n  在需要确定性延迟的场景中，结合优先级继承（PI）避免优先级反转，同时通过 WW 策略解决多锁死锁。\n- **文件系统**：  \n  某些文件系统（如 Btrfs）在元数据操作中使用 WW 互斥锁管理多个 extent 锁。",
      "similarity": 0.5744805335998535,
      "chunks": []
    },
    {
      "source_file": "kernel/locking/semaphore.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:52:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\semaphore.c`\n\n---\n\n# `locking/semaphore.c` 技术文档\n\n## 1. 文件概述\n\n`locking/semaphore.c` 实现了 Linux 内核中的**计数信号量（counting semaphore）**机制。计数信号量允许多个任务（最多为初始计数值）同时持有该锁，当计数值耗尽时，后续请求者将被阻塞，直到有其他任务释放信号量。与互斥锁（mutex）不同，信号量支持更灵活的并发控制，适用于资源池、限流等场景。该文件提供了多种获取和释放信号量的接口，包括可中断、可超时、不可中断等变体，并支持在中断上下文中调用部分函数。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数名 | 功能描述 |\n|--------|--------|\n| `down(struct semaphore *sem)` | 不可中断地获取信号量，若不可用则睡眠。**已弃用**，建议使用可中断版本。 |\n| `down_interruptible(struct semaphore *sem)` | 可被普通信号中断的获取操作，成功返回 0，被信号中断返回 `-EINTR`。 |\n| `down_killable(struct semaphore *sem)` | 可被致命信号（fatal signal）中断的获取操作，返回值同上。 |\n| `down_trylock(struct semaphore *sem)` | 非阻塞尝试获取信号量，成功返回 0，失败返回 1（**注意返回值与 mutex/spinlock 相反**）。 |\n| `down_timeout(struct semaphore *sem, long timeout)` | 带超时的获取操作，超时返回 `-ETIME`，成功返回 0。 |\n| `up(struct semaphore *sem)` | 释放信号量，可由任意上下文（包括中断）调用，唤醒等待队列中的任务。 |\n\n### 静态辅助函数\n\n- `__down*()` 系列：处理信号量争用时的阻塞逻辑。\n- `__up()`：在有等待者时执行唤醒逻辑。\n- `___down_common()`：通用的阻塞等待实现，支持不同睡眠状态和超时。\n- `__sem_acquire()`：原子减少计数并记录持有者（用于 hung task 检测）。\n\n### 数据结构\n\n- `struct semaphore`（定义在 `<linux/semaphore.h>`）：\n  - `count`：当前可用资源数（>0 表示可立即获取）。\n  - `wait_list`：等待该信号量的任务链表。\n  - `lock`：保护上述成员的原始自旋锁（`raw_spinlock_t`）。\n  - `last_holder`（条件编译）：记录最后持有者，用于 `CONFIG_DETECT_HUNG_TASK_BLOCKER`。\n\n- `struct semaphore_waiter`：\n  - 用于将任务加入等待队列，包含任务指针和唤醒标志（`up`）。\n\n## 3. 关键实现\n\n### 中断安全与自旋锁\n- 所有对外接口（包括 `down*` 和 `up`）均使用 `raw_spin_lock_irqsave()` 获取自旋锁，确保在中断上下文安全。\n- 即使 `down()` 等函数通常在进程上下文调用，也使用 `irqsave` 变体，因为内核某些部分依赖在中断上下文成功调用 `down()`（当确定信号量可用时）。\n\n### 计数语义\n- `sem->count` 表示**还可被获取的次数**。初始值由 `sema_init()` 设置。\n- 获取时：若 `count > 0`，直接减 1；否则加入等待队列。\n- 释放时：若等待队列为空，`count++`；否则唤醒队首任务。\n\n### 等待与唤醒机制\n- 使用 `wake_q`（批量唤醒队列）优化唤醒路径，避免在持有自旋锁时调用 `wake_up_process()`。\n- 等待任务通过 `schedule_timeout()` 睡眠，并在循环中检查：\n  - 是否收到信号（根据睡眠状态判断）。\n  - 是否超时。\n  - 是否被 `__up()` 标记为 `waiter.up = true`（表示已被选中唤醒）。\n\n### Hung Task 支持\n- 当启用 `CONFIG_DETECT_HUNG_TASK_BLOCKER` 时：\n  - 获取信号量时记录当前任务为 `last_holder`。\n  - 释放时若当前任务是持有者，则清除记录。\n  - 提供 `sem_last_holder()` 供 hung task 检测模块查询阻塞源头。\n\n### 返回值约定\n- `down_trylock()` 返回 **0 表示成功**，**1 表示失败**，这与 `mutex_trylock()` 和 `spin_trylock()` **相反**，需特别注意。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/semaphore.h>`：信号量结构体和 API 声明。\n  - `<linux/spinlock.h>`：原始自旋锁实现。\n  - `<linux/sched.h>`、`<linux/sched/wake_q.h>`：任务调度和批量唤醒。\n  - `<trace/events/lock.h>`：锁争用跟踪点。\n  - `<linux/hung_task.h>`：hung task 检测支持。\n\n- **内核配置依赖**：\n  - `CONFIG_DETECT_HUNG_TASK_BLOCKER`：启用信号量持有者跟踪。\n\n- **与其他同步原语关系**：\n  - 与 `mutex.c` 形成对比：mutex 是二值、不可递归、带调试信息的互斥锁；信号量是计数、可被任意任务释放、更轻量。\n  - 底层依赖调度器（`schedule_timeout`）和中断管理（`irqsave`）。\n\n## 5. 使用场景\n\n- **资源池管理**：如限制同时访问某类硬件设备的任务数量。\n- **读写并发控制**：配合其他机制实现多读者/单写者模型。\n- **内核驱动**：设备驱动中控制对共享资源的并发访问。\n- **中断上下文释放**：因 `up()` 可在中断中调用，适用于中断处理程序释放资源的场景。\n- **不可睡眠路径**：使用 `down_trylock()` 在原子上下文尝试获取资源。\n\n> **注意**：由于信号量不强制所有权（任意任务可调用 `up()`），且缺乏死锁检测等调试特性，现代内核开发中更推荐使用 `mutex` 或 `rwsem`，除非明确需要计数语义或多释放者特性。",
      "similarity": 0.5526431202888489,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/semaphore.c",
          "start_line": 46,
          "end_line": 160,
          "content": [
            "static inline void hung_task_sem_set_holder(struct semaphore *sem)",
            "{",
            "\tWRITE_ONCE((sem)->last_holder, (unsigned long)current);",
            "}",
            "static inline void hung_task_sem_clear_if_holder(struct semaphore *sem)",
            "{",
            "\tif (READ_ONCE((sem)->last_holder) == (unsigned long)current)",
            "\t\tWRITE_ONCE((sem)->last_holder, 0UL);",
            "}",
            "unsigned long sem_last_holder(struct semaphore *sem)",
            "{",
            "\treturn READ_ONCE(sem->last_holder);",
            "}",
            "static inline void hung_task_sem_set_holder(struct semaphore *sem)",
            "{",
            "}",
            "static inline void hung_task_sem_clear_if_holder(struct semaphore *sem)",
            "{",
            "}",
            "unsigned long sem_last_holder(struct semaphore *sem)",
            "{",
            "\treturn 0UL;",
            "}",
            "static inline void __sem_acquire(struct semaphore *sem)",
            "{",
            "\tsem->count--;",
            "\thung_task_sem_set_holder(sem);",
            "}",
            "void __sched down(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\t__down(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "}",
            "int __sched down_interruptible(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tint result = 0;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\tresult = __down_interruptible(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn result;",
            "}",
            "int __sched down_killable(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tint result = 0;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\tresult = __down_killable(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn result;",
            "}",
            "int __sched down_trylock(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tint count;",
            "",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tcount = sem->count - 1;",
            "\tif (likely(count >= 0))",
            "\t\t__sem_acquire(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn (count < 0);",
            "}",
            "int __sched down_timeout(struct semaphore *sem, long timeout)",
            "{",
            "\tunsigned long flags;",
            "\tint result = 0;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\tresult = __down_timeout(sem, timeout);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn result;",
            "}",
            "void __sched up(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tDEFINE_WAKE_Q(wake_q);",
            "",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "",
            "\thung_task_sem_clear_if_holder(sem);",
            "",
            "\tif (likely(list_empty(&sem->wait_list)))",
            "\t\tsem->count++;",
            "\telse",
            "\t\t__up(sem, &wake_q);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "\tif (!wake_q_empty(&wake_q))",
            "\t\twake_up_q(&wake_q);",
            "}"
          ],
          "function_name": "hung_task_sem_set_holder, hung_task_sem_clear_if_holder, sem_last_holder, hung_task_sem_set_holder, hung_task_sem_clear_if_holder, sem_last_holder, __sem_acquire, down, down_interruptible, down_killable, down_trylock, down_timeout, up",
          "description": "实现了信号量的获取与释放核心逻辑，包括down/down_interruptible/down_killable/down_trylock/down_timeout等接口，通过spinlock保护共享资源，维护等待队列并处理任务状态变更，其中包含Hung Task检测相关函数的条件性实现",
          "similarity": 0.527559220790863
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/semaphore.c",
          "start_line": 252,
          "end_line": 323,
          "content": [
            "static inline int __sched ___down_common(struct semaphore *sem, long state,",
            "\t\t\t\t\t\t\t\tlong timeout)",
            "{",
            "\tstruct semaphore_waiter waiter;",
            "",
            "\tlist_add_tail(&waiter.list, &sem->wait_list);",
            "\twaiter.task = current;",
            "\twaiter.up = false;",
            "",
            "\tfor (;;) {",
            "\t\tif (signal_pending_state(state, current))",
            "\t\t\tgoto interrupted;",
            "\t\tif (unlikely(timeout <= 0))",
            "\t\t\tgoto timed_out;",
            "\t\t__set_current_state(state);",
            "\t\traw_spin_unlock_irq(&sem->lock);",
            "\t\ttimeout = schedule_timeout(timeout);",
            "\t\traw_spin_lock_irq(&sem->lock);",
            "\t\tif (waiter.up) {",
            "\t\t\thung_task_sem_set_holder(sem);",
            "\t\t\treturn 0;",
            "\t\t}",
            "\t}",
            "",
            " timed_out:",
            "\tlist_del(&waiter.list);",
            "\treturn -ETIME;",
            "",
            " interrupted:",
            "\tlist_del(&waiter.list);",
            "\treturn -EINTR;",
            "}",
            "static inline int __sched __down_common(struct semaphore *sem, long state,",
            "\t\t\t\t\tlong timeout)",
            "{",
            "\tint ret;",
            "",
            "\thung_task_set_blocker(sem, BLOCKER_TYPE_SEM);",
            "",
            "\ttrace_contention_begin(sem, 0);",
            "\tret = ___down_common(sem, state, timeout);",
            "\ttrace_contention_end(sem, ret);",
            "",
            "\thung_task_clear_blocker();",
            "",
            "\treturn ret;",
            "}",
            "static noinline void __sched __down(struct semaphore *sem)",
            "{",
            "\t__down_common(sem, TASK_UNINTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);",
            "}",
            "static noinline int __sched __down_interruptible(struct semaphore *sem)",
            "{",
            "\treturn __down_common(sem, TASK_INTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);",
            "}",
            "static noinline int __sched __down_killable(struct semaphore *sem)",
            "{",
            "\treturn __down_common(sem, TASK_KILLABLE, MAX_SCHEDULE_TIMEOUT);",
            "}",
            "static noinline int __sched __down_timeout(struct semaphore *sem, long timeout)",
            "{",
            "\treturn __down_common(sem, TASK_UNINTERRUPTIBLE, timeout);",
            "}",
            "static noinline void __sched __up(struct semaphore *sem,",
            "\t\t\t\t  struct wake_q_head *wake_q)",
            "{",
            "\tstruct semaphore_waiter *waiter = list_first_entry(&sem->wait_list,",
            "\t\t\t\t\t\tstruct semaphore_waiter, list);",
            "\tlist_del(&waiter->list);",
            "\twaiter->up = true;",
            "\twake_q_add(wake_q, waiter->task);",
            "}"
          ],
          "function_name": "___down_common, __down_common, __down, __down_interruptible, __down_killable, __down_timeout, __up",
          "description": "实现了信号量的阻塞等待通用逻辑，包含___down_common/__down_common等辅助函数，处理信号量不足时的任务挂起、超时检测、信号处理及唤醒机制，通过循环等待并结合schedule_timeout实现阻塞式资源竞争解决",
          "similarity": 0.44023022055625916
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/semaphore.c",
          "start_line": 1,
          "end_line": 45,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Copyright (c) 2008 Intel Corporation",
            " * Author: Matthew Wilcox <willy@linux.intel.com>",
            " *",
            " * This file implements counting semaphores.",
            " * A counting semaphore may be acquired 'n' times before sleeping.",
            " * See mutex.c for single-acquisition sleeping locks which enforce",
            " * rules which allow code to be debugged more easily.",
            " */",
            "",
            "/*",
            " * Some notes on the implementation:",
            " *",
            " * The spinlock controls access to the other members of the semaphore.",
            " * down_trylock() and up() can be called from interrupt context, so we",
            " * have to disable interrupts when taking the lock.  It turns out various",
            " * parts of the kernel expect to be able to use down() on a semaphore in",
            " * interrupt context when they know it will succeed, so we have to use",
            " * irqsave variants for down(), down_interruptible() and down_killable()",
            " * too.",
            " *",
            " * The ->count variable represents how many more tasks can acquire this",
            " * semaphore.  If it's zero, there may be tasks waiting on the wait_list.",
            " */",
            "",
            "#include <linux/compiler.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>",
            "#include <linux/sched.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/semaphore.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/ftrace.h>",
            "#include <trace/events/lock.h>",
            "#include <linux/hung_task.h>",
            "",
            "static noinline void __down(struct semaphore *sem);",
            "static noinline int __down_interruptible(struct semaphore *sem);",
            "static noinline int __down_killable(struct semaphore *sem);",
            "static noinline int __down_timeout(struct semaphore *sem, long timeout);",
            "static noinline void __up(struct semaphore *sem, struct wake_q_head *wake_q);",
            "",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER"
          ],
          "function_name": null,
          "description": "此代码块定义了计数信号量的基础框架，包含实现计数信号量所需的头文件和注释，声明了多个内联函数及辅助函数，用于处理信号量的获取、释放及Hung Task检测相关逻辑，但由于代码截断，CONFIG_DETECT_HUNG_TASK_BLOCKER部分缺失，上下文不完整",
          "similarity": 0.40669307112693787
        }
      ]
    },
    {
      "source_file": "kernel/locking/rtmutex_api.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:49:05\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\rtmutex_api.c`\n\n---\n\n# `locking/rtmutex_api.c` 技术文档\n\n## 1. 文件概述\n\n`rtmutex_api.c` 是 Linux 内核中实时互斥锁（Real-Time Mutex, rtmutex）的公共 API 实现文件。该文件封装了底层 rtmutex 核心逻辑（定义在 `rtmutex.c` 中），为内核其他子系统提供统一、安全、可调试的互斥锁操作接口。它支持多种锁获取模式（不可中断、可中断、可终止）、调试锁依赖（lockdep）、PI（Priority Inheritance，优先级继承）机制，并为 futex（快速用户空间互斥）提供专用变体接口。该文件通过条件编译适配是否启用锁调试功能（`CONFIG_DEBUG_LOCK_ALLOC`）。\n\n## 2. 核心功能\n\n### 全局变量\n- `max_lock_depth`: 定义优先级继承链（boosting chain）的最大遍历深度，防止死锁检测时无限循环，默认值为 1024。\n\n### 主要函数\n\n#### 初始化与销毁\n- `rt_mutex_base_init()`: 初始化 `rt_mutex_base` 结构体的基础字段。\n- `__rt_mutex_init()`: 完整初始化一个 `rt_mutex`，包括底层 rtmutex 和 lockdep 调试信息。\n- `rt_mutex_init_proxy_locked()`: 为 PI-futex 场景初始化并立即锁定 rtmutex，指定代理持有者（proxy owner）。\n- `rt_mutex_proxy_unlock()`: 为 PI-futex 场景释放由代理持有的 rtmutex。\n\n#### 锁获取（Locking）\n- `rt_mutex_lock[_nested]()`: 以不可中断方式获取 rtmutex（支持 lockdep 嵌套子类）。\n- `_rt_mutex_lock_nest_lock()`: 获取 rtmutex 并关联一个嵌套锁（nest lock）用于 lockdep。\n- `rt_mutex_lock_interruptible()`: 以可被信号中断的方式获取 rtmutex。\n- `rt_mutex_lock_killable()`: 以可被致命信号中断的方式获取 rtmutex。\n- `rt_mutex_trylock()`: 尝试非阻塞获取 rtmutex，成功返回 1，失败返回 0。\n\n#### 锁释放（Unlocking）\n- `rt_mutex_unlock()`: 释放 rtmutex。\n- `rt_mutex_futex_unlock()`: 专用于 futex 的 rtmutex 释放接口。\n- `__rt_mutex_futex_unlock()`: futex 释放的内部实现，需配合 `rt_mutex_postunlock()` 使用。\n\n#### Futex 专用接口\n- `rt_mutex_futex_trylock()`: futex 使用的非阻塞尝试锁接口。\n- `__rt_mutex_futex_trylock()`: futex 尝试锁的底层实现。\n\n#### 代理锁操作（Proxy Locking，用于 PI-futex）\n- `__rt_mutex_start_proxy_lock()`: 为另一个任务启动代理锁获取流程（仅入队，不阻塞等待）。\n\n## 3. 关键实现\n\n### 锁操作通用封装\n- `__rt_mutex_lock_common()` 是所有阻塞式锁获取函数的统一入口。它负责：\n  - 调用 `might_sleep()` 提示可能睡眠。\n  - 通过 `mutex_acquire_nest()` 向 lockdep 子系统注册锁获取事件。\n  - 调用底层 `__rt_mutex_lock()` 执行实际的锁逻辑。\n  - 若获取失败（如被信号中断），则调用 `mutex_release()` 通知 lockdep 释放。\n\n### 调试支持\n- 在 `CONFIG_DEBUG_LOCK_ALLOC` 启用时，提供带 lockdep 子类和嵌套锁参数的锁接口（如 `rt_mutex_lock_nested`），增强死锁检测能力。\n- `rt_mutex_trylock()` 在调试模式下会检查调用上下文是否为任务上下文（`in_task()`），防止在中断上下文中误用。\n- 初始化函数 `__rt_mutex_init()` 调用 `debug_check_no_locks_freed()` 防止对已释放内存初始化锁。\n\n### Futex 特殊处理\n- Futex 相关接口（如 `rt_mutex_futex_unlock`）绕过 rtmutex 的 fast-path，直接使用 slow-path 实现。\n- `rt_mutex_init_proxy_locked()` 为 PI-futex 场景中的 `wait_lock` 分配独立的 lockdep 类键（`pi_futex_key`），避免与 futex 哈希桶自旋锁产生虚假的锁递归警告。\n- `__rt_mutex_futex_unlock()` 在释放锁时，若存在等待者，则调用 `mark_wakeup_next_waiter()` 准备唤醒，并返回 `true` 指示需后续调用 `rt_mutex_postunlock()` 完成唤醒。\n\n### 代理锁机制\n- 代理锁函数（如 `rt_mutex_init_proxy_locked` 和 `__rt_mutex_start_proxy_lock`）用于 PI-futex 实现，允许内核代表用户空间任务持有或竞争锁，是优先级继承在 futex 上的关键支撑。\n\n## 4. 依赖关系\n\n- **底层实现**: 通过 `#include \"rtmutex.c\"`（配合 `RT_MUTEX_BUILD_MUTEX` 宏）内联包含 `rtmutex.c` 中的核心逻辑（如 `__rt_mutex_lock`, `__rt_mutex_unlock` 等）。\n- **同步原语**: 依赖 `<linux/spinlock.h>` 提供自旋锁操作（如 `raw_spin_lock_irqsave`）。\n- **调试子系统**: \n  - 依赖 Lockdep（`<linux/lockdep.h>` 隐式包含）进行锁依赖和死锁检测。\n  - 依赖 RT Mutex 调试（`CONFIG_DEBUG_RT_MUTEXES`）进行运行时检查。\n- **调度器**: 使用 `TASK_*` 状态常量（如 `TASK_INTERRUPTIBLE`）与调度器交互，支持可中断睡眠。\n- **导出符号**: 通过 `EXPORT_SYMBOL` 和 `EXPORT_SYMBOL_GPL` 向内核其他模块（如 futex、PI 子系统）提供 API。\n\n## 5. 使用场景\n\n- **实时互斥锁**: 作为内核中支持优先级继承的互斥锁实现，用于需要避免优先级反转的实时任务同步。\n- **PI-futex 支持**: 为用户空间的 PI-aware futex（`FUTEX_LOCK_PI` 等操作）提供内核态代理锁管理，实现跨进程的优先级继承。\n- **内核子系统同步**: 被需要强优先级继承语义的内核子系统（如某些设备驱动、实时调度相关代码）直接使用。\n- **调试与验证**: 在启用锁调试的内核配置下，为 lockdep 提供详细的锁获取/释放轨迹，辅助死锁分析。",
      "similarity": 0.5523561239242554,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 590,
          "end_line": 607,
          "content": [
            "int __sched mutex_trylock(struct mutex *lock)",
            "{",
            "\tint ret;",
            "",
            "\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))",
            "\t\treturn 0;",
            "",
            "\tret = __rt_mutex_trylock(&lock->rtmutex);",
            "\tif (ret)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn ret;",
            "}",
            "void __sched mutex_unlock(struct mutex *lock)",
            "{",
            "\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\t__rt_mutex_unlock(&lock->rtmutex);",
            "}"
          ],
          "function_name": "mutex_trylock, mutex_unlock",
          "description": "实现互斥锁的尝试获取和释放操作，通过底层rtmutex_trylock进行非阻塞获取，成功时记录锁占用状态，释放时触发锁依赖跟踪和底层解锁流程。",
          "similarity": 0.5490245819091797
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 236,
          "end_line": 354,
          "content": [
            "void __sched rt_mutex_init_proxy_locked(struct rt_mutex_base *lock,",
            "\t\t\t\t\tstruct task_struct *proxy_owner)",
            "{",
            "\tstatic struct lock_class_key pi_futex_key;",
            "",
            "\t__rt_mutex_base_init(lock);",
            "\t/*",
            "\t * On PREEMPT_RT the futex hashbucket spinlock becomes 'sleeping'",
            "\t * and rtmutex based. That causes a lockdep false positive, because",
            "\t * some of the futex functions invoke spin_unlock(&hb->lock) with",
            "\t * the wait_lock of the rtmutex associated to the pi_futex held.",
            "\t * spin_unlock() in turn takes wait_lock of the rtmutex on which",
            "\t * the spinlock is based, which makes lockdep notice a lock",
            "\t * recursion. Give the futex/rtmutex wait_lock a separate key.",
            "\t */",
            "\tlockdep_set_class(&lock->wait_lock, &pi_futex_key);",
            "\trt_mutex_set_owner(lock, proxy_owner);",
            "}",
            "void __sched rt_mutex_proxy_unlock(struct rt_mutex_base *lock)",
            "{",
            "\tdebug_rt_mutex_proxy_unlock(lock);",
            "\trt_mutex_clear_owner(lock);",
            "}",
            "int __sched __rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t\tstruct rt_mutex_waiter *waiter,",
            "\t\t\t\t\tstruct task_struct *task)",
            "{",
            "\tint ret;",
            "",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tif (try_to_take_rt_mutex(lock, task, NULL))",
            "\t\treturn 1;",
            "",
            "\t/* We enforce deadlock detection for futexes */",
            "\tret = task_blocks_on_rt_mutex(lock, waiter, task, NULL,",
            "\t\t\t\t      RT_MUTEX_FULL_CHAINWALK);",
            "",
            "\tif (ret && !rt_mutex_owner(lock)) {",
            "\t\t/*",
            "\t\t * Reset the return value. We might have",
            "\t\t * returned with -EDEADLK and the owner",
            "\t\t * released the lock while we were walking the",
            "\t\t * pi chain.  Let the waiter sort it out.",
            "\t\t */",
            "\t\tret = 0;",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "int __sched rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t      struct rt_mutex_waiter *waiter,",
            "\t\t\t\t      struct task_struct *task)",
            "{",
            "\tint ret;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\tret = __rt_mutex_start_proxy_lock(lock, waiter, task);",
            "\tif (unlikely(ret))",
            "\t\tremove_waiter(lock, waiter);",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn ret;",
            "}",
            "int __sched rt_mutex_wait_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t     struct hrtimer_sleeper *to,",
            "\t\t\t\t     struct rt_mutex_waiter *waiter)",
            "{",
            "\tint ret;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\t/* sleep on the mutex */",
            "\tset_current_state(TASK_INTERRUPTIBLE);",
            "\tret = rt_mutex_slowlock_block(lock, NULL, TASK_INTERRUPTIBLE, to, waiter);",
            "\t/*",
            "\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might",
            "\t * have to fix that up.",
            "\t */",
            "\tfixup_rt_mutex_waiters(lock, true);",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn ret;",
            "}",
            "bool __sched rt_mutex_cleanup_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t\t struct rt_mutex_waiter *waiter)",
            "{",
            "\tbool cleanup = false;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\t/*",
            "\t * Do an unconditional try-lock, this deals with the lock stealing",
            "\t * state where __rt_mutex_futex_unlock() -> mark_wakeup_next_waiter()",
            "\t * sets a NULL owner.",
            "\t *",
            "\t * We're not interested in the return value, because the subsequent",
            "\t * test on rt_mutex_owner() will infer that. If the trylock succeeded,",
            "\t * we will own the lock and it will have removed the waiter. If we",
            "\t * failed the trylock, we're still not owner and we need to remove",
            "\t * ourselves.",
            "\t */",
            "\ttry_to_take_rt_mutex(lock, current, waiter);",
            "\t/*",
            "\t * Unless we're the owner; we're still enqueued on the wait_list.",
            "\t * So check if we became owner, if not, take us off the wait_list.",
            "\t */",
            "\tif (rt_mutex_owner(lock) != current) {",
            "\t\tremove_waiter(lock, waiter);",
            "\t\tcleanup = true;",
            "\t}",
            "\t/*",
            "\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might",
            "\t * have to fix that up.",
            "\t */",
            "\tfixup_rt_mutex_waiters(lock, false);",
            "",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn cleanup;",
            "}"
          ],
          "function_name": "rt_mutex_init_proxy_locked, rt_mutex_proxy_unlock, __rt_mutex_start_proxy_lock, rt_mutex_start_proxy_lock, rt_mutex_wait_proxy_lock, rt_mutex_cleanup_proxy_lock",
          "description": "处理锁代理机制，包含代理锁初始化、释放逻辑及死锁检测流程，通过遍历锁链进行优先级继承调整，确保多线程环境下的锁所有权安全转移。",
          "similarity": 0.548721432685852
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 453,
          "end_line": 554,
          "content": [
            "void __sched rt_mutex_adjust_pi(struct task_struct *task)",
            "{",
            "\tstruct rt_mutex_waiter *waiter;",
            "\tstruct rt_mutex_base *next_lock;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&task->pi_lock, flags);",
            "",
            "\twaiter = task->pi_blocked_on;",
            "\tif (!waiter || rt_waiter_node_equal(&waiter->tree, task_to_waiter_node(task))) {",
            "\t\traw_spin_unlock_irqrestore(&task->pi_lock, flags);",
            "\t\treturn;",
            "\t}",
            "\tnext_lock = waiter->lock;",
            "\traw_spin_unlock_irqrestore(&task->pi_lock, flags);",
            "",
            "\t/* gets dropped in rt_mutex_adjust_prio_chain()! */",
            "\tget_task_struct(task);",
            "",
            "\trt_mutex_adjust_prio_chain(task, RT_MUTEX_MIN_CHAINWALK, NULL,",
            "\t\t\t\t   next_lock, NULL, task);",
            "}",
            "void __sched rt_mutex_postunlock(struct rt_wake_q_head *wqh)",
            "{",
            "\trt_mutex_wake_up_q(wqh);",
            "}",
            "void rt_mutex_debug_task_free(struct task_struct *task)",
            "{",
            "\tDEBUG_LOCKS_WARN_ON(!RB_EMPTY_ROOT(&task->pi_waiters.rb_root));",
            "\tDEBUG_LOCKS_WARN_ON(task->pi_blocked_on);",
            "}",
            "void __mutex_rt_init(struct mutex *mutex, const char *name,",
            "\t\t     struct lock_class_key *key)",
            "{",
            "\tdebug_check_no_locks_freed((void *)mutex, sizeof(*mutex));",
            "\tlockdep_init_map_wait(&mutex->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "}",
            "static __always_inline int __mutex_lock_common(struct mutex *lock,",
            "\t\t\t\t\t       unsigned int state,",
            "\t\t\t\t\t       unsigned int subclass,",
            "\t\t\t\t\t       struct lockdep_map *nest_lock,",
            "\t\t\t\t\t       unsigned long ip)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);",
            "\tret = __rt_mutex_lock(&lock->rtmutex, state);",
            "\tif (ret)",
            "\t\tmutex_release(&lock->dep_map, ip);",
            "\telse",
            "\t\tlock_acquired(&lock->dep_map, ip);",
            "\treturn ret;",
            "}",
            "void __sched mutex_lock_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched _mutex_lock_nest_lock(struct mutex *lock,",
            "\t\t\t\t   struct lockdep_map *nest_lock)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, nest_lock, _RET_IP_);",
            "}",
            "int __sched mutex_lock_interruptible_nested(struct mutex *lock,",
            "\t\t\t\t\t    unsigned int subclass)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_killable_nested(struct mutex *lock,",
            "\t\t\t\t\t    unsigned int subclass)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched mutex_lock_io_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\tint token;",
            "",
            "\tmight_sleep();",
            "",
            "\ttoken = io_schedule_prepare();",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "\tio_schedule_finish(token);",
            "}",
            "void __sched mutex_lock(struct mutex *lock)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_interruptible(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_killable(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);",
            "}",
            "void __sched mutex_lock_io(struct mutex *lock)",
            "{",
            "\tint token = io_schedule_prepare();",
            "",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "\tio_schedule_finish(token);",
            "}"
          ],
          "function_name": "rt_mutex_adjust_pi, rt_mutex_postunlock, rt_mutex_debug_task_free, __mutex_rt_init, __mutex_lock_common, mutex_lock_nested, _mutex_lock_nest_lock, mutex_lock_interruptible_nested, mutex_lock_killable_nested, mutex_lock_io_nested, mutex_lock, mutex_lock_interruptible, mutex_lock_killable, mutex_lock_io",
          "description": "提供标准互斥锁（mutex）的封装接口，将rtmutex操作映射到传统mutex接口，包含嵌套加锁、I/O路径加锁、优先级调整等特殊场景的支持实现。",
          "similarity": 0.5176600217819214
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 22,
          "end_line": 127,
          "content": [
            "static __always_inline int __rt_mutex_lock_common(struct rt_mutex *lock,",
            "\t\t\t\t\t\t  unsigned int state,",
            "\t\t\t\t\t\t  struct lockdep_map *nest_lock,",
            "\t\t\t\t\t\t  unsigned int subclass)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, _RET_IP_);",
            "\tret = __rt_mutex_lock(&lock->rtmutex, state);",
            "\tif (ret)",
            "\t\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\treturn ret;",
            "}",
            "void rt_mutex_base_init(struct rt_mutex_base *rtb)",
            "{",
            "\t__rt_mutex_base_init(rtb);",
            "}",
            "void __sched rt_mutex_lock_nested(struct rt_mutex *lock, unsigned int subclass)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, subclass);",
            "}",
            "void __sched _rt_mutex_lock_nest_lock(struct rt_mutex *lock, struct lockdep_map *nest_lock)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, nest_lock, 0);",
            "}",
            "void __sched rt_mutex_lock(struct rt_mutex *lock)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_lock_interruptible(struct rt_mutex *lock)",
            "{",
            "\treturn __rt_mutex_lock_common(lock, TASK_INTERRUPTIBLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_lock_killable(struct rt_mutex *lock)",
            "{",
            "\treturn __rt_mutex_lock_common(lock, TASK_KILLABLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_trylock(struct rt_mutex *lock)",
            "{",
            "\tint ret;",
            "",
            "\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))",
            "\t\treturn 0;",
            "",
            "\tret = __rt_mutex_trylock(&lock->rtmutex);",
            "\tif (ret)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn ret;",
            "}",
            "void __sched rt_mutex_unlock(struct rt_mutex *lock)",
            "{",
            "\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\t__rt_mutex_unlock(&lock->rtmutex);",
            "}",
            "int __sched rt_mutex_futex_trylock(struct rt_mutex_base *lock)",
            "{",
            "\treturn rt_mutex_slowtrylock(lock);",
            "}",
            "int __sched __rt_mutex_futex_trylock(struct rt_mutex_base *lock)",
            "{",
            "\treturn __rt_mutex_slowtrylock(lock);",
            "}",
            "bool __sched __rt_mutex_futex_unlock(struct rt_mutex_base *lock,",
            "\t\t\t\t     struct rt_wake_q_head *wqh)",
            "{",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tdebug_rt_mutex_unlock(lock);",
            "",
            "\tif (!rt_mutex_has_waiters(lock)) {",
            "\t\tlock->owner = NULL;",
            "\t\treturn false; /* done */",
            "\t}",
            "",
            "\t/*",
            "\t * We've already deboosted, mark_wakeup_next_waiter() will",
            "\t * retain preempt_disabled when we drop the wait_lock, to",
            "\t * avoid inversion prior to the wakeup.  preempt_disable()",
            "\t * therein pairs with rt_mutex_postunlock().",
            "\t */",
            "\tmark_wakeup_next_waiter(wqh, lock);",
            "",
            "\treturn true; /* call postunlock() */",
            "}",
            "void __sched rt_mutex_futex_unlock(struct rt_mutex_base *lock)",
            "{",
            "\tDEFINE_RT_WAKE_Q(wqh);",
            "\tunsigned long flags;",
            "\tbool postunlock;",
            "",
            "\traw_spin_lock_irqsave(&lock->wait_lock, flags);",
            "\tpostunlock = __rt_mutex_futex_unlock(lock, &wqh);",
            "\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);",
            "",
            "\tif (postunlock)",
            "\t\trt_mutex_postunlock(&wqh);",
            "}",
            "void __sched __rt_mutex_init(struct rt_mutex *lock, const char *name,",
            "\t\t\t     struct lock_class_key *key)",
            "{",
            "\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));",
            "\t__rt_mutex_base_init(&lock->rtmutex);",
            "\tlockdep_init_map_wait(&lock->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "}"
          ],
          "function_name": "__rt_mutex_lock_common, rt_mutex_base_init, rt_mutex_lock_nested, _rt_mutex_lock_nest_lock, rt_mutex_lock, rt_mutex_lock_interruptible, rt_mutex_lock_killable, rt_mutex_trylock, rt_mutex_unlock, rt_mutex_futex_trylock, __rt_mutex_futex_trylock, __rt_mutex_futex_unlock, rt_mutex_futex_unlock, __rt_mutex_init",
          "description": "实现多种rtmutex操作接口，包括常规加锁、尝试加锁、解锁及嵌套锁管理，通过统一入口函数处理不同睡眠状态和锁依赖追踪，维护锁状态转换和抢占控制。",
          "similarity": 0.5063779354095459
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 1,
          "end_line": 21,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * rtmutex API",
            " */",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "",
            "#define RT_MUTEX_BUILD_MUTEX",
            "#include \"rtmutex.c\"",
            "",
            "/*",
            " * Max number of times we'll walk the boosting chain:",
            " */",
            "int max_lock_depth = 1024;",
            "",
            "/*",
            " * Debug aware fast / slowpath lock,trylock,unlock",
            " *",
            " * The atomic acquire/release ops are compiled away, when either the",
            " * architecture does not support cmpxchg or when debugging is enabled.",
            " */"
          ],
          "function_name": null,
          "description": "定义实时互斥锁（rtmutex）的核心参数和调试相关配置，通过宏引入rtmutex实现文件，并设置最大锁深度限制，启用原子操作优化和调试支持。",
          "similarity": 0.4770815372467041
        }
      ]
    }
  ]
}