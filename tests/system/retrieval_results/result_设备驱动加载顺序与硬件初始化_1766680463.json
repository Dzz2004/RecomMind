{
  "query": "设备驱动加载顺序与硬件初始化",
  "timestamp": "2025-12-26 00:34:23",
  "retrieved_files": [
    {
      "source_file": "mm/memblock.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:38:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memblock.c`\n\n---\n\n# memblock.c 技术文档\n\n## 1. 文件概述\n\n`memblock.c` 实现了 Linux 内核早期启动阶段的内存管理机制——**memblock**。该机制用于在常规内存分配器（如 buddy allocator）尚未初始化之前，对物理内存进行粗粒度的区域管理。它将系统内存抽象为若干连续的内存区域（regions），支持“可用内存”（memory）、“保留内存”（reserved）和“物理内存”（physmem，部分架构支持）三种类型，为内核早期初始化提供内存添加、查询和分配能力。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct memblock_region`：表示一个连续的物理内存区域，包含基地址（base）、大小（size）、NUMA 节点 ID 和属性标志。\n- `struct memblock_type`：管理一类内存区域的集合，包含区域数组、当前数量（cnt）、最大容量（max）和名称。\n- `struct memblock`：全局 memblock 管理结构，包含 `memory` 和 `reserved` 两种类型的 `memblock_type`，以及分配方向（bottom_up）和当前分配上限（current_limit）。\n- `physmem`（条件编译）：描述不受 `mem=` 参数限制的实际物理内存布局。\n\n### 主要函数与变量\n- `memblock_add()` / `memblock_add_node()`：向 memblock 添加可用内存区域。\n- `memblock_reserve()`：标记内存区域为保留（不可用于动态分配）。\n- `memblock_phys_alloc*()` / `memblock_alloc*()`：分配物理或虚拟地址的内存。\n- `memblock_overlaps_region()`：判断指定区域是否与某类 memblock 区域重叠。\n- `__memblock_find_range_bottom_up()`：从低地址向高地址查找满足条件的空闲内存范围。\n- 全局变量 `memblock`：静态初始化的主 memblock 结构体。\n- `max_low_pfn`, `min_low_pfn`, `max_pfn`, `max_possible_pfn`：记录 PFN（页帧号）边界信息。\n\n### 配置宏\n- `INIT_MEMBLOCK_REGIONS`：初始内存/保留区域数组大小（默认 128）。\n- `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 类型支持。\n- `CONFIG_MEMBLOCK_KHO_SCRATCH`：支持仅从特定标记（KHO_SCRATCH）区域分配内存。\n- `CONFIG_ARCH_KEEP_MEMBLOCK`：决定是否在初始化完成后保留 memblock 数据结构。\n\n## 3. 关键实现\n\n### 初始化与存储\n- `memblock` 结构体在编译时静态初始化，其 `memory` 和 `reserved` 的区域数组分别使用 `memblock_memory_init_regions` 和 `memblock_reserved_init_regions`，初始容量由 `INIT_MEMBLOCK_*_REGIONS` 定义。\n- 每个 `memblock_type` 的 `cnt` 初始设为 1，但实际第一个条目为空的占位符，有效区域从索引 1 开始（后续代码处理）。\n- 支持通过 `memblock_allow_resize()` 动态扩容区域数组，但需谨慎避免与 initrd 等关键区域冲突。\n\n### 内存区域管理\n- 使用 `for_each_memblock_type` 宏遍历指定类型的区域。\n- `memblock_addrs_overlap()` 通过比较区间端点判断两个物理内存区域是否重叠。\n- `memblock_overlaps_region()` 封装了对某类所有区域的重叠检测。\n\n### 分配策略\n- 默认采用 **top-down**（从高地址向低地址）分配策略，可通过 `memblock_set_bottom_up(true)` 切换为 **bottom-up**。\n- 分配时受 `current_limit` 限制（默认 `MEMBLOCK_ALLOC_ANYWHERE` 表示无限制）。\n- 支持基于 NUMA 节点、对齐要求、内存属性（如 `MEMBLOCK_MIRROR`、`MEMBLOCK_KHO_SCRATCH`）的精细控制。\n- `choose_memblock_flags()` 根据 `kho_scratch_only` 和镜像内存存在性动态选择分配标志。\n\n### 安全与调试\n- `memblock_cap_size()` 防止地址计算溢出（确保 `base + size <= PHYS_ADDR_MAX`）。\n- 条件编译的 `memblock_dbg()` 宏用于调试输出（需开启 `memblock_debug`）。\n- 使用 `__initdata_memblock` 属性标记仅在初始化阶段使用的数据，便于后续释放。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memblock.h>`：定义 memblock API 和数据结构。\n  - `<linux/kernel.h>`, `<linux/init.h>`：提供基础内核功能和初始化宏。\n  - `<linux/pfn.h>`：PFN 相关操作。\n  - `<asm/sections.h>`：访问内核链接段信息。\n  - 架构相关头文件（如 `internal.h`）。\n- **配置依赖**：\n  - `CONFIG_NUMA`：影响 `contig_page_data` 的定义。\n  - `CONFIG_KEXEC_HANDOVER`：引入 kexec 相关头文件。\n  - `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 支持。\n- **后续移交**：在 `mem_init()` 中，memblock 管理的内存会被释放给 buddy allocator，完成内存管理权移交。\n\n## 5. 使用场景\n\n- **内核早期初始化**：在 `start_kernel()` 初期，架构代码（如 `setup_arch()`）调用 `memblock_add()` 注册可用物理内存，调用 `memblock_reserve()` 保留内核镜像、设备树、initrd 等关键区域。\n- **早期内存分配**：在 slab/buddy 分配器就绪前，使用 `memblock_alloc()` 分配大块连续内存（如页表、中断向量表、ACPI 表解析缓冲区）。\n- **内存布局查询**：通过 `for_each_memblock()` 等宏遍历内存区域，用于构建 e820 表、EFI 内存映射或 NUMA 拓扑。\n- **特殊分配需求**：支持从镜像内存（`MEMBLOCK_MIRROR`）或 KHO scratch 区域分配，满足安全启动或崩溃转储等场景。\n- **调试与分析**：通过 debugfs 接口（未在片段中体现）导出 memblock 布局，辅助内存问题诊断。",
      "similarity": 0.6034811735153198,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "mm/memblock.c",
          "start_line": 1,
          "end_line": 191,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-or-later",
            "/*",
            " * Procedures for maintaining information about logical memory blocks.",
            " *",
            " * Peter Bergner, IBM Corp.\tJune 2001.",
            " * Copyright (C) 2001 Peter Bergner.",
            " */",
            "",
            "#include <linux/kernel.h>",
            "#include <linux/slab.h>",
            "#include <linux/init.h>",
            "#include <linux/bitops.h>",
            "#include <linux/poison.h>",
            "#include <linux/pfn.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/memblock.h>",
            "#include <linux/mutex.h>",
            "",
            "#ifdef CONFIG_KEXEC_HANDOVER",
            "#include <linux/libfdt.h>",
            "#include <linux/kexec_handover.h>",
            "#endif /* CONFIG_KEXEC_HANDOVER */",
            "",
            "#include <asm/sections.h>",
            "#include <linux/io.h>",
            "",
            "#include \"internal.h\"",
            "",
            "#define INIT_MEMBLOCK_REGIONS\t\t\t128",
            "#define INIT_PHYSMEM_REGIONS\t\t\t4",
            "",
            "#ifndef INIT_MEMBLOCK_RESERVED_REGIONS",
            "# define INIT_MEMBLOCK_RESERVED_REGIONS\t\tINIT_MEMBLOCK_REGIONS",
            "#endif",
            "",
            "#ifndef INIT_MEMBLOCK_MEMORY_REGIONS",
            "#define INIT_MEMBLOCK_MEMORY_REGIONS\t\tINIT_MEMBLOCK_REGIONS",
            "#endif",
            "",
            "/**",
            " * DOC: memblock overview",
            " *",
            " * Memblock is a method of managing memory regions during the early",
            " * boot period when the usual kernel memory allocators are not up and",
            " * running.",
            " *",
            " * Memblock views the system memory as collections of contiguous",
            " * regions. There are several types of these collections:",
            " *",
            " * * ``memory`` - describes the physical memory available to the",
            " *   kernel; this may differ from the actual physical memory installed",
            " *   in the system, for instance when the memory is restricted with",
            " *   ``mem=`` command line parameter",
            " * * ``reserved`` - describes the regions that were allocated",
            " * * ``physmem`` - describes the actual physical memory available during",
            " *   boot regardless of the possible restrictions and memory hot(un)plug;",
            " *   the ``physmem`` type is only available on some architectures.",
            " *",
            " * Each region is represented by struct memblock_region that",
            " * defines the region extents, its attributes and NUMA node id on NUMA",
            " * systems. Every memory type is described by the struct memblock_type",
            " * which contains an array of memory regions along with",
            " * the allocator metadata. The \"memory\" and \"reserved\" types are nicely",
            " * wrapped with struct memblock. This structure is statically",
            " * initialized at build time. The region arrays are initially sized to",
            " * %INIT_MEMBLOCK_MEMORY_REGIONS for \"memory\" and",
            " * %INIT_MEMBLOCK_RESERVED_REGIONS for \"reserved\". The region array",
            " * for \"physmem\" is initially sized to %INIT_PHYSMEM_REGIONS.",
            " * The memblock_allow_resize() enables automatic resizing of the region",
            " * arrays during addition of new regions. This feature should be used",
            " * with care so that memory allocated for the region array will not",
            " * overlap with areas that should be reserved, for example initrd.",
            " *",
            " * The early architecture setup should tell memblock what the physical",
            " * memory layout is by using memblock_add() or memblock_add_node()",
            " * functions. The first function does not assign the region to a NUMA",
            " * node and it is appropriate for UMA systems. Yet, it is possible to",
            " * use it on NUMA systems as well and assign the region to a NUMA node",
            " * later in the setup process using memblock_set_node(). The",
            " * memblock_add_node() performs such an assignment directly.",
            " *",
            " * Once memblock is setup the memory can be allocated using one of the",
            " * API variants:",
            " *",
            " * * memblock_phys_alloc*() - these functions return the **physical**",
            " *   address of the allocated memory",
            " * * memblock_alloc*() - these functions return the **virtual** address",
            " *   of the allocated memory.",
            " *",
            " * Note, that both API variants use implicit assumptions about allowed",
            " * memory ranges and the fallback methods. Consult the documentation",
            " * of memblock_alloc_internal() and memblock_alloc_range_nid()",
            " * functions for more elaborate description.",
            " *",
            " * As the system boot progresses, the architecture specific mem_init()",
            " * function frees all the memory to the buddy page allocator.",
            " *",
            " * Unless an architecture enables %CONFIG_ARCH_KEEP_MEMBLOCK, the",
            " * memblock data structures (except \"physmem\") will be discarded after the",
            " * system initialization completes.",
            " */",
            "",
            "#ifndef CONFIG_NUMA",
            "struct pglist_data __refdata contig_page_data;",
            "EXPORT_SYMBOL(contig_page_data);",
            "#endif",
            "",
            "unsigned long max_low_pfn;",
            "unsigned long min_low_pfn;",
            "unsigned long max_pfn;",
            "unsigned long long max_possible_pfn;",
            "",
            "#ifdef CONFIG_MEMBLOCK_KHO_SCRATCH",
            "/* When set to true, only allocate from MEMBLOCK_KHO_SCRATCH ranges */",
            "static bool kho_scratch_only;",
            "#else",
            "#define kho_scratch_only false",
            "#endif",
            "",
            "static struct memblock_region memblock_memory_init_regions[INIT_MEMBLOCK_MEMORY_REGIONS] __initdata_memblock;",
            "static struct memblock_region memblock_reserved_init_regions[INIT_MEMBLOCK_RESERVED_REGIONS] __initdata_memblock;",
            "#ifdef CONFIG_HAVE_MEMBLOCK_PHYS_MAP",
            "static struct memblock_region memblock_physmem_init_regions[INIT_PHYSMEM_REGIONS];",
            "#endif",
            "",
            "struct memblock memblock __initdata_memblock = {",
            "\t.memory.regions\t\t= memblock_memory_init_regions,",
            "\t.memory.cnt\t\t= 1,\t/* empty dummy entry */",
            "\t.memory.max\t\t= INIT_MEMBLOCK_MEMORY_REGIONS,",
            "\t.memory.name\t\t= \"memory\",",
            "",
            "\t.reserved.regions\t= memblock_reserved_init_regions,",
            "\t.reserved.cnt\t\t= 1,\t/* empty dummy entry */",
            "\t.reserved.max\t\t= INIT_MEMBLOCK_RESERVED_REGIONS,",
            "\t.reserved.name\t\t= \"reserved\",",
            "",
            "\t.bottom_up\t\t= false,",
            "\t.current_limit\t\t= MEMBLOCK_ALLOC_ANYWHERE,",
            "};",
            "",
            "#ifdef CONFIG_HAVE_MEMBLOCK_PHYS_MAP",
            "struct memblock_type physmem = {",
            "\t.regions\t\t= memblock_physmem_init_regions,",
            "\t.cnt\t\t\t= 1,\t/* empty dummy entry */",
            "\t.max\t\t\t= INIT_PHYSMEM_REGIONS,",
            "\t.name\t\t\t= \"physmem\",",
            "};",
            "#endif",
            "",
            "/*",
            " * keep a pointer to &memblock.memory in the text section to use it in",
            " * __next_mem_range() and its helpers.",
            " *  For architectures that do not keep memblock data after init, this",
            " * pointer will be reset to NULL at memblock_discard()",
            " */",
            "static __refdata struct memblock_type *memblock_memory = &memblock.memory;",
            "",
            "#define for_each_memblock_type(i, memblock_type, rgn)\t\t\t\\",
            "\tfor (i = 0, rgn = &memblock_type->regions[0];\t\t\t\\",
            "\t     i < memblock_type->cnt;\t\t\t\t\t\\",
            "\t     i++, rgn = &memblock_type->regions[i])",
            "",
            "#define memblock_dbg(fmt, ...)\t\t\t\t\t\t\\",
            "\tdo {\t\t\t\t\t\t\t\t\\",
            "\t\tif (memblock_debug)\t\t\t\t\t\\",
            "\t\t\tpr_info(fmt, ##__VA_ARGS__);\t\t\t\\",
            "\t} while (0)",
            "",
            "static int memblock_debug __initdata_memblock;",
            "static bool system_has_some_mirror __initdata_memblock;",
            "static int memblock_can_resize __initdata_memblock;",
            "static int memblock_memory_in_slab __initdata_memblock;",
            "static int memblock_reserved_in_slab __initdata_memblock;",
            "",
            "bool __init_memblock memblock_has_mirror(void)",
            "{",
            "\treturn system_has_some_mirror;",
            "}",
            "",
            "static enum memblock_flags __init_memblock choose_memblock_flags(void)",
            "{",
            "\t/* skip non-scratch memory for kho early boot allocations */",
            "\tif (kho_scratch_only)",
            "\t\treturn MEMBLOCK_KHO_SCRATCH;",
            "",
            "\treturn system_has_some_mirror ? MEMBLOCK_MIRROR : MEMBLOCK_NONE;",
            "}",
            "",
            "/* adjust *@size so that (@base + *@size) doesn't overflow, return new size */"
          ],
          "function_name": null,
          "description": "定义memblock数据结构及初始化内存区域类型（memory/reserved），用于早期系统启动期间管理物理内存分区，支持动态扩容和NUMA节点绑定。",
          "similarity": 0.5742526054382324
        },
        {
          "chunk_id": 13,
          "file_path": "mm/memblock.c",
          "start_line": 2347,
          "end_line": 2482,
          "content": [
            "static void __init reset_node_managed_pages(pg_data_t *pgdat)",
            "{",
            "\tstruct zone *z;",
            "",
            "\tfor (z = pgdat->node_zones; z < pgdat->node_zones + MAX_NR_ZONES; z++)",
            "\t\tatomic_long_set(&z->managed_pages, 0);",
            "}",
            "void __init reset_all_zones_managed_pages(void)",
            "{",
            "\tstruct pglist_data *pgdat;",
            "",
            "\tif (reset_managed_pages_done)",
            "\t\treturn;",
            "",
            "\tfor_each_online_pgdat(pgdat)",
            "\t\treset_node_managed_pages(pgdat);",
            "",
            "\treset_managed_pages_done = 1;",
            "}",
            "void __init memblock_free_all(void)",
            "{",
            "\tunsigned long pages;",
            "",
            "\tfree_unused_memmap();",
            "\treset_all_zones_managed_pages();",
            "",
            "\tmemblock_clear_kho_scratch_only();",
            "\tpages = free_low_memory_core_early();",
            "\ttotalram_pages_add(pages);",
            "}",
            "static void __init reserved_mem_add(phys_addr_t start, phys_addr_t size,",
            "\t\t\t\t   const char *name)",
            "{",
            "\tstruct reserve_mem_table *map;",
            "",
            "\tmap = &reserved_mem_table[reserved_mem_count++];",
            "\tmap->start = start;",
            "\tmap->size = size;",
            "\tstrscpy(map->name, name);",
            "}",
            "int reserve_mem_find_by_name(const char *name, phys_addr_t *start, phys_addr_t *size)",
            "{",
            "\tstruct reserve_mem_table *map;",
            "",
            "\tguard(mutex)(&reserve_mem_lock);",
            "\tmap = reserve_mem_find_by_name_nolock(name);",
            "\tif (!map)",
            "\t\treturn 0;",
            "",
            "\t*start = map->start;",
            "\t*size = map->size;",
            "\treturn 1;",
            "}",
            "int reserve_mem_release_by_name(const char *name)",
            "{",
            "\tchar buf[RESERVE_MEM_NAME_SIZE + 12];",
            "\tstruct reserve_mem_table *map;",
            "\tvoid *start, *end;",
            "",
            "\tguard(mutex)(&reserve_mem_lock);",
            "\tmap = reserve_mem_find_by_name_nolock(name);",
            "\tif (!map)",
            "\t\treturn 0;",
            "",
            "\tstart = phys_to_virt(map->start);",
            "\tend = start + map->size - 1;",
            "\tsnprintf(buf, sizeof(buf), \"reserve_mem:%s\", name);",
            "\tfree_reserved_area(start, end, 0, buf);",
            "\tmap->size = 0;",
            "",
            "\treturn 1;",
            "}",
            "static int reserve_mem_kho_finalize(struct kho_serialization *ser)",
            "{",
            "\tint err = 0, i;",
            "",
            "\tfor (i = 0; i < reserved_mem_count; i++) {",
            "\t\tstruct reserve_mem_table *map = &reserved_mem_table[i];",
            "",
            "\t\terr |= kho_preserve_phys(map->start, map->size);",
            "\t}",
            "",
            "\terr |= kho_preserve_folio(page_folio(kho_fdt));",
            "\terr |= kho_add_subtree(ser, MEMBLOCK_KHO_FDT, page_to_virt(kho_fdt));",
            "",
            "\treturn notifier_from_errno(err);",
            "}",
            "static int reserve_mem_kho_notifier(struct notifier_block *self,",
            "\t\t\t\t    unsigned long cmd, void *v)",
            "{",
            "\tswitch (cmd) {",
            "\tcase KEXEC_KHO_FINALIZE:",
            "\t\treturn reserve_mem_kho_finalize((struct kho_serialization *)v);",
            "\tcase KEXEC_KHO_ABORT:",
            "\t\treturn NOTIFY_DONE;",
            "\tdefault:",
            "\t\treturn NOTIFY_BAD;",
            "\t}",
            "}",
            "static int __init prepare_kho_fdt(void)",
            "{",
            "\tint err = 0, i;",
            "\tvoid *fdt;",
            "",
            "\tkho_fdt = alloc_page(GFP_KERNEL);",
            "\tif (!kho_fdt)",
            "\t\treturn -ENOMEM;",
            "",
            "\tfdt = page_to_virt(kho_fdt);",
            "",
            "\terr |= fdt_create(fdt, PAGE_SIZE);",
            "\terr |= fdt_finish_reservemap(fdt);",
            "",
            "\terr |= fdt_begin_node(fdt, \"\");",
            "\terr |= fdt_property_string(fdt, \"compatible\", MEMBLOCK_KHO_NODE_COMPATIBLE);",
            "\tfor (i = 0; i < reserved_mem_count; i++) {",
            "\t\tstruct reserve_mem_table *map = &reserved_mem_table[i];",
            "",
            "\t\terr |= fdt_begin_node(fdt, map->name);",
            "\t\terr |= fdt_property_string(fdt, \"compatible\", RESERVE_MEM_KHO_NODE_COMPATIBLE);",
            "\t\terr |= fdt_property(fdt, \"start\", &map->start, sizeof(map->start));",
            "\t\terr |= fdt_property(fdt, \"size\", &map->size, sizeof(map->size));",
            "\t\terr |= fdt_end_node(fdt);",
            "\t}",
            "\terr |= fdt_end_node(fdt);",
            "",
            "\terr |= fdt_finish(fdt);",
            "",
            "\tif (err) {",
            "\t\tpr_err(\"failed to prepare memblock FDT for KHO: %d\\n\", err);",
            "\t\tput_page(kho_fdt);",
            "\t\tkho_fdt = NULL;",
            "\t}",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "reset_node_managed_pages, reset_all_zones_managed_pages, memblock_free_all, reserved_mem_add, reserve_mem_find_by_name, reserve_mem_release_by_name, reserve_mem_kho_finalize, reserve_mem_kho_notifier, prepare_kho_fdt",
          "description": "管理节点页面计数重置、全局内存释放流程，实现预留内存注册与KHO机制的设备树准备及回调处理",
          "similarity": 0.5621346235275269
        },
        {
          "chunk_id": 11,
          "file_path": "mm/memblock.c",
          "start_line": 2094,
          "end_line": 2203,
          "content": [
            "static void __init_memblock memblock_dump(struct memblock_type *type)",
            "{",
            "\tphys_addr_t base, end, size;",
            "\tenum memblock_flags flags;",
            "\tint idx;",
            "\tstruct memblock_region *rgn;",
            "",
            "\tpr_info(\" %s.cnt  = 0x%lx\\n\", type->name, type->cnt);",
            "",
            "\tfor_each_memblock_type(idx, type, rgn) {",
            "\t\tchar nid_buf[32] = \"\";",
            "",
            "\t\tbase = rgn->base;",
            "\t\tsize = rgn->size;",
            "\t\tend = base + size - 1;",
            "\t\tflags = rgn->flags;",
            "#ifdef CONFIG_NUMA",
            "\t\tif (numa_valid_node(memblock_get_region_node(rgn)))",
            "\t\t\tsnprintf(nid_buf, sizeof(nid_buf), \" on node %d\",",
            "\t\t\t\t memblock_get_region_node(rgn));",
            "#endif",
            "\t\tpr_info(\" %s[%#x]\\t[%pa-%pa], %pa bytes%s flags: %#x\\n\",",
            "\t\t\ttype->name, idx, &base, &end, &size, nid_buf, flags);",
            "\t}",
            "}",
            "void __init memblock_allow_resize(void)",
            "{",
            "\tmemblock_can_resize = 1;",
            "}",
            "static int __init early_memblock(char *p)",
            "{",
            "\tif (p && strstr(p, \"debug\"))",
            "\t\tmemblock_debug = 1;",
            "\treturn 0;",
            "}",
            "static void __init free_memmap(unsigned long start_pfn, unsigned long end_pfn)",
            "{",
            "\tstruct page *start_pg, *end_pg;",
            "\tphys_addr_t pg, pgend;",
            "",
            "\t/*",
            "\t * Convert start_pfn/end_pfn to a struct page pointer.",
            "\t */",
            "\tstart_pg = pfn_to_page(start_pfn - 1) + 1;",
            "\tend_pg = pfn_to_page(end_pfn - 1) + 1;",
            "",
            "\t/*",
            "\t * Convert to physical addresses, and round start upwards and end",
            "\t * downwards.",
            "\t */",
            "\tpg = PAGE_ALIGN(__pa(start_pg));",
            "\tpgend = __pa(end_pg) & PAGE_MASK;",
            "",
            "\t/*",
            "\t * If there are free pages between these, free the section of the",
            "\t * memmap array.",
            "\t */",
            "\tif (pg < pgend)",
            "\t\tmemblock_phys_free(pg, pgend - pg);",
            "}",
            "static void __init free_unused_memmap(void)",
            "{",
            "\tunsigned long start, end, prev_end = 0;",
            "\tint i;",
            "",
            "\tif (!IS_ENABLED(CONFIG_HAVE_ARCH_PFN_VALID) ||",
            "\t    IS_ENABLED(CONFIG_SPARSEMEM_VMEMMAP))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * This relies on each bank being in address order.",
            "\t * The banks are sorted previously in bootmem_init().",
            "\t */",
            "\tfor_each_mem_pfn_range(i, MAX_NUMNODES, &start, &end, NULL) {",
            "#ifdef CONFIG_SPARSEMEM",
            "\t\t/*",
            "\t\t * Take care not to free memmap entries that don't exist",
            "\t\t * due to SPARSEMEM sections which aren't present.",
            "\t\t */",
            "\t\tstart = min(start, ALIGN(prev_end, PAGES_PER_SECTION));",
            "#endif",
            "\t\t/*",
            "\t\t * Align down here since many operations in VM subsystem",
            "\t\t * presume that there are no holes in the memory map inside",
            "\t\t * a pageblock",
            "\t\t */",
            "\t\tstart = pageblock_start_pfn(start);",
            "",
            "\t\t/*",
            "\t\t * If we had a previous bank, and there is a space",
            "\t\t * between the current bank and the previous, free it.",
            "\t\t */",
            "\t\tif (prev_end && prev_end < start)",
            "\t\t\tfree_memmap(prev_end, start);",
            "",
            "\t\t/*",
            "\t\t * Align up here since many operations in VM subsystem",
            "\t\t * presume that there are no holes in the memory map inside",
            "\t\t * a pageblock",
            "\t\t */",
            "\t\tprev_end = pageblock_align(end);",
            "\t}",
            "",
            "#ifdef CONFIG_SPARSEMEM",
            "\tif (!IS_ALIGNED(prev_end, PAGES_PER_SECTION)) {",
            "\t\tprev_end = pageblock_align(end);",
            "\t\tfree_memmap(prev_end, ALIGN(prev_end, PAGES_PER_SECTION));",
            "\t}",
            "#endif",
            "}"
          ],
          "function_name": "memblock_dump, memblock_allow_resize, early_memblock, free_memmap, free_unused_memmap",
          "description": "提供内存块状态调试、调整支持、早期内存处理及未使用memmap释放功能，用于优化内存映射管理",
          "similarity": 0.550460934638977
        },
        {
          "chunk_id": 12,
          "file_path": "mm/memblock.c",
          "start_line": 2233,
          "end_line": 2340,
          "content": [
            "static void __init __free_pages_memory(unsigned long start, unsigned long end)",
            "{",
            "\tint order;",
            "",
            "\twhile (start < end) {",
            "\t\t/*",
            "\t\t * Free the pages in the largest chunks alignment allows.",
            "\t\t *",
            "\t\t * __ffs() behaviour is undefined for 0. start == 0 is",
            "\t\t * MAX_PAGE_ORDER-aligned, set order to MAX_PAGE_ORDER for",
            "\t\t * the case.",
            "\t\t */",
            "\t\tif (start)",
            "\t\t\torder = min_t(int, MAX_PAGE_ORDER, __ffs(start));",
            "\t\telse",
            "\t\t\torder = MAX_PAGE_ORDER;",
            "",
            "\t\twhile (start + (1UL << order) > end)",
            "\t\t\torder--;",
            "",
            "\t\tmemblock_free_pages(pfn_to_page(start), start, order);",
            "",
            "\t\tstart += (1UL << order);",
            "\t}",
            "}",
            "static unsigned long __init __free_memory_core(phys_addr_t start,",
            "\t\t\t\t phys_addr_t end)",
            "{",
            "\tunsigned long start_pfn = PFN_UP(start);",
            "\tunsigned long end_pfn = min_t(unsigned long,",
            "\t\t\t\t      PFN_DOWN(end), max_low_pfn);",
            "",
            "\tif (start_pfn >= end_pfn)",
            "\t\treturn 0;",
            "",
            "\t__free_pages_memory(start_pfn, end_pfn);",
            "",
            "\treturn end_pfn - start_pfn;",
            "}",
            "static void __init memmap_init_reserved_pages(void)",
            "{",
            "\tstruct memblock_region *region;",
            "\tphys_addr_t start, end;",
            "\tint nid;",
            "\tunsigned long max_reserved;",
            "",
            "\t/*",
            "\t * set nid on all reserved pages and also treat struct",
            "\t * pages for the NOMAP regions as PageReserved",
            "\t */",
            "repeat:",
            "\tmax_reserved = memblock.reserved.max;",
            "\tfor_each_mem_region(region) {",
            "\t\tnid = memblock_get_region_node(region);",
            "\t\tstart = region->base;",
            "\t\tend = start + region->size;",
            "",
            "\t\tif (memblock_is_nomap(region))",
            "\t\t\treserve_bootmem_region(start, end, nid);",
            "",
            "\t\tmemblock_set_node(start, region->size, &memblock.reserved, nid);",
            "\t}",
            "\t/*",
            "\t * 'max' is changed means memblock.reserved has been doubled its",
            "\t * array, which may result a new reserved region before current",
            "\t * 'start'. Now we should repeat the procedure to set its node id.",
            "\t */",
            "\tif (max_reserved != memblock.reserved.max)",
            "\t\tgoto repeat;",
            "",
            "\t/*",
            "\t * initialize struct pages for reserved regions that don't have",
            "\t * the MEMBLOCK_RSRV_NOINIT flag set",
            "\t */",
            "\tfor_each_reserved_mem_region(region) {",
            "\t\tif (!memblock_is_reserved_noinit(region)) {",
            "\t\t\tnid = memblock_get_region_node(region);",
            "\t\t\tstart = region->base;",
            "\t\t\tend = start + region->size;",
            "",
            "\t\t\tif (!numa_valid_node(nid))",
            "\t\t\t\tnid = early_pfn_to_nid(PFN_DOWN(start));",
            "",
            "\t\t\treserve_bootmem_region(start, end, nid);",
            "\t\t}",
            "\t}",
            "}",
            "static unsigned long __init free_low_memory_core_early(void)",
            "{",
            "\tunsigned long count = 0;",
            "\tphys_addr_t start, end;",
            "\tu64 i;",
            "",
            "\tmemblock_clear_hotplug(0, -1);",
            "",
            "\tmemmap_init_reserved_pages();",
            "",
            "\t/*",
            "\t * We need to use NUMA_NO_NODE instead of NODE_DATA(0)->node_id",
            "\t *  because in some case like Node0 doesn't have RAM installed",
            "\t *  low ram will be on Node1",
            "\t */",
            "\tfor_each_free_mem_range(i, NUMA_NO_NODE, MEMBLOCK_NONE, &start, &end,",
            "\t\t\t\tNULL)",
            "\t\tcount += __free_memory_core(start, end);",
            "",
            "\treturn count;",
            "}"
          ],
          "function_name": "__free_pages_memory, __free_memory_core, memmap_init_reserved_pages, free_low_memory_core_early",
          "description": "核心实现内存页面释放逻辑，初始化保留区域页结构并处理低内存核心区域的提前释放操作",
          "similarity": 0.5462050437927246
        },
        {
          "chunk_id": 3,
          "file_path": "mm/memblock.c",
          "start_line": 537,
          "end_line": 685,
          "content": [
            "static void __init_memblock memblock_merge_regions(struct memblock_type *type,",
            "\t\t\t\t\t\t   unsigned long start_rgn,",
            "\t\t\t\t\t\t   unsigned long end_rgn)",
            "{",
            "\tint i = 0;",
            "\tif (start_rgn)",
            "\t\ti = start_rgn - 1;",
            "\tend_rgn = min(end_rgn, type->cnt - 1);",
            "\twhile (i < end_rgn) {",
            "\t\tstruct memblock_region *this = &type->regions[i];",
            "\t\tstruct memblock_region *next = &type->regions[i + 1];",
            "",
            "\t\tif (this->base + this->size != next->base ||",
            "\t\t    memblock_get_region_node(this) !=",
            "\t\t    memblock_get_region_node(next) ||",
            "\t\t    this->flags != next->flags) {",
            "\t\t\tBUG_ON(this->base + this->size > next->base);",
            "\t\t\ti++;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tthis->size += next->size;",
            "\t\t/* move forward from next + 1, index of which is i + 2 */",
            "\t\tmemmove(next, next + 1, (type->cnt - (i + 2)) * sizeof(*next));",
            "\t\ttype->cnt--;",
            "\t\tend_rgn--;",
            "\t}",
            "}",
            "static void __init_memblock memblock_insert_region(struct memblock_type *type,",
            "\t\t\t\t\t\t   int idx, phys_addr_t base,",
            "\t\t\t\t\t\t   phys_addr_t size,",
            "\t\t\t\t\t\t   int nid,",
            "\t\t\t\t\t\t   enum memblock_flags flags)",
            "{",
            "\tstruct memblock_region *rgn = &type->regions[idx];",
            "",
            "\tBUG_ON(type->cnt >= type->max);",
            "\tmemmove(rgn + 1, rgn, (type->cnt - idx) * sizeof(*rgn));",
            "\trgn->base = base;",
            "\trgn->size = size;",
            "\trgn->flags = flags;",
            "\tmemblock_set_region_node(rgn, nid);",
            "\ttype->cnt++;",
            "\ttype->total_size += size;",
            "}",
            "static int __init_memblock memblock_add_range(struct memblock_type *type,",
            "\t\t\t\tphys_addr_t base, phys_addr_t size,",
            "\t\t\t\tint nid, enum memblock_flags flags)",
            "{",
            "\tbool insert = false;",
            "\tphys_addr_t obase = base;",
            "\tphys_addr_t end = base + memblock_cap_size(base, &size);",
            "\tint idx, nr_new, start_rgn = -1, end_rgn;",
            "\tstruct memblock_region *rgn;",
            "",
            "\tif (!size)",
            "\t\treturn 0;",
            "",
            "\t/* special case for empty array */",
            "\tif (type->regions[0].size == 0) {",
            "\t\tWARN_ON(type->cnt != 1 || type->total_size);",
            "\t\ttype->regions[0].base = base;",
            "\t\ttype->regions[0].size = size;",
            "\t\ttype->regions[0].flags = flags;",
            "\t\tmemblock_set_region_node(&type->regions[0], nid);",
            "\t\ttype->total_size = size;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * The worst case is when new range overlaps all existing regions,",
            "\t * then we'll need type->cnt + 1 empty regions in @type. So if",
            "\t * type->cnt * 2 + 1 is less than or equal to type->max, we know",
            "\t * that there is enough empty regions in @type, and we can insert",
            "\t * regions directly.",
            "\t */",
            "\tif (type->cnt * 2 + 1 <= type->max)",
            "\t\tinsert = true;",
            "",
            "repeat:",
            "\t/*",
            "\t * The following is executed twice.  Once with %false @insert and",
            "\t * then with %true.  The first counts the number of regions needed",
            "\t * to accommodate the new area.  The second actually inserts them.",
            "\t */",
            "\tbase = obase;",
            "\tnr_new = 0;",
            "",
            "\tfor_each_memblock_type(idx, type, rgn) {",
            "\t\tphys_addr_t rbase = rgn->base;",
            "\t\tphys_addr_t rend = rbase + rgn->size;",
            "",
            "\t\tif (rbase >= end)",
            "\t\t\tbreak;",
            "\t\tif (rend <= base)",
            "\t\t\tcontinue;",
            "\t\t/*",
            "\t\t * @rgn overlaps.  If it separates the lower part of new",
            "\t\t * area, insert that portion.",
            "\t\t */",
            "\t\tif (rbase > base) {",
            "#ifdef CONFIG_NUMA",
            "\t\t\tWARN_ON(nid != memblock_get_region_node(rgn));",
            "#endif",
            "\t\t\tWARN_ON(flags != MEMBLOCK_NONE && flags != rgn->flags);",
            "\t\t\tnr_new++;",
            "\t\t\tif (insert) {",
            "\t\t\t\tif (start_rgn == -1)",
            "\t\t\t\t\tstart_rgn = idx;",
            "\t\t\t\tend_rgn = idx + 1;",
            "\t\t\t\tmemblock_insert_region(type, idx++, base,",
            "\t\t\t\t\t\t       rbase - base, nid,",
            "\t\t\t\t\t\t       flags);",
            "\t\t\t}",
            "\t\t}",
            "\t\t/* area below @rend is dealt with, forget about it */",
            "\t\tbase = min(rend, end);",
            "\t}",
            "",
            "\t/* insert the remaining portion */",
            "\tif (base < end) {",
            "\t\tnr_new++;",
            "\t\tif (insert) {",
            "\t\t\tif (start_rgn == -1)",
            "\t\t\t\tstart_rgn = idx;",
            "\t\t\tend_rgn = idx + 1;",
            "\t\t\tmemblock_insert_region(type, idx, base, end - base,",
            "\t\t\t\t\t       nid, flags);",
            "\t\t}",
            "\t}",
            "",
            "\tif (!nr_new)",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * If this was the first round, resize array and repeat for actual",
            "\t * insertions; otherwise, merge and return.",
            "\t */",
            "\tif (!insert) {",
            "\t\twhile (type->cnt + nr_new > type->max)",
            "\t\t\tif (memblock_double_array(type, obase, size) < 0)",
            "\t\t\t\treturn -ENOMEM;",
            "\t\tinsert = true;",
            "\t\tgoto repeat;",
            "\t} else {",
            "\t\tmemblock_merge_regions(type, start_rgn, end_rgn);",
            "\t\treturn 0;",
            "\t}",
            "}"
          ],
          "function_name": "memblock_merge_regions, memblock_insert_region, memblock_add_range",
          "description": "实现内存区域合并（merge_regions）与插入（insert_region）逻辑，处理新增内存范围的拆分与整合，优化连续区域管理。",
          "similarity": 0.543818473815918
        }
      ]
    },
    {
      "source_file": "mm/mm_init.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:50:02\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `mm_init.c`\n\n---\n\n# mm_init.c 技术文档\n\n## 1. 文件概述\n\n`mm_init.c` 是 Linux 内核内存管理子系统（Memory Management, MM）中的一个初始化和调试辅助文件。其主要作用包括：\n\n- 提供内存初始化过程的验证与调试功能（在 `CONFIG_DEBUG_MEMORY_INIT` 启用时）\n- 初始化内存相关的全局参数和 sysfs 接口\n- 解析内核启动命令行参数（如 `kernelcore` 和 `movablecore`），用于控制不可移动与可移动内存区域的分配策略\n- 在 SMP 系统中动态计算 `vm_committed_as` 的批处理阈值，以优化内存提交统计的性能\n\n该文件不直接参与页分配或虚拟内存管理的核心逻辑，而是为内存子系统的正确性验证、配置和可观测性提供支持。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数名 | 功能描述 |\n|--------|--------|\n| `mminit_verify_zonelist()` | 验证并打印每个 NUMA 节点的 zonelist 结构，用于调试内存区域组织 |\n| `mminit_verify_pageflags_layout()` | 验证 `struct page` 中用于存储节点、区域、节区等元数据的位域布局是否无重叠且对齐正确 |\n| `set_mminit_loglevel()` | 解析 `mminit_loglevel` 内核参数，设置内存初始化调试日志级别 |\n| `mm_compute_batch()` | 根据系统内存总量和 CPU 数量，计算 `vm_committed_as` per-CPU 计数器的批处理阈值 |\n| `mm_compute_batch_notifier()` | 内存热插拔事件回调，重新计算 `vm_committed_as` 批处理值 |\n| `mm_sysfs_init()` | 创建 `/sys/kernel/mm` sysfs 目录，用于暴露内存子系统信息 |\n| `cmdline_parse_core()` | 辅助函数，解析带百分比或字节单位的内存大小参数 |\n| `cmdline_parse_kernelcore()` / `cmdline_parse_movablecore()` | 解析 `kernelcore=` 和 `movablecore=` 内核启动参数 |\n\n### 主要全局变量\n\n| 变量名 | 类型/说明 |\n|--------|---------|\n| `mminit_loglevel` | 调试日志级别（仅当 `CONFIG_DEBUG_MEMORY_INIT` 启用） |\n| `mm_kobj` | 指向 `/sys/kernel/mm` 的 kobject 指针 |\n| `vm_committed_as_batch` | `vm_committed_as` per-CPU 计数器的批处理阈值（SMP） |\n| `required_kernelcore` / `required_kernelcore_percent` | 用户指定的不可移动内存需求（页数或百分比） |\n| `required_movablecore` / `required_movablecore_percent` | 用户指定的可移动内存需求（页数或百分比） |\n| `mirrored_kernelcore` | 是否启用镜像式 kernelcore 布局 |\n| `arch_zone_lowest_possible_pfn[]` / `arch_zone_highest_possible_pfn[]` | 架构定义的各内存区域（ZONE）的 PFN 范围 |\n| `zone_movable_pfn[]` | 各 NUMA 节点上 ZONE_MOVABLE 的起始 PFN |\n| `deferred_struct_pages` | 标记是否延迟初始化 struct page 实例 |\n\n## 3. 关键实现\n\n### 3.1 内存初始化调试（`CONFIG_DEBUG_MEMORY_INIT`）\n\n- **Zonelist 验证**：`mminit_verify_zonelist()` 遍历所有在线 NUMA 节点，打印其“通用”（general）和“本节点优先”（thisnode）两种 zonelist 的组成，帮助开发者确认内存区域的 fallback 顺序是否符合预期。\n- **Page Flags 布局验证**：`mminit_verify_pageflags_layout()` 检查 `struct page` 中用于编码物理位置（section/node/zone）的位域是否：\n  - 总宽度不超过 `BITS_PER_LONG`\n  - 各字段偏移（`_PGSHIFT`）与宽度一致\n  - 位掩码无重叠（通过 `or_mask == add_mask` 验证）\n\n### 3.2 内存区域划分策略\n\n- 通过 `kernelcore=` 和 `movablecore=` 参数，用户可显式指定系统中用于**不可移动分配**（如内核数据结构）和**可移动分配**（如用户页、可迁移 slab）的内存大小。\n- 支持 `kernelcore=mirror` 模式，在支持内存镜像的平台上启用特殊布局。\n- 参数值可为绝对字节数（如 `512M`）或总内存百分比（如 `40%`）。\n\n### 3.3 `vm_committed_as` 批处理优化（SMP）\n\n- `vm_committed_as` 是一个 per-CPU 计数器，跟踪已提交虚拟内存总量。\n- 为减少原子操作开销，当本地计数器变化超过 `vm_committed_as_batch` 时才同步到全局值。\n- `mm_compute_batch()` 根据 overcommit 策略动态调整 batch 大小：\n  - `OVERCOMMIT_NEVER`：batch = 总内存 / CPU数 / 256（约 0.4%）\n  - 其他策略：batch = 总内存 / CPU数 / 4（25%）\n- 注册内存热插拔通知器，确保内存容量变化后重新计算 batch 值。\n\n### 3.4 Sysfs 接口初始化\n\n- `mm_sysfs_init()` 在内核早期创建 `/sys/kernel/mm` 目录，作为内存子系统其他模块（如 compaction、numa、transparent_hugepage 等）注册 sysfs 属性的基础。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memory.h>`、`<linux/memblock.h>`：内存块和热插拔管理\n  - `<linux/page-isolation.h>`、`<linux/cma.h>`：连续内存分配和页面隔离\n  - `\"internal.h\"`、`\"slab.h\"`：MM 子系统内部接口\n  - `<asm/setup.h>`：架构相关内存布局信息\n- **配置依赖**：\n  - `CONFIG_DEBUG_MEMORY_INIT`：启用调试验证功能\n  - `CONFIG_SMP`：启用 `vm_committed_as_batch` 优化\n  - `CONFIG_SYSFS`：支持 mm sysfs 目录创建\n- **被依赖模块**：\n  - 内存初始化流程（`mm_init()` in `init/main.c`）\n  - 页面分配器（`page_alloc.c`）使用 `zone_movable_pfn` 等变量\n  - 内存热插拔子系统调用 batch 重计算回调\n\n## 5. 使用场景\n\n- **内核开发与调试**：开发者启用 `CONFIG_DEBUG_MEMORY_INIT` 并设置 `mminit_loglevel`，可在启动时验证内存拓扑结构和 page 结构体布局的正确性。\n- **系统部署调优**：管理员通过 `kernelcore=` 或 `movablecore=` 参数，强制划分不可移动/可移动内存区域，以优化透明大页（THP）或避免内存碎片。\n- **高可靠性系统**：使用 `kernelcore=mirror` 在支持的硬件上启用内存镜像，提升容错能力。\n- **大规模 SMP 系统**：自动调整 `vm_committed_as_batch` 减少锁竞争，提升多进程内存密集型应用的性能。\n- **运行时监控**：`/sys/kernel/mm` 为用户空间工具（如 `numastat`、`cma` 调试接口）提供统一入口点。",
      "similarity": 0.5981211066246033,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "mm/mm_init.c",
          "start_line": 566,
          "end_line": 671,
          "content": [
            "void __meminit __init_single_page(struct page *page, unsigned long pfn,",
            "\t\t\t\tunsigned long zone, int nid)",
            "{",
            "\tmm_zero_struct_page(page);",
            "\tset_page_links(page, zone, nid, pfn);",
            "\tinit_page_count(page);",
            "\tpage_mapcount_reset(page);",
            "\tpage_cpupid_reset_last(page);",
            "\tpage_kasan_tag_reset(page);",
            "",
            "\tINIT_LIST_HEAD(&page->lru);",
            "#ifdef WANT_PAGE_VIRTUAL",
            "\t/* The shift won't overflow because ZONE_NORMAL is below 4G. */",
            "\tif (!is_highmem_idx(zone))",
            "\t\tset_page_address(page, __va(pfn << PAGE_SHIFT));",
            "#endif",
            "}",
            "static int __meminit __early_pfn_to_nid(unsigned long pfn,",
            "\t\t\t\t\tstruct mminit_pfnnid_cache *state)",
            "{",
            "\tunsigned long start_pfn, end_pfn;",
            "\tint nid;",
            "",
            "\tif (state->last_start <= pfn && pfn < state->last_end)",
            "\t\treturn state->last_nid;",
            "",
            "\tnid = memblock_search_pfn_nid(pfn, &start_pfn, &end_pfn);",
            "\tif (nid != NUMA_NO_NODE) {",
            "\t\tstate->last_start = start_pfn;",
            "\t\tstate->last_end = end_pfn;",
            "\t\tstate->last_nid = nid;",
            "\t}",
            "",
            "\treturn nid;",
            "}",
            "int __meminit early_pfn_to_nid(unsigned long pfn)",
            "{",
            "\tstatic DEFINE_SPINLOCK(early_pfn_lock);",
            "\tint nid;",
            "",
            "\tspin_lock(&early_pfn_lock);",
            "\tnid = __early_pfn_to_nid(pfn, &early_pfnnid_cache);",
            "\tif (nid < 0)",
            "\t\tnid = first_online_node;",
            "\tspin_unlock(&early_pfn_lock);",
            "",
            "\treturn nid;",
            "}",
            "static int __init set_hashdist(char *str)",
            "{",
            "\tif (!str)",
            "\t\treturn 0;",
            "\thashdist = simple_strtoul(str, &str, 0);",
            "\treturn 1;",
            "}",
            "static inline void fixup_hashdist(void)",
            "{",
            "\tif (num_node_state(N_MEMORY) == 1)",
            "\t\thashdist = 0;",
            "}",
            "static inline void fixup_hashdist(void) {}",
            "static inline void pgdat_set_deferred_range(pg_data_t *pgdat)",
            "{",
            "\tpgdat->first_deferred_pfn = ULONG_MAX;",
            "}",
            "static inline bool __meminit early_page_initialised(unsigned long pfn, int nid)",
            "{",
            "\tif (node_online(nid) && pfn >= NODE_DATA(nid)->first_deferred_pfn)",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}",
            "static bool __meminit",
            "defer_init(int nid, unsigned long pfn, unsigned long end_pfn)",
            "{",
            "\tstatic unsigned long prev_end_pfn, nr_initialised;",
            "",
            "\tif (early_page_ext_enabled())",
            "\t\treturn false;",
            "\t/*",
            "\t * prev_end_pfn static that contains the end of previous zone",
            "\t * No need to protect because called very early in boot before smp_init.",
            "\t */",
            "\tif (prev_end_pfn != end_pfn) {",
            "\t\tprev_end_pfn = end_pfn;",
            "\t\tnr_initialised = 0;",
            "\t}",
            "",
            "\t/* Always populate low zones for address-constrained allocations */",
            "\tif (end_pfn < pgdat_end_pfn(NODE_DATA(nid)))",
            "\t\treturn false;",
            "",
            "\tif (NODE_DATA(nid)->first_deferred_pfn != ULONG_MAX)",
            "\t\treturn true;",
            "\t/*",
            "\t * We start only with one section of pages, more pages are added as",
            "\t * needed until the rest of deferred pages are initialized.",
            "\t */",
            "\tnr_initialised++;",
            "\tif ((nr_initialised > PAGES_PER_SECTION) &&",
            "\t    (pfn & (PAGES_PER_SECTION - 1)) == 0) {",
            "\t\tNODE_DATA(nid)->first_deferred_pfn = pfn;",
            "\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}"
          ],
          "function_name": "__init_single_page, __early_pfn_to_nid, early_pfn_to_nid, set_hashdist, fixup_hashdist, fixup_hashdist, pgdat_set_deferred_range, early_page_initialised, defer_init",
          "description": "初始化单页数据结构，实现PFN到节点ID映射，控制延迟初始化页面范围以优化早期启动性能",
          "similarity": 0.6316699385643005
        },
        {
          "chunk_id": 7,
          "file_path": "mm/mm_init.c",
          "start_line": 1030,
          "end_line": 1144,
          "content": [
            "static inline unsigned long compound_nr_pages(struct vmem_altmap *altmap,",
            "\t\t\t\t\t      struct dev_pagemap *pgmap)",
            "{",
            "\tif (!vmemmap_can_optimize(altmap, pgmap))",
            "\t\treturn pgmap_vmemmap_nr(pgmap);",
            "",
            "\treturn VMEMMAP_RESERVE_NR * (PAGE_SIZE / sizeof(struct page));",
            "}",
            "static void __ref memmap_init_compound(struct page *head,",
            "\t\t\t\t       unsigned long head_pfn,",
            "\t\t\t\t       unsigned long zone_idx, int nid,",
            "\t\t\t\t       struct dev_pagemap *pgmap,",
            "\t\t\t\t       unsigned long nr_pages)",
            "{",
            "\tunsigned long pfn, end_pfn = head_pfn + nr_pages;",
            "\tunsigned int order = pgmap->vmemmap_shift;",
            "",
            "\t__SetPageHead(head);",
            "\tfor (pfn = head_pfn + 1; pfn < end_pfn; pfn++) {",
            "\t\tstruct page *page = pfn_to_page(pfn);",
            "",
            "\t\t__init_zone_device_page(page, pfn, zone_idx, nid, pgmap);",
            "\t\tprep_compound_tail(head, pfn - head_pfn);",
            "\t\tset_page_count(page, 0);",
            "",
            "\t\t/*",
            "\t\t * The first tail page stores important compound page info.",
            "\t\t * Call prep_compound_head() after the first tail page has",
            "\t\t * been initialized, to not have the data overwritten.",
            "\t\t */",
            "\t\tif (pfn == head_pfn + 1)",
            "\t\t\tprep_compound_head(head, order);",
            "\t}",
            "}",
            "void __ref memmap_init_zone_device(struct zone *zone,",
            "\t\t\t\t   unsigned long start_pfn,",
            "\t\t\t\t   unsigned long nr_pages,",
            "\t\t\t\t   struct dev_pagemap *pgmap)",
            "{",
            "\tunsigned long pfn, end_pfn = start_pfn + nr_pages;",
            "\tstruct pglist_data *pgdat = zone->zone_pgdat;",
            "\tstruct vmem_altmap *altmap = pgmap_altmap(pgmap);",
            "\tunsigned int pfns_per_compound = pgmap_vmemmap_nr(pgmap);",
            "\tunsigned long zone_idx = zone_idx(zone);",
            "\tunsigned long start = jiffies;",
            "\tint nid = pgdat->node_id;",
            "",
            "\tif (WARN_ON_ONCE(!pgmap || zone_idx != ZONE_DEVICE))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * The call to memmap_init should have already taken care",
            "\t * of the pages reserved for the memmap, so we can just jump to",
            "\t * the end of that region and start processing the device pages.",
            "\t */",
            "\tif (altmap) {",
            "\t\tstart_pfn = altmap->base_pfn + vmem_altmap_offset(altmap);",
            "\t\tnr_pages = end_pfn - start_pfn;",
            "\t}",
            "",
            "\tfor (pfn = start_pfn; pfn < end_pfn; pfn += pfns_per_compound) {",
            "\t\tstruct page *page = pfn_to_page(pfn);",
            "",
            "\t\t__init_zone_device_page(page, pfn, zone_idx, nid, pgmap);",
            "",
            "\t\tif (pfns_per_compound == 1)",
            "\t\t\tcontinue;",
            "",
            "\t\tmemmap_init_compound(page, pfn, zone_idx, nid, pgmap,",
            "\t\t\t\t     compound_nr_pages(altmap, pgmap));",
            "\t}",
            "",
            "\tpr_debug(\"%s initialised %lu pages in %ums\\n\", __func__,",
            "\t\tnr_pages, jiffies_to_msecs(jiffies - start));",
            "}",
            "static void __init adjust_zone_range_for_zone_movable(int nid,",
            "\t\t\t\t\tunsigned long zone_type,",
            "\t\t\t\t\tunsigned long node_end_pfn,",
            "\t\t\t\t\tunsigned long *zone_start_pfn,",
            "\t\t\t\t\tunsigned long *zone_end_pfn)",
            "{",
            "\t/* Only adjust if ZONE_MOVABLE is on this node */",
            "\tif (zone_movable_pfn[nid]) {",
            "\t\t/* Size ZONE_MOVABLE */",
            "\t\tif (zone_type == ZONE_MOVABLE) {",
            "\t\t\t*zone_start_pfn = zone_movable_pfn[nid];",
            "\t\t\t*zone_end_pfn = min(node_end_pfn,",
            "\t\t\t\tarch_zone_highest_possible_pfn[movable_zone]);",
            "",
            "\t\t/* Adjust for ZONE_MOVABLE starting within this range */",
            "\t\t} else if (!mirrored_kernelcore &&",
            "\t\t\t*zone_start_pfn < zone_movable_pfn[nid] &&",
            "\t\t\t*zone_end_pfn > zone_movable_pfn[nid]) {",
            "\t\t\t*zone_end_pfn = zone_movable_pfn[nid];",
            "",
            "\t\t/* Check if this whole range is within ZONE_MOVABLE */",
            "\t\t} else if (*zone_start_pfn >= zone_movable_pfn[nid])",
            "\t\t\t*zone_start_pfn = *zone_end_pfn;",
            "\t}",
            "}",
            "unsigned long __init __absent_pages_in_range(int nid,",
            "\t\t\t\tunsigned long range_start_pfn,",
            "\t\t\t\tunsigned long range_end_pfn)",
            "{",
            "\tunsigned long nr_absent = range_end_pfn - range_start_pfn;",
            "\tunsigned long start_pfn, end_pfn;",
            "\tint i;",
            "",
            "\tfor_each_mem_pfn_range(i, nid, &start_pfn, &end_pfn, NULL) {",
            "\t\tstart_pfn = clamp(start_pfn, range_start_pfn, range_end_pfn);",
            "\t\tend_pfn = clamp(end_pfn, range_start_pfn, range_end_pfn);",
            "\t\tnr_absent -= end_pfn - start_pfn;",
            "\t}",
            "\treturn nr_absent;",
            "}"
          ],
          "function_name": "compound_nr_pages, memmap_init_compound, memmap_init_zone_device, adjust_zone_range_for_zone_movable, __absent_pages_in_range",
          "description": "初始化复合页结构并处理设备页映射，根据设备页类型设置页面属性，调整ZONE_MOVABLE范围以适配内存布局需求。",
          "similarity": 0.6274147033691406
        },
        {
          "chunk_id": 2,
          "file_path": "mm/mm_init.c",
          "start_line": 151,
          "end_line": 259,
          "content": [
            "static __init int set_mminit_loglevel(char *str)",
            "{",
            "\tget_option(&str, &mminit_loglevel);",
            "\treturn 0;",
            "}",
            "void mm_compute_batch(int overcommit_policy)",
            "{",
            "\tu64 memsized_batch;",
            "\ts32 nr = num_present_cpus();",
            "\ts32 batch = max_t(s32, nr*2, 32);",
            "\tunsigned long ram_pages = totalram_pages();",
            "",
            "\t/*",
            "\t * For policy OVERCOMMIT_NEVER, set batch size to 0.4% of",
            "\t * (total memory/#cpus), and lift it to 25% for other policies",
            "\t * to easy the possible lock contention for percpu_counter",
            "\t * vm_committed_as, while the max limit is INT_MAX",
            "\t */",
            "\tif (overcommit_policy == OVERCOMMIT_NEVER)",
            "\t\tmemsized_batch = min_t(u64, ram_pages/nr/256, INT_MAX);",
            "\telse",
            "\t\tmemsized_batch = min_t(u64, ram_pages/nr/4, INT_MAX);",
            "",
            "\tvm_committed_as_batch = max_t(s32, memsized_batch, batch);",
            "}",
            "static int __meminit mm_compute_batch_notifier(struct notifier_block *self,",
            "\t\t\t\t\tunsigned long action, void *arg)",
            "{",
            "\tswitch (action) {",
            "\tcase MEM_ONLINE:",
            "\tcase MEM_OFFLINE:",
            "\t\tmm_compute_batch(sysctl_overcommit_memory);",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tbreak;",
            "\t}",
            "\treturn NOTIFY_OK;",
            "}",
            "static int __init mm_compute_batch_init(void)",
            "{",
            "\tmm_compute_batch(sysctl_overcommit_memory);",
            "\thotplug_memory_notifier(mm_compute_batch_notifier, MM_COMPUTE_BATCH_PRI);",
            "\treturn 0;",
            "}",
            "static int __init mm_sysfs_init(void)",
            "{",
            "\tmm_kobj = kobject_create_and_add(\"mm\", kernel_kobj);",
            "\tif (!mm_kobj)",
            "\t\treturn -ENOMEM;",
            "",
            "\treturn 0;",
            "}",
            "static int __init cmdline_parse_core(char *p, unsigned long *core,",
            "\t\t\t\t     unsigned long *percent)",
            "{",
            "\tunsigned long long coremem;",
            "\tchar *endptr;",
            "",
            "\tif (!p)",
            "\t\treturn -EINVAL;",
            "",
            "\t/* Value may be a percentage of total memory, otherwise bytes */",
            "\tcoremem = simple_strtoull(p, &endptr, 0);",
            "\tif (*endptr == '%') {",
            "\t\t/* Paranoid check for percent values greater than 100 */",
            "\t\tWARN_ON(coremem > 100);",
            "",
            "\t\t*percent = coremem;",
            "\t} else {",
            "\t\tcoremem = memparse(p, &p);",
            "\t\t/* Paranoid check that UL is enough for the coremem value */",
            "\t\tWARN_ON((coremem >> PAGE_SHIFT) > ULONG_MAX);",
            "",
            "\t\t*core = coremem >> PAGE_SHIFT;",
            "\t\t*percent = 0UL;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int __init cmdline_parse_kernelcore(char *p)",
            "{",
            "\t/* parse kernelcore=mirror */",
            "\tif (parse_option_str(p, \"mirror\")) {",
            "\t\tmirrored_kernelcore = true;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn cmdline_parse_core(p, &required_kernelcore,",
            "\t\t\t\t  &required_kernelcore_percent);",
            "}",
            "static int __init cmdline_parse_movablecore(char *p)",
            "{",
            "\treturn cmdline_parse_core(p, &required_movablecore,",
            "\t\t\t\t  &required_movablecore_percent);",
            "}",
            "static unsigned long __init early_calculate_totalpages(void)",
            "{",
            "\tunsigned long totalpages = 0;",
            "\tunsigned long start_pfn, end_pfn;",
            "\tint i, nid;",
            "",
            "\tfor_each_mem_pfn_range(i, MAX_NUMNODES, &start_pfn, &end_pfn, &nid) {",
            "\t\tunsigned long pages = end_pfn - start_pfn;",
            "",
            "\t\ttotalpages += pages;",
            "\t\tif (pages)",
            "\t\t\tnode_set_state(nid, N_MEMORY);",
            "\t}",
            "\treturn totalpages;",
            "}"
          ],
          "function_name": "set_mminit_loglevel, mm_compute_batch, mm_compute_batch_notifier, mm_compute_batch_init, mm_sysfs_init, cmdline_parse_core, cmdline_parse_kernelcore, cmdline_parse_movablecore, early_calculate_totalpages",
          "description": "初始化内存批次计算逻辑，注册内存变化通知回调，解析命令行参数以确定内核核心和可移动内存需求",
          "similarity": 0.6222216486930847
        },
        {
          "chunk_id": 6,
          "file_path": "mm/mm_init.c",
          "start_line": 912,
          "end_line": 1017,
          "content": [
            "static void __init memmap_init_zone_range(struct zone *zone,",
            "\t\t\t\t\t  unsigned long start_pfn,",
            "\t\t\t\t\t  unsigned long end_pfn,",
            "\t\t\t\t\t  unsigned long *hole_pfn)",
            "{",
            "\tunsigned long zone_start_pfn = zone->zone_start_pfn;",
            "\tunsigned long zone_end_pfn = zone_start_pfn + zone->spanned_pages;",
            "\tint nid = zone_to_nid(zone), zone_id = zone_idx(zone);",
            "",
            "\tstart_pfn = clamp(start_pfn, zone_start_pfn, zone_end_pfn);",
            "\tend_pfn = clamp(end_pfn, zone_start_pfn, zone_end_pfn);",
            "",
            "\tif (start_pfn >= end_pfn)",
            "\t\treturn;",
            "",
            "\tmemmap_init_range(end_pfn - start_pfn, nid, zone_id, start_pfn,",
            "\t\t\t  zone_end_pfn, MEMINIT_EARLY, NULL, MIGRATE_MOVABLE);",
            "",
            "\tif (*hole_pfn < start_pfn)",
            "\t\tinit_unavailable_range(*hole_pfn, start_pfn, zone_id, nid);",
            "",
            "\t*hole_pfn = end_pfn;",
            "}",
            "static void __init memmap_init(void)",
            "{",
            "\tunsigned long start_pfn, end_pfn;",
            "\tunsigned long hole_pfn = 0;",
            "\tint i, j, zone_id = 0, nid;",
            "",
            "\tfor_each_mem_pfn_range(i, MAX_NUMNODES, &start_pfn, &end_pfn, &nid) {",
            "\t\tstruct pglist_data *node = NODE_DATA(nid);",
            "",
            "\t\tfor (j = 0; j < MAX_NR_ZONES; j++) {",
            "\t\t\tstruct zone *zone = node->node_zones + j;",
            "",
            "\t\t\tif (!populated_zone(zone))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tmemmap_init_zone_range(zone, start_pfn, end_pfn,",
            "\t\t\t\t\t       &hole_pfn);",
            "\t\t\tzone_id = j;",
            "\t\t}",
            "\t}",
            "",
            "#ifdef CONFIG_SPARSEMEM",
            "\t/*",
            "\t * Initialize the memory map for hole in the range [memory_end,",
            "\t * section_end].",
            "\t * Append the pages in this hole to the highest zone in the last",
            "\t * node.",
            "\t * The call to init_unavailable_range() is outside the ifdef to",
            "\t * silence the compiler warining about zone_id set but not used;",
            "\t * for FLATMEM it is a nop anyway",
            "\t */",
            "\tend_pfn = round_up(end_pfn, PAGES_PER_SECTION);",
            "\tif (hole_pfn < end_pfn)",
            "#endif",
            "\t\tinit_unavailable_range(hole_pfn, end_pfn, zone_id, nid);",
            "}",
            "static void __ref __init_zone_device_page(struct page *page, unsigned long pfn,",
            "\t\t\t\t\t  unsigned long zone_idx, int nid,",
            "\t\t\t\t\t  struct dev_pagemap *pgmap)",
            "{",
            "",
            "\t__init_single_page(page, pfn, zone_idx, nid);",
            "",
            "\t/*",
            "\t * Mark page reserved as it will need to wait for onlining",
            "\t * phase for it to be fully associated with a zone.",
            "\t *",
            "\t * We can use the non-atomic __set_bit operation for setting",
            "\t * the flag as we are still initializing the pages.",
            "\t */",
            "\t__SetPageReserved(page);",
            "",
            "\t/*",
            "\t * ZONE_DEVICE pages union ->lru with a ->pgmap back pointer",
            "\t * and zone_device_data.  It is a bug if a ZONE_DEVICE page is",
            "\t * ever freed or placed on a driver-private list.",
            "\t */",
            "\tpage->pgmap = pgmap;",
            "\tpage->zone_device_data = NULL;",
            "",
            "\t/*",
            "\t * Mark the block movable so that blocks are reserved for",
            "\t * movable at startup. This will force kernel allocations",
            "\t * to reserve their blocks rather than leaking throughout",
            "\t * the address space during boot when many long-lived",
            "\t * kernel allocations are made.",
            "\t *",
            "\t * Please note that MEMINIT_HOTPLUG path doesn't clear memmap",
            "\t * because this is done early in section_activate()",
            "\t */",
            "\tif (pageblock_aligned(pfn)) {",
            "\t\tset_pageblock_migratetype(page, MIGRATE_MOVABLE);",
            "\t\tcond_resched();",
            "\t}",
            "",
            "\t/*",
            "\t * ZONE_DEVICE pages are released directly to the driver page allocator",
            "\t * which will set the page count to 1 when allocating the page.",
            "\t */",
            "\tif (pgmap->type == MEMORY_DEVICE_PRIVATE ||",
            "\t    pgmap->type == MEMORY_DEVICE_COHERENT)",
            "\t\tset_page_count(page, 0);",
            "}"
          ],
          "function_name": "memmap_init_zone_range, memmap_init, __init_zone_device_page",
          "description": "遍历各节点和区，调用memmap_init_range初始化内存映射，处理稀疏内存中洞的不可用范围，并调整ZONE_MOVABLE范围以适应架构需求。",
          "similarity": 0.6166708469390869
        },
        {
          "chunk_id": 3,
          "file_path": "mm/mm_init.c",
          "start_line": 320,
          "end_line": 557,
          "content": [
            "static void __init find_usable_zone_for_movable(void)",
            "{",
            "\tint zone_index;",
            "\tfor (zone_index = MAX_NR_ZONES - 1; zone_index >= 0; zone_index--) {",
            "\t\tif (zone_index == ZONE_MOVABLE)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (arch_zone_highest_possible_pfn[zone_index] >",
            "\t\t\t\tarch_zone_lowest_possible_pfn[zone_index])",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\tVM_BUG_ON(zone_index == -1);",
            "\tmovable_zone = zone_index;",
            "}",
            "static void __init find_zone_movable_pfns_for_nodes(void)",
            "{",
            "\tint i, nid;",
            "\tunsigned long usable_startpfn;",
            "\tunsigned long kernelcore_node, kernelcore_remaining;",
            "\t/* save the state before borrow the nodemask */",
            "\tnodemask_t saved_node_state = node_states[N_MEMORY];",
            "\tunsigned long totalpages = early_calculate_totalpages();",
            "\tint usable_nodes = nodes_weight(node_states[N_MEMORY]);",
            "\tstruct memblock_region *r;",
            "",
            "\t/* Need to find movable_zone earlier when movable_node is specified. */",
            "\tfind_usable_zone_for_movable();",
            "",
            "\t/*",
            "\t * If movable_node is specified, ignore kernelcore and movablecore",
            "\t * options.",
            "\t */",
            "\tif (movable_node_is_enabled()) {",
            "\t\tfor_each_mem_region(r) {",
            "\t\t\tif (!memblock_is_hotpluggable(r))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tnid = memblock_get_region_node(r);",
            "",
            "\t\t\tusable_startpfn = PFN_DOWN(r->base);",
            "\t\t\tzone_movable_pfn[nid] = zone_movable_pfn[nid] ?",
            "\t\t\t\tmin(usable_startpfn, zone_movable_pfn[nid]) :",
            "\t\t\t\tusable_startpfn;",
            "\t\t}",
            "",
            "\t\tgoto out2;",
            "\t}",
            "",
            "\t/*",
            "\t * If kernelcore=mirror is specified, ignore movablecore option",
            "\t */",
            "\tif (mirrored_kernelcore) {",
            "\t\tbool mem_below_4gb_not_mirrored = false;",
            "",
            "\t\tif (!memblock_has_mirror()) {",
            "\t\t\tpr_warn(\"The system has no mirror memory, ignore kernelcore=mirror.\\n\");",
            "\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\tif (is_kdump_kernel()) {",
            "\t\t\tpr_warn(\"The system is under kdump, ignore kernelcore=mirror.\\n\");",
            "\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\tfor_each_mem_region(r) {",
            "\t\t\tif (memblock_is_mirror(r))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tnid = memblock_get_region_node(r);",
            "",
            "\t\t\tusable_startpfn = memblock_region_memory_base_pfn(r);",
            "",
            "\t\t\tif (usable_startpfn < PHYS_PFN(SZ_4G)) {",
            "\t\t\t\tmem_below_4gb_not_mirrored = true;",
            "\t\t\t\tcontinue;",
            "\t\t\t}",
            "",
            "\t\t\tzone_movable_pfn[nid] = zone_movable_pfn[nid] ?",
            "\t\t\t\tmin(usable_startpfn, zone_movable_pfn[nid]) :",
            "\t\t\t\tusable_startpfn;",
            "\t\t}",
            "",
            "\t\tif (mem_below_4gb_not_mirrored)",
            "\t\t\tpr_warn(\"This configuration results in unmirrored kernel memory.\\n\");",
            "",
            "\t\tgoto out2;",
            "\t}",
            "",
            "\t/*",
            "\t * If kernelcore=nn% or movablecore=nn% was specified, calculate the",
            "\t * amount of necessary memory.",
            "\t */",
            "\tif (required_kernelcore_percent)",
            "\t\trequired_kernelcore = (totalpages * 100 * required_kernelcore_percent) /",
            "\t\t\t\t       10000UL;",
            "\tif (required_movablecore_percent)",
            "\t\trequired_movablecore = (totalpages * 100 * required_movablecore_percent) /",
            "\t\t\t\t\t10000UL;",
            "",
            "\t/*",
            "\t * If movablecore= was specified, calculate what size of",
            "\t * kernelcore that corresponds so that memory usable for",
            "\t * any allocation type is evenly spread. If both kernelcore",
            "\t * and movablecore are specified, then the value of kernelcore",
            "\t * will be used for required_kernelcore if it's greater than",
            "\t * what movablecore would have allowed.",
            "\t */",
            "\tif (required_movablecore) {",
            "\t\tunsigned long corepages;",
            "",
            "\t\t/*",
            "\t\t * Round-up so that ZONE_MOVABLE is at least as large as what",
            "\t\t * was requested by the user",
            "\t\t */",
            "\t\trequired_movablecore =",
            "\t\t\troundup(required_movablecore, MAX_ORDER_NR_PAGES);",
            "\t\trequired_movablecore = min(totalpages, required_movablecore);",
            "\t\tcorepages = totalpages - required_movablecore;",
            "",
            "\t\trequired_kernelcore = max(required_kernelcore, corepages);",
            "\t}",
            "",
            "\t/*",
            "\t * If kernelcore was not specified or kernelcore size is larger",
            "\t * than totalpages, there is no ZONE_MOVABLE.",
            "\t */",
            "\tif (!required_kernelcore || required_kernelcore >= totalpages)",
            "\t\tgoto out;",
            "",
            "\t/* usable_startpfn is the lowest possible pfn ZONE_MOVABLE can be at */",
            "\tusable_startpfn = arch_zone_lowest_possible_pfn[movable_zone];",
            "",
            "restart:",
            "\t/* Spread kernelcore memory as evenly as possible throughout nodes */",
            "\tkernelcore_node = required_kernelcore / usable_nodes;",
            "\tfor_each_node_state(nid, N_MEMORY) {",
            "\t\tunsigned long start_pfn, end_pfn;",
            "",
            "\t\t/*",
            "\t\t * Recalculate kernelcore_node if the division per node",
            "\t\t * now exceeds what is necessary to satisfy the requested",
            "\t\t * amount of memory for the kernel",
            "\t\t */",
            "\t\tif (required_kernelcore < kernelcore_node)",
            "\t\t\tkernelcore_node = required_kernelcore / usable_nodes;",
            "",
            "\t\t/*",
            "\t\t * As the map is walked, we track how much memory is usable",
            "\t\t * by the kernel using kernelcore_remaining. When it is",
            "\t\t * 0, the rest of the node is usable by ZONE_MOVABLE",
            "\t\t */",
            "\t\tkernelcore_remaining = kernelcore_node;",
            "",
            "\t\t/* Go through each range of PFNs within this node */",
            "\t\tfor_each_mem_pfn_range(i, nid, &start_pfn, &end_pfn, NULL) {",
            "\t\t\tunsigned long size_pages;",
            "",
            "\t\t\tstart_pfn = max(start_pfn, zone_movable_pfn[nid]);",
            "\t\t\tif (start_pfn >= end_pfn)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\t/* Account for what is only usable for kernelcore */",
            "\t\t\tif (start_pfn < usable_startpfn) {",
            "\t\t\t\tunsigned long kernel_pages;",
            "\t\t\t\tkernel_pages = min(end_pfn, usable_startpfn)",
            "\t\t\t\t\t\t\t\t- start_pfn;",
            "",
            "\t\t\t\tkernelcore_remaining -= min(kernel_pages,",
            "\t\t\t\t\t\t\tkernelcore_remaining);",
            "\t\t\t\trequired_kernelcore -= min(kernel_pages,",
            "\t\t\t\t\t\t\trequired_kernelcore);",
            "",
            "\t\t\t\t/* Continue if range is now fully accounted */",
            "\t\t\t\tif (end_pfn <= usable_startpfn) {",
            "",
            "\t\t\t\t\t/*",
            "\t\t\t\t\t * Push zone_movable_pfn to the end so",
            "\t\t\t\t\t * that if we have to rebalance",
            "\t\t\t\t\t * kernelcore across nodes, we will",
            "\t\t\t\t\t * not double account here",
            "\t\t\t\t\t */",
            "\t\t\t\t\tzone_movable_pfn[nid] = end_pfn;",
            "\t\t\t\t\tcontinue;",
            "\t\t\t\t}",
            "\t\t\t\tstart_pfn = usable_startpfn;",
            "\t\t\t}",
            "",
            "\t\t\t/*",
            "\t\t\t * The usable PFN range for ZONE_MOVABLE is from",
            "\t\t\t * start_pfn->end_pfn. Calculate size_pages as the",
            "\t\t\t * number of pages used as kernelcore",
            "\t\t\t */",
            "\t\t\tsize_pages = end_pfn - start_pfn;",
            "\t\t\tif (size_pages > kernelcore_remaining)",
            "\t\t\t\tsize_pages = kernelcore_remaining;",
            "\t\t\tzone_movable_pfn[nid] = start_pfn + size_pages;",
            "",
            "\t\t\t/*",
            "\t\t\t * Some kernelcore has been met, update counts and",
            "\t\t\t * break if the kernelcore for this node has been",
            "\t\t\t * satisfied",
            "\t\t\t */",
            "\t\t\trequired_kernelcore -= min(required_kernelcore,",
            "\t\t\t\t\t\t\t\tsize_pages);",
            "\t\t\tkernelcore_remaining -= size_pages;",
            "\t\t\tif (!kernelcore_remaining)",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * If there is still required_kernelcore, we do another pass with one",
            "\t * less node in the count. This will push zone_movable_pfn[nid] further",
            "\t * along on the nodes that still have memory until kernelcore is",
            "\t * satisfied",
            "\t */",
            "\tusable_nodes--;",
            "\tif (usable_nodes && required_kernelcore > usable_nodes)",
            "\t\tgoto restart;",
            "",
            "out2:",
            "\t/* Align start of ZONE_MOVABLE on all nids to MAX_ORDER_NR_PAGES */",
            "\tfor (nid = 0; nid < MAX_NUMNODES; nid++) {",
            "\t\tunsigned long start_pfn, end_pfn;",
            "",
            "\t\tzone_movable_pfn[nid] =",
            "\t\t\troundup(zone_movable_pfn[nid], MAX_ORDER_NR_PAGES);",
            "",
            "\t\tget_pfn_range_for_nid(nid, &start_pfn, &end_pfn);",
            "\t\tif (zone_movable_pfn[nid] >= end_pfn)",
            "\t\t\tzone_movable_pfn[nid] = 0;",
            "\t}",
            "",
            "out:",
            "\t/* restore the node_state */",
            "\tnode_states[N_MEMORY] = saved_node_state;",
            "}"
          ],
          "function_name": "find_usable_zone_for_movable, find_zone_movable_pfns_for_nodes",
          "description": "确定可移动内存区域位置，根据内核核心/可移动核心比例分配PFN范围，平衡内存分布并设置ZONE_MOVABLE起始地址",
          "similarity": 0.6062713861465454
        }
      ]
    },
    {
      "source_file": "mm/kmsan/init.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:29:52\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kmsan\\init.c`\n\n---\n\n# `kmsan/init.c` 技术文档\n\n## 1. 文件概述\n\n`kmsan/init.c` 是 Linux 内核中 **KernelMemorySanitizer (KMSAN)** 调试工具的初始化模块。该文件负责在内核启动早期阶段为已存在的内存区域（如内核代码段、数据段、节点描述符 NODE_DATA 等）分配并初始化影子（shadow）和来源（origin）元数据页，并管理 memblock 分配器向伙伴系统移交页面时的元数据预分配策略。其目标是确保 KMSAN 能够追踪所有内核内存的初始化状态，从而检测未初始化内存的使用。\n\n## 2. 核心功能\n\n### 主要函数\n- `kmsan_record_future_shadow_range(void *start, void *end)`  \n  记录一个将在稍后（slab 初始化后）为其分配元数据的内存范围，并尝试与已有范围合并以减少碎片。\n  \n- `kmsan_init_shadow(void)`  \n  在内核初始化早期调用，收集需要初始化元数据的内存区域（包括保留内存、`.data` 段、NODE_DATA 等），并为这些区域分配影子和来源元数据。\n\n- `kmsan_memblock_free_pages(struct page *page, unsigned int order)`  \n  在 memblock 将大块连续物理页释放给伙伴系统时，拦截这些页面，按“三取一”策略：每三块同阶页面中，两块用作元数据（shadow + origin），一块作为被监控的数据页。\n\n- `kmsan_memblock_discard(void)`  \n  在 memblock 生命周期结束前，处理 `held_back[]` 中剩余的未配对元数据页，通过递归拆分和重新组合，尽可能为剩余数据页分配元数据，并将无法使用的页面归还系统。\n\n- `kmsan_init_runtime(void)`  \n  完成 KMSAN 的运行时初始化：为 init_task 创建任务上下文、清理残留元数据、启用 KMSAN 全局开关，并打印警告信息。\n\n### 主要数据结构\n- `struct start_end_pair`  \n  表示一个待分配元数据的虚拟地址范围（对齐到页边界）。\n\n- `struct metadata_page_pair`  \n  存储一对用于元数据的物理页：`shadow`（影子页，记录字节是否初始化）和 `origin`（来源页，记录未初始化值的来源信息）。\n\n- `struct smallstack`  \n  一个轻量级栈结构，用于在 `kmsan_memblock_discard()` 中暂存不同阶的页面块，支持按需拆分和重组。\n\n## 3. 关键实现\n\n### 内存范围合并机制\n`kmsan_record_future_shadow_range()` 在记录新范围前会遍历已有范围列表，若发现重叠或相邻，则合并为一个更大的连续范围。由于内核早期注册的范围数量有限（<20），采用线性扫描即可高效完成合并，避免元数据分配碎片化。\n\n### “三取一”元数据预分配策略\n在 `kmsan_memblock_free_pages()` 中，KMSAN 利用 memblock 向伙伴系统移交页面的时机，实施一种**贪婪但高效的元数据预留机制**：\n- 对于每个页面阶 `order`，维护一个 `held_back[order]` 缓存。\n- 前两次收到同阶页面块时，分别暂存为 shadow 和 origin。\n- 第三次收到时，将前两块作为元数据分配给第三块，并清空缓存供后续复用。\n- 此策略确保约 2/3 的释放内存被用作元数据，1/3 作为有效数据页，满足 KMSAN 对元数据空间的高需求。\n\n### 残留元数据回收（`kmsan_memblock_discard`）\n当 memblock 生命周期结束时，`held_back[]` 中可能残留未配对的 shadow 或 origin 页面。`kmsan_memblock_discard()` 采用**自顶向下递归拆分**策略：\n1. 从最大阶（`MAX_PAGE_ORDER`）开始，将所有残留页面压入 `collect` 栈。\n2. 若栈中元素 ≥3，则弹出三个页面，按“shadow + origin → data”方式完成一次元数据绑定，并将 data 页归还伙伴系统。\n3. 若栈中元素 <3，则将每个页面**拆分为两个低一阶的页面**，压入新栈，继续处理。\n4. 重复上述过程直至最小阶（0 阶），最大化利用残留内存。\n\n### 初始化流程整合\n- `kmsan_init_shadow()` 在 slab 初始化前运行，依赖 `memblock` 和 `phys_to_virt`，为静态内核内存分配元数据。\n- `kmsan_init_runtime()` 在伙伴系统完全就绪后调用，完成任务上下文初始化、残留清理，并最终启用 KMSAN。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `kmsan.h`：KMSAN 核心接口和宏定义（如 `KMSAN_WARN_ON`）。\n  - `<asm/sections.h>`：获取内核符号地址（如 `_sdata`, `_edata`）。\n  - `<linux/mm.h>`, `<linux/memblock.h>`：内存管理基础 API（`phys_to_virt`, `memblock` 遍历等）。\n  - `\"../internal.h\"`：KMSAN 内部实现细节（如 `kmsan_setup_meta`, `kmsan_init_alloc_meta_for_range`）。\n\n- **功能依赖**：\n  - 依赖 **memblock 分配器** 在早期内存管理中的行为。\n  - 依赖 **伙伴系统（buddy allocator）** 接管页面后的正常运作。\n  - 依赖 **percpu、NUMA NODE_DATA** 等子系统的初始化顺序（需在其注册内存范围后再调用 `kmsan_init_shadow`）。\n\n## 5. 使用场景\n\n- **内核启动早期**：在 `start_kernel()` 流程中，于 `mm_init()` 之前调用 `kmsan_init_shadow()`，为内核静态数据分配元数据。\n- **memblock 释放页面时**：每当 `memblock_free_pages()` 被调用（通常在 `free_all_bootmem()` 中），KMSAN 拦截页面释放流程，执行元数据预留。\n- **内核初始化尾声**：在 `rest_init()` 之前调用 `kmsan_init_runtime()`，完成 KMSAN 的最终激活。\n- **调试场景**：仅在启用 `CONFIG_KMSAN` 编译选项的内核中生效，用于检测内核中因未初始化内存导致的安全漏洞或逻辑错误，**严禁在生产环境使用**。",
      "similarity": 0.5853971242904663,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/kmsan/init.c",
          "start_line": 201,
          "end_line": 234,
          "content": [
            "static void kmsan_memblock_discard(void)",
            "{",
            "\t/*",
            "\t * For each order=N:",
            "\t *  - push held_back[N].shadow and .origin to @collect;",
            "\t *  - while there are >= 3 elements in @collect, do garbage collection:",
            "\t *    - pop 3 ranges from @collect;",
            "\t *    - use two of them as shadow and origin for the third one;",
            "\t *    - repeat;",
            "\t *  - split each remaining element from @collect into 2 ranges of",
            "\t *    order=N-1,",
            "\t *  - repeat.",
            "\t */",
            "\tcollect.order = MAX_PAGE_ORDER;",
            "\tfor (int i = MAX_PAGE_ORDER; i >= 0; i--) {",
            "\t\tif (held_back[i].shadow)",
            "\t\t\tsmallstack_push(&collect, held_back[i].shadow);",
            "\t\tif (held_back[i].origin)",
            "\t\t\tsmallstack_push(&collect, held_back[i].origin);",
            "\t\theld_back[i].shadow = NULL;",
            "\t\theld_back[i].origin = NULL;",
            "\t\tdo_collection();",
            "\t\tcollect_split();",
            "\t}",
            "}",
            "void __init kmsan_init_runtime(void)",
            "{",
            "\t/* Assuming current is init_task */",
            "\tkmsan_internal_task_create(current);",
            "\tkmsan_memblock_discard();",
            "\tpr_info(\"Starting KernelMemorySanitizer\\n\");",
            "\tpr_info(\"ATTENTION: KMSAN is a debugging tool! Do not use it on production machines!\\n\");",
            "\tkmsan_enabled = true;",
            "}"
          ],
          "function_name": "kmsan_memblock_discard, kmsan_init_runtime",
          "description": "执行内存块清理操作，通过小栈收集并处理不同阶序的页面资源，完成KMSAN运行时环境初始化与启用",
          "similarity": 0.57277512550354
        },
        {
          "chunk_id": 0,
          "file_path": "mm/kmsan/init.c",
          "start_line": 1,
          "end_line": 29,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * KMSAN initialization routines.",
            " *",
            " * Copyright (C) 2017-2021 Google LLC",
            " * Author: Alexander Potapenko <glider@google.com>",
            " *",
            " */",
            "",
            "#include \"kmsan.h\"",
            "",
            "#include <asm/sections.h>",
            "#include <linux/mm.h>",
            "#include <linux/memblock.h>",
            "",
            "#include \"../internal.h\"",
            "",
            "#define NUM_FUTURE_RANGES 128",
            "struct start_end_pair {",
            "\tu64 start, end;",
            "};",
            "",
            "static struct start_end_pair start_end_pairs[NUM_FUTURE_RANGES] __initdata;",
            "static int future_index __initdata;",
            "",
            "/*",
            " * Record a range of memory for which the metadata pages will be created once",
            " * the page allocator becomes available.",
            " */"
          ],
          "function_name": null,
          "description": "定义用于记录未来内存范围的辅助结构和初始化函数，用于在页面分配器就绪后创建元数据页",
          "similarity": 0.5561469793319702
        },
        {
          "chunk_id": 1,
          "file_path": "mm/kmsan/init.c",
          "start_line": 30,
          "end_line": 141,
          "content": [
            "static void __init kmsan_record_future_shadow_range(void *start, void *end)",
            "{",
            "\tu64 nstart = (u64)start, nend = (u64)end, cstart, cend;",
            "\tbool merged = false;",
            "",
            "\tKMSAN_WARN_ON(future_index == NUM_FUTURE_RANGES);",
            "\tKMSAN_WARN_ON((nstart >= nend) || !nstart || !nend);",
            "\tnstart = ALIGN_DOWN(nstart, PAGE_SIZE);",
            "\tnend = ALIGN(nend, PAGE_SIZE);",
            "",
            "\t/*",
            "\t * Scan the existing ranges to see if any of them overlaps with",
            "\t * [start, end). In that case, merge the two ranges instead of",
            "\t * creating a new one.",
            "\t * The number of ranges is less than 20, so there is no need to organize",
            "\t * them into a more intelligent data structure.",
            "\t */",
            "\tfor (int i = 0; i < future_index; i++) {",
            "\t\tcstart = start_end_pairs[i].start;",
            "\t\tcend = start_end_pairs[i].end;",
            "\t\tif ((cstart < nstart && cend < nstart) ||",
            "\t\t    (cstart > nend && cend > nend))",
            "\t\t\t/* ranges are disjoint - do not merge */",
            "\t\t\tcontinue;",
            "\t\tstart_end_pairs[i].start = min(nstart, cstart);",
            "\t\tstart_end_pairs[i].end = max(nend, cend);",
            "\t\tmerged = true;",
            "\t\tbreak;",
            "\t}",
            "\tif (merged)",
            "\t\treturn;",
            "\tstart_end_pairs[future_index].start = nstart;",
            "\tstart_end_pairs[future_index].end = nend;",
            "\tfuture_index++;",
            "}",
            "void __init kmsan_init_shadow(void)",
            "{",
            "\tconst size_t nd_size = roundup(sizeof(pg_data_t), PAGE_SIZE);",
            "\tphys_addr_t p_start, p_end;",
            "\tu64 loop;",
            "\tint nid;",
            "",
            "\tfor_each_reserved_mem_range(loop, &p_start, &p_end)",
            "\t\tkmsan_record_future_shadow_range(phys_to_virt(p_start),",
            "\t\t\t\t\t\t phys_to_virt(p_end));",
            "\t/* Allocate shadow for .data */",
            "\tkmsan_record_future_shadow_range(_sdata, _edata);",
            "",
            "\tfor_each_online_node(nid)",
            "\t\tkmsan_record_future_shadow_range(",
            "\t\t\tNODE_DATA(nid), (char *)NODE_DATA(nid) + nd_size);",
            "",
            "\tfor (int i = 0; i < future_index; i++)",
            "\t\tkmsan_init_alloc_meta_for_range(",
            "\t\t\t(void *)start_end_pairs[i].start,",
            "\t\t\t(void *)start_end_pairs[i].end);",
            "}",
            "bool kmsan_memblock_free_pages(struct page *page, unsigned int order)",
            "{",
            "\tstruct page *shadow, *origin;",
            "",
            "\tif (!held_back[order].shadow) {",
            "\t\theld_back[order].shadow = page;",
            "\t\treturn false;",
            "\t}",
            "\tif (!held_back[order].origin) {",
            "\t\theld_back[order].origin = page;",
            "\t\treturn false;",
            "\t}",
            "\tshadow = held_back[order].shadow;",
            "\torigin = held_back[order].origin;",
            "\tkmsan_setup_meta(page, shadow, origin, order);",
            "",
            "\theld_back[order].shadow = NULL;",
            "\theld_back[order].origin = NULL;",
            "\treturn true;",
            "}",
            "static void smallstack_push(struct smallstack *stack, struct page *pages)",
            "{",
            "\tKMSAN_WARN_ON(stack->index == MAX_BLOCKS);",
            "\tstack->items[stack->index] = pages;",
            "\tstack->index++;",
            "}",
            "static void do_collection(void)",
            "{",
            "\tstruct page *page, *shadow, *origin;",
            "",
            "\twhile (collect.index >= 3) {",
            "\t\tpage = smallstack_pop(&collect);",
            "\t\tshadow = smallstack_pop(&collect);",
            "\t\torigin = smallstack_pop(&collect);",
            "\t\tkmsan_setup_meta(page, shadow, origin, collect.order);",
            "\t\t__free_pages_core(page, collect.order, MEMINIT_EARLY);",
            "\t}",
            "}",
            "static void collect_split(void)",
            "{",
            "\tstruct smallstack tmp = {",
            "\t\t.order = collect.order - 1,",
            "\t\t.index = 0,",
            "\t};",
            "\tstruct page *page;",
            "",
            "\tif (!collect.order)",
            "\t\treturn;",
            "\twhile (collect.index) {",
            "\t\tpage = smallstack_pop(&collect);",
            "\t\tsmallstack_push(&tmp, &page[0]);",
            "\t\tsmallstack_push(&tmp, &page[1 << tmp.order]);",
            "\t}",
            "\t__memcpy(&collect, &tmp, sizeof(tmp));",
            "}"
          ],
          "function_name": "kmsan_record_future_shadow_range, kmsan_init_shadow, kmsan_memblock_free_pages, smallstack_push, do_collection, collect_split",
          "description": "实现未来内存范围的合并逻辑、影子内存初始化及页面回收机制，包含范围扫描、元数据分配与碎片收集处理",
          "similarity": 0.516079306602478
        }
      ]
    }
  ]
}