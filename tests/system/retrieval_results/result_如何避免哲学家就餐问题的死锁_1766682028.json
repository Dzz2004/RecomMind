{
  "query": "如何避免哲学家就餐问题的死锁",
  "timestamp": "2025-12-26 01:00:28",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/osq_lock.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:43:41\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\osq_lock.c`\n\n---\n\n# `locking/osq_lock.c` 技术文档\n\n## 1. 文件概述\n\n`osq_lock.c` 实现了一种专为**乐观自旋（Optimistic Spinning）**设计的轻量级排队自旋锁机制，称为 **OSQ（Optimistic Spin Queue）锁**。该机制主要用于支持如互斥锁（mutex）、读写信号量（rwsem）等**可睡眠锁**在争用时进行乐观自旋，以避免不必要的上下文切换和调度开销。OSQ 锁基于 MCS（Mellor-Crummey and Scott）锁的思想，但针对 Linux 内核的调度和抢占模型进行了优化，利用每个 CPU 的静态 per-CPU 节点结构，确保在禁用抢占的自旋上下文中安全使用。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct optimistic_spin_node`：每个 CPU 对应一个静态节点，包含：\n  - `cpu`：编码后的 CPU 编号（实际值 = CPU ID + 1）\n  - `locked`：布尔标志，表示是否已获得锁\n  - `next`：指向队列中下一个节点的指针\n  - `prev`：指向前一个节点的指针\n- `struct optimistic_spin_queue`：OSQ 锁结构体，仅包含一个原子变量 `tail`，用于指向队列尾部（编码后的 CPU 编号），`OSQ_UNLOCKED_VAL`（值为 0）表示无锁。\n\n### 主要函数\n- `bool osq_lock(struct optimistic_spin_queue *lock)`  \n  尝试获取 OSQ 锁。若成功获得锁或决定放弃自旋（如需要调度或前驱被抢占），返回 `true`；若成功排队但未获得锁且需继续等待，则返回 `false`（实际逻辑中，失败路径最终也返回 `false` 表示未获得锁）。\n  \n- `void osq_unlock(struct optimistic_spin_queue *lock)`  \n  释放 OSQ 锁，唤醒队列中的下一个等待者（若存在）。\n\n- `static inline struct optimistic_spin_node *osq_wait_next(...)`  \n  辅助函数，用于在解锁或取消排队时安全地获取下一个节点，并处理队列尾部的原子更新。\n\n- `encode_cpu()` / `decode_cpu()` / `node_cpu()`  \n  用于在 CPU 编号与 per-CPU 节点指针之间进行编码/解码转换，其中 CPU 编号 0 被编码为 1，以 0 表示“无 CPU”（即锁空闲）。\n\n## 3. 关键实现\n\n### Per-CPU 静态节点设计\n- 每个 CPU 拥有一个静态的 `osq_node`（通过 `DEFINE_PER_CPU_SHARED_ALIGNED` 定义），避免动态分配开销。\n- 由于 OSQ 仅在**禁用抢占**的上下文中使用（如 mutex 的乐观自旋阶段），且**不可在中断上下文调用**，因此 per-CPU 节点的生命周期安全。\n\n### 锁获取流程 (`osq_lock`)\n1. **初始化本地节点**：设置 `locked=0`、`next=NULL`，并确保 `cpu` 字段为当前 CPU 编码值。\n2. **原子交换尾指针**：通过 `atomic_xchg(&lock->tail, curr)` 尝试入队。若原值为 `OSQ_UNLOCKED_VAL`，直接获得锁。\n3. **链接到前驱**：若已有前驱（`prev`），通过 `smp_wmb()` 确保内存顺序后，设置 `prev->next = node`。\n4. **自旋等待**：使用 `smp_cond_load_relaxed()` 等待 `node->locked` 变为 1，或满足退出条件（`need_resched()` 或前驱 CPU 被抢占 `vcpu_is_preempted()`）。\n5. **取消排队（Unqueue）**：若需退出自旋：\n   - **Step A**：尝试将 `prev->next` 置为 `NULL`，断开链接。\n   - **Step B**：调用 `osq_wait_next()` 确定下一个节点，并可能将锁尾指针回退。\n   - **Step C**：若存在 `next`，将其与 `prev` 直接链接，完成队列修复。\n\n### 锁释放流程 (`osq_unlock`)\n1. **快速路径**：若当前 CPU 是唯一持有者（`tail == curr`），直接将 `tail` 设为 `OSQ_UNLOCKED_VAL`。\n2. **慢速路径**：\n   - 若本地节点的 `next` 非空，直接设置 `next->locked = 1` 唤醒后继。\n   - 否则调用 `osq_wait_next()` 获取下一个节点（处理并发取消排队的情况），再唤醒。\n\n### 内存屏障与原子操作\n- 使用 `atomic_xchg`、`atomic_cmpxchg_acquire/release` 确保对 `lock->tail` 的操作具有适当的内存序。\n- `smp_wmb()` 保证在设置 `prev->next` 前，本地节点的初始化对其他 CPU 可见。\n- `WRITE_ONCE`/`READ_ONCE` 防止编译器优化破坏并发访问语义。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/percpu.h>`：提供 per-CPU 变量支持（`this_cpu_ptr`, `per_cpu_ptr`）。\n  - `<linux/sched.h>`：提供调度相关函数（`need_resched()`）和虚拟 CPU 抢占检测（`vcpu_is_preempted()`）。\n  - `<linux/osq_lock.h>`：定义 `struct optimistic_spin_queue`、`struct optimistic_spin_node` 及 `OSQ_UNLOCKED_VAL`。\n- **架构依赖**：依赖底层架构的原子操作（`atomic_*`）、内存屏障（`smp_wmb`, `smp_load_acquire`）和 CPU ID 获取（`smp_processor_id()`）。\n- **调度器集成**：与内核调度器紧密协作，通过 `need_resched()` 和 `vcpu_is_preempted()` 决定是否继续自旋。\n\n## 5. 使用场景\n\nOSQ 锁主要用于**可睡眠锁的乐观自旋优化**，典型场景包括：\n- **Mutex（互斥锁）**：在 `mutex_spin_on_owner()` 中，若锁持有者正在运行，当前 CPU 会尝试 OSQ 自旋而非立即睡眠。\n- **Rwsem（读写信号量）**：在写者争用时，若满足条件，会使用 OSQ 进行乐观自旋。\n- **其他睡眠锁**：任何希望在锁争用时避免立即进入睡眠、以降低延迟的同步原语。\n\n其核心价值在于：当锁持有者很可能在**另一个 CPU 上运行且未被抢占**时，通过短暂自旋可避免昂贵的上下文切换，提升性能；同时通过 `vcpu_is_preempted()` 检测虚拟化环境中的抢占，避免在持有者已让出 CPU 时无效自旋。",
      "similarity": 0.45563364028930664,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/osq_lock.c",
          "start_line": 213,
          "end_line": 238,
          "content": [
            "void osq_unlock(struct optimistic_spin_queue *lock)",
            "{",
            "\tstruct optimistic_spin_node *node, *next;",
            "\tint curr = encode_cpu(smp_processor_id());",
            "",
            "\t/*",
            "\t * Fast path for the uncontended case.",
            "\t */",
            "\tif (likely(atomic_cmpxchg_release(&lock->tail, curr,",
            "\t\t\t\t\t  OSQ_UNLOCKED_VAL) == curr))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Second most likely case.",
            "\t */",
            "\tnode = this_cpu_ptr(&osq_node);",
            "\tnext = xchg(&node->next, NULL);",
            "\tif (next) {",
            "\t\tWRITE_ONCE(next->locked, 1);",
            "\t\treturn;",
            "\t}",
            "",
            "\tnext = osq_wait_next(lock, node, NULL);",
            "\tif (next)",
            "\t\tWRITE_ONCE(next->locked, 1);",
            "}"
          ],
          "function_name": "osq_unlock",
          "description": "实现osq_unlock函数，处理锁的释放。通过原子比较交换操作快速处理无竞争情况，否则查找并唤醒下一个等待节点，确保锁状态的正确性与线程安全。",
          "similarity": 0.42835354804992676
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/osq_lock.c",
          "start_line": 20,
          "end_line": 149,
          "content": [
            "static inline int encode_cpu(int cpu_nr)",
            "{",
            "\treturn cpu_nr + 1;",
            "}",
            "static inline int node_cpu(struct optimistic_spin_node *node)",
            "{",
            "\treturn node->cpu - 1;",
            "}",
            "bool osq_lock(struct optimistic_spin_queue *lock)",
            "{",
            "\tstruct optimistic_spin_node *node = this_cpu_ptr(&osq_node);",
            "\tstruct optimistic_spin_node *prev, *next;",
            "\tint curr = encode_cpu(smp_processor_id());",
            "\tint old;",
            "",
            "\tnode->locked = 0;",
            "\tnode->next = NULL;",
            "\t/*",
            "\t * After this cpu member is initialized for the first time, it",
            "\t * would no longer change in fact. That could avoid cache misses",
            "\t * when spin and access the cpu member by other CPUs.",
            "\t */",
            "\tif (node->cpu != curr)",
            "\t\tnode->cpu = curr;",
            "",
            "\t/*",
            "\t * We need both ACQUIRE (pairs with corresponding RELEASE in",
            "\t * unlock() uncontended, or fastpath) and RELEASE (to publish",
            "\t * the node fields we just initialised) semantics when updating",
            "\t * the lock tail.",
            "\t */",
            "\told = atomic_xchg(&lock->tail, curr);",
            "\tif (old == OSQ_UNLOCKED_VAL)",
            "\t\treturn true;",
            "",
            "\tprev = decode_cpu(old);",
            "\tnode->prev = prev;",
            "",
            "\t/*",
            "\t * osq_lock()\t\t\tunqueue",
            "\t *",
            "\t * node->prev = prev\t\tosq_wait_next()",
            "\t * WMB\t\t\t\tMB",
            "\t * prev->next = node\t\tnext->prev = prev // unqueue-C",
            "\t *",
            "\t * Here 'node->prev' and 'next->prev' are the same variable and we need",
            "\t * to ensure these stores happen in-order to avoid corrupting the list.",
            "\t */",
            "\tsmp_wmb();",
            "",
            "\tWRITE_ONCE(prev->next, node);",
            "",
            "\t/*",
            "\t * Normally @prev is untouchable after the above store; because at that",
            "\t * moment unlock can proceed and wipe the node element from stack.",
            "\t *",
            "\t * However, since our nodes are static per-cpu storage, we're",
            "\t * guaranteed their existence -- this allows us to apply",
            "\t * cmpxchg in an attempt to undo our queueing.",
            "\t */",
            "",
            "\t/*",
            "\t * Wait to acquire the lock or cancellation. Note that need_resched()",
            "\t * will come with an IPI, which will wake smp_cond_load_relaxed() if it",
            "\t * is implemented with a monitor-wait. vcpu_is_preempted() relies on",
            "\t * polling, be careful.",
            "\t */",
            "\tif (smp_cond_load_relaxed(&node->locked, VAL || need_resched() ||",
            "\t\t\t\t  vcpu_is_preempted(node_cpu(node->prev))))",
            "\t\treturn true;",
            "",
            "\t/* unqueue */",
            "\t/*",
            "\t * Step - A  -- stabilize @prev",
            "\t *",
            "\t * Undo our @prev->next assignment; this will make @prev's",
            "\t * unlock()/unqueue() wait for a next pointer since @lock points to us",
            "\t * (or later).",
            "\t */",
            "",
            "\tfor (;;) {",
            "\t\t/*",
            "\t\t * cpu_relax() below implies a compiler barrier which would",
            "\t\t * prevent this comparison being optimized away.",
            "\t\t */",
            "\t\tif (data_race(prev->next) == node &&",
            "\t\t    cmpxchg(&prev->next, node, NULL) == node)",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * We can only fail the cmpxchg() racing against an unlock(),",
            "\t\t * in which case we should observe @node->locked becoming",
            "\t\t * true.",
            "\t\t */",
            "\t\tif (smp_load_acquire(&node->locked))",
            "\t\t\treturn true;",
            "",
            "\t\tcpu_relax();",
            "",
            "\t\t/*",
            "\t\t * Or we race against a concurrent unqueue()'s step-B, in which",
            "\t\t * case its step-C will write us a new @node->prev pointer.",
            "\t\t */",
            "\t\tprev = READ_ONCE(node->prev);",
            "\t}",
            "",
            "\t/*",
            "\t * Step - B -- stabilize @next",
            "\t *",
            "\t * Similar to unlock(), wait for @node->next or move @lock from @node",
            "\t * back to @prev.",
            "\t */",
            "",
            "\tnext = osq_wait_next(lock, node, prev);",
            "\tif (!next)",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Step - C -- unlink",
            "\t *",
            "\t * @prev is stable because its still waiting for a new @prev->next",
            "\t * pointer, @next is stable because our @node->next pointer is NULL and",
            "\t * it will wait in Step-A.",
            "\t */",
            "",
            "\tWRITE_ONCE(next->prev, prev);",
            "\tWRITE_ONCE(prev->next, next);",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "encode_cpu, node_cpu, osq_lock",
          "description": "实现osq_lock函数，负责获取乐观自旋锁。通过原子操作将当前节点插入队列，利用内存屏障保证顺序一致性，并通过循环等待条件满足或被唤醒，最终完成锁的获取过程。",
          "similarity": 0.4175516664981842
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/osq_lock.c",
          "start_line": 1,
          "end_line": 19,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/percpu.h>",
            "#include <linux/sched.h>",
            "#include <linux/osq_lock.h>",
            "",
            "/*",
            " * An MCS like lock especially tailored for optimistic spinning for sleeping",
            " * lock implementations (mutex, rwsem, etc).",
            " *",
            " * Using a single mcs node per CPU is safe because sleeping locks should not be",
            " * called from interrupt context and we have preemption disabled while",
            " * spinning.",
            " */",
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);",
            "",
            "/*",
            " * We use the value 0 to represent \"no CPU\", thus the encoded value",
            " * will be the CPU number incremented by 1.",
            " */"
          ],
          "function_name": null,
          "description": "定义全局的per-CPU乐观自旋节点osq_node，用于支持多CPU环境下乐观自旋锁的实现。通过encode_cpu和node_cpu函数处理CPU编号转换，为后续锁操作提供基础设施。",
          "similarity": 0.36192822456359863
        }
      ]
    },
    {
      "source_file": "kernel/power/wakelock.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:29:10\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `power\\wakelock.c`\n\n---\n\n# `power/wakelock.c` 技术文档\n\n## 1. 文件概述\n\n`power/wakelock.c` 实现了 Linux 内核中面向用户空间的 **wakelock（唤醒锁）机制**，允许用户空间程序通过 sysfs 接口创建、激活和释放唤醒锁，以防止系统在特定任务执行期间进入低功耗状态（如 suspend）。该实现借鉴了 Android 系统中的 wakelock 接口，但基于标准 Linux 内核的 `wakeup_source` 基础设施，提供更安全、可配置的用户空间电源管理能力。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct wakelock`**  \n  表示一个用户空间可操作的唤醒锁对象：\n  - `name`：唤醒锁名称（用户指定）\n  - `node`：用于在红黑树 `wakelocks_tree` 中组织所有 wakelock\n  - `ws`：指向内核 `wakeup_source` 对象，实际执行电源管理逻辑\n  - `lru`（条件编译）：用于垃圾回收（GC）机制的 LRU 链表节点（当 `CONFIG_PM_WAKELOCKS_GC` 启用时）\n\n### 主要函数\n\n- **`pm_show_wakelocks(char *buf, bool show_active)`**  \n  将当前所有（活跃或非活跃）wakelock 名称输出到缓冲区，供 sysfs 读取（如 `/sys/power/wake_lock` 或 `/sys/power/wake_unlock`）。\n\n- **`pm_wake_lock(const char *buf)`**  \n  用户空间通过写入 `/sys/power/wake_lock` 触发此函数，用于**获取**指定名称的 wakelock。支持可选超时参数（单位：纳秒）。\n\n- **`pm_wake_unlock(const char *buf)`**  \n  用户空间通过写入 `/sys/power/wake_unlock` 触发此函数，用于**释放**指定名称的 wakelock。\n\n- **`wakelock_lookup_add(const char *name, size_t len, bool add_if_not_found)`**  \n  在全局红黑树中查找或创建 wakelock 对象，是 `pm_wake_lock` 和 `pm_wake_unlock` 的核心辅助函数。\n\n- **`__wakelocks_gc(struct work_struct *work)`**（条件编译）  \n  垃圾回收工作函数，定期清理长时间未使用且非活跃的 wakelock 对象（当 `CONFIG_PM_WAKELOCKS_GC` 启用时）。\n\n### 辅助机制\n\n- **数量限制**：通过 `CONFIG_PM_WAKELOCKS_LIMIT` 控制系统中 wakelock 的最大数量。\n- **LRU 管理**：通过 `wakelocks_lru_add` / `wakelocks_lru_most_recent` 维护最近使用顺序。\n- **自动回收**：通过 `wakelocks_gc()` 触发异步 GC 工作队列。\n\n## 3. 关键实现\n\n### 红黑树管理\n所有 `wakelock` 对象通过名称作为键，存储在全局红黑树 `wakelocks_tree` 中，确保 O(log n) 时间复杂度的查找、插入和删除操作。\n\n### 唤醒源集成\n每个 `wakelock` 封装一个 `wakeup_source`（通过 `wakeup_source_register()` 创建），实际的电源阻止逻辑由内核 PM 子系统的 `wakeup_source` 机制处理：\n- `__pm_stay_awake(ws)`：永久保持唤醒（直到显式释放）\n- `__pm_wakeup_event(ws, timeout_ms)`：带超时的唤醒\n- `__pm_relax(ws)`：释放唤醒锁\n\n### 安全与权限控制\n- 仅具备 `CAP_BLOCK_SUSPEND` 能力的进程可操作 wakelock（防止普通用户滥用导致无法休眠）。\n- 名称解析严格处理空格和换行符，防止注入或解析错误。\n\n### 垃圾回收机制（可选）\n当启用 `CONFIG_PM_WAKELOCKS_GC`：\n- 每次访问 wakelock 时将其移至 LRU 链表头部（`wakelocks_lru_most_recent`）。\n- 每进行 `WL_GC_COUNT_MAX`（默认 100）次操作后，调度 GC 工作。\n- GC 遍历 LRU 链表（从最旧开始），删除满足以下条件的对象：\n  - 非活跃（`!active`）\n  - 空闲时间超过 `WL_GC_TIME_SEC`（默认 300 秒）\n\n### 数量限制（可选）\n当 `CONFIG_PM_WAKELOCKS_LIMIT > 0` 时，系统维护 `number_of_wakelocks` 计数器，防止用户空间创建过多 wakelock 耗尽内存。\n\n## 4. 依赖关系\n\n- **内核头文件**：\n  - `<linux/wakeup_source.h>`（通过 `\"power.h\"` 间接包含）：提供 `wakeup_source` 相关 API\n  - `<linux/sysfs.h>`：通过 `sysfs_emit_at` 实现 sysfs 输出\n  - `<linux/workqueue.h>`：用于 GC 异步任务调度\n  - `<linux/rbtree.h>`：红黑树数据结构支持\n  - `<linux/capability.h>`：权限检查\n\n- **内核子系统**：\n  - **电源管理 (PM) 子系统**：依赖 `wakeup_source` 基础设施实现实际的 suspend 阻止逻辑。\n  - **sysfs**：通过 sysfs 文件（如 `/sys/power/wake_lock`）暴露用户接口。\n  - **内存管理**：使用 `kzalloc`/`kstrndup`/`kfree` 管理动态内存。\n\n- **配置选项**：\n  - `CONFIG_PM_WAKELOCKS`：主开关\n  - `CONFIG_PM_WAKELOCKS_LIMIT`：限制最大数量\n  - `CONFIG_PM_WAKELOCKS_GC`：启用自动垃圾回收\n\n## 5. 使用场景\n\n- **Android 兼容层**：为基于 Android 的系统提供标准 Linux 内核上的 wakelock 支持，无需修改用户空间应用。\n- **用户空间电源控制**：允许特权应用（如媒体播放器、下载管理器）在执行关键任务时阻止系统休眠。\n- **调试与监控**：通过读取 `/sys/power/wake_lock` 查看当前活跃的 wakelock，辅助电源问题诊断。\n- **资源受限设备**：通过 `CONFIG_PM_WAKELOCKS_LIMIT` 和 GC 机制防止内存泄漏，适用于嵌入式或移动设备。",
      "similarity": 0.4456743001937866,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/power/wakelock.c",
          "start_line": 254,
          "end_line": 288,
          "content": [
            "int pm_wake_unlock(const char *buf)",
            "{",
            "\tstruct wakelock *wl;",
            "\tsize_t len;",
            "\tint ret = 0;",
            "",
            "\tif (!capable(CAP_BLOCK_SUSPEND))",
            "\t\treturn -EPERM;",
            "",
            "\tlen = strlen(buf);",
            "\tif (!len)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (buf[len-1] == '\\n')",
            "\t\tlen--;",
            "",
            "\tif (!len)",
            "\t\treturn -EINVAL;",
            "",
            "\tmutex_lock(&wakelocks_lock);",
            "",
            "\twl = wakelock_lookup_add(buf, len, false);",
            "\tif (IS_ERR(wl)) {",
            "\t\tret = PTR_ERR(wl);",
            "\t\tgoto out;",
            "\t}",
            "\t__pm_relax(wl->ws);",
            "",
            "\twakelocks_lru_most_recent(wl);",
            "\twakelocks_gc();",
            "",
            " out:",
            "\tmutex_unlock(&wakelocks_lock);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "pm_wake_unlock",
          "description": "提供唤醒锁解除接口，通过名称匹配目标唤醒锁并调用__pm_relax释放，同步更新LRU顺序并触发动态垃圾回收机制",
          "similarity": 0.429178386926651
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/power/wakelock.c",
          "start_line": 38,
          "end_line": 172,
          "content": [
            "ssize_t pm_show_wakelocks(char *buf, bool show_active)",
            "{",
            "\tstruct rb_node *node;",
            "\tstruct wakelock *wl;",
            "\tint len = 0;",
            "",
            "\tmutex_lock(&wakelocks_lock);",
            "",
            "\tfor (node = rb_first(&wakelocks_tree); node; node = rb_next(node)) {",
            "\t\twl = rb_entry(node, struct wakelock, node);",
            "\t\tif (wl->ws->active == show_active)",
            "\t\t\tlen += sysfs_emit_at(buf, len, \"%s \", wl->name);",
            "\t}",
            "",
            "\tif (len > 0)",
            "\t\t--len;",
            "",
            "\tlen += sysfs_emit_at(buf, len, \"\\n\");",
            "",
            "\tmutex_unlock(&wakelocks_lock);",
            "\treturn len;",
            "}",
            "static inline bool wakelocks_limit_exceeded(void)",
            "{",
            "\treturn number_of_wakelocks > CONFIG_PM_WAKELOCKS_LIMIT;",
            "}",
            "static inline void increment_wakelocks_number(void)",
            "{",
            "\tnumber_of_wakelocks++;",
            "}",
            "static inline void decrement_wakelocks_number(void)",
            "{",
            "\tnumber_of_wakelocks--;",
            "}",
            "static inline bool wakelocks_limit_exceeded(void) { return false; }",
            "static inline void increment_wakelocks_number(void) {}",
            "static inline void decrement_wakelocks_number(void) {}",
            "static inline void wakelocks_lru_add(struct wakelock *wl)",
            "{",
            "\tlist_add(&wl->lru, &wakelocks_lru_list);",
            "}",
            "static inline void wakelocks_lru_most_recent(struct wakelock *wl)",
            "{",
            "\tlist_move(&wl->lru, &wakelocks_lru_list);",
            "}",
            "static void __wakelocks_gc(struct work_struct *work)",
            "{",
            "\tstruct wakelock *wl, *aux;",
            "\tktime_t now;",
            "",
            "\tmutex_lock(&wakelocks_lock);",
            "",
            "\tnow = ktime_get();",
            "\tlist_for_each_entry_safe_reverse(wl, aux, &wakelocks_lru_list, lru) {",
            "\t\tu64 idle_time_ns;",
            "\t\tbool active;",
            "",
            "\t\tspin_lock_irq(&wl->ws->lock);",
            "\t\tidle_time_ns = ktime_to_ns(ktime_sub(now, wl->ws->last_time));",
            "\t\tactive = wl->ws->active;",
            "\t\tspin_unlock_irq(&wl->ws->lock);",
            "",
            "\t\tif (idle_time_ns < ((u64)WL_GC_TIME_SEC * NSEC_PER_SEC))",
            "\t\t\tbreak;",
            "",
            "\t\tif (!active) {",
            "\t\t\twakeup_source_unregister(wl->ws);",
            "\t\t\trb_erase(&wl->node, &wakelocks_tree);",
            "\t\t\tlist_del(&wl->lru);",
            "\t\t\tkfree(wl->name);",
            "\t\t\tkfree(wl);",
            "\t\t\tdecrement_wakelocks_number();",
            "\t\t}",
            "\t}",
            "\twakelocks_gc_count = 0;",
            "",
            "\tmutex_unlock(&wakelocks_lock);",
            "}",
            "static void wakelocks_gc(void)",
            "{",
            "\tif (++wakelocks_gc_count <= WL_GC_COUNT_MAX)",
            "\t\treturn;",
            "",
            "\tschedule_work(&wakelock_work);",
            "}",
            "static inline void wakelocks_lru_add(struct wakelock *wl) {}",
            "static inline void wakelocks_lru_most_recent(struct wakelock *wl) {}",
            "static inline void wakelocks_gc(void) {}",
            "int pm_wake_lock(const char *buf)",
            "{",
            "\tconst char *str = buf;",
            "\tstruct wakelock *wl;",
            "\tu64 timeout_ns = 0;",
            "\tsize_t len;",
            "\tint ret = 0;",
            "",
            "\tif (!capable(CAP_BLOCK_SUSPEND))",
            "\t\treturn -EPERM;",
            "",
            "\twhile (*str && !isspace(*str))",
            "\t\tstr++;",
            "",
            "\tlen = str - buf;",
            "\tif (!len)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (*str && *str != '\\n') {",
            "\t\t/* Find out if there's a valid timeout string appended. */",
            "\t\tret = kstrtou64(skip_spaces(str), 10, &timeout_ns);",
            "\t\tif (ret)",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tmutex_lock(&wakelocks_lock);",
            "",
            "\twl = wakelock_lookup_add(buf, len, true);",
            "\tif (IS_ERR(wl)) {",
            "\t\tret = PTR_ERR(wl);",
            "\t\tgoto out;",
            "\t}",
            "\tif (timeout_ns) {",
            "\t\tu64 timeout_ms = timeout_ns + NSEC_PER_MSEC - 1;",
            "",
            "\t\tdo_div(timeout_ms, NSEC_PER_MSEC);",
            "\t\t__pm_wakeup_event(wl->ws, timeout_ms);",
            "\t} else {",
            "\t\t__pm_stay_awake(wl->ws);",
            "\t}",
            "",
            "\twakelocks_lru_most_recent(wl);",
            "",
            " out:",
            "\tmutex_unlock(&wakelocks_lock);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "pm_show_wakelocks, wakelocks_limit_exceeded, increment_wakelocks_number, decrement_wakelocks_number, wakelocks_limit_exceeded, increment_wakelocks_number, decrement_wakelocks_number, wakelocks_lru_add, wakelocks_lru_most_recent, __wakelocks_gc, wakelocks_gc, wakelocks_lru_add, wakelocks_lru_most_recent, wakelocks_gc, pm_wake_lock",
          "description": "实现唤醒锁状态展示、计数控制、LRU列表维护及垃圾回收逻辑，包含唤醒锁激活/释放接口，通过工作队列异步清理闲置唤醒源",
          "similarity": 0.3944850265979767
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/power/wakelock.c",
          "start_line": 1,
          "end_line": 37,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * kernel/power/wakelock.c",
            " *",
            " * User space wakeup sources support.",
            " *",
            " * Copyright (C) 2012 Rafael J. Wysocki <rjw@sisk.pl>",
            " *",
            " * This code is based on the analogous interface allowing user space to",
            " * manipulate wakelocks on Android.",
            " */",
            "",
            "#include <linux/capability.h>",
            "#include <linux/ctype.h>",
            "#include <linux/device.h>",
            "#include <linux/err.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/list.h>",
            "#include <linux/rbtree.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "",
            "#include \"power.h\"",
            "",
            "static DEFINE_MUTEX(wakelocks_lock);",
            "",
            "struct wakelock {",
            "\tchar\t\t\t*name;",
            "\tstruct rb_node\t\tnode;",
            "\tstruct wakeup_source\t*ws;",
            "#ifdef CONFIG_PM_WAKELOCKS_GC",
            "\tstruct list_head\tlru;",
            "#endif",
            "};",
            "",
            "static struct rb_root wakelocks_tree = RB_ROOT;",
            ""
          ],
          "function_name": null,
          "description": "定义唤醒锁数据结构及其红黑树管理基础，包含名称字段、RB节点、唤醒源指针及LRU链表节点（CONFIG_PM_WAKELOCKS_GC启用时），并初始化红黑树根节点",
          "similarity": 0.3636641502380371
        }
      ]
    },
    {
      "source_file": "kernel/locking/mutex.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:42:50\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\mutex.c`\n\n---\n\n# Linux 内核互斥锁（mutex）实现文档\n\n## 1. 文件概述\n\n`locking/mutex.c` 是 Linux 内核中互斥锁（mutex）的核心实现文件，提供了基于阻塞的互斥同步原语。该文件实现了高效、可睡眠的互斥锁机制，支持自旋优化、锁移交（handoff）、调试功能以及与调度器、死锁检测等子系统的深度集成。互斥锁用于保护临界区，确保同一时间只有一个任务可以持有锁，适用于需要长时间持有锁或可能睡眠的场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `__mutex_init()`：初始化互斥锁对象\n- `mutex_is_locked()`：检查互斥锁是否已被持有\n- `mutex_get_owner()`：获取当前锁持有者的任务指针（仅用于调试）\n- `__mutex_trylock()`：尝试获取互斥锁（非阻塞）\n- `__mutex_trylock_fast()`：快速路径尝试获取未竞争的锁\n- `__mutex_unlock_fast()`：快速路径释放锁\n- `__mutex_lock_slowpath()`：慢速路径获取锁（包含睡眠和等待逻辑）\n- `__mutex_handoff()`：将锁所有权移交给指定任务\n- `__mutex_add_waiter()` / `__mutex_remove_waiter()`：管理等待队列\n\n### 关键数据结构\n\n- `struct mutex`：互斥锁核心结构体\n  - `atomic_long_t owner`：原子存储锁持有者指针和状态标志\n  - `raw_spinlock_t wait_lock`：保护等待队列的自旋锁\n  - `struct list_head wait_list`：等待获取锁的任务队列\n  - `struct optimistic_spin_queue osq`：用于自旋优化的队列（CONFIG_MUTEX_SPIN_ON_OWNER）\n\n### 状态标志位\n\n- `MUTEX_FLAG_WAITERS (0x01)`：表示存在等待者，解锁时需唤醒\n- `MUTEX_FLAG_HANDOFF (0x02)`：表示需要将锁移交给队首等待者\n- `MUTEX_FLAG_PICKUP (0x04)`：表示锁已被移交给特定任务，等待其获取\n\n## 3. 关键实现\n\n### 锁状态编码\n互斥锁的 `owner` 字段采用指针-标志位混合编码：利用 `task_struct` 指针的低 3 位（因内存对齐保证为 0）存储状态标志。这种设计避免了额外的内存访问，提高了原子操作效率。\n\n### 快慢路径分离\n- **快速路径**：针对无竞争场景，直接通过原子比较交换（cmpxchg）获取/释放锁，避免函数调用开销\n- **慢速路径**：处理竞争情况，包含自旋等待、任务阻塞、唤醒等复杂逻辑\n\n### 自适应自旋（Adaptive Spinning）\n在 `CONFIG_MUTEX_SPIN_ON_OWNER` 配置下，当检测到锁持有者正在运行时，当前任务会先自旋等待而非立即睡眠，减少上下文切换开销。使用 OSQ（Optimistic Spin Queue）机制协调多个自旋任务。\n\n### 锁移交机制（Handoff）\n通过 `MUTEX_FLAG_HANDOFF` 和 `MUTEX_FLAG_PICKUP` 标志实现高效的锁移交：\n1. 解锁者设置 `HANDOFF` 标志并唤醒队首等待者\n2. 被唤醒任务在获取锁时检测到 `HANDOFF`，设置 `PICKUP` 标志\n3. 解锁者通过 `__mutex_handoff()` 直接将所有权转移给指定任务\n避免了唤醒后再次竞争的问题，提高实时性。\n\n### 调试支持\n- `CONFIG_DEBUG_MUTEXES`：提供锁状态验证、死锁检测\n- `CONFIG_DETECT_HUNG_TASK_BLOCKER`：集成 hung task 检测，记录阻塞源\n- `lockdep`：通过 `debug_mutex_*` 函数集成锁依赖验证\n\n## 4. 依赖关系\n\n### 头文件依赖\n- `<linux/mutex.h>` / `<linux/ww_mutex.h>`：互斥锁接口定义\n- `<linux/sched/*.h>`：调度器相关功能（睡眠、唤醒、实时任务）\n- `<linux/spinlock.h>`：底层自旋锁实现\n- `<linux/osq_lock.h>`：乐观自旋队列支持\n- `<linux/hung_task.h>`：hung task 检测集成\n- `<trace/events/lock.h>`：锁事件跟踪点\n\n### 子系统交互\n- **调度器**：通过 `schedule()` 实现任务阻塞，`wake_q` 机制批量唤醒\n- **内存管理**：依赖 `task_struct` 的内存对齐特性\n- **实时补丁（PREEMPT_RT）**：非 RT 配置下编译此文件（`#ifndef CONFIG_PREEMPT_RT`）\n- **调试子系统**：与 lockdep、hung task detector 深度集成\n\n## 5. 使用场景\n\n### 典型应用场景\n- **长临界区保护**：当临界区执行时间较长或包含可能睡眠的操作（如内存分配、I/O）\n- **驱动程序同步**：设备驱动中保护硬件寄存器访问或共享数据结构\n- **文件系统操作**：保护 inode、dentry 等元数据结构\n- **内核子系统互斥**：如网络协议栈、块设备层等需要互斥访问的场景\n\n### 使用约束\n- **不可递归**：同一任务重复获取会导致死锁\n- **必须配对使用**：获取锁的任务必须负责释放\n- **禁止中断上下文使用**：因可能睡眠，只能在进程上下文使用\n- **内存生命周期**：锁对象内存不能在持有锁时释放\n\n### 性能考量\n- 无竞争场景：纳秒级延迟（快速路径原子操作）\n- 有竞争场景：微秒级延迟（自旋优化）或毫秒级（任务切换）\n- 适用于中低频竞争场景，高频竞争建议使用读写锁或 RCU",
      "similarity": 0.4390066862106323,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 758,
          "end_line": 862,
          "content": [
            "static int __sched",
            "__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t     struct lockdep_map *nest_lock, unsigned long ip)",
            "{",
            "\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);",
            "}",
            "static int __sched",
            "__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)",
            "{",
            "\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);",
            "}",
            "int ww_mutex_trylock(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)",
            "{",
            "\tif (!ww_ctx)",
            "\t\treturn mutex_trylock(&ww->base);",
            "",
            "\tMUTEX_WARN_ON(ww->base.magic != &ww->base);",
            "",
            "\t/*",
            "\t * Reset the wounded flag after a kill. No other process can",
            "\t * race and wound us here, since they can't have a valid owner",
            "\t * pointer if we don't have any locks held.",
            "\t */",
            "\tif (ww_ctx->acquired == 0)",
            "\t\tww_ctx->wounded = 0;",
            "",
            "\tif (__mutex_trylock(&ww->base)) {",
            "\t\tww_mutex_set_context_fastpath(ww, ww_ctx);",
            "\t\tmutex_acquire_nest(&ww->base.dep_map, 0, 1, &ww_ctx->dep_map, _RET_IP_);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void __sched",
            "mutex_lock_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched",
            "_mutex_lock_nest_lock(struct mutex *lock, struct lockdep_map *nest)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, nest, _RET_IP_);",
            "}",
            "int __sched",
            "mutex_lock_killable_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\treturn __mutex_lock(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);",
            "}",
            "int __sched",
            "mutex_lock_interruptible_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched",
            "mutex_lock_io_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\tint token;",
            "",
            "\tmight_sleep();",
            "",
            "\ttoken = io_schedule_prepare();",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE,",
            "\t\t\t    subclass, NULL, _RET_IP_, NULL, 0);",
            "\tio_schedule_finish(token);",
            "}",
            "static inline int",
            "ww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH",
            "\tunsigned tmp;",
            "",
            "\tif (ctx->deadlock_inject_countdown-- == 0) {",
            "\t\ttmp = ctx->deadlock_inject_interval;",
            "\t\tif (tmp > UINT_MAX/4)",
            "\t\t\ttmp = UINT_MAX;",
            "\t\telse",
            "\t\t\ttmp = tmp*2 + tmp + tmp/2;",
            "",
            "\t\tctx->deadlock_inject_interval = tmp;",
            "\t\tctx->deadlock_inject_countdown = tmp;",
            "\t\tctx->contending_lock = lock;",
            "",
            "\t\tww_mutex_unlock(lock);",
            "",
            "\t\treturn -EDEADLK;",
            "\t}",
            "#endif",
            "",
            "\treturn 0;",
            "}",
            "int __sched",
            "ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tret =  __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE,",
            "\t\t\t       0, _RET_IP_, ctx);",
            "\tif (!ret && ctx && ctx->acquired > 1)",
            "\t\treturn ww_mutex_deadlock_injection(lock, ctx);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__mutex_lock, __ww_mutex_lock, ww_mutex_trylock, mutex_lock_nested, _mutex_lock_nest_lock, mutex_lock_killable_nested, mutex_lock_interruptible_nested, mutex_lock_io_nested, ww_mutex_deadlock_injection, ww_mutex_lock",
          "description": "封装多种锁获取接口，处理嵌套锁、可中断锁及死锁注入逻辑，协调锁持有者与等待者的交互关系。",
          "similarity": 0.45025634765625
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 296,
          "end_line": 406,
          "content": [
            "void __sched mutex_lock(struct mutex *lock)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (!__mutex_trylock_fast(lock))",
            "\t\t__mutex_lock_slowpath(lock);",
            "}",
            "static inline",
            "bool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t\t    struct mutex_waiter *waiter)",
            "{",
            "\tstruct ww_mutex *ww;",
            "",
            "\tww = container_of(lock, struct ww_mutex, base);",
            "",
            "\t/*",
            "\t * If ww->ctx is set the contents are undefined, only",
            "\t * by acquiring wait_lock there is a guarantee that",
            "\t * they are not invalid when reading.",
            "\t *",
            "\t * As such, when deadlock detection needs to be",
            "\t * performed the optimistic spinning cannot be done.",
            "\t *",
            "\t * Check this in every inner iteration because we may",
            "\t * be racing against another thread's ww_mutex_lock.",
            "\t */",
            "\tif (ww_ctx->acquired > 0 && READ_ONCE(ww->ctx))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * If we aren't on the wait list yet, cancel the spin",
            "\t * if there are waiters. We want  to avoid stealing the",
            "\t * lock from a waiter with an earlier stamp, since the",
            "\t * other thread may already own a lock that we also",
            "\t * need.",
            "\t */",
            "\tif (!waiter && (atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Similarly, stop spinning if we are no longer the",
            "\t * first waiter.",
            "\t */",
            "\tif (waiter && !__mutex_waiter_is_first(lock, waiter))",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}",
            "static noinline",
            "bool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,",
            "\t\t\t struct ww_acquire_ctx *ww_ctx, struct mutex_waiter *waiter)",
            "{",
            "\tbool ret = true;",
            "",
            "\tlockdep_assert_preemption_disabled();",
            "",
            "\twhile (__mutex_owner(lock) == owner) {",
            "\t\t/*",
            "\t\t * Ensure we emit the owner->on_cpu, dereference _after_",
            "\t\t * checking lock->owner still matches owner. And we already",
            "\t\t * disabled preemption which is equal to the RCU read-side",
            "\t\t * crital section in optimistic spinning code. Thus the",
            "\t\t * task_strcut structure won't go away during the spinning",
            "\t\t * period",
            "\t\t */",
            "\t\tbarrier();",
            "",
            "\t\t/*",
            "\t\t * Use vcpu_is_preempted to detect lock holder preemption issue.",
            "\t\t */",
            "\t\tif (!owner_on_cpu(owner) || need_resched()) {",
            "\t\t\tret = false;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tif (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {",
            "\t\t\tret = false;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tcpu_relax();",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "static inline int mutex_can_spin_on_owner(struct mutex *lock)",
            "{",
            "\tstruct task_struct *owner;",
            "\tint retval = 1;",
            "",
            "\tlockdep_assert_preemption_disabled();",
            "",
            "\tif (need_resched())",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * We already disabled preemption which is equal to the RCU read-side",
            "\t * crital section in optimistic spinning code. Thus the task_strcut",
            "\t * structure won't go away during the spinning period.",
            "\t */",
            "\towner = __mutex_owner(lock);",
            "\tif (owner)",
            "\t\tretval = owner_on_cpu(owner);",
            "",
            "\t/*",
            "\t * If lock->owner is not set, the mutex has been released. Return true",
            "\t * such that we'll trylock in the spin path, which is a faster option",
            "\t * than the blocking slow path.",
            "\t */",
            "\treturn retval;",
            "}"
          ],
          "function_name": "mutex_lock, ww_mutex_spin_on_owner, mutex_spin_on_owner, mutex_can_spin_on_owner",
          "description": "提供自旋锁优化策略，通过检查当前持有者状态决定是否继续自旋，支持死锁检测和抢占式调度。",
          "similarity": 0.42833203077316284
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 455,
          "end_line": 722,
          "content": [
            "static __always_inline bool",
            "mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t      struct mutex_waiter *waiter)",
            "{",
            "\tif (!waiter) {",
            "\t\t/*",
            "\t\t * The purpose of the mutex_can_spin_on_owner() function is",
            "\t\t * to eliminate the overhead of osq_lock() and osq_unlock()",
            "\t\t * in case spinning isn't possible. As a waiter-spinner",
            "\t\t * is not going to take OSQ lock anyway, there is no need",
            "\t\t * to call mutex_can_spin_on_owner().",
            "\t\t */",
            "\t\tif (!mutex_can_spin_on_owner(lock))",
            "\t\t\tgoto fail;",
            "",
            "\t\t/*",
            "\t\t * In order to avoid a stampede of mutex spinners trying to",
            "\t\t * acquire the mutex all at once, the spinners need to take a",
            "\t\t * MCS (queued) lock first before spinning on the owner field.",
            "\t\t */",
            "\t\tif (!osq_lock(&lock->osq))",
            "\t\t\tgoto fail;",
            "\t}",
            "",
            "\tfor (;;) {",
            "\t\tstruct task_struct *owner;",
            "",
            "\t\t/* Try to acquire the mutex... */",
            "\t\towner = __mutex_trylock_or_owner(lock);",
            "\t\tif (!owner)",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * There's an owner, wait for it to either",
            "\t\t * release the lock or go to sleep.",
            "\t\t */",
            "\t\tif (!mutex_spin_on_owner(lock, owner, ww_ctx, waiter))",
            "\t\t\tgoto fail_unlock;",
            "",
            "\t\t/*",
            "\t\t * The cpu_relax() call is a compiler barrier which forces",
            "\t\t * everything in this loop to be re-loaded. We don't need",
            "\t\t * memory barriers as we'll eventually observe the right",
            "\t\t * values at the cost of a few extra spins.",
            "\t\t */",
            "\t\tcpu_relax();",
            "\t}",
            "",
            "\tif (!waiter)",
            "\t\tosq_unlock(&lock->osq);",
            "",
            "\treturn true;",
            "",
            "",
            "fail_unlock:",
            "\tif (!waiter)",
            "\t\tosq_unlock(&lock->osq);",
            "",
            "fail:",
            "\t/*",
            "\t * If we fell out of the spin path because of need_resched(),",
            "\t * reschedule now, before we try-lock the mutex. This avoids getting",
            "\t * scheduled out right after we obtained the mutex.",
            "\t */",
            "\tif (need_resched()) {",
            "\t\t/*",
            "\t\t * We _should_ have TASK_RUNNING here, but just in case",
            "\t\t * we do not, make it so, otherwise we might get stuck.",
            "\t\t */",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t\tschedule_preempt_disabled();",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static __always_inline bool",
            "mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t      struct mutex_waiter *waiter)",
            "{",
            "\treturn false;",
            "}",
            "void __sched mutex_unlock(struct mutex *lock)",
            "{",
            "#ifndef CONFIG_DEBUG_LOCK_ALLOC",
            "\tif (__mutex_unlock_fast(lock))",
            "\t\treturn;",
            "#endif",
            "\t__mutex_unlock_slowpath(lock, _RET_IP_);",
            "}",
            "void __sched ww_mutex_unlock(struct ww_mutex *lock)",
            "{",
            "\t__ww_mutex_unlock(lock);",
            "\tmutex_unlock(&lock->base);",
            "}",
            "static __always_inline int __sched",
            "__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t\t    struct lockdep_map *nest_lock, unsigned long ip,",
            "\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)",
            "{",
            "\tstruct mutex_waiter waiter;",
            "\tstruct ww_mutex *ww;",
            "\tint ret;",
            "",
            "\tif (!use_ww_ctx)",
            "\t\tww_ctx = NULL;",
            "",
            "\tmight_sleep();",
            "",
            "\tMUTEX_WARN_ON(lock->magic != lock);",
            "",
            "\tww = container_of(lock, struct ww_mutex, base);",
            "\tif (ww_ctx) {",
            "\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))",
            "\t\t\treturn -EALREADY;",
            "",
            "\t\t/*",
            "\t\t * Reset the wounded flag after a kill. No other process can",
            "\t\t * race and wound us here since they can't have a valid owner",
            "\t\t * pointer if we don't have any locks held.",
            "\t\t */",
            "\t\tif (ww_ctx->acquired == 0)",
            "\t\t\tww_ctx->wounded = 0;",
            "",
            "#ifdef CONFIG_DEBUG_LOCK_ALLOC",
            "\t\tnest_lock = &ww_ctx->dep_map;",
            "#endif",
            "\t}",
            "",
            "\tpreempt_disable();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);",
            "",
            "\ttrace_contention_begin(lock, LCB_F_MUTEX | LCB_F_SPIN);",
            "\tif (__mutex_trylock(lock) ||",
            "\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {",
            "\t\t/* got the lock, yay! */",
            "\t\tlock_acquired(&lock->dep_map, ip);",
            "\t\tif (ww_ctx)",
            "\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);",
            "\t\ttrace_contention_end(lock, 0);",
            "\t\tpreempt_enable();",
            "\t\treturn 0;",
            "\t}",
            "",
            "\traw_spin_lock(&lock->wait_lock);",
            "\t/*",
            "\t * After waiting to acquire the wait_lock, try again.",
            "\t */",
            "\tif (__mutex_trylock(lock)) {",
            "\t\tif (ww_ctx)",
            "\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);",
            "",
            "\t\tgoto skip_wait;",
            "\t}",
            "",
            "\tdebug_mutex_lock_common(lock, &waiter);",
            "\twaiter.task = current;",
            "\tif (use_ww_ctx)",
            "\t\twaiter.ww_ctx = ww_ctx;",
            "",
            "\tlock_contended(&lock->dep_map, ip);",
            "",
            "\tif (!use_ww_ctx) {",
            "\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */",
            "\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);",
            "\t} else {",
            "\t\t/*",
            "\t\t * Add in stamp order, waking up waiters that must kill",
            "\t\t * themselves.",
            "\t\t */",
            "\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);",
            "\t\tif (ret)",
            "\t\t\tgoto err_early_kill;",
            "\t}",
            "",
            "\tset_current_state(state);",
            "\ttrace_contention_begin(lock, LCB_F_MUTEX);",
            "\tfor (;;) {",
            "\t\tbool first;",
            "",
            "\t\t/*",
            "\t\t * Once we hold wait_lock, we're serialized against",
            "\t\t * mutex_unlock() handing the lock off to us, do a trylock",
            "\t\t * before testing the error conditions to make sure we pick up",
            "\t\t * the handoff.",
            "\t\t */",
            "\t\tif (__mutex_trylock(lock))",
            "\t\t\tgoto acquired;",
            "",
            "\t\t/*",
            "\t\t * Check for signals and kill conditions while holding",
            "\t\t * wait_lock. This ensures the lock cancellation is ordered",
            "\t\t * against mutex_unlock() and wake-ups do not go missing.",
            "\t\t */",
            "\t\tif (signal_pending_state(state, current)) {",
            "\t\t\tret = -EINTR;",
            "\t\t\tgoto err;",
            "\t\t}",
            "",
            "\t\tif (ww_ctx) {",
            "\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);",
            "\t\t\tif (ret)",
            "\t\t\t\tgoto err;",
            "\t\t}",
            "",
            "\t\traw_spin_unlock(&lock->wait_lock);",
            "\t\tschedule_preempt_disabled();",
            "",
            "\t\tfirst = __mutex_waiter_is_first(lock, &waiter);",
            "",
            "\t\tset_current_state(state);",
            "\t\t/*",
            "\t\t * Here we order against unlock; we must either see it change",
            "\t\t * state back to RUNNING and fall through the next schedule(),",
            "\t\t * or we must see its unlock and acquire.",
            "\t\t */",
            "\t\tif (__mutex_trylock_or_handoff(lock, first))",
            "\t\t\tbreak;",
            "",
            "\t\tif (first) {",
            "\t\t\ttrace_contention_begin(lock, LCB_F_MUTEX | LCB_F_SPIN);",
            "\t\t\tif (mutex_optimistic_spin(lock, ww_ctx, &waiter))",
            "\t\t\t\tbreak;",
            "\t\t\ttrace_contention_begin(lock, LCB_F_MUTEX);",
            "\t\t}",
            "",
            "\t\traw_spin_lock(&lock->wait_lock);",
            "\t}",
            "\traw_spin_lock(&lock->wait_lock);",
            "acquired:",
            "\t__set_current_state(TASK_RUNNING);",
            "",
            "\tif (ww_ctx) {",
            "\t\t/*",
            "\t\t * Wound-Wait; we stole the lock (!first_waiter), check the",
            "\t\t * waiters as anyone might want to wound us.",
            "\t\t */",
            "\t\tif (!ww_ctx->is_wait_die &&",
            "\t\t    !__mutex_waiter_is_first(lock, &waiter))",
            "\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);",
            "\t}",
            "",
            "\t__mutex_remove_waiter(lock, &waiter);",
            "",
            "\tdebug_mutex_free_waiter(&waiter);",
            "",
            "skip_wait:",
            "\t/* got the lock - cleanup and rejoice! */",
            "\tlock_acquired(&lock->dep_map, ip);",
            "\ttrace_contention_end(lock, 0);",
            "",
            "\tif (ww_ctx)",
            "\t\tww_mutex_lock_acquired(ww, ww_ctx);",
            "",
            "\traw_spin_unlock(&lock->wait_lock);",
            "\tpreempt_enable();",
            "\treturn 0;",
            "",
            "err:",
            "\t__set_current_state(TASK_RUNNING);",
            "\t__mutex_remove_waiter(lock, &waiter);",
            "err_early_kill:",
            "\ttrace_contention_end(lock, ret);",
            "\traw_spin_unlock(&lock->wait_lock);",
            "\tdebug_mutex_free_waiter(&waiter);",
            "\tmutex_release(&lock->dep_map, ip);",
            "\tpreempt_enable();",
            "\treturn ret;",
            "}"
          ],
          "function_name": "mutex_optimistic_spin, mutex_optimistic_spin, mutex_unlock, ww_mutex_unlock, __mutex_lock_common",
          "description": "实现乐观自旋逻辑和锁解除操作，通过原子操作和同步机制管理锁竞争，支持带资源检查的锁操作。",
          "similarity": 0.42603611946105957
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 895,
          "end_line": 996,
          "content": [
            "int __sched",
            "ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tret = __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE,",
            "\t\t\t      0, _RET_IP_, ctx);",
            "",
            "\tif (!ret && ctx && ctx->acquired > 1)",
            "\t\treturn ww_mutex_deadlock_injection(lock, ctx);",
            "",
            "\treturn ret;",
            "}",
            "static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)",
            "{",
            "\tstruct task_struct *next = NULL;",
            "\tDEFINE_WAKE_Q(wake_q);",
            "\tunsigned long owner;",
            "",
            "\tmutex_release(&lock->dep_map, ip);",
            "",
            "\t/*",
            "\t * Release the lock before (potentially) taking the spinlock such that",
            "\t * other contenders can get on with things ASAP.",
            "\t *",
            "\t * Except when HANDOFF, in that case we must not clear the owner field,",
            "\t * but instead set it to the top waiter.",
            "\t */",
            "\towner = atomic_long_read(&lock->owner);",
            "\tfor (;;) {",
            "\t\tMUTEX_WARN_ON(__owner_task(owner) != current);",
            "\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);",
            "",
            "\t\tif (owner & MUTEX_FLAG_HANDOFF)",
            "\t\t\tbreak;",
            "",
            "\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, __owner_flags(owner))) {",
            "\t\t\tif (owner & MUTEX_FLAG_WAITERS)",
            "\t\t\t\tbreak;",
            "",
            "\t\t\treturn;",
            "\t\t}",
            "\t}",
            "",
            "\traw_spin_lock(&lock->wait_lock);",
            "\tdebug_mutex_unlock(lock);",
            "\tif (!list_empty(&lock->wait_list)) {",
            "\t\t/* get the first entry from the wait-list: */",
            "\t\tstruct mutex_waiter *waiter =",
            "\t\t\tlist_first_entry(&lock->wait_list,",
            "\t\t\t\t\t struct mutex_waiter, list);",
            "",
            "\t\tnext = waiter->task;",
            "",
            "\t\tdebug_mutex_wake_waiter(lock, waiter);",
            "\t\twake_q_add(&wake_q, next);",
            "\t}",
            "",
            "\tif (owner & MUTEX_FLAG_HANDOFF)",
            "\t\t__mutex_handoff(lock, next);",
            "",
            "\traw_spin_unlock(&lock->wait_lock);",
            "",
            "\twake_up_q(&wake_q);",
            "}",
            "int __sched mutex_lock_interruptible(struct mutex *lock)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(lock))",
            "\t\treturn 0;",
            "",
            "\treturn __mutex_lock_interruptible_slowpath(lock);",
            "}",
            "int __sched mutex_lock_killable(struct mutex *lock)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(lock))",
            "\t\treturn 0;",
            "",
            "\treturn __mutex_lock_killable_slowpath(lock);",
            "}",
            "void __sched mutex_lock_io(struct mutex *lock)",
            "{",
            "\tint token;",
            "",
            "\ttoken = io_schedule_prepare();",
            "\tmutex_lock(lock);",
            "\tio_schedule_finish(token);",
            "}",
            "static noinline void __sched",
            "__mutex_lock_slowpath(struct mutex *lock)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "static noinline int __sched",
            "__mutex_lock_killable_slowpath(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);",
            "}"
          ],
          "function_name": "ww_mutex_lock_interruptible, __mutex_unlock_slowpath, mutex_lock_interruptible, mutex_lock_killable, mutex_lock_io, __mutex_lock_slowpath, __mutex_lock_killable_slowpath",
          "description": "实现带死锁检测的递归互斥锁中断获取逻辑，处理锁状态转换、唤醒等待线程及异常注入场景",
          "similarity": 0.4089466333389282
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 46,
          "end_line": 151,
          "content": [
            "void",
            "__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)",
            "{",
            "\tatomic_long_set(&lock->owner, 0);",
            "\traw_spin_lock_init(&lock->wait_lock);",
            "\tINIT_LIST_HEAD(&lock->wait_list);",
            "#ifdef CONFIG_MUTEX_SPIN_ON_OWNER",
            "\tosq_lock_init(&lock->osq);",
            "#endif",
            "",
            "\tdebug_mutex_init(lock, name, key);",
            "}",
            "bool mutex_is_locked(struct mutex *lock)",
            "{",
            "\treturn __mutex_owner(lock) != NULL;",
            "}",
            "static inline unsigned long __owner_flags(unsigned long owner)",
            "{",
            "\treturn owner & MUTEX_FLAGS;",
            "}",
            "unsigned long mutex_get_owner(struct mutex *lock)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\treturn (unsigned long)__owner_task(owner);",
            "}",
            "static inline bool __mutex_trylock_or_handoff(struct mutex *lock, bool handoff)",
            "{",
            "\treturn !__mutex_trylock_common(lock, handoff);",
            "}",
            "static inline bool __mutex_trylock(struct mutex *lock)",
            "{",
            "\treturn !__mutex_trylock_common(lock, false);",
            "}",
            "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "\tunsigned long zero = 0UL;",
            "",
            "\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "static __always_inline bool __mutex_unlock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "",
            "\treturn atomic_long_try_cmpxchg_release(&lock->owner, &curr, 0UL);",
            "}",
            "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_or(flag, &lock->owner);",
            "}",
            "static inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_andnot(flag, &lock->owner);",
            "}",
            "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;",
            "}",
            "static void",
            "__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,",
            "\t\t   struct list_head *list)",
            "{",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_set_blocker(lock, BLOCKER_TYPE_MUTEX);",
            "#endif",
            "\tdebug_mutex_add_waiter(lock, waiter, current);",
            "",
            "\tlist_add_tail(&waiter->list, list);",
            "\tif (__mutex_waiter_is_first(lock, waiter))",
            "\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);",
            "}",
            "static void",
            "__mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\tlist_del(&waiter->list);",
            "\tif (likely(list_empty(&lock->wait_list)))",
            "\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);",
            "",
            "\tdebug_mutex_remove_waiter(lock, waiter, current);",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_clear_blocker();",
            "#endif",
            "}",
            "static void __mutex_handoff(struct mutex *lock, struct task_struct *task)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\tfor (;;) {",
            "\t\tunsigned long new;",
            "",
            "\t\tMUTEX_WARN_ON(__owner_task(owner) != current);",
            "\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);",
            "",
            "\t\tnew = (owner & MUTEX_FLAG_WAITERS);",
            "\t\tnew |= (unsigned long)task;",
            "\t\tif (task)",
            "\t\t\tnew |= MUTEX_FLAG_PICKUP;",
            "",
            "\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, new))",
            "\t\t\tbreak;",
            "\t}",
            "}"
          ],
          "function_name": "__mutex_init, mutex_is_locked, __owner_flags, mutex_get_owner, __mutex_trylock_or_handoff, __mutex_trylock, __mutex_trylock_fast, __mutex_unlock_fast, __mutex_set_flag, __mutex_clear_flag, __mutex_waiter_is_first, __mutex_add_waiter, __mutex_remove_waiter, __mutex_handoff",
          "description": "实现互斥锁核心操作，包括初始化、状态检查、快速尝试加锁、标志位操作及等待者链表管理。",
          "similarity": 0.39227139949798584
        }
      ]
    }
  ]
}