{
  "query": "file system hierarchy",
  "timestamp": "2025-12-25 23:27:41",
  "retrieved_files": [
    {
      "source_file": "kernel/bpf/hashtab.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:10:56\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\hashtab.c`\n\n---\n\n# bpf/hashtab.c 技术文档\n\n## 1. 文件概述\n\n`bpf/hashtab.c` 是 Linux 内核中 BPF（Berkeley Packet Filter）子系统的核心实现文件之一，负责提供基于哈希表（hash table）的 BPF map 类型支持。该文件实现了多种 BPF map 类型，包括普通哈希表（`BPF_MAP_TYPE_HASH`）、LRU 哈希表（`BPF_MAP_TYPE_LRU_HASH`）、每 CPU 哈希表（`BPF_MAP_TYPE_PERCPU_HASH`）及其 LRU 变体。它支持预分配（pre-allocated）和动态分配（non-preallocated）两种内存管理模式，并集成了 BPF 内存分配器（`bpf_mem_alloc`）、LRU 驱逐机制、每 CPU 自由列表（percpu freelist）等高级特性，以满足高性能、低延迟的 BPF 程序需求。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct bucket`**  \n  哈希桶结构，包含一个 `hlist_nulls_head` 链表头和一个 `raw_spinlock_t` 原始自旋锁，用于保护桶内元素的并发访问。\n\n- **`struct bpf_htab`**  \n  BPF 哈希表的主控制结构，继承自 `struct bpf_map`，包含：\n  - 桶数组指针 `buckets`\n  - 元素存储区 `elems`\n  - 内存分配器 `ma`（主）和 `pcpu_ma`（每 CPU）\n  - LRU 或 percpu_freelist 联合体\n  - 元素计数器（`pcount` 或 `count`）\n  - 哈希种子 `hashrnd`\n  - 锁依赖类键 `lockdep_key`\n  - 每 CPU 锁状态数组 `map_locked`（用于防止递归）\n\n- **`struct htab_elem`**  \n  哈希表元素结构，包含：\n  - 哈希链表节点 `hash_node`\n  - LRU 节点或自由列表节点\n  - 指向每 CPU 指针的指针（用于 per-CPU map）\n  - 哈希值 `hash`\n  - 可变长键 `key[]`（后接值或 per-CPU 指针）\n\n### 关键辅助函数\n\n- `htab_is_prealloc()`：判断是否为预分配模式\n- `htab_is_lru()` / `htab_is_percpu()`：判断 map 类型是否为 LRU 或 per-CPU\n- `htab_init_buckets()`：初始化所有哈希桶\n- `htab_lock_bucket()` / `htab_unlock_bucket()`：带递归保护的桶锁操作\n- `htab_elem_set_ptr()` / `htab_elem_get_ptr()`：操作 per-CPU 指针\n- `get_htab_elem()`：从预分配区域获取第 i 个元素\n- `htab_has_extra_elems()`：判断是否包含额外元素（用于 per-CPU 扩展）\n- `htab_free_prealloced_timers_and_wq()`：释放预分配元素中的 BPF 定时器和工作队列资源\n\n### 批量操作宏\n\n- `BATCH_OPS(_name)`：定义批量操作函数指针，如 `map_lookup_batch`、`map_update_batch` 等。\n\n## 3. 关键实现\n\n### 并发控制与死锁预防\n\n- 使用 **原始自旋锁（`raw_spinlock_t`）** 保护每个哈希桶，确保在任意上下文（如 kprobe、perf、tracepoint）中安全使用。\n- 引入 **每 CPU 递归计数器 `map_locked[]`**，防止 BPF 程序在持有桶锁时再次进入（例如通过 `sys_bpf()` 或嵌套 BPF 调用），避免死锁。\n- 在 `PREEMPT_RT` 实时内核上，由于普通自旋锁可能睡眠，必须使用 `raw_spinlock` 以保证原子性；结合 `bpf_mem_alloc` 后，即使非预分配模式也可安全使用原始锁。\n\n### 内存管理\n\n- **预分配模式（`BPF_F_NO_PREALLOC` 未设置）**：启动时一次性分配所有元素，使用 `pcpu_freelist` 管理空闲元素。\n- **非预分配模式**：按需通过 `bpf_mem_alloc` 动态分配元素，支持 NUMA 感知和内存回收。\n- **Per-CPU 支持**：对于 `PERCPU_HASH` 类型，每个键对应一个 per-CPU 值数组，通过 `htab_elem_get_ptr()` 访问。\n\n### LRU 驱逐机制\n\n- 当 map 类型为 `LRU_HASH` 或 `LRU_PERCPU_HASH` 时，使用 `bpf_lru` 子系统管理元素生命周期，自动驱逐最近最少使用的条目以维持 `max_entries` 限制。\n\n### 扩展字段支持\n\n- 支持 BTF（BPF Type Format）描述的复杂值类型，如 `BPF_TIMER` 和 `BPF_WORKQUEUE`，在销毁 map 时自动释放相关资源（见 `htab_free_prealloced_timers_and_wq`）。\n\n### 哈希与对齐\n\n- 使用 `jhash` 算法计算键的哈希值，并通过 `hashrnd` 引入随机种子防止哈希碰撞攻击。\n- 键和值之间按 8 字节对齐（`__aligned(8)`），确保 per-CPU 指针正确对齐。\n\n## 4. 依赖关系\n\n- **内核头文件**：\n  - `<linux/bpf.h>`、`<linux/btf.h>`：BPF 和 BTF 核心接口\n  - `<linux/jhash.h>`：哈希函数\n  - `<linux/rculist_nulls.h>`：RCU 安全的空指针链表\n  - `<linux/percpu_freelist.h>`、`<linux/bpf_lru_list.h>`：内存管理子系统\n  - `<linux/bpf_mem_alloc.h>`：BPF 专用内存分配器\n\n- **内部模块**：\n  - `map_in_map.h`：支持 map-in-map 功能\n  - `bpf_lru_list.c`：LRU 驱逐实现\n  - `percpu_freelist.c`：每 CPU 自由列表管理\n\n- **BPF 子系统**：\n  - 与 `bpf_map` 通用框架集成，通过 `bpf_map_ops` 注册操作函数\n  - 依赖 `bpf_prog_active` 机制防止 BPF 递归\n\n## 5. 使用场景\n\n- **网络数据包过滤与监控**：eBPF 程序使用 `BPF_MAP_TYPE_HASH` 存储连接状态、统计信息等。\n- **性能分析**：通过 `PERCPU_HASH` 收集每 CPU 的性能计数器，避免锁竞争。\n- **资源限制与缓存**：`LRU_HASH` 用于实现有界缓存（如 DNS 缓存、会话表），自动淘汰旧条目。\n- **内核跟踪**：kprobe、tracepoint 等 attach 的 BPF 程序频繁读写哈希表，要求低延迟和高并发。\n- **用户空间交互**：通过 `bpf(2)` 系统调用进行 map 的创建、更新、查询和删除，支持批量操作提升效率。\n- **高级 BPF 功能**：支持包含定时器（`bpf_timer`）或工作队列（`bpf_workqueue`）的复杂 map 值类型，用于异步任务调度。",
      "similarity": 0.5961530804634094,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 1,
          "end_line": 131,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/* Copyright (c) 2011-2014 PLUMgrid, http://plumgrid.com",
            " * Copyright (c) 2016 Facebook",
            " */",
            "#include <linux/bpf.h>",
            "#include <linux/btf.h>",
            "#include <linux/jhash.h>",
            "#include <linux/filter.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/random.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/btf_ids.h>",
            "#include \"percpu_freelist.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"map_in_map.h\"",
            "#include <linux/bpf_mem_alloc.h>",
            "",
            "#define HTAB_CREATE_FLAG_MASK\t\t\t\t\t\t\\",
            "\t(BPF_F_NO_PREALLOC | BPF_F_NO_COMMON_LRU | BPF_F_NUMA_NODE |\t\\",
            "\t BPF_F_ACCESS_MASK | BPF_F_ZERO_SEED)",
            "",
            "#define BATCH_OPS(_name)\t\t\t\\",
            "\t.map_lookup_batch =\t\t\t\\",
            "\t_name##_map_lookup_batch,\t\t\\",
            "\t.map_lookup_and_delete_batch =\t\t\\",
            "\t_name##_map_lookup_and_delete_batch,\t\\",
            "\t.map_update_batch =\t\t\t\\",
            "\tgeneric_map_update_batch,\t\t\\",
            "\t.map_delete_batch =\t\t\t\\",
            "\tgeneric_map_delete_batch",
            "",
            "/*",
            " * The bucket lock has two protection scopes:",
            " *",
            " * 1) Serializing concurrent operations from BPF programs on different",
            " *    CPUs",
            " *",
            " * 2) Serializing concurrent operations from BPF programs and sys_bpf()",
            " *",
            " * BPF programs can execute in any context including perf, kprobes and",
            " * tracing. As there are almost no limits where perf, kprobes and tracing",
            " * can be invoked from the lock operations need to be protected against",
            " * deadlocks. Deadlocks can be caused by recursion and by an invocation in",
            " * the lock held section when functions which acquire this lock are invoked",
            " * from sys_bpf(). BPF recursion is prevented by incrementing the per CPU",
            " * variable bpf_prog_active, which prevents BPF programs attached to perf",
            " * events, kprobes and tracing to be invoked before the prior invocation",
            " * from one of these contexts completed. sys_bpf() uses the same mechanism",
            " * by pinning the task to the current CPU and incrementing the recursion",
            " * protection across the map operation.",
            " *",
            " * This has subtle implications on PREEMPT_RT. PREEMPT_RT forbids certain",
            " * operations like memory allocations (even with GFP_ATOMIC) from atomic",
            " * contexts. This is required because even with GFP_ATOMIC the memory",
            " * allocator calls into code paths which acquire locks with long held lock",
            " * sections. To ensure the deterministic behaviour these locks are regular",
            " * spinlocks, which are converted to 'sleepable' spinlocks on RT. The only",
            " * true atomic contexts on an RT kernel are the low level hardware",
            " * handling, scheduling, low level interrupt handling, NMIs etc. None of",
            " * these contexts should ever do memory allocations.",
            " *",
            " * As regular device interrupt handlers and soft interrupts are forced into",
            " * thread context, the existing code which does",
            " *   spin_lock*(); alloc(GFP_ATOMIC); spin_unlock*();",
            " * just works.",
            " *",
            " * In theory the BPF locks could be converted to regular spinlocks as well,",
            " * but the bucket locks and percpu_freelist locks can be taken from",
            " * arbitrary contexts (perf, kprobes, tracepoints) which are required to be",
            " * atomic contexts even on RT. Before the introduction of bpf_mem_alloc,",
            " * it is only safe to use raw spinlock for preallocated hash map on a RT kernel,",
            " * because there is no memory allocation within the lock held sections. However",
            " * after hash map was fully converted to use bpf_mem_alloc, there will be",
            " * non-synchronous memory allocation for non-preallocated hash map, so it is",
            " * safe to always use raw spinlock for bucket lock.",
            " */",
            "struct bucket {",
            "\tstruct hlist_nulls_head head;",
            "\traw_spinlock_t raw_lock;",
            "};",
            "",
            "#define HASHTAB_MAP_LOCK_COUNT 8",
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)",
            "",
            "struct bpf_htab {",
            "\tstruct bpf_map map;",
            "\tstruct bpf_mem_alloc ma;",
            "\tstruct bpf_mem_alloc pcpu_ma;",
            "\tstruct bucket *buckets;",
            "\tvoid *elems;",
            "\tunion {",
            "\t\tstruct pcpu_freelist freelist;",
            "\t\tstruct bpf_lru lru;",
            "\t};",
            "\tstruct htab_elem *__percpu *extra_elems;",
            "\t/* number of elements in non-preallocated hashtable are kept",
            "\t * in either pcount or count",
            "\t */",
            "\tstruct percpu_counter pcount;",
            "\tatomic_t count;",
            "\tbool use_percpu_counter;",
            "\tu32 n_buckets;\t/* number of hash buckets */",
            "\tu32 elem_size;\t/* size of each element in bytes */",
            "\tu32 hashrnd;",
            "\tstruct lock_class_key lockdep_key;",
            "\tint __percpu *map_locked[HASHTAB_MAP_LOCK_COUNT];",
            "};",
            "",
            "/* each htab element is struct htab_elem + key + value */",
            "struct htab_elem {",
            "\tunion {",
            "\t\tstruct hlist_nulls_node hash_node;",
            "\t\tstruct {",
            "\t\t\tvoid *padding;",
            "\t\t\tunion {",
            "\t\t\t\tstruct pcpu_freelist_node fnode;",
            "\t\t\t\tstruct htab_elem *batch_flink;",
            "\t\t\t};",
            "\t\t};",
            "\t};",
            "\tunion {",
            "\t\t/* pointer to per-cpu pointer */",
            "\t\tvoid *ptr_to_pptr;",
            "\t\tstruct bpf_lru_node lru_node;",
            "\t};",
            "\tu32 hash;",
            "\tchar key[] __aligned(8);",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义BPF哈希表相关的头文件和宏常量，声明bucket结构体及bpf_htab结构体，包含哈希表的桶锁、元素存储、LRU/PCPU管理等核心成员变量，描述了哈希表的并发控制机制和内存分配策略。",
          "similarity": 0.5457566380500793
        },
        {
          "chunk_id": 12,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 1941,
          "end_line": 2043,
          "content": [
            "static int",
            "htab_percpu_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,",
            "\t\t\t     union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,",
            "\t\t\t\t\t\t  false, true);",
            "}",
            "static int",
            "htab_percpu_map_lookup_and_delete_batch(struct bpf_map *map,",
            "\t\t\t\t\tconst union bpf_attr *attr,",
            "\t\t\t\t\tunion bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,",
            "\t\t\t\t\t\t  false, true);",
            "}",
            "static int",
            "htab_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,",
            "\t\t      union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,",
            "\t\t\t\t\t\t  false, false);",
            "}",
            "static int",
            "htab_map_lookup_and_delete_batch(struct bpf_map *map,",
            "\t\t\t\t const union bpf_attr *attr,",
            "\t\t\t\t union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,",
            "\t\t\t\t\t\t  false, false);",
            "}",
            "static int",
            "htab_lru_percpu_map_lookup_batch(struct bpf_map *map,",
            "\t\t\t\t const union bpf_attr *attr,",
            "\t\t\t\t union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,",
            "\t\t\t\t\t\t  true, true);",
            "}",
            "static int",
            "htab_lru_percpu_map_lookup_and_delete_batch(struct bpf_map *map,",
            "\t\t\t\t\t    const union bpf_attr *attr,",
            "\t\t\t\t\t    union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,",
            "\t\t\t\t\t\t  true, true);",
            "}",
            "static int",
            "htab_lru_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,",
            "\t\t\t  union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,",
            "\t\t\t\t\t\t  true, false);",
            "}",
            "static int",
            "htab_lru_map_lookup_and_delete_batch(struct bpf_map *map,",
            "\t\t\t\t     const union bpf_attr *attr,",
            "\t\t\t\t     union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,",
            "\t\t\t\t\t\t  true, false);",
            "}",
            "static int __bpf_hash_map_seq_show(struct seq_file *seq, struct htab_elem *elem)",
            "{",
            "\tstruct bpf_iter_seq_hash_map_info *info = seq->private;",
            "\tu32 roundup_key_size, roundup_value_size;",
            "\tstruct bpf_iter__bpf_map_elem ctx = {};",
            "\tstruct bpf_map *map = info->map;",
            "\tstruct bpf_iter_meta meta;",
            "\tint ret = 0, off = 0, cpu;",
            "\tstruct bpf_prog *prog;",
            "\tvoid __percpu *pptr;",
            "",
            "\tmeta.seq = seq;",
            "\tprog = bpf_iter_get_info(&meta, elem == NULL);",
            "\tif (prog) {",
            "\t\tctx.meta = &meta;",
            "\t\tctx.map = info->map;",
            "\t\tif (elem) {",
            "\t\t\troundup_key_size = round_up(map->key_size, 8);",
            "\t\t\tctx.key = elem->key;",
            "\t\t\tif (!info->percpu_value_buf) {",
            "\t\t\t\tctx.value = elem->key + roundup_key_size;",
            "\t\t\t} else {",
            "\t\t\t\troundup_value_size = round_up(map->value_size, 8);",
            "\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);",
            "\t\t\t\tfor_each_possible_cpu(cpu) {",
            "\t\t\t\t\tcopy_map_value_long(map, info->percpu_value_buf + off,",
            "\t\t\t\t\t\t\t    per_cpu_ptr(pptr, cpu));",
            "\t\t\t\t\tcheck_and_init_map_value(map, info->percpu_value_buf + off);",
            "\t\t\t\t\toff += roundup_value_size;",
            "\t\t\t\t}",
            "\t\t\t\tctx.value = info->percpu_value_buf;",
            "\t\t\t}",
            "\t\t}",
            "\t\tret = bpf_iter_run_prog(prog, &ctx);",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "static int bpf_hash_map_seq_show(struct seq_file *seq, void *v)",
            "{",
            "\treturn __bpf_hash_map_seq_show(seq, v);",
            "}"
          ],
          "function_name": "htab_percpu_map_lookup_batch, htab_percpu_map_lookup_and_delete_batch, htab_map_lookup_batch, htab_map_lookup_and_delete_batch, htab_lru_percpu_map_lookup_batch, htab_lru_percpu_map_lookup_and_delete_batch, htab_lru_map_lookup_batch, htab_lru_map_lookup_and_delete_batch, __bpf_hash_map_seq_show, bpf_hash_map_seq_show",
          "description": "提供多种批量操作接口封装，统一调用__htab_map_lookup_and_delete_batch实现。包含序列化展示函数，处理PERCPU值的特殊复制逻辑，支持迭代器上下文管理。",
          "similarity": 0.5261296033859253
        },
        {
          "chunk_id": 14,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 2345,
          "end_line": 2464,
          "content": [
            "static int htab_percpu_map_gen_lookup(struct bpf_map *map, struct bpf_insn *insn_buf)",
            "{",
            "\tstruct bpf_insn *insn = insn_buf;",
            "",
            "\tif (!bpf_jit_supports_percpu_insn())",
            "\t\treturn -EOPNOTSUPP;",
            "",
            "\tBUILD_BUG_ON(!__same_type(&__htab_map_lookup_elem,",
            "\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));",
            "\t*insn++ = BPF_EMIT_CALL(__htab_map_lookup_elem);",
            "\t*insn++ = BPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 3);",
            "\t*insn++ = BPF_ALU64_IMM(BPF_ADD, BPF_REG_0,",
            "\t\t\t\toffsetof(struct htab_elem, key) + roundup(map->key_size, 8));",
            "\t*insn++ = BPF_LDX_MEM(BPF_DW, BPF_REG_0, BPF_REG_0, 0);",
            "\t*insn++ = BPF_MOV64_PERCPU_REG(BPF_REG_0, BPF_REG_0);",
            "",
            "\treturn insn - insn_buf;",
            "}",
            "int bpf_percpu_hash_copy(struct bpf_map *map, void *key, void *value)",
            "{",
            "\tstruct htab_elem *l;",
            "\tvoid __percpu *pptr;",
            "\tint ret = -ENOENT;",
            "\tint cpu, off = 0;",
            "\tu32 size;",
            "",
            "\t/* per_cpu areas are zero-filled and bpf programs can only",
            "\t * access 'value_size' of them, so copying rounded areas",
            "\t * will not leak any kernel data",
            "\t */",
            "\tsize = round_up(map->value_size, 8);",
            "\trcu_read_lock();",
            "\tl = __htab_map_lookup_elem(map, key);",
            "\tif (!l)",
            "\t\tgoto out;",
            "\t/* We do not mark LRU map element here in order to not mess up",
            "\t * eviction heuristics when user space does a map walk.",
            "\t */",
            "\tpptr = htab_elem_get_ptr(l, map->key_size);",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tcopy_map_value_long(map, value + off, per_cpu_ptr(pptr, cpu));",
            "\t\tcheck_and_init_map_value(map, value + off);",
            "\t\toff += size;",
            "\t}",
            "\tret = 0;",
            "out:",
            "\trcu_read_unlock();",
            "\treturn ret;",
            "}",
            "int bpf_percpu_hash_update(struct bpf_map *map, void *key, void *value,",
            "\t\t\t   u64 map_flags)",
            "{",
            "\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);",
            "\tint ret;",
            "",
            "\trcu_read_lock();",
            "\tif (htab_is_lru(htab))",
            "\t\tret = __htab_lru_percpu_map_update_elem(map, key, value,",
            "\t\t\t\t\t\t\tmap_flags, true);",
            "\telse",
            "\t\tret = __htab_percpu_map_update_elem(map, key, value, map_flags,",
            "\t\t\t\t\t\t    true);",
            "\trcu_read_unlock();",
            "",
            "\treturn ret;",
            "}",
            "static void htab_percpu_map_seq_show_elem(struct bpf_map *map, void *key,",
            "\t\t\t\t\t  struct seq_file *m)",
            "{",
            "\tstruct htab_elem *l;",
            "\tvoid __percpu *pptr;",
            "\tint cpu;",
            "",
            "\trcu_read_lock();",
            "",
            "\tl = __htab_map_lookup_elem(map, key);",
            "\tif (!l) {",
            "\t\trcu_read_unlock();",
            "\t\treturn;",
            "\t}",
            "",
            "\tbtf_type_seq_show(map->btf, map->btf_key_type_id, key, m);",
            "\tseq_puts(m, \": {\\n\");",
            "\tpptr = htab_elem_get_ptr(l, map->key_size);",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tseq_printf(m, \"\\tcpu%d: \", cpu);",
            "\t\tbtf_type_seq_show(map->btf, map->btf_value_type_id,",
            "\t\t\t\t  per_cpu_ptr(pptr, cpu), m);",
            "\t\tseq_puts(m, \"\\n\");",
            "\t}",
            "\tseq_puts(m, \"}\\n\");",
            "",
            "\trcu_read_unlock();",
            "}",
            "static int fd_htab_map_alloc_check(union bpf_attr *attr)",
            "{",
            "\tif (attr->value_size != sizeof(u32))",
            "\t\treturn -EINVAL;",
            "\treturn htab_map_alloc_check(attr);",
            "}",
            "static void fd_htab_map_free(struct bpf_map *map)",
            "{",
            "\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);",
            "\tstruct hlist_nulls_node *n;",
            "\tstruct hlist_nulls_head *head;",
            "\tstruct htab_elem *l;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < htab->n_buckets; i++) {",
            "\t\thead = select_bucket(htab, i);",
            "",
            "\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {",
            "\t\t\tvoid *ptr = fd_htab_map_get_ptr(map, l);",
            "",
            "\t\t\tmap->ops->map_fd_put_ptr(map, ptr, false);",
            "\t\t}",
            "\t}",
            "",
            "\thtab_map_free(map);",
            "}"
          ],
          "function_name": "htab_percpu_map_gen_lookup, bpf_percpu_hash_copy, bpf_percpu_hash_update, htab_percpu_map_seq_show_elem, fd_htab_map_alloc_check, fd_htab_map_free",
          "description": "生成PERCPU哈希表查找指令，实现值复制/更新操作，支持序列化展示多CPU值。包含资源分配校验和释放函数，确保PERCPU映射生命周期管理及内存安全。",
          "similarity": 0.5137621760368347
        },
        {
          "chunk_id": 15,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 2555,
          "end_line": 2611,
          "content": [
            "int bpf_fd_htab_map_lookup_elem(struct bpf_map *map, void *key, u32 *value)",
            "{",
            "\tvoid **ptr;",
            "\tint ret = 0;",
            "",
            "\tif (!map->ops->map_fd_sys_lookup_elem)",
            "\t\treturn -ENOTSUPP;",
            "",
            "\trcu_read_lock();",
            "\tptr = htab_map_lookup_elem(map, key);",
            "\tif (ptr)",
            "\t\t*value = map->ops->map_fd_sys_lookup_elem(READ_ONCE(*ptr));",
            "\telse",
            "\t\tret = -ENOENT;",
            "\trcu_read_unlock();",
            "",
            "\treturn ret;",
            "}",
            "int bpf_fd_htab_map_update_elem(struct bpf_map *map, struct file *map_file,",
            "\t\t\t\tvoid *key, void *value, u64 map_flags)",
            "{",
            "\tvoid *ptr;",
            "\tint ret;",
            "\tu32 ufd = *(u32 *)value;",
            "",
            "\tptr = map->ops->map_fd_get_ptr(map, map_file, ufd);",
            "\tif (IS_ERR(ptr))",
            "\t\treturn PTR_ERR(ptr);",
            "",
            "\tret = htab_map_update_elem(map, key, &ptr, map_flags);",
            "\tif (ret)",
            "\t\tmap->ops->map_fd_put_ptr(map, ptr, false);",
            "",
            "\treturn ret;",
            "}",
            "static int htab_of_map_gen_lookup(struct bpf_map *map,",
            "\t\t\t\t  struct bpf_insn *insn_buf)",
            "{",
            "\tstruct bpf_insn *insn = insn_buf;",
            "\tconst int ret = BPF_REG_0;",
            "",
            "\tBUILD_BUG_ON(!__same_type(&__htab_map_lookup_elem,",
            "\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));",
            "\t*insn++ = BPF_EMIT_CALL(__htab_map_lookup_elem);",
            "\t*insn++ = BPF_JMP_IMM(BPF_JEQ, ret, 0, 2);",
            "\t*insn++ = BPF_ALU64_IMM(BPF_ADD, ret,",
            "\t\t\t\toffsetof(struct htab_elem, key) +",
            "\t\t\t\tround_up(map->key_size, 8));",
            "\t*insn++ = BPF_LDX_MEM(BPF_DW, ret, ret, 0);",
            "",
            "\treturn insn - insn_buf;",
            "}",
            "static void htab_of_map_free(struct bpf_map *map)",
            "{",
            "\tbpf_map_meta_free(map->inner_map_meta);",
            "\tfd_htab_map_free(map);",
            "}"
          ],
          "function_name": "bpf_fd_htab_map_lookup_elem, bpf_fd_htab_map_update_elem, htab_of_map_gen_lookup, htab_of_map_free",
          "description": "该代码段实现了基于文件描述符的哈希表操作，包含查找、更新及释放逻辑。  \n`bpf_fd_htab_map_lookup_elem` 和 `bpf_fd_htab_map_update_elem` 分别用于通过文件描述符键查找和更新哈希表项，依赖于 `map->ops` 中的回调函数。  \n`htab_of_map_gen_lookup` 生成 eBPF 指令以调用哈希表查找逻辑，`htab_of_map_free` 释放哈希表相关元数据；部分底层函数（如 `htab_map_lookup_elem`）未展示，上下文不完整。",
          "similarity": 0.5125482082366943
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 275,
          "end_line": 381,
          "content": [
            "static void htab_free_elems(struct bpf_htab *htab)",
            "{",
            "\tint i;",
            "",
            "\tif (!htab_is_percpu(htab))",
            "\t\tgoto free_elems;",
            "",
            "\tfor (i = 0; i < htab->map.max_entries; i++) {",
            "\t\tvoid __percpu *pptr;",
            "",
            "\t\tpptr = htab_elem_get_ptr(get_htab_elem(htab, i),",
            "\t\t\t\t\t htab->map.key_size);",
            "\t\tfree_percpu(pptr);",
            "\t\tcond_resched();",
            "\t}",
            "free_elems:",
            "\tbpf_map_area_free(htab->elems);",
            "}",
            "static int prealloc_init(struct bpf_htab *htab)",
            "{",
            "\tu32 num_entries = htab->map.max_entries;",
            "\tint err = -ENOMEM, i;",
            "",
            "\tif (htab_has_extra_elems(htab))",
            "\t\tnum_entries += num_possible_cpus();",
            "",
            "\thtab->elems = bpf_map_area_alloc((u64)htab->elem_size * num_entries,",
            "\t\t\t\t\t htab->map.numa_node);",
            "\tif (!htab->elems)",
            "\t\treturn -ENOMEM;",
            "",
            "\tif (!htab_is_percpu(htab))",
            "\t\tgoto skip_percpu_elems;",
            "",
            "\tfor (i = 0; i < num_entries; i++) {",
            "\t\tu32 size = round_up(htab->map.value_size, 8);",
            "\t\tvoid __percpu *pptr;",
            "",
            "\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,",
            "\t\t\t\t\t    GFP_USER | __GFP_NOWARN);",
            "\t\tif (!pptr)",
            "\t\t\tgoto free_elems;",
            "\t\thtab_elem_set_ptr(get_htab_elem(htab, i), htab->map.key_size,",
            "\t\t\t\t  pptr);",
            "\t\tcond_resched();",
            "\t}",
            "",
            "skip_percpu_elems:",
            "\tif (htab_is_lru(htab))",
            "\t\terr = bpf_lru_init(&htab->lru,",
            "\t\t\t\t   htab->map.map_flags & BPF_F_NO_COMMON_LRU,",
            "\t\t\t\t   offsetof(struct htab_elem, hash) -",
            "\t\t\t\t   offsetof(struct htab_elem, lru_node),",
            "\t\t\t\t   htab_lru_map_delete_node,",
            "\t\t\t\t   htab);",
            "\telse",
            "\t\terr = pcpu_freelist_init(&htab->freelist);",
            "",
            "\tif (err)",
            "\t\tgoto free_elems;",
            "",
            "\tif (htab_is_lru(htab))",
            "\t\tbpf_lru_populate(&htab->lru, htab->elems,",
            "\t\t\t\t offsetof(struct htab_elem, lru_node),",
            "\t\t\t\t htab->elem_size, num_entries);",
            "\telse",
            "\t\tpcpu_freelist_populate(&htab->freelist,",
            "\t\t\t\t       htab->elems + offsetof(struct htab_elem, fnode),",
            "\t\t\t\t       htab->elem_size, num_entries);",
            "",
            "\treturn 0;",
            "",
            "free_elems:",
            "\thtab_free_elems(htab);",
            "\treturn err;",
            "}",
            "static void prealloc_destroy(struct bpf_htab *htab)",
            "{",
            "\thtab_free_elems(htab);",
            "",
            "\tif (htab_is_lru(htab))",
            "\t\tbpf_lru_destroy(&htab->lru);",
            "\telse",
            "\t\tpcpu_freelist_destroy(&htab->freelist);",
            "}",
            "static int alloc_extra_elems(struct bpf_htab *htab)",
            "{",
            "\tstruct htab_elem *__percpu *pptr, *l_new;",
            "\tstruct pcpu_freelist_node *l;",
            "\tint cpu;",
            "",
            "\tpptr = bpf_map_alloc_percpu(&htab->map, sizeof(struct htab_elem *), 8,",
            "\t\t\t\t    GFP_USER | __GFP_NOWARN);",
            "\tif (!pptr)",
            "\t\treturn -ENOMEM;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tl = pcpu_freelist_pop(&htab->freelist);",
            "\t\t/* pop will succeed, since prealloc_init()",
            "\t\t * preallocated extra num_possible_cpus elements",
            "\t\t */",
            "\t\tl_new = container_of(l, struct htab_elem, fnode);",
            "\t\t*per_cpu_ptr(pptr, cpu) = l_new;",
            "\t}",
            "\thtab->extra_elems = pptr;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "htab_free_elems, prealloc_init, prealloc_destroy, alloc_extra_elems",
          "description": "实现预分配元素的初始化、销毁和额外元素分配逻辑，包含内存分配、指针对齐处理、PCPU资源管理等细节，负责构建哈希表的物理存储结构。",
          "similarity": 0.5094830989837646
        }
      ]
    },
    {
      "source_file": "kernel/pid_sysctl.h",
      "md_summary": "> 自动生成时间: 2025-10-25 15:17:36\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `pid_sysctl.h`\n\n---\n\n# `pid_sysctl.h` 技术文档\n\n## 1. 文件概述\n\n`pid_sysctl.h` 是 Linux 内核中用于定义与 PID 命名空间（`pid_namespace`）相关的系统控制（sysctl）接口的头文件。其核心功能是提供对 `memfd_noexec` 系统策略的运行时配置支持，该策略用于控制通过 `memfd_create()` 创建的内存文件是否允许执行代码。该配置具有层级继承语义：子 PID 命名空间的策略不能比其父命名空间更宽松，以确保安全策略的向下兼容性和强制性。\n\n## 2. 核心功能\n\n### 函数\n\n- **`pid_mfd_noexec_dointvec_minmax`**  \n  自定义的 sysctl 处理函数，用于读写 `memfd_noexec` 策略值。在写入时执行权限检查和策略继承约束验证。\n\n- **`register_pid_ns_sysctl_table_vm`**  \n  内联函数，用于向内核 sysctl 子系统注册 `vm.memfd_noexec` 控制项（仅在 `CONFIG_SYSCTL` 和 `CONFIG_MEMFD_CREATE` 同时启用时有效）。\n\n### 数据结构\n\n- **`pid_ns_ctl_table_vm`**  \n  `ctl_table` 类型的静态数组，定义了 `vm.memfd_noexec` sysctl 条目，包括其名称、数据指针、访问权限、处理函数及取值范围（0 到 2）。\n\n## 3. 关键实现\n\n- **权限控制**：  \n  在写入 `memfd_noexec` 值时，调用 `ns_capable(ns->user_ns, CAP_SYS_ADMIN)` 检查当前任务是否在对应用户命名空间中拥有 `CAP_SYS_ADMIN` 能力，防止非特权用户修改安全策略。\n\n- **策略继承约束**：  \n  通过 `pidns_memfd_noexec_scope(ns->parent)` 获取父 PID 命名空间的策略值 `parent_scope`，并确保当前命名空间的策略值 `scope` 不小于父策略（即不能更宽松）。实际写入前使用 `max(READ_ONCE(ns->memfd_noexec_scope), parent_scope)` 保证该约束。\n\n- **原子读写**：  \n  使用 `READ_ONCE()` 和 `WRITE_ONCE()` 对 `ns->memfd_noexec_scope` 进行访问，确保在并发环境下内存访问的可见性和顺序性。\n\n- **sysctl 注册**：  \n  通过 `register_sysctl(\"vm\", pid_ns_ctl_table_vm)` 将控制项注册到 `/proc/sys/vm/memfd_noexec` 路径下，供用户空间通过标准 sysctl 接口访问。\n\n- **条件编译**：  \n  整个功能仅在 `CONFIG_SYSCTL`（启用 sysctl 支持）和 `CONFIG_MEMFD_CREATE`（启用 memfd_create 系统调用）同时配置时编译，否则 `register_pid_ns_sysctl_table_vm` 为空内联函数，避免代码膨胀。\n\n## 4. 依赖关系\n\n- **`<linux/pid_namespace.h>`**：  \n  提供 `struct pid_namespace` 定义及辅助函数如 `task_active_pid_ns()` 和 `pidns_memfd_noexec_scope()`。\n\n- **`CONFIG_SYSCTL`**：  \n  内核配置选项，启用 sysctl 框架支持，提供 `register_sysctl`、`proc_dointvec_minmax` 等接口。\n\n- **`CONFIG_MEMFD_CREATE`**：  \n  内核配置选项，启用 `memfd_create()` 系统调用及相关功能（如 `memfd_noexec_scope` 字段）。\n\n- **能力子系统（Capabilities）**：  \n  依赖 `ns_capable()` 进行命名空间感知的权限检查。\n\n## 5. 使用场景\n\n- **安全策略配置**：  \n  系统管理员或容器运行时可通过写入 `/proc/sys/vm/memfd_noexec` 设置当前 PID 命名空间中 `memfd` 文件的执行限制级别（0=允许执行，1=禁止执行但可覆盖，2=严格禁止执行），用于防御基于内存文件的代码注入攻击。\n\n- **容器隔离**：  \n  在容器化环境中，不同容器运行在独立的 PID 命名空间中。父命名空间（如宿主机）可设置较严格的 `memfd_noexec` 策略，子容器无法降低该策略级别，从而实现自上而下的安全策略强制。\n\n- **运行时动态调整**：  \n  允许在系统运行期间动态调整 `memfd` 执行策略，无需重启或重新加载内核模块，提升系统灵活性与安全性。",
      "similarity": 0.5791782140731812,
      "chunks": []
    },
    {
      "source_file": "kernel/bpf/local_storage.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:15:04\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\local_storage.c`\n\n---\n\n# `bpf/local_storage.c` 技术文档\n\n## 1. 文件概述\n\n`bpf/local_storage.c` 是 Linux 内核中 BPF（Berkeley Packet Filter）子系统的一部分，专门用于实现 **cgroup 本地存储（cgroup local storage）** 功能。该文件在 `CONFIG_CGROUP_BPF` 配置启用时编译，提供了一种机制，允许 BPF 程序为每个 cgroup 实例关联私有的、可持久化的存储空间（即“本地存储”）。这种存储可用于在 BPF 程序中跨调用保存状态，例如统计信息、配置参数等。\n\n该文件实现了两种 BPF map 类型：\n- `BPF_MAP_TYPE_CGROUP_STORAGE`\n- `BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE`\n\n分别用于单值存储和 per-CPU 存储，均基于 cgroup 的 inode ID（及可选的 attach type）作为键进行索引。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct bpf_cgroup_storage_map`**  \n  表示 cgroup 存储类型的 BPF map。包含：\n  - `struct bpf_map map`：继承自通用 BPF map 结构\n  - `spinlock_t lock`：保护红黑树和链表的自旋锁\n  - `struct rb_root root`：以键为索引的红黑树，用于快速查找\n  - `struct list_head list`：用于遍历所有存储项的链表\n\n- **`struct bpf_cgroup_storage_key`**  \n  键结构体，包含：\n  - `__u64 cgroup_inode_id`：cgroup 的 inode ID（唯一标识）\n  - `__u32 attach_type`：BPF 程序附加类型（如 `BPF_CGROUP_INET_INGRESS`）\n\n- **`struct bpf_cgroup_storage`**  \n  存储条目，包含：\n  - `struct rb_node node`：红黑树节点\n  - `struct list_head list_map`：链表节点\n  - `union { struct bpf_storage_buffer *buf; void __percpu *percpu_buf; }`：指向实际数据的指针（单值或 per-CPU）\n\n### 主要函数\n\n- **`cgroup_storage_lookup()`**  \n  在红黑树中根据 key 查找对应的 `bpf_cgroup_storage` 条目，支持加锁/不加锁模式。\n\n- **`cgroup_storage_insert()`**  \n  将新的存储条目插入红黑树，若键已存在则返回 `-EEXIST`。\n\n- **`cgroup_storage_lookup_elem()`**  \n  BPF map 的 `lookup` 操作回调，返回存储数据的起始地址。\n\n- **`cgroup_storage_update_elem()`**  \n  BPF map 的 `update` 操作回调，支持原子更新（带 `BPF_F_LOCK`）或替换整个缓冲区。\n\n- **`bpf_percpu_cgroup_storage_copy()`**  \n  用于 `PERCPU_CGROUP_STORAGE` 类型的 lookup，聚合所有 CPU 的数据。\n\n- **`bpf_percpu_cgroup_storage_update()`**  \n  用于 `PERCPU_CGROUP_STORAGE` 类型的 update，将用户提供的数据分发到各 CPU。\n\n- **`cgroup_storage_get_next_key()`**  \n  实现 BPF map 的 `get_next_key` 操作，用于遍历所有存储条目。\n\n- **`cgroup_storage_map_alloc()`**  \n  分配并初始化 cgroup storage 类型的 BPF map。\n\n- **`cgroup_storage_map_free()`**  \n  释放 map 及其所有存储条目（代码未完整显示，但功能明确）。\n\n## 3. 关键实现\n\n### 键值设计与比较逻辑\n\n- 支持两种键格式：\n  1. 仅 `__u64 cgroup_inode_id`（用于非隔离 attach type）\n  2. `struct bpf_cgroup_storage_key`（包含 inode ID + attach type，用于隔离场景）\n- `attach_type_isolated()` 判断是否使用完整键结构。\n- `bpf_cgroup_storage_key_cmp()` 实现红黑树的比较逻辑，先比较 inode ID，再比较 attach type（如适用）。\n\n### 并发控制\n\n- 使用 `spinlock_t lock` 保护红黑树和链表的修改操作（如插入、遍历）。\n- 查找操作可选择是否加锁（`locked` 参数），以支持 RCU 读路径（如 per-CPU update 中使用 `rcu_read_lock()`）。\n- 单值存储更新时使用 `xchg()` + `kfree_rcu()` 实现无锁读取和安全释放。\n\n### 内存管理\n\n- 单值存储使用 `bpf_map_kmalloc_node()` 分配 `bpf_storage_buffer`，包含数据和可能的 BTF 记录。\n- per-CPU 存储使用 `__percpu` 指针，通过 `per_cpu_ptr()` 访问各 CPU 数据。\n- 所有分配考虑 NUMA 节点（通过 `numa_node` 字段）。\n\n### 安全与限制\n\n- `value_size` 限制：\n  - 普通类型：最大 `BPF_LOCAL_STORAGE_MAX_VALUE_SIZE`\n  - per-CPU 类型：额外受限于 `PCPU_MIN_UNIT_SIZE`\n- 键大小必须为 `sizeof(__u64)` 或 `sizeof(bpf_cgroup_storage_key)`\n- `max_entries` 必须为 0（动态扩展）\n- `map_flags` 仅允许 `BPF_F_NUMA_NODE` 和访问权限标志\n\n### per-CPU 数据对齐\n\n- per-CPU 数据按 8 字节对齐（`round_up(value_size, 8)`），确保跨 CPU 访问安全，并防止内核数据泄露（因 per-CPU 区域初始化为零）。\n\n## 4. 依赖关系\n\n- **BPF 子系统**：依赖 `bpf.h`、`bpf_map.h`、`filter.h` 等核心 BPF 头文件。\n- **cgroup 子系统**：依赖 `cgroup-internal.h` 获取 cgroup 内部结构（如 inode ID）。\n- **内存管理**：使用 `slab.h`、`mm.h` 进行内存分配。\n- **RCU 机制**：用于安全释放旧缓冲区（`kfree_rcu`）。\n- **BTF（BPF Type Format）**：支持带锁字段的类型验证（`btf_record_has_field`）。\n- **红黑树**：使用 `rbtree.h` 实现高效查找。\n- **Per-CPU 基础设施**：使用 `percpu.h` 相关宏（隐式包含）。\n\n## 5. 使用场景\n\n- **BPF 程序状态持久化**：  \n  BPF 程序（如 cgroup hook 程序）可为每个 cgroup 维护独立的计数器、配置或状态机。\n\n- **网络策略与限速**：  \n  在 `BPF_CGROUP_INET_*` 程序中，为每个 cgroup 存储流量统计或令牌桶状态。\n\n- **资源监控**：  \n  用户空间通过 BPF map 接口读取各 cgroup 的累计指标（如 I/O 次数、进程数）。\n\n- **安全策略**：  \n  存储 cgroup 特定的安全上下文或访问控制列表。\n\n- **调试与追踪**：  \n  在 BPF tracepoint 或 kprobe 程序中，按 cgroup 聚合事件数据。\n\n> **注意**：该机制仅在 cgroup BPF 支持启用（`CONFIG_CGROUP_BPF=y`）时可用，且必须通过 BPF 系统调用创建对应类型的 map，并由 BPF 程序或用户空间程序操作。",
      "similarity": 0.573173999786377,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 414,
          "end_line": 530,
          "content": [
            "static void cgroup_storage_seq_show_elem(struct bpf_map *map, void *key,",
            "\t\t\t\t\t struct seq_file *m)",
            "{",
            "\tenum bpf_cgroup_storage_type stype;",
            "\tstruct bpf_cgroup_storage *storage;",
            "\tint cpu;",
            "",
            "\trcu_read_lock();",
            "\tstorage = cgroup_storage_lookup(map_to_storage(map), key, false);",
            "\tif (!storage) {",
            "\t\trcu_read_unlock();",
            "\t\treturn;",
            "\t}",
            "",
            "\tbtf_type_seq_show(map->btf, map->btf_key_type_id, key, m);",
            "\tstype = cgroup_storage_type(map);",
            "\tif (stype == BPF_CGROUP_STORAGE_SHARED) {",
            "\t\tseq_puts(m, \": \");",
            "\t\tbtf_type_seq_show(map->btf, map->btf_value_type_id,",
            "\t\t\t\t  &READ_ONCE(storage->buf)->data[0], m);",
            "\t\tseq_puts(m, \"\\n\");",
            "\t} else {",
            "\t\tseq_puts(m, \": {\\n\");",
            "\t\tfor_each_possible_cpu(cpu) {",
            "\t\t\tseq_printf(m, \"\\tcpu%d: \", cpu);",
            "\t\t\tbtf_type_seq_show(map->btf, map->btf_value_type_id,",
            "\t\t\t\t\t  per_cpu_ptr(storage->percpu_buf, cpu),",
            "\t\t\t\t\t  m);",
            "\t\t\tseq_puts(m, \"\\n\");",
            "\t\t}",
            "\t\tseq_puts(m, \"}\\n\");",
            "\t}",
            "\trcu_read_unlock();",
            "}",
            "static u64 cgroup_storage_map_usage(const struct bpf_map *map)",
            "{",
            "\t/* Currently the dynamically allocated elements are not counted. */",
            "\treturn sizeof(struct bpf_cgroup_storage_map);",
            "}",
            "int bpf_cgroup_storage_assign(struct bpf_prog_aux *aux, struct bpf_map *_map)",
            "{",
            "\tenum bpf_cgroup_storage_type stype = cgroup_storage_type(_map);",
            "",
            "\tif (aux->cgroup_storage[stype] &&",
            "\t    aux->cgroup_storage[stype] != _map)",
            "\t\treturn -EBUSY;",
            "",
            "\taux->cgroup_storage[stype] = _map;",
            "\treturn 0;",
            "}",
            "static size_t bpf_cgroup_storage_calculate_size(struct bpf_map *map, u32 *pages)",
            "{",
            "\tsize_t size;",
            "",
            "\tif (cgroup_storage_type(map) == BPF_CGROUP_STORAGE_SHARED) {",
            "\t\tsize = sizeof(struct bpf_storage_buffer) + map->value_size;",
            "\t\t*pages = round_up(sizeof(struct bpf_cgroup_storage) + size,",
            "\t\t\t\t  PAGE_SIZE) >> PAGE_SHIFT;",
            "\t} else {",
            "\t\tsize = map->value_size;",
            "\t\t*pages = round_up(round_up(size, 8) * num_possible_cpus(),",
            "\t\t\t\t  PAGE_SIZE) >> PAGE_SHIFT;",
            "\t}",
            "",
            "\treturn size;",
            "}",
            "static void free_shared_cgroup_storage_rcu(struct rcu_head *rcu)",
            "{",
            "\tstruct bpf_cgroup_storage *storage =",
            "\t\tcontainer_of(rcu, struct bpf_cgroup_storage, rcu);",
            "",
            "\tkfree(storage->buf);",
            "\tkfree(storage);",
            "}",
            "static void free_percpu_cgroup_storage_rcu(struct rcu_head *rcu)",
            "{",
            "\tstruct bpf_cgroup_storage *storage =",
            "\t\tcontainer_of(rcu, struct bpf_cgroup_storage, rcu);",
            "",
            "\tfree_percpu(storage->percpu_buf);",
            "\tkfree(storage);",
            "}",
            "void bpf_cgroup_storage_free(struct bpf_cgroup_storage *storage)",
            "{",
            "\tenum bpf_cgroup_storage_type stype;",
            "\tstruct bpf_map *map;",
            "",
            "\tif (!storage)",
            "\t\treturn;",
            "",
            "\tmap = &storage->map->map;",
            "\tstype = cgroup_storage_type(map);",
            "\tif (stype == BPF_CGROUP_STORAGE_SHARED)",
            "\t\tcall_rcu(&storage->rcu, free_shared_cgroup_storage_rcu);",
            "\telse",
            "\t\tcall_rcu(&storage->rcu, free_percpu_cgroup_storage_rcu);",
            "}",
            "void bpf_cgroup_storage_link(struct bpf_cgroup_storage *storage,",
            "\t\t\t     struct cgroup *cgroup,",
            "\t\t\t     enum bpf_attach_type type)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map;",
            "",
            "\tif (!storage)",
            "\t\treturn;",
            "",
            "\tstorage->key.attach_type = type;",
            "\tstorage->key.cgroup_inode_id = cgroup_id(cgroup);",
            "",
            "\tmap = storage->map;",
            "",
            "\tspin_lock_bh(&map->lock);",
            "\tWARN_ON(cgroup_storage_insert(map, storage));",
            "\tlist_add(&storage->list_map, &map->list);",
            "\tlist_add(&storage->list_cg, &cgroup->bpf.storages);",
            "\tspin_unlock_bh(&map->lock);",
            "}"
          ],
          "function_name": "cgroup_storage_seq_show_elem, cgroup_storage_map_usage, bpf_cgroup_storage_assign, bpf_cgroup_storage_calculate_size, free_shared_cgroup_storage_rcu, free_percpu_cgroup_storage_rcu, bpf_cgroup_storage_free, bpf_cgroup_storage_link",
          "description": "包含存储元素序列化显示、内存占用统计、存储分配绑定及RCU安全的内存回收机制，区分共享与per-CPU存储的释放路径。",
          "similarity": 0.5246927738189697
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 1,
          "end_line": 33,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bpf_local_storage.h>",
            "#include <linux/btf.h>",
            "#include <linux/bug.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/rbtree.h>",
            "#include <linux/slab.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/btf_ids.h>",
            "",
            "#ifdef CONFIG_CGROUP_BPF",
            "",
            "#include \"../cgroup/cgroup-internal.h\"",
            "",
            "#define LOCAL_STORAGE_CREATE_FLAG_MASK\t\t\t\t\t\\",
            "\t(BPF_F_NUMA_NODE | BPF_F_ACCESS_MASK)",
            "",
            "struct bpf_cgroup_storage_map {",
            "\tstruct bpf_map map;",
            "",
            "\tspinlock_t lock;",
            "\tstruct rb_root root;",
            "\tstruct list_head list;",
            "};",
            "",
            "static struct bpf_cgroup_storage_map *map_to_storage(struct bpf_map *map)",
            "{",
            "\treturn container_of(map, struct bpf_cgroup_storage_map, map);",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义了BPF cgroup存储管理的基础结构，包含红黑树根节点、锁和链表，通过map_to_storage函数将通用map转换为专用存储结构。",
          "similarity": 0.5229858160018921
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 595,
          "end_line": 612,
          "content": [
            "void bpf_cgroup_storage_unlink(struct bpf_cgroup_storage *storage)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map;",
            "\tstruct rb_root *root;",
            "",
            "\tif (!storage)",
            "\t\treturn;",
            "",
            "\tmap = storage->map;",
            "",
            "\tspin_lock_bh(&map->lock);",
            "\troot = &map->root;",
            "\trb_erase(&storage->node, root);",
            "",
            "\tlist_del(&storage->list_map);",
            "\tlist_del(&storage->list_cg);",
            "\tspin_unlock_bh(&map->lock);",
            "}"
          ],
          "function_name": "bpf_cgroup_storage_unlink",
          "description": "负责从红黑树和链表中移除存储项，通过自旋锁保护并发访问，同步维护存储结构与cgroup关联列表。",
          "similarity": 0.5086483955383301
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 34,
          "end_line": 157,
          "content": [
            "static bool attach_type_isolated(const struct bpf_map *map)",
            "{",
            "\treturn map->key_size == sizeof(struct bpf_cgroup_storage_key);",
            "}",
            "static int bpf_cgroup_storage_key_cmp(const struct bpf_cgroup_storage_map *map,",
            "\t\t\t\t      const void *_key1, const void *_key2)",
            "{",
            "\tif (attach_type_isolated(&map->map)) {",
            "\t\tconst struct bpf_cgroup_storage_key *key1 = _key1;",
            "\t\tconst struct bpf_cgroup_storage_key *key2 = _key2;",
            "",
            "\t\tif (key1->cgroup_inode_id < key2->cgroup_inode_id)",
            "\t\t\treturn -1;",
            "\t\telse if (key1->cgroup_inode_id > key2->cgroup_inode_id)",
            "\t\t\treturn 1;",
            "\t\telse if (key1->attach_type < key2->attach_type)",
            "\t\t\treturn -1;",
            "\t\telse if (key1->attach_type > key2->attach_type)",
            "\t\t\treturn 1;",
            "\t} else {",
            "\t\tconst __u64 *cgroup_inode_id1 = _key1;",
            "\t\tconst __u64 *cgroup_inode_id2 = _key2;",
            "",
            "\t\tif (*cgroup_inode_id1 < *cgroup_inode_id2)",
            "\t\t\treturn -1;",
            "\t\telse if (*cgroup_inode_id1 > *cgroup_inode_id2)",
            "\t\t\treturn 1;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int cgroup_storage_insert(struct bpf_cgroup_storage_map *map,",
            "\t\t\t\t struct bpf_cgroup_storage *storage)",
            "{",
            "\tstruct rb_root *root = &map->root;",
            "\tstruct rb_node **new = &(root->rb_node), *parent = NULL;",
            "",
            "\twhile (*new) {",
            "\t\tstruct bpf_cgroup_storage *this;",
            "",
            "\t\tthis = container_of(*new, struct bpf_cgroup_storage, node);",
            "",
            "\t\tparent = *new;",
            "\t\tswitch (bpf_cgroup_storage_key_cmp(map, &storage->key, &this->key)) {",
            "\t\tcase -1:",
            "\t\t\tnew = &((*new)->rb_left);",
            "\t\t\tbreak;",
            "\t\tcase 1:",
            "\t\t\tnew = &((*new)->rb_right);",
            "\t\t\tbreak;",
            "\t\tdefault:",
            "\t\t\treturn -EEXIST;",
            "\t\t}",
            "\t}",
            "",
            "\trb_link_node(&storage->node, parent, new);",
            "\trb_insert_color(&storage->node, root);",
            "",
            "\treturn 0;",
            "}",
            "static long cgroup_storage_update_elem(struct bpf_map *map, void *key,",
            "\t\t\t\t       void *value, u64 flags)",
            "{",
            "\tstruct bpf_cgroup_storage *storage;",
            "\tstruct bpf_storage_buffer *new;",
            "",
            "\tif (unlikely(flags & ~(BPF_F_LOCK | BPF_EXIST)))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (unlikely((flags & BPF_F_LOCK) &&",
            "\t\t     !btf_record_has_field(map->record, BPF_SPIN_LOCK)))",
            "\t\treturn -EINVAL;",
            "",
            "\tstorage = cgroup_storage_lookup((struct bpf_cgroup_storage_map *)map,",
            "\t\t\t\t\tkey, false);",
            "\tif (!storage)",
            "\t\treturn -ENOENT;",
            "",
            "\tif (flags & BPF_F_LOCK) {",
            "\t\tcopy_map_value_locked(map, storage->buf->data, value, false);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tnew = bpf_map_kmalloc_node(map, struct_size(new, data, map->value_size),",
            "\t\t\t\t   __GFP_ZERO | GFP_NOWAIT | __GFP_NOWARN,",
            "\t\t\t\t   map->numa_node);",
            "\tif (!new)",
            "\t\treturn -ENOMEM;",
            "",
            "\tmemcpy(&new->data[0], value, map->value_size);",
            "\tcheck_and_init_map_value(map, new->data);",
            "",
            "\tnew = xchg(&storage->buf, new);",
            "\tkfree_rcu(new, rcu);",
            "",
            "\treturn 0;",
            "}",
            "int bpf_percpu_cgroup_storage_copy(struct bpf_map *_map, void *key,",
            "\t\t\t\t   void *value)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map = map_to_storage(_map);",
            "\tstruct bpf_cgroup_storage *storage;",
            "\tint cpu, off = 0;",
            "\tu32 size;",
            "",
            "\trcu_read_lock();",
            "\tstorage = cgroup_storage_lookup(map, key, false);",
            "\tif (!storage) {",
            "\t\trcu_read_unlock();",
            "\t\treturn -ENOENT;",
            "\t}",
            "",
            "\t/* per_cpu areas are zero-filled and bpf programs can only",
            "\t * access 'value_size' of them, so copying rounded areas",
            "\t * will not leak any kernel data",
            "\t */",
            "\tsize = round_up(_map->value_size, 8);",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tbpf_long_memcpy(value + off,",
            "\t\t\t\tper_cpu_ptr(storage->percpu_buf, cpu), size);",
            "\t\toff += size;",
            "\t}",
            "\trcu_read_unlock();",
            "\treturn 0;",
            "}"
          ],
          "function_name": "attach_type_isolated, bpf_cgroup_storage_key_cmp, cgroup_storage_insert, cgroup_storage_update_elem, bpf_percpu_cgroup_storage_copy",
          "description": "实现了键值比较逻辑、红黑树插入操作、多CPU数据复制及存储更新功能，支持基于cgroup inode ID和attach类型的键区分。",
          "similarity": 0.47872087359428406
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 211,
          "end_line": 363,
          "content": [
            "int bpf_percpu_cgroup_storage_update(struct bpf_map *_map, void *key,",
            "\t\t\t\t     void *value, u64 map_flags)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map = map_to_storage(_map);",
            "\tstruct bpf_cgroup_storage *storage;",
            "\tint cpu, off = 0;",
            "\tu32 size;",
            "",
            "\tif (map_flags != BPF_ANY && map_flags != BPF_EXIST)",
            "\t\treturn -EINVAL;",
            "",
            "\trcu_read_lock();",
            "\tstorage = cgroup_storage_lookup(map, key, false);",
            "\tif (!storage) {",
            "\t\trcu_read_unlock();",
            "\t\treturn -ENOENT;",
            "\t}",
            "",
            "\t/* the user space will provide round_up(value_size, 8) bytes that",
            "\t * will be copied into per-cpu area. bpf programs can only access",
            "\t * value_size of it. During lookup the same extra bytes will be",
            "\t * returned or zeros which were zero-filled by percpu_alloc,",
            "\t * so no kernel data leaks possible",
            "\t */",
            "\tsize = round_up(_map->value_size, 8);",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tbpf_long_memcpy(per_cpu_ptr(storage->percpu_buf, cpu),",
            "\t\t\t\tvalue + off, size);",
            "\t\toff += size;",
            "\t}",
            "\trcu_read_unlock();",
            "\treturn 0;",
            "}",
            "static int cgroup_storage_get_next_key(struct bpf_map *_map, void *key,",
            "\t\t\t\t       void *_next_key)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map = map_to_storage(_map);",
            "\tstruct bpf_cgroup_storage *storage;",
            "",
            "\tspin_lock_bh(&map->lock);",
            "",
            "\tif (list_empty(&map->list))",
            "\t\tgoto enoent;",
            "",
            "\tif (key) {",
            "\t\tstorage = cgroup_storage_lookup(map, key, true);",
            "\t\tif (!storage)",
            "\t\t\tgoto enoent;",
            "",
            "\t\tstorage = list_next_entry(storage, list_map);",
            "\t\tif (!storage)",
            "\t\t\tgoto enoent;",
            "\t} else {",
            "\t\tstorage = list_first_entry(&map->list,",
            "\t\t\t\t\t struct bpf_cgroup_storage, list_map);",
            "\t}",
            "",
            "\tspin_unlock_bh(&map->lock);",
            "",
            "\tif (attach_type_isolated(&map->map)) {",
            "\t\tstruct bpf_cgroup_storage_key *next = _next_key;",
            "\t\t*next = storage->key;",
            "\t} else {",
            "\t\t__u64 *next = _next_key;",
            "\t\t*next = storage->key.cgroup_inode_id;",
            "\t}",
            "\treturn 0;",
            "",
            "enoent:",
            "\tspin_unlock_bh(&map->lock);",
            "\treturn -ENOENT;",
            "}",
            "static void cgroup_storage_map_free(struct bpf_map *_map)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map = map_to_storage(_map);",
            "\tstruct list_head *storages = &map->list;",
            "\tstruct bpf_cgroup_storage *storage, *stmp;",
            "",
            "\tcgroup_lock();",
            "",
            "\tlist_for_each_entry_safe(storage, stmp, storages, list_map) {",
            "\t\tbpf_cgroup_storage_unlink(storage);",
            "\t\tbpf_cgroup_storage_free(storage);",
            "\t}",
            "",
            "\tcgroup_unlock();",
            "",
            "\tWARN_ON(!RB_EMPTY_ROOT(&map->root));",
            "\tWARN_ON(!list_empty(&map->list));",
            "",
            "\tbpf_map_area_free(map);",
            "}",
            "static long cgroup_storage_delete_elem(struct bpf_map *map, void *key)",
            "{",
            "\treturn -EINVAL;",
            "}",
            "static int cgroup_storage_check_btf(const struct bpf_map *map,",
            "\t\t\t\t    const struct btf *btf,",
            "\t\t\t\t    const struct btf_type *key_type,",
            "\t\t\t\t    const struct btf_type *value_type)",
            "{",
            "\tif (attach_type_isolated(map)) {",
            "\t\tstruct btf_member *m;",
            "\t\tu32 offset, size;",
            "",
            "\t\t/* Key is expected to be of struct bpf_cgroup_storage_key type,",
            "\t\t * which is:",
            "\t\t * struct bpf_cgroup_storage_key {",
            "\t\t *\t__u64\tcgroup_inode_id;",
            "\t\t *\t__u32\tattach_type;",
            "\t\t * };",
            "\t\t */",
            "",
            "\t\t/*",
            "\t\t * Key_type must be a structure with two fields.",
            "\t\t */",
            "\t\tif (BTF_INFO_KIND(key_type->info) != BTF_KIND_STRUCT ||",
            "\t\t    BTF_INFO_VLEN(key_type->info) != 2)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * The first field must be a 64 bit integer at 0 offset.",
            "\t\t */",
            "\t\tm = (struct btf_member *)(key_type + 1);",
            "\t\tsize = sizeof_field(struct bpf_cgroup_storage_key, cgroup_inode_id);",
            "\t\tif (!btf_member_is_reg_int(btf, key_type, m, 0, size))",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * The second field must be a 32 bit integer at 64 bit offset.",
            "\t\t */",
            "\t\tm++;",
            "\t\toffset = offsetof(struct bpf_cgroup_storage_key, attach_type);",
            "\t\tsize = sizeof_field(struct bpf_cgroup_storage_key, attach_type);",
            "\t\tif (!btf_member_is_reg_int(btf, key_type, m, offset, size))",
            "\t\t\treturn -EINVAL;",
            "\t} else {",
            "\t\tu32 int_data;",
            "",
            "\t\t/*",
            "\t\t * Key is expected to be u64, which stores the cgroup_inode_id",
            "\t\t */",
            "",
            "\t\tif (BTF_INFO_KIND(key_type->info) != BTF_KIND_INT)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\tint_data = *(u32 *)(key_type + 1);",
            "\t\tif (BTF_INT_BITS(int_data) != 64 || BTF_INT_OFFSET(int_data))",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "bpf_percpu_cgroup_storage_update, cgroup_storage_get_next_key, cgroup_storage_map_free, cgroup_storage_delete_elem, cgroup_storage_check_btf",
          "description": "提供了存储遍历、资源释放和BTF类型校验功能，其中delete_elem未实际实现直接返回错误码，check_btf验证键值类型合法性。",
          "similarity": 0.453210711479187
        }
      ]
    }
  ]
}