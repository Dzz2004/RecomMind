{
  "query": "Linux内核消息传递机制实现",
  "timestamp": "2025-12-26 01:13:55",
  "retrieved_files": [
    {
      "source_file": "kernel/notifier.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:11:27\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `notifier.c`\n\n---\n\n# notifier.c 技术文档\n\n## 1. 文件概述\n\n`notifier.c` 是 Linux 内核中实现通知链（notifier chain）机制的核心文件。通知链是一种回调机制，允许内核子系统在特定事件发生时（如系统关机、硬件状态变化等）注册回调函数并被依次调用。该文件提供了原子通知链（atomic notifier chain）和阻塞通知链（blocking notifier chain）的通用注册、注销和调用逻辑，并定义了系统关机时使用的 `reboot_notifier_list`。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct notifier_block`：通知回调的基本单元，包含回调函数指针 `notifier_call`、优先级 `priority` 和下一个节点指针 `next`。\n- `struct atomic_notifier_head`：原子通知链头结构，包含自旋锁 `lock` 和链表头 `head`。\n- `struct blocking_notifier_head`：阻塞通知链头结构，包含读写信号量 `rwsem` 和链表头 `head`。\n- `reboot_notifier_list`：全局阻塞通知链，用于系统关机/重启时通知各子系统。\n\n### 主要函数\n- **通用内部函数**：\n  - `notifier_chain_register()`：将通知块插入链表（按优先级排序）。\n  - `notifier_chain_unregister()`：从链表中移除指定通知块。\n  - `notifier_call_chain()`：遍历并调用通知链中的回调函数。\n  - `notifier_call_chain_robust()`：支持错误回滚的通知调用（先 `val_up`，失败则 `val_down`）。\n\n- **原子通知链接口（导出）**：\n  - `atomic_notifier_chain_register()`\n  - `atomic_notifier_chain_register_unique_prio()`\n  - `atomic_notifier_chain_unregister()`\n  - `atomic_notifier_call_chain()`\n  - `atomic_notifier_call_chain_is_empty()`\n\n- **阻塞通知链接口（部分在文件后续定义）**：\n  - `__blocking_notifier_chain_register()`（内部辅助函数）\n\n## 3. 关键实现\n\n### 通知链注册逻辑\n- 通知块按 `priority` 字段**降序插入**链表（高优先级在前）。\n- `notifier_chain_register()` 支持 `unique_priority` 模式：若启用，则不允许相同优先级的多个通知块共存（返回 `-EBUSY`）。\n- 使用 `rcu_assign_pointer()` 安全地更新指针，确保 RCU 读端可见性。\n- 重复注册同一回调函数会触发 `WARN()` 并返回 `-EEXIST`。\n\n### 通知调用机制\n- `notifier_call_chain()` 遍历链表，依次调用每个 `notifier_call` 回调。\n- 若回调返回值包含 `NOTIFY_STOP_MASK`（如 `NOTIFY_STOP` 或 `NOTIFY_BAD`），则立即终止调用。\n- 支持限制调用数量（`nr_to_call`）和记录已调用数量（`nr_calls`）。\n- 在 `CONFIG_DEBUG_NOTIFIERS` 启用时，会验证回调函数地址是否在内核代码段，防止非法调用。\n\n### 同步机制\n- **原子通知链**：注册/注销使用 `spinlock`（`spin_lock_irqsave`），调用使用 `rcu_read_lock()`，适用于中断上下文。\n- **阻塞通知链**：注册/注销使用 `rwsem`（读写信号量），但**在系统启动阶段**（`SYSTEM_BOOTING`）会绕过锁，直接调用底层注册函数以避免死锁。\n- 注销原子通知块后调用 `synchronize_rcu()` 确保所有读者完成。\n\n### 回滚机制\n- `notifier_call_chain_robust()` 先尝试 `val_up` 事件，若中途失败（返回 `NOTIFY_STOP_MASK`），则反向调用前 `nr-1` 个回调并传入 `val_down` 事件，实现资源回滚。\n\n### 跟踪点支持\n- 通过 `trace/events/notifier.h` 定义了三个跟踪点：\n  - `notifier_register`：注册时触发\n  - `notifier_unregister`：注销时触发  \n  - `notifier_run`：调用回调时触发\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/notifier.h>`：定义通知链核心数据结构和宏（如 `BLOCKING_NOTIFIER_HEAD`）\n  - `<linux/rcupdate.h>`：提供 RCU 同步原语（`rcu_assign_pointer`, `rcu_dereference_raw` 等）\n  - `<linux/spinlock.h>` / `<linux/rwsem.h>`：通过 `notifier.h` 间接依赖，用于同步\n  - `<linux/tracepoint.h>`：通过 `trace/events/notifier.h` 实现跟踪点\n  - `<linux/kdebug.h>`：提供 `func_ptr_is_kernel_text()` 用于调试验证\n  - `<linux/reboot.h>`：声明 `reboot_notifier_list` 的外部使用者\n\n- **导出符号**：\n  - 所有 `atomic_notifier_*` 函数通过 `EXPORT_SYMBOL_GPL` 导出，供其他内核模块使用。\n\n- **架构约束**：\n  - `notifier_call_chain` 和 `atomic_notifier_call_chain` 标记为 `NOKPROBE_SYMBOL`，禁止 kprobes 插桩，确保关键路径稳定性。\n\n## 5. 使用场景\n\n- **系统关机/重启**：`reboot_notifier_list` 被 `kernel/reboot.c` 使用，在 `kernel_restart()`、`kernel_halt()` 等路径中通知驱动停止 DMA、保存状态等。\n- **硬件事件通知**：如 CPU 热插拔、内存热插拔等子系统通过原子或阻塞通知链广播状态变化。\n- **内核子系统解耦**：允许模块在不直接依赖的情况下响应全局事件（如网络子系统监听设备状态变化）。\n- **错误恢复**：`notifier_call_chain_robust()` 用于需要事务性语义的场景（如设备初始化失败时回滚已分配资源）。\n- **调试与追踪**：通过 ftrace 跟踪通知链的注册、注销和调用行为，辅助内核调试。",
      "similarity": 0.6576839089393616,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/notifier.c",
          "start_line": 25,
          "end_line": 136,
          "content": [
            "static int notifier_chain_register(struct notifier_block **nl,",
            "\t\t\t\t   struct notifier_block *n,",
            "\t\t\t\t   bool unique_priority)",
            "{",
            "\twhile ((*nl) != NULL) {",
            "\t\tif (unlikely((*nl) == n)) {",
            "\t\t\tWARN(1, \"notifier callback %ps already registered\",",
            "\t\t\t     n->notifier_call);",
            "\t\t\treturn -EEXIST;",
            "\t\t}",
            "\t\tif (n->priority > (*nl)->priority)",
            "\t\t\tbreak;",
            "\t\tif (n->priority == (*nl)->priority && unique_priority)",
            "\t\t\treturn -EBUSY;",
            "\t\tnl = &((*nl)->next);",
            "\t}",
            "\tn->next = *nl;",
            "\trcu_assign_pointer(*nl, n);",
            "\ttrace_notifier_register((void *)n->notifier_call);",
            "\treturn 0;",
            "}",
            "static int notifier_chain_unregister(struct notifier_block **nl,",
            "\t\tstruct notifier_block *n)",
            "{",
            "\twhile ((*nl) != NULL) {",
            "\t\tif ((*nl) == n) {",
            "\t\t\trcu_assign_pointer(*nl, n->next);",
            "\t\t\ttrace_notifier_unregister((void *)n->notifier_call);",
            "\t\t\treturn 0;",
            "\t\t}",
            "\t\tnl = &((*nl)->next);",
            "\t}",
            "\treturn -ENOENT;",
            "}",
            "static int notifier_call_chain(struct notifier_block **nl,",
            "\t\t\t       unsigned long val, void *v,",
            "\t\t\t       int nr_to_call, int *nr_calls)",
            "{",
            "\tint ret = NOTIFY_DONE;",
            "\tstruct notifier_block *nb, *next_nb;",
            "",
            "\tnb = rcu_dereference_raw(*nl);",
            "",
            "\twhile (nb && nr_to_call) {",
            "\t\tnext_nb = rcu_dereference_raw(nb->next);",
            "",
            "#ifdef CONFIG_DEBUG_NOTIFIERS",
            "\t\tif (unlikely(!func_ptr_is_kernel_text(nb->notifier_call))) {",
            "\t\t\tWARN(1, \"Invalid notifier called!\");",
            "\t\t\tnb = next_nb;",
            "\t\t\tcontinue;",
            "\t\t}",
            "#endif",
            "\t\ttrace_notifier_run((void *)nb->notifier_call);",
            "\t\tret = nb->notifier_call(nb, val, v);",
            "",
            "\t\tif (nr_calls)",
            "\t\t\t(*nr_calls)++;",
            "",
            "\t\tif (ret & NOTIFY_STOP_MASK)",
            "\t\t\tbreak;",
            "\t\tnb = next_nb;",
            "\t\tnr_to_call--;",
            "\t}",
            "\treturn ret;",
            "}",
            "static int notifier_call_chain_robust(struct notifier_block **nl,",
            "\t\t\t\t     unsigned long val_up, unsigned long val_down,",
            "\t\t\t\t     void *v)",
            "{",
            "\tint ret, nr = 0;",
            "",
            "\tret = notifier_call_chain(nl, val_up, v, -1, &nr);",
            "\tif (ret & NOTIFY_STOP_MASK)",
            "\t\tnotifier_call_chain(nl, val_down, v, nr-1, NULL);",
            "",
            "\treturn ret;",
            "}",
            "int atomic_notifier_chain_register(struct atomic_notifier_head *nh,",
            "\t\tstruct notifier_block *n)",
            "{",
            "\tunsigned long flags;",
            "\tint ret;",
            "",
            "\tspin_lock_irqsave(&nh->lock, flags);",
            "\tret = notifier_chain_register(&nh->head, n, false);",
            "\tspin_unlock_irqrestore(&nh->lock, flags);",
            "\treturn ret;",
            "}",
            "int atomic_notifier_chain_register_unique_prio(struct atomic_notifier_head *nh,",
            "\t\t\t\t\t       struct notifier_block *n)",
            "{",
            "\tunsigned long flags;",
            "\tint ret;",
            "",
            "\tspin_lock_irqsave(&nh->lock, flags);",
            "\tret = notifier_chain_register(&nh->head, n, true);",
            "\tspin_unlock_irqrestore(&nh->lock, flags);",
            "\treturn ret;",
            "}",
            "int atomic_notifier_chain_unregister(struct atomic_notifier_head *nh,",
            "\t\tstruct notifier_block *n)",
            "{",
            "\tunsigned long flags;",
            "\tint ret;",
            "",
            "\tspin_lock_irqsave(&nh->lock, flags);",
            "\tret = notifier_chain_unregister(&nh->head, n);",
            "\tspin_unlock_irqrestore(&nh->lock, flags);",
            "\tsynchronize_rcu();",
            "\treturn ret;",
            "}"
          ],
          "function_name": "notifier_chain_register, notifier_chain_unregister, notifier_call_chain, notifier_call_chain_robust, atomic_notifier_chain_register, atomic_notifier_chain_register_unique_prio, atomic_notifier_chain_unregister",
          "description": "实现通用通知链的注册/注销与调用逻辑，支持优先级排序与冲突检测，使用RCU指针保证内存安全，包含原子、阻塞等变体的注册接口。",
          "similarity": 0.5881960391998291
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/notifier.c",
          "start_line": 427,
          "end_line": 519,
          "content": [
            "int raw_notifier_chain_unregister(struct raw_notifier_head *nh,",
            "\t\tstruct notifier_block *n)",
            "{",
            "\treturn notifier_chain_unregister(&nh->head, n);",
            "}",
            "int raw_notifier_call_chain_robust(struct raw_notifier_head *nh,",
            "\t\tunsigned long val_up, unsigned long val_down, void *v)",
            "{",
            "\treturn notifier_call_chain_robust(&nh->head, val_up, val_down, v);",
            "}",
            "int raw_notifier_call_chain(struct raw_notifier_head *nh,",
            "\t\tunsigned long val, void *v)",
            "{",
            "\treturn notifier_call_chain(&nh->head, val, v, -1, NULL);",
            "}",
            "int srcu_notifier_chain_register(struct srcu_notifier_head *nh,",
            "\t\tstruct notifier_block *n)",
            "{",
            "\tint ret;",
            "",
            "\t/*",
            "\t * This code gets used during boot-up, when task switching is",
            "\t * not yet working and interrupts must remain disabled.  At",
            "\t * such times we must not call mutex_lock().",
            "\t */",
            "\tif (unlikely(system_state == SYSTEM_BOOTING))",
            "\t\treturn notifier_chain_register(&nh->head, n, false);",
            "",
            "\tmutex_lock(&nh->mutex);",
            "\tret = notifier_chain_register(&nh->head, n, false);",
            "\tmutex_unlock(&nh->mutex);",
            "\treturn ret;",
            "}",
            "int srcu_notifier_chain_unregister(struct srcu_notifier_head *nh,",
            "\t\tstruct notifier_block *n)",
            "{",
            "\tint ret;",
            "",
            "\t/*",
            "\t * This code gets used during boot-up, when task switching is",
            "\t * not yet working and interrupts must remain disabled.  At",
            "\t * such times we must not call mutex_lock().",
            "\t */",
            "\tif (unlikely(system_state == SYSTEM_BOOTING))",
            "\t\treturn notifier_chain_unregister(&nh->head, n);",
            "",
            "\tmutex_lock(&nh->mutex);",
            "\tret = notifier_chain_unregister(&nh->head, n);",
            "\tmutex_unlock(&nh->mutex);",
            "\tsynchronize_srcu(&nh->srcu);",
            "\treturn ret;",
            "}",
            "int srcu_notifier_call_chain(struct srcu_notifier_head *nh,",
            "\t\tunsigned long val, void *v)",
            "{",
            "\tint ret;",
            "\tint idx;",
            "",
            "\tidx = srcu_read_lock(&nh->srcu);",
            "\tret = notifier_call_chain(&nh->head, val, v, -1, NULL);",
            "\tsrcu_read_unlock(&nh->srcu, idx);",
            "\treturn ret;",
            "}",
            "void srcu_init_notifier_head(struct srcu_notifier_head *nh)",
            "{",
            "\tmutex_init(&nh->mutex);",
            "\tif (init_srcu_struct(&nh->srcu) < 0)",
            "\t\tBUG();",
            "\tnh->head = NULL;",
            "}",
            "int notrace notify_die(enum die_val val, const char *str,",
            "\t       struct pt_regs *regs, long err, int trap, int sig)",
            "{",
            "\tstruct die_args args = {",
            "\t\t.regs\t= regs,",
            "\t\t.str\t= str,",
            "\t\t.err\t= err,",
            "\t\t.trapnr\t= trap,",
            "\t\t.signr\t= sig,",
            "",
            "\t};",
            "\tRCU_LOCKDEP_WARN(!rcu_is_watching(),",
            "\t\t\t   \"notify_die called but RCU thinks we're quiescent\");",
            "\treturn atomic_notifier_call_chain(&die_chain, val, &args);",
            "}",
            "int register_die_notifier(struct notifier_block *nb)",
            "{",
            "\treturn atomic_notifier_chain_register(&die_chain, nb);",
            "}",
            "int unregister_die_notifier(struct notifier_block *nb)",
            "{",
            "\treturn atomic_notifier_chain_unregister(&die_chain, nb);",
            "}"
          ],
          "function_name": "raw_notifier_chain_unregister, raw_notifier_call_chain_robust, raw_notifier_call_chain, srcu_notifier_chain_register, srcu_notifier_chain_unregister, srcu_notifier_call_chain, srcu_init_notifier_head, notify_die, register_die_notifier, unregister_die_notifier",
          "description": "实现基于SRCU的同步通知链操作及死亡通知处理，包含初始化函数、异常通知入口点notify_die，以及注册/注销死亡通知回调的接口。",
          "similarity": 0.5474283695220947
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/notifier.c",
          "start_line": 225,
          "end_line": 325,
          "content": [
            "int atomic_notifier_call_chain(struct atomic_notifier_head *nh,",
            "\t\t\t       unsigned long val, void *v)",
            "{",
            "\tint ret;",
            "",
            "\trcu_read_lock();",
            "\tret = notifier_call_chain(&nh->head, val, v, -1, NULL);",
            "\trcu_read_unlock();",
            "",
            "\treturn ret;",
            "}",
            "bool atomic_notifier_call_chain_is_empty(struct atomic_notifier_head *nh)",
            "{",
            "\treturn !rcu_access_pointer(nh->head);",
            "}",
            "static int __blocking_notifier_chain_register(struct blocking_notifier_head *nh,",
            "\t\t\t\t\t      struct notifier_block *n,",
            "\t\t\t\t\t      bool unique_priority)",
            "{",
            "\tint ret;",
            "",
            "\t/*",
            "\t * This code gets used during boot-up, when task switching is",
            "\t * not yet working and interrupts must remain disabled.  At",
            "\t * such times we must not call down_write().",
            "\t */",
            "\tif (unlikely(system_state == SYSTEM_BOOTING))",
            "\t\treturn notifier_chain_register(&nh->head, n, unique_priority);",
            "",
            "\tdown_write(&nh->rwsem);",
            "\tret = notifier_chain_register(&nh->head, n, unique_priority);",
            "\tup_write(&nh->rwsem);",
            "\treturn ret;",
            "}",
            "int blocking_notifier_chain_register(struct blocking_notifier_head *nh,",
            "\t\tstruct notifier_block *n)",
            "{",
            "\treturn __blocking_notifier_chain_register(nh, n, false);",
            "}",
            "int blocking_notifier_chain_register_unique_prio(struct blocking_notifier_head *nh,",
            "\t\t\t\t\t\t struct notifier_block *n)",
            "{",
            "\treturn __blocking_notifier_chain_register(nh, n, true);",
            "}",
            "int blocking_notifier_chain_unregister(struct blocking_notifier_head *nh,",
            "\t\tstruct notifier_block *n)",
            "{",
            "\tint ret;",
            "",
            "\t/*",
            "\t * This code gets used during boot-up, when task switching is",
            "\t * not yet working and interrupts must remain disabled.  At",
            "\t * such times we must not call down_write().",
            "\t */",
            "\tif (unlikely(system_state == SYSTEM_BOOTING))",
            "\t\treturn notifier_chain_unregister(&nh->head, n);",
            "",
            "\tdown_write(&nh->rwsem);",
            "\tret = notifier_chain_unregister(&nh->head, n);",
            "\tup_write(&nh->rwsem);",
            "\treturn ret;",
            "}",
            "int blocking_notifier_call_chain_robust(struct blocking_notifier_head *nh,",
            "\t\tunsigned long val_up, unsigned long val_down, void *v)",
            "{",
            "\tint ret = NOTIFY_DONE;",
            "",
            "\t/*",
            "\t * We check the head outside the lock, but if this access is",
            "\t * racy then it does not matter what the result of the test",
            "\t * is, we re-check the list after having taken the lock anyway:",
            "\t */",
            "\tif (rcu_access_pointer(nh->head)) {",
            "\t\tdown_read(&nh->rwsem);",
            "\t\tret = notifier_call_chain_robust(&nh->head, val_up, val_down, v);",
            "\t\tup_read(&nh->rwsem);",
            "\t}",
            "\treturn ret;",
            "}",
            "int blocking_notifier_call_chain(struct blocking_notifier_head *nh,",
            "\t\tunsigned long val, void *v)",
            "{",
            "\tint ret = NOTIFY_DONE;",
            "",
            "\t/*",
            "\t * We check the head outside the lock, but if this access is",
            "\t * racy then it does not matter what the result of the test",
            "\t * is, we re-check the list after having taken the lock anyway:",
            "\t */",
            "\tif (rcu_access_pointer(nh->head)) {",
            "\t\tdown_read(&nh->rwsem);",
            "\t\tret = notifier_call_chain(&nh->head, val, v, -1, NULL);",
            "\t\tup_read(&nh->rwsem);",
            "\t}",
            "\treturn ret;",
            "}",
            "int raw_notifier_chain_register(struct raw_notifier_head *nh,",
            "\t\tstruct notifier_block *n)",
            "{",
            "\treturn notifier_chain_register(&nh->head, n, false);",
            "}"
          ],
          "function_name": "atomic_notifier_call_chain, atomic_notifier_call_chain_is_empty, __blocking_notifier_chain_register, blocking_notifier_chain_register, blocking_notifier_chain_register_unique_prio, blocking_notifier_chain_unregister, blocking_notifier_call_chain_robust, blocking_notifier_call_chain, raw_notifier_chain_register",
          "description": "提供原子通知链的调用接口及阻塞通知链的注册/注销方法，处理系统启动初期特殊场景下的同步限制，包含带恢复机制的调用链处理函数。",
          "similarity": 0.546195924282074
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/notifier.c",
          "start_line": 1,
          "end_line": 24,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "#include <linux/kdebug.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/export.h>",
            "#include <linux/notifier.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/reboot.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/notifier.h>",
            "",
            "/*",
            " *\tNotifier list for kernel code which wants to be called",
            " *\tat shutdown. This is used to stop any idling DMA operations",
            " *\tand the like.",
            " */",
            "BLOCKING_NOTIFIER_HEAD(reboot_notifier_list);",
            "",
            "/*",
            " *\tNotifier chain core routines.  The exported routines below",
            " *\tare layered on top of these, with appropriate locking added.",
            " */",
            ""
          ],
          "function_name": null,
          "description": "声明并初始化全局重启通知链头reboot_notifier_list，用于注册系统关机前执行的回调函数，如停止DMA操作。",
          "similarity": 0.46272146701812744
        }
      ]
    },
    {
      "source_file": "kernel/watch_queue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:50:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `watch_queue.c`\n\n---\n\n# watch_queue.c 技术文档\n\n## 文件概述\n\n`watch_queue.c` 实现了 Linux 内核中的**监视队列**（Watch Queue）机制，这是一种基于管道（pipe）构建的通用事件通知系统。该机制允许内核子系统（如文件系统、密钥管理、设备驱动等）向用户空间异步发送结构化通知。用户空间通过创建特殊类型的管道并关联监视队列，即可接收来自内核的各类事件通知。该文件定义了通知的投递、过滤、缓冲管理及与管道集成的核心逻辑。\n\n## 核心功能\n\n### 主要函数\n\n- **`__post_watch_notification()`**  \n  核心通知投递函数。遍历指定 `watch_list` 中所有匹配 `id` 的监视器（`watch`），对每个关联的 `watch_queue` 应用过滤规则、安全检查，并将通知写入底层管道。\n\n- **`post_one_notification()`**  \n  将单个通知写入指定 `watch_queue` 的底层管道缓冲区。负责从预分配的通知页中获取空闲槽位、填充数据、更新管道头指针并唤醒等待读取的进程。\n\n- **`filter_watch_notification()`**  \n  根据 `watch_filter` 中的类型、子类型和信息掩码规则，判断是否允许特定通知通过。\n\n- **`watch_queue_set_size()`**  \n  为监视队列分配预分配的通知缓冲区（页数组和位图），并调整底层管道的环形缓冲区大小。\n\n- **`watch_queue_pipe_buf_release()`**  \n  管道缓冲区释放回调。当用户空间读取完通知后，将对应的通知槽位在位图中标记为空闲，供后续复用。\n\n### 关键数据结构\n\n- **`struct watch_queue`**  \n  表示一个监视队列，包含：\n  - 指向底层 `pipe_inode_info` 的指针\n  - 预分配的通知页数组（`notes`）\n  - 通知槽位空闲位图（`notes_bitmap`）\n  - 通知过滤器（`filter`）\n  - 保护锁（`lock`）\n\n- **`struct watch_notification`**  \n  通用通知记录格式，包含类型（`type`）、子类型（`subtype`）、信息字段（`info`，含长度和ID）及可变负载。\n\n- **`struct watch_filter` / `struct watch_type_filter`**  \n  定义通知过滤规则，支持按类型、子类型及信息字段的位掩码进行精确过滤。\n\n- **`watch_queue_pipe_buf_ops`**  \n  自定义的 `pipe_buf_operations`，用于管理监视队列专用管道缓冲区的生命周期。\n\n## 关键实现\n\n### 基于管道的通知传输\n- 监视队列复用内核管道（`pipe_inode_info`）作为通知传输通道，利用其成熟的读写、轮询、异步通知机制。\n- 通过自定义 `pipe_buf_operations`（`watch_queue_pipe_buf_ops`）实现通知槽位的回收：当用户读取通知后，`release` 回调将对应槽位在 `notes_bitmap` 中置位，标记为空闲。\n\n### 预分配通知缓冲区\n- 通知数据存储在预分配的内核页（`notes`）中，每页划分为多个固定大小（128字节）的槽位（`WATCH_QUEUE_NOTE_SIZE`）。\n- 使用位图（`notes_bitmap`）跟踪槽位使用状态，1 表示空闲。投递通知时通过 `find_first_bit()` 快速查找空闲槽位。\n- 缓冲区大小由用户通过 `watch_queue_set_size()` 设置（1-512个通知），并受管道缓冲区配额限制。\n\n### 通知投递流程\n1. **匹配监视器**：遍历 `watch_list`，查找 `id` 匹配的 `watch`。\n2. **应用过滤**：若队列配置了过滤器，调用 `filter_watch_notification()` 决定是否丢弃。\n3. **安全检查**：调用 LSM 钩子 `security_post_notification()` 进行权限验证。\n4. **写入管道**：\n   - 获取空闲通知槽位，复制通知数据。\n   - 构造 `pipe_buffer` 指向该槽位，设置自定义操作集。\n   - 更新管道 `head` 指针，唤醒等待读取的进程。\n   - 若缓冲区满，标记前一个缓冲区为 `PIPE_BUF_FLAG_LOSS` 表示丢包。\n\n### 并发与同步\n- **RCU 保护**：`watch_list` 和 `watch_queue` 的访问通过 RCU 机制保护，确保遍历时结构体不被释放。\n- **自旋锁**：\n  - `wqueue->lock`：保护 `wqueue` 状态（如 `pipe` 指针有效性）。\n  - `pipe->rd_wait.lock`：保护管道环形缓冲区的读写操作。\n- **原子操作**：管道 `head` 指针使用 `smp_store_release()` 更新，确保与 `pipe_read()` 的同步。\n\n## 依赖关系\n\n- **管道子系统**（`fs/pipe.c`）  \n  依赖管道的核心数据结构（`pipe_inode_info`、`pipe_buffer`）和操作接口（`pipe_buf()`、`pipe_full()`、`generic_pipe_buf_*`）。\n\n- **内存管理**  \n  使用 `alloc_page()`、`kmap_atomic()` 管理通知缓冲区页，`bitmap_alloc()` 管理槽位位图。\n\n- **安全模块**（LSM）  \n  通过 `security_post_notification()` 钩子集成安全策略。\n\n- **用户空间接口**  \n  与 `fs/watch_queue.c` 中的系统调用（如 `watch_queue_set_size()`）协同工作，后者负责创建监视队列并与管道关联。\n\n- **头文件依赖**  \n  `linux/watch_queue.h`（核心数据结构定义）、`linux/pipe_fs_i.h`（管道内部接口）。\n\n## 使用场景\n\n- **文件系统事件监控**  \n  如 `fsnotify` 子系统可通过监视队列向用户空间报告文件访问、修改等事件。\n\n- **密钥管理通知**  \n  内核密钥环（`KEYS`）子系统使用该机制通知密钥状态变更（如过期、撤销）。\n\n- **设备事件上报**  \n  设备驱动可利用监视队列异步上报硬件状态变化或错误事件。\n\n- **通用内核事件分发**  \n  任何需要向特权用户空间守护进程（如 `systemd`）发送结构化事件的内核子系统均可集成此机制。\n\n- **用户空间消费**  \n  应用程序通过 `open(\"/dev/watch_queue\")` 获取监视队列文件描述符，调用 `ioctl()` 设置缓冲区大小和过滤器，然后像读取普通管道一样接收通知。",
      "similarity": 0.6294386386871338,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/watch_queue.c",
          "start_line": 42,
          "end_line": 154,
          "content": [
            "static inline bool lock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_lock_bh(&wqueue->lock);",
            "\tif (unlikely(!wqueue->pipe)) {",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "\t\treturn false;",
            "\t}",
            "\treturn true;",
            "}",
            "static inline void unlock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_unlock_bh(&wqueue->lock);",
            "}",
            "static void watch_queue_pipe_buf_release(struct pipe_inode_info *pipe,",
            "\t\t\t\t\t struct pipe_buffer *buf)",
            "{",
            "\tstruct watch_queue *wqueue = (struct watch_queue *)buf->private;",
            "\tstruct page *page;",
            "\tunsigned int bit;",
            "",
            "\t/* We need to work out which note within the page this refers to, but",
            "\t * the note might have been maximum size, so merely ANDing the offset",
            "\t * off doesn't work.  OTOH, the note must've been more than zero size.",
            "\t */",
            "\tbit = buf->offset + buf->len;",
            "\tif ((bit & (WATCH_QUEUE_NOTE_SIZE - 1)) == 0)",
            "\t\tbit -= WATCH_QUEUE_NOTE_SIZE;",
            "\tbit /= WATCH_QUEUE_NOTE_SIZE;",
            "",
            "\tpage = buf->page;",
            "\tbit += page->index;",
            "",
            "\tset_bit(bit, wqueue->notes_bitmap);",
            "\tgeneric_pipe_buf_release(pipe, buf);",
            "}",
            "static bool post_one_notification(struct watch_queue *wqueue,",
            "\t\t\t\t  struct watch_notification *n)",
            "{",
            "\tvoid *p;",
            "\tstruct pipe_inode_info *pipe = wqueue->pipe;",
            "\tstruct pipe_buffer *buf;",
            "\tstruct page *page;",
            "\tunsigned int head, tail, note, offset, len;",
            "\tbool done = false;",
            "",
            "\tspin_lock_irq(&pipe->rd_wait.lock);",
            "",
            "\thead = pipe->head;",
            "\ttail = pipe->tail;",
            "\tif (pipe_full(head, tail, pipe->ring_size))",
            "\t\tgoto lost;",
            "",
            "\tnote = find_first_bit(wqueue->notes_bitmap, wqueue->nr_notes);",
            "\tif (note >= wqueue->nr_notes)",
            "\t\tgoto lost;",
            "",
            "\tpage = wqueue->notes[note / WATCH_QUEUE_NOTES_PER_PAGE];",
            "\toffset = note % WATCH_QUEUE_NOTES_PER_PAGE * WATCH_QUEUE_NOTE_SIZE;",
            "\tget_page(page);",
            "\tlen = n->info & WATCH_INFO_LENGTH;",
            "\tp = kmap_atomic(page);",
            "\tmemcpy(p + offset, n, len);",
            "\tkunmap_atomic(p);",
            "",
            "\tbuf = pipe_buf(pipe, head);",
            "\tbuf->page = page;",
            "\tbuf->private = (unsigned long)wqueue;",
            "\tbuf->ops = &watch_queue_pipe_buf_ops;",
            "\tbuf->offset = offset;",
            "\tbuf->len = len;",
            "\tbuf->flags = PIPE_BUF_FLAG_WHOLE;",
            "\tsmp_store_release(&pipe->head, head + 1); /* vs pipe_read() */",
            "",
            "\tif (!test_and_clear_bit(note, wqueue->notes_bitmap)) {",
            "\t\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\t\tBUG();",
            "\t}",
            "\twake_up_interruptible_sync_poll_locked(&pipe->rd_wait, EPOLLIN | EPOLLRDNORM);",
            "\tdone = true;",
            "",
            "out:",
            "\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\tif (done)",
            "\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);",
            "\treturn done;",
            "",
            "lost:",
            "\tbuf = pipe_buf(pipe, head - 1);",
            "\tbuf->flags |= PIPE_BUF_FLAG_LOSS;",
            "\tgoto out;",
            "}",
            "static bool filter_watch_notification(const struct watch_filter *wf,",
            "\t\t\t\t      const struct watch_notification *n)",
            "{",
            "\tconst struct watch_type_filter *wt;",
            "\tunsigned int st_bits = sizeof(wt->subtype_filter[0]) * 8;",
            "\tunsigned int st_index = n->subtype / st_bits;",
            "\tunsigned int st_bit = 1U << (n->subtype % st_bits);",
            "\tint i;",
            "",
            "\tif (!test_bit(n->type, wf->type_filter))",
            "\t\treturn false;",
            "",
            "\tfor (i = 0; i < wf->nr_filters; i++) {",
            "\t\twt = &wf->filters[i];",
            "\t\tif (n->type == wt->type &&",
            "\t\t    (wt->subtype_filter[st_index] & st_bit) &&",
            "\t\t    (n->info & wt->info_mask) == wt->info_filter)",
            "\t\t\treturn true;",
            "\t}",
            "",
            "\treturn false; /* If there is a filter, the default is to reject. */",
            "}"
          ],
          "function_name": "lock_wqueue, unlock_wqueue, watch_queue_pipe_buf_release, post_one_notification, filter_watch_notification",
          "description": "实现了watch_queue的锁操作、缓冲区释放、通知提交及过滤逻辑。lock_wqueue/unlock_wqueue用于保护队列访问，watch_queue_pipe_buf_release处理缓冲区回收并更新位图，post_one_notification将通知数据写入管道，filter_watch_notification进行类型和子类型的匹配判断。",
          "similarity": 0.5339833498001099
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/watch_queue.c",
          "start_line": 1,
          "end_line": 41,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/* Watch queue and general notification mechanism, built on pipes",
            " *",
            " * Copyright (C) 2020 Red Hat, Inc. All Rights Reserved.",
            " * Written by David Howells (dhowells@redhat.com)",
            " *",
            " * See Documentation/core-api/watch_queue.rst",
            " */",
            "",
            "#define pr_fmt(fmt) \"watchq: \" fmt",
            "#include <linux/module.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/printk.h>",
            "#include <linux/miscdevice.h>",
            "#include <linux/fs.h>",
            "#include <linux/mm.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/poll.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <linux/security.h>",
            "#include <linux/cred.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/watch_queue.h>",
            "#include <linux/pipe_fs_i.h>",
            "",
            "MODULE_DESCRIPTION(\"Watch queue\");",
            "MODULE_AUTHOR(\"Red Hat, Inc.\");",
            "",
            "#define WATCH_QUEUE_NOTE_SIZE 128",
            "#define WATCH_QUEUE_NOTES_PER_PAGE (PAGE_SIZE / WATCH_QUEUE_NOTE_SIZE)",
            "",
            "/*",
            " * This must be called under the RCU read-lock, which makes",
            " * sure that the wqueue still exists. It can then take the lock,",
            " * and check that the wqueue hasn't been destroyed, which in",
            " * turn makes sure that the notification pipe still exists.",
            " */"
          ],
          "function_name": null,
          "description": "定义了watch_queue模块的头部信息，包含常量WATCH_QUEUE_NOTE_SIZE和NOTES_PER_PAGE，声明模块许可证及作者信息，并引入相关内核头文件，为后续实现提供基础框架。",
          "similarity": 0.511110782623291
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/watch_queue.c",
          "start_line": 315,
          "end_line": 422,
          "content": [
            "long watch_queue_set_filter(struct pipe_inode_info *pipe,",
            "\t\t\t    struct watch_notification_filter __user *_filter)",
            "{",
            "\tstruct watch_notification_type_filter *tf;",
            "\tstruct watch_notification_filter filter;",
            "\tstruct watch_type_filter *q;",
            "\tstruct watch_filter *wfilter;",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tint ret, nr_filter = 0, i;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "",
            "\tif (!_filter) {",
            "\t\t/* Remove the old filter */",
            "\t\twfilter = NULL;",
            "\t\tgoto set;",
            "\t}",
            "",
            "\t/* Grab the user's filter specification */",
            "\tif (copy_from_user(&filter, _filter, sizeof(filter)) != 0)",
            "\t\treturn -EFAULT;",
            "\tif (filter.nr_filters == 0 ||",
            "\t    filter.nr_filters > 16 ||",
            "\t    filter.__reserved != 0)",
            "\t\treturn -EINVAL;",
            "",
            "\ttf = memdup_array_user(_filter->filters, filter.nr_filters, sizeof(*tf));",
            "\tif (IS_ERR(tf))",
            "\t\treturn PTR_ERR(tf);",
            "",
            "\tret = -EINVAL;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif ((tf[i].info_filter & ~tf[i].info_mask) ||",
            "\t\t    tf[i].info_mask & WATCH_INFO_LENGTH)",
            "\t\t\tgoto err_filter;",
            "\t\t/* Ignore any unknown types */",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "\t\tnr_filter++;",
            "\t}",
            "",
            "\t/* Now we need to build the internal filter from only the relevant",
            "\t * user-specified filters.",
            "\t */",
            "\tret = -ENOMEM;",
            "\twfilter = kzalloc(struct_size(wfilter, filters, nr_filter), GFP_KERNEL);",
            "\tif (!wfilter)",
            "\t\tgoto err_filter;",
            "\twfilter->nr_filters = nr_filter;",
            "",
            "\tq = wfilter->filters;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "",
            "\t\tq->type\t\t\t= tf[i].type;",
            "\t\tq->info_filter\t\t= tf[i].info_filter;",
            "\t\tq->info_mask\t\t= tf[i].info_mask;",
            "\t\tq->subtype_filter[0]\t= tf[i].subtype_filter[0];",
            "\t\t__set_bit(q->type, wfilter->type_filter);",
            "\t\tq++;",
            "\t}",
            "",
            "\tkfree(tf);",
            "set:",
            "\tpipe_lock(pipe);",
            "\twfilter = rcu_replace_pointer(wqueue->filter, wfilter,",
            "\t\t\t\t      lockdep_is_held(&pipe->mutex));",
            "\tpipe_unlock(pipe);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\treturn 0;",
            "",
            "err_filter:",
            "\tkfree(tf);",
            "\treturn ret;",
            "}",
            "static void __put_watch_queue(struct kref *kref)",
            "{",
            "\tstruct watch_queue *wqueue =",
            "\t\tcontainer_of(kref, struct watch_queue, usage);",
            "\tstruct watch_filter *wfilter;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < wqueue->nr_pages; i++)",
            "\t\t__free_page(wqueue->notes[i]);",
            "\tkfree(wqueue->notes);",
            "\tbitmap_free(wqueue->notes_bitmap);",
            "",
            "\twfilter = rcu_access_pointer(wqueue->filter);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\tkfree_rcu(wqueue, rcu);",
            "}",
            "void put_watch_queue(struct watch_queue *wqueue)",
            "{",
            "\tkref_put(&wqueue->usage, __put_watch_queue);",
            "}",
            "static void free_watch(struct rcu_head *rcu)",
            "{",
            "\tstruct watch *watch = container_of(rcu, struct watch, rcu);",
            "",
            "\tput_watch_queue(rcu_access_pointer(watch->queue));",
            "\tatomic_dec(&watch->cred->user->nr_watches);",
            "\tput_cred(watch->cred);",
            "\tkfree(watch);",
            "}"
          ],
          "function_name": "watch_queue_set_filter, __put_watch_queue, put_watch_queue, free_watch",
          "description": "watch_queue_set_filter设置过滤规则并转换为内核内部结构，__put_watch_queue释放watch_queue相关资源包括页面、位图和过滤器，put_watch_queue通过引用计数管理watch_queue生命周期，free_watch执行RCU回调完成最终释放。",
          "similarity": 0.47461313009262085
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/watch_queue.c",
          "start_line": 602,
          "end_line": 680,
          "content": [
            "void watch_queue_clear(struct watch_queue *wqueue)",
            "{",
            "\tstruct watch_list *wlist;",
            "\tstruct watch *watch;",
            "\tbool release;",
            "",
            "\trcu_read_lock();",
            "\tspin_lock_bh(&wqueue->lock);",
            "",
            "\t/*",
            "\t * This pipe can be freed by callers like free_pipe_info().",
            "\t * Removing this reference also prevents new notifications.",
            "\t */",
            "\twqueue->pipe = NULL;",
            "",
            "\twhile (!hlist_empty(&wqueue->watches)) {",
            "\t\twatch = hlist_entry(wqueue->watches.first, struct watch, queue_node);",
            "\t\thlist_del_init_rcu(&watch->queue_node);",
            "\t\t/* We now own a ref on the watch. */",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "",
            "\t\t/* We can't do the next bit under the queue lock as we need to",
            "\t\t * get the list lock - which would cause a deadlock if someone",
            "\t\t * was removing from the opposite direction at the same time or",
            "\t\t * posting a notification.",
            "\t\t */",
            "\t\twlist = rcu_dereference(watch->watch_list);",
            "\t\tif (wlist) {",
            "\t\t\tvoid (*release_watch)(struct watch *);",
            "",
            "\t\t\tspin_lock(&wlist->lock);",
            "",
            "\t\t\trelease = !hlist_unhashed(&watch->list_node);",
            "\t\t\tif (release) {",
            "\t\t\t\thlist_del_init_rcu(&watch->list_node);",
            "\t\t\t\trcu_assign_pointer(watch->watch_list, NULL);",
            "",
            "\t\t\t\t/* We now own a second ref on the watch. */",
            "\t\t\t}",
            "",
            "\t\t\trelease_watch = wlist->release_watch;",
            "\t\t\tspin_unlock(&wlist->lock);",
            "",
            "\t\t\tif (release) {",
            "\t\t\t\tif (release_watch) {",
            "\t\t\t\t\trcu_read_unlock();",
            "\t\t\t\t\t/* This might need to call dput(), so",
            "\t\t\t\t\t * we have to drop all the locks.",
            "\t\t\t\t\t */",
            "\t\t\t\t\t(*release_watch)(watch);",
            "\t\t\t\t\trcu_read_lock();",
            "\t\t\t\t}",
            "\t\t\t\tput_watch(watch);",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tput_watch(watch);",
            "\t\tspin_lock_bh(&wqueue->lock);",
            "\t}",
            "",
            "\tspin_unlock_bh(&wqueue->lock);",
            "\trcu_read_unlock();",
            "}",
            "int watch_queue_init(struct pipe_inode_info *pipe)",
            "{",
            "\tstruct watch_queue *wqueue;",
            "",
            "\twqueue = kzalloc(sizeof(*wqueue), GFP_KERNEL);",
            "\tif (!wqueue)",
            "\t\treturn -ENOMEM;",
            "",
            "\twqueue->pipe = pipe;",
            "\tkref_init(&wqueue->usage);",
            "\tspin_lock_init(&wqueue->lock);",
            "\tINIT_HLIST_HEAD(&wqueue->watches);",
            "",
            "\tpipe->watch_queue = wqueue;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "watch_queue_clear, watch_queue_init",
          "description": "该代码实现了监视队列的初始化与清理功能。  \n`watch_queue_clear`通过RCU和自旋锁机制安全地移除所有监视项并释放资源，`watch_queue_init`初始化监视队列结构并绑定至管道对象。  \n上下文不完整：`release_watch`等关键函数依赖外部定义，部分RCU回调逻辑未完全展示。",
          "similarity": 0.4533105492591858
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/watch_queue.c",
          "start_line": 193,
          "end_line": 304,
          "content": [
            "void __post_watch_notification(struct watch_list *wlist,",
            "\t\t\t       struct watch_notification *n,",
            "\t\t\t       const struct cred *cred,",
            "\t\t\t       u64 id)",
            "{",
            "\tconst struct watch_filter *wf;",
            "\tstruct watch_queue *wqueue;",
            "\tstruct watch *watch;",
            "",
            "\tif (((n->info & WATCH_INFO_LENGTH) >> WATCH_INFO_LENGTH__SHIFT) == 0) {",
            "\t\tWARN_ON(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\trcu_read_lock();",
            "",
            "\thlist_for_each_entry_rcu(watch, &wlist->watchers, list_node) {",
            "\t\tif (watch->id != id)",
            "\t\t\tcontinue;",
            "\t\tn->info &= ~WATCH_INFO_ID;",
            "\t\tn->info |= watch->info_id;",
            "",
            "\t\twqueue = rcu_dereference(watch->queue);",
            "\t\twf = rcu_dereference(wqueue->filter);",
            "\t\tif (wf && !filter_watch_notification(wf, n))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (security_post_notification(watch->cred, cred, n) < 0)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (lock_wqueue(wqueue)) {",
            "\t\t\tpost_one_notification(wqueue, n);",
            "\t\t\tunlock_wqueue(wqueue);",
            "\t\t}",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "}",
            "long watch_queue_set_size(struct pipe_inode_info *pipe, unsigned int nr_notes)",
            "{",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tstruct page **pages;",
            "\tunsigned long *bitmap;",
            "\tunsigned long user_bufs;",
            "\tint ret, i, nr_pages;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "\tif (wqueue->notes)",
            "\t\treturn -EBUSY;",
            "",
            "\tif (nr_notes < 1 ||",
            "\t    nr_notes > 512) /* TODO: choose a better hard limit */",
            "\t\treturn -EINVAL;",
            "",
            "\tnr_pages = (nr_notes + WATCH_QUEUE_NOTES_PER_PAGE - 1);",
            "\tnr_pages /= WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tuser_bufs = account_pipe_buffers(pipe->user, pipe->nr_accounted, nr_pages);",
            "",
            "\tif (nr_pages > pipe->max_usage &&",
            "\t    (too_many_pipe_buffers_hard(user_bufs) ||",
            "\t     too_many_pipe_buffers_soft(user_bufs)) &&",
            "\t    pipe_is_unprivileged_user()) {",
            "\t\tret = -EPERM;",
            "\t\tgoto error;",
            "\t}",
            "",
            "\tnr_notes = nr_pages * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tret = pipe_resize_ring(pipe, roundup_pow_of_two(nr_notes));",
            "\tif (ret < 0)",
            "\t\tgoto error;",
            "",
            "\t/*",
            "\t * pipe_resize_ring() does not update nr_accounted for watch_queue",
            "\t * pipes, because the above vastly overprovisions. Set nr_accounted on",
            "\t * and max_usage this pipe to the number that was actually charged to",
            "\t * the user above via account_pipe_buffers.",
            "\t */",
            "\tpipe->max_usage = nr_pages;",
            "\tpipe->nr_accounted = nr_pages;",
            "",
            "\tret = -ENOMEM;",
            "\tpages = kcalloc(sizeof(struct page *), nr_pages, GFP_KERNEL);",
            "\tif (!pages)",
            "\t\tgoto error;",
            "",
            "\tfor (i = 0; i < nr_pages; i++) {",
            "\t\tpages[i] = alloc_page(GFP_KERNEL);",
            "\t\tif (!pages[i])",
            "\t\t\tgoto error_p;",
            "\t\tpages[i]->index = i * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\t}",
            "",
            "\tbitmap = bitmap_alloc(nr_notes, GFP_KERNEL);",
            "\tif (!bitmap)",
            "\t\tgoto error_p;",
            "",
            "\tbitmap_fill(bitmap, nr_notes);",
            "\twqueue->notes = pages;",
            "\twqueue->notes_bitmap = bitmap;",
            "\twqueue->nr_pages = nr_pages;",
            "\twqueue->nr_notes = nr_notes;",
            "\treturn 0;",
            "",
            "error_p:",
            "\twhile (--i >= 0)",
            "\t\t__free_page(pages[i]);",
            "\tkfree(pages);",
            "error:",
            "\t(void) account_pipe_buffers(pipe->user, nr_pages, pipe->nr_accounted);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__post_watch_notification, watch_queue_set_size",
          "description": "__post_watch_notification遍历watch列表并应用过滤器后提交通知，watch_queue_set_size动态调整管道容量，通过计算所需页数和位图分配，限制最大容量为512个笔记，支持扩展性需求。",
          "similarity": 0.44139403104782104
        }
      ]
    },
    {
      "source_file": "kernel/fork.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:30:07\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `fork.c`\n\n---\n\n# fork.c 技术文档\n\n## 1. 文件概述\n\n`fork.c` 是 Linux 内核中实现进程创建（fork）系统调用的核心源文件。该文件包含了创建新进程所需的所有辅助例程，负责复制父进程的资源（如内存、文件描述符、信号处理等）以生成子进程。虽然 fork 逻辑本身概念简单，但其涉及的内存管理（尤其是写时复制 COW 机制）极为复杂，实际内存页的复制由 `mm/memory.c` 中的 `copy_page_range()` 等函数处理。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `total_forks`: 累计系统自启动以来创建的进程总数\n- `nr_threads`: 当前系统中的线程总数（不包括 idle 线程）\n- `max_threads`: 可配置的线程数量上限（默认为 `FUTEX_TID_MASK`）\n- `process_counts`: 每 CPU 的进程计数器（per-CPU 变量）\n- `tasklist_lock`: 保护任务链表的读写锁（全局任务列表的同步原语）\n\n### 关键辅助函数\n- `nr_processes()`: 计算系统中所有进程的总数（聚合各 CPU 的 `process_counts`）\n- `arch_release_task_struct()`: 架构相关的 task_struct 释放钩子（弱符号，默认为空）\n- `alloc_task_struct_node()` / `free_task_struct()`: 分配/释放 `task_struct` 结构（基于 slab 分配器）\n- `alloc_thread_stack_node()` / `thread_stack_delayed_free()`: 分配/延迟释放线程内核栈（支持 `CONFIG_VMAP_STACK`）\n\n### 核心数据结构\n- `resident_page_types[]`: 用于内存统计的页面类型名称映射数组\n- `vm_stack`: 用于 RCU 延迟释放的虚拟内存栈封装结构\n- `cached_stacks[NR_CACHED_STACKS]`: 每 CPU 的内核栈缓存（减少频繁 vmalloc/vfree 开销）\n\n## 3. 关键实现\n\n### 进程/线程计数管理\n- 使用 per-CPU 变量 `process_counts` 避免全局锁竞争\n- 全局计数器 `nr_threads` 和 `total_forks` 由 `tasklist_lock` 保护\n- `nr_processes()` 通过遍历所有可能的 CPU 聚合计数\n\n### 内核栈分配策略（`CONFIG_VMAP_STACK`）\n- **缓存机制**：每个 CPU 缓存最多 2 个已释放的栈（`NR_CACHED_STACKS`），减少 TLB 刷新和 vmalloc 开销\n- **内存分配**：\n  - 优先从本地缓存获取栈\n  - 缓存未命中时使用 `__vmalloc_node_range()` 分配连续虚拟地址空间\n  - 显式禁用 `__GFP_ACCOUNT`（因后续手动进行 memcg 计费）\n- **安全清理**：\n  - 重用栈时清零内存（`memset(stack, 0, THREAD_SIZE)`）\n  - KASAN 消毒（`kasan_unpoison_range`）和标签重置\n- **延迟释放**：\n  - 通过 RCU 机制延迟释放栈（`call_rcu`）\n  - 释放时尝试回填缓存，失败则直接 `vfree`\n\n### 内存控制组（memcg）集成\n- 手动对栈的每个物理页进行 memcg 计费（`memcg_kmem_charge_page`）\n- 计费失败时回滚已计费页面（`memcg_kmem_uncharge_page`）\n- 确保内核栈内存纳入 cgroup 内存限制\n\n### 锁与同步\n- `tasklist_lock` 作为全局任务列表的保护锁（读写锁）\n- 提供 `lockdep_tasklist_lock_is_held()` 供 RCU 锁验证使用\n- RCU 用于安全延迟释放内核栈资源\n\n## 4. 依赖关系\n\n### 内核子系统依赖\n- **内存管理 (MM)**：`<linux/mm.h>`, `<linux/vmalloc.h>`, `<linux/memcontrol.h>`\n- **调度器 (Scheduler)**：`<linux/sched/*.h>`, 任务状态和 CPU 绑定\n- **安全模块**：`<linux/security.h>`, `<linux/capability.h>`, `<linux/seccomp.h>`\n- **命名空间**：`<linux/nsproxy.h>`（UTS, IPC, PID, 网络等）\n- **文件系统**：`<linux/fs.h>`, `<linux/fdtable.h>`（文件描述符复制）\n- **跟踪与调试**：`<trace/events/sched.h>`, `<linux/ftrace.h>`, KASAN/KMSAN\n\n### 架构相关依赖\n- `<asm/pgalloc.h>`：页表分配\n- `<asm/mmu_context.h>`：MMU 上下文切换\n- `<asm/tlbflush.h>`：TLB 刷新操作\n- 架构特定的 `THREAD_SIZE` 和栈对齐要求\n\n### 配置选项依赖\n- `CONFIG_VMAP_STACK`：启用虚拟内存分配内核栈\n- `CONFIG_PROVE_RCU`：RCU 锁验证支持\n- `CONFIG_ARCH_TASK_STRUCT_ALLOCATOR`：架构自定义 task_struct 分配器\n- `CONFIG_MEMCG_KMEM`：内核内存 cgroup 支持\n\n## 5. 使用场景\n\n### 进程创建路径\n- **系统调用入口**：`sys_fork()`, `sys_vfork()`, `sys_clone()` 最终调用 `_do_fork()`\n- **内核线程创建**：`kthread_create()` 通过 `kernel_thread()` 触发 fork 逻辑\n- **容器/命名空间初始化**：新 PID/UTS/IPC 命名空间创建时伴随进程 fork\n\n### 资源复制关键点\n- **内存描述符 (mm_struct)**：通过 `dup_mm()` 复制地址空间（COW 页表）\n- **文件描述符表**：`dup_fd()` 复制打开文件表\n- **信号处理**：复制信号掩码和处理函数\n- **POSIX 定时器/异步 I/O**：复制相关上下文（如 `aio`, `posix-timers`）\n\n### 特殊场景处理\n- **写时复制优化**：避免物理内存立即复制，提升 fork 性能\n- **OOM Killer 集成**：在内存不足时参与进程选择\n- **审计与监控**：通过 `audit_alloc()` 和 `proc` 文件系统暴露进程信息\n- **实时性保障**：RT 任务 fork 时保持调度策略和优先级",
      "similarity": 0.6245527863502502,
      "chunks": [
        {
          "chunk_id": 13,
          "file_path": "kernel/fork.c",
          "start_line": 2924,
          "end_line": 3037,
          "content": [
            "pid_t kernel_thread(int (*fn)(void *), void *arg, const char *name,",
            "\t\t    unsigned long flags)",
            "{",
            "\tstruct kernel_clone_args args = {",
            "\t\t.flags\t\t= ((lower_32_bits(flags) | CLONE_VM |",
            "\t\t\t\t    CLONE_UNTRACED) & ~CSIGNAL),",
            "\t\t.exit_signal\t= (lower_32_bits(flags) & CSIGNAL),",
            "\t\t.fn\t\t= fn,",
            "\t\t.fn_arg\t\t= arg,",
            "\t\t.name\t\t= name,",
            "\t\t.kthread\t= 1,",
            "\t};",
            "",
            "\treturn kernel_clone(&args);",
            "}",
            "pid_t user_mode_thread(int (*fn)(void *), void *arg, unsigned long flags)",
            "{",
            "\tstruct kernel_clone_args args = {",
            "\t\t.flags\t\t= ((lower_32_bits(flags) | CLONE_VM |",
            "\t\t\t\t    CLONE_UNTRACED) & ~CSIGNAL),",
            "\t\t.exit_signal\t= (lower_32_bits(flags) & CSIGNAL),",
            "\t\t.fn\t\t= fn,",
            "\t\t.fn_arg\t\t= arg,",
            "\t};",
            "",
            "\treturn kernel_clone(&args);",
            "}",
            "noinline static int copy_clone_args_from_user(struct kernel_clone_args *kargs,",
            "\t\t\t\t\t      struct clone_args __user *uargs,",
            "\t\t\t\t\t      size_t usize)",
            "{",
            "\tint err;",
            "\tstruct clone_args args;",
            "\tpid_t *kset_tid = kargs->set_tid;",
            "",
            "\tBUILD_BUG_ON(offsetofend(struct clone_args, tls) !=",
            "\t\t     CLONE_ARGS_SIZE_VER0);",
            "\tBUILD_BUG_ON(offsetofend(struct clone_args, set_tid_size) !=",
            "\t\t     CLONE_ARGS_SIZE_VER1);",
            "\tBUILD_BUG_ON(offsetofend(struct clone_args, cgroup) !=",
            "\t\t     CLONE_ARGS_SIZE_VER2);",
            "\tBUILD_BUG_ON(sizeof(struct clone_args) != CLONE_ARGS_SIZE_VER2);",
            "",
            "\tif (unlikely(usize > PAGE_SIZE))",
            "\t\treturn -E2BIG;",
            "\tif (unlikely(usize < CLONE_ARGS_SIZE_VER0))",
            "\t\treturn -EINVAL;",
            "",
            "\terr = copy_struct_from_user(&args, sizeof(args), uargs, usize);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tif (unlikely(args.set_tid_size > MAX_PID_NS_LEVEL))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (unlikely(!args.set_tid && args.set_tid_size > 0))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (unlikely(args.set_tid && args.set_tid_size == 0))",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * Verify that higher 32bits of exit_signal are unset and that",
            "\t * it is a valid signal",
            "\t */",
            "\tif (unlikely((args.exit_signal & ~((u64)CSIGNAL)) ||",
            "\t\t     !valid_signal(args.exit_signal)))",
            "\t\treturn -EINVAL;",
            "",
            "\tif ((args.flags & CLONE_INTO_CGROUP) &&",
            "\t    (args.cgroup > INT_MAX || usize < CLONE_ARGS_SIZE_VER2))",
            "\t\treturn -EINVAL;",
            "",
            "\t*kargs = (struct kernel_clone_args){",
            "\t\t.flags\t\t= args.flags,",
            "\t\t.pidfd\t\t= u64_to_user_ptr(args.pidfd),",
            "\t\t.child_tid\t= u64_to_user_ptr(args.child_tid),",
            "\t\t.parent_tid\t= u64_to_user_ptr(args.parent_tid),",
            "\t\t.exit_signal\t= args.exit_signal,",
            "\t\t.stack\t\t= args.stack,",
            "\t\t.stack_size\t= args.stack_size,",
            "\t\t.tls\t\t= args.tls,",
            "\t\t.set_tid_size\t= args.set_tid_size,",
            "\t\t.cgroup\t\t= args.cgroup,",
            "\t};",
            "",
            "\tif (args.set_tid &&",
            "\t\tcopy_from_user(kset_tid, u64_to_user_ptr(args.set_tid),",
            "\t\t\t(kargs->set_tid_size * sizeof(pid_t))))",
            "\t\treturn -EFAULT;",
            "",
            "\tkargs->set_tid = kset_tid;",
            "",
            "\treturn 0;",
            "}",
            "static inline bool clone3_stack_valid(struct kernel_clone_args *kargs)",
            "{",
            "\tif (kargs->stack == 0) {",
            "\t\tif (kargs->stack_size > 0)",
            "\t\t\treturn false;",
            "\t} else {",
            "\t\tif (kargs->stack_size == 0)",
            "\t\t\treturn false;",
            "",
            "\t\tif (!access_ok((void __user *)kargs->stack, kargs->stack_size))",
            "\t\t\treturn false;",
            "",
            "#if !defined(CONFIG_STACK_GROWSUP)",
            "\t\tkargs->stack += kargs->stack_size;",
            "#endif",
            "\t}",
            "",
            "\treturn true;",
            "}"
          ],
          "function_name": "kernel_thread, user_mode_thread, copy_clone_args_from_user, clone3_stack_valid",
          "description": "提供内核线程与用户线程创建接口，解析并验证clone3参数，转换用户空间clone_args到内核结构体，校验栈地址有效性",
          "similarity": 0.5812713503837585
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/fork.c",
          "start_line": 666,
          "end_line": 845,
          "content": [
            "static __latent_entropy int dup_mmap(struct mm_struct *mm,",
            "\t\t\t\t\tstruct mm_struct *oldmm)",
            "{",
            "\tstruct vm_area_struct *mpnt, *tmp;",
            "\tint retval;",
            "\tunsigned long charge = 0;",
            "\tLIST_HEAD(uf);",
            "\tVMA_ITERATOR(vmi, mm, 0);",
            "",
            "\tuprobe_start_dup_mmap();",
            "\tif (mmap_write_lock_killable(oldmm)) {",
            "\t\tretval = -EINTR;",
            "\t\tgoto fail_uprobe_end;",
            "\t}",
            "\tflush_cache_dup_mm(oldmm);",
            "\tuprobe_dup_mmap(oldmm, mm);",
            "\t/*",
            "\t * Not linked in yet - no deadlock potential:",
            "\t */",
            "\tmmap_write_lock_nested(mm, SINGLE_DEPTH_NESTING);",
            "",
            "\t/* No ordering required: file already has been exposed. */",
            "\tdup_mm_exe_file(mm, oldmm);",
            "",
            "\tmm->total_vm = oldmm->total_vm;",
            "\tmm->data_vm = oldmm->data_vm;",
            "\tmm->exec_vm = oldmm->exec_vm;",
            "\tmm->stack_vm = oldmm->stack_vm;",
            "",
            "\t/* Use __mt_dup() to efficiently build an identical maple tree. */",
            "\tretval = __mt_dup(&oldmm->mm_mt, &mm->mm_mt, GFP_KERNEL);",
            "\tif (unlikely(retval))",
            "\t\tgoto out;",
            "",
            "\tmt_clear_in_rcu(vmi.mas.tree);",
            "\tfor_each_vma(vmi, mpnt) {",
            "\t\tstruct file *file;",
            "",
            "\t\tvma_start_write(mpnt);",
            "\t\tif (mpnt->vm_flags & VM_DONTCOPY) {",
            "\t\t\tretval = vma_iter_clear_gfp(&vmi, mpnt->vm_start,",
            "\t\t\t\t\t\t    mpnt->vm_end, GFP_KERNEL);",
            "\t\t\tif (retval)",
            "\t\t\t\tgoto loop_out;",
            "",
            "\t\t\tvm_stat_account(mm, mpnt->vm_flags, -vma_pages(mpnt));",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tcharge = 0;",
            "\t\t/*",
            "\t\t * Don't duplicate many vmas if we've been oom-killed (for",
            "\t\t * example)",
            "\t\t */",
            "\t\tif (fatal_signal_pending(current)) {",
            "\t\t\tretval = -EINTR;",
            "\t\t\tgoto loop_out;",
            "\t\t}",
            "\t\tif (mpnt->vm_flags & VM_ACCOUNT) {",
            "\t\t\tunsigned long len = vma_pages(mpnt);",
            "",
            "\t\t\tif (security_vm_enough_memory_mm(oldmm, len)) /* sic */",
            "\t\t\t\tgoto fail_nomem;",
            "\t\t\tcharge = len;",
            "\t\t}",
            "\t\ttmp = vm_area_dup(mpnt);",
            "\t\tif (!tmp)",
            "\t\t\tgoto fail_nomem;",
            "",
            "\t\t/* track_pfn_copy() will later take care of copying internal state. */",
            "\t\tif (unlikely(tmp->vm_flags & VM_PFNMAP))",
            "\t\t\tuntrack_pfn_clear(tmp);",
            "",
            "\t\tretval = vma_dup_policy(mpnt, tmp);",
            "\t\tif (retval)",
            "\t\t\tgoto fail_nomem_policy;",
            "\t\ttmp->vm_mm = mm;",
            "\t\tretval = dup_userfaultfd(tmp, &uf);",
            "\t\tif (retval)",
            "\t\t\tgoto fail_nomem_anon_vma_fork;",
            "\t\tif (tmp->vm_flags & VM_WIPEONFORK) {",
            "\t\t\t/*",
            "\t\t\t * VM_WIPEONFORK gets a clean slate in the child.",
            "\t\t\t * Don't prepare anon_vma until fault since we don't",
            "\t\t\t * copy page for current vma.",
            "\t\t\t */",
            "\t\t\ttmp->anon_vma = NULL;",
            "\t\t} else if (anon_vma_fork(tmp, mpnt))",
            "\t\t\tgoto fail_nomem_anon_vma_fork;",
            "\t\tvm_flags_clear(tmp, VM_LOCKED_MASK);",
            "\t\tfile = tmp->vm_file;",
            "\t\tif (file) {",
            "\t\t\tstruct address_space *mapping = file->f_mapping;",
            "",
            "\t\t\tget_file(file);",
            "\t\t\ti_mmap_lock_write(mapping);",
            "\t\t\tif (vma_is_shared_maywrite(tmp))",
            "\t\t\t\tmapping_allow_writable(mapping);",
            "\t\t\tflush_dcache_mmap_lock(mapping);",
            "\t\t\t/* insert tmp into the share list, just after mpnt */",
            "\t\t\tvma_interval_tree_insert_after(tmp, mpnt,",
            "\t\t\t\t\t&mapping->i_mmap);",
            "\t\t\tflush_dcache_mmap_unlock(mapping);",
            "\t\t\ti_mmap_unlock_write(mapping);",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Copy/update hugetlb private vma information.",
            "\t\t */",
            "\t\tif (is_vm_hugetlb_page(tmp))",
            "\t\t\thugetlb_dup_vma_private(tmp);",
            "",
            "\t\t/*",
            "\t\t * Link the vma into the MT. After using __mt_dup(), memory",
            "\t\t * allocation is not necessary here, so it cannot fail.",
            "\t\t */",
            "\t\tvma_iter_bulk_store(&vmi, tmp);",
            "",
            "\t\tmm->map_count++;",
            "\t\tif (!(tmp->vm_flags & VM_WIPEONFORK))",
            "\t\t\tretval = copy_page_range(tmp, mpnt);",
            "",
            "\t\tif (tmp->vm_ops && tmp->vm_ops->open)",
            "\t\t\ttmp->vm_ops->open(tmp);",
            "",
            "\t\tif (retval) {",
            "\t\t\tmpnt = vma_next(&vmi);",
            "\t\t\tgoto loop_out;",
            "\t\t}",
            "\t}",
            "\t/* a new mm has just been created */",
            "\tretval = arch_dup_mmap(oldmm, mm);",
            "loop_out:",
            "\tvma_iter_free(&vmi);",
            "\tif (!retval) {",
            "\t\tmt_set_in_rcu(vmi.mas.tree);",
            "\t\tksm_fork(mm, oldmm);",
            "\t\tkhugepaged_fork(mm, oldmm);",
            "\t} else {",
            "",
            "\t\t/*",
            "\t\t * The entire maple tree has already been duplicated. If the",
            "\t\t * mmap duplication fails, mark the failure point with",
            "\t\t * XA_ZERO_ENTRY. In exit_mmap(), if this marker is encountered,",
            "\t\t * stop releasing VMAs that have not been duplicated after this",
            "\t\t * point.",
            "\t\t */",
            "\t\tif (mpnt) {",
            "\t\t\tmas_set_range(&vmi.mas, mpnt->vm_start, mpnt->vm_end - 1);",
            "\t\t\tmas_store(&vmi.mas, XA_ZERO_ENTRY);",
            "\t\t\t/* Avoid OOM iterating a broken tree */",
            "\t\t\tset_bit(MMF_OOM_SKIP, &mm->flags);",
            "\t\t}",
            "\t\t/*",
            "\t\t * The mm_struct is going to exit, but the locks will be dropped",
            "\t\t * first.  Set the mm_struct as unstable is advisable as it is",
            "\t\t * not fully initialised.",
            "\t\t */",
            "\t\tset_bit(MMF_UNSTABLE, &mm->flags);",
            "\t}",
            "out:",
            "\tmmap_write_unlock(mm);",
            "\tflush_tlb_mm(oldmm);",
            "\tmmap_write_unlock(oldmm);",
            "\tif (!retval)",
            "\t\tdup_userfaultfd_complete(&uf);",
            "\telse",
            "\t\tdup_userfaultfd_fail(&uf);",
            "fail_uprobe_end:",
            "\tuprobe_end_dup_mmap();",
            "\treturn retval;",
            "",
            "fail_nomem_anon_vma_fork:",
            "\tmpol_put(vma_policy(tmp));",
            "fail_nomem_policy:",
            "\tvm_area_free(tmp);",
            "fail_nomem:",
            "\tretval = -ENOMEM;",
            "\tvm_unacct_memory(charge);",
            "\tgoto loop_out;",
            "}"
          ],
          "function_name": "dup_mmap",
          "description": "实现进程fork时的内存映射复制逻辑，深度遍历原进程的VMA结构创建副本，处理共享文件映射、hugetlb页等特殊内存类型，并管理OOM异常情况下的失败恢复。",
          "similarity": 0.5772550106048584
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/fork.c",
          "start_line": 847,
          "end_line": 965,
          "content": [
            "static inline int mm_alloc_pgd(struct mm_struct *mm)",
            "{",
            "\tmm->pgd = pgd_alloc(mm);",
            "\tif (unlikely(!mm->pgd))",
            "\t\treturn -ENOMEM;",
            "\treturn 0;",
            "}",
            "static inline void mm_free_pgd(struct mm_struct *mm)",
            "{",
            "\tpgd_free(mm, mm->pgd);",
            "}",
            "static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)",
            "{",
            "\tmmap_write_lock(oldmm);",
            "\tdup_mm_exe_file(mm, oldmm);",
            "\tmmap_write_unlock(oldmm);",
            "\treturn 0;",
            "}",
            "static void check_mm(struct mm_struct *mm)",
            "{",
            "\tint i;",
            "",
            "\tBUILD_BUG_ON_MSG(ARRAY_SIZE(resident_page_types) != NR_MM_COUNTERS,",
            "\t\t\t \"Please make sure 'struct resident_page_types[]' is updated as well\");",
            "",
            "\tfor (i = 0; i < NR_MM_COUNTERS; i++) {",
            "\t\tlong x = percpu_counter_sum(&mm->rss_stat[i]);",
            "",
            "\t\tif (unlikely(x))",
            "\t\t\tpr_alert(\"BUG: Bad rss-counter state mm:%p type:%s val:%ld\\n\",",
            "\t\t\t\t mm, resident_page_types[i], x);",
            "\t}",
            "",
            "\tif (mm_pgtables_bytes(mm))",
            "\t\tpr_alert(\"BUG: non-zero pgtables_bytes on freeing mm: %ld\\n\",",
            "\t\t\t\tmm_pgtables_bytes(mm));",
            "",
            "#if defined(CONFIG_TRANSPARENT_HUGEPAGE) && !defined(CONFIG_SPLIT_PMD_PTLOCKS)",
            "\tVM_BUG_ON_MM(mm->pmd_huge_pte, mm);",
            "#endif",
            "}",
            "static void do_check_lazy_tlb(void *arg)",
            "{",
            "\tstruct mm_struct *mm = arg;",
            "",
            "\tWARN_ON_ONCE(current->active_mm == mm);",
            "}",
            "static void do_shoot_lazy_tlb(void *arg)",
            "{",
            "\tstruct mm_struct *mm = arg;",
            "",
            "\tif (current->active_mm == mm) {",
            "\t\tWARN_ON_ONCE(current->mm);",
            "\t\tcurrent->active_mm = &init_mm;",
            "\t\tswitch_mm(mm, &init_mm, current);",
            "\t}",
            "}",
            "static void cleanup_lazy_tlbs(struct mm_struct *mm)",
            "{",
            "\tif (!IS_ENABLED(CONFIG_MMU_LAZY_TLB_SHOOTDOWN)) {",
            "\t\t/*",
            "\t\t * In this case, lazy tlb mms are refounted and would not reach",
            "\t\t * __mmdrop until all CPUs have switched away and mmdrop()ed.",
            "\t\t */",
            "\t\treturn;",
            "\t}",
            "",
            "\t/*",
            "\t * Lazy mm shootdown does not refcount \"lazy tlb mm\" usage, rather it",
            "\t * requires lazy mm users to switch to another mm when the refcount",
            "\t * drops to zero, before the mm is freed. This requires IPIs here to",
            "\t * switch kernel threads to init_mm.",
            "\t *",
            "\t * archs that use IPIs to flush TLBs can piggy-back that lazy tlb mm",
            "\t * switch with the final userspace teardown TLB flush which leaves the",
            "\t * mm lazy on this CPU but no others, reducing the need for additional",
            "\t * IPIs here. There are cases where a final IPI is still required here,",
            "\t * such as the final mmdrop being performed on a different CPU than the",
            "\t * one exiting, or kernel threads using the mm when userspace exits.",
            "\t *",
            "\t * IPI overheads have not found to be expensive, but they could be",
            "\t * reduced in a number of possible ways, for example (roughly",
            "\t * increasing order of complexity):",
            "\t * - The last lazy reference created by exit_mm() could instead switch",
            "\t *   to init_mm, however it's probable this will run on the same CPU",
            "\t *   immediately afterwards, so this may not reduce IPIs much.",
            "\t * - A batch of mms requiring IPIs could be gathered and freed at once.",
            "\t * - CPUs store active_mm where it can be remotely checked without a",
            "\t *   lock, to filter out false-positives in the cpumask.",
            "\t * - After mm_users or mm_count reaches zero, switching away from the",
            "\t *   mm could clear mm_cpumask to reduce some IPIs, perhaps together",
            "\t *   with some batching or delaying of the final IPIs.",
            "\t * - A delayed freeing and RCU-like quiescing sequence based on mm",
            "\t *   switching to avoid IPIs completely.",
            "\t */",
            "\ton_each_cpu_mask(mm_cpumask(mm), do_shoot_lazy_tlb, (void *)mm, 1);",
            "\tif (IS_ENABLED(CONFIG_DEBUG_VM_SHOOT_LAZIES))",
            "\t\ton_each_cpu(do_check_lazy_tlb, (void *)mm, 1);",
            "}",
            "void __mmdrop(struct mm_struct *mm)",
            "{",
            "\tBUG_ON(mm == &init_mm);",
            "\tWARN_ON_ONCE(mm == current->mm);",
            "",
            "\t/* Ensure no CPUs are using this as their lazy tlb mm */",
            "\tcleanup_lazy_tlbs(mm);",
            "",
            "\tWARN_ON_ONCE(mm == current->active_mm);",
            "\tmm_free_pgd(mm);",
            "\tdestroy_context(mm);",
            "\tmmu_notifier_subscriptions_destroy(mm);",
            "\tcheck_mm(mm);",
            "\tput_user_ns(mm->user_ns);",
            "\tmm_pasid_drop(mm);",
            "\tmm_destroy_cid(mm);",
            "\tpercpu_counter_destroy_many(mm->rss_stat, NR_MM_COUNTERS);",
            "",
            "\tfree_mm(mm);",
            "}"
          ],
          "function_name": "mm_alloc_pgd, mm_free_pgd, dup_mmap, check_mm, do_check_lazy_tlb, do_shoot_lazy_tlb, cleanup_lazy_tlbs, __mmdrop",
          "description": "实现mm结构体的页目录表分配与释放，dup_mmap复制mmap信息，check_mm验证内存计数器状态，清理延迟TLB射杀并安全释放mm资源。",
          "similarity": 0.5719475150108337
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/fork.c",
          "start_line": 159,
          "end_line": 303,
          "content": [
            "int lockdep_tasklist_lock_is_held(void)",
            "{",
            "\treturn lockdep_is_held(&tasklist_lock);",
            "}",
            "int nr_processes(void)",
            "{",
            "\tint cpu;",
            "\tint total = 0;",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\ttotal += per_cpu(process_counts, cpu);",
            "",
            "\treturn total;",
            "}",
            "void __weak arch_release_task_struct(struct task_struct *tsk)",
            "{",
            "}",
            "static inline void free_task_struct(struct task_struct *tsk)",
            "{",
            "\tkmem_cache_free(task_struct_cachep, tsk);",
            "}",
            "static bool try_release_thread_stack_to_cache(struct vm_struct *vm)",
            "{",
            "\tunsigned int i;",
            "",
            "\tfor (i = 0; i < NR_CACHED_STACKS; i++) {",
            "\t\tif (this_cpu_cmpxchg(cached_stacks[i], NULL, vm) != NULL)",
            "\t\t\tcontinue;",
            "\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "static void thread_stack_free_rcu(struct rcu_head *rh)",
            "{",
            "\tstruct vm_stack *vm_stack = container_of(rh, struct vm_stack, rcu);",
            "",
            "\tif (try_release_thread_stack_to_cache(vm_stack->stack_vm_area))",
            "\t\treturn;",
            "",
            "\tvfree(vm_stack);",
            "}",
            "static void thread_stack_delayed_free(struct task_struct *tsk)",
            "{",
            "\tstruct vm_stack *vm_stack = tsk->stack;",
            "",
            "\tvm_stack->stack_vm_area = tsk->stack_vm_area;",
            "\tcall_rcu(&vm_stack->rcu, thread_stack_free_rcu);",
            "}",
            "static int free_vm_stack_cache(unsigned int cpu)",
            "{",
            "\tstruct vm_struct **cached_vm_stacks = per_cpu_ptr(cached_stacks, cpu);",
            "\tint i;",
            "",
            "\tfor (i = 0; i < NR_CACHED_STACKS; i++) {",
            "\t\tstruct vm_struct *vm_stack = cached_vm_stacks[i];",
            "",
            "\t\tif (!vm_stack)",
            "\t\t\tcontinue;",
            "",
            "\t\tvfree(vm_stack->addr);",
            "\t\tcached_vm_stacks[i] = NULL;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int memcg_charge_kernel_stack(struct vm_struct *vm)",
            "{",
            "\tint i;",
            "\tint ret;",
            "\tint nr_charged = 0;",
            "",
            "\tBUG_ON(vm->nr_pages != THREAD_SIZE / PAGE_SIZE);",
            "",
            "\tfor (i = 0; i < THREAD_SIZE / PAGE_SIZE; i++) {",
            "\t\tret = memcg_kmem_charge_page(vm->pages[i], GFP_KERNEL, 0);",
            "\t\tif (ret)",
            "\t\t\tgoto err;",
            "\t\tnr_charged++;",
            "\t}",
            "\treturn 0;",
            "err:",
            "\tfor (i = 0; i < nr_charged; i++)",
            "\t\tmemcg_kmem_uncharge_page(vm->pages[i], 0);",
            "\treturn ret;",
            "}",
            "static int alloc_thread_stack_node(struct task_struct *tsk, int node)",
            "{",
            "\tstruct vm_struct *vm;",
            "\tvoid *stack;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < NR_CACHED_STACKS; i++) {",
            "\t\tstruct vm_struct *s;",
            "",
            "\t\ts = this_cpu_xchg(cached_stacks[i], NULL);",
            "",
            "\t\tif (!s)",
            "\t\t\tcontinue;",
            "",
            "\t\t/* Reset stack metadata. */",
            "\t\tkasan_unpoison_range(s->addr, THREAD_SIZE);",
            "",
            "\t\tstack = kasan_reset_tag(s->addr);",
            "",
            "\t\t/* Clear stale pointers from reused stack. */",
            "\t\tmemset(stack, 0, THREAD_SIZE);",
            "",
            "\t\tif (memcg_charge_kernel_stack(s)) {",
            "\t\t\tvfree(s->addr);",
            "\t\t\treturn -ENOMEM;",
            "\t\t}",
            "",
            "\t\ttsk->stack_vm_area = s;",
            "\t\ttsk->stack = stack;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * Allocated stacks are cached and later reused by new threads,",
            "\t * so memcg accounting is performed manually on assigning/releasing",
            "\t * stacks to tasks. Drop __GFP_ACCOUNT.",
            "\t */",
            "\tstack = __vmalloc_node_range(THREAD_SIZE, THREAD_ALIGN,",
            "\t\t\t\t     VMALLOC_START, VMALLOC_END,",
            "\t\t\t\t     THREADINFO_GFP & ~__GFP_ACCOUNT,",
            "\t\t\t\t     PAGE_KERNEL,",
            "\t\t\t\t     0, node, __builtin_return_address(0));",
            "\tif (!stack)",
            "\t\treturn -ENOMEM;",
            "",
            "\tvm = find_vm_area(stack);",
            "\tif (memcg_charge_kernel_stack(vm)) {",
            "\t\tvfree(stack);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "\t/*",
            "\t * We can't call find_vm_area() in interrupt context, and",
            "\t * free_thread_stack() can be called in interrupt context,",
            "\t * so cache the vm_struct.",
            "\t */",
            "\ttsk->stack_vm_area = vm;",
            "\tstack = kasan_reset_tag(stack);",
            "\ttsk->stack = stack;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "lockdep_tasklist_lock_is_held, nr_processes, arch_release_task_struct, free_task_struct, try_release_thread_stack_to_cache, thread_stack_free_rcu, thread_stack_delayed_free, free_vm_stack_cache, memcg_charge_kernel_stack, alloc_thread_stack_node",
          "description": "实现任务列表锁状态检测、进程总数统计及线程栈分配释放逻辑，通过缓存机制优化线程栈复用并利用RCU实现延迟释放，包含栈内存管理和内存会计功能。",
          "similarity": 0.5570398569107056
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/fork.c",
          "start_line": 1863,
          "end_line": 1988,
          "content": [
            "static int copy_sighand(unsigned long clone_flags, struct task_struct *tsk)",
            "{",
            "\tstruct sighand_struct *sig;",
            "",
            "\tif (clone_flags & CLONE_SIGHAND) {",
            "\t\trefcount_inc(&current->sighand->count);",
            "\t\treturn 0;",
            "\t}",
            "\tsig = kmem_cache_alloc(sighand_cachep, GFP_KERNEL);",
            "\tRCU_INIT_POINTER(tsk->sighand, sig);",
            "\tif (!sig)",
            "\t\treturn -ENOMEM;",
            "",
            "\trefcount_set(&sig->count, 1);",
            "\tspin_lock_irq(&current->sighand->siglock);",
            "\tmemcpy(sig->action, current->sighand->action, sizeof(sig->action));",
            "\tspin_unlock_irq(&current->sighand->siglock);",
            "",
            "\t/* Reset all signal handler not set to SIG_IGN to SIG_DFL. */",
            "\tif (clone_flags & CLONE_CLEAR_SIGHAND)",
            "\t\tflush_signal_handlers(tsk, 0);",
            "",
            "\treturn 0;",
            "}",
            "void __cleanup_sighand(struct sighand_struct *sighand)",
            "{",
            "\tif (refcount_dec_and_test(&sighand->count)) {",
            "\t\tsignalfd_cleanup(sighand);",
            "\t\t/*",
            "\t\t * sighand_cachep is SLAB_TYPESAFE_BY_RCU so we can free it",
            "\t\t * without an RCU grace period, see __lock_task_sighand().",
            "\t\t */",
            "\t\tkmem_cache_free(sighand_cachep, sighand);",
            "\t}",
            "}",
            "static void posix_cpu_timers_init_group(struct signal_struct *sig)",
            "{",
            "\tstruct posix_cputimers *pct = &sig->posix_cputimers;",
            "\tunsigned long cpu_limit;",
            "",
            "\tcpu_limit = READ_ONCE(sig->rlim[RLIMIT_CPU].rlim_cur);",
            "\tposix_cputimers_group_init(pct, cpu_limit);",
            "}",
            "static int copy_signal(unsigned long clone_flags, struct task_struct *tsk)",
            "{",
            "\tstruct signal_struct *sig;",
            "",
            "\tif (clone_flags & CLONE_THREAD)",
            "\t\treturn 0;",
            "",
            "\tsig = kmem_cache_zalloc(signal_cachep, GFP_KERNEL);",
            "\ttsk->signal = sig;",
            "\tif (!sig)",
            "\t\treturn -ENOMEM;",
            "",
            "\tsig->nr_threads = 1;",
            "\tsig->quick_threads = 1;",
            "\tatomic_set(&sig->live, 1);",
            "\trefcount_set(&sig->sigcnt, 1);",
            "",
            "\t/* list_add(thread_node, thread_head) without INIT_LIST_HEAD() */",
            "\tsig->thread_head = (struct list_head)LIST_HEAD_INIT(tsk->thread_node);",
            "\ttsk->thread_node = (struct list_head)LIST_HEAD_INIT(sig->thread_head);",
            "",
            "\tinit_waitqueue_head(&sig->wait_chldexit);",
            "\tsig->curr_target = tsk;",
            "\tinit_sigpending(&sig->shared_pending);",
            "\tINIT_HLIST_HEAD(&sig->multiprocess);",
            "\tseqlock_init(&sig->stats_lock);",
            "\tprev_cputime_init(&sig->prev_cputime);",
            "",
            "#ifdef CONFIG_POSIX_TIMERS",
            "\tINIT_LIST_HEAD(&sig->posix_timers);",
            "\thrtimer_init(&sig->real_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);",
            "\tsig->real_timer.function = it_real_fn;",
            "#endif",
            "",
            "\ttask_lock(current->group_leader);",
            "\tmemcpy(sig->rlim, current->signal->rlim, sizeof sig->rlim);",
            "\ttask_unlock(current->group_leader);",
            "",
            "\tposix_cpu_timers_init_group(sig);",
            "",
            "\ttty_audit_fork(sig);",
            "\tsched_autogroup_fork(sig);",
            "",
            "\tsig->oom_score_adj = current->signal->oom_score_adj;",
            "\tsig->oom_score_adj_min = current->signal->oom_score_adj_min;",
            "",
            "\tmutex_init(&sig->cred_guard_mutex);",
            "\tinit_rwsem(&sig->exec_update_lock);",
            "",
            "\treturn 0;",
            "}",
            "static void copy_seccomp(struct task_struct *p)",
            "{",
            "#ifdef CONFIG_SECCOMP",
            "\t/*",
            "\t * Must be called with sighand->lock held, which is common to",
            "\t * all threads in the group. Holding cred_guard_mutex is not",
            "\t * needed because this new task is not yet running and cannot",
            "\t * be racing exec.",
            "\t */",
            "\tassert_spin_locked(&current->sighand->siglock);",
            "",
            "\t/* Ref-count the new filter user, and assign it. */",
            "\tget_seccomp_filter(current);",
            "\tp->seccomp = current->seccomp;",
            "",
            "\t/*",
            "\t * Explicitly enable no_new_privs here in case it got set",
            "\t * between the task_struct being duplicated and holding the",
            "\t * sighand lock. The seccomp state and nnp must be in sync.",
            "\t */",
            "\tif (task_no_new_privs(current))",
            "\t\ttask_set_no_new_privs(p);",
            "",
            "\t/*",
            "\t * If the parent gained a seccomp mode after copying thread",
            "\t * flags and between before we held the sighand lock, we have",
            "\t * to manually enable the seccomp thread flag here.",
            "\t */",
            "\tif (p->seccomp.mode != SECCOMP_MODE_DISABLED)",
            "\t\tset_task_syscall_work(p, SECCOMP);",
            "#endif",
            "}"
          ],
          "function_name": "copy_sighand, __cleanup_sighand, posix_cpu_timers_init_group, copy_signal, copy_seccomp",
          "description": "实现进程克隆时信号处理手柄的复制逻辑，根据克隆标志决定是否共享或新建sighand结构体，同步信号动作数组并处理信号处理器重置，包含seccomp过滤器和线程组资源的复制",
          "similarity": 0.5399215817451477
        }
      ]
    }
  ]
}