{
  "query": "TIMER_SOFTIRQ触发条件",
  "timestamp": "2025-12-26 02:16:38",
  "retrieved_files": [
    {
      "source_file": "kernel/softirq.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:26:22\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `softirq.c`\n\n---\n\n# softirq.c 技术文档\n\n## 1. 文件概述\n\n`softirq.c` 是 Linux 内核中实现软中断（softirq）机制的核心文件。软中断是一种延迟执行中断处理下半部（bottom half）的机制，用于在中断上下文之外安全、高效地处理高频率、低延迟要求的任务。该文件负责软中断的注册、调度、执行以及与内核其他子系统（如调度器、RCU、SMP 等）的协同工作，并为每个 CPU 维护独立的软中断状态，确保无锁化和良好的 CPU 局部性。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `softirq_vec[NR_SOFTIRQS]`：全局数组，存储所有软中断类型的处理函数（`softirq_action`），每个软中断类型（如 `NET_RX`、`TIMER` 等）对应一个条目。\n- `ksoftirqd`：每 CPU 变量，指向该 CPU 上专用于处理软中断的内核线程（`ksoftirqd`）。\n- `softirq_to_name[NR_SOFTIRQS]`：软中断类型的名称字符串数组，用于调试和追踪。\n- `softirq_ctrl`（仅限 `CONFIG_PREEMPT_RT`）：每 CPU 结构体，包含本地锁（`local_lock_t`）和计数器（`cnt`），用于在实时内核中管理软中断禁用状态，支持抢占。\n- `irq_stat`：每 CPU 的中断统计结构体（若架构未提供）。\n\n### 主要函数\n\n- `wakeup_softirqd()`：唤醒当前 CPU 的 `ksoftirqd` 内核线程。\n- `__local_bh_disable_ip()` / `__local_bh_enable_ip()`：用于禁用/启用软中断（Bottom Half），并处理嵌套计数、RCU 锁、锁依赖追踪等。\n- `local_bh_blocked()`（仅限 RT）：检查当前 CPU 是否处于软中断被阻塞状态，用于 idle 任务避免误报。\n- `ksoftirqd_run_begin()` / `ksoftirqd_run_end()`：`ksoftirqd` 线程执行软中断前后的上下文管理。\n- `invoke_softirq()`：根据当前软中断状态决定是否唤醒 `ksoftirqd`。\n- `__do_softirq()`（声明在别处，但在此被调用）：实际执行挂起的软中断处理函数。\n\n## 3. 关键实现\n\n### 软中断执行模型\n- 软中断是 **CPU 本地** 的，无共享变量，天然支持 SMP。\n- 若软中断需要序列化（如 `TASKLET`），由其自身通过自旋锁实现。\n- 软中断执行具有 **弱 CPU 绑定**：仅在触发中断的 CPU 上标记为待执行，提升缓存局部性。\n\n### 实时内核（PREEMPT_RT）支持\n- 在 `CONFIG_PREEMPT_RT` 下，软中断禁用状态不再依赖抢占计数器，而是使用每任务（`task_struct::softirq_disable_cnt`）和每 CPU（`softirq_ctrl::cnt`）两个计数器。\n- 引入 `local_lock_t` 保护软中断临界区，允许在 BH 禁用期间被其他高优先级任务抢占。\n- `ksoftirqd` 线程通过 `ksoftirqd_run_begin/end` 获取本地锁，确保重入安全。\n\n### 软中断调度策略\n- 当软中断在原子上下文（不可抢占）中被启用且有待处理任务时，不直接执行，而是唤醒 `ksoftirqd` 线程处理，避免用户空间饥饿。\n- 在可抢占上下文中启用软中断时，若有待处理软中断，则立即调用 `__do_softirq()` 执行。\n\n### 调试与追踪\n- 集成 `lockdep` 锁依赖分析器，通过 `bh_lock_map` 跟踪软中断禁用区域。\n- 支持 `ftrace` 的 `irq` 事件追踪（通过 `trace/events/irq.h`）。\n- 提供 `in_softirq()`、`softirq_count()` 等宏用于上下文判断。\n\n## 4. 依赖关系\n\n- **中断子系统**：依赖 `irq.h`、`interrupt.h` 提供硬中断接口和状态管理。\n- **调度器**：与 `kthread.h` 协作创建和管理 `ksoftirqd` 内核线程；依赖 `sched.h` 相关机制进行唤醒和调度。\n- **RCU**：在 RT 模式下，软中断禁用区域需持有 `rcu_read_lock()`，确保 RCU 语义正确。\n- **SMP 支持**：使用 `smp.h`、`smpboot.h` 实现每 CPU 变量和 CPU 热插拔支持。\n- **内存管理**：依赖 `mm.h` 和 `percpu.h` 管理每 CPU 数据。\n- **调试设施**：集成 `lockdep`（`DEBUG_LOCK_ALLOC`）、`ftrace`、`irqflags tracing` 等调试框架。\n- **架构相关代码**：可能使用 `asm/softirq_stack.h` 提供的架构特定栈处理。\n\n## 5. 使用场景\n\n- **网络子系统**：`NET_RX` 和 `NET_TX` 软中断用于高效处理网络包接收和发送。\n- **块设备层**：`BLOCK` 软中断处理块 I/O 完成回调。\n- **定时器**：`TIMER` 和 `HRTIMER` 软中断用于执行高精度和普通定时器回调。\n- **RCU**：`RCU` 软中断用于执行宽限期（grace period）相关的回调。\n- **任务队列**：`TASKLET` 软中断提供轻量级、序列化的下半部机制。\n- **调度器事件**：`SCHED` 软中断用于处理调度相关的延迟任务（如负载均衡触发）。\n- **中断轮询**：`IRQ_POLL` 用于高吞吐场景下的中断合并与轮询。\n\n该机制广泛应用于需要在中断后快速、批量、低开销处理任务的内核子系统中，是 Linux 中断处理下半部的核心基础设施之一。",
      "similarity": 0.5387147068977356,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "kernel/softirq.c",
          "start_line": 914,
          "end_line": 1021,
          "content": [
            "void tasklet_kill(struct tasklet_struct *t)",
            "{",
            "\tif (in_interrupt())",
            "\t\tpr_notice(\"Attempt to kill tasklet from interrupt\\n\");",
            "",
            "\twhile (test_and_set_bit(TASKLET_STATE_SCHED, &t->state))",
            "\t\twait_var_event(&t->state, !test_bit(TASKLET_STATE_SCHED, &t->state));",
            "",
            "\ttasklet_unlock_wait(t);",
            "\ttasklet_clear_sched(t);",
            "}",
            "void tasklet_unlock(struct tasklet_struct *t)",
            "{",
            "\tsmp_mb__before_atomic();",
            "\tclear_bit(TASKLET_STATE_RUN, &t->state);",
            "\tsmp_mb__after_atomic();",
            "\twake_up_var(&t->state);",
            "}",
            "void tasklet_unlock_wait(struct tasklet_struct *t)",
            "{",
            "\twait_var_event(&t->state, !test_bit(TASKLET_STATE_RUN, &t->state));",
            "}",
            "void __init softirq_init(void)",
            "{",
            "\tint cpu;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tper_cpu(tasklet_vec, cpu).tail =",
            "\t\t\t&per_cpu(tasklet_vec, cpu).head;",
            "\t\tper_cpu(tasklet_hi_vec, cpu).tail =",
            "\t\t\t&per_cpu(tasklet_hi_vec, cpu).head;",
            "\t}",
            "",
            "\topen_softirq(TASKLET_SOFTIRQ, tasklet_action);",
            "\topen_softirq(HI_SOFTIRQ, tasklet_hi_action);",
            "}",
            "static int ksoftirqd_should_run(unsigned int cpu)",
            "{",
            "\treturn local_softirq_pending();",
            "}",
            "static void run_ksoftirqd(unsigned int cpu)",
            "{",
            "\tksoftirqd_run_begin();",
            "\tif (local_softirq_pending()) {",
            "\t\t/*",
            "\t\t * We can safely run softirq on inline stack, as we are not deep",
            "\t\t * in the task stack here.",
            "\t\t */",
            "\t\thandle_softirqs(true);",
            "\t\tksoftirqd_run_end();",
            "\t\tcond_resched();",
            "\t\treturn;",
            "\t}",
            "\tksoftirqd_run_end();",
            "}",
            "static int takeover_tasklets(unsigned int cpu)",
            "{",
            "\t/* CPU is dead, so no lock needed. */",
            "\tlocal_irq_disable();",
            "",
            "\t/* Find end, append list for that CPU. */",
            "\tif (&per_cpu(tasklet_vec, cpu).head != per_cpu(tasklet_vec, cpu).tail) {",
            "\t\t*__this_cpu_read(tasklet_vec.tail) = per_cpu(tasklet_vec, cpu).head;",
            "\t\t__this_cpu_write(tasklet_vec.tail, per_cpu(tasklet_vec, cpu).tail);",
            "\t\tper_cpu(tasklet_vec, cpu).head = NULL;",
            "\t\tper_cpu(tasklet_vec, cpu).tail = &per_cpu(tasklet_vec, cpu).head;",
            "\t}",
            "\traise_softirq_irqoff(TASKLET_SOFTIRQ);",
            "",
            "\tif (&per_cpu(tasklet_hi_vec, cpu).head != per_cpu(tasklet_hi_vec, cpu).tail) {",
            "\t\t*__this_cpu_read(tasklet_hi_vec.tail) = per_cpu(tasklet_hi_vec, cpu).head;",
            "\t\t__this_cpu_write(tasklet_hi_vec.tail, per_cpu(tasklet_hi_vec, cpu).tail);",
            "\t\tper_cpu(tasklet_hi_vec, cpu).head = NULL;",
            "\t\tper_cpu(tasklet_hi_vec, cpu).tail = &per_cpu(tasklet_hi_vec, cpu).head;",
            "\t}",
            "\traise_softirq_irqoff(HI_SOFTIRQ);",
            "",
            "\tlocal_irq_enable();",
            "\treturn 0;",
            "}",
            "static void ktimerd_setup(unsigned int cpu)",
            "{",
            "\t/* Above SCHED_NORMAL to handle timers before regular tasks. */",
            "\tsched_set_fifo_low(current);",
            "}",
            "static int ktimerd_should_run(unsigned int cpu)",
            "{",
            "\treturn local_timers_pending_force_th();",
            "}",
            "void raise_ktimers_thread(unsigned int nr)",
            "{",
            "\ttrace_softirq_raise(nr);",
            "\t__this_cpu_or(pending_timer_softirq, BIT(nr));",
            "}",
            "static void run_ktimerd(unsigned int cpu)",
            "{",
            "\tunsigned int timer_si;",
            "",
            "\tksoftirqd_run_begin();",
            "",
            "\ttimer_si = local_timers_pending_force_th();",
            "\t__this_cpu_write(pending_timer_softirq, 0);",
            "\tor_softirq_pending(timer_si);",
            "",
            "\t__do_softirq();",
            "",
            "\tksoftirqd_run_end();",
            "}"
          ],
          "function_name": "tasklet_kill, tasklet_unlock, tasklet_unlock_wait, softirq_init, ksoftirqd_should_run, run_ksoftirqd, takeover_tasklets, ktimerd_setup, ktimerd_should_run, raise_ktimers_thread, run_ktimerd",
          "description": "提供tasklet终止、状态同步及软中断处理线程管理功能，softirq_init完成软中断处理函数注册，ksoftirqd_should_run/run_ksoftirqd控制软中断处理线程运行，takeover_tasklets实现CPU死亡时任务接管，ktimerd相关接口处理定时器任务",
          "similarity": 0.5410587787628174
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/softirq.c",
          "start_line": 270,
          "end_line": 380,
          "content": [
            "static inline void ksoftirqd_run_begin(void)",
            "{",
            "\t__local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET);",
            "\tlocal_irq_disable();",
            "}",
            "static inline void ksoftirqd_run_end(void)",
            "{",
            "\t/* pairs with the lock_map_acquire_read() in ksoftirqd_run_begin() */",
            "\tlock_map_release(&bh_lock_map);",
            "\t__local_bh_enable(SOFTIRQ_OFFSET, true);",
            "\tWARN_ON_ONCE(in_interrupt());",
            "\tlocal_irq_enable();",
            "}",
            "static inline void softirq_handle_begin(void) { }",
            "static inline void softirq_handle_end(void) { }",
            "static inline bool should_wake_ksoftirqd(void)",
            "{",
            "\treturn !this_cpu_read(softirq_ctrl.cnt);",
            "}",
            "static inline void invoke_softirq(void)",
            "{",
            "\tif (should_wake_ksoftirqd())",
            "\t\twakeup_softirqd();",
            "}",
            "void do_softirq_post_smp_call_flush(unsigned int was_pending)",
            "{",
            "\tunsigned int is_pending = local_softirq_pending();",
            "",
            "\tif (unlikely(was_pending != is_pending)) {",
            "\t\tWARN_ON_ONCE(was_pending != (is_pending & ~SCHED_SOFTIRQ_MASK));",
            "\t\tinvoke_softirq();",
            "\t}",
            "}",
            "void __local_bh_disable_ip(unsigned long ip, unsigned int cnt)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tWARN_ON_ONCE(in_hardirq());",
            "",
            "\traw_local_irq_save(flags);",
            "\t/*",
            "\t * The preempt tracer hooks into preempt_count_add and will break",
            "\t * lockdep because it calls back into lockdep after SOFTIRQ_OFFSET",
            "\t * is set and before current->softirq_enabled is cleared.",
            "\t * We must manually increment preempt_count here and manually",
            "\t * call the trace_preempt_off later.",
            "\t */",
            "\t__preempt_count_add(cnt);",
            "\t/*",
            "\t * Were softirqs turned off above:",
            "\t */",
            "\tif (softirq_count() == (cnt & SOFTIRQ_MASK))",
            "\t\tlockdep_softirqs_off(ip);",
            "\traw_local_irq_restore(flags);",
            "",
            "\tif (preempt_count() == cnt) {",
            "#ifdef CONFIG_DEBUG_PREEMPT",
            "\t\tcurrent->preempt_disable_ip = get_lock_parent_ip();",
            "#endif",
            "\t\ttrace_preempt_off(CALLER_ADDR0, get_lock_parent_ip());",
            "\t}",
            "}",
            "static void __local_bh_enable(unsigned int cnt)",
            "{",
            "\tlockdep_assert_irqs_disabled();",
            "",
            "\tif (preempt_count() == cnt)",
            "\t\ttrace_preempt_on(CALLER_ADDR0, get_lock_parent_ip());",
            "",
            "\tif (softirq_count() == (cnt & SOFTIRQ_MASK))",
            "\t\tlockdep_softirqs_on(_RET_IP_);",
            "",
            "\t__preempt_count_sub(cnt);",
            "}",
            "void _local_bh_enable(void)",
            "{",
            "\tWARN_ON_ONCE(in_hardirq());",
            "\t__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);",
            "}",
            "void __local_bh_enable_ip(unsigned long ip, unsigned int cnt)",
            "{",
            "\tWARN_ON_ONCE(in_hardirq());",
            "\tlockdep_assert_irqs_enabled();",
            "#ifdef CONFIG_TRACE_IRQFLAGS",
            "\tlocal_irq_disable();",
            "#endif",
            "\t/*",
            "\t * Are softirqs going to be turned on now:",
            "\t */",
            "\tif (softirq_count() == SOFTIRQ_DISABLE_OFFSET)",
            "\t\tlockdep_softirqs_on(ip);",
            "\t/*",
            "\t * Keep preemption disabled until we are done with",
            "\t * softirq processing:",
            "\t */",
            "\t__preempt_count_sub(cnt - 1);",
            "",
            "\tif (unlikely(!in_interrupt() && local_softirq_pending())) {",
            "\t\t/*",
            "\t\t * Run softirq if any pending. And do it in its own stack",
            "\t\t * as we may be calling this deep in a task call stack already.",
            "\t\t */",
            "\t\tdo_softirq();",
            "\t}",
            "",
            "\tpreempt_count_dec();",
            "#ifdef CONFIG_TRACE_IRQFLAGS",
            "\tlocal_irq_enable();",
            "#endif",
            "\tpreempt_check_resched();",
            "}"
          ],
          "function_name": "ksoftirqd_run_begin, ksoftirqd_run_end, softirq_handle_begin, softirq_handle_end, should_wake_ksoftirqd, invoke_softirq, do_softirq_post_smp_call_flush, __local_bh_disable_ip, __local_bh_enable, _local_bh_enable, __local_bh_enable_ip",
          "description": "提供ksoftirqd线程运行时的上下文切换辅助函数，包含软中断处理入口标记、唤醒条件判断及实际执行路径选择逻辑。",
          "similarity": 0.5184531211853027
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/softirq.c",
          "start_line": 74,
          "end_line": 191,
          "content": [
            "static void wakeup_softirqd(void)",
            "{",
            "\t/* Interrupts are disabled: no need to stop preemption */",
            "\tstruct task_struct *tsk = __this_cpu_read(ksoftirqd);",
            "",
            "\tif (tsk)",
            "\t\twake_up_process(tsk);",
            "}",
            "bool local_bh_blocked(void)",
            "{",
            "\treturn __this_cpu_read(softirq_ctrl.cnt) != 0;",
            "}",
            "void __local_bh_disable_ip(unsigned long ip, unsigned int cnt)",
            "{",
            "\tunsigned long flags;",
            "\tint newcnt;",
            "",
            "\tWARN_ON_ONCE(in_hardirq());",
            "",
            "\tlock_map_acquire_read(&bh_lock_map);",
            "",
            "\t/* First entry of a task into a BH disabled section? */",
            "\tif (!current->softirq_disable_cnt) {",
            "\t\tif (preemptible()) {",
            "\t\t\tlocal_lock(&softirq_ctrl.lock);",
            "\t\t\t/* Required to meet the RCU bottomhalf requirements. */",
            "\t\t\trcu_read_lock();",
            "\t\t} else {",
            "\t\t\tDEBUG_LOCKS_WARN_ON(this_cpu_read(softirq_ctrl.cnt));",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * Track the per CPU softirq disabled state. On RT this is per CPU",
            "\t * state to allow preemption of bottom half disabled sections.",
            "\t */",
            "\tnewcnt = __this_cpu_add_return(softirq_ctrl.cnt, cnt);",
            "\t/*",
            "\t * Reflect the result in the task state to prevent recursion on the",
            "\t * local lock and to make softirq_count() & al work.",
            "\t */",
            "\tcurrent->softirq_disable_cnt = newcnt;",
            "",
            "\tif (IS_ENABLED(CONFIG_TRACE_IRQFLAGS) && newcnt == cnt) {",
            "\t\traw_local_irq_save(flags);",
            "\t\tlockdep_softirqs_off(ip);",
            "\t\traw_local_irq_restore(flags);",
            "\t}",
            "}",
            "static void __local_bh_enable(unsigned int cnt, bool unlock)",
            "{",
            "\tunsigned long flags;",
            "\tint newcnt;",
            "",
            "\tDEBUG_LOCKS_WARN_ON(current->softirq_disable_cnt !=",
            "\t\t\t    this_cpu_read(softirq_ctrl.cnt));",
            "",
            "\tif (IS_ENABLED(CONFIG_TRACE_IRQFLAGS) && softirq_count() == cnt) {",
            "\t\traw_local_irq_save(flags);",
            "\t\tlockdep_softirqs_on(_RET_IP_);",
            "\t\traw_local_irq_restore(flags);",
            "\t}",
            "",
            "\tnewcnt = __this_cpu_sub_return(softirq_ctrl.cnt, cnt);",
            "\tcurrent->softirq_disable_cnt = newcnt;",
            "",
            "\tif (!newcnt && unlock) {",
            "\t\trcu_read_unlock();",
            "\t\tlocal_unlock(&softirq_ctrl.lock);",
            "\t}",
            "}",
            "void __local_bh_enable_ip(unsigned long ip, unsigned int cnt)",
            "{",
            "\tbool preempt_on = preemptible();",
            "\tunsigned long flags;",
            "\tu32 pending;",
            "\tint curcnt;",
            "",
            "\tWARN_ON_ONCE(in_hardirq());",
            "\tlockdep_assert_irqs_enabled();",
            "",
            "\tlock_map_release(&bh_lock_map);",
            "",
            "\tlocal_irq_save(flags);",
            "\tcurcnt = __this_cpu_read(softirq_ctrl.cnt);",
            "",
            "\t/*",
            "\t * If this is not reenabling soft interrupts, no point in trying to",
            "\t * run pending ones.",
            "\t */",
            "\tif (curcnt != cnt)",
            "\t\tgoto out;",
            "",
            "\tpending = local_softirq_pending();",
            "\tif (!pending)",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * If this was called from non preemptible context, wake up the",
            "\t * softirq daemon.",
            "\t */",
            "\tif (!preempt_on) {",
            "\t\twakeup_softirqd();",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * Adjust softirq count to SOFTIRQ_OFFSET which makes",
            "\t * in_serving_softirq() become true.",
            "\t */",
            "\tcnt = SOFTIRQ_OFFSET;",
            "\t__local_bh_enable(cnt, false);",
            "\t__do_softirq();",
            "",
            "out:",
            "\t__local_bh_enable(cnt, preempt_on);",
            "\tlocal_irq_restore(flags);",
            "}"
          ],
          "function_name": "wakeup_softirqd, local_bh_blocked, __local_bh_disable_ip, __local_bh_enable, __local_bh_enable_ip",
          "description": "实现软中断屏蔽/恢复逻辑，通过修改per-CPU计数器控制软中断状态，包含唤醒ksoftirqd线程的逻辑，处理抢占和锁依赖关系。",
          "similarity": 0.466987669467926
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/softirq.c",
          "start_line": 1059,
          "end_line": 1085,
          "content": [
            "static __init int spawn_ksoftirqd(void)",
            "{",
            "\tcpuhp_setup_state_nocalls(CPUHP_SOFTIRQ_DEAD, \"softirq:dead\", NULL,",
            "\t\t\t\t  takeover_tasklets);",
            "\tBUG_ON(smpboot_register_percpu_thread(&softirq_threads));",
            "#ifdef CONFIG_IRQ_FORCED_THREADING",
            "\tif (force_irqthreads())",
            "\t\tBUG_ON(smpboot_register_percpu_thread(&timer_thread));",
            "#endif",
            "\treturn 0;",
            "}",
            "int __init __weak early_irq_init(void)",
            "{",
            "\treturn 0;",
            "}",
            "int __init __weak arch_probe_nr_irqs(void)",
            "{",
            "\treturn NR_IRQS_LEGACY;",
            "}",
            "int __init __weak arch_early_irq_init(void)",
            "{",
            "\treturn 0;",
            "}",
            "unsigned int __weak arch_dynirq_lower_bound(unsigned int from)",
            "{",
            "\treturn from;",
            "}"
          ],
          "function_name": "spawn_ksoftirqd, early_irq_init, arch_probe_nr_irqs, arch_early_irq_init, arch_dynirq_lower_bound",
          "description": "实现软中断处理线程的注册与早期中断初始化，spawn_ksoftirqd注册软中断处理线程并绑定takeover_tasklets，arch_*系列弱符号接口处理不同架构的中断探测与动态中断范围计算",
          "similarity": 0.4406074583530426
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/softirq.c",
          "start_line": 618,
          "end_line": 732,
          "content": [
            "void irq_enter_rcu(void)",
            "{",
            "\t__irq_enter_raw();",
            "",
            "\tif (tick_nohz_full_cpu(smp_processor_id()) ||",
            "\t    (is_idle_task(current) && (irq_count() == HARDIRQ_OFFSET)))",
            "\t\ttick_irq_enter();",
            "",
            "\taccount_hardirq_enter(current);",
            "}",
            "void irq_enter(void)",
            "{",
            "\tct_irq_enter();",
            "\tirq_enter_rcu();",
            "}",
            "static inline void tick_irq_exit(void)",
            "{",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "\tint cpu = smp_processor_id();",
            "",
            "\t/* Make sure that timer wheel updates are propagated */",
            "\tif ((sched_core_idle_cpu(cpu) && !need_resched()) || tick_nohz_full_cpu(cpu)) {",
            "\t\tif (!in_hardirq())",
            "\t\t\ttick_nohz_irq_exit();",
            "\t}",
            "#endif",
            "}",
            "static void wake_timersd(void)",
            "{",
            "\tstruct task_struct *tsk = __this_cpu_read(ktimerd);",
            "",
            "\tif (tsk)",
            "\t\twake_up_process(tsk);",
            "}",
            "static inline void wake_timersd(void) { }",
            "static inline void __irq_exit_rcu(void)",
            "{",
            "#ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED",
            "\tlocal_irq_disable();",
            "#else",
            "\tlockdep_assert_irqs_disabled();",
            "#endif",
            "\taccount_hardirq_exit(current);",
            "\tpreempt_count_sub(HARDIRQ_OFFSET);",
            "\tif (!in_interrupt() && local_softirq_pending())",
            "\t\tinvoke_softirq();",
            "",
            "\tif (IS_ENABLED(CONFIG_IRQ_FORCED_THREADING) && force_irqthreads() &&",
            "\t    local_timers_pending_force_th() && !(in_nmi() | in_hardirq()))",
            "\t\twake_timersd();",
            "",
            "\ttick_irq_exit();",
            "}",
            "void irq_exit_rcu(void)",
            "{",
            "\t__irq_exit_rcu();",
            "\t /* must be last! */",
            "\tlockdep_hardirq_exit();",
            "}",
            "void irq_exit(void)",
            "{",
            "\t__irq_exit_rcu();",
            "\tct_irq_exit();",
            "\t /* must be last! */",
            "\tlockdep_hardirq_exit();",
            "}",
            "inline void raise_softirq_irqoff(unsigned int nr)",
            "{",
            "\t__raise_softirq_irqoff(nr);",
            "",
            "\t/*",
            "\t * If we're in an interrupt or softirq, we're done",
            "\t * (this also catches softirq-disabled code). We will",
            "\t * actually run the softirq once we return from",
            "\t * the irq or softirq.",
            "\t *",
            "\t * Otherwise we wake up ksoftirqd to make sure we",
            "\t * schedule the softirq soon.",
            "\t */",
            "\tif (!in_interrupt() && should_wake_ksoftirqd())",
            "\t\twakeup_softirqd();",
            "}",
            "void raise_softirq(unsigned int nr)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\traise_softirq_irqoff(nr);",
            "\tlocal_irq_restore(flags);",
            "}",
            "void __raise_softirq_irqoff(unsigned int nr)",
            "{",
            "\tlockdep_assert_irqs_disabled();",
            "\ttrace_softirq_raise(nr);",
            "\tor_softirq_pending(1UL << nr);",
            "}",
            "void open_softirq(int nr, void (*action)(struct softirq_action *))",
            "{",
            "\tsoftirq_vec[nr].action = action;",
            "}",
            "static void __tasklet_schedule_common(struct tasklet_struct *t,",
            "\t\t\t\t      struct tasklet_head __percpu *headp,",
            "\t\t\t\t      unsigned int softirq_nr)",
            "{",
            "\tstruct tasklet_head *head;",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "\thead = this_cpu_ptr(headp);",
            "\tt->next = NULL;",
            "\t*head->tail = t;",
            "\thead->tail = &(t->next);",
            "\traise_softirq_irqoff(softirq_nr);",
            "\tlocal_irq_restore(flags);",
            "}"
          ],
          "function_name": "irq_enter_rcu, irq_enter, tick_irq_exit, wake_timersd, wake_timersd, __irq_exit_rcu, irq_exit_rcu, irq_exit, raise_softirq_irqoff, raise_softirq, __raise_softirq_irqoff, open_softirq, __tasklet_schedule_common",
          "description": "处理中断上下文切换相关操作，包含软中断触发接口、中断进入/退出时的统计更新和唤醒逻辑，以及任务队列调度辅助函数。",
          "similarity": 0.4402221441268921
        }
      ]
    },
    {
      "source_file": "kernel/irq_work.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:11:23\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq_work.c`\n\n---\n\n# `irq_work.c` 技术文档\n\n## 1. 文件概述\n\n`irq_work.c` 实现了一个轻量级的中断上下文工作队列机制，允许在硬中断（hardirq）或 NMI（不可屏蔽中断）上下文中安全地调度回调函数，并在稍后的硬中断上下文或专用内核线程中执行。该机制的核心目标是提供一种 **NMI 安全** 的方式来延迟执行某些不能在 NMI 或硬中断中直接完成的操作。\n\n该框架特别适用于需要从 NMI 或硬中断中触发后续处理（如 perf 事件、ftrace、RCU 等子系统）但又不能阻塞或执行复杂逻辑的场景。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct irq_work`：表示一个中断工作项，包含回调函数 `func` 和状态标志（如 `IRQ_WORK_PENDING`、`IRQ_WORK_CLAIMED`、`IRQ_WORK_BUSY`、`IRQ_WORK_LAZY`、`IRQ_WORK_HARD_IRQ`）。\n- 每 CPU 变量：\n  - `raised_list`：存放需在硬中断上下文中立即处理的工作项。\n  - `lazy_list`：存放“惰性”工作项，在非硬中断上下文（如 tick 或专用线程）中处理。\n  - `irq_workd`：指向每 CPU 的 `irq_work` 内核线程（仅在 `CONFIG_PREEMPT_RT` 下使用）。\n\n### 主要函数\n\n| 函数 | 功能 |\n|------|------|\n| `irq_work_queue(struct irq_work *work)` | 在当前 CPU 上排队一个 `irq_work`，若未被声明则声明并入队。 |\n| `irq_work_queue_on(struct irq_work *work, int cpu)` | 将 `irq_work` 排队到指定 CPU（支持跨 CPU 调度）。 |\n| `irq_work_run(void)` | 在当前 CPU 上执行所有 `raised_list` 和（非 RT 下的）`lazy_list` 中的工作项。 |\n| `irq_work_tick(void)` | 由时钟 tick 调用，处理未被硬中断处理的 `raised_list` 和 `lazy_list`。 |\n| `irq_work_sync(struct irq_work *work)` | 同步等待指定 `irq_work` 执行完毕。 |\n| `irq_work_single(void *arg)` | 执行单个工作项的回调函数，并清理状态。 |\n| `arch_irq_work_raise(void)` | 架构相关函数，用于触发 IPI 或中断以唤醒处理逻辑（弱符号，默认为空）。 |\n\n## 3. 关键实现\n\n### 状态管理与原子操作\n\n- 每个 `irq_work` 通过 `atomic_t node.a_flags` 管理状态：\n  - `IRQ_WORK_PENDING`：表示工作项已入队但尚未执行。\n  - `IRQ_WORK_CLAIMED`：表示已被声明，防止重复入队。\n  - `IRQ_WORK_BUSY`：表示正在执行中。\n- `irq_work_claim()` 使用 `atomic_fetch_or()` 原子地设置 `CLAIMED` 和 `PENDING` 标志，并检查是否已存在，避免重复入队。\n\n### 双队列设计\n\n- **`raised_list`**：用于需要尽快在硬中断上下文执行的工作（如标记为 `IRQ_WORK_HARD_IRQ` 的项）。\n- **`lazy_list`**：\n  - 在非 RT 内核中，由 `irq_work_tick()` 或 `irq_work_run()` 在软中断或进程上下文中处理。\n  - 在 `CONFIG_PREEMPT_RT` 下，由每 CPU 的 `irq_work/%u` 内核线程处理（以避免在硬中断中执行非硬实时代码）。\n\n### NMI 安全性\n\n- 入队操作（如 `irq_work_queue`）仅使用原子操作和每 CPU 链表（`llist`），不涉及锁或内存分配，因此可在 NMI 上下文中安全调用。\n- 跨 CPU 入队时（`irq_work_queue_on`）会检查 `in_nmi()`，防止在 NMI 中调用非 NMI 安全的 IPI 发送函数。\n\n### PREEMPT_RT 支持\n\n- 在 RT 内核中，非 `IRQ_WORK_HARD_IRQ` 的工作项被放入 `lazy_list`，并通过专用内核线程执行，以避免在硬中断中运行可能阻塞或延迟高的代码。\n- 使用 `rcuwait` 机制实现 `irq_work_sync()` 的睡眠等待。\n\n### IPI 触发机制\n\n- 若架构支持（通过 `arch_irq_work_has_interrupt()`），调用 `arch_irq_work_raise()` 触发本地中断处理。\n- 否则依赖时钟 tick（`irq_work_tick`）或显式调用 `irq_work_run` 来处理队列。\n\n## 4. 依赖关系\n\n- **架构依赖**：\n  - `arch_irq_work_raise()` 和 `arch_irq_work_has_interrupt()` 需由具体架构实现（如 x86 提供）。\n- **内核子系统**：\n  - `llist`（无锁链表）：用于高效、无锁的每 CPU 队列管理。\n  - `smpboot`：用于注册每 CPU 内核线程（RT 模式）。\n  - `rcu`：`rcuwait` 用于同步等待（RT 模式）。\n  - `tick`：`tick_nohz_tick_stopped()` 用于判断是否需要立即触发处理。\n  - `trace_events`：IPI 跟踪点 `trace_ipi_send_cpu`。\n- **配置选项**：\n  - `CONFIG_SMP`：启用跨 CPU 调度和 IPI 支持。\n  - `CONFIG_PREEMPT_RT`：启用 RT 模式下的线程化处理。\n\n## 5. 使用场景\n\n- **性能监控（perf）**：从 NMI 中记录采样后，通过 `irq_work` 安全地将数据传递到常规上下文处理。\n- **ftrace / tracing**：在中断上下文中触发延迟的跟踪事件处理。\n- **RCU**：某些 RCU 实现使用 `irq_work` 来触发宽限期处理。\n- **热插拔 CPU**：在 CPU 离线前通过 `flush_smp_call_function_queue()` 调用 `irq_work_run()` 确保工作项被清空。\n- **中断负载均衡或延迟处理**：将非关键中断处理逻辑延迟到更安全的上下文执行。\n\n该机制为内核提供了一种高效、安全且可扩展的中断后处理框架，尤其适用于实时性和可靠性要求高的子系统。",
      "similarity": 0.5107525587081909,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/irq_work.c",
          "start_line": 1,
          "end_line": 30,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Copyright (C) 2010 Red Hat, Inc., Peter Zijlstra",
            " *",
            " * Provides a framework for enqueueing and running callbacks from hardirq",
            " * context. The enqueueing is NMI-safe.",
            " */",
            "",
            "#include <linux/bug.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/percpu.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/sched.h>",
            "#include <linux/tick.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/smp.h>",
            "#include <linux/smpboot.h>",
            "#include <asm/processor.h>",
            "#include <linux/kasan.h>",
            "",
            "#include <trace/events/ipi.h>",
            "",
            "static DEFINE_PER_CPU(struct llist_head, raised_list);",
            "static DEFINE_PER_CPU(struct llist_head, lazy_list);",
            "static DEFINE_PER_CPU(struct task_struct *, irq_workd);",
            ""
          ],
          "function_name": null,
          "description": "定义了用于管理中断工作队列的per-CPU链表（raised_list/lazy_list）和irq_workd线程指针，提供NMI安全的enqueue框架",
          "similarity": 0.43903669714927673
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/irq_work.c",
          "start_line": 303,
          "end_line": 316,
          "content": [
            "static void run_irq_workd(unsigned int cpu)",
            "{",
            "\tirq_work_run_list(this_cpu_ptr(&lazy_list));",
            "}",
            "static void irq_workd_setup(unsigned int cpu)",
            "{",
            "\tsched_set_fifo_low(current);",
            "}",
            "static __init int irq_work_init_threads(void)",
            "{",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\tBUG_ON(smpboot_register_percpu_thread(&irqwork_threads));",
            "\treturn 0;",
            "}"
          ],
          "function_name": "run_irq_workd, irq_workd_setup, irq_work_init_threads",
          "description": "初始化PREEMPT_RT环境下的per-CPU工作线程，注册并启动处理延迟工作项的专用线程，通过smpboot接口创建线程实体",
          "similarity": 0.4274060130119324
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/irq_work.c",
          "start_line": 31,
          "end_line": 157,
          "content": [
            "static void wake_irq_workd(void)",
            "{",
            "\tstruct task_struct *tsk = __this_cpu_read(irq_workd);",
            "",
            "\tif (!llist_empty(this_cpu_ptr(&lazy_list)) && tsk)",
            "\t\twake_up_process(tsk);",
            "}",
            "static void irq_work_wake(struct irq_work *entry)",
            "{",
            "\twake_irq_workd();",
            "}",
            "static int irq_workd_should_run(unsigned int cpu)",
            "{",
            "\treturn !llist_empty(this_cpu_ptr(&lazy_list));",
            "}",
            "static bool irq_work_claim(struct irq_work *work)",
            "{",
            "\tint oflags;",
            "",
            "\toflags = atomic_fetch_or(IRQ_WORK_CLAIMED | CSD_TYPE_IRQ_WORK, &work->node.a_flags);",
            "\t/*",
            "\t * If the work is already pending, no need to raise the IPI.",
            "\t * The pairing smp_mb() in irq_work_single() makes sure",
            "\t * everything we did before is visible.",
            "\t */",
            "\tif (oflags & IRQ_WORK_PENDING)",
            "\t\treturn false;",
            "\treturn true;",
            "}",
            "void __weak arch_irq_work_raise(void)",
            "{",
            "\t/*",
            "\t * Lame architectures will get the timer tick callback",
            "\t */",
            "}",
            "static __always_inline void irq_work_raise(struct irq_work *work)",
            "{",
            "\tif (trace_ipi_send_cpu_enabled() && arch_irq_work_has_interrupt())",
            "\t\ttrace_ipi_send_cpu(smp_processor_id(), _RET_IP_, work->func);",
            "",
            "\tarch_irq_work_raise();",
            "}",
            "static void __irq_work_queue_local(struct irq_work *work)",
            "{",
            "\tstruct llist_head *list;",
            "\tbool rt_lazy_work = false;",
            "\tbool lazy_work = false;",
            "\tint work_flags;",
            "",
            "\twork_flags = atomic_read(&work->node.a_flags);",
            "\tif (work_flags & IRQ_WORK_LAZY)",
            "\t\tlazy_work = true;",
            "\telse if (IS_ENABLED(CONFIG_PREEMPT_RT) &&",
            "\t\t !(work_flags & IRQ_WORK_HARD_IRQ))",
            "\t\trt_lazy_work = true;",
            "",
            "\tif (lazy_work || rt_lazy_work)",
            "\t\tlist = this_cpu_ptr(&lazy_list);",
            "\telse",
            "\t\tlist = this_cpu_ptr(&raised_list);",
            "",
            "\tif (!llist_add(&work->node.llist, list))",
            "\t\treturn;",
            "",
            "\t/* If the work is \"lazy\", handle it from next tick if any */",
            "\tif (!lazy_work || tick_nohz_tick_stopped())",
            "\t\tirq_work_raise(work);",
            "}",
            "bool irq_work_queue(struct irq_work *work)",
            "{",
            "\t/* Only queue if not already pending */",
            "\tif (!irq_work_claim(work))",
            "\t\treturn false;",
            "",
            "\t/* Queue the entry and raise the IPI if needed. */",
            "\tpreempt_disable();",
            "\t__irq_work_queue_local(work);",
            "\tpreempt_enable();",
            "",
            "\treturn true;",
            "}",
            "bool irq_work_queue_on(struct irq_work *work, int cpu)",
            "{",
            "#ifndef CONFIG_SMP",
            "\treturn irq_work_queue(work);",
            "",
            "#else /* CONFIG_SMP: */",
            "\t/* All work should have been flushed before going offline */",
            "\tWARN_ON_ONCE(cpu_is_offline(cpu));",
            "",
            "\t/* Only queue if not already pending */",
            "\tif (!irq_work_claim(work))",
            "\t\treturn false;",
            "",
            "\tkasan_record_aux_stack_noalloc(work);",
            "",
            "\tpreempt_disable();",
            "\tif (cpu != smp_processor_id()) {",
            "\t\t/* Arch remote IPI send/receive backend aren't NMI safe */",
            "\t\tWARN_ON_ONCE(in_nmi());",
            "",
            "\t\t/*",
            "\t\t * On PREEMPT_RT the items which are not marked as",
            "\t\t * IRQ_WORK_HARD_IRQ are added to the lazy list and a HARD work",
            "\t\t * item is used on the remote CPU to wake the thread.",
            "\t\t */",
            "\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) &&",
            "\t\t    !(atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ)) {",
            "",
            "\t\t\tif (!llist_add(&work->node.llist, &per_cpu(lazy_list, cpu)))",
            "\t\t\t\tgoto out;",
            "",
            "\t\t\twork = &per_cpu(irq_work_wakeup, cpu);",
            "\t\t\tif (!irq_work_claim(work))",
            "\t\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\t__smp_call_single_queue(cpu, &work->node.llist);",
            "\t} else {",
            "\t\t__irq_work_queue_local(work);",
            "\t}",
            "out:",
            "\tpreempt_enable();",
            "",
            "\treturn true;",
            "#endif /* CONFIG_SMP */",
            "}"
          ],
          "function_name": "wake_irq_workd, irq_work_wake, irq_workd_should_run, irq_work_claim, arch_irq_work_raise, irq_work_raise, __irq_work_queue_local, irq_work_queue, irq_work_queue_on",
          "description": "实现了中断工作项的排队逻辑，区分硬中断与延迟工作项，通过IPI或线程唤醒机制确保跨CPU执行，支持PREEMPT_RT配置下的延迟处理",
          "similarity": 0.41979557275772095
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/irq_work.c",
          "start_line": 184,
          "end_line": 286,
          "content": [
            "bool irq_work_needs_cpu(void)",
            "{",
            "\tstruct llist_head *raised, *lazy;",
            "",
            "\traised = this_cpu_ptr(&raised_list);",
            "\tlazy = this_cpu_ptr(&lazy_list);",
            "",
            "\tif (llist_empty(raised) || arch_irq_work_has_interrupt())",
            "\t\tif (llist_empty(lazy))",
            "\t\t\treturn false;",
            "",
            "\t/* All work should have been flushed before going offline */",
            "\tWARN_ON_ONCE(cpu_is_offline(smp_processor_id()));",
            "",
            "\treturn true;",
            "}",
            "void irq_work_single(void *arg)",
            "{",
            "\tstruct irq_work *work = arg;",
            "\tint flags;",
            "",
            "\t/*",
            "\t * Clear the PENDING bit, after this point the @work can be re-used.",
            "\t * The PENDING bit acts as a lock, and we own it, so we can clear it",
            "\t * without atomic ops.",
            "\t */",
            "\tflags = atomic_read(&work->node.a_flags);",
            "\tflags &= ~IRQ_WORK_PENDING;",
            "\tatomic_set(&work->node.a_flags, flags);",
            "",
            "\t/*",
            "\t * See irq_work_claim().",
            "\t */",
            "\tsmp_mb();",
            "",
            "\tlockdep_irq_work_enter(flags);",
            "\twork->func(work);",
            "\tlockdep_irq_work_exit(flags);",
            "",
            "\t/*",
            "\t * Clear the BUSY bit, if set, and return to the free state if no-one",
            "\t * else claimed it meanwhile.",
            "\t */",
            "\t(void)atomic_cmpxchg(&work->node.a_flags, flags, flags & ~IRQ_WORK_BUSY);",
            "",
            "\tif ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||",
            "\t    !arch_irq_work_has_interrupt())",
            "\t\trcuwait_wake_up(&work->irqwait);",
            "}",
            "static void irq_work_run_list(struct llist_head *list)",
            "{",
            "\tstruct irq_work *work, *tmp;",
            "\tstruct llist_node *llnode;",
            "",
            "\t/*",
            "\t * On PREEMPT_RT IRQ-work which is not marked as HARD will be processed",
            "\t * in a per-CPU thread in preemptible context. Only the items which are",
            "\t * marked as IRQ_WORK_HARD_IRQ will be processed in hardirq context.",
            "\t */",
            "\tBUG_ON(!irqs_disabled() && !IS_ENABLED(CONFIG_PREEMPT_RT));",
            "",
            "\tif (llist_empty(list))",
            "\t\treturn;",
            "",
            "\tllnode = llist_del_all(list);",
            "\tllist_for_each_entry_safe(work, tmp, llnode, node.llist)",
            "\t\tirq_work_single(work);",
            "}",
            "void irq_work_run(void)",
            "{",
            "\tirq_work_run_list(this_cpu_ptr(&raised_list));",
            "\tif (!IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\tirq_work_run_list(this_cpu_ptr(&lazy_list));",
            "\telse",
            "\t\twake_irq_workd();",
            "}",
            "void irq_work_tick(void)",
            "{",
            "\tstruct llist_head *raised = this_cpu_ptr(&raised_list);",
            "",
            "\tif (!llist_empty(raised) && !arch_irq_work_has_interrupt())",
            "\t\tirq_work_run_list(raised);",
            "",
            "\tif (!IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\tirq_work_run_list(this_cpu_ptr(&lazy_list));",
            "\telse",
            "\t\twake_irq_workd();",
            "}",
            "void irq_work_sync(struct irq_work *work)",
            "{",
            "\tlockdep_assert_irqs_enabled();",
            "\tmight_sleep();",
            "",
            "\tif ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||",
            "\t    !arch_irq_work_has_interrupt()) {",
            "\t\trcuwait_wait_event(&work->irqwait, !irq_work_is_busy(work),",
            "\t\t\t\t   TASK_UNINTERRUPTIBLE);",
            "\t\treturn;",
            "\t}",
            "",
            "\twhile (irq_work_is_busy(work))",
            "\t\tcpu_relax();",
            "}"
          ],
          "function_name": "irq_work_needs_cpu, irq_work_single, irq_work_run_list, irq_work_run, irq_work_tick, irq_work_sync",
          "description": "处理工作项的实际执行流程，包含单次执行逻辑、链表遍历运行及同步等待机制，区分硬中断上下文与RCU等待状态的处理",
          "similarity": 0.40130215883255005
        }
      ]
    },
    {
      "source_file": "kernel/irq/autoprobe.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:47:42\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\autoprobe.c`\n\n---\n\n# `irq/autoprobe.c` 技术文档\n\n## 1. 文件概述\n\n`irq/autoprobe.c` 实现了 Linux 内核中的中断自动探测（IRQ autodetection）机制。该机制用于在设备驱动程序无法预先知道其所使用的中断号时，动态探测硬件实际触发的中断线。文件提供了一组 API，允许驱动程序在安全、受控的环境下扫描并识别有效的中断请求（IRQ）线路。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`probe_irq_on(void)`**  \n  启动中断自动探测过程。激活所有可探测的未分配中断线，等待潜在中断触发，并返回一个位掩码，表示可能有效的低编号（<32）中断线。\n\n- **`probe_irq_mask(unsigned long val)`**  \n  扫描所有中断线，返回在指定掩码 `val` 范围内被触发的有效中断位图，并清理探测状态。\n\n- **`probe_irq_off(unsigned long val)`**  \n  结束中断探测，检查哪些中断线在探测期间被触发。若唯一中断被触发，返回其中断号；若多个中断被触发，返回负值表示冲突；若无中断触发，返回 0。\n\n### 关键数据结构与状态标志\n\n- **`IRQS_AUTODETECT`**：标记该中断正处于自动探测状态。\n- **`IRQS_WAITING`**：表示该中断尚未被触发；若在探测期间被触发，此标志会被清除。\n- **`probing_active`**：全局互斥锁（`mutex`），确保同一时间只有一个探测过程在进行。\n\n## 3. 关键实现\n\n### 探测流程\n\n1. **准备阶段（`probe_irq_on`）**：\n   - 调用 `async_synchronize_full()` 确保异步任务完成，避免干扰。\n   - 获取 `probing_active` 互斥锁，防止并发探测。\n   - 遍历所有中断描述符（`irq_desc`），对未分配（`!desc->action`）且允许探测（`irq_settings_can_probe`）的中断：\n     - 若芯片支持，调用 `irq_set_type(..., IRQ_TYPE_PROBE)` 通知硬件进入探测模式。\n     - 调用 `irq_activate_and_startup()` 激活并启用中断（不重发）。\n   - 等待 20ms，让“陈旧”中断（longstanding irq）有机会触发并自屏蔽。\n\n2. **正式探测阶段**：\n   - 再次遍历中断描述符，为可探测中断设置 `IRQS_AUTODETECT | IRQS_WAITING`。\n   - 重新激活中断（处理可能因陈旧中断而被屏蔽的情况）。\n   - 等待 100ms，让真实硬件中断触发。\n\n3. **结果收集与清理**：\n   - 在 `probe_irq_off` 或 `probe_irq_mask` 中：\n     - 检查哪些中断仍带有 `IRQS_AUTODETECT` 且 **未** 设置 `IRQS_WAITING`（即已被触发）。\n     - 清除 `IRQS_AUTODETECT` 标志，并调用 `irq_shutdown_and_deactivate()` 关闭中断。\n     - 根据触发中断的数量返回结果：唯一中断返回正号，多个返回负号，无触发返回 0。\n\n### 并发控制\n\n- 使用 `probing_active` 互斥锁保证探测过程的原子性。\n- 所有对 `irq_desc` 的访问均在 `raw_spin_lock_irq()` 保护下进行，确保中断上下文安全。\n\n### 硬件交互\n\n- 支持通过 `irq_chip->irq_set_type()` 向中断控制器发送 `IRQ_TYPE_PROBE` 类型，使某些硬件（如 ISA 控制器）进入探测兼容模式。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/irq.h>`：IRQ 核心定义。\n  - `<linux/interrupt.h>`：中断处理相关 API。\n  - `<linux/delay.h>`：提供 `msleep()`。\n  - `<linux/async.h>`：用于同步异步任务。\n  - `\"internals.h\"`：包含 IRQ 子系统内部函数（如 `irq_activate_and_startup`、`irq_shutdown_and_deactivate`）。\n\n- **内核子系统依赖**：\n  - **IRQ 子系统核心**：依赖 `irq_desc` 管理、中断激活/关闭逻辑。\n  - **中断控制器驱动**：依赖 `irq_chip` 回调（特别是 `irq_set_type`）。\n\n## 5. 使用场景\n\n- **传统 ISA/PnP 设备驱动**：在即插即用（PnP）或资源未知的旧硬件驱动中，用于动态确定设备使用的 IRQ 号。\n- **调试与诊断工具**：内核调试时用于验证硬件中断线路是否正常工作。\n- **模块化驱动初始化**：在 `module_init` 阶段，当设备资源未通过 ACPI/FDT 等机制明确指定时，作为后备探测手段。\n\n> **注意**：现代设备通常通过设备树（Device Tree）、ACPI 或 PCI 配置空间明确指定中断号，因此该机制主要用于遗留硬件支持。文档中也指出，在模块中使用时存在并发风险，应避免重叠调用。",
      "similarity": 0.5047702193260193,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/autoprobe.c",
          "start_line": 30,
          "end_line": 149,
          "content": [
            "unsigned long probe_irq_on(void)",
            "{",
            "\tstruct irq_desc *desc;",
            "\tunsigned long mask = 0;",
            "\tint i;",
            "",
            "\t/*",
            "\t * quiesce the kernel, or at least the asynchronous portion",
            "\t */",
            "\tasync_synchronize_full();",
            "\tmutex_lock(&probing_active);",
            "\t/*",
            "\t * something may have generated an irq long ago and we want to",
            "\t * flush such a longstanding irq before considering it as spurious.",
            "\t */",
            "\tfor_each_irq_desc_reverse(i, desc) {",
            "\t\traw_spin_lock_irq(&desc->lock);",
            "\t\tif (!desc->action && irq_settings_can_probe(desc)) {",
            "\t\t\t/*",
            "\t\t\t * Some chips need to know about probing in",
            "\t\t\t * progress:",
            "\t\t\t */",
            "\t\t\tif (desc->irq_data.chip->irq_set_type)",
            "\t\t\t\tdesc->irq_data.chip->irq_set_type(&desc->irq_data,",
            "\t\t\t\t\t\t\t IRQ_TYPE_PROBE);",
            "\t\t\tirq_activate_and_startup(desc, IRQ_NORESEND);",
            "\t\t}",
            "\t\traw_spin_unlock_irq(&desc->lock);",
            "\t}",
            "",
            "\t/* Wait for longstanding interrupts to trigger. */",
            "\tmsleep(20);",
            "",
            "\t/*",
            "\t * enable any unassigned irqs",
            "\t * (we must startup again here because if a longstanding irq",
            "\t * happened in the previous stage, it may have masked itself)",
            "\t */",
            "\tfor_each_irq_desc_reverse(i, desc) {",
            "\t\traw_spin_lock_irq(&desc->lock);",
            "\t\tif (!desc->action && irq_settings_can_probe(desc)) {",
            "\t\t\tdesc->istate |= IRQS_AUTODETECT | IRQS_WAITING;",
            "\t\t\tif (irq_activate_and_startup(desc, IRQ_NORESEND))",
            "\t\t\t\tdesc->istate |= IRQS_PENDING;",
            "\t\t}",
            "\t\traw_spin_unlock_irq(&desc->lock);",
            "\t}",
            "",
            "\t/*",
            "\t * Wait for spurious interrupts to trigger",
            "\t */",
            "\tmsleep(100);",
            "",
            "\t/*",
            "\t * Now filter out any obviously spurious interrupts",
            "\t */",
            "\tfor_each_irq_desc(i, desc) {",
            "\t\traw_spin_lock_irq(&desc->lock);",
            "",
            "\t\tif (desc->istate & IRQS_AUTODETECT) {",
            "\t\t\t/* It triggered already - consider it spurious. */",
            "\t\t\tif (!(desc->istate & IRQS_WAITING)) {",
            "\t\t\t\tdesc->istate &= ~IRQS_AUTODETECT;",
            "\t\t\t\tirq_shutdown_and_deactivate(desc);",
            "\t\t\t} else",
            "\t\t\t\tif (i < 32)",
            "\t\t\t\t\tmask |= 1 << i;",
            "\t\t}",
            "\t\traw_spin_unlock_irq(&desc->lock);",
            "\t}",
            "",
            "\treturn mask;",
            "}",
            "unsigned int probe_irq_mask(unsigned long val)",
            "{",
            "\tunsigned int mask = 0;",
            "\tstruct irq_desc *desc;",
            "\tint i;",
            "",
            "\tfor_each_irq_desc(i, desc) {",
            "\t\traw_spin_lock_irq(&desc->lock);",
            "\t\tif (desc->istate & IRQS_AUTODETECT) {",
            "\t\t\tif (i < 16 && !(desc->istate & IRQS_WAITING))",
            "\t\t\t\tmask |= 1 << i;",
            "",
            "\t\t\tdesc->istate &= ~IRQS_AUTODETECT;",
            "\t\t\tirq_shutdown_and_deactivate(desc);",
            "\t\t}",
            "\t\traw_spin_unlock_irq(&desc->lock);",
            "\t}",
            "\tmutex_unlock(&probing_active);",
            "",
            "\treturn mask & val;",
            "}",
            "int probe_irq_off(unsigned long val)",
            "{",
            "\tint i, irq_found = 0, nr_of_irqs = 0;",
            "\tstruct irq_desc *desc;",
            "",
            "\tfor_each_irq_desc(i, desc) {",
            "\t\traw_spin_lock_irq(&desc->lock);",
            "",
            "\t\tif (desc->istate & IRQS_AUTODETECT) {",
            "\t\t\tif (!(desc->istate & IRQS_WAITING)) {",
            "\t\t\t\tif (!nr_of_irqs)",
            "\t\t\t\t\tirq_found = i;",
            "\t\t\t\tnr_of_irqs++;",
            "\t\t\t}",
            "\t\t\tdesc->istate &= ~IRQS_AUTODETECT;",
            "\t\t\tirq_shutdown_and_deactivate(desc);",
            "\t\t}",
            "\t\traw_spin_unlock_irq(&desc->lock);",
            "\t}",
            "\tmutex_unlock(&probing_active);",
            "",
            "\tif (nr_of_irqs > 1)",
            "\t\tirq_found = -irq_found;",
            "",
            "\treturn irq_found;",
            "}"
          ],
          "function_name": "probe_irq_on, probe_irq_mask, probe_irq_off",
          "description": "实现中断自动检测三阶段流程，probe_irq_on启用未分配中断并收集触发掩码，probe_irq_mask筛选有效中断位，probe_irq_off解析最终中断号，通过遍历中断描述符完成状态修改与激活控制。",
          "similarity": 0.5080063343048096
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/autoprobe.c",
          "start_line": 1,
          "end_line": 29,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 1992, 1998-2004 Linus Torvalds, Ingo Molnar",
            " *",
            " * This file contains the interrupt probing code and driver APIs.",
            " */",
            "",
            "#include <linux/irq.h>",
            "#include <linux/module.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/delay.h>",
            "#include <linux/async.h>",
            "",
            "#include \"internals.h\"",
            "",
            "/*",
            " * Autodetection depends on the fact that any interrupt that",
            " * comes in on to an unassigned handler will get stuck with",
            " * \"IRQS_WAITING\" cleared and the interrupt disabled.",
            " */",
            "static DEFINE_MUTEX(probing_active);",
            "",
            "/**",
            " *\tprobe_irq_on\t- begin an interrupt autodetect",
            " *",
            " *\tCommence probing for an interrupt. The interrupts are scanned",
            " *\tand a mask of potential interrupt lines is returned.",
            " *",
            " */"
          ],
          "function_name": null,
          "description": "定义用于中断自动检测的互斥锁probing_active，并声明probe_irq_on、probe_irq_mask和probe_irq_off函数，为后续中断探针流程提供基础框架。",
          "similarity": 0.4360019862651825
        }
      ]
    }
  ]
}