{
  "query": "线程间通信与进程间通信的实现方式对比",
  "timestamp": "2025-12-25 23:30:44",
  "retrieved_files": [
    {
      "source_file": "kernel/workqueue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:53:20\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `workqueue.c`\n\n---\n\n# workqueue.c 技术文档\n\n## 1. 文件概述\n\n`workqueue.c` 是 Linux 内核中实现通用异步执行机制的核心文件，提供基于共享工作线程池（worker pool）的延迟任务调度功能。工作项（work items）在进程上下文中执行，支持 CPU 绑定和非绑定两种模式。每个 CPU 默认拥有两个标准工作池（普通优先级和高优先级），同时支持动态创建非绑定工作池以满足不同工作队列的需求。该机制替代了早期的 taskqueue/keventd 实现，具有更高的可扩展性和资源利用率。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct worker_pool`**  \n  工作线程池结构体，管理一组工作线程（workers），包含：\n  - `lock`：保护池状态的自旋锁\n  - `cpu` / `node`：关联的 CPU 和 NUMA 节点（绑定池）\n  - `worklist`：待处理工作项队列\n  - `idle_list` / `busy_hash`：空闲和忙碌工作线程的管理结构\n  - `nr_workers` / `nr_idle`：工作线程数量统计\n  - `attrs`：工作线程属性（如优先级、CPU 亲和性）\n  - `mayday_timer`：紧急情况下的救援请求定时器\n\n- **`struct pool_workqueue`**  \n  工作队列与工作池之间的关联结构，每个工作队列在每个池中都有一个对应的 `pool_workqueue` 实例，用于：\n  - 管理工作项的入队和执行\n  - 实现 `max_active` 限制（控制并发执行数）\n  - 支持 flush 操作（等待所有工作完成）\n  - 统计性能指标（如启动/完成次数、CPU 时间等）\n\n- **`struct worker`**（定义在 `workqueue_internal.h`）  \n  工作线程的运行时上下文，包含状态标志（如 `WORKER_IDLE`, `WORKER_UNBOUND`）、当前执行的工作项等。\n\n### 关键枚举与常量\n\n- **池/工作线程标志**：\n  - `POOL_DISASSOCIATED`：CPU 离线时池进入非绑定状态\n  - `WORKER_UNBOUND`：工作线程可在任意 CPU 上运行\n  - `WORKER_CPU_INTENSIVE`：标记 CPU 密集型任务，影响并发控制\n\n- **配置参数**：\n  - `NR_STD_WORKER_POOLS = 2`：每 CPU 标准池数量（普通 + 高优先级）\n  - `IDLE_WORKER_TIMEOUT = 300 * HZ`：空闲线程保留时间（5 分钟）\n  - `MAYDAY_INITIAL_TIMEOUT`：工作积压时触发救援的延迟（10ms）\n\n- **统计指标**（`pool_workqueue_stats`）：\n  - `PWQ_STAT_STARTED` / `PWQ_STAT_COMPLETED`：工作项执行统计\n  - `PWQ_STAT_MAYDAY` / `PWQ_STAT_RESCUED`：紧急救援事件计数\n\n## 3. 关键实现\n\n### 工作池管理\n- **绑定池（Bound Pool）**：与特定 CPU 关联，工作线程默认绑定到该 CPU。当 CPU 离线时，池进入 `DISASSOCIATED` 状态，工作线程转为非绑定模式。\n- **非绑定池（Unbound Pool）**：动态创建，通过哈希表（`unbound_pool_hash`）按属性（`workqueue_attrs`）去重，支持跨 CPU 调度。\n- **并发控制**：通过 `nr_running` 计数器和 `max_active` 限制，防止工作项过度并发执行。\n\n### 工作线程生命周期\n- **空闲管理**：空闲线程加入 `idle_list`，超时（`IDLE_WORKER_TIMEOUT`）后被回收。\n- **动态伸缩**：当工作积压时，通过 `mayday_timer` 触发新线程创建；若创建失败，向全局救援线程（rescuer）求助。\n- **状态标志**：使用位标志（如 `WORKER_IDLE`, `WORKER_PREP`）高效管理线程状态，避免锁竞争。\n\n### 内存与同步\n- **RCU 保护**：工作池销毁通过 RCU 延迟释放，确保 `get_work_pool()` 等读取路径无锁安全。\n- **锁分层**：\n  - `pool->lock`（自旋锁）：保护池内部状态\n  - `wq_pool_mutex`：全局池管理互斥锁\n  - `wq_pool_attach_mutex`：防止 CPU 绑定状态变更冲突\n\n### 工作项调度\n- **数据指针复用**：`work_struct->data` 的高有效位存储 `pool_workqueue` 指针，低有效位用于标志位（如 `WORK_STRUCT_INACTIVE`）。\n- **优先级支持**：高优先级工作池使用 `HIGHPRI_NICE_LEVEL = MIN_NICE` 提升调度优先级。\n\n## 4. 依赖关系\n\n- **内核子系统**：\n  - **调度器**（`<linux/sched.h>`）：创建工作线程（kworker），管理 CPU 亲和性\n  - **内存管理**（`<linux/slab.h>`）：分配工作池、工作队列等结构\n  - **CPU 热插拔**（`<linux/cpu.h>`）：处理 CPU 上下线时的池绑定状态切换\n  - **RCU**（`<linux/rculist.h>`）：实现无锁读取路径\n  - **定时器**（`<linux/timer.h>`）：实现空闲超时和救援机制\n\n- **内部依赖**：\n  - `workqueue_internal.h`：定义 `struct worker` 等内部结构\n  - `Documentation/core-api/workqueue.rst`：详细设计文档\n\n## 5. 使用场景\n\n- **驱动程序延迟操作**：硬件中断后调度下半部处理（如网络包处理、磁盘 I/O 完成回调）。\n- **内核子系统异步任务**：文件系统元数据更新、内存回收、电源管理状态切换。\n- **高优先级任务**：使用 `WQ_HIGHPRI` 标志创建工作队列，确保关键任务及时执行（如死锁恢复）。\n- **CPU 密集型任务**：标记 `WQ_CPU_INTENSIVE` 避免占用过多并发槽位，提升系统响应性。\n- **NUMA 感知调度**：非绑定工作队列可指定 NUMA 节点，优化内存访问延迟。",
      "similarity": 0.5674741268157959,
      "chunks": [
        {
          "chunk_id": 27,
          "file_path": "kernel/workqueue.c",
          "start_line": 5563,
          "end_line": 5664,
          "content": [
            "int workqueue_prepare_cpu(unsigned int cpu)",
            "{",
            "\tstruct worker_pool *pool;",
            "",
            "\tfor_each_cpu_worker_pool(pool, cpu) {",
            "\t\tif (pool->nr_workers)",
            "\t\t\tcontinue;",
            "\t\tif (!create_worker(pool))",
            "\t\t\treturn -ENOMEM;",
            "\t}",
            "\treturn 0;",
            "}",
            "int workqueue_online_cpu(unsigned int cpu)",
            "{",
            "\tstruct worker_pool *pool;",
            "\tstruct workqueue_struct *wq;",
            "\tint pi;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tfor_each_pool(pool, pi) {",
            "\t\tmutex_lock(&wq_pool_attach_mutex);",
            "",
            "\t\tif (pool->cpu == cpu)",
            "\t\t\trebind_workers(pool);",
            "\t\telse if (pool->cpu < 0)",
            "\t\t\trestore_unbound_workers_cpumask(pool, cpu);",
            "",
            "\t\tmutex_unlock(&wq_pool_attach_mutex);",
            "\t}",
            "",
            "\t/* update pod affinity of unbound workqueues */",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tstruct workqueue_attrs *attrs = wq->unbound_attrs;",
            "",
            "\t\tif (attrs) {",
            "\t\t\tconst struct wq_pod_type *pt = wqattrs_pod_type(attrs);",
            "\t\t\tint tcpu;",
            "",
            "\t\t\tfor_each_cpu(tcpu, pt->pod_cpus[pt->cpu_pod[cpu]])",
            "\t\t\t\twq_update_pod(wq, tcpu, cpu, true);",
            "\t\t}",
            "\t}",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\treturn 0;",
            "}",
            "int workqueue_offline_cpu(unsigned int cpu)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "",
            "\t/* unbinding per-cpu workers should happen on the local CPU */",
            "\tif (WARN_ON(cpu != smp_processor_id()))",
            "\t\treturn -1;",
            "",
            "\tunbind_workers(cpu);",
            "",
            "\t/* update pod affinity of unbound workqueues */",
            "\tmutex_lock(&wq_pool_mutex);",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tstruct workqueue_attrs *attrs = wq->unbound_attrs;",
            "",
            "\t\tif (attrs) {",
            "\t\t\tconst struct wq_pod_type *pt = wqattrs_pod_type(attrs);",
            "\t\t\tint tcpu;",
            "",
            "\t\t\tfor_each_cpu(tcpu, pt->pod_cpus[pt->cpu_pod[cpu]])",
            "\t\t\t\twq_update_pod(wq, tcpu, cpu, false);",
            "\t\t}",
            "\t}",
            "\tmutex_unlock(&wq_pool_mutex);",
            "",
            "\treturn 0;",
            "}",
            "static void work_for_cpu_fn(struct work_struct *work)",
            "{",
            "\tstruct work_for_cpu *wfc = container_of(work, struct work_for_cpu, work);",
            "",
            "\twfc->ret = wfc->fn(wfc->arg);",
            "}",
            "long work_on_cpu_key(int cpu, long (*fn)(void *),",
            "\t\t     void *arg, struct lock_class_key *key)",
            "{",
            "\tstruct work_for_cpu wfc = { .fn = fn, .arg = arg };",
            "",
            "\tINIT_WORK_ONSTACK_KEY(&wfc.work, work_for_cpu_fn, key);",
            "\tschedule_work_on(cpu, &wfc.work);",
            "\tflush_work(&wfc.work);",
            "\tdestroy_work_on_stack(&wfc.work);",
            "\treturn wfc.ret;",
            "}",
            "long work_on_cpu_safe_key(int cpu, long (*fn)(void *),",
            "\t\t\t  void *arg, struct lock_class_key *key)",
            "{",
            "\tlong ret = -ENODEV;",
            "",
            "\tcpus_read_lock();",
            "\tif (cpu_online(cpu))",
            "\t\tret = work_on_cpu_key(cpu, fn, arg, key);",
            "\tcpus_read_unlock();",
            "\treturn ret;",
            "}"
          ],
          "function_name": "workqueue_prepare_cpu, workqueue_online_cpu, workqueue_offline_cpu, work_for_cpu_fn, work_on_cpu_key, work_on_cpu_safe_key",
          "description": "处理CPU事件生命周期，准备工作者、更新工作者池状态，并提供跨CPU任务执行接口以保证调度一致性",
          "similarity": 0.5380098819732666
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/workqueue.c",
          "start_line": 895,
          "end_line": 1037,
          "content": [
            "static inline void worker_clr_flags(struct worker *worker, unsigned int flags)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "\tunsigned int oflags = worker->flags;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\tworker->flags &= ~flags;",
            "",
            "\t/*",
            "\t * If transitioning out of NOT_RUNNING, increment nr_running.  Note",
            "\t * that the nested NOT_RUNNING is not a noop.  NOT_RUNNING is mask",
            "\t * of multiple flags, not a single flag.",
            "\t */",
            "\tif ((flags & WORKER_NOT_RUNNING) && (oflags & WORKER_NOT_RUNNING))",
            "\t\tif (!(worker->flags & WORKER_NOT_RUNNING))",
            "\t\t\tpool->nr_running++;",
            "}",
            "static void worker_enter_idle(struct worker *worker)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "",
            "\tif (WARN_ON_ONCE(worker->flags & WORKER_IDLE) ||",
            "\t    WARN_ON_ONCE(!list_empty(&worker->entry) &&",
            "\t\t\t (worker->hentry.next || worker->hentry.pprev)))",
            "\t\treturn;",
            "",
            "\t/* can't use worker_set_flags(), also called from create_worker() */",
            "\tworker->flags |= WORKER_IDLE;",
            "\tpool->nr_idle++;",
            "\tworker->last_active = jiffies;",
            "",
            "\t/* idle_list is LIFO */",
            "\tlist_add(&worker->entry, &pool->idle_list);",
            "",
            "\tif (too_many_workers(pool) && !timer_pending(&pool->idle_timer))",
            "\t\tmod_timer(&pool->idle_timer, jiffies + IDLE_WORKER_TIMEOUT);",
            "",
            "\t/* Sanity check nr_running. */",
            "\tWARN_ON_ONCE(pool->nr_workers == pool->nr_idle && pool->nr_running);",
            "}",
            "static void worker_leave_idle(struct worker *worker)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "",
            "\tif (WARN_ON_ONCE(!(worker->flags & WORKER_IDLE)))",
            "\t\treturn;",
            "\tworker_clr_flags(worker, WORKER_IDLE);",
            "\tpool->nr_idle--;",
            "\tlist_del_init(&worker->entry);",
            "}",
            "static void move_linked_works(struct work_struct *work, struct list_head *head,",
            "\t\t\t      struct work_struct **nextp)",
            "{",
            "\tstruct work_struct *n;",
            "",
            "\t/*",
            "\t * Linked worklist will always end before the end of the list,",
            "\t * use NULL for list head.",
            "\t */",
            "\tlist_for_each_entry_safe_from(work, n, NULL, entry) {",
            "\t\tlist_move_tail(&work->entry, head);",
            "\t\tif (!(*work_data_bits(work) & WORK_STRUCT_LINKED))",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\t/*",
            "\t * If we're already inside safe list traversal and have moved",
            "\t * multiple works to the scheduled queue, the next position",
            "\t * needs to be updated.",
            "\t */",
            "\tif (nextp)",
            "\t\t*nextp = n;",
            "}",
            "static bool assign_work(struct work_struct *work, struct worker *worker,",
            "\t\t\tstruct work_struct **nextp)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "\tstruct worker *collision;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\t/*",
            "\t * A single work shouldn't be executed concurrently by multiple workers.",
            "\t * __queue_work() ensures that @work doesn't jump to a different pool",
            "\t * while still running in the previous pool. Here, we should ensure that",
            "\t * @work is not executed concurrently by multiple workers from the same",
            "\t * pool. Check whether anyone is already processing the work. If so,",
            "\t * defer the work to the currently executing one.",
            "\t */",
            "\tcollision = find_worker_executing_work(pool, work);",
            "\tif (unlikely(collision)) {",
            "\t\tmove_linked_works(work, &collision->scheduled, nextp);",
            "\t\treturn false;",
            "\t}",
            "",
            "\tmove_linked_works(work, &worker->scheduled, nextp);",
            "\treturn true;",
            "}",
            "static bool kick_pool(struct worker_pool *pool)",
            "{",
            "\tstruct worker *worker = first_idle_worker(pool);",
            "\tstruct task_struct *p;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\tif (!need_more_worker(pool) || !worker)",
            "\t\treturn false;",
            "",
            "\tp = worker->task;",
            "",
            "#ifdef CONFIG_SMP",
            "\t/*",
            "\t * Idle @worker is about to execute @work and waking up provides an",
            "\t * opportunity to migrate @worker at a lower cost by setting the task's",
            "\t * wake_cpu field. Let's see if we want to move @worker to improve",
            "\t * execution locality.",
            "\t *",
            "\t * We're waking the worker that went idle the latest and there's some",
            "\t * chance that @worker is marked idle but hasn't gone off CPU yet. If",
            "\t * so, setting the wake_cpu won't do anything. As this is a best-effort",
            "\t * optimization and the race window is narrow, let's leave as-is for",
            "\t * now. If this becomes pronounced, we can skip over workers which are",
            "\t * still on cpu when picking an idle worker.",
            "\t *",
            "\t * If @pool has non-strict affinity, @worker might have ended up outside",
            "\t * its affinity scope. Repatriate.",
            "\t */",
            "\tif (!pool->attrs->affn_strict &&",
            "\t    !cpumask_test_cpu(p->wake_cpu, pool->attrs->__pod_cpumask)) {",
            "\t\tstruct work_struct *work = list_first_entry(&pool->worklist,",
            "\t\t\t\t\t\tstruct work_struct, entry);",
            "\t\tint wake_cpu = cpumask_any_and_distribute(pool->attrs->__pod_cpumask,",
            "\t\t\t\t\t\t\t  cpu_online_mask);",
            "\t\tif (wake_cpu < nr_cpu_ids) {",
            "\t\t\tp->wake_cpu = wake_cpu;",
            "\t\t\tget_work_pwq(work)->stats[PWQ_STAT_REPATRIATED]++;",
            "\t\t}",
            "\t}",
            "#endif",
            "\twake_up_process(p);",
            "\treturn true;",
            "}"
          ],
          "function_name": "worker_clr_flags, worker_enter_idle, worker_leave_idle, move_linked_works, assign_work, kick_pool",
          "description": "实现工作者线程空闲状态切换和工作项迁移机制，包含空闲工作者列表管理、链接工作项批量转移功能，以及唤醒工作者线程的调度逻辑，支持跨CPU亲和性迁移优化，确保工作项正确分发到可用工作者线程。",
          "similarity": 0.5357593894004822
        },
        {
          "chunk_id": 30,
          "file_path": "kernel/workqueue.c",
          "start_line": 6019,
          "end_line": 6134,
          "content": [
            "static void apply_wqattrs_unlock(void)",
            "{",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tcpus_read_unlock();",
            "}",
            "static ssize_t wq_nice_show(struct device *dev, struct device_attribute *attr,",
            "\t\t\t    char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint written;",
            "",
            "\tmutex_lock(&wq->mutex);",
            "\twritten = scnprintf(buf, PAGE_SIZE, \"%d\\n\", wq->unbound_attrs->nice);",
            "\tmutex_unlock(&wq->mutex);",
            "",
            "\treturn written;",
            "}",
            "static ssize_t wq_nice_store(struct device *dev, struct device_attribute *attr,",
            "\t\t\t     const char *buf, size_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tstruct workqueue_attrs *attrs;",
            "\tint ret = -ENOMEM;",
            "",
            "\tapply_wqattrs_lock();",
            "",
            "\tattrs = wq_sysfs_prep_attrs(wq);",
            "\tif (!attrs)",
            "\t\tgoto out_unlock;",
            "",
            "\tif (sscanf(buf, \"%d\", &attrs->nice) == 1 &&",
            "\t    attrs->nice >= MIN_NICE && attrs->nice <= MAX_NICE)",
            "\t\tret = apply_workqueue_attrs_locked(wq, attrs);",
            "\telse",
            "\t\tret = -EINVAL;",
            "",
            "out_unlock:",
            "\tapply_wqattrs_unlock();",
            "\tfree_workqueue_attrs(attrs);",
            "\treturn ret ?: count;",
            "}",
            "static ssize_t wq_cpumask_show(struct device *dev,",
            "\t\t\t       struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint written;",
            "",
            "\tmutex_lock(&wq->mutex);",
            "\twritten = scnprintf(buf, PAGE_SIZE, \"%*pb\\n\",",
            "\t\t\t    cpumask_pr_args(wq->unbound_attrs->cpumask));",
            "\tmutex_unlock(&wq->mutex);",
            "\treturn written;",
            "}",
            "static ssize_t wq_cpumask_store(struct device *dev,",
            "\t\t\t\tstruct device_attribute *attr,",
            "\t\t\t\tconst char *buf, size_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tstruct workqueue_attrs *attrs;",
            "\tint ret = -ENOMEM;",
            "",
            "\tapply_wqattrs_lock();",
            "",
            "\tattrs = wq_sysfs_prep_attrs(wq);",
            "\tif (!attrs)",
            "\t\tgoto out_unlock;",
            "",
            "\tret = cpumask_parse(buf, attrs->cpumask);",
            "\tif (!ret)",
            "\t\tret = apply_workqueue_attrs_locked(wq, attrs);",
            "",
            "out_unlock:",
            "\tapply_wqattrs_unlock();",
            "\tfree_workqueue_attrs(attrs);",
            "\treturn ret ?: count;",
            "}",
            "static ssize_t wq_affn_scope_show(struct device *dev,",
            "\t\t\t\t  struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint written;",
            "",
            "\tmutex_lock(&wq->mutex);",
            "\tif (wq->unbound_attrs->affn_scope == WQ_AFFN_DFL)",
            "\t\twritten = scnprintf(buf, PAGE_SIZE, \"%s (%s)\\n\",",
            "\t\t\t\t    wq_affn_names[WQ_AFFN_DFL],",
            "\t\t\t\t    wq_affn_names[wq_affn_dfl]);",
            "\telse",
            "\t\twritten = scnprintf(buf, PAGE_SIZE, \"%s\\n\",",
            "\t\t\t\t    wq_affn_names[wq->unbound_attrs->affn_scope]);",
            "\tmutex_unlock(&wq->mutex);",
            "",
            "\treturn written;",
            "}",
            "static ssize_t wq_affn_scope_store(struct device *dev,",
            "\t\t\t\t   struct device_attribute *attr,",
            "\t\t\t\t   const char *buf, size_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tstruct workqueue_attrs *attrs;",
            "\tint affn, ret = -ENOMEM;",
            "",
            "\taffn = parse_affn_scope(buf);",
            "\tif (affn < 0)",
            "\t\treturn affn;",
            "",
            "\tapply_wqattrs_lock();",
            "\tattrs = wq_sysfs_prep_attrs(wq);",
            "\tif (attrs) {",
            "\t\tattrs->affn_scope = affn;",
            "\t\tret = apply_workqueue_attrs_locked(wq, attrs);",
            "\t}",
            "\tapply_wqattrs_unlock();",
            "\tfree_workqueue_attrs(attrs);",
            "\treturn ret ?: count;",
            "}"
          ],
          "function_name": "apply_wqattrs_unlock, wq_nice_show, wq_nice_store, wq_cpumask_show, wq_cpumask_store, wq_affn_scope_show, wq_affn_scope_store",
          "description": "实现工作队列属性的读写接口，通过device attribute接口暴露nice值、CPU掩码及亲和范围配置，支持动态调整工作队列调度策略，包含互斥锁保护和属性应用逻辑。",
          "similarity": 0.5321143865585327
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/workqueue.c",
          "start_line": 692,
          "end_line": 797,
          "content": [
            "static void set_work_pool_and_clear_pending(struct work_struct *work,",
            "\t\t\t\t\t    int pool_id)",
            "{",
            "\t/*",
            "\t * The following wmb is paired with the implied mb in",
            "\t * test_and_set_bit(PENDING) and ensures all updates to @work made",
            "\t * here are visible to and precede any updates by the next PENDING",
            "\t * owner.",
            "\t */",
            "\tsmp_wmb();",
            "\tset_work_data(work, (unsigned long)pool_id << WORK_OFFQ_POOL_SHIFT, 0);",
            "\t/*",
            "\t * The following mb guarantees that previous clear of a PENDING bit",
            "\t * will not be reordered with any speculative LOADS or STORES from",
            "\t * work->current_func, which is executed afterwards.  This possible",
            "\t * reordering can lead to a missed execution on attempt to queue",
            "\t * the same @work.  E.g. consider this case:",
            "\t *",
            "\t *   CPU#0                         CPU#1",
            "\t *   ----------------------------  --------------------------------",
            "\t *",
            "\t * 1  STORE event_indicated",
            "\t * 2  queue_work_on() {",
            "\t * 3    test_and_set_bit(PENDING)",
            "\t * 4 }                             set_..._and_clear_pending() {",
            "\t * 5                                 set_work_data() # clear bit",
            "\t * 6                                 smp_mb()",
            "\t * 7                               work->current_func() {",
            "\t * 8\t\t\t\t      LOAD event_indicated",
            "\t *\t\t\t\t   }",
            "\t *",
            "\t * Without an explicit full barrier speculative LOAD on line 8 can",
            "\t * be executed before CPU#0 does STORE on line 1.  If that happens,",
            "\t * CPU#0 observes the PENDING bit is still set and new execution of",
            "\t * a @work is not queued in a hope, that CPU#1 will eventually",
            "\t * finish the queued @work.  Meanwhile CPU#1 does not see",
            "\t * event_indicated is set, because speculative LOAD was executed",
            "\t * before actual STORE.",
            "\t */",
            "\tsmp_mb();",
            "}",
            "static void clear_work_data(struct work_struct *work)",
            "{",
            "\tsmp_wmb();\t/* see set_work_pool_and_clear_pending() */",
            "\tset_work_data(work, WORK_STRUCT_NO_POOL, 0);",
            "}",
            "static int get_work_pool_id(struct work_struct *work)",
            "{",
            "\tunsigned long data = atomic_long_read(&work->data);",
            "",
            "\tif (data & WORK_STRUCT_PWQ)",
            "\t\treturn work_struct_pwq(data)->pool->id;",
            "",
            "\treturn data >> WORK_OFFQ_POOL_SHIFT;",
            "}",
            "static void mark_work_canceling(struct work_struct *work)",
            "{",
            "\tunsigned long pool_id = get_work_pool_id(work);",
            "",
            "\tpool_id <<= WORK_OFFQ_POOL_SHIFT;",
            "\tset_work_data(work, pool_id | WORK_OFFQ_CANCELING, WORK_STRUCT_PENDING);",
            "}",
            "static bool work_is_canceling(struct work_struct *work)",
            "{",
            "\tunsigned long data = atomic_long_read(&work->data);",
            "",
            "\treturn !(data & WORK_STRUCT_PWQ) && (data & WORK_OFFQ_CANCELING);",
            "}",
            "static bool need_more_worker(struct worker_pool *pool)",
            "{",
            "\treturn !list_empty(&pool->worklist) && !pool->nr_running;",
            "}",
            "static bool may_start_working(struct worker_pool *pool)",
            "{",
            "\treturn pool->nr_idle;",
            "}",
            "static bool keep_working(struct worker_pool *pool)",
            "{",
            "\treturn !list_empty(&pool->worklist) && (pool->nr_running <= 1);",
            "}",
            "static bool need_to_create_worker(struct worker_pool *pool)",
            "{",
            "\treturn need_more_worker(pool) && !may_start_working(pool);",
            "}",
            "static bool too_many_workers(struct worker_pool *pool)",
            "{",
            "\tbool managing = pool->flags & POOL_MANAGER_ACTIVE;",
            "\tint nr_idle = pool->nr_idle + managing; /* manager is considered idle */",
            "\tint nr_busy = pool->nr_workers - nr_idle;",
            "",
            "\treturn nr_idle > 2 && (nr_idle - 2) * MAX_IDLE_WORKERS_RATIO >= nr_busy;",
            "}",
            "static inline void worker_set_flags(struct worker *worker, unsigned int flags)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\t/* If transitioning into NOT_RUNNING, adjust nr_running. */",
            "\tif ((flags & WORKER_NOT_RUNNING) &&",
            "\t    !(worker->flags & WORKER_NOT_RUNNING)) {",
            "\t\tpool->nr_running--;",
            "\t}",
            "",
            "\tworker->flags |= flags;",
            "}"
          ],
          "function_name": "set_work_pool_and_clear_pending, clear_work_data, get_work_pool_id, mark_work_canceling, work_is_canceling, need_more_worker, may_start_working, keep_working, need_to_create_worker, too_many_workers, worker_set_flags",
          "description": "实现工作者线程池状态控制逻辑，包含需要创建新工作者的判断条件、工作者空闲状态管理、工作项冲突检测及任务分配函数，通过锁保护保证池状态一致性，维护工作者线程与待处理工作项的匹配关系。",
          "similarity": 0.5186847448348999
        },
        {
          "chunk_id": 17,
          "file_path": "kernel/workqueue.c",
          "start_line": 3639,
          "end_line": 3741,
          "content": [
            "bool cancel_work(struct work_struct *work)",
            "{",
            "\treturn __cancel_work(work, false);",
            "}",
            "bool cancel_delayed_work(struct delayed_work *dwork)",
            "{",
            "\treturn __cancel_work(&dwork->work, true);",
            "}",
            "bool cancel_delayed_work_sync(struct delayed_work *dwork)",
            "{",
            "\treturn __cancel_work_timer(&dwork->work, true);",
            "}",
            "int schedule_on_each_cpu(work_func_t func)",
            "{",
            "\tint cpu;",
            "\tstruct work_struct __percpu *works;",
            "",
            "\tworks = alloc_percpu(struct work_struct);",
            "\tif (!works)",
            "\t\treturn -ENOMEM;",
            "",
            "\tcpus_read_lock();",
            "",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct work_struct *work = per_cpu_ptr(works, cpu);",
            "",
            "\t\tINIT_WORK(work, func);",
            "\t\tschedule_work_on(cpu, work);",
            "\t}",
            "",
            "\tfor_each_online_cpu(cpu)",
            "\t\tflush_work(per_cpu_ptr(works, cpu));",
            "",
            "\tcpus_read_unlock();",
            "\tfree_percpu(works);",
            "\treturn 0;",
            "}",
            "int execute_in_process_context(work_func_t fn, struct execute_work *ew)",
            "{",
            "\tif (!in_interrupt()) {",
            "\t\tfn(&ew->work);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tINIT_WORK(&ew->work, fn);",
            "\tschedule_work(&ew->work);",
            "",
            "\treturn 1;",
            "}",
            "void free_workqueue_attrs(struct workqueue_attrs *attrs)",
            "{",
            "\tif (attrs) {",
            "\t\tfree_cpumask_var(attrs->cpumask);",
            "\t\tfree_cpumask_var(attrs->__pod_cpumask);",
            "\t\tkfree(attrs);",
            "\t}",
            "}",
            "static void copy_workqueue_attrs(struct workqueue_attrs *to,",
            "\t\t\t\t const struct workqueue_attrs *from)",
            "{",
            "\tto->nice = from->nice;",
            "\tcpumask_copy(to->cpumask, from->cpumask);",
            "\tcpumask_copy(to->__pod_cpumask, from->__pod_cpumask);",
            "\tto->affn_strict = from->affn_strict;",
            "",
            "\t/*",
            "\t * Unlike hash and equality test, copying shouldn't ignore wq-only",
            "\t * fields as copying is used for both pool and wq attrs. Instead,",
            "\t * get_unbound_pool() explicitly clears the fields.",
            "\t */",
            "\tto->affn_scope = from->affn_scope;",
            "\tto->ordered = from->ordered;",
            "}",
            "static void wqattrs_clear_for_pool(struct workqueue_attrs *attrs)",
            "{",
            "\tattrs->affn_scope = WQ_AFFN_NR_TYPES;",
            "\tattrs->ordered = false;",
            "}",
            "static u32 wqattrs_hash(const struct workqueue_attrs *attrs)",
            "{",
            "\tu32 hash = 0;",
            "",
            "\thash = jhash_1word(attrs->nice, hash);",
            "\thash = jhash(cpumask_bits(attrs->cpumask),",
            "\t\t     BITS_TO_LONGS(nr_cpumask_bits) * sizeof(long), hash);",
            "\thash = jhash(cpumask_bits(attrs->__pod_cpumask),",
            "\t\t     BITS_TO_LONGS(nr_cpumask_bits) * sizeof(long), hash);",
            "\thash = jhash_1word(attrs->affn_strict, hash);",
            "\treturn hash;",
            "}",
            "static bool wqattrs_equal(const struct workqueue_attrs *a,",
            "\t\t\t  const struct workqueue_attrs *b)",
            "{",
            "\tif (a->nice != b->nice)",
            "\t\treturn false;",
            "\tif (!cpumask_equal(a->cpumask, b->cpumask))",
            "\t\treturn false;",
            "\tif (!cpumask_equal(a->__pod_cpumask, b->__pod_cpumask))",
            "\t\treturn false;",
            "\tif (a->affn_strict != b->affn_strict)",
            "\t\treturn false;",
            "\treturn true;",
            "}"
          ],
          "function_name": "cancel_work, cancel_delayed_work, cancel_delayed_work_sync, schedule_on_each_cpu, execute_in_process_context, free_workqueue_attrs, copy_workqueue_attrs, wqattrs_clear_for_pool, wqattrs_hash, wqattrs_equal",
          "description": "cancel_work 和 cancel_delayed_work 取消工作项，schedule_on_each_cpu 在每个 CPU 上调度工作函数，execute_in_process_context 允许在进程上下文执行工作。copy_workqueue_attrs 和 free_workqueue_attrs 管理工作队列属性的复制与释放。",
          "similarity": 0.5070544481277466
        }
      ]
    },
    {
      "source_file": "kernel/irq/handle.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:55:29\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\handle.c`\n\n---\n\n# `irq/handle.c` 技术文档\n\n## 1. 文件概述\n\n`irq/handle.c` 是 Linux 内核通用中断子系统（Generic IRQ）的核心实现文件之一，负责中断事件的高层处理逻辑。该文件实现了中断处理流程中的关键函数，包括中断动作（`irqaction`）的调用、线程化中断的唤醒机制、未处理或异常中断的处理，以及架构无关的中断入口封装。其目标是为不同硬件架构提供统一、可扩展的中断处理框架。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`handle_bad_irq(struct irq_desc *desc)`**  \n  处理伪中断（spurious IRQ）或未注册处理函数的中断，记录统计信息并调用架构相关的 `ack_bad_irq()`。\n\n- **`no_action(int cpl, void *dev_id)`**  \n  空中断处理函数，返回 `IRQ_NONE`，常用于占位或测试。\n\n- **`__irq_wake_thread(struct irq_desc *desc, struct irqaction *action)`**  \n  唤醒与中断动作关联的内核线程（用于线程化中断），管理 `threads_oneshot` 和 `threads_active` 状态。\n\n- **`__handle_irq_event_percpu(struct irq_desc *desc)`**  \n  在当前 CPU 上遍历并执行该中断描述符关联的所有 `irqaction` 处理函数，支持 `IRQ_WAKE_THREAD` 返回值以触发线程化处理。\n\n- **`handle_irq_event_percpu(struct irq_desc *desc)`**  \n  对 `__handle_irq_event_percpu` 的封装，附加中断随机数注入（`add_interrupt_randomness`）和调试记录（`note_interrupt`）。\n\n- **`handle_irq_event(struct irq_desc *desc)`**  \n  中断事件处理的顶层入口，负责清除 `IRQS_PENDING` 状态、设置 `IRQD_IRQ_INPROGRESS` 标志，并在释放 `desc->lock` 后调用 per-CPU 处理函数，最后恢复锁和状态。\n\n- **`generic_handle_arch_irq(struct pt_regs *regs)`**（仅当 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 启用）  \n  架构无关的通用中断入口点，封装 `irq_enter()`/`irq_exit()` 和寄存器上下文切换。\n\n- **`set_handle_irq(void (*handle_irq)(struct pt_regs *))`**（仅当 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 启用）  \n  初始化架构特定的底层中断处理函数指针 `handle_arch_irq`。\n\n### 关键数据结构（引用）\n\n- `struct irq_desc`：中断描述符，包含中断状态、动作链表、锁等。\n- `struct irqaction`：中断动作，包含处理函数 `handler`、线程函数 `thread_fn`、设备 ID、标志等。\n- `handle_arch_irq`：函数指针，指向架构特定的底层中断分发函数（仅在 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 下定义）。\n\n## 3. 关键实现\n\n### 线程化中断唤醒机制\n\n当硬中断处理函数返回 `IRQ_WAKE_THREAD` 时，内核需唤醒对应的线程处理下半部。`__irq_wake_thread` 实现了以下关键逻辑：\n\n- 检查线程是否已退出（`PF_EXITING`），若是则忽略。\n- 使用原子位操作 `test_and_set_bit(IRQTF_RUNTHREAD, ...)` 避免重复唤醒。\n- 通过 `desc->threads_oneshot |= action->thread_mask` 标记需运行的线程。\n- 原子递增 `desc->threads_active`，供 `synchronize_irq()` 等同步原语使用。\n- 调用 `wake_up_process()` 唤醒内核线程。\n\n该机制通过 `IRQS_INPROGRESS` 状态和 `desc->lock` 实现硬中断上下文与中断线程之间的同步，确保 `threads_oneshot` 的读写安全。\n\n### 中断处理流程控制\n\n`handle_irq_event` 是中断流控的关键：\n\n1. 清除 `IRQS_PENDING`（表示中断已开始处理）。\n2. 设置 `IRQD_IRQ_INPROGRESS`（防止嵌套处理）。\n3. 释放 `desc->lock`，允许中断线程或其他 CPU 并发访问。\n4. 调用 `handle_irq_event_percpu` 执行实际处理。\n5. 重新获取锁，清除 `IRQD_IRQ_INPROGRESS`。\n\n此设计解耦了中断流控（如电平触发中断的 EOI）与具体处理逻辑，提高并发性。\n\n### 架构无关中断入口（`CONFIG_GENERIC_IRQ_MULTI_HANDLER`）\n\n该配置允许架构代码注册一个统一的中断入口函数 `handle_arch_irq`。`generic_handle_arch_irq` 作为通用包装器：\n\n- 调用 `irq_enter()` 进入中断上下文。\n- 使用 `set_irq_regs()` 切换当前 CPU 的中断寄存器上下文。\n- 调用注册的 `handle_arch_irq` 进行实际分发。\n- 恢复寄存器上下文并调用 `irq_exit()`。\n\n适用于不自行管理中断入口计数和上下文的架构（如 ARM64）。\n\n### 安全与调试\n\n- **中断使能检查**：在调用 `action->handler` 后，检查中断是否被意外使能（`WARN_ONCE(!irqs_disabled(), ...)`），若发现则强制禁用。\n- **伪中断处理**：`handle_bad_irq` 提供统一的异常中断处理路径，便于调试和统计。\n- **随机数注入**：通过 `add_interrupt_randomness()` 利用中断时间戳增强内核熵池。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/irq.h>`、`<linux/interrupt.h>`：中断核心 API 和数据结构。\n  - `<linux/kernel_stat.h>`：中断统计（`kstat_incr_irqs_this_cpu`）。\n  - `<linux/random.h>`：中断随机数注入。\n  - `<asm/irq_regs.h>`：架构相关的中断寄存器上下文管理。\n  - `\"internals.h\"`：中断子系统内部实现细节。\n  - `<trace/events/irq.h>`：中断事件跟踪点。\n\n- **模块依赖**：\n  - **Generic IRQ 子系统**：依赖 `irqdesc.c`、`irqchip.c` 等提供的 `irq_desc` 管理。\n  - **调度器**：`wake_up_process()` 依赖进程调度。\n  - **RCU 与同步原语**：`synchronize_irq()` 依赖 `threads_active` 计数。\n  - **架构代码**：`ack_bad_irq()`、`handle_arch_irq` 由具体架构实现。\n\n## 5. 使用场景\n\n- **设备驱动注册中断处理函数**：驱动通过 `request_irq()` 注册 `irqaction`，中断触发时由 `handle_irq_event_percpu` 调用其 `handler`。\n- **线程化中断处理**：驱动设置 `IRQF_ONESHOT` 并提供 `thread_fn`，硬中断返回 `IRQ_WAKE_THREAD` 后由 `__irq_wake_thread` 唤醒线程。\n- **伪中断或未处理中断**：硬件误触发或未注册处理函数的中断由 `handle_bad_irq` 统一处理。\n- **架构中断入口**：在 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 架构（如 ARM64）中，异常向量表直接跳转至 `generic_handle_arch_irq`。\n- **中断同步**：`synchronize_irq()` 等函数依赖 `threads_active` 计数等待线程化中断完成。\n- **内核调试与监控**：通过 `note_interrupt()` 记录异常中断，通过 ftrace 的 `irq_handler_entry/exit` 跟踪点监控中断处理性能。",
      "similarity": 0.5619123578071594,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/handle.c",
          "start_line": 33,
          "end_line": 178,
          "content": [
            "void handle_bad_irq(struct irq_desc *desc)",
            "{",
            "\tunsigned int irq = irq_desc_get_irq(desc);",
            "",
            "\tprint_irq_desc(irq, desc);",
            "\tkstat_incr_irqs_this_cpu(desc);",
            "\tack_bad_irq(irq);",
            "}",
            "irqreturn_t no_action(int cpl, void *dev_id)",
            "{",
            "\treturn IRQ_NONE;",
            "}",
            "static void warn_no_thread(unsigned int irq, struct irqaction *action)",
            "{",
            "\tif (test_and_set_bit(IRQTF_WARNED, &action->thread_flags))",
            "\t\treturn;",
            "",
            "\tprintk(KERN_WARNING \"IRQ %d device %s returned IRQ_WAKE_THREAD \"",
            "\t       \"but no thread function available.\", irq, action->name);",
            "}",
            "void __irq_wake_thread(struct irq_desc *desc, struct irqaction *action)",
            "{",
            "\t/*",
            "\t * In case the thread crashed and was killed we just pretend that",
            "\t * we handled the interrupt. The hardirq handler has disabled the",
            "\t * device interrupt, so no irq storm is lurking.",
            "\t */",
            "\tif (action->thread->flags & PF_EXITING)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Wake up the handler thread for this action. If the",
            "\t * RUNTHREAD bit is already set, nothing to do.",
            "\t */",
            "\tif (test_and_set_bit(IRQTF_RUNTHREAD, &action->thread_flags))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * It's safe to OR the mask lockless here. We have only two",
            "\t * places which write to threads_oneshot: This code and the",
            "\t * irq thread.",
            "\t *",
            "\t * This code is the hard irq context and can never run on two",
            "\t * cpus in parallel. If it ever does we have more serious",
            "\t * problems than this bitmask.",
            "\t *",
            "\t * The irq threads of this irq which clear their \"running\" bit",
            "\t * in threads_oneshot are serialized via desc->lock against",
            "\t * each other and they are serialized against this code by",
            "\t * IRQS_INPROGRESS.",
            "\t *",
            "\t * Hard irq handler:",
            "\t *",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tdesc->state |= IRQS_INPROGRESS;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *\tset_bit(IRQTF_RUNTHREAD, &action->thread_flags);",
            "\t *\tdesc->threads_oneshot |= mask;",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tdesc->state &= ~IRQS_INPROGRESS;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *",
            "\t * irq thread:",
            "\t *",
            "\t * again:",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tif (desc->state & IRQS_INPROGRESS) {",
            "\t *\t\tspin_unlock(desc->lock);",
            "\t *\t\twhile(desc->state & IRQS_INPROGRESS)",
            "\t *\t\t\tcpu_relax();",
            "\t *\t\tgoto again;",
            "\t *\t}",
            "\t *\tif (!test_bit(IRQTF_RUNTHREAD, &action->thread_flags))",
            "\t *\t\tdesc->threads_oneshot &= ~mask;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *",
            "\t * So either the thread waits for us to clear IRQS_INPROGRESS",
            "\t * or we are waiting in the flow handler for desc->lock to be",
            "\t * released before we reach this point. The thread also checks",
            "\t * IRQTF_RUNTHREAD under desc->lock. If set it leaves",
            "\t * threads_oneshot untouched and runs the thread another time.",
            "\t */",
            "\tdesc->threads_oneshot |= action->thread_mask;",
            "",
            "\t/*",
            "\t * We increment the threads_active counter in case we wake up",
            "\t * the irq thread. The irq thread decrements the counter when",
            "\t * it returns from the handler or in the exit path and wakes",
            "\t * up waiters which are stuck in synchronize_irq() when the",
            "\t * active count becomes zero. synchronize_irq() is serialized",
            "\t * against this code (hard irq handler) via IRQS_INPROGRESS",
            "\t * like the finalize_oneshot() code. See comment above.",
            "\t */",
            "\tatomic_inc(&desc->threads_active);",
            "",
            "\twake_up_process(action->thread);",
            "}",
            "irqreturn_t __handle_irq_event_percpu(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t retval = IRQ_NONE;",
            "\tunsigned int irq = desc->irq_data.irq;",
            "\tstruct irqaction *action;",
            "",
            "\trecord_irq_time(desc);",
            "",
            "\tfor_each_action_of_desc(desc, action) {",
            "\t\tirqreturn_t res;",
            "",
            "\t\t/*",
            "\t\t * If this IRQ would be threaded under force_irqthreads, mark it so.",
            "\t\t */",
            "\t\tif (irq_settings_can_thread(desc) &&",
            "\t\t    !(action->flags & (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT)))",
            "\t\t\tlockdep_hardirq_threaded();",
            "",
            "\t\ttrace_irq_handler_entry(irq, action);",
            "\t\tres = action->handler(irq, action->dev_id);",
            "\t\ttrace_irq_handler_exit(irq, action, res);",
            "",
            "\t\tif (WARN_ONCE(!irqs_disabled(),\"irq %u handler %pS enabled interrupts\\n\",",
            "\t\t\t      irq, action->handler))",
            "\t\t\tlocal_irq_disable();",
            "",
            "\t\tswitch (res) {",
            "\t\tcase IRQ_WAKE_THREAD:",
            "\t\t\t/*",
            "\t\t\t * Catch drivers which return WAKE_THREAD but",
            "\t\t\t * did not set up a thread function",
            "\t\t\t */",
            "\t\t\tif (unlikely(!action->thread_fn)) {",
            "\t\t\t\twarn_no_thread(irq, action);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "",
            "\t\t\t__irq_wake_thread(desc, action);",
            "\t\t\tbreak;",
            "",
            "\t\tdefault:",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tretval |= res;",
            "\t}",
            "",
            "\treturn retval;",
            "}"
          ],
          "function_name": "handle_bad_irq, no_action, warn_no_thread, __irq_wake_thread, __handle_irq_event_percpu",
          "description": "实现中断处理核心逻辑，包括错误中断处理、唤醒线程函数、事件分发及中断处理结果收集，包含中断线程唤醒与状态同步机制",
          "similarity": 0.5439659357070923
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/irq/handle.c",
          "start_line": 189,
          "end_line": 232,
          "content": [
            "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t retval;",
            "",
            "\tretval = __handle_irq_event_percpu(desc);",
            "",
            "\tadd_interrupt_randomness(desc->irq_data.irq);",
            "",
            "\tif (!irq_settings_no_debug(desc))",
            "\t\tnote_interrupt(desc, retval);",
            "\treturn retval;",
            "}",
            "irqreturn_t handle_irq_event(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t ret;",
            "",
            "\tdesc->istate &= ~IRQS_PENDING;",
            "\tirqd_set(&desc->irq_data, IRQD_IRQ_INPROGRESS);",
            "\traw_spin_unlock(&desc->lock);",
            "",
            "\tret = handle_irq_event_percpu(desc);",
            "",
            "\traw_spin_lock(&desc->lock);",
            "\tirqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);",
            "\treturn ret;",
            "}",
            "int __init set_handle_irq(void (*handle_irq)(struct pt_regs *))",
            "{",
            "\tif (handle_arch_irq)",
            "\t\treturn -EBUSY;",
            "",
            "\thandle_arch_irq = handle_irq;",
            "\treturn 0;",
            "}",
            "asmlinkage void noinstr generic_handle_arch_irq(struct pt_regs *regs)",
            "{",
            "\tstruct pt_regs *old_regs;",
            "",
            "\tirq_enter();",
            "\told_regs = set_irq_regs(regs);",
            "\thandle_arch_irq(regs);",
            "\tset_irq_regs(old_regs);",
            "\tirq_exit();",
            "}"
          ],
          "function_name": "handle_irq_event_percpu, handle_irq_event, set_handle_irq, generic_handle_arch_irq",
          "description": "提供中断事件处理接口，包含通用架构中断入口点generic_handle_arch_irq，管理中断处理流程并集成随机化干扰注入功能",
          "similarity": 0.5207749605178833
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/handle.c",
          "start_line": 1,
          "end_line": 32,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar",
            " * Copyright (C) 2005-2006, Thomas Gleixner, Russell King",
            " *",
            " * This file contains the core interrupt handling code. Detailed",
            " * information is available in Documentation/core-api/genericirq.rst",
            " *",
            " */",
            "",
            "#include <linux/irq.h>",
            "#include <linux/random.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "",
            "#include <asm/irq_regs.h>",
            "",
            "#include <trace/events/irq.h>",
            "",
            "#include \"internals.h\"",
            "",
            "#ifdef CONFIG_GENERIC_IRQ_MULTI_HANDLER",
            "void (*handle_arch_irq)(struct pt_regs *) __ro_after_init;",
            "#endif",
            "",
            "/**",
            " * handle_bad_irq - handle spurious and unhandled irqs",
            " * @desc:      description of the interrupt",
            " *",
            " * Handles spurious and unhandled IRQ's. It also prints a debugmessage.",
            " */"
          ],
          "function_name": null,
          "description": "定义了处理异常中断的函数handle_bad_irq，用于处理未处理或误触发的中断，打印调试信息并更新中断统计",
          "similarity": 0.462654709815979
        }
      ]
    },
    {
      "source_file": "kernel/watch_queue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:50:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `watch_queue.c`\n\n---\n\n# watch_queue.c 技术文档\n\n## 文件概述\n\n`watch_queue.c` 实现了 Linux 内核中的**监视队列**（Watch Queue）机制，这是一种基于管道（pipe）构建的通用事件通知系统。该机制允许内核子系统（如文件系统、密钥管理、设备驱动等）向用户空间异步发送结构化通知。用户空间通过创建特殊类型的管道并关联监视队列，即可接收来自内核的各类事件通知。该文件定义了通知的投递、过滤、缓冲管理及与管道集成的核心逻辑。\n\n## 核心功能\n\n### 主要函数\n\n- **`__post_watch_notification()`**  \n  核心通知投递函数。遍历指定 `watch_list` 中所有匹配 `id` 的监视器（`watch`），对每个关联的 `watch_queue` 应用过滤规则、安全检查，并将通知写入底层管道。\n\n- **`post_one_notification()`**  \n  将单个通知写入指定 `watch_queue` 的底层管道缓冲区。负责从预分配的通知页中获取空闲槽位、填充数据、更新管道头指针并唤醒等待读取的进程。\n\n- **`filter_watch_notification()`**  \n  根据 `watch_filter` 中的类型、子类型和信息掩码规则，判断是否允许特定通知通过。\n\n- **`watch_queue_set_size()`**  \n  为监视队列分配预分配的通知缓冲区（页数组和位图），并调整底层管道的环形缓冲区大小。\n\n- **`watch_queue_pipe_buf_release()`**  \n  管道缓冲区释放回调。当用户空间读取完通知后，将对应的通知槽位在位图中标记为空闲，供后续复用。\n\n### 关键数据结构\n\n- **`struct watch_queue`**  \n  表示一个监视队列，包含：\n  - 指向底层 `pipe_inode_info` 的指针\n  - 预分配的通知页数组（`notes`）\n  - 通知槽位空闲位图（`notes_bitmap`）\n  - 通知过滤器（`filter`）\n  - 保护锁（`lock`）\n\n- **`struct watch_notification`**  \n  通用通知记录格式，包含类型（`type`）、子类型（`subtype`）、信息字段（`info`，含长度和ID）及可变负载。\n\n- **`struct watch_filter` / `struct watch_type_filter`**  \n  定义通知过滤规则，支持按类型、子类型及信息字段的位掩码进行精确过滤。\n\n- **`watch_queue_pipe_buf_ops`**  \n  自定义的 `pipe_buf_operations`，用于管理监视队列专用管道缓冲区的生命周期。\n\n## 关键实现\n\n### 基于管道的通知传输\n- 监视队列复用内核管道（`pipe_inode_info`）作为通知传输通道，利用其成熟的读写、轮询、异步通知机制。\n- 通过自定义 `pipe_buf_operations`（`watch_queue_pipe_buf_ops`）实现通知槽位的回收：当用户读取通知后，`release` 回调将对应槽位在 `notes_bitmap` 中置位，标记为空闲。\n\n### 预分配通知缓冲区\n- 通知数据存储在预分配的内核页（`notes`）中，每页划分为多个固定大小（128字节）的槽位（`WATCH_QUEUE_NOTE_SIZE`）。\n- 使用位图（`notes_bitmap`）跟踪槽位使用状态，1 表示空闲。投递通知时通过 `find_first_bit()` 快速查找空闲槽位。\n- 缓冲区大小由用户通过 `watch_queue_set_size()` 设置（1-512个通知），并受管道缓冲区配额限制。\n\n### 通知投递流程\n1. **匹配监视器**：遍历 `watch_list`，查找 `id` 匹配的 `watch`。\n2. **应用过滤**：若队列配置了过滤器，调用 `filter_watch_notification()` 决定是否丢弃。\n3. **安全检查**：调用 LSM 钩子 `security_post_notification()` 进行权限验证。\n4. **写入管道**：\n   - 获取空闲通知槽位，复制通知数据。\n   - 构造 `pipe_buffer` 指向该槽位，设置自定义操作集。\n   - 更新管道 `head` 指针，唤醒等待读取的进程。\n   - 若缓冲区满，标记前一个缓冲区为 `PIPE_BUF_FLAG_LOSS` 表示丢包。\n\n### 并发与同步\n- **RCU 保护**：`watch_list` 和 `watch_queue` 的访问通过 RCU 机制保护，确保遍历时结构体不被释放。\n- **自旋锁**：\n  - `wqueue->lock`：保护 `wqueue` 状态（如 `pipe` 指针有效性）。\n  - `pipe->rd_wait.lock`：保护管道环形缓冲区的读写操作。\n- **原子操作**：管道 `head` 指针使用 `smp_store_release()` 更新，确保与 `pipe_read()` 的同步。\n\n## 依赖关系\n\n- **管道子系统**（`fs/pipe.c`）  \n  依赖管道的核心数据结构（`pipe_inode_info`、`pipe_buffer`）和操作接口（`pipe_buf()`、`pipe_full()`、`generic_pipe_buf_*`）。\n\n- **内存管理**  \n  使用 `alloc_page()`、`kmap_atomic()` 管理通知缓冲区页，`bitmap_alloc()` 管理槽位位图。\n\n- **安全模块**（LSM）  \n  通过 `security_post_notification()` 钩子集成安全策略。\n\n- **用户空间接口**  \n  与 `fs/watch_queue.c` 中的系统调用（如 `watch_queue_set_size()`）协同工作，后者负责创建监视队列并与管道关联。\n\n- **头文件依赖**  \n  `linux/watch_queue.h`（核心数据结构定义）、`linux/pipe_fs_i.h`（管道内部接口）。\n\n## 使用场景\n\n- **文件系统事件监控**  \n  如 `fsnotify` 子系统可通过监视队列向用户空间报告文件访问、修改等事件。\n\n- **密钥管理通知**  \n  内核密钥环（`KEYS`）子系统使用该机制通知密钥状态变更（如过期、撤销）。\n\n- **设备事件上报**  \n  设备驱动可利用监视队列异步上报硬件状态变化或错误事件。\n\n- **通用内核事件分发**  \n  任何需要向特权用户空间守护进程（如 `systemd`）发送结构化事件的内核子系统均可集成此机制。\n\n- **用户空间消费**  \n  应用程序通过 `open(\"/dev/watch_queue\")` 获取监视队列文件描述符，调用 `ioctl()` 设置缓冲区大小和过滤器，然后像读取普通管道一样接收通知。",
      "similarity": 0.5609172582626343,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/watch_queue.c",
          "start_line": 42,
          "end_line": 154,
          "content": [
            "static inline bool lock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_lock_bh(&wqueue->lock);",
            "\tif (unlikely(!wqueue->pipe)) {",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "\t\treturn false;",
            "\t}",
            "\treturn true;",
            "}",
            "static inline void unlock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_unlock_bh(&wqueue->lock);",
            "}",
            "static void watch_queue_pipe_buf_release(struct pipe_inode_info *pipe,",
            "\t\t\t\t\t struct pipe_buffer *buf)",
            "{",
            "\tstruct watch_queue *wqueue = (struct watch_queue *)buf->private;",
            "\tstruct page *page;",
            "\tunsigned int bit;",
            "",
            "\t/* We need to work out which note within the page this refers to, but",
            "\t * the note might have been maximum size, so merely ANDing the offset",
            "\t * off doesn't work.  OTOH, the note must've been more than zero size.",
            "\t */",
            "\tbit = buf->offset + buf->len;",
            "\tif ((bit & (WATCH_QUEUE_NOTE_SIZE - 1)) == 0)",
            "\t\tbit -= WATCH_QUEUE_NOTE_SIZE;",
            "\tbit /= WATCH_QUEUE_NOTE_SIZE;",
            "",
            "\tpage = buf->page;",
            "\tbit += page->index;",
            "",
            "\tset_bit(bit, wqueue->notes_bitmap);",
            "\tgeneric_pipe_buf_release(pipe, buf);",
            "}",
            "static bool post_one_notification(struct watch_queue *wqueue,",
            "\t\t\t\t  struct watch_notification *n)",
            "{",
            "\tvoid *p;",
            "\tstruct pipe_inode_info *pipe = wqueue->pipe;",
            "\tstruct pipe_buffer *buf;",
            "\tstruct page *page;",
            "\tunsigned int head, tail, note, offset, len;",
            "\tbool done = false;",
            "",
            "\tspin_lock_irq(&pipe->rd_wait.lock);",
            "",
            "\thead = pipe->head;",
            "\ttail = pipe->tail;",
            "\tif (pipe_full(head, tail, pipe->ring_size))",
            "\t\tgoto lost;",
            "",
            "\tnote = find_first_bit(wqueue->notes_bitmap, wqueue->nr_notes);",
            "\tif (note >= wqueue->nr_notes)",
            "\t\tgoto lost;",
            "",
            "\tpage = wqueue->notes[note / WATCH_QUEUE_NOTES_PER_PAGE];",
            "\toffset = note % WATCH_QUEUE_NOTES_PER_PAGE * WATCH_QUEUE_NOTE_SIZE;",
            "\tget_page(page);",
            "\tlen = n->info & WATCH_INFO_LENGTH;",
            "\tp = kmap_atomic(page);",
            "\tmemcpy(p + offset, n, len);",
            "\tkunmap_atomic(p);",
            "",
            "\tbuf = pipe_buf(pipe, head);",
            "\tbuf->page = page;",
            "\tbuf->private = (unsigned long)wqueue;",
            "\tbuf->ops = &watch_queue_pipe_buf_ops;",
            "\tbuf->offset = offset;",
            "\tbuf->len = len;",
            "\tbuf->flags = PIPE_BUF_FLAG_WHOLE;",
            "\tsmp_store_release(&pipe->head, head + 1); /* vs pipe_read() */",
            "",
            "\tif (!test_and_clear_bit(note, wqueue->notes_bitmap)) {",
            "\t\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\t\tBUG();",
            "\t}",
            "\twake_up_interruptible_sync_poll_locked(&pipe->rd_wait, EPOLLIN | EPOLLRDNORM);",
            "\tdone = true;",
            "",
            "out:",
            "\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\tif (done)",
            "\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);",
            "\treturn done;",
            "",
            "lost:",
            "\tbuf = pipe_buf(pipe, head - 1);",
            "\tbuf->flags |= PIPE_BUF_FLAG_LOSS;",
            "\tgoto out;",
            "}",
            "static bool filter_watch_notification(const struct watch_filter *wf,",
            "\t\t\t\t      const struct watch_notification *n)",
            "{",
            "\tconst struct watch_type_filter *wt;",
            "\tunsigned int st_bits = sizeof(wt->subtype_filter[0]) * 8;",
            "\tunsigned int st_index = n->subtype / st_bits;",
            "\tunsigned int st_bit = 1U << (n->subtype % st_bits);",
            "\tint i;",
            "",
            "\tif (!test_bit(n->type, wf->type_filter))",
            "\t\treturn false;",
            "",
            "\tfor (i = 0; i < wf->nr_filters; i++) {",
            "\t\twt = &wf->filters[i];",
            "\t\tif (n->type == wt->type &&",
            "\t\t    (wt->subtype_filter[st_index] & st_bit) &&",
            "\t\t    (n->info & wt->info_mask) == wt->info_filter)",
            "\t\t\treturn true;",
            "\t}",
            "",
            "\treturn false; /* If there is a filter, the default is to reject. */",
            "}"
          ],
          "function_name": "lock_wqueue, unlock_wqueue, watch_queue_pipe_buf_release, post_one_notification, filter_watch_notification",
          "description": "实现了watch_queue的锁操作、缓冲区释放、通知提交及过滤逻辑。lock_wqueue/unlock_wqueue用于保护队列访问，watch_queue_pipe_buf_release处理缓冲区回收并更新位图，post_one_notification将通知数据写入管道，filter_watch_notification进行类型和子类型的匹配判断。",
          "similarity": 0.48867174983024597
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/watch_queue.c",
          "start_line": 1,
          "end_line": 41,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/* Watch queue and general notification mechanism, built on pipes",
            " *",
            " * Copyright (C) 2020 Red Hat, Inc. All Rights Reserved.",
            " * Written by David Howells (dhowells@redhat.com)",
            " *",
            " * See Documentation/core-api/watch_queue.rst",
            " */",
            "",
            "#define pr_fmt(fmt) \"watchq: \" fmt",
            "#include <linux/module.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/printk.h>",
            "#include <linux/miscdevice.h>",
            "#include <linux/fs.h>",
            "#include <linux/mm.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/poll.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <linux/security.h>",
            "#include <linux/cred.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/watch_queue.h>",
            "#include <linux/pipe_fs_i.h>",
            "",
            "MODULE_DESCRIPTION(\"Watch queue\");",
            "MODULE_AUTHOR(\"Red Hat, Inc.\");",
            "",
            "#define WATCH_QUEUE_NOTE_SIZE 128",
            "#define WATCH_QUEUE_NOTES_PER_PAGE (PAGE_SIZE / WATCH_QUEUE_NOTE_SIZE)",
            "",
            "/*",
            " * This must be called under the RCU read-lock, which makes",
            " * sure that the wqueue still exists. It can then take the lock,",
            " * and check that the wqueue hasn't been destroyed, which in",
            " * turn makes sure that the notification pipe still exists.",
            " */"
          ],
          "function_name": null,
          "description": "定义了watch_queue模块的头部信息，包含常量WATCH_QUEUE_NOTE_SIZE和NOTES_PER_PAGE，声明模块许可证及作者信息，并引入相关内核头文件，为后续实现提供基础框架。",
          "similarity": 0.43573206663131714
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/watch_queue.c",
          "start_line": 602,
          "end_line": 680,
          "content": [
            "void watch_queue_clear(struct watch_queue *wqueue)",
            "{",
            "\tstruct watch_list *wlist;",
            "\tstruct watch *watch;",
            "\tbool release;",
            "",
            "\trcu_read_lock();",
            "\tspin_lock_bh(&wqueue->lock);",
            "",
            "\t/*",
            "\t * This pipe can be freed by callers like free_pipe_info().",
            "\t * Removing this reference also prevents new notifications.",
            "\t */",
            "\twqueue->pipe = NULL;",
            "",
            "\twhile (!hlist_empty(&wqueue->watches)) {",
            "\t\twatch = hlist_entry(wqueue->watches.first, struct watch, queue_node);",
            "\t\thlist_del_init_rcu(&watch->queue_node);",
            "\t\t/* We now own a ref on the watch. */",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "",
            "\t\t/* We can't do the next bit under the queue lock as we need to",
            "\t\t * get the list lock - which would cause a deadlock if someone",
            "\t\t * was removing from the opposite direction at the same time or",
            "\t\t * posting a notification.",
            "\t\t */",
            "\t\twlist = rcu_dereference(watch->watch_list);",
            "\t\tif (wlist) {",
            "\t\t\tvoid (*release_watch)(struct watch *);",
            "",
            "\t\t\tspin_lock(&wlist->lock);",
            "",
            "\t\t\trelease = !hlist_unhashed(&watch->list_node);",
            "\t\t\tif (release) {",
            "\t\t\t\thlist_del_init_rcu(&watch->list_node);",
            "\t\t\t\trcu_assign_pointer(watch->watch_list, NULL);",
            "",
            "\t\t\t\t/* We now own a second ref on the watch. */",
            "\t\t\t}",
            "",
            "\t\t\trelease_watch = wlist->release_watch;",
            "\t\t\tspin_unlock(&wlist->lock);",
            "",
            "\t\t\tif (release) {",
            "\t\t\t\tif (release_watch) {",
            "\t\t\t\t\trcu_read_unlock();",
            "\t\t\t\t\t/* This might need to call dput(), so",
            "\t\t\t\t\t * we have to drop all the locks.",
            "\t\t\t\t\t */",
            "\t\t\t\t\t(*release_watch)(watch);",
            "\t\t\t\t\trcu_read_lock();",
            "\t\t\t\t}",
            "\t\t\t\tput_watch(watch);",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tput_watch(watch);",
            "\t\tspin_lock_bh(&wqueue->lock);",
            "\t}",
            "",
            "\tspin_unlock_bh(&wqueue->lock);",
            "\trcu_read_unlock();",
            "}",
            "int watch_queue_init(struct pipe_inode_info *pipe)",
            "{",
            "\tstruct watch_queue *wqueue;",
            "",
            "\twqueue = kzalloc(sizeof(*wqueue), GFP_KERNEL);",
            "\tif (!wqueue)",
            "\t\treturn -ENOMEM;",
            "",
            "\twqueue->pipe = pipe;",
            "\tkref_init(&wqueue->usage);",
            "\tspin_lock_init(&wqueue->lock);",
            "\tINIT_HLIST_HEAD(&wqueue->watches);",
            "",
            "\tpipe->watch_queue = wqueue;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "watch_queue_clear, watch_queue_init",
          "description": "该代码实现了监视队列的初始化与清理功能。  \n`watch_queue_clear`通过RCU和自旋锁机制安全地移除所有监视项并释放资源，`watch_queue_init`初始化监视队列结构并绑定至管道对象。  \n上下文不完整：`release_watch`等关键函数依赖外部定义，部分RCU回调逻辑未完全展示。",
          "similarity": 0.4346345067024231
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/watch_queue.c",
          "start_line": 193,
          "end_line": 304,
          "content": [
            "void __post_watch_notification(struct watch_list *wlist,",
            "\t\t\t       struct watch_notification *n,",
            "\t\t\t       const struct cred *cred,",
            "\t\t\t       u64 id)",
            "{",
            "\tconst struct watch_filter *wf;",
            "\tstruct watch_queue *wqueue;",
            "\tstruct watch *watch;",
            "",
            "\tif (((n->info & WATCH_INFO_LENGTH) >> WATCH_INFO_LENGTH__SHIFT) == 0) {",
            "\t\tWARN_ON(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\trcu_read_lock();",
            "",
            "\thlist_for_each_entry_rcu(watch, &wlist->watchers, list_node) {",
            "\t\tif (watch->id != id)",
            "\t\t\tcontinue;",
            "\t\tn->info &= ~WATCH_INFO_ID;",
            "\t\tn->info |= watch->info_id;",
            "",
            "\t\twqueue = rcu_dereference(watch->queue);",
            "\t\twf = rcu_dereference(wqueue->filter);",
            "\t\tif (wf && !filter_watch_notification(wf, n))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (security_post_notification(watch->cred, cred, n) < 0)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (lock_wqueue(wqueue)) {",
            "\t\t\tpost_one_notification(wqueue, n);",
            "\t\t\tunlock_wqueue(wqueue);",
            "\t\t}",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "}",
            "long watch_queue_set_size(struct pipe_inode_info *pipe, unsigned int nr_notes)",
            "{",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tstruct page **pages;",
            "\tunsigned long *bitmap;",
            "\tunsigned long user_bufs;",
            "\tint ret, i, nr_pages;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "\tif (wqueue->notes)",
            "\t\treturn -EBUSY;",
            "",
            "\tif (nr_notes < 1 ||",
            "\t    nr_notes > 512) /* TODO: choose a better hard limit */",
            "\t\treturn -EINVAL;",
            "",
            "\tnr_pages = (nr_notes + WATCH_QUEUE_NOTES_PER_PAGE - 1);",
            "\tnr_pages /= WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tuser_bufs = account_pipe_buffers(pipe->user, pipe->nr_accounted, nr_pages);",
            "",
            "\tif (nr_pages > pipe->max_usage &&",
            "\t    (too_many_pipe_buffers_hard(user_bufs) ||",
            "\t     too_many_pipe_buffers_soft(user_bufs)) &&",
            "\t    pipe_is_unprivileged_user()) {",
            "\t\tret = -EPERM;",
            "\t\tgoto error;",
            "\t}",
            "",
            "\tnr_notes = nr_pages * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tret = pipe_resize_ring(pipe, roundup_pow_of_two(nr_notes));",
            "\tif (ret < 0)",
            "\t\tgoto error;",
            "",
            "\t/*",
            "\t * pipe_resize_ring() does not update nr_accounted for watch_queue",
            "\t * pipes, because the above vastly overprovisions. Set nr_accounted on",
            "\t * and max_usage this pipe to the number that was actually charged to",
            "\t * the user above via account_pipe_buffers.",
            "\t */",
            "\tpipe->max_usage = nr_pages;",
            "\tpipe->nr_accounted = nr_pages;",
            "",
            "\tret = -ENOMEM;",
            "\tpages = kcalloc(sizeof(struct page *), nr_pages, GFP_KERNEL);",
            "\tif (!pages)",
            "\t\tgoto error;",
            "",
            "\tfor (i = 0; i < nr_pages; i++) {",
            "\t\tpages[i] = alloc_page(GFP_KERNEL);",
            "\t\tif (!pages[i])",
            "\t\t\tgoto error_p;",
            "\t\tpages[i]->index = i * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\t}",
            "",
            "\tbitmap = bitmap_alloc(nr_notes, GFP_KERNEL);",
            "\tif (!bitmap)",
            "\t\tgoto error_p;",
            "",
            "\tbitmap_fill(bitmap, nr_notes);",
            "\twqueue->notes = pages;",
            "\twqueue->notes_bitmap = bitmap;",
            "\twqueue->nr_pages = nr_pages;",
            "\twqueue->nr_notes = nr_notes;",
            "\treturn 0;",
            "",
            "error_p:",
            "\twhile (--i >= 0)",
            "\t\t__free_page(pages[i]);",
            "\tkfree(pages);",
            "error:",
            "\t(void) account_pipe_buffers(pipe->user, nr_pages, pipe->nr_accounted);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__post_watch_notification, watch_queue_set_size",
          "description": "__post_watch_notification遍历watch列表并应用过滤器后提交通知，watch_queue_set_size动态调整管道容量，通过计算所需页数和位图分配，限制最大容量为512个笔记，支持扩展性需求。",
          "similarity": 0.41088518500328064
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/watch_queue.c",
          "start_line": 315,
          "end_line": 422,
          "content": [
            "long watch_queue_set_filter(struct pipe_inode_info *pipe,",
            "\t\t\t    struct watch_notification_filter __user *_filter)",
            "{",
            "\tstruct watch_notification_type_filter *tf;",
            "\tstruct watch_notification_filter filter;",
            "\tstruct watch_type_filter *q;",
            "\tstruct watch_filter *wfilter;",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tint ret, nr_filter = 0, i;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "",
            "\tif (!_filter) {",
            "\t\t/* Remove the old filter */",
            "\t\twfilter = NULL;",
            "\t\tgoto set;",
            "\t}",
            "",
            "\t/* Grab the user's filter specification */",
            "\tif (copy_from_user(&filter, _filter, sizeof(filter)) != 0)",
            "\t\treturn -EFAULT;",
            "\tif (filter.nr_filters == 0 ||",
            "\t    filter.nr_filters > 16 ||",
            "\t    filter.__reserved != 0)",
            "\t\treturn -EINVAL;",
            "",
            "\ttf = memdup_array_user(_filter->filters, filter.nr_filters, sizeof(*tf));",
            "\tif (IS_ERR(tf))",
            "\t\treturn PTR_ERR(tf);",
            "",
            "\tret = -EINVAL;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif ((tf[i].info_filter & ~tf[i].info_mask) ||",
            "\t\t    tf[i].info_mask & WATCH_INFO_LENGTH)",
            "\t\t\tgoto err_filter;",
            "\t\t/* Ignore any unknown types */",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "\t\tnr_filter++;",
            "\t}",
            "",
            "\t/* Now we need to build the internal filter from only the relevant",
            "\t * user-specified filters.",
            "\t */",
            "\tret = -ENOMEM;",
            "\twfilter = kzalloc(struct_size(wfilter, filters, nr_filter), GFP_KERNEL);",
            "\tif (!wfilter)",
            "\t\tgoto err_filter;",
            "\twfilter->nr_filters = nr_filter;",
            "",
            "\tq = wfilter->filters;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "",
            "\t\tq->type\t\t\t= tf[i].type;",
            "\t\tq->info_filter\t\t= tf[i].info_filter;",
            "\t\tq->info_mask\t\t= tf[i].info_mask;",
            "\t\tq->subtype_filter[0]\t= tf[i].subtype_filter[0];",
            "\t\t__set_bit(q->type, wfilter->type_filter);",
            "\t\tq++;",
            "\t}",
            "",
            "\tkfree(tf);",
            "set:",
            "\tpipe_lock(pipe);",
            "\twfilter = rcu_replace_pointer(wqueue->filter, wfilter,",
            "\t\t\t\t      lockdep_is_held(&pipe->mutex));",
            "\tpipe_unlock(pipe);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\treturn 0;",
            "",
            "err_filter:",
            "\tkfree(tf);",
            "\treturn ret;",
            "}",
            "static void __put_watch_queue(struct kref *kref)",
            "{",
            "\tstruct watch_queue *wqueue =",
            "\t\tcontainer_of(kref, struct watch_queue, usage);",
            "\tstruct watch_filter *wfilter;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < wqueue->nr_pages; i++)",
            "\t\t__free_page(wqueue->notes[i]);",
            "\tkfree(wqueue->notes);",
            "\tbitmap_free(wqueue->notes_bitmap);",
            "",
            "\twfilter = rcu_access_pointer(wqueue->filter);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\tkfree_rcu(wqueue, rcu);",
            "}",
            "void put_watch_queue(struct watch_queue *wqueue)",
            "{",
            "\tkref_put(&wqueue->usage, __put_watch_queue);",
            "}",
            "static void free_watch(struct rcu_head *rcu)",
            "{",
            "\tstruct watch *watch = container_of(rcu, struct watch, rcu);",
            "",
            "\tput_watch_queue(rcu_access_pointer(watch->queue));",
            "\tatomic_dec(&watch->cred->user->nr_watches);",
            "\tput_cred(watch->cred);",
            "\tkfree(watch);",
            "}"
          ],
          "function_name": "watch_queue_set_filter, __put_watch_queue, put_watch_queue, free_watch",
          "description": "watch_queue_set_filter设置过滤规则并转换为内核内部结构，__put_watch_queue释放watch_queue相关资源包括页面、位图和过滤器，put_watch_queue通过引用计数管理watch_queue生命周期，free_watch执行RCU回调完成最终释放。",
          "similarity": 0.3966626524925232
        }
      ]
    }
  ]
}