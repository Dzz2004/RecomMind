{
  "query": "task_struct中exit_code字段作用",
  "timestamp": "2025-12-26 00:40:45",
  "retrieved_files": [
    {
      "source_file": "kernel/exit.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:27:18\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `exit.c`\n\n---\n\n# `exit.c` 技术文档\n\n## 1. 文件概述\n\n`exit.c` 是 Linux 内核中负责进程退出（termination）核心逻辑的关键源文件，位于 `kernel/` 目录下。该文件实现了进程终止时的资源回收、信号处理、线程组清理、引用计数释放以及与用户空间和内核其他子系统的协调机制。其主要职责包括：\n\n- 安全地释放进程占用的内核资源（如内存、文件描述符、信号处理结构等）\n- 更新进程组和会话的统计信息\n- 通知父进程子进程已退出（通过 `SIGCHLD` 信号）\n- 管理僵尸进程（zombie）的生命周期\n- 支持线程组（thread group）的协同退出\n- 提供与 oops（内核异常）相关的计数和限制机制\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数名 | 功能描述 |\n|--------|---------|\n| `__unhash_process()` | 从内核的进程哈希表和链表中移除进程，减少线程计数 |\n| `__exit_signal()` | 清理进程的信号相关资源，累加 CPU 时间和 I/O 统计到 `signal_struct` |\n| `delayed_put_task_struct()` | RCU 回调函数，延迟释放 `task_struct` 及其关联资源 |\n| `put_task_struct_rcu_user()` | 安全地减少 `task_struct` 的 RCU 用户引用计数，并在为零时调度延迟释放 |\n| `release_thread()` | 架构相关的线程资源释放钩子（弱符号，可由架构代码覆盖） |\n| `release_task()` | 主进程释放入口函数，协调整个退出流程，包括通知父进程、释放资源等 |\n| `rcuwait_wake_up()` | 唤醒等待在 `rcuwait` 上的任务（代码片段未完整） |\n\n### 关键数据结构与变量\n\n| 名称 | 类型/说明 |\n|------|----------|\n| `oops_limit` | `unsigned int`，限制内核 oops 发生次数的阈值（默认 10000） |\n| `oops_count` | `atomic_t`，原子计数器，记录系统发生 oops 的总次数 |\n| `kern_exit_table` | `ctl_table`，用于 `/proc/sys/kernel/oops_limit` 的 sysctl 接口 |\n| `oops_count_attr` | `kobj_attribute`，用于 `/sys/kernel/oops_count` 的 sysfs 接口 |\n\n## 3. 关键实现\n\n### 进程退出流程\n\n1. **资源统计聚合**：  \n   在 `__exit_signal()` 中，将退出线程的 CPU 时间（`utime`/`stime`）、I/O 操作、上下文切换次数等统计信息累加到所属线程组的 `signal_struct` 中，确保即使线程组 leader 尚未退出，也能被 `wait4()` 等系统调用正确获取。\n\n2. **线程组协同退出**：  \n   - 若当前退出的是线程组 leader（`group_dead == true`），则清理整个线程组的 PID 类型（TGID、PGID、SID），并从全局任务链表中移除。\n   - 若非 leader，则仅减少线程组计数，并可能更新 `curr_target`（用于信号投递）。\n\n3. **僵尸进程处理**：  \n   在 `release_task()` 中，检查线程组 leader 是否已变为僵尸状态。若是且当前线程是最后一个成员，则调用 `do_notify_parent()` 通知其父进程。若父进程忽略 `SIGCHLD`，则直接将 leader 状态置为 `EXIT_DEAD` 并递归释放。\n\n4. **延迟释放机制**：  \n   通过 RCU（Read-Copy-Update）机制安全释放 `task_struct`。`put_task_struct_rcu_user()` 在引用计数归零时调用 `call_rcu()`，由 `delayed_put_task_struct()` 在 RCU 宽限期后执行实际释放，确保并发读取安全。\n\n5. **Oops 计数与限制**：  \n   提供 `oops_count`（只读）和 `oops_limit`（可调）两个接口，用于监控和限制内核异常次数，防止因频繁崩溃导致资源耗尽或引用计数溢出。\n\n### 锁与同步\n\n- **`tasklist_lock`**：写锁保护进程链表和 PID 哈希表的修改。\n- **`sighand->siglock`**：自旋锁保护信号处理结构。\n- **`signal->stats_lock`**：顺序锁（seqlock）保护线程组统计信息的聚合。\n- **RCU**：用于安全地延迟释放 `task_struct`，避免在遍历任务链表时访问已释放内存。\n\n## 4. 依赖关系\n\n`exit.c` 与内核多个子系统紧密耦合，主要依赖包括：\n\n- **调度器（SCHED）**：`<linux/sched/*.h>`，用于任务状态管理、CPU 时间统计、任务链表操作。\n- **内存管理（MM）**：`<linux/mm.h>`、`<linux/slab.h>`，用于内存释放和 slab 分配器交互。\n- **文件系统（VFS）**：`<linux/file.h>`、`<linux/fdtable.h>`、`<linux/fs_struct.h>`，用于关闭文件描述符和释放文件系统上下文。\n- **进程间通信（IPC）**：`<linux/shm.h>`、`<linux/posix-timers.h>`，用于清理共享内存和定时器资源。\n- **安全与审计**：`<linux/audit.h>`、`<linux/seccomp.h>`（通过 `seccomp_filter_release`），用于释放安全策略和审计上下文。\n- **cgroup 与资源控制**：`<linux/cgroup.h>`、`<linux/resource.h>`，用于资源计数释放和限制检查。\n- **跟踪与性能**：`<linux/perf_event.h>`、`<trace/events/sched.h>`，用于性能事件清理和调度跟踪点。\n- **架构相关代码**：`<asm/mmu_context.h>`、`release_thread()` 弱符号，允许架构层定制线程释放逻辑。\n\n## 5. 使用场景\n\n- **进程正常退出**：当用户程序调用 `exit()` 或 `exit_group()` 系统调用时，内核通过此文件执行清理。\n- **进程被信号终止**：如收到 `SIGKILL` 或 `SIGTERM` 后，内核调度退出路径。\n- **线程退出**：POSIX 线程（通过 `pthread_exit()` 或线程函数返回）触发 `release_task()` 清理单个线程。\n- **内核 Oops/panic 处理**：每次内核异常会递增 `oops_count`，用于监控系统稳定性。\n- **僵尸进程回收**：父进程调用 `wait()` 系列系统调用后，内核最终通过 `release_task()` 释放僵尸进程的内核结构。\n- **容器/命名空间退出**：在 PID 命名空间或 cgroup 中进程退出时，协调资源释放和通知机制。",
      "similarity": 0.618888795375824,
      "chunks": [
        {
          "chunk_id": 5,
          "file_path": "kernel/exit.c",
          "start_line": 791,
          "end_line": 942,
          "content": [
            "static void check_stack_usage(void)",
            "{",
            "\tstatic DEFINE_SPINLOCK(low_water_lock);",
            "\tstatic int lowest_to_date = THREAD_SIZE;",
            "\tunsigned long free;",
            "",
            "\tfree = stack_not_used(current);",
            "",
            "\tif (free >= lowest_to_date)",
            "\t\treturn;",
            "",
            "\tspin_lock(&low_water_lock);",
            "\tif (free < lowest_to_date) {",
            "\t\tpr_info(\"%s (%d) used greatest stack depth: %lu bytes left\\n\",",
            "\t\t\tcurrent->comm, task_pid_nr(current), free);",
            "\t\tlowest_to_date = free;",
            "\t}",
            "\tspin_unlock(&low_water_lock);",
            "}",
            "static inline void check_stack_usage(void) {}",
            "static void synchronize_group_exit(struct task_struct *tsk, long code)",
            "{",
            "\tstruct sighand_struct *sighand = tsk->sighand;",
            "\tstruct signal_struct *signal = tsk->signal;",
            "",
            "\tspin_lock_irq(&sighand->siglock);",
            "\tsignal->quick_threads--;",
            "\tif ((signal->quick_threads == 0) &&",
            "\t    !(signal->flags & SIGNAL_GROUP_EXIT)) {",
            "\t\tsignal->flags = SIGNAL_GROUP_EXIT;",
            "\t\tsignal->group_exit_code = code;",
            "\t\tsignal->group_stop_count = 0;",
            "\t}",
            "\tspin_unlock_irq(&sighand->siglock);",
            "}",
            "void __noreturn do_exit(long code)",
            "{",
            "\tstruct task_struct *tsk = current;",
            "\tint group_dead;",
            "",
            "\tWARN_ON(irqs_disabled());",
            "",
            "\tsynchronize_group_exit(tsk, code);",
            "",
            "\tWARN_ON(tsk->plug);",
            "",
            "\tkcov_task_exit(tsk);",
            "\tkmsan_task_exit(tsk);",
            "",
            "\tcoredump_task_exit(tsk);",
            "\tptrace_event(PTRACE_EVENT_EXIT, code);",
            "\tuser_events_exit(tsk);",
            "",
            "\tio_uring_files_cancel();",
            "\texit_signals(tsk);  /* sets PF_EXITING */",
            "",
            "\t/* sync mm's RSS info before statistics gathering */",
            "\tif (tsk->mm)",
            "\t\tsync_mm_rss(tsk->mm);",
            "\tacct_update_integrals(tsk);",
            "\tgroup_dead = atomic_dec_and_test(&tsk->signal->live);",
            "\tif (group_dead) {",
            "\t\t/*",
            "\t\t * If the last thread of global init has exited, panic",
            "\t\t * immediately to get a useable coredump.",
            "\t\t */",
            "\t\tif (unlikely(is_global_init(tsk)))",
            "\t\t\tpanic(\"Attempted to kill init! exitcode=0x%08x\\n\",",
            "\t\t\t\ttsk->signal->group_exit_code ?: (int)code);",
            "",
            "#ifdef CONFIG_POSIX_TIMERS",
            "\t\thrtimer_cancel(&tsk->signal->real_timer);",
            "\t\texit_itimers(tsk);",
            "#endif",
            "\t\tif (tsk->mm)",
            "\t\t\tsetmax_mm_hiwater_rss(&tsk->signal->maxrss, tsk->mm);",
            "\t}",
            "\tacct_collect(code, group_dead);",
            "\tif (group_dead)",
            "\t\ttty_audit_exit();",
            "\taudit_free(tsk);",
            "",
            "\ttsk->exit_code = code;",
            "\ttaskstats_exit(tsk, group_dead);",
            "",
            "\t/*",
            "\t * Since sampling can touch ->mm, make sure to stop everything before we",
            "\t * tear it down.",
            "\t *",
            "\t * Also flushes inherited counters to the parent - before the parent",
            "\t * gets woken up by child-exit notifications.",
            "\t */",
            "\tperf_event_exit_task(tsk);",
            "",
            "\texit_mm();",
            "",
            "\tif (group_dead)",
            "\t\tacct_process();",
            "\ttrace_sched_process_exit(tsk);",
            "",
            "\texit_sem(tsk);",
            "\texit_shm(tsk);",
            "\texit_files(tsk);",
            "\texit_fs(tsk);",
            "\tif (group_dead)",
            "\t\tdisassociate_ctty(1);",
            "\texit_task_namespaces(tsk);",
            "\texit_task_work(tsk);",
            "\texit_thread(tsk);",
            "",
            "\tsched_autogroup_exit_task(tsk);",
            "\tcgroup_exit(tsk);",
            "",
            "\t/*",
            "\t * FIXME: do that only when needed, using sched_exit tracepoint",
            "\t */",
            "\tflush_ptrace_hw_breakpoint(tsk);",
            "",
            "\texit_tasks_rcu_start();",
            "\texit_notify(tsk, group_dead);",
            "\tproc_exit_connector(tsk);",
            "\tmpol_put_task_policy(tsk);",
            "#ifdef CONFIG_FUTEX",
            "\tif (unlikely(current->pi_state_cache))",
            "\t\tkfree(current->pi_state_cache);",
            "#endif",
            "\t/*",
            "\t * Make sure we are holding no locks:",
            "\t */",
            "\tdebug_check_no_locks_held();",
            "",
            "\tif (tsk->io_context)",
            "\t\texit_io_context(tsk);",
            "",
            "\tif (tsk->splice_pipe)",
            "\t\tfree_pipe_info(tsk->splice_pipe);",
            "",
            "\tif (tsk->task_frag.page)",
            "\t\tput_page(tsk->task_frag.page);",
            "",
            "\texit_task_stack_account(tsk);",
            "",
            "\tcheck_stack_usage();",
            "\tpreempt_disable();",
            "\tif (tsk->nr_dirtied)",
            "\t\t__this_cpu_add(dirty_throttle_leaks, tsk->nr_dirtied);",
            "\texit_rcu();",
            "\texit_tasks_rcu_finish();",
            "",
            "\tlockdep_free_task(tsk);",
            "\tdo_task_dead();",
            "}"
          ],
          "function_name": "check_stack_usage, check_stack_usage, synchronize_group_exit, do_exit",
          "description": "do_exit函数负责处理进程退出流程，包括同步线程组退出、释放资源、更新统计信息、清理内存映射、解除命名空间关联等操作。其中synchronize_group_exit用于减少信号量计数并标记线程组退出状态，check_stack_usage监控最大堆栈使用量。",
          "similarity": 0.6285871267318726
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/exit.c",
          "start_line": 948,
          "end_line": 1066,
          "content": [
            "void __noreturn make_task_dead(int signr)",
            "{",
            "\t/*",
            "\t * Take the task off the cpu after something catastrophic has",
            "\t * happened.",
            "\t *",
            "\t * We can get here from a kernel oops, sometimes with preemption off.",
            "\t * Start by checking for critical errors.",
            "\t * Then fix up important state like USER_DS and preemption.",
            "\t * Then do everything else.",
            "\t */",
            "\tstruct task_struct *tsk = current;",
            "\tunsigned int limit;",
            "",
            "\tif (unlikely(in_interrupt()))",
            "\t\tpanic(\"Aiee, killing interrupt handler!\");",
            "\tif (unlikely(!tsk->pid))",
            "\t\tpanic(\"Attempted to kill the idle task!\");",
            "",
            "\tif (unlikely(irqs_disabled())) {",
            "\t\tpr_info(\"note: %s[%d] exited with irqs disabled\\n\",",
            "\t\t\tcurrent->comm, task_pid_nr(current));",
            "\t\tlocal_irq_enable();",
            "\t}",
            "\tif (unlikely(in_atomic())) {",
            "\t\tpr_info(\"note: %s[%d] exited with preempt_count %d\\n\",",
            "\t\t\tcurrent->comm, task_pid_nr(current),",
            "\t\t\tpreempt_count());",
            "\t\tpreempt_count_set(PREEMPT_ENABLED);",
            "\t}",
            "",
            "\t/*",
            "\t * Every time the system oopses, if the oops happens while a reference",
            "\t * to an object was held, the reference leaks.",
            "\t * If the oops doesn't also leak memory, repeated oopsing can cause",
            "\t * reference counters to wrap around (if they're not using refcount_t).",
            "\t * This means that repeated oopsing can make unexploitable-looking bugs",
            "\t * exploitable through repeated oopsing.",
            "\t * To make sure this can't happen, place an upper bound on how often the",
            "\t * kernel may oops without panic().",
            "\t */",
            "\tlimit = READ_ONCE(oops_limit);",
            "\tif (atomic_inc_return(&oops_count) >= limit && limit)",
            "\t\tpanic(\"Oopsed too often (kernel.oops_limit is %d)\", limit);",
            "",
            "\t/*",
            "\t * We're taking recursive faults here in make_task_dead. Safest is to just",
            "\t * leave this task alone and wait for reboot.",
            "\t */",
            "\tif (unlikely(tsk->flags & PF_EXITING)) {",
            "\t\tpr_alert(\"Fixing recursive fault but reboot is needed!\\n\");",
            "\t\tfutex_exit_recursive(tsk);",
            "\t\ttsk->exit_state = EXIT_DEAD;",
            "\t\trefcount_inc(&tsk->rcu_users);",
            "\t\tdo_task_dead();",
            "\t}",
            "",
            "\tdo_exit(signr);",
            "}",
            "void __noreturn",
            "do_group_exit(int exit_code)",
            "{",
            "\tstruct signal_struct *sig = current->signal;",
            "",
            "\tif (sig->flags & SIGNAL_GROUP_EXIT)",
            "\t\texit_code = sig->group_exit_code;",
            "\telse if (sig->group_exec_task)",
            "\t\texit_code = 0;",
            "\telse {",
            "\t\tstruct sighand_struct *const sighand = current->sighand;",
            "",
            "\t\tspin_lock_irq(&sighand->siglock);",
            "\t\tif (sig->flags & SIGNAL_GROUP_EXIT)",
            "\t\t\t/* Another thread got here before we took the lock.  */",
            "\t\t\texit_code = sig->group_exit_code;",
            "\t\telse if (sig->group_exec_task)",
            "\t\t\texit_code = 0;",
            "\t\telse {",
            "\t\t\tsig->group_exit_code = exit_code;",
            "\t\t\tsig->flags = SIGNAL_GROUP_EXIT;",
            "\t\t\tzap_other_threads(current);",
            "\t\t}",
            "\t\tspin_unlock_irq(&sighand->siglock);",
            "\t}",
            "",
            "\tdo_exit(exit_code);",
            "\t/* NOTREACHED */",
            "}",
            "static int eligible_pid(struct wait_opts *wo, struct task_struct *p)",
            "{",
            "\treturn\two->wo_type == PIDTYPE_MAX ||",
            "\t\ttask_pid_type(p, wo->wo_type) == wo->wo_pid;",
            "}",
            "static int",
            "eligible_child(struct wait_opts *wo, bool ptrace, struct task_struct *p)",
            "{",
            "\tif (!eligible_pid(wo, p))",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * Wait for all children (clone and not) if __WALL is set or",
            "\t * if it is traced by us.",
            "\t */",
            "\tif (ptrace || (wo->wo_flags & __WALL))",
            "\t\treturn 1;",
            "",
            "\t/*",
            "\t * Otherwise, wait for clone children *only* if __WCLONE is set;",
            "\t * otherwise, wait for non-clone children *only*.",
            "\t *",
            "\t * Note: a \"clone\" child here is one that reports to its parent",
            "\t * using a signal other than SIGCHLD, or a non-leader thread which",
            "\t * we can only see if it is traced by us.",
            "\t */",
            "\tif ((p->exit_signal != SIGCHLD) ^ !!(wo->wo_flags & __WCLONE))",
            "\t\treturn 0;",
            "",
            "\treturn 1;",
            "}"
          ],
          "function_name": "make_task_dead, do_group_exit, eligible_pid, eligible_child",
          "description": "make_task_dead处理致命错误导致的进程终止，通过do_exit完成退出流程；do_group_exit用于线程组统一退出，设置退出码并触发do_exit；eligible_pid和eligible_child用于过滤符合等待条件的子进程，根据PID类型和跟踪标志进行匹配。",
          "similarity": 0.5957858562469482
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/exit.c",
          "start_line": 1494,
          "end_line": 1580,
          "content": [
            "static int do_wait_thread(struct wait_opts *wo, struct task_struct *tsk)",
            "{",
            "\tstruct task_struct *p;",
            "",
            "\tlist_for_each_entry(p, &tsk->children, sibling) {",
            "\t\tint ret = wait_consider_task(wo, 0, p);",
            "",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int ptrace_do_wait(struct wait_opts *wo, struct task_struct *tsk)",
            "{",
            "\tstruct task_struct *p;",
            "",
            "\tlist_for_each_entry(p, &tsk->ptraced, ptrace_entry) {",
            "\t\tint ret = wait_consider_task(wo, 1, p);",
            "",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "bool pid_child_should_wake(struct wait_opts *wo, struct task_struct *p)",
            "{",
            "\tif (!eligible_pid(wo, p))",
            "\t\treturn false;",
            "",
            "\tif ((wo->wo_flags & __WNOTHREAD) && wo->child_wait.private != p->parent)",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}",
            "static int child_wait_callback(wait_queue_entry_t *wait, unsigned mode,",
            "\t\t\t\tint sync, void *key)",
            "{",
            "\tstruct wait_opts *wo = container_of(wait, struct wait_opts,",
            "\t\t\t\t\t\tchild_wait);",
            "\tstruct task_struct *p = key;",
            "",
            "\tif (pid_child_should_wake(wo, p))",
            "\t\treturn default_wake_function(wait, mode, sync, key);",
            "",
            "\treturn 0;",
            "}",
            "void __wake_up_parent(struct task_struct *p, struct task_struct *parent)",
            "{",
            "\t__wake_up_sync_key(&parent->signal->wait_chldexit,",
            "\t\t\t   TASK_INTERRUPTIBLE, p);",
            "}",
            "static bool is_effectively_child(struct wait_opts *wo, bool ptrace,",
            "\t\t\t\t struct task_struct *target)",
            "{",
            "\tstruct task_struct *parent =",
            "\t\t!ptrace ? target->real_parent : target->parent;",
            "",
            "\treturn current == parent || (!(wo->wo_flags & __WNOTHREAD) &&",
            "\t\t\t\t     same_thread_group(current, parent));",
            "}",
            "static int do_wait_pid(struct wait_opts *wo)",
            "{",
            "\tbool ptrace;",
            "\tstruct task_struct *target;",
            "\tint retval;",
            "",
            "\tptrace = false;",
            "\ttarget = pid_task(wo->wo_pid, PIDTYPE_TGID);",
            "\tif (target && is_effectively_child(wo, ptrace, target)) {",
            "\t\tretval = wait_consider_task(wo, ptrace, target);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "\t}",
            "",
            "\tptrace = true;",
            "\ttarget = pid_task(wo->wo_pid, PIDTYPE_PID);",
            "\tif (target && target->ptrace &&",
            "\t    is_effectively_child(wo, ptrace, target)) {",
            "\t\tretval = wait_consider_task(wo, ptrace, target);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "\t}",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "do_wait_thread, ptrace_do_wait, pid_child_should_wake, child_wait_callback, __wake_up_parent, is_effectively_child, do_wait_pid",
          "description": "该代码段实现了父进程对子进程退出状态的等待逻辑，包含线程组子进程和被ptrace跟踪子进程的处理。do_wait_thread和ptrace_do_wait遍历子进程列表并调用wait_consider_task检查是否满足等待条件，而child_wait_callback与__wake_up_parent协同完成子进程退出时的唤醒机制。is_effectively_child用于判定当前进程是否为有效子进程，do_wait_pid则根据PID类型选择具体的目标子进程进行等待。",
          "similarity": 0.5634039640426636
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/exit.c",
          "start_line": 228,
          "end_line": 339,
          "content": [
            "void put_task_struct_rcu_user(struct task_struct *task)",
            "{",
            "\tif (refcount_dec_and_test(&task->rcu_users))",
            "\t\tcall_rcu(&task->rcu, delayed_put_task_struct);",
            "}",
            "void __weak release_thread(struct task_struct *dead_task)",
            "{",
            "}",
            "void release_task(struct task_struct *p)",
            "{",
            "\tstruct task_struct *leader;",
            "\tstruct pid *thread_pid;",
            "\tint zap_leader;",
            "repeat:",
            "\t/* don't need to get the RCU readlock here - the process is dead and",
            "\t * can't be modifying its own credentials. But shut RCU-lockdep up */",
            "\trcu_read_lock();",
            "\tdec_rlimit_ucounts(task_ucounts(p), UCOUNT_RLIMIT_NPROC, 1);",
            "\trcu_read_unlock();",
            "",
            "\tcgroup_release(p);",
            "",
            "\twrite_lock_irq(&tasklist_lock);",
            "\tptrace_release_task(p);",
            "\tthread_pid = get_pid(p->thread_pid);",
            "\t__exit_signal(p);",
            "",
            "\t/*",
            "\t * If we are the last non-leader member of the thread",
            "\t * group, and the leader is zombie, then notify the",
            "\t * group leader's parent process. (if it wants notification.)",
            "\t */",
            "\tzap_leader = 0;",
            "\tleader = p->group_leader;",
            "\tif (leader != p && thread_group_empty(leader)",
            "\t\t\t&& leader->exit_state == EXIT_ZOMBIE) {",
            "\t\t/*",
            "\t\t * If we were the last child thread and the leader has",
            "\t\t * exited already, and the leader's parent ignores SIGCHLD,",
            "\t\t * then we are the one who should release the leader.",
            "\t\t */",
            "\t\tzap_leader = do_notify_parent(leader, leader->exit_signal);",
            "\t\tif (zap_leader)",
            "\t\t\tleader->exit_state = EXIT_DEAD;",
            "\t}",
            "",
            "\twrite_unlock_irq(&tasklist_lock);",
            "\tseccomp_filter_release(p);",
            "\tproc_flush_pid(thread_pid);",
            "\tput_pid(thread_pid);",
            "\trelease_thread(p);",
            "\t/*",
            "\t * This task was already removed from the process/thread/pid lists",
            "\t * and lock_task_sighand(p) can't succeed. Nobody else can touch",
            "\t * ->pending or, if group dead, signal->shared_pending. We can call",
            "\t * flush_sigqueue() lockless.",
            "\t */",
            "\tflush_sigqueue(&p->pending);",
            "\tif (thread_group_leader(p))",
            "\t\tflush_sigqueue(&p->signal->shared_pending);",
            "",
            "\tput_task_struct_rcu_user(p);",
            "",
            "\tp = leader;",
            "\tif (unlikely(zap_leader))",
            "\t\tgoto repeat;",
            "}",
            "int rcuwait_wake_up(struct rcuwait *w)",
            "{",
            "\tint ret = 0;",
            "\tstruct task_struct *task;",
            "",
            "\trcu_read_lock();",
            "",
            "\t/*",
            "\t * Order condition vs @task, such that everything prior to the load",
            "\t * of @task is visible. This is the condition as to why the user called",
            "\t * rcuwait_wake() in the first place. Pairs with set_current_state()",
            "\t * barrier (A) in rcuwait_wait_event().",
            "\t *",
            "\t *    WAIT                WAKE",
            "\t *    [S] tsk = current\t  [S] cond = true",
            "\t *        MB (A)\t      MB (B)",
            "\t *    [L] cond\t\t  [L] tsk",
            "\t */",
            "\tsmp_mb(); /* (B) */",
            "",
            "\ttask = rcu_dereference(w->task);",
            "\tif (task)",
            "\t\tret = wake_up_process(task);",
            "\trcu_read_unlock();",
            "",
            "\treturn ret;",
            "}",
            "static int will_become_orphaned_pgrp(struct pid *pgrp,",
            "\t\t\t\t\tstruct task_struct *ignored_task)",
            "{",
            "\tstruct task_struct *p;",
            "",
            "\tdo_each_pid_task(pgrp, PIDTYPE_PGID, p) {",
            "\t\tif ((p == ignored_task) ||",
            "\t\t    (p->exit_state && thread_group_empty(p)) ||",
            "\t\t    is_global_init(p->real_parent))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (task_pgrp(p->real_parent) != pgrp &&",
            "\t\t    task_session(p->real_parent) == task_session(p))",
            "\t\t\treturn 0;",
            "\t} while_each_pid_task(pgrp, PIDTYPE_PGID, p);",
            "",
            "\treturn 1;",
            "}"
          ],
          "function_name": "put_task_struct_rcu_user, release_thread, release_task, rcuwait_wake_up, will_become_orphaned_pgrp",
          "description": "提供RCU安全的任务结构释放机制，处理线程组解关联、会话管理及条件唤醒操作。",
          "similarity": 0.5541495680809021
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/exit.c",
          "start_line": 1,
          "end_line": 101,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " *  linux/kernel/exit.c",
            " *",
            " *  Copyright (C) 1991, 1992  Linus Torvalds",
            " */",
            "",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/module.h>",
            "#include <linux/capability.h>",
            "#include <linux/completion.h>",
            "#include <linux/personality.h>",
            "#include <linux/tty.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/key.h>",
            "#include <linux/cpu.h>",
            "#include <linux/acct.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/freezer.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/profile.h>",
            "#include <linux/mount.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/kthread.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/signal.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/mutex.h>",
            "#include <linux/futex.h>",
            "#include <linux/pipe_fs_i.h>",
            "#include <linux/audit.h> /* for audit_free() */",
            "#include <linux/resource.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/task_work.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/init_task.h>",
            "#include <linux/perf_event.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/oom.h>",
            "#include <linux/writeback.h>",
            "#include <linux/shm.h>",
            "#include <linux/kcov.h>",
            "#include <linux/kmsan.h>",
            "#include <linux/random.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/compat.h>",
            "#include <linux/io_uring.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rethook.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/user_events.h>",
            "#include <linux/uaccess.h>",
            "",
            "#include <uapi/linux/wait.h>",
            "",
            "#include <asm/unistd.h>",
            "#include <asm/mmu_context.h>",
            "#ifdef CONFIG_IEE",
            "#include <asm/iee-token.h>",
            "#endif",
            "",
            "#include \"exit.h\"",
            "",
            "/*",
            " * The default value should be high enough to not crash a system that randomly",
            " * crashes its kernel from time to time, but low enough to at least not permit",
            " * overflowing 32-bit refcounts or the ldsem writer count.",
            " */",
            "static unsigned int oops_limit = 10000;",
            "",
            "#ifdef CONFIG_SYSCTL",
            "static struct ctl_table kern_exit_table[] = {",
            "\t{",
            "\t\t.procname       = \"oops_limit\",",
            "\t\t.data           = &oops_limit,",
            "\t\t.maxlen         = sizeof(oops_limit),",
            "\t\t.mode           = 0644,",
            "\t\t.proc_handler   = proc_douintvec,",
            "\t},",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义oops_limit变量及sysctl表项，用于控制内核崩溃次数限制并通过proc文件系统暴露配置接口。",
          "similarity": 0.504833459854126
        }
      ]
    },
    {
      "source_file": "kernel/task_work.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:33:42\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `task_work.c`\n\n---\n\n# task_work.c 技术文档\n\n## 文件概述\n\n`task_work.c` 实现了 Linux 内核中的 **任务工作（task work）机制**，允许内核在特定时机（如任务返回用户态、收到信号或处于 NMI 上下文）异步执行回调函数。该机制主要用于在不阻塞当前执行路径的前提下，将工作延迟到目标任务的合适上下文中执行，常用于安全模块（如 seccomp）、用户态通知、延迟清理等场景。\n\n任务工作队列是 **LIFO（后进先出）** 的，且不保证多个工作项之间的执行顺序。该机制支持多种通知模式，以适应不同的延迟和中断需求。\n\n## 核心功能\n\n### 主要函数\n\n| 函数 | 功能描述 |\n|------|--------|\n| `task_work_add()` | 向指定任务添加一个回调工作项，并根据通知模式触发相应通知 |\n| `task_work_run()` | 执行当前任务的所有挂起工作项，通常在返回用户态或任务退出前调用 |\n| `task_work_cancel_match()` | 根据自定义匹配函数取消队列中的某个工作项 |\n| `task_work_cancel_func()` | 取消队列中第一个函数指针匹配指定函数的工作项 |\n| `task_work_cancel()` | 取消队列中指定的回调结构体（精确匹配指针） |\n\n### 主要数据结构\n\n- `struct callback_head`：通用回调结构体，包含 `next` 指针和 `func` 回调函数指针。\n- `enum task_work_notify_mode`：通知模式枚举，包括：\n  - `TWA_NONE`：不通知\n  - `TWA_RESUME`：在任务返回用户态或进入 guest 模式前执行\n  - `TWA_SIGNAL`：类似信号，可中断内核态任务并立即调度执行\n  - `TWA_SIGNAL_NO_IPI`：类似 `TWA_SIGNAL`，但不发送 IPI 强制重调度\n  - `TWA_NMI_CURRENT`：仅用于当前任务且在 NMI 上下文中，通过 IRQ work 触发\n\n### 全局变量\n\n- `work_exited`：特殊标记，表示任务已退出，不能再接受新工作。\n- `irq_work_NMI_resume`（per-CPU）：用于 `TWA_NMI_CURRENT` 模式下触发 `TIF_NOTIFY_RESUME` 标志。\n\n## 关键实现\n\n### 1. 无锁队列插入（LIFO）\n\n`task_work_add()` 使用 `try_cmpxchg()` 原子操作将新工作项插入到 `task->task_works` 链表头部，实现无锁并发插入。若发现 `task_works == &work_exited`，说明任务正在退出，返回 `-ESRCH`。\n\n### 2. 多种通知机制\n\n- **`TWA_RESUME`**：调用 `set_notify_resume(task)`，设置 `TIF_NOTIFY_RESUME` 标志，确保任务在 `exit_to_user_mode()` 路径中调用 `task_work_run()`。\n- **`TWA_SIGNAL` / `TWA_SIGNAL_NO_IPI`**：分别调用 `set_notify_signal()` 和 `__set_notify_signal()`，设置 `TIF_NOTIFY_SIGNAL` 标志，并可能发送 IPI 强制目标 CPU 重调度。\n- **`TWA_NMI_CURRENT`**：在 NMI 上下文中，通过 per-CPU 的 `irq_work` 触发软中断，在 IRQ 上下文中设置 `TIF_NOTIFY_RESUME`。\n\n### 3. 安全退出处理\n\n`task_work_run()` 在循环中：\n- 原子地将 `task_works` 置为 `NULL`（或 `&work_exited`，若任务正在退出）。\n- 若任务正在退出（`PF_EXITING`），则标记为 `work_exited`，防止后续 `task_work_add()` 成功。\n- 执行所有取出的工作项，每个 `work->func(work)` 可能再次调用 `task_work_add()`，因此需循环处理。\n\n### 4. 并发取消机制\n\n`task_work_cancel_match()` 使用 `task->pi_lock` 保护遍历和删除操作：\n- 遍历链表查找匹配项。\n- 使用 `try_cmpxchg()` 原子地移除节点，避免与 `task_work_add()` 或 `task_work_run()` 冲突。\n- 特别地，`task_work_run()` 在执行前会短暂获取 `pi_lock`，确保取消操作不会在执行过程中移除正在运行的工作项。\n\n### 5. KASAN 辅助栈记录\n\n在 `task_work_add()` 中，根据 `TWAF_NO_ALLOC` 标志调用 `kasan_record_aux_stack()` 或 `kasan_record_aux_stack_noalloc()`，用于在 KASAN 报告中显示工作项的分配调用栈。\n\n## 依赖关系\n\n- **`<linux/irq_work.h>`**：提供 `irq_work` 机制，用于 `TWA_NMI_CURRENT` 模式。\n- **`<linux/resume_user_mode.h>`**：提供 `set_notify_resume()` 等接口，用于在返回用户态时触发回调。\n- **`<linux/spinlock.h>`**：使用 `raw_spinlock_t`（`pi_lock`）保护取消操作。\n- **`<linux/task_work.h>`**：定义 `task_work_notify_mode`、`callback_head` 等核心类型。\n- **调度子系统**：依赖 `TIF_NOTIFY_RESUME` / `TIF_NOTIFY_SIGNAL` 标志位，在调度路径中调用 `task_work_run()`。\n- **KASAN**：集成内存错误检测的调用栈记录功能。\n\n## 使用场景\n\n1. **Seccomp 通知**：当 seccomp 策略需要异步通知用户态代理时，通过 `task_work_add()` 添加回调。\n2. **用户态延迟操作**：内核模块需要在任务下次返回用户态时执行清理或通知，使用 `TWA_RESUME`。\n3. **NMI 上下文延迟处理**：在不可睡眠的 NMI 处理程序中，通过 `TWA_NMI_CURRENT` 安全地安排后续工作。\n4. **信号式中断执行**：需要立即中断目标任务（即使在内核态）以执行高优先级工作，使用 `TWA_SIGNAL`。\n5. **资源回收**：在任务退出路径中，确保所有挂起工作被执行或清理。\n6. **动态取消机制**：如 seccomp 可能需要在条件变化时取消之前安排的工作，使用 `task_work_cancel_func()`。",
      "similarity": 0.5993464589118958,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/task_work.c",
          "start_line": 1,
          "end_line": 9,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/task_work.h>",
            "#include <linux/resume_user_mode.h>",
            "",
            "static struct callback_head work_exited; /* all we need is ->next == NULL */",
            "",
            "#ifdef CONFIG_IRQ_WORK"
          ],
          "function_name": null,
          "description": "声明用于任务工作通知的静态变量work_exited，该变量通过next指针判断任务工作链表是否为空，上下文不完整",
          "similarity": 0.611426591873169
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/task_work.c",
          "start_line": 10,
          "end_line": 125,
          "content": [
            "static void task_work_set_notify_irq(struct irq_work *entry)",
            "{",
            "\ttest_and_set_tsk_thread_flag(current, TIF_NOTIFY_RESUME);",
            "}",
            "int task_work_add(struct task_struct *task, struct callback_head *work,",
            "\t\t  enum task_work_notify_mode notify)",
            "{",
            "\tstruct callback_head *head;",
            "\tint flags = notify & TWA_FLAGS;",
            "",
            "\tnotify &= ~TWA_FLAGS;",
            "\tif (notify == TWA_NMI_CURRENT) {",
            "\t\tif (WARN_ON_ONCE(task != current))",
            "\t\t\treturn -EINVAL;",
            "\t\tif (!IS_ENABLED(CONFIG_IRQ_WORK))",
            "\t\t\treturn -EINVAL;",
            "\t} else {",
            "\t\t/*",
            "\t\t * Record the work call stack in order to print it in KASAN",
            "\t\t * reports.",
            "\t\t *",
            "\t\t * Note that stack allocation can fail if TWAF_NO_ALLOC flag",
            "\t\t * is set and new page is needed to expand the stack buffer.",
            "\t\t */",
            "\t\tif (flags & TWAF_NO_ALLOC)",
            "\t\t\tkasan_record_aux_stack_noalloc(work);",
            "\t\telse",
            "\t\t\tkasan_record_aux_stack(work);",
            "\t}",
            "",
            "\thead = READ_ONCE(task->task_works);",
            "\tdo {",
            "\t\tif (unlikely(head == &work_exited))",
            "\t\t\treturn -ESRCH;",
            "\t\twork->next = head;",
            "\t} while (!try_cmpxchg(&task->task_works, &head, work));",
            "",
            "\tswitch (notify) {",
            "\tcase TWA_NONE:",
            "\t\tbreak;",
            "\tcase TWA_RESUME:",
            "\t\tset_notify_resume(task);",
            "\t\tbreak;",
            "\tcase TWA_SIGNAL:",
            "\t\tset_notify_signal(task);",
            "\t\tbreak;",
            "\tcase TWA_SIGNAL_NO_IPI:",
            "\t\t__set_notify_signal(task);",
            "\t\tbreak;",
            "#ifdef CONFIG_IRQ_WORK",
            "\tcase TWA_NMI_CURRENT:",
            "\t\tirq_work_queue(this_cpu_ptr(&irq_work_NMI_resume));",
            "\t\tbreak;",
            "#endif",
            "\tdefault:",
            "\t\tWARN_ON_ONCE(1);",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static bool task_work_func_match(struct callback_head *cb, void *data)",
            "{",
            "\treturn cb->func == data;",
            "}",
            "static bool task_work_match(struct callback_head *cb, void *data)",
            "{",
            "\treturn cb == data;",
            "}",
            "bool task_work_cancel(struct task_struct *task, struct callback_head *cb)",
            "{",
            "\tstruct callback_head *ret;",
            "",
            "\tret = task_work_cancel_match(task, task_work_match, cb);",
            "",
            "\treturn ret == cb;",
            "}",
            "void task_work_run(void)",
            "{",
            "\tstruct task_struct *task = current;",
            "\tstruct callback_head *work, *head, *next;",
            "",
            "\tfor (;;) {",
            "\t\t/*",
            "\t\t * work->func() can do task_work_add(), do not set",
            "\t\t * work_exited unless the list is empty.",
            "\t\t */",
            "\t\twork = READ_ONCE(task->task_works);",
            "\t\tdo {",
            "\t\t\thead = NULL;",
            "\t\t\tif (!work) {",
            "\t\t\t\tif (task->flags & PF_EXITING)",
            "\t\t\t\t\thead = &work_exited;",
            "\t\t\t\telse",
            "\t\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t} while (!try_cmpxchg(&task->task_works, &work, head));",
            "",
            "\t\tif (!work)",
            "\t\t\tbreak;",
            "\t\t/*",
            "\t\t * Synchronize with task_work_cancel_match(). It can not remove",
            "\t\t * the first entry == work, cmpxchg(task_works) must fail.",
            "\t\t * But it can remove another entry from the ->next list.",
            "\t\t */",
            "\t\traw_spin_lock_irq(&task->pi_lock);",
            "\t\traw_spin_unlock_irq(&task->pi_lock);",
            "",
            "\t\tdo {",
            "\t\t\tnext = work->next;",
            "\t\t\twork->func(work);",
            "\t\t\twork = next;",
            "\t\t\tcond_resched();",
            "\t\t} while (work);",
            "\t}",
            "}"
          ],
          "function_name": "task_work_set_notify_irq, task_work_add, task_work_func_match, task_work_match, task_work_cancel, task_work_run",
          "description": "实现任务工作队列的添加、匹配、取消及执行逻辑，支持多种通知模式（如RESUME/SIGNAL/NMI），通过原子操作维护链表并同步执行回调函数",
          "similarity": 0.5327283143997192
        }
      ]
    },
    {
      "source_file": "kernel/sched/ext.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:08:15\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\ext.c`\n\n---\n\n# `sched/ext.c` 技术文档\n\n## 文件概述\n\n`sched/ext.c` 是 Linux 内核中 **BPF 可扩展调度器（sched_ext）** 的核心实现文件之一，定义了调度器与 BPF 程序交互所需的数据结构、常量和操作接口。该文件为用户空间通过 BPF 实现自定义调度策略提供了内核侧的框架支持，允许将任务调度逻辑完全委托给加载的 BPF 程序，同时保留与内核调度子系统的安全集成。\n\n## 核心功能\n\n### 主要数据结构\n\n- **`struct sched_ext_ops`**  \n  BPF 调度器的操作函数表，包含调度器必须或可选实现的回调函数，如 `select_cpu`、`enqueue`、`dequeue`、`dispatch` 等，用于控制任务的 CPU 选择、入队、出队和分发逻辑。\n\n- **`struct scx_exit_info`**  \n  描述 BPF 调度器退出原因的结构体，包含退出类型（`kind`）、退出码（`exit_code`）、错误信息（`reason`、`msg`）、回溯栈（`bt`）和调试转储（`dump`）。\n\n- **`struct scx_init_task_args` / `scx_exit_task_args`**  \n  分别用于 `ops.init_task()` 和 `ops.exit_task()` 回调的参数容器，传递任务初始化/退出上下文（如是否由 fork 触发、所属 cgroup 等）。\n\n- **`struct scx_cpu_acquire_args` / `scx_cpu_release_args`**  \n  用于 CPU 获取/释放回调的参数结构，其中 `cpu_release` 包含抢占原因（如 RT/DL 任务抢占）和即将运行的任务。\n\n- **`struct scx_dump_ctx`**  \n  为调度器转储（dump）操作提供上下文信息，包括退出类型、时间戳等。\n\n### 关键枚举与常量\n\n- **`enum scx_exit_kind`**  \n  定义调度器退出的类别，如正常退出（`SCX_EXIT_DONE`）、用户/BPF/内核主动注销（`SCX_EXIT_UNREG*`）、系统请求（`SCX_EXIT_SYSRQ`）或运行时错误（`SCX_EXIT_ERROR*`）。\n\n- **`enum scx_exit_code`**  \n  定义 64 位退出码的位域格式，支持系统原因（如 `SCX_ECODE_RSN_HOTPLUG`）和系统动作（如 `SCX_ECODE_ACT_RESTART`），允许用户自定义退出上下文。\n\n- **`enum scx_ops_flags`**  \n  调度器操作标志，控制调度行为：\n  - `SCX_OPS_KEEP_BUILTIN_IDLE`：保留内建空闲跟踪\n  - `SCX_OPS_ENQ_LAST`：切片到期后仍无任务时重新入队\n  - `SCX_OPS_ENQ_EXITING`：由 BPF 处理退出中任务\n  - `SCX_OPS_SWITCH_PARTIAL`：仅调度 `SCHED_EXT` 策略任务\n  - `SCX_OPS_HAS_CGROUP_WEIGHT`：支持 cgroup cpu.weight\n\n- **调度器常量**  \n  如 `SCX_DSP_DFL_MAX_BATCH`（默认分发批大小）、`SCX_WATCHDOG_MAX_TIMEOUT`（看门狗超时）、`SCX_OPS_TASK_ITER_BATCH`（任务迭代锁释放批次）等，用于控制调度器内部行为。\n\n## 关键实现\n\n- **BPF 调度器生命周期管理**  \n  通过 `scx_exit_info` 和退出码机制，支持多种退出路径（用户、BPF、内核、SysRq、错误），并提供详细的诊断信息（回溯、消息、转储）。\n\n- **任务入队优化**  \n  在 `select_cpu` 中允许直接插入 DSQ（如本地 DSQ），跳过后续 `enqueue` 调用，减少调度开销；同时通过 `SCX_OPS_ENQ_EXITING` 标志处理退出中任务的调度问题，避免 RCU 停顿。\n\n- **CPU 抢占通知**  \n  通过 `scx_cpu_release_args` 向 BPF 调度器传递 CPU 被高优先级调度类（RT/DL/Stop）抢占的原因，便于调度器做出相应调整。\n\n- **cgroup 集成**  \n  支持 cgroup 调度（`CONFIG_EXT_GROUP_SCHED`），在任务加入 cgroup 时传递权重信息（`scx_cgroup_init_args`），并通过 `SCX_OPS_HAS_CGROUP_WEIGHT` 标志启用。\n\n- **安全与鲁棒性**  \n  内核侧跟踪 BPF 是否拥有任务，可忽略无效分发；任务迭代时定期释放锁（`SCX_OPS_TASK_ITER_BATCH`），防止 RCU/CSD 停顿；看门狗机制（`SCX_WATCHDOG_MAX_TIMEOUT`）检测任务卡死。\n\n## 依赖关系\n\n- **BPF 子系统**：通过 `#include <linux/bpf.h>` 依赖 BPF 基础设施，用于加载和验证调度器 BPF 程序。\n- **调度核心**：与 `kernel/sched/` 下的核心调度代码（如 `core.c`、`rt.c`、`dl.c`）交互，处理任务入队、CPU 选择和抢占。\n- **cgroup 子系统**：当启用 `CONFIG_EXT_GROUP_SCHED` 时，依赖 cgroup CPU 控制器获取任务权重和层级信息。\n- **RCU 与锁机制**：使用 `scx_tasks_lock` 保护任务迭代，需与 RCU 同步机制协调。\n\n## 使用场景\n\n- **自定义调度策略开发**：用户通过 BPF 实现特定工作负载的调度逻辑（如延迟敏感型、批处理优化、NUMA 感知等），并注册到 `sched_ext`。\n- **系统调试与监控**：利用 `ops.dump()` 和退出信息结构体，在调度器异常退出时收集诊断数据。\n- **混合调度部署**：通过 `SCX_OPS_SWITCH_PARTIAL` 标志，仅对部分任务（`SCHED_EXT`）启用 BPF 调度，其余任务仍由 CFS 处理。\n- **资源隔离与 QoS**：结合 cgroup 支持，为不同 cgroup 配置不同的调度行为和资源权重。\n- **内核调度实验平台**：作为安全的沙箱环境，测试新型调度算法而无需修改核心调度代码。",
      "similarity": 0.5933036804199219,
      "chunks": [
        {
          "chunk_id": 22,
          "file_path": "kernel/sched/ext.c",
          "start_line": 4366,
          "end_line": 4528,
          "content": [
            "static void free_exit_info(struct scx_exit_info *ei)",
            "{",
            "\tkfree(ei->dump);",
            "\tkfree(ei->msg);",
            "\tkfree(ei->bt);",
            "\tkfree(ei);",
            "}",
            "static void scx_ops_disable_workfn(struct kthread_work *work)",
            "{",
            "\tstruct scx_exit_info *ei = scx_exit_info;",
            "\tstruct scx_task_iter sti;",
            "\tstruct task_struct *p;",
            "\tstruct rhashtable_iter rht_iter;",
            "\tstruct scx_dispatch_q *dsq;",
            "\tint i, kind;",
            "",
            "\tkind = atomic_read(&scx_exit_kind);",
            "\twhile (true) {",
            "\t\t/*",
            "\t\t * NONE indicates that a new scx_ops has been registered since",
            "\t\t * disable was scheduled - don't kill the new ops. DONE",
            "\t\t * indicates that the ops has already been disabled.",
            "\t\t */",
            "\t\tif (kind == SCX_EXIT_NONE || kind == SCX_EXIT_DONE)",
            "\t\t\treturn;",
            "\t\tif (atomic_try_cmpxchg(&scx_exit_kind, &kind, SCX_EXIT_DONE))",
            "\t\t\tbreak;",
            "\t}",
            "\tei->kind = kind;",
            "\tei->reason = scx_exit_reason(ei->kind);",
            "",
            "\t/* guarantee forward progress by bypassing scx_ops */",
            "\tscx_ops_bypass(true);",
            "",
            "\tswitch (scx_ops_set_enable_state(SCX_OPS_DISABLING)) {",
            "\tcase SCX_OPS_DISABLING:",
            "\t\tWARN_ONCE(true, \"sched_ext: duplicate disabling instance?\");",
            "\t\tbreak;",
            "\tcase SCX_OPS_DISABLED:",
            "\t\tpr_warn(\"sched_ext: ops error detected without ops (%s)\\n\",",
            "\t\t\tscx_exit_info->msg);",
            "\t\tWARN_ON_ONCE(scx_ops_set_enable_state(SCX_OPS_DISABLED) !=",
            "\t\t\t     SCX_OPS_DISABLING);",
            "\t\tgoto done;",
            "\tdefault:",
            "\t\tbreak;",
            "\t}",
            "",
            "\t/*",
            "\t * Here, every runnable task is guaranteed to make forward progress and",
            "\t * we can safely use blocking synchronization constructs. Actually",
            "\t * disable ops.",
            "\t */",
            "\tmutex_lock(&scx_ops_enable_mutex);",
            "",
            "\tstatic_branch_disable(&__scx_switched_all);",
            "\tWRITE_ONCE(scx_switching_all, false);",
            "",
            "\t/*",
            "\t * Shut down cgroup support before tasks so that the cgroup attach path",
            "\t * doesn't race against scx_ops_exit_task().",
            "\t */",
            "\tscx_cgroup_lock();",
            "\tscx_cgroup_exit();",
            "\tscx_cgroup_unlock();",
            "",
            "\t/*",
            "\t * The BPF scheduler is going away. All tasks including %TASK_DEAD ones",
            "\t * must be switched out and exited synchronously.",
            "\t */",
            "\tpercpu_down_write(&scx_fork_rwsem);",
            "",
            "\tscx_ops_init_task_enabled = false;",
            "",
            "\tscx_task_iter_start(&sti);",
            "\twhile ((p = scx_task_iter_next_locked(&sti))) {",
            "\t\tconst struct sched_class *old_class = p->sched_class;",
            "\t\tconst struct sched_class *new_class =",
            "\t\t\t__setscheduler_class(p->policy, p->prio);",
            "\t\tstruct sched_enq_and_set_ctx ctx;",
            "",
            "\t\tif (old_class != new_class && p->se.sched_delayed)",
            "\t\t\tdequeue_task(task_rq(p), p, DEQUEUE_SLEEP | DEQUEUE_DELAYED);",
            "",
            "\t\tsched_deq_and_put_task(p, DEQUEUE_SAVE | DEQUEUE_MOVE, &ctx);",
            "",
            "\t\tp->sched_class = new_class;",
            "\t\tcheck_class_changing(task_rq(p), p, old_class);",
            "",
            "\t\tsched_enq_and_set_task(&ctx);",
            "",
            "\t\tcheck_class_changed(task_rq(p), p, old_class, p->prio);",
            "\t\tscx_ops_exit_task(p);",
            "\t}",
            "\tscx_task_iter_stop(&sti);",
            "\tpercpu_up_write(&scx_fork_rwsem);",
            "",
            "\t/* no task is on scx, turn off all the switches and flush in-progress calls */",
            "\tstatic_branch_disable(&__scx_ops_enabled);",
            "\tfor (i = SCX_OPI_BEGIN; i < SCX_OPI_END; i++)",
            "\t\tstatic_branch_disable(&scx_has_op[i]);",
            "\tstatic_branch_disable(&scx_ops_enq_last);",
            "\tstatic_branch_disable(&scx_ops_enq_exiting);",
            "\tstatic_branch_disable(&scx_ops_cpu_preempt);",
            "\tstatic_branch_disable(&scx_builtin_idle_enabled);",
            "\tsynchronize_rcu();",
            "",
            "\tif (ei->kind >= SCX_EXIT_ERROR) {",
            "\t\tpr_err(\"sched_ext: BPF scheduler \\\"%s\\\" disabled (%s)\\n\",",
            "\t\t       scx_ops.name, ei->reason);",
            "",
            "\t\tif (ei->msg[0] != '\\0')",
            "\t\t\tpr_err(\"sched_ext: %s: %s\\n\", scx_ops.name, ei->msg);",
            "#ifdef CONFIG_STACKTRACE",
            "\t\tstack_trace_print(ei->bt, ei->bt_len, 2);",
            "#endif",
            "\t} else {",
            "\t\tpr_info(\"sched_ext: BPF scheduler \\\"%s\\\" disabled (%s)\\n\",",
            "\t\t\tscx_ops.name, ei->reason);",
            "\t}",
            "",
            "\tif (scx_ops.exit)",
            "\t\tSCX_CALL_OP(SCX_KF_UNLOCKED, exit, ei);",
            "",
            "\tcancel_delayed_work_sync(&scx_watchdog_work);",
            "",
            "\t/*",
            "\t * Delete the kobject from the hierarchy eagerly in addition to just",
            "\t * dropping a reference. Otherwise, if the object is deleted",
            "\t * asynchronously, sysfs could observe an object of the same name still",
            "\t * in the hierarchy when another scheduler is loaded.",
            "\t */",
            "\tkobject_del(scx_root_kobj);",
            "\tkobject_put(scx_root_kobj);",
            "\tscx_root_kobj = NULL;",
            "",
            "\tmemset(&scx_ops, 0, sizeof(scx_ops));",
            "",
            "\trhashtable_walk_enter(&dsq_hash, &rht_iter);",
            "\tdo {",
            "\t\trhashtable_walk_start(&rht_iter);",
            "",
            "\t\twhile ((dsq = rhashtable_walk_next(&rht_iter)) && !IS_ERR(dsq))",
            "\t\t\tdestroy_dsq(dsq->id);",
            "",
            "\t\trhashtable_walk_stop(&rht_iter);",
            "\t} while (dsq == ERR_PTR(-EAGAIN));",
            "\trhashtable_walk_exit(&rht_iter);",
            "",
            "\tfree_percpu(scx_dsp_ctx);",
            "\tscx_dsp_ctx = NULL;",
            "\tscx_dsp_max_batch = 0;",
            "",
            "\tfree_exit_info(scx_exit_info);",
            "\tscx_exit_info = NULL;",
            "",
            "\tmutex_unlock(&scx_ops_enable_mutex);",
            "",
            "\tWARN_ON_ONCE(scx_ops_set_enable_state(SCX_OPS_DISABLED) !=",
            "\t\t     SCX_OPS_DISABLING);",
            "done:",
            "\tscx_ops_bypass(false);",
            "}"
          ],
          "function_name": "free_exit_info, scx_ops_disable_workfn",
          "description": "该代码段包含两个函数：  \n1. `free_exit_info` 用于释放 `scx_exit_info` 结构体关联的动态内存（`dump`/`msg`/`bt`）及自身；  \n2. `scx_ops_disable_workfn` 核心功能为安全禁用 SCX 操作，通过原子操作标记状态、强制切换所有任务至新调度类、清理 DSQ 和 kobject 等资源，并最终释放 `scx_exit_info`。  \n\n`scx_ops_disable_workfn` 实现了 SCX 操作的有序停用逻辑，确保任务迁移、状态同步及资源回收的完整性，同时处理异常情况下的错误日志输出。",
          "similarity": 0.6167585849761963
        },
        {
          "chunk_id": 33,
          "file_path": "kernel/sched/ext.c",
          "start_line": 6413,
          "end_line": 6524,
          "content": [
            "__bpf_kfunc bool scx_bpf_dispatch_vtime_from_dsq(struct bpf_iter_scx_dsq *it__iter,",
            "\t\t\t\t\t\t struct task_struct *p, u64 dsq_id,",
            "\t\t\t\t\t\t u64 enq_flags)",
            "{",
            "\tprintk_deferred_once(KERN_WARNING \"sched_ext: scx_bpf_dispatch_from_dsq_vtime() renamed to scx_bpf_dsq_move_vtime()\");",
            "\treturn scx_bpf_dsq_move_vtime(it__iter, p, dsq_id, enq_flags);",
            "}",
            "__bpf_kfunc u32 scx_bpf_reenqueue_local(void)",
            "{",
            "\tLIST_HEAD(tasks);",
            "\tu32 nr_enqueued = 0;",
            "\tstruct rq *rq;",
            "\tstruct task_struct *p, *n;",
            "",
            "\tif (!scx_kf_allowed(SCX_KF_CPU_RELEASE))",
            "\t\treturn 0;",
            "",
            "\trq = cpu_rq(smp_processor_id());",
            "\tlockdep_assert_rq_held(rq);",
            "",
            "\t/*",
            "\t * The BPF scheduler may choose to dispatch tasks back to",
            "\t * @rq->scx.local_dsq. Move all candidate tasks off to a private list",
            "\t * first to avoid processing the same tasks repeatedly.",
            "\t */",
            "\tlist_for_each_entry_safe(p, n, &rq->scx.local_dsq.list,",
            "\t\t\t\t scx.dsq_list.node) {",
            "\t\t/*",
            "\t\t * If @p is being migrated, @p's current CPU may not agree with",
            "\t\t * its allowed CPUs and the migration_cpu_stop is about to",
            "\t\t * deactivate and re-activate @p anyway. Skip re-enqueueing.",
            "\t\t *",
            "\t\t * While racing sched property changes may also dequeue and",
            "\t\t * re-enqueue a migrating task while its current CPU and allowed",
            "\t\t * CPUs disagree, they use %ENQUEUE_RESTORE which is bypassed to",
            "\t\t * the current local DSQ for running tasks and thus are not",
            "\t\t * visible to the BPF scheduler.",
            "\t\t */",
            "\t\tif (p->migration_pending)",
            "\t\t\tcontinue;",
            "",
            "\t\tdispatch_dequeue(rq, p);",
            "\t\tlist_add_tail(&p->scx.dsq_list.node, &tasks);",
            "\t}",
            "",
            "\tlist_for_each_entry_safe(p, n, &tasks, scx.dsq_list.node) {",
            "\t\tlist_del_init(&p->scx.dsq_list.node);",
            "\t\tdo_enqueue_task(rq, p, SCX_ENQ_REENQ, -1);",
            "\t\tnr_enqueued++;",
            "\t}",
            "",
            "\treturn nr_enqueued;",
            "}",
            "__bpf_kfunc s32 scx_bpf_create_dsq(u64 dsq_id, s32 node)",
            "{",
            "\tif (unlikely(node >= (int)nr_node_ids ||",
            "\t\t     (node < 0 && node != NUMA_NO_NODE)))",
            "\t\treturn -EINVAL;",
            "\treturn PTR_ERR_OR_ZERO(create_dsq(dsq_id, node));",
            "}",
            "__bpf_kfunc void scx_bpf_kick_cpu(s32 cpu, u64 flags)",
            "{",
            "\tstruct rq *this_rq;",
            "\tunsigned long irq_flags;",
            "",
            "\tif (!ops_cpu_valid(cpu, NULL))",
            "\t\treturn;",
            "",
            "\tlocal_irq_save(irq_flags);",
            "",
            "\tthis_rq = this_rq();",
            "",
            "\t/*",
            "\t * While bypassing for PM ops, IRQ handling may not be online which can",
            "\t * lead to irq_work_queue() malfunction such as infinite busy wait for",
            "\t * IRQ status update. Suppress kicking.",
            "\t */",
            "\tif (scx_rq_bypassing(this_rq))",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * Actual kicking is bounced to kick_cpus_irq_workfn() to avoid nesting",
            "\t * rq locks. We can probably be smarter and avoid bouncing if called",
            "\t * from ops which don't hold a rq lock.",
            "\t */",
            "\tif (flags & SCX_KICK_IDLE) {",
            "\t\tstruct rq *target_rq = cpu_rq(cpu);",
            "",
            "\t\tif (unlikely(flags & (SCX_KICK_PREEMPT | SCX_KICK_WAIT)))",
            "\t\t\tscx_ops_error(\"PREEMPT/WAIT cannot be used with SCX_KICK_IDLE\");",
            "",
            "\t\tif (raw_spin_rq_trylock(target_rq)) {",
            "\t\t\tif (can_skip_idle_kick(target_rq)) {",
            "\t\t\t\traw_spin_rq_unlock(target_rq);",
            "\t\t\t\tgoto out;",
            "\t\t\t}",
            "\t\t\traw_spin_rq_unlock(target_rq);",
            "\t\t}",
            "\t\tcpumask_set_cpu(cpu, this_rq->scx.cpus_to_kick_if_idle);",
            "\t} else {",
            "\t\tcpumask_set_cpu(cpu, this_rq->scx.cpus_to_kick);",
            "",
            "\t\tif (flags & SCX_KICK_PREEMPT)",
            "\t\t\tcpumask_set_cpu(cpu, this_rq->scx.cpus_to_preempt);",
            "\t\tif (flags & SCX_KICK_WAIT)",
            "\t\t\tcpumask_set_cpu(cpu, this_rq->scx.cpus_to_wait);",
            "\t}",
            "",
            "\tirq_work_queue(&this_rq->scx.kick_cpus_irq_work);",
            "out:",
            "\tlocal_irq_restore(irq_flags);",
            "}"
          ],
          "function_name": "scx_bpf_dispatch_vtime_from_dsq, scx_bpf_reenqueue_local, scx_bpf_create_dsq, scx_bpf_kick_cpu",
          "description": "该代码段为Linux内核调度器扩展模块中与BPF调度队列（DSQ）相关的辅助函数集合，主要实现任务迁移、本地重入队、DSQ创建及CPU唤醒控制功能。  \n`scx_bpf_dispatch_vtime_from_dsq` 是 `scx_bpf_dsq_move_vtime` 的别名，用于将任务从DSQ迁移到其他队列；`scx_bpf_reenqueue_local` 将本地DSQ中非迁移任务重新入队并统计数量；`scx_bpf_create_dsq` 创建指定节点的DSQ并校验参数合法性；`scx_bpf_kick_cpu` 根据标志位异步触发目标CPU的唤醒操作。  \n代码缺少DSQ结构体定义及`create_dsq`等底层实现细节，需结合上下文进一步确认完整逻辑。",
          "similarity": 0.5558708906173706
        },
        {
          "chunk_id": 35,
          "file_path": "kernel/sched/ext.c",
          "start_line": 6810,
          "end_line": 6910,
          "content": [
            "static s32 bstr_format(struct scx_bstr_buf *buf,",
            "\t\t       char *fmt, unsigned long long *data, u32 data__sz)",
            "{",
            "\treturn __bstr_format(buf->data, buf->line, sizeof(buf->line),",
            "\t\t\t     fmt, data, data__sz);",
            "}",
            "__bpf_kfunc void scx_bpf_exit_bstr(s64 exit_code, char *fmt,",
            "\t\t\t\t   unsigned long long *data, u32 data__sz)",
            "{",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&scx_exit_bstr_buf_lock, flags);",
            "\tif (bstr_format(&scx_exit_bstr_buf, fmt, data, data__sz) >= 0)",
            "\t\tscx_ops_exit_kind(SCX_EXIT_UNREG_BPF, exit_code, \"%s\",",
            "\t\t\t\t  scx_exit_bstr_buf.line);",
            "\traw_spin_unlock_irqrestore(&scx_exit_bstr_buf_lock, flags);",
            "}",
            "__bpf_kfunc void scx_bpf_error_bstr(char *fmt, unsigned long long *data,",
            "\t\t\t\t    u32 data__sz)",
            "{",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&scx_exit_bstr_buf_lock, flags);",
            "\tif (bstr_format(&scx_exit_bstr_buf, fmt, data, data__sz) >= 0)",
            "\t\tscx_ops_exit_kind(SCX_EXIT_ERROR_BPF, 0, \"%s\",",
            "\t\t\t\t  scx_exit_bstr_buf.line);",
            "\traw_spin_unlock_irqrestore(&scx_exit_bstr_buf_lock, flags);",
            "}",
            "__bpf_kfunc void scx_bpf_dump_bstr(char *fmt, unsigned long long *data,",
            "\t\t\t\t   u32 data__sz)",
            "{",
            "\tstruct scx_dump_data *dd = &scx_dump_data;",
            "\tstruct scx_bstr_buf *buf = &dd->buf;",
            "\ts32 ret;",
            "",
            "\tif (raw_smp_processor_id() != dd->cpu) {",
            "\t\tscx_ops_error(\"scx_bpf_dump() must only be called from ops.dump() and friends\");",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* append the formatted string to the line buf */",
            "\tret = __bstr_format(buf->data, buf->line + dd->cursor,",
            "\t\t\t    sizeof(buf->line) - dd->cursor, fmt, data, data__sz);",
            "\tif (ret < 0) {",
            "\t\tdump_line(dd->s, \"%s[!] (\\\"%s\\\", %p, %u) failed to format (%d)\",",
            "\t\t\t  dd->prefix, fmt, data, data__sz, ret);",
            "\t\treturn;",
            "\t}",
            "",
            "\tdd->cursor += ret;",
            "\tdd->cursor = min_t(s32, dd->cursor, sizeof(buf->line));",
            "",
            "\tif (!dd->cursor)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If the line buf overflowed or ends in a newline, flush it into the",
            "\t * dump. This is to allow the caller to generate a single line over",
            "\t * multiple calls. As ops_dump_flush() can also handle multiple lines in",
            "\t * the line buf, the only case which can lead to an unexpected",
            "\t * truncation is when the caller keeps generating newlines in the middle",
            "\t * instead of the end consecutively. Don't do that.",
            "\t */",
            "\tif (dd->cursor >= sizeof(buf->line) || buf->line[dd->cursor - 1] == '\\n')",
            "\t\tops_dump_flush();",
            "}",
            "__bpf_kfunc u32 scx_bpf_cpuperf_cap(s32 cpu)",
            "{",
            "\tif (ops_cpu_valid(cpu, NULL))",
            "\t\treturn arch_scale_cpu_capacity(cpu);",
            "\telse",
            "\t\treturn SCX_CPUPERF_ONE;",
            "}",
            "__bpf_kfunc u32 scx_bpf_cpuperf_cur(s32 cpu)",
            "{",
            "\tif (ops_cpu_valid(cpu, NULL))",
            "\t\treturn arch_scale_freq_capacity(cpu);",
            "\telse",
            "\t\treturn SCX_CPUPERF_ONE;",
            "}",
            "__bpf_kfunc void scx_bpf_cpuperf_set(s32 cpu, u32 perf)",
            "{",
            "\tif (unlikely(perf > SCX_CPUPERF_ONE)) {",
            "\t\tscx_ops_error(\"Invalid cpuperf target %u for CPU %d\", perf, cpu);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (ops_cpu_valid(cpu, NULL)) {",
            "\t\tstruct rq *rq = cpu_rq(cpu);",
            "",
            "\t\trq->scx.cpuperf_target = perf;",
            "",
            "\t\trcu_read_lock_sched_notrace();",
            "\t\tcpufreq_update_util(cpu_rq(cpu), 0);",
            "\t\trcu_read_unlock_sched_notrace();",
            "\t}",
            "}",
            "__bpf_kfunc u32 scx_bpf_nr_cpu_ids(void)",
            "{",
            "\treturn nr_cpu_ids;",
            "}"
          ],
          "function_name": "bstr_format, scx_bpf_exit_bstr, scx_bpf_error_bstr, scx_bpf_dump_bstr, scx_bpf_cpuperf_cap, scx_bpf_cpuperf_cur, scx_bpf_cpuperf_set, scx_bpf_nr_cpu_ids",
          "description": "实现字符串格式化辅助函数及错误/退出信息记录功能，通过锁保护缓冲区并调用scx_ops_exit_kind或scx_ops_error接口上报格式化后的错误信息或退出码。包含CPU性能监控相关接口，提供CPU容量比例查询和设置接口，以及获取CPU数量的功能。",
          "similarity": 0.5557986497879028
        },
        {
          "chunk_id": 20,
          "file_path": "kernel/sched/ext.c",
          "start_line": 4057,
          "end_line": 4157,
          "content": [
            "static void scx_cgroup_exit(void)",
            "{",
            "\tstruct cgroup_subsys_state *css;",
            "",
            "\tpercpu_rwsem_assert_held(&scx_cgroup_rwsem);",
            "",
            "\tscx_cgroup_enabled = false;",
            "",
            "\t/*",
            "\t * scx_tg_on/offline() are excluded through scx_cgroup_rwsem. If we walk",
            "\t * cgroups and exit all the inited ones, all online cgroups are exited.",
            "\t */",
            "\trcu_read_lock();",
            "\tcss_for_each_descendant_post(css, &root_task_group.css) {",
            "\t\tstruct task_group *tg = css_tg(css);",
            "",
            "\t\tif (!(tg->scx_flags & SCX_TG_INITED))",
            "\t\t\tcontinue;",
            "\t\ttg->scx_flags &= ~SCX_TG_INITED;",
            "",
            "\t\tif (!scx_ops.cgroup_exit)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (WARN_ON_ONCE(!css_tryget(css)))",
            "\t\t\tcontinue;",
            "\t\trcu_read_unlock();",
            "",
            "\t\tSCX_CALL_OP(SCX_KF_UNLOCKED, cgroup_exit, css->cgroup);",
            "",
            "\t\trcu_read_lock();",
            "\t\tcss_put(css);",
            "\t}",
            "\trcu_read_unlock();",
            "}",
            "static int scx_cgroup_init(void)",
            "{",
            "\tstruct cgroup_subsys_state *css;",
            "\tint ret;",
            "",
            "\tpercpu_rwsem_assert_held(&scx_cgroup_rwsem);",
            "",
            "\tcgroup_warned_missing_weight = false;",
            "\tcgroup_warned_missing_idle = false;",
            "",
            "\t/*",
            "\t * scx_tg_on/offline() are excluded thorugh scx_cgroup_rwsem. If we walk",
            "\t * cgroups and init, all online cgroups are initialized.",
            "\t */",
            "\trcu_read_lock();",
            "\tcss_for_each_descendant_pre(css, &root_task_group.css) {",
            "\t\tstruct task_group *tg = css_tg(css);",
            "\t\tstruct scx_cgroup_init_args args = { .weight = tg->scx_weight };",
            "",
            "\t\tscx_cgroup_warn_missing_weight(tg);",
            "\t\tscx_cgroup_warn_missing_idle(tg);",
            "",
            "\t\tif ((tg->scx_flags &",
            "\t\t     (SCX_TG_ONLINE | SCX_TG_INITED)) != SCX_TG_ONLINE)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (!scx_ops.cgroup_init) {",
            "\t\t\ttg->scx_flags |= SCX_TG_INITED;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tif (WARN_ON_ONCE(!css_tryget(css)))",
            "\t\t\tcontinue;",
            "\t\trcu_read_unlock();",
            "",
            "\t\tret = SCX_CALL_OP_RET(SCX_KF_UNLOCKED, cgroup_init,",
            "\t\t\t\t      css->cgroup, &args);",
            "\t\tif (ret) {",
            "\t\t\tcss_put(css);",
            "\t\t\tscx_ops_error(\"ops.cgroup_init() failed (%d)\", ret);",
            "\t\t\treturn ret;",
            "\t\t}",
            "\t\ttg->scx_flags |= SCX_TG_INITED;",
            "",
            "\t\trcu_read_lock();",
            "\t\tcss_put(css);",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\tWARN_ON_ONCE(scx_cgroup_enabled);",
            "\tscx_cgroup_enabled = true;",
            "",
            "\treturn 0;",
            "}",
            "static void scx_cgroup_exit(void) {}",
            "static int scx_cgroup_init(void) { return 0; }",
            "static ssize_t scx_attr_state_show(struct kobject *kobj,",
            "\t\t\t\t   struct kobj_attribute *ka, char *buf)",
            "{",
            "\treturn sysfs_emit(buf, \"%s\\n\",",
            "\t\t\t  scx_ops_enable_state_str[scx_ops_enable_state()]);",
            "}",
            "static ssize_t scx_attr_switch_all_show(struct kobject *kobj,",
            "\t\t\t\t\tstruct kobj_attribute *ka, char *buf)",
            "{",
            "\treturn sysfs_emit(buf, \"%d\\n\", READ_ONCE(scx_switching_all));",
            "}"
          ],
          "function_name": "scx_cgroup_exit, scx_cgroup_init, scx_cgroup_exit, scx_cgroup_init, scx_attr_state_show, scx_attr_switch_all_show",
          "description": "该代码段实现与cgroup相关调度扩展的初始化与清理逻辑。  \n`scx_cgroup_init` 遍历所有cgroup任务组，调用`scx_ops.cgroup_init`进行初始化标记；`scx_cgroup_exit`则反向清除已初始化cgroup的状态。  \n代码末尾存在同名函数的空定义，导致上下文不完整，实际行为取决于优先级更高的定义。",
          "similarity": 0.5512586832046509
        },
        {
          "chunk_id": 13,
          "file_path": "kernel/sched/ext.c",
          "start_line": 3141,
          "end_line": 3247,
          "content": [
            "static int select_task_rq_scx(struct task_struct *p, int prev_cpu, int wake_flags)",
            "{",
            "\t/*",
            "\t * sched_exec() calls with %WF_EXEC when @p is about to exec(2) as it",
            "\t * can be a good migration opportunity with low cache and memory",
            "\t * footprint. Returning a CPU different than @prev_cpu triggers",
            "\t * immediate rq migration. However, for SCX, as the current rq",
            "\t * association doesn't dictate where the task is going to run, this",
            "\t * doesn't fit well. If necessary, we can later add a dedicated method",
            "\t * which can decide to preempt self to force it through the regular",
            "\t * scheduling path.",
            "\t */",
            "\tif (unlikely(wake_flags & WF_EXEC))",
            "\t\treturn prev_cpu;",
            "",
            "\tif (SCX_HAS_OP(select_cpu) && !scx_rq_bypassing(task_rq(p))) {",
            "\t\ts32 cpu;",
            "\t\tstruct task_struct **ddsp_taskp;",
            "",
            "\t\tddsp_taskp = this_cpu_ptr(&direct_dispatch_task);",
            "\t\tWARN_ON_ONCE(*ddsp_taskp);",
            "\t\t*ddsp_taskp = p;",
            "",
            "\t\tcpu = SCX_CALL_OP_TASK_RET(SCX_KF_ENQUEUE | SCX_KF_SELECT_CPU,",
            "\t\t\t\t\t   select_cpu, p, prev_cpu, wake_flags);",
            "\t\t*ddsp_taskp = NULL;",
            "\t\tif (ops_cpu_valid(cpu, \"from ops.select_cpu()\"))",
            "\t\t\treturn cpu;",
            "\t\telse",
            "\t\t\treturn prev_cpu;",
            "\t} else {",
            "\t\tbool found;",
            "\t\ts32 cpu;",
            "",
            "\t\tcpu = scx_select_cpu_dfl(p, prev_cpu, wake_flags, &found);",
            "\t\tif (found) {",
            "\t\t\tp->scx.slice = SCX_SLICE_DFL;",
            "\t\t\tp->scx.ddsp_dsq_id = SCX_DSQ_LOCAL;",
            "\t\t}",
            "\t\treturn cpu;",
            "\t}",
            "}",
            "static void task_woken_scx(struct rq *rq, struct task_struct *p)",
            "{",
            "\trun_deferred(rq);",
            "}",
            "static void set_cpus_allowed_scx(struct task_struct *p,",
            "\t\t\t\t struct affinity_context *ac)",
            "{",
            "\tset_cpus_allowed_common(p, ac);",
            "",
            "\t/*",
            "\t * The effective cpumask is stored in @p->cpus_ptr which may temporarily",
            "\t * differ from the configured one in @p->cpus_mask. Always tell the bpf",
            "\t * scheduler the effective one.",
            "\t *",
            "\t * Fine-grained memory write control is enforced by BPF making the const",
            "\t * designation pointless. Cast it away when calling the operation.",
            "\t */",
            "\tif (SCX_HAS_OP(set_cpumask))",
            "\t\tSCX_CALL_OP_TASK(SCX_KF_REST, set_cpumask, p,",
            "\t\t\t\t (struct cpumask *)p->cpus_ptr);",
            "}",
            "static void reset_idle_masks(void)",
            "{",
            "\t/*",
            "\t * Consider all online cpus idle. Should converge to the actual state",
            "\t * quickly.",
            "\t */",
            "\tcpumask_copy(idle_masks.cpu, cpu_online_mask);",
            "\tcpumask_copy(idle_masks.smt, cpu_online_mask);",
            "}",
            "void __scx_update_idle(struct rq *rq, bool idle)",
            "{",
            "\tint cpu = cpu_of(rq);",
            "",
            "\tif (SCX_HAS_OP(update_idle) && !scx_rq_bypassing(rq)) {",
            "\t\tSCX_CALL_OP(SCX_KF_REST, update_idle, cpu_of(rq), idle);",
            "\t\tif (!static_branch_unlikely(&scx_builtin_idle_enabled))",
            "\t\t\treturn;",
            "\t}",
            "",
            "\tif (idle)",
            "\t\tcpumask_set_cpu(cpu, idle_masks.cpu);",
            "\telse",
            "\t\tcpumask_clear_cpu(cpu, idle_masks.cpu);",
            "",
            "#ifdef CONFIG_SCHED_SMT",
            "\tif (sched_smt_active()) {",
            "\t\tconst struct cpumask *smt = cpu_smt_mask(cpu);",
            "",
            "\t\tif (idle) {",
            "\t\t\t/*",
            "\t\t\t * idle_masks.smt handling is racy but that's fine as",
            "\t\t\t * it's only for optimization and self-correcting.",
            "\t\t\t */",
            "\t\t\tfor_each_cpu(cpu, smt) {",
            "\t\t\t\tif (!cpumask_test_cpu(cpu, idle_masks.cpu))",
            "\t\t\t\t\treturn;",
            "\t\t\t}",
            "\t\t\tcpumask_or(idle_masks.smt, idle_masks.smt, smt);",
            "\t\t} else {",
            "\t\t\tcpumask_andnot(idle_masks.smt, idle_masks.smt, smt);",
            "\t\t}",
            "\t}",
            "#endif",
            "}"
          ],
          "function_name": "select_task_rq_scx, task_woken_scx, set_cpus_allowed_scx, reset_idle_masks, __scx_update_idle",
          "description": "该代码块实现了SCX（Scalable Cores eXtension）调度扩展的辅助逻辑，主要包含任务CPU选择、唤醒后处理、CPU亲和性设置及空闲状态管理等功能。  \n`select_task_rq_scx` 根据SCX操作是否存在决定任务迁移目标CPU，`set_cpus_allowed_scx` 更新BPF调度器的CPU掩码，`reset_idle_masks` 和 `__scx_update_idle` 维护全局空闲CPU掩码以优化负载均衡。  \n由于缺少`run_deferred`等关键函数定义及SCX操作的具体实现，上下文存在不完整性。",
          "similarity": 0.5477526783943176
        }
      ]
    }
  ]
}