{
  "query": "do_exit函数实现分析",
  "timestamp": "2025-12-26 00:40:44",
  "retrieved_files": [
    {
      "source_file": "kernel/exit.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:27:18\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `exit.c`\n\n---\n\n# `exit.c` 技术文档\n\n## 1. 文件概述\n\n`exit.c` 是 Linux 内核中负责进程退出（termination）核心逻辑的关键源文件，位于 `kernel/` 目录下。该文件实现了进程终止时的资源回收、信号处理、线程组清理、引用计数释放以及与用户空间和内核其他子系统的协调机制。其主要职责包括：\n\n- 安全地释放进程占用的内核资源（如内存、文件描述符、信号处理结构等）\n- 更新进程组和会话的统计信息\n- 通知父进程子进程已退出（通过 `SIGCHLD` 信号）\n- 管理僵尸进程（zombie）的生命周期\n- 支持线程组（thread group）的协同退出\n- 提供与 oops（内核异常）相关的计数和限制机制\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数名 | 功能描述 |\n|--------|---------|\n| `__unhash_process()` | 从内核的进程哈希表和链表中移除进程，减少线程计数 |\n| `__exit_signal()` | 清理进程的信号相关资源，累加 CPU 时间和 I/O 统计到 `signal_struct` |\n| `delayed_put_task_struct()` | RCU 回调函数，延迟释放 `task_struct` 及其关联资源 |\n| `put_task_struct_rcu_user()` | 安全地减少 `task_struct` 的 RCU 用户引用计数，并在为零时调度延迟释放 |\n| `release_thread()` | 架构相关的线程资源释放钩子（弱符号，可由架构代码覆盖） |\n| `release_task()` | 主进程释放入口函数，协调整个退出流程，包括通知父进程、释放资源等 |\n| `rcuwait_wake_up()` | 唤醒等待在 `rcuwait` 上的任务（代码片段未完整） |\n\n### 关键数据结构与变量\n\n| 名称 | 类型/说明 |\n|------|----------|\n| `oops_limit` | `unsigned int`，限制内核 oops 发生次数的阈值（默认 10000） |\n| `oops_count` | `atomic_t`，原子计数器，记录系统发生 oops 的总次数 |\n| `kern_exit_table` | `ctl_table`，用于 `/proc/sys/kernel/oops_limit` 的 sysctl 接口 |\n| `oops_count_attr` | `kobj_attribute`，用于 `/sys/kernel/oops_count` 的 sysfs 接口 |\n\n## 3. 关键实现\n\n### 进程退出流程\n\n1. **资源统计聚合**：  \n   在 `__exit_signal()` 中，将退出线程的 CPU 时间（`utime`/`stime`）、I/O 操作、上下文切换次数等统计信息累加到所属线程组的 `signal_struct` 中，确保即使线程组 leader 尚未退出，也能被 `wait4()` 等系统调用正确获取。\n\n2. **线程组协同退出**：  \n   - 若当前退出的是线程组 leader（`group_dead == true`），则清理整个线程组的 PID 类型（TGID、PGID、SID），并从全局任务链表中移除。\n   - 若非 leader，则仅减少线程组计数，并可能更新 `curr_target`（用于信号投递）。\n\n3. **僵尸进程处理**：  \n   在 `release_task()` 中，检查线程组 leader 是否已变为僵尸状态。若是且当前线程是最后一个成员，则调用 `do_notify_parent()` 通知其父进程。若父进程忽略 `SIGCHLD`，则直接将 leader 状态置为 `EXIT_DEAD` 并递归释放。\n\n4. **延迟释放机制**：  \n   通过 RCU（Read-Copy-Update）机制安全释放 `task_struct`。`put_task_struct_rcu_user()` 在引用计数归零时调用 `call_rcu()`，由 `delayed_put_task_struct()` 在 RCU 宽限期后执行实际释放，确保并发读取安全。\n\n5. **Oops 计数与限制**：  \n   提供 `oops_count`（只读）和 `oops_limit`（可调）两个接口，用于监控和限制内核异常次数，防止因频繁崩溃导致资源耗尽或引用计数溢出。\n\n### 锁与同步\n\n- **`tasklist_lock`**：写锁保护进程链表和 PID 哈希表的修改。\n- **`sighand->siglock`**：自旋锁保护信号处理结构。\n- **`signal->stats_lock`**：顺序锁（seqlock）保护线程组统计信息的聚合。\n- **RCU**：用于安全地延迟释放 `task_struct`，避免在遍历任务链表时访问已释放内存。\n\n## 4. 依赖关系\n\n`exit.c` 与内核多个子系统紧密耦合，主要依赖包括：\n\n- **调度器（SCHED）**：`<linux/sched/*.h>`，用于任务状态管理、CPU 时间统计、任务链表操作。\n- **内存管理（MM）**：`<linux/mm.h>`、`<linux/slab.h>`，用于内存释放和 slab 分配器交互。\n- **文件系统（VFS）**：`<linux/file.h>`、`<linux/fdtable.h>`、`<linux/fs_struct.h>`，用于关闭文件描述符和释放文件系统上下文。\n- **进程间通信（IPC）**：`<linux/shm.h>`、`<linux/posix-timers.h>`，用于清理共享内存和定时器资源。\n- **安全与审计**：`<linux/audit.h>`、`<linux/seccomp.h>`（通过 `seccomp_filter_release`），用于释放安全策略和审计上下文。\n- **cgroup 与资源控制**：`<linux/cgroup.h>`、`<linux/resource.h>`，用于资源计数释放和限制检查。\n- **跟踪与性能**：`<linux/perf_event.h>`、`<trace/events/sched.h>`，用于性能事件清理和调度跟踪点。\n- **架构相关代码**：`<asm/mmu_context.h>`、`release_thread()` 弱符号，允许架构层定制线程释放逻辑。\n\n## 5. 使用场景\n\n- **进程正常退出**：当用户程序调用 `exit()` 或 `exit_group()` 系统调用时，内核通过此文件执行清理。\n- **进程被信号终止**：如收到 `SIGKILL` 或 `SIGTERM` 后，内核调度退出路径。\n- **线程退出**：POSIX 线程（通过 `pthread_exit()` 或线程函数返回）触发 `release_task()` 清理单个线程。\n- **内核 Oops/panic 处理**：每次内核异常会递增 `oops_count`，用于监控系统稳定性。\n- **僵尸进程回收**：父进程调用 `wait()` 系列系统调用后，内核最终通过 `release_task()` 释放僵尸进程的内核结构。\n- **容器/命名空间退出**：在 PID 命名空间或 cgroup 中进程退出时，协调资源释放和通知机制。",
      "similarity": 0.5942434668540955,
      "chunks": [
        {
          "chunk_id": 5,
          "file_path": "kernel/exit.c",
          "start_line": 791,
          "end_line": 942,
          "content": [
            "static void check_stack_usage(void)",
            "{",
            "\tstatic DEFINE_SPINLOCK(low_water_lock);",
            "\tstatic int lowest_to_date = THREAD_SIZE;",
            "\tunsigned long free;",
            "",
            "\tfree = stack_not_used(current);",
            "",
            "\tif (free >= lowest_to_date)",
            "\t\treturn;",
            "",
            "\tspin_lock(&low_water_lock);",
            "\tif (free < lowest_to_date) {",
            "\t\tpr_info(\"%s (%d) used greatest stack depth: %lu bytes left\\n\",",
            "\t\t\tcurrent->comm, task_pid_nr(current), free);",
            "\t\tlowest_to_date = free;",
            "\t}",
            "\tspin_unlock(&low_water_lock);",
            "}",
            "static inline void check_stack_usage(void) {}",
            "static void synchronize_group_exit(struct task_struct *tsk, long code)",
            "{",
            "\tstruct sighand_struct *sighand = tsk->sighand;",
            "\tstruct signal_struct *signal = tsk->signal;",
            "",
            "\tspin_lock_irq(&sighand->siglock);",
            "\tsignal->quick_threads--;",
            "\tif ((signal->quick_threads == 0) &&",
            "\t    !(signal->flags & SIGNAL_GROUP_EXIT)) {",
            "\t\tsignal->flags = SIGNAL_GROUP_EXIT;",
            "\t\tsignal->group_exit_code = code;",
            "\t\tsignal->group_stop_count = 0;",
            "\t}",
            "\tspin_unlock_irq(&sighand->siglock);",
            "}",
            "void __noreturn do_exit(long code)",
            "{",
            "\tstruct task_struct *tsk = current;",
            "\tint group_dead;",
            "",
            "\tWARN_ON(irqs_disabled());",
            "",
            "\tsynchronize_group_exit(tsk, code);",
            "",
            "\tWARN_ON(tsk->plug);",
            "",
            "\tkcov_task_exit(tsk);",
            "\tkmsan_task_exit(tsk);",
            "",
            "\tcoredump_task_exit(tsk);",
            "\tptrace_event(PTRACE_EVENT_EXIT, code);",
            "\tuser_events_exit(tsk);",
            "",
            "\tio_uring_files_cancel();",
            "\texit_signals(tsk);  /* sets PF_EXITING */",
            "",
            "\t/* sync mm's RSS info before statistics gathering */",
            "\tif (tsk->mm)",
            "\t\tsync_mm_rss(tsk->mm);",
            "\tacct_update_integrals(tsk);",
            "\tgroup_dead = atomic_dec_and_test(&tsk->signal->live);",
            "\tif (group_dead) {",
            "\t\t/*",
            "\t\t * If the last thread of global init has exited, panic",
            "\t\t * immediately to get a useable coredump.",
            "\t\t */",
            "\t\tif (unlikely(is_global_init(tsk)))",
            "\t\t\tpanic(\"Attempted to kill init! exitcode=0x%08x\\n\",",
            "\t\t\t\ttsk->signal->group_exit_code ?: (int)code);",
            "",
            "#ifdef CONFIG_POSIX_TIMERS",
            "\t\thrtimer_cancel(&tsk->signal->real_timer);",
            "\t\texit_itimers(tsk);",
            "#endif",
            "\t\tif (tsk->mm)",
            "\t\t\tsetmax_mm_hiwater_rss(&tsk->signal->maxrss, tsk->mm);",
            "\t}",
            "\tacct_collect(code, group_dead);",
            "\tif (group_dead)",
            "\t\ttty_audit_exit();",
            "\taudit_free(tsk);",
            "",
            "\ttsk->exit_code = code;",
            "\ttaskstats_exit(tsk, group_dead);",
            "",
            "\t/*",
            "\t * Since sampling can touch ->mm, make sure to stop everything before we",
            "\t * tear it down.",
            "\t *",
            "\t * Also flushes inherited counters to the parent - before the parent",
            "\t * gets woken up by child-exit notifications.",
            "\t */",
            "\tperf_event_exit_task(tsk);",
            "",
            "\texit_mm();",
            "",
            "\tif (group_dead)",
            "\t\tacct_process();",
            "\ttrace_sched_process_exit(tsk);",
            "",
            "\texit_sem(tsk);",
            "\texit_shm(tsk);",
            "\texit_files(tsk);",
            "\texit_fs(tsk);",
            "\tif (group_dead)",
            "\t\tdisassociate_ctty(1);",
            "\texit_task_namespaces(tsk);",
            "\texit_task_work(tsk);",
            "\texit_thread(tsk);",
            "",
            "\tsched_autogroup_exit_task(tsk);",
            "\tcgroup_exit(tsk);",
            "",
            "\t/*",
            "\t * FIXME: do that only when needed, using sched_exit tracepoint",
            "\t */",
            "\tflush_ptrace_hw_breakpoint(tsk);",
            "",
            "\texit_tasks_rcu_start();",
            "\texit_notify(tsk, group_dead);",
            "\tproc_exit_connector(tsk);",
            "\tmpol_put_task_policy(tsk);",
            "#ifdef CONFIG_FUTEX",
            "\tif (unlikely(current->pi_state_cache))",
            "\t\tkfree(current->pi_state_cache);",
            "#endif",
            "\t/*",
            "\t * Make sure we are holding no locks:",
            "\t */",
            "\tdebug_check_no_locks_held();",
            "",
            "\tif (tsk->io_context)",
            "\t\texit_io_context(tsk);",
            "",
            "\tif (tsk->splice_pipe)",
            "\t\tfree_pipe_info(tsk->splice_pipe);",
            "",
            "\tif (tsk->task_frag.page)",
            "\t\tput_page(tsk->task_frag.page);",
            "",
            "\texit_task_stack_account(tsk);",
            "",
            "\tcheck_stack_usage();",
            "\tpreempt_disable();",
            "\tif (tsk->nr_dirtied)",
            "\t\t__this_cpu_add(dirty_throttle_leaks, tsk->nr_dirtied);",
            "\texit_rcu();",
            "\texit_tasks_rcu_finish();",
            "",
            "\tlockdep_free_task(tsk);",
            "\tdo_task_dead();",
            "}"
          ],
          "function_name": "check_stack_usage, check_stack_usage, synchronize_group_exit, do_exit",
          "description": "do_exit函数负责处理进程退出流程，包括同步线程组退出、释放资源、更新统计信息、清理内存映射、解除命名空间关联等操作。其中synchronize_group_exit用于减少信号量计数并标记线程组退出状态，check_stack_usage监控最大堆栈使用量。",
          "similarity": 0.738059401512146
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/exit.c",
          "start_line": 948,
          "end_line": 1066,
          "content": [
            "void __noreturn make_task_dead(int signr)",
            "{",
            "\t/*",
            "\t * Take the task off the cpu after something catastrophic has",
            "\t * happened.",
            "\t *",
            "\t * We can get here from a kernel oops, sometimes with preemption off.",
            "\t * Start by checking for critical errors.",
            "\t * Then fix up important state like USER_DS and preemption.",
            "\t * Then do everything else.",
            "\t */",
            "\tstruct task_struct *tsk = current;",
            "\tunsigned int limit;",
            "",
            "\tif (unlikely(in_interrupt()))",
            "\t\tpanic(\"Aiee, killing interrupt handler!\");",
            "\tif (unlikely(!tsk->pid))",
            "\t\tpanic(\"Attempted to kill the idle task!\");",
            "",
            "\tif (unlikely(irqs_disabled())) {",
            "\t\tpr_info(\"note: %s[%d] exited with irqs disabled\\n\",",
            "\t\t\tcurrent->comm, task_pid_nr(current));",
            "\t\tlocal_irq_enable();",
            "\t}",
            "\tif (unlikely(in_atomic())) {",
            "\t\tpr_info(\"note: %s[%d] exited with preempt_count %d\\n\",",
            "\t\t\tcurrent->comm, task_pid_nr(current),",
            "\t\t\tpreempt_count());",
            "\t\tpreempt_count_set(PREEMPT_ENABLED);",
            "\t}",
            "",
            "\t/*",
            "\t * Every time the system oopses, if the oops happens while a reference",
            "\t * to an object was held, the reference leaks.",
            "\t * If the oops doesn't also leak memory, repeated oopsing can cause",
            "\t * reference counters to wrap around (if they're not using refcount_t).",
            "\t * This means that repeated oopsing can make unexploitable-looking bugs",
            "\t * exploitable through repeated oopsing.",
            "\t * To make sure this can't happen, place an upper bound on how often the",
            "\t * kernel may oops without panic().",
            "\t */",
            "\tlimit = READ_ONCE(oops_limit);",
            "\tif (atomic_inc_return(&oops_count) >= limit && limit)",
            "\t\tpanic(\"Oopsed too often (kernel.oops_limit is %d)\", limit);",
            "",
            "\t/*",
            "\t * We're taking recursive faults here in make_task_dead. Safest is to just",
            "\t * leave this task alone and wait for reboot.",
            "\t */",
            "\tif (unlikely(tsk->flags & PF_EXITING)) {",
            "\t\tpr_alert(\"Fixing recursive fault but reboot is needed!\\n\");",
            "\t\tfutex_exit_recursive(tsk);",
            "\t\ttsk->exit_state = EXIT_DEAD;",
            "\t\trefcount_inc(&tsk->rcu_users);",
            "\t\tdo_task_dead();",
            "\t}",
            "",
            "\tdo_exit(signr);",
            "}",
            "void __noreturn",
            "do_group_exit(int exit_code)",
            "{",
            "\tstruct signal_struct *sig = current->signal;",
            "",
            "\tif (sig->flags & SIGNAL_GROUP_EXIT)",
            "\t\texit_code = sig->group_exit_code;",
            "\telse if (sig->group_exec_task)",
            "\t\texit_code = 0;",
            "\telse {",
            "\t\tstruct sighand_struct *const sighand = current->sighand;",
            "",
            "\t\tspin_lock_irq(&sighand->siglock);",
            "\t\tif (sig->flags & SIGNAL_GROUP_EXIT)",
            "\t\t\t/* Another thread got here before we took the lock.  */",
            "\t\t\texit_code = sig->group_exit_code;",
            "\t\telse if (sig->group_exec_task)",
            "\t\t\texit_code = 0;",
            "\t\telse {",
            "\t\t\tsig->group_exit_code = exit_code;",
            "\t\t\tsig->flags = SIGNAL_GROUP_EXIT;",
            "\t\t\tzap_other_threads(current);",
            "\t\t}",
            "\t\tspin_unlock_irq(&sighand->siglock);",
            "\t}",
            "",
            "\tdo_exit(exit_code);",
            "\t/* NOTREACHED */",
            "}",
            "static int eligible_pid(struct wait_opts *wo, struct task_struct *p)",
            "{",
            "\treturn\two->wo_type == PIDTYPE_MAX ||",
            "\t\ttask_pid_type(p, wo->wo_type) == wo->wo_pid;",
            "}",
            "static int",
            "eligible_child(struct wait_opts *wo, bool ptrace, struct task_struct *p)",
            "{",
            "\tif (!eligible_pid(wo, p))",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * Wait for all children (clone and not) if __WALL is set or",
            "\t * if it is traced by us.",
            "\t */",
            "\tif (ptrace || (wo->wo_flags & __WALL))",
            "\t\treturn 1;",
            "",
            "\t/*",
            "\t * Otherwise, wait for clone children *only* if __WCLONE is set;",
            "\t * otherwise, wait for non-clone children *only*.",
            "\t *",
            "\t * Note: a \"clone\" child here is one that reports to its parent",
            "\t * using a signal other than SIGCHLD, or a non-leader thread which",
            "\t * we can only see if it is traced by us.",
            "\t */",
            "\tif ((p->exit_signal != SIGCHLD) ^ !!(wo->wo_flags & __WCLONE))",
            "\t\treturn 0;",
            "",
            "\treturn 1;",
            "}"
          ],
          "function_name": "make_task_dead, do_group_exit, eligible_pid, eligible_child",
          "description": "make_task_dead处理致命错误导致的进程终止，通过do_exit完成退出流程；do_group_exit用于线程组统一退出，设置退出码并触发do_exit；eligible_pid和eligible_child用于过滤符合等待条件的子进程，根据PID类型和跟踪标志进行匹配。",
          "similarity": 0.663647472858429
        },
        {
          "chunk_id": 10,
          "file_path": "kernel/exit.c",
          "start_line": 1494,
          "end_line": 1580,
          "content": [
            "static int do_wait_thread(struct wait_opts *wo, struct task_struct *tsk)",
            "{",
            "\tstruct task_struct *p;",
            "",
            "\tlist_for_each_entry(p, &tsk->children, sibling) {",
            "\t\tint ret = wait_consider_task(wo, 0, p);",
            "",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int ptrace_do_wait(struct wait_opts *wo, struct task_struct *tsk)",
            "{",
            "\tstruct task_struct *p;",
            "",
            "\tlist_for_each_entry(p, &tsk->ptraced, ptrace_entry) {",
            "\t\tint ret = wait_consider_task(wo, 1, p);",
            "",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "bool pid_child_should_wake(struct wait_opts *wo, struct task_struct *p)",
            "{",
            "\tif (!eligible_pid(wo, p))",
            "\t\treturn false;",
            "",
            "\tif ((wo->wo_flags & __WNOTHREAD) && wo->child_wait.private != p->parent)",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}",
            "static int child_wait_callback(wait_queue_entry_t *wait, unsigned mode,",
            "\t\t\t\tint sync, void *key)",
            "{",
            "\tstruct wait_opts *wo = container_of(wait, struct wait_opts,",
            "\t\t\t\t\t\tchild_wait);",
            "\tstruct task_struct *p = key;",
            "",
            "\tif (pid_child_should_wake(wo, p))",
            "\t\treturn default_wake_function(wait, mode, sync, key);",
            "",
            "\treturn 0;",
            "}",
            "void __wake_up_parent(struct task_struct *p, struct task_struct *parent)",
            "{",
            "\t__wake_up_sync_key(&parent->signal->wait_chldexit,",
            "\t\t\t   TASK_INTERRUPTIBLE, p);",
            "}",
            "static bool is_effectively_child(struct wait_opts *wo, bool ptrace,",
            "\t\t\t\t struct task_struct *target)",
            "{",
            "\tstruct task_struct *parent =",
            "\t\t!ptrace ? target->real_parent : target->parent;",
            "",
            "\treturn current == parent || (!(wo->wo_flags & __WNOTHREAD) &&",
            "\t\t\t\t     same_thread_group(current, parent));",
            "}",
            "static int do_wait_pid(struct wait_opts *wo)",
            "{",
            "\tbool ptrace;",
            "\tstruct task_struct *target;",
            "\tint retval;",
            "",
            "\tptrace = false;",
            "\ttarget = pid_task(wo->wo_pid, PIDTYPE_TGID);",
            "\tif (target && is_effectively_child(wo, ptrace, target)) {",
            "\t\tretval = wait_consider_task(wo, ptrace, target);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "\t}",
            "",
            "\tptrace = true;",
            "\ttarget = pid_task(wo->wo_pid, PIDTYPE_PID);",
            "\tif (target && target->ptrace &&",
            "\t    is_effectively_child(wo, ptrace, target)) {",
            "\t\tretval = wait_consider_task(wo, ptrace, target);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "\t}",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "do_wait_thread, ptrace_do_wait, pid_child_should_wake, child_wait_callback, __wake_up_parent, is_effectively_child, do_wait_pid",
          "description": "该代码段实现了父进程对子进程退出状态的等待逻辑，包含线程组子进程和被ptrace跟踪子进程的处理。do_wait_thread和ptrace_do_wait遍历子进程列表并调用wait_consider_task检查是否满足等待条件，而child_wait_callback与__wake_up_parent协同完成子进程退出时的唤醒机制。is_effectively_child用于判定当前进程是否为有效子进程，do_wait_pid则根据PID类型选择具体的目标子进程进行等待。",
          "similarity": 0.5749493837356567
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/exit.c",
          "start_line": 546,
          "end_line": 686,
          "content": [
            "static void exit_mm(void)",
            "{",
            "\tstruct mm_struct *mm = current->mm;",
            "",
            "\texit_mm_release(current, mm);",
            "\tif (!mm)",
            "\t\treturn;",
            "\tsync_mm_rss(mm);",
            "\tmmap_read_lock(mm);",
            "\tmmgrab_lazy_tlb(mm);",
            "\tBUG_ON(mm != current->active_mm);",
            "\t/* more a memory barrier than a real lock */",
            "\ttask_lock(current);",
            "\t/*",
            "\t * When a thread stops operating on an address space, the loop",
            "\t * in membarrier_private_expedited() may not observe that",
            "\t * tsk->mm, and the loop in membarrier_global_expedited() may",
            "\t * not observe a MEMBARRIER_STATE_GLOBAL_EXPEDITED",
            "\t * rq->membarrier_state, so those would not issue an IPI.",
            "\t * Membarrier requires a memory barrier after accessing",
            "\t * user-space memory, before clearing tsk->mm or the",
            "\t * rq->membarrier_state.",
            "\t */",
            "\tsmp_mb__after_spinlock();",
            "\tlocal_irq_disable();",
            "\tcurrent->mm = NULL;",
            "\t#ifdef CONFIG_IEE",
            "\tiee_set_token_pgd(current, NULL);",
            "\t#endif",
            "\tmembarrier_update_current_mm(NULL);",
            "\tenter_lazy_tlb(mm, current);",
            "\tlocal_irq_enable();",
            "\ttask_unlock(current);",
            "\tmmap_read_unlock(mm);",
            "\tmm_update_next_owner(mm);",
            "\tmmput(mm);",
            "\tif (test_thread_flag(TIF_MEMDIE))",
            "\t\texit_oom_victim();",
            "}",
            "static void reparent_leader(struct task_struct *father, struct task_struct *p,",
            "\t\t\t\tstruct list_head *dead)",
            "{",
            "\tif (unlikely(p->exit_state == EXIT_DEAD))",
            "\t\treturn;",
            "",
            "\t/* We don't want people slaying init. */",
            "\tp->exit_signal = SIGCHLD;",
            "",
            "\t/* If it has exited notify the new parent about this child's death. */",
            "\tif (!p->ptrace &&",
            "\t    p->exit_state == EXIT_ZOMBIE && thread_group_empty(p)) {",
            "\t\tif (do_notify_parent(p, p->exit_signal)) {",
            "\t\t\tp->exit_state = EXIT_DEAD;",
            "\t\t\tlist_add(&p->ptrace_entry, dead);",
            "\t\t}",
            "\t}",
            "",
            "\tkill_orphaned_pgrp(p, father);",
            "}",
            "static void forget_original_parent(struct task_struct *father,",
            "\t\t\t\t\tstruct list_head *dead)",
            "{",
            "\tstruct task_struct *p, *t, *reaper;",
            "",
            "\tif (unlikely(!list_empty(&father->ptraced)))",
            "\t\texit_ptrace(father, dead);",
            "",
            "\t/* Can drop and reacquire tasklist_lock */",
            "\treaper = find_child_reaper(father, dead);",
            "\tif (list_empty(&father->children))",
            "\t\treturn;",
            "",
            "\treaper = find_new_reaper(father, reaper);",
            "\tlist_for_each_entry(p, &father->children, sibling) {",
            "\t\tfor_each_thread(p, t) {",
            "\t\t\tRCU_INIT_POINTER(t->real_parent, reaper);",
            "\t\t\tBUG_ON((!t->ptrace) != (rcu_access_pointer(t->parent) == father));",
            "\t\t\tif (likely(!t->ptrace))",
            "\t\t\t\tt->parent = t->real_parent;",
            "\t\t\tif (t->pdeath_signal)",
            "\t\t\t\tgroup_send_sig_info(t->pdeath_signal,",
            "\t\t\t\t\t\t    SEND_SIG_NOINFO, t,",
            "\t\t\t\t\t\t    PIDTYPE_TGID);",
            "\t\t}",
            "\t\t/*",
            "\t\t * If this is a threaded reparent there is no need to",
            "\t\t * notify anyone anything has happened.",
            "\t\t */",
            "\t\tif (!same_thread_group(reaper, father))",
            "\t\t\treparent_leader(father, p, dead);",
            "\t}",
            "\tlist_splice_tail_init(&father->children, &reaper->children);",
            "}",
            "static void exit_notify(struct task_struct *tsk, int group_dead)",
            "{",
            "\tbool autoreap;",
            "\tstruct task_struct *p, *n;",
            "\tLIST_HEAD(dead);",
            "",
            "\twrite_lock_irq(&tasklist_lock);",
            "\tforget_original_parent(tsk, &dead);",
            "",
            "\tif (group_dead)",
            "\t\tkill_orphaned_pgrp(tsk->group_leader, NULL);",
            "",
            "\ttsk->exit_state = EXIT_ZOMBIE;",
            "\t/*",
            "\t * sub-thread or delay_group_leader(), wake up the",
            "\t * PIDFD_THREAD waiters.",
            "\t */",
            "\tif (!thread_group_empty(tsk))",
            "\t\tdo_notify_pidfd(tsk);",
            "",
            "\tif (unlikely(tsk->ptrace)) {",
            "\t\tint sig = thread_group_leader(tsk) &&",
            "\t\t\t\tthread_group_empty(tsk) &&",
            "\t\t\t\t!ptrace_reparented(tsk) ?",
            "\t\t\ttsk->exit_signal : SIGCHLD;",
            "\t\tautoreap = do_notify_parent(tsk, sig);",
            "\t} else if (thread_group_leader(tsk)) {",
            "\t\tautoreap = thread_group_empty(tsk) &&",
            "\t\t\tdo_notify_parent(tsk, tsk->exit_signal);",
            "\t} else {",
            "\t\tautoreap = true;",
            "\t}",
            "",
            "\tif (autoreap) {",
            "\t\ttsk->exit_state = EXIT_DEAD;",
            "\t\tlist_add(&tsk->ptrace_entry, &dead);",
            "\t}",
            "",
            "\t/* mt-exec, de_thread() is waiting for group leader */",
            "\tif (unlikely(tsk->signal->notify_count < 0))",
            "\t\twake_up_process(tsk->signal->group_exec_task);",
            "\twrite_unlock_irq(&tasklist_lock);",
            "",
            "\tlist_for_each_entry_safe(p, n, &dead, ptrace_entry) {",
            "\t\tlist_del_init(&p->ptrace_entry);",
            "\t\trelease_task(p);",
            "\t}",
            "}"
          ],
          "function_name": "exit_mm, reparent_leader, forget_original_parent, exit_notify",
          "description": "完成内存映射释放、父进程重定位、原始父进程解除关联及进程退出状态通知流程。",
          "similarity": 0.5356496572494507
        },
        {
          "chunk_id": 9,
          "file_path": "kernel/exit.c",
          "start_line": 1382,
          "end_line": 1483,
          "content": [
            "static int wait_consider_task(struct wait_opts *wo, int ptrace,",
            "\t\t\t\tstruct task_struct *p)",
            "{",
            "\t/*",
            "\t * We can race with wait_task_zombie() from another thread.",
            "\t * Ensure that EXIT_ZOMBIE -> EXIT_DEAD/EXIT_TRACE transition",
            "\t * can't confuse the checks below.",
            "\t */",
            "\tint exit_state = READ_ONCE(p->exit_state);",
            "\tint ret;",
            "",
            "\tif (unlikely(exit_state == EXIT_DEAD))",
            "\t\treturn 0;",
            "",
            "\tret = eligible_child(wo, ptrace, p);",
            "\tif (!ret)",
            "\t\treturn ret;",
            "",
            "\tif (unlikely(exit_state == EXIT_TRACE)) {",
            "\t\t/*",
            "\t\t * ptrace == 0 means we are the natural parent. In this case",
            "\t\t * we should clear notask_error, debugger will notify us.",
            "\t\t */",
            "\t\tif (likely(!ptrace))",
            "\t\t\two->notask_error = 0;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tif (likely(!ptrace) && unlikely(p->ptrace)) {",
            "\t\t/*",
            "\t\t * If it is traced by its real parent's group, just pretend",
            "\t\t * the caller is ptrace_do_wait() and reap this child if it",
            "\t\t * is zombie.",
            "\t\t *",
            "\t\t * This also hides group stop state from real parent; otherwise",
            "\t\t * a single stop can be reported twice as group and ptrace stop.",
            "\t\t * If a ptracer wants to distinguish these two events for its",
            "\t\t * own children it should create a separate process which takes",
            "\t\t * the role of real parent.",
            "\t\t */",
            "\t\tif (!ptrace_reparented(p))",
            "\t\t\tptrace = 1;",
            "\t}",
            "",
            "\t/* slay zombie? */",
            "\tif (exit_state == EXIT_ZOMBIE) {",
            "\t\t/* we don't reap group leaders with subthreads */",
            "\t\tif (!delay_group_leader(p)) {",
            "\t\t\t/*",
            "\t\t\t * A zombie ptracee is only visible to its ptracer.",
            "\t\t\t * Notification and reaping will be cascaded to the",
            "\t\t\t * real parent when the ptracer detaches.",
            "\t\t\t */",
            "\t\t\tif (unlikely(ptrace) || likely(!p->ptrace))",
            "\t\t\t\treturn wait_task_zombie(wo, p);",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Allow access to stopped/continued state via zombie by",
            "\t\t * falling through.  Clearing of notask_error is complex.",
            "\t\t *",
            "\t\t * When !@ptrace:",
            "\t\t *",
            "\t\t * If WEXITED is set, notask_error should naturally be",
            "\t\t * cleared.  If not, subset of WSTOPPED|WCONTINUED is set,",
            "\t\t * so, if there are live subthreads, there are events to",
            "\t\t * wait for.  If all subthreads are dead, it's still safe",
            "\t\t * to clear - this function will be called again in finite",
            "\t\t * amount time once all the subthreads are released and",
            "\t\t * will then return without clearing.",
            "\t\t *",
            "\t\t * When @ptrace:",
            "\t\t *",
            "\t\t * Stopped state is per-task and thus can't change once the",
            "\t\t * target task dies.  Only continued and exited can happen.",
            "\t\t * Clear notask_error if WCONTINUED | WEXITED.",
            "\t\t */",
            "\t\tif (likely(!ptrace) || (wo->wo_flags & (WCONTINUED | WEXITED)))",
            "\t\t\two->notask_error = 0;",
            "\t} else {",
            "\t\t/*",
            "\t\t * @p is alive and it's gonna stop, continue or exit, so",
            "\t\t * there always is something to wait for.",
            "\t\t */",
            "\t\two->notask_error = 0;",
            "\t}",
            "",
            "\t/*",
            "\t * Wait for stopped.  Depending on @ptrace, different stopped state",
            "\t * is used and the two don't interact with each other.",
            "\t */",
            "\tret = wait_task_stopped(wo, ptrace, p);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\t/*",
            "\t * Wait for continued.  There's only one continued state and the",
            "\t * ptracer can consume it which can confuse the real parent.  Don't",
            "\t * use WCONTINUED from ptracer.  You don't need or want it.",
            "\t */",
            "\treturn wait_task_continued(wo, p);",
            "}"
          ],
          "function_name": "wait_consider_task",
          "description": "wait_consider_task作为主处理函数，根据进程状态(僵尸/停止/继续)和等待参数，依次调用wait_task_zombie、wait_task_stopped、wait_task_continued进行处理，控制是否回收僵尸进程或报告停止/继续事件。",
          "similarity": 0.5238341093063354
        }
      ]
    },
    {
      "source_file": "kernel/sched/ext.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:08:15\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\ext.c`\n\n---\n\n# `sched/ext.c` 技术文档\n\n## 文件概述\n\n`sched/ext.c` 是 Linux 内核中 **BPF 可扩展调度器（sched_ext）** 的核心实现文件之一，定义了调度器与 BPF 程序交互所需的数据结构、常量和操作接口。该文件为用户空间通过 BPF 实现自定义调度策略提供了内核侧的框架支持，允许将任务调度逻辑完全委托给加载的 BPF 程序，同时保留与内核调度子系统的安全集成。\n\n## 核心功能\n\n### 主要数据结构\n\n- **`struct sched_ext_ops`**  \n  BPF 调度器的操作函数表，包含调度器必须或可选实现的回调函数，如 `select_cpu`、`enqueue`、`dequeue`、`dispatch` 等，用于控制任务的 CPU 选择、入队、出队和分发逻辑。\n\n- **`struct scx_exit_info`**  \n  描述 BPF 调度器退出原因的结构体，包含退出类型（`kind`）、退出码（`exit_code`）、错误信息（`reason`、`msg`）、回溯栈（`bt`）和调试转储（`dump`）。\n\n- **`struct scx_init_task_args` / `scx_exit_task_args`**  \n  分别用于 `ops.init_task()` 和 `ops.exit_task()` 回调的参数容器，传递任务初始化/退出上下文（如是否由 fork 触发、所属 cgroup 等）。\n\n- **`struct scx_cpu_acquire_args` / `scx_cpu_release_args`**  \n  用于 CPU 获取/释放回调的参数结构，其中 `cpu_release` 包含抢占原因（如 RT/DL 任务抢占）和即将运行的任务。\n\n- **`struct scx_dump_ctx`**  \n  为调度器转储（dump）操作提供上下文信息，包括退出类型、时间戳等。\n\n### 关键枚举与常量\n\n- **`enum scx_exit_kind`**  \n  定义调度器退出的类别，如正常退出（`SCX_EXIT_DONE`）、用户/BPF/内核主动注销（`SCX_EXIT_UNREG*`）、系统请求（`SCX_EXIT_SYSRQ`）或运行时错误（`SCX_EXIT_ERROR*`）。\n\n- **`enum scx_exit_code`**  \n  定义 64 位退出码的位域格式，支持系统原因（如 `SCX_ECODE_RSN_HOTPLUG`）和系统动作（如 `SCX_ECODE_ACT_RESTART`），允许用户自定义退出上下文。\n\n- **`enum scx_ops_flags`**  \n  调度器操作标志，控制调度行为：\n  - `SCX_OPS_KEEP_BUILTIN_IDLE`：保留内建空闲跟踪\n  - `SCX_OPS_ENQ_LAST`：切片到期后仍无任务时重新入队\n  - `SCX_OPS_ENQ_EXITING`：由 BPF 处理退出中任务\n  - `SCX_OPS_SWITCH_PARTIAL`：仅调度 `SCHED_EXT` 策略任务\n  - `SCX_OPS_HAS_CGROUP_WEIGHT`：支持 cgroup cpu.weight\n\n- **调度器常量**  \n  如 `SCX_DSP_DFL_MAX_BATCH`（默认分发批大小）、`SCX_WATCHDOG_MAX_TIMEOUT`（看门狗超时）、`SCX_OPS_TASK_ITER_BATCH`（任务迭代锁释放批次）等，用于控制调度器内部行为。\n\n## 关键实现\n\n- **BPF 调度器生命周期管理**  \n  通过 `scx_exit_info` 和退出码机制，支持多种退出路径（用户、BPF、内核、SysRq、错误），并提供详细的诊断信息（回溯、消息、转储）。\n\n- **任务入队优化**  \n  在 `select_cpu` 中允许直接插入 DSQ（如本地 DSQ），跳过后续 `enqueue` 调用，减少调度开销；同时通过 `SCX_OPS_ENQ_EXITING` 标志处理退出中任务的调度问题，避免 RCU 停顿。\n\n- **CPU 抢占通知**  \n  通过 `scx_cpu_release_args` 向 BPF 调度器传递 CPU 被高优先级调度类（RT/DL/Stop）抢占的原因，便于调度器做出相应调整。\n\n- **cgroup 集成**  \n  支持 cgroup 调度（`CONFIG_EXT_GROUP_SCHED`），在任务加入 cgroup 时传递权重信息（`scx_cgroup_init_args`），并通过 `SCX_OPS_HAS_CGROUP_WEIGHT` 标志启用。\n\n- **安全与鲁棒性**  \n  内核侧跟踪 BPF 是否拥有任务，可忽略无效分发；任务迭代时定期释放锁（`SCX_OPS_TASK_ITER_BATCH`），防止 RCU/CSD 停顿；看门狗机制（`SCX_WATCHDOG_MAX_TIMEOUT`）检测任务卡死。\n\n## 依赖关系\n\n- **BPF 子系统**：通过 `#include <linux/bpf.h>` 依赖 BPF 基础设施，用于加载和验证调度器 BPF 程序。\n- **调度核心**：与 `kernel/sched/` 下的核心调度代码（如 `core.c`、`rt.c`、`dl.c`）交互，处理任务入队、CPU 选择和抢占。\n- **cgroup 子系统**：当启用 `CONFIG_EXT_GROUP_SCHED` 时，依赖 cgroup CPU 控制器获取任务权重和层级信息。\n- **RCU 与锁机制**：使用 `scx_tasks_lock` 保护任务迭代，需与 RCU 同步机制协调。\n\n## 使用场景\n\n- **自定义调度策略开发**：用户通过 BPF 实现特定工作负载的调度逻辑（如延迟敏感型、批处理优化、NUMA 感知等），并注册到 `sched_ext`。\n- **系统调试与监控**：利用 `ops.dump()` 和退出信息结构体，在调度器异常退出时收集诊断数据。\n- **混合调度部署**：通过 `SCX_OPS_SWITCH_PARTIAL` 标志，仅对部分任务（`SCHED_EXT`）启用 BPF 调度，其余任务仍由 CFS 处理。\n- **资源隔离与 QoS**：结合 cgroup 支持，为不同 cgroup 配置不同的调度行为和资源权重。\n- **内核调度实验平台**：作为安全的沙箱环境，测试新型调度算法而无需修改核心调度代码。",
      "similarity": 0.5791952610015869,
      "chunks": [
        {
          "chunk_id": 22,
          "file_path": "kernel/sched/ext.c",
          "start_line": 4366,
          "end_line": 4528,
          "content": [
            "static void free_exit_info(struct scx_exit_info *ei)",
            "{",
            "\tkfree(ei->dump);",
            "\tkfree(ei->msg);",
            "\tkfree(ei->bt);",
            "\tkfree(ei);",
            "}",
            "static void scx_ops_disable_workfn(struct kthread_work *work)",
            "{",
            "\tstruct scx_exit_info *ei = scx_exit_info;",
            "\tstruct scx_task_iter sti;",
            "\tstruct task_struct *p;",
            "\tstruct rhashtable_iter rht_iter;",
            "\tstruct scx_dispatch_q *dsq;",
            "\tint i, kind;",
            "",
            "\tkind = atomic_read(&scx_exit_kind);",
            "\twhile (true) {",
            "\t\t/*",
            "\t\t * NONE indicates that a new scx_ops has been registered since",
            "\t\t * disable was scheduled - don't kill the new ops. DONE",
            "\t\t * indicates that the ops has already been disabled.",
            "\t\t */",
            "\t\tif (kind == SCX_EXIT_NONE || kind == SCX_EXIT_DONE)",
            "\t\t\treturn;",
            "\t\tif (atomic_try_cmpxchg(&scx_exit_kind, &kind, SCX_EXIT_DONE))",
            "\t\t\tbreak;",
            "\t}",
            "\tei->kind = kind;",
            "\tei->reason = scx_exit_reason(ei->kind);",
            "",
            "\t/* guarantee forward progress by bypassing scx_ops */",
            "\tscx_ops_bypass(true);",
            "",
            "\tswitch (scx_ops_set_enable_state(SCX_OPS_DISABLING)) {",
            "\tcase SCX_OPS_DISABLING:",
            "\t\tWARN_ONCE(true, \"sched_ext: duplicate disabling instance?\");",
            "\t\tbreak;",
            "\tcase SCX_OPS_DISABLED:",
            "\t\tpr_warn(\"sched_ext: ops error detected without ops (%s)\\n\",",
            "\t\t\tscx_exit_info->msg);",
            "\t\tWARN_ON_ONCE(scx_ops_set_enable_state(SCX_OPS_DISABLED) !=",
            "\t\t\t     SCX_OPS_DISABLING);",
            "\t\tgoto done;",
            "\tdefault:",
            "\t\tbreak;",
            "\t}",
            "",
            "\t/*",
            "\t * Here, every runnable task is guaranteed to make forward progress and",
            "\t * we can safely use blocking synchronization constructs. Actually",
            "\t * disable ops.",
            "\t */",
            "\tmutex_lock(&scx_ops_enable_mutex);",
            "",
            "\tstatic_branch_disable(&__scx_switched_all);",
            "\tWRITE_ONCE(scx_switching_all, false);",
            "",
            "\t/*",
            "\t * Shut down cgroup support before tasks so that the cgroup attach path",
            "\t * doesn't race against scx_ops_exit_task().",
            "\t */",
            "\tscx_cgroup_lock();",
            "\tscx_cgroup_exit();",
            "\tscx_cgroup_unlock();",
            "",
            "\t/*",
            "\t * The BPF scheduler is going away. All tasks including %TASK_DEAD ones",
            "\t * must be switched out and exited synchronously.",
            "\t */",
            "\tpercpu_down_write(&scx_fork_rwsem);",
            "",
            "\tscx_ops_init_task_enabled = false;",
            "",
            "\tscx_task_iter_start(&sti);",
            "\twhile ((p = scx_task_iter_next_locked(&sti))) {",
            "\t\tconst struct sched_class *old_class = p->sched_class;",
            "\t\tconst struct sched_class *new_class =",
            "\t\t\t__setscheduler_class(p->policy, p->prio);",
            "\t\tstruct sched_enq_and_set_ctx ctx;",
            "",
            "\t\tif (old_class != new_class && p->se.sched_delayed)",
            "\t\t\tdequeue_task(task_rq(p), p, DEQUEUE_SLEEP | DEQUEUE_DELAYED);",
            "",
            "\t\tsched_deq_and_put_task(p, DEQUEUE_SAVE | DEQUEUE_MOVE, &ctx);",
            "",
            "\t\tp->sched_class = new_class;",
            "\t\tcheck_class_changing(task_rq(p), p, old_class);",
            "",
            "\t\tsched_enq_and_set_task(&ctx);",
            "",
            "\t\tcheck_class_changed(task_rq(p), p, old_class, p->prio);",
            "\t\tscx_ops_exit_task(p);",
            "\t}",
            "\tscx_task_iter_stop(&sti);",
            "\tpercpu_up_write(&scx_fork_rwsem);",
            "",
            "\t/* no task is on scx, turn off all the switches and flush in-progress calls */",
            "\tstatic_branch_disable(&__scx_ops_enabled);",
            "\tfor (i = SCX_OPI_BEGIN; i < SCX_OPI_END; i++)",
            "\t\tstatic_branch_disable(&scx_has_op[i]);",
            "\tstatic_branch_disable(&scx_ops_enq_last);",
            "\tstatic_branch_disable(&scx_ops_enq_exiting);",
            "\tstatic_branch_disable(&scx_ops_cpu_preempt);",
            "\tstatic_branch_disable(&scx_builtin_idle_enabled);",
            "\tsynchronize_rcu();",
            "",
            "\tif (ei->kind >= SCX_EXIT_ERROR) {",
            "\t\tpr_err(\"sched_ext: BPF scheduler \\\"%s\\\" disabled (%s)\\n\",",
            "\t\t       scx_ops.name, ei->reason);",
            "",
            "\t\tif (ei->msg[0] != '\\0')",
            "\t\t\tpr_err(\"sched_ext: %s: %s\\n\", scx_ops.name, ei->msg);",
            "#ifdef CONFIG_STACKTRACE",
            "\t\tstack_trace_print(ei->bt, ei->bt_len, 2);",
            "#endif",
            "\t} else {",
            "\t\tpr_info(\"sched_ext: BPF scheduler \\\"%s\\\" disabled (%s)\\n\",",
            "\t\t\tscx_ops.name, ei->reason);",
            "\t}",
            "",
            "\tif (scx_ops.exit)",
            "\t\tSCX_CALL_OP(SCX_KF_UNLOCKED, exit, ei);",
            "",
            "\tcancel_delayed_work_sync(&scx_watchdog_work);",
            "",
            "\t/*",
            "\t * Delete the kobject from the hierarchy eagerly in addition to just",
            "\t * dropping a reference. Otherwise, if the object is deleted",
            "\t * asynchronously, sysfs could observe an object of the same name still",
            "\t * in the hierarchy when another scheduler is loaded.",
            "\t */",
            "\tkobject_del(scx_root_kobj);",
            "\tkobject_put(scx_root_kobj);",
            "\tscx_root_kobj = NULL;",
            "",
            "\tmemset(&scx_ops, 0, sizeof(scx_ops));",
            "",
            "\trhashtable_walk_enter(&dsq_hash, &rht_iter);",
            "\tdo {",
            "\t\trhashtable_walk_start(&rht_iter);",
            "",
            "\t\twhile ((dsq = rhashtable_walk_next(&rht_iter)) && !IS_ERR(dsq))",
            "\t\t\tdestroy_dsq(dsq->id);",
            "",
            "\t\trhashtable_walk_stop(&rht_iter);",
            "\t} while (dsq == ERR_PTR(-EAGAIN));",
            "\trhashtable_walk_exit(&rht_iter);",
            "",
            "\tfree_percpu(scx_dsp_ctx);",
            "\tscx_dsp_ctx = NULL;",
            "\tscx_dsp_max_batch = 0;",
            "",
            "\tfree_exit_info(scx_exit_info);",
            "\tscx_exit_info = NULL;",
            "",
            "\tmutex_unlock(&scx_ops_enable_mutex);",
            "",
            "\tWARN_ON_ONCE(scx_ops_set_enable_state(SCX_OPS_DISABLED) !=",
            "\t\t     SCX_OPS_DISABLING);",
            "done:",
            "\tscx_ops_bypass(false);",
            "}"
          ],
          "function_name": "free_exit_info, scx_ops_disable_workfn",
          "description": "该代码段包含两个函数：  \n1. `free_exit_info` 用于释放 `scx_exit_info` 结构体关联的动态内存（`dump`/`msg`/`bt`）及自身；  \n2. `scx_ops_disable_workfn` 核心功能为安全禁用 SCX 操作，通过原子操作标记状态、强制切换所有任务至新调度类、清理 DSQ 和 kobject 等资源，并最终释放 `scx_exit_info`。  \n\n`scx_ops_disable_workfn` 实现了 SCX 操作的有序停用逻辑，确保任务迁移、状态同步及资源回收的完整性，同时处理异常情况下的错误日志输出。",
          "similarity": 0.5955256819725037
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/sched/ext.c",
          "start_line": 2213,
          "end_line": 2319,
          "content": [
            "static void yield_task_scx(struct rq *rq)",
            "{",
            "\tstruct task_struct *p = rq->curr;",
            "",
            "\tif (SCX_HAS_OP(yield))",
            "\t\tSCX_CALL_OP_2TASKS_RET(SCX_KF_REST, yield, p, NULL);",
            "\telse",
            "\t\tp->scx.slice = 0;",
            "}",
            "static bool yield_to_task_scx(struct rq *rq, struct task_struct *to)",
            "{",
            "\tstruct task_struct *from = rq->curr;",
            "",
            "\tif (SCX_HAS_OP(yield))",
            "\t\treturn SCX_CALL_OP_2TASKS_RET(SCX_KF_REST, yield, from, to);",
            "\telse",
            "\t\treturn false;",
            "}",
            "static void move_local_task_to_local_dsq(struct task_struct *p, u64 enq_flags,",
            "\t\t\t\t\t struct scx_dispatch_q *src_dsq,",
            "\t\t\t\t\t struct rq *dst_rq)",
            "{",
            "\tstruct scx_dispatch_q *dst_dsq = &dst_rq->scx.local_dsq;",
            "",
            "\t/* @dsq is locked and @p is on @dst_rq */",
            "\tlockdep_assert_held(&src_dsq->lock);",
            "\tlockdep_assert_rq_held(dst_rq);",
            "",
            "\tWARN_ON_ONCE(p->scx.holding_cpu >= 0);",
            "",
            "\tif (enq_flags & (SCX_ENQ_HEAD | SCX_ENQ_PREEMPT))",
            "\t\tlist_add(&p->scx.dsq_list.node, &dst_dsq->list);",
            "\telse",
            "\t\tlist_add_tail(&p->scx.dsq_list.node, &dst_dsq->list);",
            "",
            "\tdsq_mod_nr(dst_dsq, 1);",
            "\tp->scx.dsq = dst_dsq;",
            "}",
            "static void move_remote_task_to_local_dsq(struct task_struct *p, u64 enq_flags,",
            "\t\t\t\t\t  struct rq *src_rq, struct rq *dst_rq)",
            "{",
            "\tlockdep_assert_rq_held(src_rq);",
            "",
            "\t/* the following marks @p MIGRATING which excludes dequeue */",
            "\tdeactivate_task(src_rq, p, 0);",
            "\tset_task_cpu(p, cpu_of(dst_rq));",
            "\tp->scx.sticky_cpu = cpu_of(dst_rq);",
            "",
            "\traw_spin_rq_unlock(src_rq);",
            "\traw_spin_rq_lock(dst_rq);",
            "",
            "\t/*",
            "\t * We want to pass scx-specific enq_flags but activate_task() will",
            "\t * truncate the upper 32 bit. As we own @rq, we can pass them through",
            "\t * @rq->scx.extra_enq_flags instead.",
            "\t */",
            "\tWARN_ON_ONCE(!cpumask_test_cpu(cpu_of(dst_rq), p->cpus_ptr));",
            "\tWARN_ON_ONCE(dst_rq->scx.extra_enq_flags);",
            "\tdst_rq->scx.extra_enq_flags = enq_flags;",
            "\tactivate_task(dst_rq, p, 0);",
            "\tdst_rq->scx.extra_enq_flags = 0;",
            "}",
            "static bool task_can_run_on_remote_rq(struct task_struct *p, struct rq *rq,",
            "\t\t\t\t      bool trigger_error)",
            "{",
            "\tint cpu = cpu_of(rq);",
            "",
            "\t/*",
            "\t * We don't require the BPF scheduler to avoid dispatching to offline",
            "\t * CPUs mostly for convenience but also because CPUs can go offline",
            "\t * between scx_bpf_dsq_insert() calls and here. Trigger error iff the",
            "\t * picked CPU is outside the allowed mask.",
            "\t */",
            "\tif (!task_allowed_on_cpu(p, cpu)) {",
            "\t\tif (trigger_error)",
            "\t\t\tscx_ops_error(\"SCX_DSQ_LOCAL[_ON] verdict target cpu %d not allowed for %s[%d]\",",
            "\t\t\t\t      cpu_of(rq), p->comm, p->pid);",
            "\t\treturn false;",
            "\t}",
            "",
            "\tif (unlikely(is_migration_disabled(p)))",
            "\t\treturn false;",
            "",
            "\tif (!scx_rq_online(rq))",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}",
            "static bool unlink_dsq_and_lock_src_rq(struct task_struct *p,",
            "\t\t\t\t       struct scx_dispatch_q *dsq,",
            "\t\t\t\t       struct rq *src_rq)",
            "{",
            "\ts32 cpu = raw_smp_processor_id();",
            "",
            "\tlockdep_assert_held(&dsq->lock);",
            "",
            "\tWARN_ON_ONCE(p->scx.holding_cpu >= 0);",
            "\ttask_unlink_from_dsq(p, dsq);",
            "\tp->scx.holding_cpu = cpu;",
            "",
            "\traw_spin_unlock(&dsq->lock);",
            "\traw_spin_rq_lock(src_rq);",
            "",
            "\t/* task_rq couldn't have changed if we're still the holding cpu */",
            "\treturn likely(p->scx.holding_cpu == cpu) &&",
            "\t\t!WARN_ON_ONCE(src_rq != task_rq(p));",
            "}"
          ],
          "function_name": "yield_task_scx, yield_to_task_scx, move_local_task_to_local_dsq, move_remote_task_to_local_dsq, task_can_run_on_remote_rq, unlink_dsq_and_lock_src_rq",
          "description": "实现任务迁移和本地DSQ操作，yield_task_scx触发BPF的yield回调，move系列函数处理任务在本地/远程DSQ间的移动，task_can_run_on_remote_rq校验任务能否在远程CPU运行",
          "similarity": 0.5750107765197754
        },
        {
          "chunk_id": 16,
          "file_path": "kernel/sched/ext.c",
          "start_line": 3513,
          "end_line": 3625,
          "content": [
            "static void scx_ops_disable_task(struct task_struct *p)",
            "{",
            "\tlockdep_assert_rq_held(task_rq(p));",
            "\tWARN_ON_ONCE(scx_get_task_state(p) != SCX_TASK_ENABLED);",
            "",
            "\tif (SCX_HAS_OP(disable))",
            "\t\tSCX_CALL_OP(SCX_KF_REST, disable, p);",
            "\tscx_set_task_state(p, SCX_TASK_READY);",
            "}",
            "static void scx_ops_exit_task(struct task_struct *p)",
            "{",
            "\tstruct scx_exit_task_args args = {",
            "\t\t.cancelled = false,",
            "\t};",
            "",
            "\tlockdep_assert_rq_held(task_rq(p));",
            "",
            "\tswitch (scx_get_task_state(p)) {",
            "\tcase SCX_TASK_NONE:",
            "\t\treturn;",
            "\tcase SCX_TASK_INIT:",
            "\t\targs.cancelled = true;",
            "\t\tbreak;",
            "\tcase SCX_TASK_READY:",
            "\t\tbreak;",
            "\tcase SCX_TASK_ENABLED:",
            "\t\tscx_ops_disable_task(p);",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tWARN_ON_ONCE(true);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (SCX_HAS_OP(exit_task))",
            "\t\tSCX_CALL_OP(SCX_KF_REST, exit_task, p, &args);",
            "\tscx_set_task_state(p, SCX_TASK_NONE);",
            "}",
            "void init_scx_entity(struct sched_ext_entity *scx)",
            "{",
            "\t/*",
            "\t * init_idle() calls this function again after fork sequence is",
            "\t * complete. Don't touch ->tasks_node as it's already linked.",
            "\t */",
            "\tmemset(scx, 0, offsetof(struct sched_ext_entity, tasks_node));",
            "",
            "\tINIT_LIST_HEAD(&scx->dsq_list.node);",
            "\tRB_CLEAR_NODE(&scx->dsq_priq);",
            "\tscx->sticky_cpu = -1;",
            "\tscx->holding_cpu = -1;",
            "\tINIT_LIST_HEAD(&scx->runnable_node);",
            "\tscx->runnable_at = jiffies;",
            "\tscx->ddsp_dsq_id = SCX_DSQ_INVALID;",
            "\tscx->slice = SCX_SLICE_DFL;",
            "}",
            "void scx_pre_fork(struct task_struct *p)",
            "{",
            "\t/*",
            "\t * BPF scheduler enable/disable paths want to be able to iterate and",
            "\t * update all tasks which can become complex when racing forks. As",
            "\t * enable/disable are very cold paths, let's use a percpu_rwsem to",
            "\t * exclude forks.",
            "\t */",
            "\tpercpu_down_read(&scx_fork_rwsem);",
            "}",
            "int scx_fork(struct task_struct *p)",
            "{",
            "\tpercpu_rwsem_assert_held(&scx_fork_rwsem);",
            "",
            "\tif (scx_ops_init_task_enabled)",
            "\t\treturn scx_ops_init_task(p, task_group(p), true);",
            "\telse",
            "\t\treturn 0;",
            "}",
            "void scx_post_fork(struct task_struct *p)",
            "{",
            "\tif (scx_ops_init_task_enabled) {",
            "\t\tscx_set_task_state(p, SCX_TASK_READY);",
            "",
            "\t\t/*",
            "\t\t * Enable the task immediately if it's running on sched_ext.",
            "\t\t * Otherwise, it'll be enabled in switching_to_scx() if and",
            "\t\t * when it's ever configured to run with a SCHED_EXT policy.",
            "\t\t */",
            "\t\tif (p->sched_class == &ext_sched_class) {",
            "\t\t\tstruct rq_flags rf;",
            "\t\t\tstruct rq *rq;",
            "",
            "\t\t\trq = task_rq_lock(p, &rf);",
            "\t\t\tscx_ops_enable_task(p);",
            "\t\t\ttask_rq_unlock(rq, p, &rf);",
            "\t\t}",
            "\t}",
            "",
            "\tspin_lock_irq(&scx_tasks_lock);",
            "\tlist_add_tail(&p->scx.tasks_node, &scx_tasks);",
            "\tspin_unlock_irq(&scx_tasks_lock);",
            "",
            "\tpercpu_up_read(&scx_fork_rwsem);",
            "}",
            "void scx_cancel_fork(struct task_struct *p)",
            "{",
            "\tif (scx_enabled()) {",
            "\t\tstruct rq *rq;",
            "\t\tstruct rq_flags rf;",
            "",
            "\t\trq = task_rq_lock(p, &rf);",
            "\t\tWARN_ON_ONCE(scx_get_task_state(p) >= SCX_TASK_READY);",
            "\t\tscx_ops_exit_task(p);",
            "\t\ttask_rq_unlock(rq, p, &rf);",
            "\t}",
            "",
            "\tpercpu_up_read(&scx_fork_rwsem);",
            "}"
          ],
          "function_name": "scx_ops_disable_task, scx_ops_exit_task, init_scx_entity, scx_pre_fork, scx_fork, scx_post_fork, scx_cancel_fork",
          "description": "提供任务禁用退出逻辑和fork流程控制，通过读锁保护并发访问，在分叉前后调整任务状态并维护全局任务列表。",
          "similarity": 0.5368647575378418
        },
        {
          "chunk_id": 35,
          "file_path": "kernel/sched/ext.c",
          "start_line": 6810,
          "end_line": 6910,
          "content": [
            "static s32 bstr_format(struct scx_bstr_buf *buf,",
            "\t\t       char *fmt, unsigned long long *data, u32 data__sz)",
            "{",
            "\treturn __bstr_format(buf->data, buf->line, sizeof(buf->line),",
            "\t\t\t     fmt, data, data__sz);",
            "}",
            "__bpf_kfunc void scx_bpf_exit_bstr(s64 exit_code, char *fmt,",
            "\t\t\t\t   unsigned long long *data, u32 data__sz)",
            "{",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&scx_exit_bstr_buf_lock, flags);",
            "\tif (bstr_format(&scx_exit_bstr_buf, fmt, data, data__sz) >= 0)",
            "\t\tscx_ops_exit_kind(SCX_EXIT_UNREG_BPF, exit_code, \"%s\",",
            "\t\t\t\t  scx_exit_bstr_buf.line);",
            "\traw_spin_unlock_irqrestore(&scx_exit_bstr_buf_lock, flags);",
            "}",
            "__bpf_kfunc void scx_bpf_error_bstr(char *fmt, unsigned long long *data,",
            "\t\t\t\t    u32 data__sz)",
            "{",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&scx_exit_bstr_buf_lock, flags);",
            "\tif (bstr_format(&scx_exit_bstr_buf, fmt, data, data__sz) >= 0)",
            "\t\tscx_ops_exit_kind(SCX_EXIT_ERROR_BPF, 0, \"%s\",",
            "\t\t\t\t  scx_exit_bstr_buf.line);",
            "\traw_spin_unlock_irqrestore(&scx_exit_bstr_buf_lock, flags);",
            "}",
            "__bpf_kfunc void scx_bpf_dump_bstr(char *fmt, unsigned long long *data,",
            "\t\t\t\t   u32 data__sz)",
            "{",
            "\tstruct scx_dump_data *dd = &scx_dump_data;",
            "\tstruct scx_bstr_buf *buf = &dd->buf;",
            "\ts32 ret;",
            "",
            "\tif (raw_smp_processor_id() != dd->cpu) {",
            "\t\tscx_ops_error(\"scx_bpf_dump() must only be called from ops.dump() and friends\");",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* append the formatted string to the line buf */",
            "\tret = __bstr_format(buf->data, buf->line + dd->cursor,",
            "\t\t\t    sizeof(buf->line) - dd->cursor, fmt, data, data__sz);",
            "\tif (ret < 0) {",
            "\t\tdump_line(dd->s, \"%s[!] (\\\"%s\\\", %p, %u) failed to format (%d)\",",
            "\t\t\t  dd->prefix, fmt, data, data__sz, ret);",
            "\t\treturn;",
            "\t}",
            "",
            "\tdd->cursor += ret;",
            "\tdd->cursor = min_t(s32, dd->cursor, sizeof(buf->line));",
            "",
            "\tif (!dd->cursor)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If the line buf overflowed or ends in a newline, flush it into the",
            "\t * dump. This is to allow the caller to generate a single line over",
            "\t * multiple calls. As ops_dump_flush() can also handle multiple lines in",
            "\t * the line buf, the only case which can lead to an unexpected",
            "\t * truncation is when the caller keeps generating newlines in the middle",
            "\t * instead of the end consecutively. Don't do that.",
            "\t */",
            "\tif (dd->cursor >= sizeof(buf->line) || buf->line[dd->cursor - 1] == '\\n')",
            "\t\tops_dump_flush();",
            "}",
            "__bpf_kfunc u32 scx_bpf_cpuperf_cap(s32 cpu)",
            "{",
            "\tif (ops_cpu_valid(cpu, NULL))",
            "\t\treturn arch_scale_cpu_capacity(cpu);",
            "\telse",
            "\t\treturn SCX_CPUPERF_ONE;",
            "}",
            "__bpf_kfunc u32 scx_bpf_cpuperf_cur(s32 cpu)",
            "{",
            "\tif (ops_cpu_valid(cpu, NULL))",
            "\t\treturn arch_scale_freq_capacity(cpu);",
            "\telse",
            "\t\treturn SCX_CPUPERF_ONE;",
            "}",
            "__bpf_kfunc void scx_bpf_cpuperf_set(s32 cpu, u32 perf)",
            "{",
            "\tif (unlikely(perf > SCX_CPUPERF_ONE)) {",
            "\t\tscx_ops_error(\"Invalid cpuperf target %u for CPU %d\", perf, cpu);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (ops_cpu_valid(cpu, NULL)) {",
            "\t\tstruct rq *rq = cpu_rq(cpu);",
            "",
            "\t\trq->scx.cpuperf_target = perf;",
            "",
            "\t\trcu_read_lock_sched_notrace();",
            "\t\tcpufreq_update_util(cpu_rq(cpu), 0);",
            "\t\trcu_read_unlock_sched_notrace();",
            "\t}",
            "}",
            "__bpf_kfunc u32 scx_bpf_nr_cpu_ids(void)",
            "{",
            "\treturn nr_cpu_ids;",
            "}"
          ],
          "function_name": "bstr_format, scx_bpf_exit_bstr, scx_bpf_error_bstr, scx_bpf_dump_bstr, scx_bpf_cpuperf_cap, scx_bpf_cpuperf_cur, scx_bpf_cpuperf_set, scx_bpf_nr_cpu_ids",
          "description": "实现字符串格式化辅助函数及错误/退出信息记录功能，通过锁保护缓冲区并调用scx_ops_exit_kind或scx_ops_error接口上报格式化后的错误信息或退出码。包含CPU性能监控相关接口，提供CPU容量比例查询和设置接口，以及获取CPU数量的功能。",
          "similarity": 0.5336053371429443
        },
        {
          "chunk_id": 34,
          "file_path": "kernel/sched/ext.c",
          "start_line": 6617,
          "end_line": 6731,
          "content": [
            "__bpf_kfunc s32 scx_bpf_dsq_nr_queued(u64 dsq_id)",
            "{",
            "\tstruct scx_dispatch_q *dsq;",
            "\ts32 ret;",
            "",
            "\tpreempt_disable();",
            "",
            "\tif (dsq_id == SCX_DSQ_LOCAL) {",
            "\t\tret = READ_ONCE(this_rq()->scx.local_dsq.nr);",
            "\t\tgoto out;",
            "\t} else if ((dsq_id & SCX_DSQ_LOCAL_ON) == SCX_DSQ_LOCAL_ON) {",
            "\t\ts32 cpu = dsq_id & SCX_DSQ_LOCAL_CPU_MASK;",
            "",
            "\t\tif (ops_cpu_valid(cpu, NULL)) {",
            "\t\t\tret = READ_ONCE(cpu_rq(cpu)->scx.local_dsq.nr);",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t} else {",
            "\t\tdsq = find_user_dsq(dsq_id);",
            "\t\tif (dsq) {",
            "\t\t\tret = READ_ONCE(dsq->nr);",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t}",
            "\tret = -ENOENT;",
            "out:",
            "\tpreempt_enable();",
            "\treturn ret;",
            "}",
            "__bpf_kfunc void scx_bpf_destroy_dsq(u64 dsq_id)",
            "{",
            "\tdestroy_dsq(dsq_id);",
            "}",
            "__bpf_kfunc int bpf_iter_scx_dsq_new(struct bpf_iter_scx_dsq *it, u64 dsq_id,",
            "\t\t\t\t     u64 flags)",
            "{",
            "\tstruct bpf_iter_scx_dsq_kern *kit = (void *)it;",
            "",
            "\tBUILD_BUG_ON(sizeof(struct bpf_iter_scx_dsq_kern) >",
            "\t\t     sizeof(struct bpf_iter_scx_dsq));",
            "\tBUILD_BUG_ON(__alignof__(struct bpf_iter_scx_dsq_kern) !=",
            "\t\t     __alignof__(struct bpf_iter_scx_dsq));",
            "",
            "\t/*",
            "\t * next() and destroy() will be called regardless of the return value.",
            "\t * Always clear $kit->dsq.",
            "\t */",
            "\tkit->dsq = NULL;",
            "",
            "\tif (flags & ~__SCX_DSQ_ITER_USER_FLAGS)",
            "\t\treturn -EINVAL;",
            "",
            "\tkit->dsq = find_user_dsq(dsq_id);",
            "\tif (!kit->dsq)",
            "\t\treturn -ENOENT;",
            "",
            "\tINIT_LIST_HEAD(&kit->cursor.node);",
            "\tkit->cursor.flags |= SCX_DSQ_LNODE_ITER_CURSOR | flags;",
            "\tkit->cursor.priv = READ_ONCE(kit->dsq->seq);",
            "",
            "\treturn 0;",
            "}",
            "__bpf_kfunc void bpf_iter_scx_dsq_destroy(struct bpf_iter_scx_dsq *it)",
            "{",
            "\tstruct bpf_iter_scx_dsq_kern *kit = (void *)it;",
            "",
            "\tif (!kit->dsq)",
            "\t\treturn;",
            "",
            "\tif (!list_empty(&kit->cursor.node)) {",
            "\t\tunsigned long flags;",
            "",
            "\t\traw_spin_lock_irqsave(&kit->dsq->lock, flags);",
            "\t\tlist_del_init(&kit->cursor.node);",
            "\t\traw_spin_unlock_irqrestore(&kit->dsq->lock, flags);",
            "\t}",
            "\tkit->dsq = NULL;",
            "}",
            "static s32 __bstr_format(u64 *data_buf, char *line_buf, size_t line_size,",
            "\t\t\t char *fmt, unsigned long long *data, u32 data__sz)",
            "{",
            "\tstruct bpf_bprintf_data bprintf_data = { .get_bin_args = true };",
            "\ts32 ret;",
            "",
            "\tif (data__sz % 8 || data__sz > MAX_BPRINTF_VARARGS * 8 ||",
            "\t    (data__sz && !data)) {",
            "\t\tscx_ops_error(\"invalid data=%p and data__sz=%u\",",
            "\t\t\t      (void *)data, data__sz);",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tret = copy_from_kernel_nofault(data_buf, data, data__sz);",
            "\tif (ret < 0) {",
            "\t\tscx_ops_error(\"failed to read data fields (%d)\", ret);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tret = bpf_bprintf_prepare(fmt, UINT_MAX, data_buf, data__sz / 8,",
            "\t\t\t\t  &bprintf_data);",
            "\tif (ret < 0) {",
            "\t\tscx_ops_error(\"format preparation failed (%d)\", ret);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tret = bstr_printf(line_buf, line_size, fmt,",
            "\t\t\t  bprintf_data.bin_args);",
            "\tbpf_bprintf_cleanup(&bprintf_data);",
            "\tif (ret < 0) {",
            "\t\tscx_ops_error(\"(\\\"%s\\\", %p, %u) failed to format\",",
            "\t\t\t      fmt, data, data__sz);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "scx_bpf_dsq_nr_queued, scx_bpf_destroy_dsq, bpf_iter_scx_dsq_new, bpf_iter_scx_dsq_destroy, __bstr_format",
          "description": "该代码块实现了调度器扩展模块中与DSQ（ Dispatch Queue ）相关的BPF辅助函数，包括查询队列长度、销毁队列及迭代器管理等功能。  \n`scx_bpf_dsq_nr_queued` 根据 `dsq_id` 查找并返回对应 DSQ 的排队数，`scx_bpf_destroy_dsq` 销毁指定 DSQ，而迭代器函数用于遍历 DSQ 数据。  \n由于 `destroy_dsq` 和 DSQ 数据结构定义未完全展示，部分逻辑依赖上下文实现，存在上下文不完整的风险。",
          "similarity": 0.5289760231971741
        }
      ]
    },
    {
      "source_file": "kernel/fail_function.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:29:07\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `fail_function.c`\n\n---\n\n# fail_function.c 技术文档\n\n## 1. 文件概述\n\n`fail_function.c` 实现了基于函数的错误注入（Function-based Error Injection, FEI）机制，允许内核开发者在指定的可注入函数调用点动态注入预定义的错误返回值。该机制通过 kprobe 技术拦截目标函数的执行，并在满足故障注入条件时覆盖其返回值，用于测试内核错误处理路径的健壮性。所有功能通过 debugfs 接口暴露给用户空间，便于运行时控制。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct fei_attr`**  \n  表示一个错误注入点的元数据，包含：\n  - `list`：用于链入全局 `fei_attr_list` 链表\n  - `kp`：关联的 kprobe 实例，用于拦截函数执行\n  - `retval`：预设的错误返回值\n\n- **全局变量**\n  - `fei_lock`：保护 `fei_attr_list` 的互斥锁\n  - `fei_attr_list`：所有已注册错误注入点的链表\n  - `fei_fault_attr`：故障注入属性，控制注入概率/条件\n  - `fei_debugfs_dir`：debugfs 根目录句柄\n\n### 主要函数\n\n- **错误值调整**\n  - `adjust_error_retval()`：根据函数的可注入错误类型（如 `EI_ETYPE_ERRNO`、`EI_ETYPE_NULL` 等）校验并标准化返回值\n\n- **注入点管理**\n  - `fei_attr_new()` / `fei_attr_free()`：创建/销毁 `fei_attr` 实例\n  - `fei_attr_lookup()`：通过符号名查找注入点\n  - `fei_attr_is_valid()`：验证 `fei_attr` 是否仍在全局链表中\n  - `fei_attr_remove()` / `fei_attr_remove_all()`：移除单个或所有注入点\n\n- **Kprobe 处理**\n  - `fei_kprobe_handler()`：kprobe 前置处理函数，决定是否注入错误并覆盖返回值\n  - `fei_post_handler()`：空后置处理函数，防止 kprobe 优化\n\n- **Debugfs 接口**\n  - `fei_retval_get()` / `fei_retval_set()`：读写指定注入点的返回值\n  - `fei_write()`：主控制接口，支持添加/删除注入点\n  - `fei_seq_*()`：实现 `/sys/kernel/debug/fail_function/inject` 的列表读取\n\n- **初始化**\n  - `fei_debugfs_init()`：创建 debugfs 目录和文件\n\n## 3. 关键实现\n\n### 错误注入机制\n1. **函数拦截**：通过 kprobe 在目标函数入口处设置断点，触发 `fei_kprobe_handler`\n2. **条件判断**：调用 `should_fail(&fei_fault_attr, 1)` 检查是否满足注入条件（基于 `fail_function` 的故障属性配置）\n3. **返回值覆盖**：\n   - 调用 `regs_set_return_value(regs, attr->retval)` 设置返回值\n   - 调用 `override_function_with_return(regs)` 跳过原函数执行，直接返回\n\n### 安全性保障\n- **防优化**：`fei_post_handler` 作为空函数存在，阻止 kprobe 的跳转优化（因优化不支持执行路径覆盖）\n- **并发保护**：所有链表操作受 `fei_lock` 互斥锁保护\n- **有效性验证**：在 debugfs 回调中通过 `fei_attr_is_valid()` 检查对象是否已被释放\n\n### Debugfs 接口设计\n- **主控制文件** (`inject`)：\n  - **写入函数名**：添加新注入点（需在 `error_injection/list` 中注册）\n  - **写入 `!函数名`**：移除指定注入点\n  - **写入空内容**：清空所有注入点\n- **返回值文件** (`retval`)：每个注入点目录下独立的 `retval` 文件，支持动态修改返回值\n- **符号链接** (`injectable`)：指向 `error_injection/list`，显示所有可注入函数\n\n### 返回值类型处理\n`adjust_error_retval()` 根据函数声明的错误类型自动校验返回值：\n- `EI_ETYPE_NULL`：强制返回 `0`\n- `EI_ETYPE_ERRNO`：非错误值转换为 `-EINVAL`\n- `EI_ETYPE_ERRNO_NULL`：非零且非错误值转换为 `-EINVAL`\n- `EI_ETYPE_TRUE`：强制返回 `1`\n\n## 4. 依赖关系\n\n- **`<linux/error-injection.h>`**  \n  提供 `get_injectable_error_type()` 和 `within_error_injection_list()`，用于验证函数是否支持错误注入\n- **`<linux/fault-inject.h>`**  \n  提供 `DECLARE_FAULT_ATTR` 和 `should_fail()`，实现概率性故障注入控制\n- **`<linux/kprobes.h>`**  \n  核心拦截机制，通过 kprobe 动态修改函数执行流\n- **`<linux/kallsyms.h>`**  \n  通过 `kallsyms_lookup_name()` 解析函数符号地址\n- **`<linux/debugfs.h>`**  \n  提供用户空间控制接口\n- **`<linux/uaccess.h>`**  \n  处理用户空间数据拷贝（`memdup_user_nul`）\n\n## 5. 使用场景\n\n1. **内核错误路径测试**  \n   开发者可通过注入特定错误（如 `-ENOMEM`、`-EINVAL`）验证内核模块对异常返回值的处理逻辑\n\n2. **故障恢复验证**  \n   模拟硬件/驱动故障（如 I/O 失败），测试系统恢复机制（如重试、降级、崩溃防护）\n\n3. **安全边界测试**  \n   验证内核在非法返回值（如非错误码的正数）下的行为是否符合预期\n\n4. **动态调试**  \n   运行时无需重新编译内核，通过 debugfs 快速启用/禁用特定函数的错误注入\n\n**典型操作流程**：\n```bash\n# 查看可注入函数列表\ncat /sys/kernel/debug/error_injection/list\n\n# 为目标函数添加注入点\necho \"some_function\" > /sys/kernel/debug/fail_function/inject\n\n# 设置返回值为 -ENOMEM\necho -12 > /sys/kernel/debug/fail_function/some_function/retval\n\n# 触发故障（需先配置故障属性）\necho 100 > /sys/kernel/debug/fail_function/probability  # 100% 概率\n\n# 移除注入点\necho \"!some_function\" > /sys/kernel/debug/fail_function/inject\n```",
      "similarity": 0.5486496686935425,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/fail_function.c",
          "start_line": 169,
          "end_line": 280,
          "content": [
            "static int fei_kprobe_handler(struct kprobe *kp, struct pt_regs *regs)",
            "{",
            "\tstruct fei_attr *attr = container_of(kp, struct fei_attr, kp);",
            "",
            "\tif (should_fail(&fei_fault_attr, 1)) {",
            "\t\tregs_set_return_value(regs, attr->retval);",
            "\t\toverride_function_with_return(regs);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static void fei_seq_stop(struct seq_file *m, void *v)",
            "{",
            "\tmutex_unlock(&fei_lock);",
            "}",
            "static int fei_seq_show(struct seq_file *m, void *v)",
            "{",
            "\tstruct fei_attr *attr = list_entry(v, struct fei_attr, list);",
            "",
            "\tseq_printf(m, \"%ps\\n\", attr->kp.addr);",
            "\treturn 0;",
            "}",
            "static int fei_open(struct inode *inode, struct file *file)",
            "{",
            "\treturn seq_open(file, &fei_seq_ops);",
            "}",
            "static void fei_attr_remove(struct fei_attr *attr)",
            "{",
            "\tfei_debugfs_remove_attr(attr);",
            "\tunregister_kprobe(&attr->kp);",
            "\tlist_del(&attr->list);",
            "\tfei_attr_free(attr);",
            "}",
            "static void fei_attr_remove_all(void)",
            "{",
            "\tstruct fei_attr *attr, *n;",
            "",
            "\tlist_for_each_entry_safe(attr, n, &fei_attr_list, list) {",
            "\t\tfei_attr_remove(attr);",
            "\t}",
            "}",
            "static ssize_t fei_write(struct file *file, const char __user *buffer,",
            "\t\t\t size_t count, loff_t *ppos)",
            "{",
            "\tstruct fei_attr *attr;",
            "\tunsigned long addr;",
            "\tchar *buf, *sym;",
            "\tint ret;",
            "",
            "\t/* cut off if it is too long */",
            "\tif (count > KSYM_NAME_LEN)",
            "\t\tcount = KSYM_NAME_LEN;",
            "",
            "\tbuf = memdup_user_nul(buffer, count);",
            "\tif (IS_ERR(buf))",
            "\t\treturn PTR_ERR(buf);",
            "",
            "\tsym = strstrip(buf);",
            "",
            "\tmutex_lock(&fei_lock);",
            "",
            "\t/* Writing just spaces will remove all injection points */",
            "\tif (sym[0] == '\\0') {",
            "\t\tfei_attr_remove_all();",
            "\t\tret = count;",
            "\t\tgoto out;",
            "\t}",
            "\t/* Writing !function will remove one injection point */",
            "\tif (sym[0] == '!') {",
            "\t\tattr = fei_attr_lookup(sym + 1);",
            "\t\tif (!attr) {",
            "\t\t\tret = -ENOENT;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t\tfei_attr_remove(attr);",
            "\t\tret = count;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\taddr = kallsyms_lookup_name(sym);",
            "\tif (!addr) {",
            "\t\tret = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "\tif (!within_error_injection_list(addr)) {",
            "\t\tret = -ERANGE;",
            "\t\tgoto out;",
            "\t}",
            "\tif (fei_attr_lookup(sym)) {",
            "\t\tret = -EBUSY;",
            "\t\tgoto out;",
            "\t}",
            "\tattr = fei_attr_new(sym, addr);",
            "\tif (!attr) {",
            "\t\tret = -ENOMEM;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tret = register_kprobe(&attr->kp);",
            "\tif (ret) {",
            "\t\tfei_attr_free(attr);",
            "\t\tgoto out;",
            "\t}",
            "\tfei_debugfs_add_attr(attr);",
            "\tlist_add_tail(&attr->list, &fei_attr_list);",
            "\tret = count;",
            "out:",
            "\tmutex_unlock(&fei_lock);",
            "\tkfree(buf);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "fei_kprobe_handler, fei_seq_stop, fei_seq_show, fei_open, fei_attr_remove, fei_attr_remove_all, fei_write",
          "description": "实现kprobe处理函数和序列化展示接口，支持动态添加/移除错误注入点并通过文件操作控制",
          "similarity": 0.4902038276195526
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/fail_function.c",
          "start_line": 17,
          "end_line": 117,
          "content": [
            "static void fei_post_handler(struct kprobe *kp, struct pt_regs *regs,",
            "\t\t\t     unsigned long flags)",
            "{",
            "\t/*",
            "\t * A dummy post handler is required to prohibit optimizing, because",
            "\t * jump optimization does not support execution path overriding.",
            "\t */",
            "}",
            "static unsigned long adjust_error_retval(unsigned long addr, unsigned long retv)",
            "{",
            "\tswitch (get_injectable_error_type(addr)) {",
            "\tcase EI_ETYPE_NULL:",
            "\t\treturn 0;",
            "\tcase EI_ETYPE_ERRNO:",
            "\t\tif (retv < (unsigned long)-MAX_ERRNO)",
            "\t\t\treturn (unsigned long)-EINVAL;",
            "\t\tbreak;",
            "\tcase EI_ETYPE_ERRNO_NULL:",
            "\t\tif (retv != 0 && retv < (unsigned long)-MAX_ERRNO)",
            "\t\t\treturn (unsigned long)-EINVAL;",
            "\t\tbreak;",
            "\tcase EI_ETYPE_TRUE:",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn retv;",
            "}",
            "static void fei_attr_free(struct fei_attr *attr)",
            "{",
            "\tif (attr) {",
            "\t\tkfree(attr->kp.symbol_name);",
            "\t\tkfree(attr);",
            "\t}",
            "}",
            "static bool fei_attr_is_valid(struct fei_attr *_attr)",
            "{",
            "\tstruct fei_attr *attr;",
            "",
            "\tlist_for_each_entry(attr, &fei_attr_list, list) {",
            "\t\tif (attr == _attr)",
            "\t\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static int fei_retval_set(void *data, u64 val)",
            "{",
            "\tstruct fei_attr *attr = data;",
            "\tunsigned long retv = (unsigned long)val;",
            "\tint err = 0;",
            "",
            "\tmutex_lock(&fei_lock);",
            "\t/*",
            "\t * Since this operation can be done after retval file is removed,",
            "\t * It is safer to check the attr is still valid before accessing",
            "\t * its member.",
            "\t */",
            "\tif (!fei_attr_is_valid(attr)) {",
            "\t\terr = -ENOENT;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (attr->kp.addr) {",
            "\t\tif (adjust_error_retval((unsigned long)attr->kp.addr,",
            "\t\t\t\t\tval) != retv)",
            "\t\t\terr = -EINVAL;",
            "\t}",
            "\tif (!err)",
            "\t\tattr->retval = val;",
            "out:",
            "\tmutex_unlock(&fei_lock);",
            "",
            "\treturn err;",
            "}",
            "static int fei_retval_get(void *data, u64 *val)",
            "{",
            "\tstruct fei_attr *attr = data;",
            "\tint err = 0;",
            "",
            "\tmutex_lock(&fei_lock);",
            "\t/* Here we also validate @attr to ensure it still exists. */",
            "\tif (!fei_attr_is_valid(attr))",
            "\t\terr = -ENOENT;",
            "\telse",
            "\t\t*val = attr->retval;",
            "\tmutex_unlock(&fei_lock);",
            "",
            "\treturn err;",
            "}",
            "static void fei_debugfs_add_attr(struct fei_attr *attr)",
            "{",
            "\tstruct dentry *dir;",
            "",
            "\tdir = debugfs_create_dir(attr->kp.symbol_name, fei_debugfs_dir);",
            "",
            "\tdebugfs_create_file(\"retval\", 0600, dir, attr, &fei_retval_ops);",
            "}",
            "static void fei_debugfs_remove_attr(struct fei_attr *attr)",
            "{",
            "\tdebugfs_lookup_and_remove(attr->kp.symbol_name, fei_debugfs_dir);",
            "}"
          ],
          "function_name": "fei_post_handler, adjust_error_retval, fei_attr_free, fei_attr_is_valid, fei_retval_set, fei_retval_get, fei_debugfs_add_attr, fei_debugfs_remove_attr",
          "description": "实现错误注入的核心逻辑，包括返回值调整、属性管理、debugfs接口创建及验证机制",
          "similarity": 0.47839587926864624
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/fail_function.c",
          "start_line": 1,
          "end_line": 16,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * fail_function.c: Function-based error injection",
            " */",
            "#include <linux/error-injection.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/module.h>",
            "#include <linux/mutex.h>",
            "#include <linux/slab.h>",
            "#include <linux/uaccess.h>",
            "",
            "static int fei_kprobe_handler(struct kprobe *kp, struct pt_regs *regs);",
            ""
          ],
          "function_name": null,
          "description": "定义错误注入模块所需头文件并声明kprobe处理函数，为后续错误注入功能提供基础支持",
          "similarity": 0.4434540867805481
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/fail_function.c",
          "start_line": 315,
          "end_line": 332,
          "content": [
            "static int __init fei_debugfs_init(void)",
            "{",
            "\tstruct dentry *dir;",
            "",
            "\tdir = fault_create_debugfs_attr(\"fail_function\", NULL,",
            "\t\t\t\t\t&fei_fault_attr);",
            "\tif (IS_ERR(dir))",
            "\t\treturn PTR_ERR(dir);",
            "",
            "\t/* injectable attribute is just a symlink of error_inject/list */",
            "\tdebugfs_create_symlink(\"injectable\", dir, \"../error_injection/list\");",
            "",
            "\tdebugfs_create_file(\"inject\", 0600, dir, NULL, &fei_ops);",
            "",
            "\tfei_debugfs_dir = dir;",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "fei_debugfs_init",
          "description": "初始化debugfs调试接口，创建错误注入配置文件和符号链接以供用户空间访问",
          "similarity": 0.420499324798584
        }
      ]
    }
  ]
}