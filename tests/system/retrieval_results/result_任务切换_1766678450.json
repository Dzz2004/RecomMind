{
  "query": "任务切换",
  "timestamp": "2025-12-26 00:00:50",
  "retrieved_files": [
    {
      "source_file": "kernel/livepatch/transition.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:34:51\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `livepatch\\transition.c`\n\n---\n\n# livepatch/transition.c 技术文档\n\n## 1. 文件概述\n\n`livepatch/transition.c` 是 Linux 内核实时补丁（Kernel Live Patching）子系统的核心组件之一，负责管理补丁状态转换过程。该文件实现了从旧代码到新补丁代码（或反向）的安全过渡机制，确保所有正在运行的任务（包括内核线程、用户态进程和 idle 线程）都能安全地切换到目标补丁状态，避免在函数栈中仍存在待替换函数时进行切换，从而防止系统崩溃或行为异常。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `klp_transition_patch`：指向当前正在进行状态转换的补丁对象。\n- `klp_target_state`：目标补丁状态（`KLP_PATCHED` 或 `KLP_UNPATCHED`），初始为 `KLP_UNDEFINED`。\n- `klp_signals_cnt`：用于统计信号处理相关计数（当前未在代码片段中完整使用）。\n- `klp_stack_entries`：每 CPU 栈追踪缓冲区，用于保存任务调用栈。\n\n### 主要函数\n- `klp_transition_work_fn()`：延迟工作队列回调，用于重试未能完成转换的“滞留”任务。\n- `klp_synchronize_transition()`：强制在所有 CPU 上执行调度同步，确保 RCU 不可见区域也能完成同步。\n- `klp_complete_transition()`：完成整个补丁状态转换，清理数据结构并调用回调。\n- `klp_cancel_transition()`：在转换开始前取消补丁操作。\n- `klp_update_patch_state()`：更新指定任务的补丁状态。\n- `klp_check_stack_func()`：检查给定函数是否出现在栈追踪中。\n- `klp_check_stack()`：检查任务栈中是否存在待替换/待移除的函数（代码片段中被截断）。\n\n### 静态键与调度集成\n- 在支持 `CONFIG_PREEMPT_DYNAMIC` 的系统上，通过 `sched_dynamic_klp_enable/disable()` 启用/禁用 cond_resched 中的栈检查。\n- 否则使用静态键 `klp_sched_try_switch_key` 控制是否在 `cond_resched()` 中进行补丁栈检查，以帮助 CPU 密集型内核线程完成补丁切换。\n\n## 3. 关键实现\n\n### 补丁状态转换流程\n1. **初始化阶段**：设置 `klp_transition_patch` 和 `klp_target_state`。\n2. **任务状态更新**：通过 `TIF_PATCH_PENDING` 标志标记需要更新状态的任务。\n3. **栈安全检查**：使用 `stack_trace_save_tsk_reliable()` 获取可靠栈追踪，检查是否存在待替换函数。\n4. **同步机制**：\n   - 使用 `klp_synchronize_transition()` 调用 `schedule_on_each_cpu(klp_sync)`，强制所有 CPU（包括 idle 和用户态）参与同步。\n   - 此机制绕过标准 RCU，适用于 RCU 不活跃的上下文（如 `user_exit()` 前）。\n5. **完成清理**：\n   - 清除所有任务的 `patch_state` 为 `KLP_UNDEFINED`。\n   - 调用对象级的 `post_patch` 或 `post_unpatch` 回调。\n   - 重置全局状态变量。\n\n### 栈检查逻辑\n- **打补丁时（KLP_PATCHED）**：检查栈中是否包含**旧函数**（原始函数或上一个补丁版本的函数）。\n- **卸补丁时（KLP_UNPATCHED）**：检查栈中是否包含**新函数**（当前补丁中的函数）。\n- 若发现相关函数在栈中，则返回 `-EAGAIN`，推迟该任务的状态切换。\n\n### 内存屏障与并发控制\n- `test_and_clear_tsk_thread_flag()` 不仅清除 `TIF_PATCH_PENDING`，还充当读屏障（`smp_rmb`），确保：\n  1. `klp_target_state` 的读取顺序正确。\n  2. 后续 `klp_ftrace_handler()` 能看到一致的 `func->transition` 状态。\n\n### 滞留任务处理\n- 通过 `DECLARE_DELAYED_WORK(klp_transition_work, ...)` 定期重试未能完成转换的任务，提高转换成功率。\n\n## 4. 依赖关系\n\n- **内部依赖**：\n  - `core.h`：提供 `klp_mutex`、`klp_for_each_object/func` 等核心宏和函数。\n  - `patch.h`：定义 `klp_func`、`klp_object`、`klp_patch` 等数据结构及操作函数（如 `klp_unpatch_objects`）。\n  - `transition.h`：声明本文件导出的接口（如 `klp_cancel_transition`）。\n- **内核子系统**：\n  - **RCU**：用于常规同步，但在 RCU 不活跃区域使用自定义同步。\n  - **调度器**：通过 `cond_resched()` 集成补丁检查，依赖 `CONFIG_PREEMPT_DYNAMIC` 或静态键。\n  - **栈追踪**：使用 `stack_trace_save_tsk_reliable()` 获取可靠调用栈。\n  - **CPU 热插拔**：通过 `for_each_possible_cpu` 处理所有可能的 CPU（包括离线 CPU 的 idle 任务）。\n\n## 5. 使用场景\n\n- **应用实时补丁**：当管理员通过 sysfs 启用一个 livepatch 模块时，内核调用此文件中的函数将所有任务从旧代码切换到新补丁代码。\n- **卸载实时补丁**：当禁用补丁时，安全地将所有任务切换回旧函数，并清理补丁数据结构。\n- **处理滞留任务**：对于因长时间运行或处于不可中断状态而未能及时切换的任务，通过延迟工作队列周期性重试。\n- **支持特殊上下文**：确保在 RCU 不活跃的上下文（如系统调用入口/出口、idle 循环）中也能安全完成补丁切换。\n- **错误恢复**：在补丁初始化后、实际切换前发生错误时，调用 `klp_cancel_transition()` 安全回滚。",
      "similarity": 0.5913381576538086,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/livepatch/transition.c",
          "start_line": 214,
          "end_line": 352,
          "content": [
            "static int klp_check_stack_func(struct klp_func *func, unsigned long *entries,",
            "\t\t\t\tunsigned int nr_entries)",
            "{",
            "\tunsigned long func_addr, func_size, address;",
            "\tstruct klp_ops *ops;",
            "\tint i;",
            "",
            "\tif (klp_target_state == KLP_UNPATCHED) {",
            "\t\t /*",
            "\t\t  * Check for the to-be-unpatched function",
            "\t\t  * (the func itself).",
            "\t\t  */",
            "\t\tfunc_addr = (unsigned long)func->new_func;",
            "\t\tfunc_size = func->new_size;",
            "\t} else {",
            "\t\t/*",
            "\t\t * Check for the to-be-patched function",
            "\t\t * (the previous func).",
            "\t\t */",
            "\t\tops = klp_find_ops(func->old_func);",
            "",
            "\t\tif (list_is_singular(&ops->func_stack)) {",
            "\t\t\t/* original function */",
            "\t\t\tfunc_addr = (unsigned long)func->old_func;",
            "\t\t\tfunc_size = func->old_size;",
            "\t\t} else {",
            "\t\t\t/* previously patched function */",
            "\t\t\tstruct klp_func *prev;",
            "",
            "\t\t\tprev = list_next_entry(func, stack_node);",
            "\t\t\tfunc_addr = (unsigned long)prev->new_func;",
            "\t\t\tfunc_size = prev->new_size;",
            "\t\t}",
            "\t}",
            "",
            "\tfor (i = 0; i < nr_entries; i++) {",
            "\t\taddress = entries[i];",
            "",
            "\t\tif (address >= func_addr && address < func_addr + func_size)",
            "\t\t\treturn -EAGAIN;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int klp_check_stack(struct task_struct *task, const char **oldname)",
            "{",
            "\tunsigned long *entries = this_cpu_ptr(klp_stack_entries);",
            "\tstruct klp_object *obj;",
            "\tstruct klp_func *func;",
            "\tint ret, nr_entries;",
            "",
            "\t/* Protect 'klp_stack_entries' */",
            "\tlockdep_assert_preemption_disabled();",
            "",
            "\tret = stack_trace_save_tsk_reliable(task, entries, MAX_STACK_ENTRIES);",
            "\tif (ret < 0)",
            "\t\treturn -EINVAL;",
            "\tnr_entries = ret;",
            "",
            "\tklp_for_each_object(klp_transition_patch, obj) {",
            "\t\tif (!obj->patched)",
            "\t\t\tcontinue;",
            "\t\tklp_for_each_func(obj, func) {",
            "\t\t\tret = klp_check_stack_func(func, entries, nr_entries);",
            "\t\t\tif (ret) {",
            "\t\t\t\t*oldname = func->old_name;",
            "\t\t\t\treturn -EADDRINUSE;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int klp_check_and_switch_task(struct task_struct *task, void *arg)",
            "{",
            "\tint ret;",
            "",
            "\tif (task_curr(task) && task != current)",
            "\t\treturn -EBUSY;",
            "",
            "\tret = klp_check_stack(task, arg);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tclear_tsk_thread_flag(task, TIF_PATCH_PENDING);",
            "\ttask->patch_state = klp_target_state;",
            "\treturn 0;",
            "}",
            "static bool klp_try_switch_task(struct task_struct *task)",
            "{",
            "\tconst char *old_name;",
            "\tint ret;",
            "",
            "\t/* check if this task has already switched over */",
            "\tif (task->patch_state == klp_target_state)",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * For arches which don't have reliable stack traces, we have to rely",
            "\t * on other methods (e.g., switching tasks at kernel exit).",
            "\t */",
            "\tif (!klp_have_reliable_stack())",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Now try to check the stack for any to-be-patched or to-be-unpatched",
            "\t * functions.  If all goes well, switch the task to the target patch",
            "\t * state.",
            "\t */",
            "\tif (task == current)",
            "\t\tret = klp_check_and_switch_task(current, &old_name);",
            "\telse",
            "\t\tret = task_call_func(task, klp_check_and_switch_task, &old_name);",
            "",
            "\tswitch (ret) {",
            "\tcase 0:\t\t/* success */",
            "\t\tbreak;",
            "",
            "\tcase -EBUSY:\t/* klp_check_and_switch_task() */",
            "\t\tpr_debug(\"%s: %s:%d is running\\n\",",
            "\t\t\t __func__, task->comm, task->pid);",
            "\t\tbreak;",
            "\tcase -EINVAL:\t/* klp_check_and_switch_task() */",
            "\t\tpr_debug(\"%s: %s:%d has an unreliable stack\\n\",",
            "\t\t\t __func__, task->comm, task->pid);",
            "\t\tbreak;",
            "\tcase -EADDRINUSE: /* klp_check_and_switch_task() */",
            "\t\tpr_debug(\"%s: %s:%d is sleeping on function %s\\n\",",
            "\t\t\t __func__, task->comm, task->pid, old_name);",
            "\t\tbreak;",
            "",
            "\tdefault:",
            "\t\tpr_debug(\"%s: Unknown error code (%d) when trying to switch %s:%d\\n\",",
            "\t\t\t __func__, ret, task->comm, task->pid);",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn !ret;",
            "}"
          ],
          "function_name": "klp_check_stack_func, klp_check_stack, klp_check_and_switch_task, klp_try_switch_task",
          "description": "提供堆栈检查与任务状态切换机制，验证当前线程堆栈中是否包含待修改函数地址，确保安全切换到目标补丁状态",
          "similarity": 0.6583077907562256
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/livepatch/transition.c",
          "start_line": 366,
          "end_line": 509,
          "content": [
            "void __klp_sched_try_switch(void)",
            "{",
            "\tif (likely(!klp_patch_pending(current)))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * This function is called from cond_resched() which is called in many",
            "\t * places throughout the kernel.  Using the klp_mutex here might",
            "\t * deadlock.",
            "\t *",
            "\t * Instead, disable preemption to prevent racing with other callers of",
            "\t * klp_try_switch_task().  Thanks to task_call_func() they won't be",
            "\t * able to switch this task while it's running.",
            "\t */",
            "\tpreempt_disable();",
            "",
            "\t/*",
            "\t * Make sure current didn't get patched between the above check and",
            "\t * preempt_disable().",
            "\t */",
            "\tif (unlikely(!klp_patch_pending(current)))",
            "\t\tgoto out;",
            "",
            "\t/*",
            "\t * Enforce the order of the TIF_PATCH_PENDING read above and the",
            "\t * klp_target_state read in klp_try_switch_task().  The corresponding",
            "\t * write barriers are in klp_init_transition() and",
            "\t * klp_reverse_transition().",
            "\t */",
            "\tsmp_rmb();",
            "",
            "\tklp_try_switch_task(current);",
            "",
            "out:",
            "\tpreempt_enable();",
            "}",
            "static void klp_send_signals(void)",
            "{",
            "\tstruct task_struct *g, *task;",
            "",
            "\tif (klp_signals_cnt == SIGNALS_TIMEOUT)",
            "\t\tpr_notice(\"signaling remaining tasks\\n\");",
            "",
            "\tread_lock(&tasklist_lock);",
            "\tfor_each_process_thread(g, task) {",
            "\t\tif (!klp_patch_pending(task))",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * There is a small race here. We could see TIF_PATCH_PENDING",
            "\t\t * set and decide to wake up a kthread or send a fake signal.",
            "\t\t * Meanwhile the task could migrate itself and the action",
            "\t\t * would be meaningless. It is not serious though.",
            "\t\t */",
            "\t\tif (task->flags & PF_KTHREAD) {",
            "\t\t\t/*",
            "\t\t\t * Wake up a kthread which sleeps interruptedly and",
            "\t\t\t * still has not been migrated.",
            "\t\t\t */",
            "\t\t\twake_up_state(task, TASK_INTERRUPTIBLE);",
            "\t\t} else {",
            "\t\t\t/*",
            "\t\t\t * Send fake signal to all non-kthread tasks which are",
            "\t\t\t * still not migrated.",
            "\t\t\t */",
            "\t\t\tset_notify_signal(task);",
            "\t\t}",
            "\t}",
            "\tread_unlock(&tasklist_lock);",
            "}",
            "void klp_try_complete_transition(void)",
            "{",
            "\tunsigned int cpu;",
            "\tstruct task_struct *g, *task;",
            "\tstruct klp_patch *patch;",
            "\tbool complete = true;",
            "",
            "\tWARN_ON_ONCE(klp_target_state == KLP_UNDEFINED);",
            "",
            "\t/*",
            "\t * Try to switch the tasks to the target patch state by walking their",
            "\t * stacks and looking for any to-be-patched or to-be-unpatched",
            "\t * functions.  If such functions are found on a stack, or if the stack",
            "\t * is deemed unreliable, the task can't be switched yet.",
            "\t *",
            "\t * Usually this will transition most (or all) of the tasks on a system",
            "\t * unless the patch includes changes to a very common function.",
            "\t */",
            "\tread_lock(&tasklist_lock);",
            "\tfor_each_process_thread(g, task)",
            "\t\tif (!klp_try_switch_task(task))",
            "\t\t\tcomplete = false;",
            "\tread_unlock(&tasklist_lock);",
            "",
            "\t/*",
            "\t * Ditto for the idle \"swapper\" tasks.",
            "\t */",
            "\tcpus_read_lock();",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\ttask = idle_task(cpu);",
            "\t\tif (cpu_online(cpu)) {",
            "\t\t\tif (!klp_try_switch_task(task)) {",
            "\t\t\t\tcomplete = false;",
            "\t\t\t\t/* Make idle task go through the main loop. */",
            "\t\t\t\twake_up_if_idle(cpu);",
            "\t\t\t}",
            "\t\t} else if (task->patch_state != klp_target_state) {",
            "\t\t\t/* offline idle tasks can be switched immediately */",
            "\t\t\tclear_tsk_thread_flag(task, TIF_PATCH_PENDING);",
            "\t\t\ttask->patch_state = klp_target_state;",
            "\t\t}",
            "\t}",
            "\tcpus_read_unlock();",
            "",
            "\tif (!complete) {",
            "\t\tif (klp_signals_cnt && !(klp_signals_cnt % SIGNALS_TIMEOUT))",
            "\t\t\tklp_send_signals();",
            "\t\tklp_signals_cnt++;",
            "",
            "\t\t/*",
            "\t\t * Some tasks weren't able to be switched over.  Try again",
            "\t\t * later and/or wait for other methods like kernel exit",
            "\t\t * switching.",
            "\t\t */",
            "\t\tschedule_delayed_work(&klp_transition_work,",
            "\t\t\t\t      round_jiffies_relative(HZ));",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* Done!  Now cleanup the data structures. */",
            "\tklp_cond_resched_disable();",
            "\tpatch = klp_transition_patch;",
            "\tklp_complete_transition();",
            "",
            "\t/*",
            "\t * It would make more sense to free the unused patches in",
            "\t * klp_complete_transition() but it is called also",
            "\t * from klp_cancel_transition().",
            "\t */",
            "\tif (!patch->enabled)",
            "\t\tklp_free_patch_async(patch);",
            "\telse if (patch->replace)",
            "\t\tklp_free_replaced_patches_async(patch);",
            "}"
          ],
          "function_name": "__klp_sched_try_switch, klp_send_signals, klp_try_complete_transition",
          "description": "调度器层面的过渡辅助函数，通过禁止抢占防止竞态条件，并向未迁移任务发送信号触发上下文切换以完成补丁应用",
          "similarity": 0.6542930603027344
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/livepatch/transition.c",
          "start_line": 530,
          "end_line": 634,
          "content": [
            "void klp_start_transition(void)",
            "{",
            "\tstruct task_struct *g, *task;",
            "\tunsigned int cpu;",
            "",
            "\tWARN_ON_ONCE(klp_target_state == KLP_UNDEFINED);",
            "",
            "\tpr_notice(\"'%s': starting %s transition\\n\",",
            "\t\t  klp_transition_patch->mod->name,",
            "\t\t  klp_target_state == KLP_PATCHED ? \"patching\" : \"unpatching\");",
            "",
            "\t/*",
            "\t * Mark all normal tasks as needing a patch state update.  They'll",
            "\t * switch either in klp_try_complete_transition() or as they exit the",
            "\t * kernel.",
            "\t */",
            "\tread_lock(&tasklist_lock);",
            "\tfor_each_process_thread(g, task)",
            "\t\tif (task->patch_state != klp_target_state)",
            "\t\t\tset_tsk_thread_flag(task, TIF_PATCH_PENDING);",
            "\tread_unlock(&tasklist_lock);",
            "",
            "\t/*",
            "\t * Mark all idle tasks as needing a patch state update.  They'll switch",
            "\t * either in klp_try_complete_transition() or at the idle loop switch",
            "\t * point.",
            "\t */",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\ttask = idle_task(cpu);",
            "\t\tif (task->patch_state != klp_target_state)",
            "\t\t\tset_tsk_thread_flag(task, TIF_PATCH_PENDING);",
            "\t}",
            "",
            "\tklp_cond_resched_enable();",
            "",
            "\tklp_signals_cnt = 0;",
            "}",
            "void klp_init_transition(struct klp_patch *patch, int state)",
            "{",
            "\tstruct task_struct *g, *task;",
            "\tunsigned int cpu;",
            "\tstruct klp_object *obj;",
            "\tstruct klp_func *func;",
            "\tint initial_state = !state;",
            "",
            "\tWARN_ON_ONCE(klp_target_state != KLP_UNDEFINED);",
            "",
            "\tklp_transition_patch = patch;",
            "",
            "\t/*",
            "\t * Set the global target patch state which tasks will switch to.  This",
            "\t * has no effect until the TIF_PATCH_PENDING flags get set later.",
            "\t */",
            "\tklp_target_state = state;",
            "",
            "\tpr_debug(\"'%s': initializing %s transition\\n\", patch->mod->name,",
            "\t\t klp_target_state == KLP_PATCHED ? \"patching\" : \"unpatching\");",
            "",
            "\t/*",
            "\t * Initialize all tasks to the initial patch state to prepare them for",
            "\t * switching to the target state.",
            "\t */",
            "\tread_lock(&tasklist_lock);",
            "\tfor_each_process_thread(g, task) {",
            "\t\tWARN_ON_ONCE(task->patch_state != KLP_UNDEFINED);",
            "\t\ttask->patch_state = initial_state;",
            "\t}",
            "\tread_unlock(&tasklist_lock);",
            "",
            "\t/*",
            "\t * Ditto for the idle \"swapper\" tasks.",
            "\t */",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\ttask = idle_task(cpu);",
            "\t\tWARN_ON_ONCE(task->patch_state != KLP_UNDEFINED);",
            "\t\ttask->patch_state = initial_state;",
            "\t}",
            "",
            "\t/*",
            "\t * Enforce the order of the task->patch_state initializations and the",
            "\t * func->transition updates to ensure that klp_ftrace_handler() doesn't",
            "\t * see a func in transition with a task->patch_state of KLP_UNDEFINED.",
            "\t *",
            "\t * Also enforce the order of the klp_target_state write and future",
            "\t * TIF_PATCH_PENDING writes to ensure klp_update_patch_state() and",
            "\t * __klp_sched_try_switch() don't set a task->patch_state to",
            "\t * KLP_UNDEFINED.",
            "\t */",
            "\tsmp_wmb();",
            "",
            "\t/*",
            "\t * Set the func transition states so klp_ftrace_handler() will know to",
            "\t * switch to the transition logic.",
            "\t *",
            "\t * When patching, the funcs aren't yet in the func_stack and will be",
            "\t * made visible to the ftrace handler shortly by the calls to",
            "\t * klp_patch_object().",
            "\t *",
            "\t * When unpatching, the funcs are already in the func_stack and so are",
            "\t * already visible to the ftrace handler.",
            "\t */",
            "\tklp_for_each_object(patch, obj)",
            "\t\tklp_for_each_func(obj, func)",
            "\t\t\tfunc->transition = true;",
            "}"
          ],
          "function_name": "klp_start_transition, klp_init_transition",
          "description": "初始化热补丁过渡阶段，设置全局目标状态并批量标记所有任务需更新补丁状态，通过内存屏障保证状态更新顺序性",
          "similarity": 0.5986759662628174
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/livepatch/transition.c",
          "start_line": 53,
          "end_line": 172,
          "content": [
            "static void klp_transition_work_fn(struct work_struct *work)",
            "{",
            "\tmutex_lock(&klp_mutex);",
            "",
            "\tif (klp_transition_patch)",
            "\t\tklp_try_complete_transition();",
            "",
            "\tmutex_unlock(&klp_mutex);",
            "}",
            "static void klp_sync(struct work_struct *work)",
            "{",
            "}",
            "static void klp_synchronize_transition(void)",
            "{",
            "\tschedule_on_each_cpu(klp_sync);",
            "}",
            "static void klp_complete_transition(void)",
            "{",
            "\tstruct klp_object *obj;",
            "\tstruct klp_func *func;",
            "\tstruct task_struct *g, *task;",
            "\tunsigned int cpu;",
            "",
            "\tpr_debug(\"'%s': completing %s transition\\n\",",
            "\t\t klp_transition_patch->mod->name,",
            "\t\t klp_target_state == KLP_PATCHED ? \"patching\" : \"unpatching\");",
            "",
            "\tif (klp_transition_patch->replace && klp_target_state == KLP_PATCHED) {",
            "\t\tklp_unpatch_replaced_patches(klp_transition_patch);",
            "\t\tklp_discard_nops(klp_transition_patch);",
            "\t}",
            "",
            "\tif (klp_target_state == KLP_UNPATCHED) {",
            "\t\t/*",
            "\t\t * All tasks have transitioned to KLP_UNPATCHED so we can now",
            "\t\t * remove the new functions from the func_stack.",
            "\t\t */",
            "\t\tklp_unpatch_objects(klp_transition_patch);",
            "",
            "\t\t/*",
            "\t\t * Make sure klp_ftrace_handler() can no longer see functions",
            "\t\t * from this patch on the ops->func_stack.  Otherwise, after",
            "\t\t * func->transition gets cleared, the handler may choose a",
            "\t\t * removed function.",
            "\t\t */",
            "\t\tklp_synchronize_transition();",
            "\t}",
            "",
            "\tklp_for_each_object(klp_transition_patch, obj)",
            "\t\tklp_for_each_func(obj, func)",
            "\t\t\tfunc->transition = false;",
            "",
            "\t/* Prevent klp_ftrace_handler() from seeing KLP_UNDEFINED state */",
            "\tif (klp_target_state == KLP_PATCHED)",
            "\t\tklp_synchronize_transition();",
            "",
            "\tread_lock(&tasklist_lock);",
            "\tfor_each_process_thread(g, task) {",
            "\t\tWARN_ON_ONCE(test_tsk_thread_flag(task, TIF_PATCH_PENDING));",
            "\t\ttask->patch_state = KLP_UNDEFINED;",
            "\t}",
            "\tread_unlock(&tasklist_lock);",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\ttask = idle_task(cpu);",
            "\t\tWARN_ON_ONCE(test_tsk_thread_flag(task, TIF_PATCH_PENDING));",
            "\t\ttask->patch_state = KLP_UNDEFINED;",
            "\t}",
            "",
            "\tklp_for_each_object(klp_transition_patch, obj) {",
            "\t\tif (!klp_is_object_loaded(obj))",
            "\t\t\tcontinue;",
            "\t\tif (klp_target_state == KLP_PATCHED)",
            "\t\t\tklp_post_patch_callback(obj);",
            "\t\telse if (klp_target_state == KLP_UNPATCHED)",
            "\t\t\tklp_post_unpatch_callback(obj);",
            "\t}",
            "",
            "\tpr_notice(\"'%s': %s complete\\n\", klp_transition_patch->mod->name,",
            "\t\t  klp_target_state == KLP_PATCHED ? \"patching\" : \"unpatching\");",
            "",
            "\tklp_target_state = KLP_UNDEFINED;",
            "\tklp_transition_patch = NULL;",
            "}",
            "void klp_cancel_transition(void)",
            "{",
            "\tif (WARN_ON_ONCE(klp_target_state != KLP_PATCHED))",
            "\t\treturn;",
            "",
            "\tpr_debug(\"'%s': canceling patching transition, going to unpatch\\n\",",
            "\t\t klp_transition_patch->mod->name);",
            "",
            "\tklp_target_state = KLP_UNPATCHED;",
            "\tklp_complete_transition();",
            "}",
            "void klp_update_patch_state(struct task_struct *task)",
            "{",
            "\t/*",
            "\t * A variant of synchronize_rcu() is used to allow patching functions",
            "\t * where RCU is not watching, see klp_synchronize_transition().",
            "\t */",
            "\tpreempt_disable_notrace();",
            "",
            "\t/*",
            "\t * This test_and_clear_tsk_thread_flag() call also serves as a read",
            "\t * barrier (smp_rmb) for two cases:",
            "\t *",
            "\t * 1) Enforce the order of the TIF_PATCH_PENDING read and the",
            "\t *    klp_target_state read.  The corresponding write barriers are in",
            "\t *    klp_init_transition() and klp_reverse_transition().",
            "\t *",
            "\t * 2) Enforce the order of the TIF_PATCH_PENDING read and a future read",
            "\t *    of func->transition, if klp_ftrace_handler() is called later on",
            "\t *    the same CPU.  See __klp_disable_patch().",
            "\t */",
            "\tif (test_and_clear_tsk_thread_flag(task, TIF_PATCH_PENDING))",
            "\t\ttask->patch_state = READ_ONCE(klp_target_state);",
            "",
            "\tpreempt_enable_notrace();",
            "}"
          ],
          "function_name": "klp_transition_work_fn, klp_sync, klp_synchronize_transition, klp_complete_transition, klp_cancel_transition, klp_update_patch_state",
          "description": "实现热补丁过渡的核心协程逻辑，包含任务状态同步、补丁完成处理、取消操作及状态更新，通过循环遍历进程和空闲任务确保全部迁移",
          "similarity": 0.588379979133606
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/livepatch/transition.c",
          "start_line": 648,
          "end_line": 740,
          "content": [
            "void klp_reverse_transition(void)",
            "{",
            "\tunsigned int cpu;",
            "\tstruct task_struct *g, *task;",
            "",
            "\tpr_debug(\"'%s': reversing transition from %s\\n\",",
            "\t\t klp_transition_patch->mod->name,",
            "\t\t klp_target_state == KLP_PATCHED ? \"patching to unpatching\" :",
            "\t\t\t\t\t\t   \"unpatching to patching\");",
            "",
            "\t/*",
            "\t * Clear all TIF_PATCH_PENDING flags to prevent races caused by",
            "\t * klp_update_patch_state() or __klp_sched_try_switch() running in",
            "\t * parallel with the reverse transition.",
            "\t */",
            "\tread_lock(&tasklist_lock);",
            "\tfor_each_process_thread(g, task)",
            "\t\tclear_tsk_thread_flag(task, TIF_PATCH_PENDING);",
            "\tread_unlock(&tasklist_lock);",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tclear_tsk_thread_flag(idle_task(cpu), TIF_PATCH_PENDING);",
            "",
            "\t/*",
            "\t * Make sure all existing invocations of klp_update_patch_state() and",
            "\t * __klp_sched_try_switch() see the cleared TIF_PATCH_PENDING before",
            "\t * starting the reverse transition.",
            "\t */",
            "\tklp_synchronize_transition();",
            "",
            "\t/*",
            "\t * All patching has stopped, now re-initialize the global variables to",
            "\t * prepare for the reverse transition.",
            "\t */",
            "\tklp_transition_patch->enabled = !klp_transition_patch->enabled;",
            "\tklp_target_state = !klp_target_state;",
            "",
            "\t/*",
            "\t * Enforce the order of the klp_target_state write and the",
            "\t * TIF_PATCH_PENDING writes in klp_start_transition() to ensure",
            "\t * klp_update_patch_state() and __klp_sched_try_switch() don't set",
            "\t * task->patch_state to the wrong value.",
            "\t */",
            "\tsmp_wmb();",
            "",
            "\tklp_start_transition();",
            "}",
            "void klp_copy_process(struct task_struct *child)",
            "{",
            "",
            "\t/*",
            "\t * The parent process may have gone through a KLP transition since",
            "\t * the thread flag was copied in setup_thread_stack earlier. Bring",
            "\t * the task flag up to date with the parent here.",
            "\t *",
            "\t * The operation is serialized against all klp_*_transition()",
            "\t * operations by the tasklist_lock. The only exceptions are",
            "\t * klp_update_patch_state(current) and __klp_sched_try_switch(), but we",
            "\t * cannot race with them because we are current.",
            "\t */",
            "\tif (test_tsk_thread_flag(current, TIF_PATCH_PENDING))",
            "\t\tset_tsk_thread_flag(child, TIF_PATCH_PENDING);",
            "\telse",
            "\t\tclear_tsk_thread_flag(child, TIF_PATCH_PENDING);",
            "",
            "\tchild->patch_state = current->patch_state;",
            "}",
            "void klp_force_transition(void)",
            "{",
            "\tstruct klp_patch *patch;",
            "\tstruct task_struct *g, *task;",
            "\tunsigned int cpu;",
            "",
            "\tpr_warn(\"forcing remaining tasks to the patched state\\n\");",
            "",
            "\tread_lock(&tasklist_lock);",
            "\tfor_each_process_thread(g, task)",
            "\t\tklp_update_patch_state(task);",
            "\tread_unlock(&tasklist_lock);",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tklp_update_patch_state(idle_task(cpu));",
            "",
            "\t/* Set forced flag for patches being removed. */",
            "\tif (klp_target_state == KLP_UNPATCHED)",
            "\t\tklp_transition_patch->forced = true;",
            "\telse if (klp_transition_patch->replace) {",
            "\t\tklp_for_each_patch(patch) {",
            "\t\t\tif (patch != klp_transition_patch)",
            "\t\t\t\tpatch->forced = true;",
            "\t\t}",
            "\t}",
            "}"
          ],
          "function_name": "klp_reverse_transition, klp_copy_process, klp_force_transition",
          "description": "该代码段实现Live Patching框架中的状态转换控制逻辑。  \n`klp_reverse_transition`负责反向转换补丁状态，清除所有任务的TIF_PATCH_PENDING标志并切换全局状态后启动反向迁移；`klp_copy_process`在进程复制时同步父进程的补丁状态标志；`klp_force_transition`强制将剩余任务设为目标状态，并标记待移除补丁的强制属性。  \n\n注：代码依赖`klp_transition_patch`、`klp_target_state`等全局变量及`tasklist_lock`等上下文，此处仅展示部分实现。",
          "similarity": 0.583881139755249
        }
      ]
    },
    {
      "source_file": "kernel/task_work.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:33:42\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `task_work.c`\n\n---\n\n# task_work.c 技术文档\n\n## 文件概述\n\n`task_work.c` 实现了 Linux 内核中的 **任务工作（task work）机制**，允许内核在特定时机（如任务返回用户态、收到信号或处于 NMI 上下文）异步执行回调函数。该机制主要用于在不阻塞当前执行路径的前提下，将工作延迟到目标任务的合适上下文中执行，常用于安全模块（如 seccomp）、用户态通知、延迟清理等场景。\n\n任务工作队列是 **LIFO（后进先出）** 的，且不保证多个工作项之间的执行顺序。该机制支持多种通知模式，以适应不同的延迟和中断需求。\n\n## 核心功能\n\n### 主要函数\n\n| 函数 | 功能描述 |\n|------|--------|\n| `task_work_add()` | 向指定任务添加一个回调工作项，并根据通知模式触发相应通知 |\n| `task_work_run()` | 执行当前任务的所有挂起工作项，通常在返回用户态或任务退出前调用 |\n| `task_work_cancel_match()` | 根据自定义匹配函数取消队列中的某个工作项 |\n| `task_work_cancel_func()` | 取消队列中第一个函数指针匹配指定函数的工作项 |\n| `task_work_cancel()` | 取消队列中指定的回调结构体（精确匹配指针） |\n\n### 主要数据结构\n\n- `struct callback_head`：通用回调结构体，包含 `next` 指针和 `func` 回调函数指针。\n- `enum task_work_notify_mode`：通知模式枚举，包括：\n  - `TWA_NONE`：不通知\n  - `TWA_RESUME`：在任务返回用户态或进入 guest 模式前执行\n  - `TWA_SIGNAL`：类似信号，可中断内核态任务并立即调度执行\n  - `TWA_SIGNAL_NO_IPI`：类似 `TWA_SIGNAL`，但不发送 IPI 强制重调度\n  - `TWA_NMI_CURRENT`：仅用于当前任务且在 NMI 上下文中，通过 IRQ work 触发\n\n### 全局变量\n\n- `work_exited`：特殊标记，表示任务已退出，不能再接受新工作。\n- `irq_work_NMI_resume`（per-CPU）：用于 `TWA_NMI_CURRENT` 模式下触发 `TIF_NOTIFY_RESUME` 标志。\n\n## 关键实现\n\n### 1. 无锁队列插入（LIFO）\n\n`task_work_add()` 使用 `try_cmpxchg()` 原子操作将新工作项插入到 `task->task_works` 链表头部，实现无锁并发插入。若发现 `task_works == &work_exited`，说明任务正在退出，返回 `-ESRCH`。\n\n### 2. 多种通知机制\n\n- **`TWA_RESUME`**：调用 `set_notify_resume(task)`，设置 `TIF_NOTIFY_RESUME` 标志，确保任务在 `exit_to_user_mode()` 路径中调用 `task_work_run()`。\n- **`TWA_SIGNAL` / `TWA_SIGNAL_NO_IPI`**：分别调用 `set_notify_signal()` 和 `__set_notify_signal()`，设置 `TIF_NOTIFY_SIGNAL` 标志，并可能发送 IPI 强制目标 CPU 重调度。\n- **`TWA_NMI_CURRENT`**：在 NMI 上下文中，通过 per-CPU 的 `irq_work` 触发软中断，在 IRQ 上下文中设置 `TIF_NOTIFY_RESUME`。\n\n### 3. 安全退出处理\n\n`task_work_run()` 在循环中：\n- 原子地将 `task_works` 置为 `NULL`（或 `&work_exited`，若任务正在退出）。\n- 若任务正在退出（`PF_EXITING`），则标记为 `work_exited`，防止后续 `task_work_add()` 成功。\n- 执行所有取出的工作项，每个 `work->func(work)` 可能再次调用 `task_work_add()`，因此需循环处理。\n\n### 4. 并发取消机制\n\n`task_work_cancel_match()` 使用 `task->pi_lock` 保护遍历和删除操作：\n- 遍历链表查找匹配项。\n- 使用 `try_cmpxchg()` 原子地移除节点，避免与 `task_work_add()` 或 `task_work_run()` 冲突。\n- 特别地，`task_work_run()` 在执行前会短暂获取 `pi_lock`，确保取消操作不会在执行过程中移除正在运行的工作项。\n\n### 5. KASAN 辅助栈记录\n\n在 `task_work_add()` 中，根据 `TWAF_NO_ALLOC` 标志调用 `kasan_record_aux_stack()` 或 `kasan_record_aux_stack_noalloc()`，用于在 KASAN 报告中显示工作项的分配调用栈。\n\n## 依赖关系\n\n- **`<linux/irq_work.h>`**：提供 `irq_work` 机制，用于 `TWA_NMI_CURRENT` 模式。\n- **`<linux/resume_user_mode.h>`**：提供 `set_notify_resume()` 等接口，用于在返回用户态时触发回调。\n- **`<linux/spinlock.h>`**：使用 `raw_spinlock_t`（`pi_lock`）保护取消操作。\n- **`<linux/task_work.h>`**：定义 `task_work_notify_mode`、`callback_head` 等核心类型。\n- **调度子系统**：依赖 `TIF_NOTIFY_RESUME` / `TIF_NOTIFY_SIGNAL` 标志位，在调度路径中调用 `task_work_run()`。\n- **KASAN**：集成内存错误检测的调用栈记录功能。\n\n## 使用场景\n\n1. **Seccomp 通知**：当 seccomp 策略需要异步通知用户态代理时，通过 `task_work_add()` 添加回调。\n2. **用户态延迟操作**：内核模块需要在任务下次返回用户态时执行清理或通知，使用 `TWA_RESUME`。\n3. **NMI 上下文延迟处理**：在不可睡眠的 NMI 处理程序中，通过 `TWA_NMI_CURRENT` 安全地安排后续工作。\n4. **信号式中断执行**：需要立即中断目标任务（即使在内核态）以执行高优先级工作，使用 `TWA_SIGNAL`。\n5. **资源回收**：在任务退出路径中，确保所有挂起工作被执行或清理。\n6. **动态取消机制**：如 seccomp 可能需要在条件变化时取消之前安排的工作，使用 `task_work_cancel_func()`。",
      "similarity": 0.571883499622345,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/task_work.c",
          "start_line": 10,
          "end_line": 125,
          "content": [
            "static void task_work_set_notify_irq(struct irq_work *entry)",
            "{",
            "\ttest_and_set_tsk_thread_flag(current, TIF_NOTIFY_RESUME);",
            "}",
            "int task_work_add(struct task_struct *task, struct callback_head *work,",
            "\t\t  enum task_work_notify_mode notify)",
            "{",
            "\tstruct callback_head *head;",
            "\tint flags = notify & TWA_FLAGS;",
            "",
            "\tnotify &= ~TWA_FLAGS;",
            "\tif (notify == TWA_NMI_CURRENT) {",
            "\t\tif (WARN_ON_ONCE(task != current))",
            "\t\t\treturn -EINVAL;",
            "\t\tif (!IS_ENABLED(CONFIG_IRQ_WORK))",
            "\t\t\treturn -EINVAL;",
            "\t} else {",
            "\t\t/*",
            "\t\t * Record the work call stack in order to print it in KASAN",
            "\t\t * reports.",
            "\t\t *",
            "\t\t * Note that stack allocation can fail if TWAF_NO_ALLOC flag",
            "\t\t * is set and new page is needed to expand the stack buffer.",
            "\t\t */",
            "\t\tif (flags & TWAF_NO_ALLOC)",
            "\t\t\tkasan_record_aux_stack_noalloc(work);",
            "\t\telse",
            "\t\t\tkasan_record_aux_stack(work);",
            "\t}",
            "",
            "\thead = READ_ONCE(task->task_works);",
            "\tdo {",
            "\t\tif (unlikely(head == &work_exited))",
            "\t\t\treturn -ESRCH;",
            "\t\twork->next = head;",
            "\t} while (!try_cmpxchg(&task->task_works, &head, work));",
            "",
            "\tswitch (notify) {",
            "\tcase TWA_NONE:",
            "\t\tbreak;",
            "\tcase TWA_RESUME:",
            "\t\tset_notify_resume(task);",
            "\t\tbreak;",
            "\tcase TWA_SIGNAL:",
            "\t\tset_notify_signal(task);",
            "\t\tbreak;",
            "\tcase TWA_SIGNAL_NO_IPI:",
            "\t\t__set_notify_signal(task);",
            "\t\tbreak;",
            "#ifdef CONFIG_IRQ_WORK",
            "\tcase TWA_NMI_CURRENT:",
            "\t\tirq_work_queue(this_cpu_ptr(&irq_work_NMI_resume));",
            "\t\tbreak;",
            "#endif",
            "\tdefault:",
            "\t\tWARN_ON_ONCE(1);",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static bool task_work_func_match(struct callback_head *cb, void *data)",
            "{",
            "\treturn cb->func == data;",
            "}",
            "static bool task_work_match(struct callback_head *cb, void *data)",
            "{",
            "\treturn cb == data;",
            "}",
            "bool task_work_cancel(struct task_struct *task, struct callback_head *cb)",
            "{",
            "\tstruct callback_head *ret;",
            "",
            "\tret = task_work_cancel_match(task, task_work_match, cb);",
            "",
            "\treturn ret == cb;",
            "}",
            "void task_work_run(void)",
            "{",
            "\tstruct task_struct *task = current;",
            "\tstruct callback_head *work, *head, *next;",
            "",
            "\tfor (;;) {",
            "\t\t/*",
            "\t\t * work->func() can do task_work_add(), do not set",
            "\t\t * work_exited unless the list is empty.",
            "\t\t */",
            "\t\twork = READ_ONCE(task->task_works);",
            "\t\tdo {",
            "\t\t\thead = NULL;",
            "\t\t\tif (!work) {",
            "\t\t\t\tif (task->flags & PF_EXITING)",
            "\t\t\t\t\thead = &work_exited;",
            "\t\t\t\telse",
            "\t\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t} while (!try_cmpxchg(&task->task_works, &work, head));",
            "",
            "\t\tif (!work)",
            "\t\t\tbreak;",
            "\t\t/*",
            "\t\t * Synchronize with task_work_cancel_match(). It can not remove",
            "\t\t * the first entry == work, cmpxchg(task_works) must fail.",
            "\t\t * But it can remove another entry from the ->next list.",
            "\t\t */",
            "\t\traw_spin_lock_irq(&task->pi_lock);",
            "\t\traw_spin_unlock_irq(&task->pi_lock);",
            "",
            "\t\tdo {",
            "\t\t\tnext = work->next;",
            "\t\t\twork->func(work);",
            "\t\t\twork = next;",
            "\t\t\tcond_resched();",
            "\t\t} while (work);",
            "\t}",
            "}"
          ],
          "function_name": "task_work_set_notify_irq, task_work_add, task_work_func_match, task_work_match, task_work_cancel, task_work_run",
          "description": "实现任务工作队列的添加、匹配、取消及执行逻辑，支持多种通知模式（如RESUME/SIGNAL/NMI），通过原子操作维护链表并同步执行回调函数",
          "similarity": 0.5485424399375916
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/task_work.c",
          "start_line": 1,
          "end_line": 9,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/task_work.h>",
            "#include <linux/resume_user_mode.h>",
            "",
            "static struct callback_head work_exited; /* all we need is ->next == NULL */",
            "",
            "#ifdef CONFIG_IRQ_WORK"
          ],
          "function_name": null,
          "description": "声明用于任务工作通知的静态变量work_exited，该变量通过next指针判断任务工作链表是否为空，上下文不完整",
          "similarity": 0.5349557399749756
        }
      ]
    },
    {
      "source_file": "mm/shuffle.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:21:18\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `shuffle.c`\n\n---\n\n# shuffle.c 技术文档\n\n## 1. 文件概述\n\n`shuffle.c` 实现了 Linux 内核内存管理子系统中的**页面分配随机化（Page Allocation Shuffling）**功能。该机制通过在内存初始化阶段对空闲页面链表进行 Fisher-Yates 洗牌操作，降低物理页帧分配的可预测性，从而增强系统安全性，抵御基于内存布局预测的攻击（如堆喷射、地址泄露等）。该功能默认关闭，可通过内核启动参数 `shuffle=1` 启用。\n\n## 2. 核心功能\n\n### 数据结构与全局变量\n- `page_alloc_shuffle_key`：静态分支键（static key），用于运行时启用/禁用洗牌逻辑，减少未启用时的性能开销。\n- `shuffle_param`：模块参数布尔值，控制是否启用洗牌功能。\n- `shuffle_param_ops`：自定义模块参数操作集，用于处理 `shuffle` 参数的设置和读取。\n\n### 主要函数\n- `shuffle_param_set()`：解析并设置 `shuffle` 内核参数，若启用则激活 `page_alloc_shuffle_key`。\n- `shuffle_valid_page()`：验证指定 PFN 的页面是否满足洗牌条件（属于 buddy 系统、同 zone、空闲、相同 order 和 migratetype）。\n- `__shuffle_zone()`：对指定内存区域（zone）执行 Fisher-Yates 洗牌算法，随机交换同阶空闲页面。\n- `__shuffle_free_memory()`：遍历节点（pgdat）中所有 zone，依次调用 `shuffle_zone()` 进行洗牌。\n- `shuffle_pick_tail()`：提供轻量级随机位生成器，用于在分配时决定从链表头部还是尾部取页（增强运行时随机性）。\n\n## 3. 关键实现\n\n### 洗牌算法（Fisher-Yates）\n- **粒度**：以 `SHUFFLE_ORDER`（通常为 0，即单页）为单位进行洗牌。\n- **范围**：遍历 zone 内所有按 order 对齐的 PFN，对每个有效页面 `page_i` 随机选择另一个有效页面 `page_j` 进行交换。\n- **有效性校验**：通过 `shuffle_valid_page()` 确保交换双方均为 buddy 系统管理的空闲页，且具有相同的迁移类型（migratetype）。\n- **重试机制**：最多尝试 `SHUFFLE_RETRY`（10 次）寻找有效的随机目标页，避免因内存空洞导致失败。\n- **锁优化**：每处理 100 个页面后释放 zone 自旋锁并调度，防止长时间持锁影响系统响应。\n\n### 随机性来源\n- 使用 `get_random_long()` 获取高质量伪随机数作为洗牌索引。\n- `shuffle_pick_tail()` 使用无锁的 64 位随机状态生成器，每次返回最低位并右移，用于运行时分配策略的微调。\n\n### 安全性权衡\n- 明确承认不消除模运算偏差（modulo bias）或 PRNG 偏差，目标是“提高攻击门槛”而非完美随机。\n- 仅在内存初始化阶段（`__meminit`）执行一次洗牌，不影响运行时分配性能。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/mm.h>`、`<linux/mmzone.h>`：内存管理核心数据结构（`struct zone`, `struct page`）。\n  - `<linux/random.h>`：提供 `get_random_long()` 和 `get_random_u64()`。\n  - `\"internal.h\"`、`\"shuffle.h\"`：内核 MM 子系统内部接口及洗牌功能声明。\n- **功能依赖**：\n  - Buddy 分配器：依赖 `PageBuddy()`、`buddy_order()` 等接口判断页面状态。\n  - 页面迁移类型（Migratetype）：确保洗牌不破坏不同迁移类型页面的隔离。\n  - 静态分支（Static Keys）：通过 `static_branch_enable()` 动态启用洗牌路径。\n\n## 5. 使用场景\n\n- **安全加固**：在需要防范物理地址预测攻击的场景（如虚拟化宿主机、安全敏感设备）中启用，增加攻击者利用内存布局漏洞的难度。\n- **内核初始化**：在 `free_area_init_core()` 等内存子系统初始化流程中调用 `__shuffle_free_memory()`，对初始空闲内存进行一次性洗牌。\n- **运行时分配辅助**：`shuffle_pick_tail()` 被页面分配器调用，决定从空闲链表头/尾取页，进一步增加分配时序的不可预测性。\n- **调试支持**：通过 `pr_debug()` 输出洗牌失败或迁移类型不匹配的日志，便于问题诊断（需开启 `DEBUG_SHUFFLE`）。",
      "similarity": 0.5697986483573914,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/shuffle.c",
          "start_line": 16,
          "end_line": 121,
          "content": [
            "static __meminit int shuffle_param_set(const char *val,",
            "\t\tconst struct kernel_param *kp)",
            "{",
            "\tif (param_set_bool(val, kp))",
            "\t\treturn -EINVAL;",
            "\tif (*(bool *)kp->arg)",
            "\t\tstatic_branch_enable(&page_alloc_shuffle_key);",
            "\treturn 0;",
            "}",
            "void __meminit __shuffle_zone(struct zone *z)",
            "{",
            "\tunsigned long i, flags;",
            "\tunsigned long start_pfn = z->zone_start_pfn;",
            "\tunsigned long end_pfn = zone_end_pfn(z);",
            "\tconst int order = SHUFFLE_ORDER;",
            "\tconst int order_pages = 1 << order;",
            "",
            "\tspin_lock_irqsave(&z->lock, flags);",
            "\tstart_pfn = ALIGN(start_pfn, order_pages);",
            "\tfor (i = start_pfn; i < end_pfn; i += order_pages) {",
            "\t\tunsigned long j;",
            "\t\tint migratetype, retry;",
            "\t\tstruct page *page_i, *page_j;",
            "",
            "\t\t/*",
            "\t\t * We expect page_i, in the sub-range of a zone being added",
            "\t\t * (@start_pfn to @end_pfn), to more likely be valid compared to",
            "\t\t * page_j randomly selected in the span @zone_start_pfn to",
            "\t\t * @spanned_pages.",
            "\t\t */",
            "\t\tpage_i = shuffle_valid_page(z, i, order);",
            "\t\tif (!page_i)",
            "\t\t\tcontinue;",
            "",
            "\t\tfor (retry = 0; retry < SHUFFLE_RETRY; retry++) {",
            "\t\t\t/*",
            "\t\t\t * Pick a random order aligned page in the zone span as",
            "\t\t\t * a swap target. If the selected pfn is a hole, retry",
            "\t\t\t * up to SHUFFLE_RETRY attempts find a random valid pfn",
            "\t\t\t * in the zone.",
            "\t\t\t */",
            "\t\t\tj = z->zone_start_pfn +",
            "\t\t\t\tALIGN_DOWN(get_random_long() % z->spanned_pages,",
            "\t\t\t\t\t\torder_pages);",
            "\t\t\tpage_j = shuffle_valid_page(z, j, order);",
            "\t\t\tif (page_j && page_j != page_i)",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t\tif (retry >= SHUFFLE_RETRY) {",
            "\t\t\tpr_debug(\"%s: failed to swap %#lx\\n\", __func__, i);",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Each migratetype corresponds to its own list, make sure the",
            "\t\t * types match otherwise we're moving pages to lists where they",
            "\t\t * do not belong.",
            "\t\t */",
            "\t\tmigratetype = get_pageblock_migratetype(page_i);",
            "\t\tif (get_pageblock_migratetype(page_j) != migratetype) {",
            "\t\t\tpr_debug(\"%s: migratetype mismatch %#lx\\n\", __func__, i);",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tlist_swap(&page_i->lru, &page_j->lru);",
            "",
            "\t\tpr_debug(\"%s: swap: %#lx -> %#lx\\n\", __func__, i, j);",
            "",
            "\t\t/* take it easy on the zone lock */",
            "\t\tif ((i % (100 * order_pages)) == 0) {",
            "\t\t\tspin_unlock_irqrestore(&z->lock, flags);",
            "\t\t\tcond_resched();",
            "\t\t\tspin_lock_irqsave(&z->lock, flags);",
            "\t\t}",
            "\t}",
            "\tspin_unlock_irqrestore(&z->lock, flags);",
            "}",
            "void __meminit __shuffle_free_memory(pg_data_t *pgdat)",
            "{",
            "\tstruct zone *z;",
            "",
            "\tfor (z = pgdat->node_zones; z < pgdat->node_zones + MAX_NR_ZONES; z++)",
            "\t\tshuffle_zone(z);",
            "}",
            "bool shuffle_pick_tail(void)",
            "{",
            "\tstatic u64 rand;",
            "\tstatic u8 rand_bits;",
            "\tbool ret;",
            "",
            "\t/*",
            "\t * The lack of locking is deliberate. If 2 threads race to",
            "\t * update the rand state it just adds to the entropy.",
            "\t */",
            "\tif (rand_bits == 0) {",
            "\t\trand_bits = 64;",
            "\t\trand = get_random_u64();",
            "\t}",
            "",
            "\tret = rand & 1;",
            "",
            "\trand_bits--;",
            "\trand >>= 1;",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "shuffle_param_set, __shuffle_zone, __shuffle_free_memory, shuffle_pick_tail",
          "description": "shuffle_param_set设置参数并启用/禁用静态键；__shuffle_zone在内存区随机交换页面以打乱物理顺序；__shuffle_free_memory初始化时调用__shuffle_zone；shuffle_pick_tail生成随机布尔值用于选择尾部页",
          "similarity": 0.5619770288467407
        },
        {
          "chunk_id": 0,
          "file_path": "mm/shuffle.c",
          "start_line": 1,
          "end_line": 15,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "// Copyright(c) 2018 Intel Corporation. All rights reserved.",
            "",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/random.h>",
            "#include <linux/moduleparam.h>",
            "#include \"internal.h\"",
            "#include \"shuffle.h\"",
            "",
            "DEFINE_STATIC_KEY_FALSE(page_alloc_shuffle_key);",
            "",
            "static bool shuffle_param;",
            ""
          ],
          "function_name": null,
          "description": "定义静态键用于控制页面分配随机化功能，并声明参数变量shuffle_param，用于启用或禁用相关机制",
          "similarity": 0.4505247175693512
        }
      ]
    }
  ]
}