{
  "query": "多读者单写者同步机制设计",
  "timestamp": "2025-12-26 01:02:09",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/rwbase_rt.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:50:50\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\rwbase_rt.c`\n\n---\n\n# `locking/rwbase_rt.c` 技术文档\n\n## 1. 文件概述\n\n`rwbase_rt.c` 是 Linux 内核实时（RT）补丁中用于实现 **实时读者-写者同步原语**（包括 `rw_semaphore` 和 `rwlock`）的通用底层代码。该文件为实时调度环境（如 `PREEMPT_RT`）提供了一套基于 `rtmutex` 的读写锁实现，以解决传统读写锁在实时系统中可能导致的优先级反转和不可预测延迟问题。\n\n该实现通过将写者操作与 `rtmutex` 绑定，利用 `rtmutex` 的优先级继承（PI）或截止时间（DL）调度机制，确保写者不会被低优先级读者无限阻塞，同时在多数情况下允许读者通过无锁快速路径（fast path）高效执行。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct rwbase_rt`：读写同步原语的通用底层结构，包含：\n  - `atomic_t readers`：读者计数器，使用偏置（bias）机制区分读/写状态\n  - `struct rt_mutex_base rtmutex`：底层实时互斥锁，用于串行化写者和阻塞读者\n\n### 关键常量\n- `READER_BIAS`：正偏置值（通常为 `0x7fffffff`），表示允许读者使用快速路径\n- `WRITER_BIAS`：负偏置值（通常为 `-0x80000000`），表示写者已持有锁\n\n### 主要函数\n\n| 函数 | 功能 |\n|------|------|\n| `rwbase_read_trylock()` | 尝试快速获取读锁（仅当 `READER_BIAS` 存在时） |\n| `__rwbase_read_lock()` / `rwbase_read_lock()` | 获取读锁（慢路径 + 快路径组合） |\n| `__rwbase_read_unlock()` / `rwbase_read_unlock()` | 释放读锁，必要时唤醒等待的写者 |\n| `__rwbase_write_unlock()` / `rwbase_write_unlock()` | 释放写锁，恢复 `READER_BIAS` 并释放 `rtmutex` |\n| `rwbase_write_downgrade()` | 将写锁降级为读锁 |\n| `__rwbase_write_trylock()` | 在持有 `wait_lock` 下尝试获取写锁 |\n| `rwbase_write_lock()` | 获取写锁（完整慢路径，含阻塞等待） |\n| `rwbase_write_trylock()` | 尝试非阻塞获取写锁（代码片段未完整） |\n\n## 3. 关键实现\n\n### 3.1 读者-写者状态管理\n- 使用 `atomic_t readers` 字段统一管理状态：\n  - **初始状态**：`readers = READER_BIAS`（正值），允许读者走快速路径\n  - **写者加锁时**：先获取 `rtmutex`，然后 `atomic_sub(READER_BIAS, &readers)`，使值变为负或零，强制后续读者进入慢路径\n  - **写者持有锁**：`readers = WRITER_BIAS`（最小负值）\n  - **读者持有锁**：`readers = READER_BIAS + N`（N 为活跃读者数）\n\n### 3.2 快速路径（Fast Path）\n- **读锁获取**：通过 `atomic_try_cmpxchg_acquire()` 原子递增 `readers`（仅当 `< 0` 不成立，即偏置存在）\n- **读锁释放**：`atomic_dec_and_test()`，仅当计数归零（即最后一个读者）时才需唤醒写者\n- 所有原子操作均使用 `_acquire` / `_release` 语义，确保内存顺序正确\n\n### 3.3 写者加锁流程\n1. 获取底层 `rtmutex`（可能阻塞）\n2. 清除 `READER_BIAS`，阻止新读者进入快速路径\n3. 在 `rtmutex.wait_lock` 保护下检查是否所有读者已退出（`readers == 0`）\n4. 若仍有读者，循环等待并调度，直到可安全设置 `WRITER_BIAS`\n\n### 3.4 非写者公平性\n- **明确不保证写者公平**：新到达的读者即使在写者等待时仍可获取读锁（若写者尚未清除 `READER_BIAS`）\n- 原因：实现完全公平需为每个读者代理锁定 `rtmutex` 并逐个继承优先级，这在 `SCHED_DEADLINE` 下不可行\n- 权衡：接受潜在写者饥饿风险，换取实现简洁性和典型 RT 场景下的低延迟\n\n### 3.5 与 `rtmutex` 的集成\n- 所有慢路径操作均在 `rtmutex.wait_lock`（raw spinlock）保护下进行\n- 写者通过 `rtmutex` 阻塞，天然获得 PI/DL 调度支持\n- 读者在慢路径中临时获取 `rtmutex` 以确保与写者互斥，成功后立即释放\n\n## 4. 依赖关系\n\n- **`rtmutex` 子系统**：依赖 `rt_mutex_base`、`rt_mutex_lock/unlock`、`rt_mutex_wake_q` 等接口实现阻塞/唤醒和优先级继承\n- **原子操作**：使用 `atomic_read`、`atomic_try_cmpxchg_acquire`、`atomic_add_return_release` 等提供内存序保证\n- **调度器**：调用 `rwbase_pre_schedule()` / `rwbase_post_schedule()`、`rwbase_schedule()` 与 RT 调度器交互\n- **跟踪机制**：使用 `trace_contention_begin/end` 提供锁竞争跟踪\n- **中断管理**：使用 `raw_spin_lock_irq{save/restore}` 保护关键区\n- **信号处理**：通过 `rwbase_signal_pending_state()` 支持可中断等待\n\n## 5. 使用场景\n\n- **实时任务中的读写同步**：适用于需要低延迟响应的 RT 任务访问共享数据结构\n- **`mmap_sem` 等内核锁的 RT 实现**：作为 `rw_semaphore` 的底层支持，用于内存管理等子系统\n- **避免优先级反转**：当高优先级写者需等待低优先级读者时，通过 `rtmutex` 的 PI 机制临时提升读者优先级\n- **高并发读场景**：允许多个读者无锁并发执行，仅在写者存在时才串行化\n- **不适用于强写者公平需求场景**：如需严格 FIFO 写者调度，应避免在 RT 任务中使用此类锁",
      "similarity": 0.6028683185577393,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/rwbase_rt.c",
          "start_line": 168,
          "end_line": 273,
          "content": [
            "static __always_inline void rwbase_read_unlock(struct rwbase_rt *rwb,",
            "\t\t\t\t\t       unsigned int state)",
            "{",
            "\t/*",
            "\t * rwb->readers can only hit 0 when a writer is waiting for the",
            "\t * active readers to leave the critical section.",
            "\t *",
            "\t * dec_and_test() is fully ordered, provides RELEASE.",
            "\t */",
            "\tif (unlikely(atomic_dec_and_test(&rwb->readers)))",
            "\t\t__rwbase_read_unlock(rwb, state);",
            "}",
            "static inline void __rwbase_write_unlock(struct rwbase_rt *rwb, int bias,",
            "\t\t\t\t\t unsigned long flags)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "",
            "\t/*",
            "\t * _release() is needed in case that reader is in fast path, pairing",
            "\t * with atomic_try_cmpxchg_acquire() in rwbase_read_trylock().",
            "\t */",
            "\t(void)atomic_add_return_release(READER_BIAS - bias, &rwb->readers);",
            "\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);",
            "\trwbase_rtmutex_unlock(rtm);",
            "}",
            "static inline void rwbase_write_unlock(struct rwbase_rt *rwb)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "\t__rwbase_write_unlock(rwb, WRITER_BIAS, flags);",
            "}",
            "static inline void rwbase_write_downgrade(struct rwbase_rt *rwb)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "\t/* Release it and account current as reader */",
            "\t__rwbase_write_unlock(rwb, WRITER_BIAS - 1, flags);",
            "}",
            "static inline bool __rwbase_write_trylock(struct rwbase_rt *rwb)",
            "{",
            "\t/* Can do without CAS because we're serialized by wait_lock. */",
            "\tlockdep_assert_held(&rwb->rtmutex.wait_lock);",
            "",
            "\t/*",
            "\t * _acquire is needed in case the reader is in the fast path, pairing",
            "\t * with rwbase_read_unlock(), provides ACQUIRE.",
            "\t */",
            "\tif (!atomic_read_acquire(&rwb->readers)) {",
            "\t\tatomic_set(&rwb->readers, WRITER_BIAS);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,",
            "\t\t\t\t     unsigned int state)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tunsigned long flags;",
            "",
            "\t/* Take the rtmutex as a first step */",
            "\tif (rwbase_rtmutex_lock_state(rtm, state))",
            "\t\treturn -EINTR;",
            "",
            "\t/* Force readers into slow path */",
            "\tatomic_sub(READER_BIAS, &rwb->readers);",
            "",
            "\trwbase_pre_schedule();",
            "",
            "\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "\tif (__rwbase_write_trylock(rwb))",
            "\t\tgoto out_unlock;",
            "",
            "\trwbase_set_and_save_current_state(state);",
            "\ttrace_contention_begin(rwb, LCB_F_RT | LCB_F_WRITE);",
            "\tfor (;;) {",
            "\t\t/* Optimized out for rwlocks */",
            "\t\tif (rwbase_signal_pending_state(state, current)) {",
            "\t\t\trwbase_restore_current_state();",
            "\t\t\t__rwbase_write_unlock(rwb, 0, flags);",
            "\t\t\trwbase_post_schedule();",
            "\t\t\ttrace_contention_end(rwb, -EINTR);",
            "\t\t\treturn -EINTR;",
            "\t\t}",
            "",
            "\t\tif (__rwbase_write_trylock(rwb))",
            "\t\t\tbreak;",
            "",
            "\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);",
            "\t\trwbase_schedule();",
            "\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "",
            "\t\tset_current_state(state);",
            "\t}",
            "\trwbase_restore_current_state();",
            "\ttrace_contention_end(rwb, 0);",
            "",
            "out_unlock:",
            "\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);",
            "\trwbase_post_schedule();",
            "\treturn 0;",
            "}"
          ],
          "function_name": "rwbase_read_unlock, __rwbase_write_unlock, rwbase_write_unlock, rwbase_write_downgrade, __rwbase_write_trylock, rwbase_write_lock",
          "description": "处理写锁的释放、降级与尝试获取逻辑，包含读者偏置调整、内存序保障、写锁竞争解决及状态转换的完整流程",
          "similarity": 0.5866333842277527
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/rwbase_rt.c",
          "start_line": 53,
          "end_line": 163,
          "content": [
            "static __always_inline int rwbase_read_trylock(struct rwbase_rt *rwb)",
            "{",
            "\tint r;",
            "",
            "\t/*",
            "\t * Increment reader count, if sem->readers < 0, i.e. READER_BIAS is",
            "\t * set.",
            "\t */",
            "\tfor (r = atomic_read(&rwb->readers); r < 0;) {",
            "\t\tif (likely(atomic_try_cmpxchg_acquire(&rwb->readers, &r, r + 1)))",
            "\t\t\treturn 1;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int __sched __rwbase_read_lock(struct rwbase_rt *rwb,",
            "\t\t\t\t      unsigned int state)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tint ret;",
            "",
            "\trwbase_pre_schedule();",
            "\traw_spin_lock_irq(&rtm->wait_lock);",
            "",
            "\t/*",
            "\t * Call into the slow lock path with the rtmutex->wait_lock",
            "\t * held, so this can't result in the following race:",
            "\t *",
            "\t * Reader1\t\tReader2\t\tWriter",
            "\t *\t\t\tdown_read()",
            "\t *\t\t\t\t\tdown_write()",
            "\t *\t\t\t\t\trtmutex_lock(m)",
            "\t *\t\t\t\t\twait()",
            "\t * down_read()",
            "\t * unlock(m->wait_lock)",
            "\t *\t\t\tup_read()",
            "\t *\t\t\twake(Writer)",
            "\t *\t\t\t\t\tlock(m->wait_lock)",
            "\t *\t\t\t\t\tsem->writelocked=true",
            "\t *\t\t\t\t\tunlock(m->wait_lock)",
            "\t *",
            "\t *\t\t\t\t\tup_write()",
            "\t *\t\t\t\t\tsem->writelocked=false",
            "\t *\t\t\t\t\trtmutex_unlock(m)",
            "\t *\t\t\tdown_read()",
            "\t *\t\t\t\t\tdown_write()",
            "\t *\t\t\t\t\trtmutex_lock(m)",
            "\t *\t\t\t\t\twait()",
            "\t * rtmutex_lock(m)",
            "\t *",
            "\t * That would put Reader1 behind the writer waiting on",
            "\t * Reader2 to call up_read(), which might be unbound.",
            "\t */",
            "",
            "\ttrace_contention_begin(rwb, LCB_F_RT | LCB_F_READ);",
            "",
            "\t/*",
            "\t * For rwlocks this returns 0 unconditionally, so the below",
            "\t * !ret conditionals are optimized out.",
            "\t */",
            "\tret = rwbase_rtmutex_slowlock_locked(rtm, state);",
            "",
            "\t/*",
            "\t * On success the rtmutex is held, so there can't be a writer",
            "\t * active. Increment the reader count and immediately drop the",
            "\t * rtmutex again.",
            "\t *",
            "\t * rtmutex->wait_lock has to be unlocked in any case of course.",
            "\t */",
            "\tif (!ret)",
            "\t\tatomic_inc(&rwb->readers);",
            "\traw_spin_unlock_irq(&rtm->wait_lock);",
            "\tif (!ret)",
            "\t\trwbase_rtmutex_unlock(rtm);",
            "",
            "\ttrace_contention_end(rwb, ret);",
            "\trwbase_post_schedule();",
            "\treturn ret;",
            "}",
            "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,",
            "\t\t\t\t\t    unsigned int state)",
            "{",
            "\tlockdep_assert(!current->pi_blocked_on);",
            "",
            "\tif (rwbase_read_trylock(rwb))",
            "\t\treturn 0;",
            "",
            "\treturn __rwbase_read_lock(rwb, state);",
            "}",
            "static void __sched __rwbase_read_unlock(struct rwbase_rt *rwb,",
            "\t\t\t\t\t unsigned int state)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tstruct task_struct *owner;",
            "\tDEFINE_RT_WAKE_Q(wqh);",
            "",
            "\traw_spin_lock_irq(&rtm->wait_lock);",
            "\t/*",
            "\t * Wake the writer, i.e. the rtmutex owner. It might release the",
            "\t * rtmutex concurrently in the fast path (due to a signal), but to",
            "\t * clean up rwb->readers it needs to acquire rtm->wait_lock. The",
            "\t * worst case which can happen is a spurious wakeup.",
            "\t */",
            "\towner = rt_mutex_owner(rtm);",
            "\tif (owner)",
            "\t\trt_mutex_wake_q_add_task(&wqh, owner, state);",
            "",
            "\t/* Pairs with the preempt_enable in rt_mutex_wake_up_q() */",
            "\tpreempt_disable();",
            "\traw_spin_unlock_irq(&rtm->wait_lock);",
            "\trt_mutex_wake_up_q(&wqh);",
            "}"
          ],
          "function_name": "rwbase_read_trylock, __rwbase_read_lock, rwbase_read_lock, __rwbase_read_unlock",
          "description": "实现读锁的尝试获取与锁定逻辑，包含原子操作更新读者计数、持有rtmutex_wait_lock保护临界区、唤醒等待写者的解锁逻辑",
          "similarity": 0.5852791666984558
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/rwbase_rt.c",
          "start_line": 1,
          "end_line": 52,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "",
            "/*",
            " * RT-specific reader/writer semaphores and reader/writer locks",
            " *",
            " * down_write/write_lock()",
            " *  1) Lock rtmutex",
            " *  2) Remove the reader BIAS to force readers into the slow path",
            " *  3) Wait until all readers have left the critical section",
            " *  4) Mark it write locked",
            " *",
            " * up_write/write_unlock()",
            " *  1) Remove the write locked marker",
            " *  2) Set the reader BIAS, so readers can use the fast path again",
            " *  3) Unlock rtmutex, to release blocked readers",
            " *",
            " * down_read/read_lock()",
            " *  1) Try fast path acquisition (reader BIAS is set)",
            " *  2) Take tmutex::wait_lock, which protects the writelocked flag",
            " *  3) If !writelocked, acquire it for read",
            " *  4) If writelocked, block on tmutex",
            " *  5) unlock rtmutex, goto 1)",
            " *",
            " * up_read/read_unlock()",
            " *  1) Try fast path release (reader count != 1)",
            " *  2) Wake the writer waiting in down_write()/write_lock() #3",
            " *",
            " * down_read/read_lock()#3 has the consequence, that rw semaphores and rw",
            " * locks on RT are not writer fair, but writers, which should be avoided in",
            " * RT tasks (think mmap_sem), are subject to the rtmutex priority/DL",
            " * inheritance mechanism.",
            " *",
            " * It's possible to make the rw primitives writer fair by keeping a list of",
            " * active readers. A blocked writer would force all newly incoming readers",
            " * to block on the rtmutex, but the rtmutex would have to be proxy locked",
            " * for one reader after the other. We can't use multi-reader inheritance",
            " * because there is no way to support that with SCHED_DEADLINE.",
            " * Implementing the one by one reader boosting/handover mechanism is a",
            " * major surgery for a very dubious value.",
            " *",
            " * The risk of writer starvation is there, but the pathological use cases",
            " * which trigger it are not necessarily the typical RT workloads.",
            " *",
            " * Fast-path orderings:",
            " * The lock/unlock of readers can run in fast paths: lock and unlock are only",
            " * atomic ops, and there is no inner lock to provide ACQUIRE and RELEASE",
            " * semantics of rwbase_rt. Atomic ops should thus provide _acquire()",
            " * and _release() (or stronger).",
            " *",
            " * Common code shared between RT rw_semaphore and rwlock",
            " */",
            ""
          ],
          "function_name": null,
          "description": "描述RT读写锁的实现机制，包括写锁强制读者进入慢路径、读锁快慢路径切换及优先级继承特性，说明其不支持公平写入但通过RT mutex机制控制并发",
          "similarity": 0.5628503561019897
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/rwbase_rt.c",
          "start_line": 280,
          "end_line": 297,
          "content": [
            "static inline int rwbase_write_trylock(struct rwbase_rt *rwb)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tunsigned long flags;",
            "",
            "\tif (!rwbase_rtmutex_trylock(rtm))",
            "\t\treturn 0;",
            "",
            "\tatomic_sub(READER_BIAS, &rwb->readers);",
            "",
            "\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "\tif (__rwbase_write_trylock(rwb)) {",
            "\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);",
            "\t\treturn 1;",
            "\t}",
            "\t__rwbase_write_unlock(rwb, 0, flags);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "rwbase_write_trylock",
          "description": "实现非阻塞式写锁尝试获取，通过先获取rtmutex再调整读者偏置，最终判断能否直接获得写锁的原子化操作流程",
          "similarity": 0.5500494241714478
        }
      ]
    },
    {
      "source_file": "kernel/rcu/sync.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:44:18\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `rcu\\sync.c`\n\n---\n\n# rcu/sync.c 技术文档\n\n## 文件概述\n\n`rcu/sync.c` 实现了一个基于 RCU（Read-Copy-Update）机制的轻量级读写同步基础设施，称为 `rcu_sync`。该机制允许写者（更新者）在需要时强制所有读者切换到“慢路径”（slow path），并在更新完成后经过一个 RCU 宽限期（grace period）后，允许读者重新使用“快路径”（fast path）。该设计特别适用于需要频繁但短暂地禁用读者快路径的场景，避免了传统读写锁的开销，同时利用 RCU 的无锁读取特性提升性能。\n\n## 核心功能\n\n### 数据结构\n\n- **`struct rcu_sync`**  \n  核心同步控制结构，包含以下关键字段：\n  - `gp_state`：当前同步状态（`GP_IDLE`, `GP_ENTER`, `GP_PASSED`, `GP_EXIT`, `GP_REPLAY`）\n  - `gp_count`：嵌套的 `rcu_sync_enter()` 调用计数\n  - `cb_head`：用于 RCU 回调的 `rcu_head`\n  - `gp_wait`：等待队列，用于阻塞等待状态转换完成\n\n### 主要函数\n\n| 函数 | 功能描述 |\n|------|--------|\n| `rcu_sync_init()` | 初始化 `rcu_sync` 结构体 |\n| `rcu_sync_enter_start()` | 预激活同步机制，使 `rcu_sync_is_idle()` 返回 false，且后续 enter/exit 成为 NO-OP |\n| `rcu_sync_enter()` | 强制读者进入慢路径，确保后续读者不会使用快路径 |\n| `rcu_sync_exit()` | 标记更新结束，安排在宽限期后恢复读者快路径 |\n| `rcu_sync_dtor()` | 销毁 `rcu_sync` 结构，确保所有 RCU 回调已完成 |\n| `rcu_sync_func()` | RCU 回调函数，根据当前状态推进状态机 |\n\n## 关键实现\n\n### 状态机设计\n\n`rcu_sync` 使用五种状态实现高效的状态转换：\n\n- **`GP_IDLE`**：初始状态，读者可使用快路径。\n- **`GP_ENTER`**：正在进入同步状态，需等待宽限期。\n- **`GP_PASSED`**：宽限期已过，读者已全部进入慢路径。\n- **`GP_EXIT`**：正在退出同步，需等待另一个宽限期以恢复快路径。\n- **`GP_REPLAY`**：在退出过程中又有新的 enter/exit 对发生，需重新调度回调。\n\n### 嵌套与优化\n\n- **嵌套支持**：通过 `gp_count` 支持 `rcu_sync_enter()` 的嵌套调用。只有当 `gp_count` 从 1 递减到 0 时，才触发退出流程。\n- **宽限期合并**：连续的 `enter/exit` 调用可避免多次等待宽限期。例如：\n  - 若在 `GP_PASSED` 状态下调用 `exit`，直接进入 `GP_EXIT` 并调度回调。\n  - 若在回调执行前再次调用 `enter/exit`，状态转为 `GP_REPLAY`，并在回调中重新调度，避免冗余宽限期。\n- **快速路径优化**：首次 `enter` 时若处于 `GP_IDLE`，直接调用 `synchronize_rcu()` 而非异步 `call_rcu()`，可利用 `rcu_expedited` 或 `rcu_blocking_is_gp()` 加速。\n\n### 同步与唤醒\n\n- 写者调用 `rcu_sync_enter()` 后，若非首次进入，会阻塞在 `wait_event()`，直到状态变为 `GP_PASSED` 或更高。\n- `rcu_sync_func()` 在宽限期后执行，根据 `gp_count` 和当前状态决定是唤醒等待者、重调度回调，还是恢复到 `GP_IDLE`。\n\n## 依赖关系\n\n- **`<linux/rcu_sync.h>`**：定义 `struct rcu_sync` 及相关 API。\n- **`<linux/sched.h>`**：提供 `wait_event()`、`wake_up_locked()` 等调度和等待队列原语。\n- **RCU 子系统**：\n  - `call_rcu_hurry()` / `call_rcu()`：用于注册宽限期后的回调。\n  - `synchronize_rcu()`：用于同步等待宽限期。\n  - `rcu_barrier()`：在析构时确保所有回调完成。\n- **自旋锁**：使用 `spin_lock_irqsave()` 保护状态和计数器，确保中断上下文安全。\n\n## 使用场景\n\n- **文件系统元数据更新**：如 overlayfs、btrfs 等在修改共享元数据结构时，临时禁止读者使用快路径缓存。\n- **动态配置更新**：内核模块或子系统在热更新全局配置时，确保读者看到一致状态。\n- **轻量级写者同步**：适用于写操作较少但需高效读者路径的场景，避免传统 rwlock 的读者竞争开销。\n- **替代 `synchronize_rcu()` 的批量操作**：当多个连续更新可合并为一次宽限期等待时，提升性能。",
      "similarity": 0.5941175222396851,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/rcu/sync.c",
          "start_line": 21,
          "end_line": 136,
          "content": [
            "void rcu_sync_init(struct rcu_sync *rsp)",
            "{",
            "\tmemset(rsp, 0, sizeof(*rsp));",
            "\tinit_waitqueue_head(&rsp->gp_wait);",
            "}",
            "void rcu_sync_enter_start(struct rcu_sync *rsp)",
            "{",
            "\trsp->gp_count++;",
            "\trsp->gp_state = GP_PASSED;",
            "}",
            "static void rcu_sync_call(struct rcu_sync *rsp)",
            "{",
            "\tcall_rcu_hurry(&rsp->cb_head, rcu_sync_func);",
            "}",
            "static void rcu_sync_func(struct rcu_head *rhp)",
            "{",
            "\tstruct rcu_sync *rsp = container_of(rhp, struct rcu_sync, cb_head);",
            "\tunsigned long flags;",
            "",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_state) == GP_IDLE);",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_state) == GP_PASSED);",
            "",
            "\tspin_lock_irqsave(&rsp->rss_lock, flags);",
            "\tif (rsp->gp_count) {",
            "\t\t/*",
            "\t\t * We're at least a GP after the GP_IDLE->GP_ENTER transition.",
            "\t\t */",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_PASSED);",
            "\t\twake_up_locked(&rsp->gp_wait);",
            "\t} else if (rsp->gp_state == GP_REPLAY) {",
            "\t\t/*",
            "\t\t * A new rcu_sync_exit() has happened; requeue the callback to",
            "\t\t * catch a later GP.",
            "\t\t */",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_EXIT);",
            "\t\trcu_sync_call(rsp);",
            "\t} else {",
            "\t\t/*",
            "\t\t * We're at least a GP after the last rcu_sync_exit(); everybody",
            "\t\t * will now have observed the write side critical section.",
            "\t\t * Let 'em rip!",
            "\t\t */",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_IDLE);",
            "\t}",
            "\tspin_unlock_irqrestore(&rsp->rss_lock, flags);",
            "}",
            "void rcu_sync_enter(struct rcu_sync *rsp)",
            "{",
            "\tint gp_state;",
            "",
            "\tspin_lock_irq(&rsp->rss_lock);",
            "\tgp_state = rsp->gp_state;",
            "\tif (gp_state == GP_IDLE) {",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_ENTER);",
            "\t\tWARN_ON_ONCE(rsp->gp_count);",
            "\t\t/*",
            "\t\t * Note that we could simply do rcu_sync_call(rsp) here and",
            "\t\t * avoid the \"if (gp_state == GP_IDLE)\" block below.",
            "\t\t *",
            "\t\t * However, synchronize_rcu() can be faster if rcu_expedited",
            "\t\t * or rcu_blocking_is_gp() is true.",
            "\t\t *",
            "\t\t * Another reason is that we can't wait for rcu callback if",
            "\t\t * we are called at early boot time but this shouldn't happen.",
            "\t\t */",
            "\t}",
            "\trsp->gp_count++;",
            "\tspin_unlock_irq(&rsp->rss_lock);",
            "",
            "\tif (gp_state == GP_IDLE) {",
            "\t\t/*",
            "\t\t * See the comment above, this simply does the \"synchronous\"",
            "\t\t * call_rcu(rcu_sync_func) which does GP_ENTER -> GP_PASSED.",
            "\t\t */",
            "\t\tsynchronize_rcu();",
            "\t\trcu_sync_func(&rsp->cb_head);",
            "\t\t/* Not really needed, wait_event() would see GP_PASSED. */",
            "\t\treturn;",
            "\t}",
            "",
            "\twait_event(rsp->gp_wait, READ_ONCE(rsp->gp_state) >= GP_PASSED);",
            "}",
            "void rcu_sync_exit(struct rcu_sync *rsp)",
            "{",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_state) == GP_IDLE);",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_count) == 0);",
            "",
            "\tspin_lock_irq(&rsp->rss_lock);",
            "\tif (!--rsp->gp_count) {",
            "\t\tif (rsp->gp_state == GP_PASSED) {",
            "\t\t\tWRITE_ONCE(rsp->gp_state, GP_EXIT);",
            "\t\t\trcu_sync_call(rsp);",
            "\t\t} else if (rsp->gp_state == GP_EXIT) {",
            "\t\t\tWRITE_ONCE(rsp->gp_state, GP_REPLAY);",
            "\t\t}",
            "\t}",
            "\tspin_unlock_irq(&rsp->rss_lock);",
            "}",
            "void rcu_sync_dtor(struct rcu_sync *rsp)",
            "{",
            "\tint gp_state;",
            "",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_count));",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_state) == GP_PASSED);",
            "",
            "\tspin_lock_irq(&rsp->rss_lock);",
            "\tif (rsp->gp_state == GP_REPLAY)",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_EXIT);",
            "\tgp_state = rsp->gp_state;",
            "\tspin_unlock_irq(&rsp->rss_lock);",
            "",
            "\tif (gp_state != GP_IDLE) {",
            "\t\trcu_barrier();",
            "\t\tWARN_ON_ONCE(rsp->gp_state != GP_IDLE);",
            "\t}",
            "}"
          ],
          "function_name": "rcu_sync_init, rcu_sync_enter_start, rcu_sync_call, rcu_sync_func, rcu_sync_enter, rcu_sync_exit, rcu_sync_dtor",
          "description": "实现了RCU同步核心函数，包括初始化、状态管理、回调触发和退出处理，通过spinlock保护状态机并利用RCU回调实现延迟同步，用于协调读者-写者并发访问的安全转换",
          "similarity": 0.6059784889221191
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/rcu/sync.c",
          "start_line": 1,
          "end_line": 20,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0+",
            "/*",
            " * RCU-based infrastructure for lightweight reader-writer locking",
            " *",
            " * Copyright (c) 2015, Red Hat, Inc.",
            " *",
            " * Author: Oleg Nesterov <oleg@redhat.com>",
            " */",
            "",
            "#include <linux/rcu_sync.h>",
            "#include <linux/sched.h>",
            "",
            "enum { GP_IDLE = 0, GP_ENTER, GP_PASSED, GP_EXIT, GP_REPLAY };",
            "",
            "#define\trss_lock\tgp_wait.lock",
            "",
            "/**",
            " * rcu_sync_init() - Initialize an rcu_sync structure",
            " * @rsp: Pointer to rcu_sync structure to be initialized",
            " */"
          ],
          "function_name": null,
          "description": "定义了RCU同步基础设施的枚举常量和rcu_sync_init函数声明，用于初始化rcu_sync结构体，但代码上下文不完整",
          "similarity": 0.4598565101623535
        }
      ]
    },
    {
      "source_file": "kernel/locking/percpu-rwsem.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:44:20\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\percpu-rwsem.c`\n\n---\n\n# `locking/percpu-rwsem.c` 技术文档\n\n## 1. 文件概述\n\n`percpu-rwsem.c` 实现了一种高性能的**每 CPU 读写信号量**（per-CPU read-write semaphore），专为读多写少场景优化。该机制允许多个读者在无写者时并发执行（无需全局同步），而写者则需等待所有活跃读者退出后才能获得独占访问权。其核心思想是利用 per-CPU 计数器记录读者数量，避免读者之间的原子操作竞争，从而显著提升可扩展性。\n\n## 2. 核心功能\n\n### 主要数据结构\n- **`struct percpu_rw_semaphore`**：每 CPU 读写信号量控制结构，包含：\n  - `read_count`：per-CPU 整型变量，记录各 CPU 上的活跃读者数量\n  - `rss`：`rcu_sync` 结构，用于协调 RCU 与写者临界区\n  - `writer`：`rcuwait` 结构，供写者等待读者退出\n  - `waiters`：等待队列头，管理阻塞的读者/写者\n  - `block`：原子变量，标志写者是否已请求独占（1=阻塞新读者）\n  - `dep_map`：Lockdep 调试用的依赖映射\n\n### 主要函数\n| 函数 | 功能 |\n|------|------|\n| `__percpu_init_rwsem()` | 初始化 per-CPU 读写信号量 |\n| `percpu_free_rwsem()` | 释放信号量资源 |\n| `__percpu_down_read()` | 获取读者锁（支持尝试模式） |\n| `percpu_down_write()` | 获取写者锁（阻塞式） |\n| `percpu_up_write()` | 释放写者锁 |\n| `percpu_is_read_locked()` | 检查是否存在活跃读者 |\n| `__percpu_down_read_trylock()` | 尝试快速获取读者锁 |\n| `__percpu_down_write_trylock()` | 尝试快速获取写者锁 |\n| `readers_active_check()` | 检查所有读者是否已退出 |\n\n## 3. 关键实现\n\n### 3.1 读者快速路径（Fast Path）\n- **无锁计数**：读者通过 `this_cpu_inc(*sem->read_count)` 原子增加本 CPU 计数（禁用抢占保证 CPU 亲和性）\n- **内存屏障**：`smp_mb()` 确保 `block` 标志的读取顺序\n- **乐观检查**：若 `block==0` 则直接进入临界区；否则回退并唤醒写者\n\n### 3.2 写者同步机制\n1. **阻塞新读者**：通过 `rcu_sync_enter()` 通知读者走慢路径，并设置 `block=1`\n2. **等待活跃读者**：使用 `rcuwait_wait_event()` 轮询 `readers_active_check()` 直到所有 per-CPU 计数归零\n3. **释放写锁**：\n   - 清除 `block` 标志（`atomic_set_release` 保证临界区内存可见性）\n   - 唤醒等待队列中的一个任务（FIFO 顺序）\n   - 调用 `rcu_sync_exit()` 允许读者恢复快速路径\n\n### 3.3 等待队列管理\n- **自定义唤醒函数** `percpu_rwsem_wake_function()`：\n  - 使用 `WQ_FLAG_EXCLUSIVE` 保证 FIFO\n  - 通过 `WQ_FLAG_CUSTOM` 区分读者/写者\n  - 返回值控制唤醒数量：读者可批量唤醒，写者仅唤醒一个\n\n### 3.4 内存序保障\n- **读者-写者同步**：通过四组内存屏障配对（代码注释 A/B/C/D）确保：\n  - 读者增量操作与写者 `block` 检查的顺序性\n  - 写者释放锁后读者能观察到临界区修改\n\n## 4. 依赖关系\n\n| 依赖模块 | 用途 |\n|----------|------|\n| `linux/percpu.h` | 提供 per-CPU 变量分配/访问接口 |\n| `linux/rcupdate.h` | 通过 `rcu_sync` 协调 RCU 与写者临界区 |\n| `linux/rcuwait.h` | 实现写者等待读者退出的睡眠机制 |\n| `linux/lockdep.h` | 提供锁依赖验证（DEBUG_LOCK_ALLOC） |\n| `linux/atomic.h` | 原子操作（`block` 标志管理） |\n| `trace/events/lock.h` | 锁竞争事件追踪 |\n\n## 5. 使用场景\n\n- **文件系统**：如 `alloc_super()` 中用于保护超级块操作\n- **内存管理**：需要频繁读取但偶尔修改的全局状态（如内存策略）\n- **网络子系统**：路由表等读多写少的数据结构保护\n- **性能关键路径**：替代传统读写锁以消除读者间的原子操作开销\n\n> **典型工作流**：  \n> 1. 读者通过 `__percpu_down_read()` 快速进入（无全局锁）  \n> 2. 写者调用 `percpu_down_write()` 阻塞新读者并等待现存读者退出  \n> 3. 写者完成操作后 `percpu_up_write()` 恢复读者快速路径  \n> 4. 所有操作通过 RCU 机制保证内存一致性",
      "similarity": 0.5762155055999756,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/percpu-rwsem.c",
          "start_line": 141,
          "end_line": 255,
          "content": [
            "static void percpu_rwsem_wait(struct percpu_rw_semaphore *sem, bool reader)",
            "{",
            "\tDEFINE_WAIT_FUNC(wq_entry, percpu_rwsem_wake_function);",
            "\tbool wait;",
            "",
            "\tspin_lock_irq(&sem->waiters.lock);",
            "\t/*",
            "\t * Serialize against the wakeup in percpu_up_write(), if we fail",
            "\t * the trylock, the wakeup must see us on the list.",
            "\t */",
            "\twait = !__percpu_rwsem_trylock(sem, reader);",
            "\tif (wait) {",
            "\t\twq_entry.flags |= WQ_FLAG_EXCLUSIVE | reader * WQ_FLAG_CUSTOM;",
            "\t\t__add_wait_queue_entry_tail(&sem->waiters, &wq_entry);",
            "\t}",
            "\tspin_unlock_irq(&sem->waiters.lock);",
            "",
            "\twhile (wait) {",
            "\t\tset_current_state(TASK_UNINTERRUPTIBLE);",
            "\t\tif (!smp_load_acquire(&wq_entry.private))",
            "\t\t\tbreak;",
            "\t\tschedule();",
            "\t}",
            "\t__set_current_state(TASK_RUNNING);",
            "}",
            "bool __sched __percpu_down_read(struct percpu_rw_semaphore *sem, bool try)",
            "{",
            "\tif (__percpu_down_read_trylock(sem))",
            "\t\treturn true;",
            "",
            "\tif (try)",
            "\t\treturn false;",
            "",
            "\ttrace_contention_begin(sem, LCB_F_PERCPU | LCB_F_READ);",
            "\tpreempt_enable();",
            "\tpercpu_rwsem_wait(sem, /* .reader = */ true);",
            "\tpreempt_disable();",
            "\ttrace_contention_end(sem, 0);",
            "",
            "\treturn true;",
            "}",
            "bool percpu_is_read_locked(struct percpu_rw_semaphore *sem)",
            "{",
            "\treturn per_cpu_sum(*sem->read_count) != 0 && !atomic_read(&sem->block);",
            "}",
            "static bool readers_active_check(struct percpu_rw_semaphore *sem)",
            "{",
            "\tif (per_cpu_sum(*sem->read_count) != 0)",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * If we observed the decrement; ensure we see the entire critical",
            "\t * section.",
            "\t */",
            "",
            "\tsmp_mb(); /* C matches B */",
            "",
            "\treturn true;",
            "}",
            "void __sched percpu_down_write(struct percpu_rw_semaphore *sem)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);",
            "\ttrace_contention_begin(sem, LCB_F_PERCPU | LCB_F_WRITE);",
            "",
            "\t/* Notify readers to take the slow path. */",
            "\trcu_sync_enter(&sem->rss);",
            "",
            "\t/*",
            "\t * Try set sem->block; this provides writer-writer exclusion.",
            "\t * Having sem->block set makes new readers block.",
            "\t */",
            "\tif (!__percpu_down_write_trylock(sem))",
            "\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);",
            "",
            "\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */",
            "",
            "\t/*",
            "\t * If they don't see our store of sem->block, then we are guaranteed to",
            "\t * see their sem->read_count increment, and therefore will wait for",
            "\t * them.",
            "\t */",
            "",
            "\t/* Wait for all active readers to complete. */",
            "\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);",
            "\ttrace_contention_end(sem, 0);",
            "}",
            "void percpu_up_write(struct percpu_rw_semaphore *sem)",
            "{",
            "\trwsem_release(&sem->dep_map, _RET_IP_);",
            "",
            "\t/*",
            "\t * Signal the writer is done, no fast path yet.",
            "\t *",
            "\t * One reason that we cannot just immediately flip to readers_fast is",
            "\t * that new readers might fail to see the results of this writer's",
            "\t * critical section.",
            "\t *",
            "\t * Therefore we force it through the slow path which guarantees an",
            "\t * acquire and thereby guarantees the critical section's consistency.",
            "\t */",
            "\tatomic_set_release(&sem->block, 0);",
            "",
            "\t/*",
            "\t * Prod any pending reader/writer to make progress.",
            "\t */",
            "\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);",
            "",
            "\t/*",
            "\t * Once this completes (at least one RCU-sched grace period hence) the",
            "\t * reader fast path will be available again. Safe to use outside the",
            "\t * exclusive write lock because its counting.",
            "\t */",
            "\trcu_sync_exit(&sem->rss);",
            "}"
          ],
          "function_name": "percpu_rwsem_wait, __percpu_down_read, percpu_is_read_locked, readers_active_check, percpu_down_write, percpu_up_write",
          "description": "实现读写信号量的阻塞等待逻辑，包含读锁状态检测、读者活跃性检查、写锁获取与释放流程，通过 RCU 等待队列实现跨 CPU 的有序唤醒机制",
          "similarity": 0.5871168375015259
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/percpu-rwsem.c",
          "start_line": 14,
          "end_line": 119,
          "content": [
            "int __percpu_init_rwsem(struct percpu_rw_semaphore *sem,",
            "\t\t\tconst char *name, struct lock_class_key *key)",
            "{",
            "\tsem->read_count = alloc_percpu(int);",
            "\tif (unlikely(!sem->read_count))",
            "\t\treturn -ENOMEM;",
            "",
            "\trcu_sync_init(&sem->rss);",
            "\trcuwait_init(&sem->writer);",
            "\tinit_waitqueue_head(&sem->waiters);",
            "\tatomic_set(&sem->block, 0);",
            "#ifdef CONFIG_DEBUG_LOCK_ALLOC",
            "\tdebug_check_no_locks_freed((void *)sem, sizeof(*sem));",
            "\tlockdep_init_map(&sem->dep_map, name, key, 0);",
            "#endif",
            "\treturn 0;",
            "}",
            "void percpu_free_rwsem(struct percpu_rw_semaphore *sem)",
            "{",
            "\t/*",
            "\t * XXX: temporary kludge. The error path in alloc_super()",
            "\t * assumes that percpu_free_rwsem() is safe after kzalloc().",
            "\t */",
            "\tif (!sem->read_count)",
            "\t\treturn;",
            "",
            "\trcu_sync_dtor(&sem->rss);",
            "\tfree_percpu(sem->read_count);",
            "\tsem->read_count = NULL; /* catch use after free bugs */",
            "}",
            "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)",
            "{",
            "\tthis_cpu_inc(*sem->read_count);",
            "",
            "\t/*",
            "\t * Due to having preemption disabled the decrement happens on",
            "\t * the same CPU as the increment, avoiding the",
            "\t * increment-on-one-CPU-and-decrement-on-another problem.",
            "\t *",
            "\t * If the reader misses the writer's assignment of sem->block, then the",
            "\t * writer is guaranteed to see the reader's increment.",
            "\t *",
            "\t * Conversely, any readers that increment their sem->read_count after",
            "\t * the writer looks are guaranteed to see the sem->block value, which",
            "\t * in turn means that they are guaranteed to immediately decrement",
            "\t * their sem->read_count, so that it doesn't matter that the writer",
            "\t * missed them.",
            "\t */",
            "",
            "\tsmp_mb(); /* A matches D */",
            "",
            "\t/*",
            "\t * If !sem->block the critical section starts here, matched by the",
            "\t * release in percpu_up_write().",
            "\t */",
            "\tif (likely(!atomic_read_acquire(&sem->block)))",
            "\t\treturn true;",
            "",
            "\tthis_cpu_dec(*sem->read_count);",
            "",
            "\t/* Prod writer to re-evaluate readers_active_check() */",
            "\trcuwait_wake_up(&sem->writer);",
            "",
            "\treturn false;",
            "}",
            "static inline bool __percpu_down_write_trylock(struct percpu_rw_semaphore *sem)",
            "{",
            "\tif (atomic_read(&sem->block))",
            "\t\treturn false;",
            "",
            "\treturn atomic_xchg(&sem->block, 1) == 0;",
            "}",
            "static bool __percpu_rwsem_trylock(struct percpu_rw_semaphore *sem, bool reader)",
            "{",
            "\tif (reader) {",
            "\t\tbool ret;",
            "",
            "\t\tpreempt_disable();",
            "\t\tret = __percpu_down_read_trylock(sem);",
            "\t\tpreempt_enable();",
            "",
            "\t\treturn ret;",
            "\t}",
            "\treturn __percpu_down_write_trylock(sem);",
            "}",
            "static int percpu_rwsem_wake_function(struct wait_queue_entry *wq_entry,",
            "\t\t\t\t      unsigned int mode, int wake_flags,",
            "\t\t\t\t      void *key)",
            "{",
            "\tbool reader = wq_entry->flags & WQ_FLAG_CUSTOM;",
            "\tstruct percpu_rw_semaphore *sem = key;",
            "\tstruct task_struct *p;",
            "",
            "\t/* concurrent against percpu_down_write(), can get stolen */",
            "\tif (!__percpu_rwsem_trylock(sem, reader))",
            "\t\treturn 1;",
            "",
            "\tp = get_task_struct(wq_entry->private);",
            "\tlist_del_init(&wq_entry->entry);",
            "\tsmp_store_release(&wq_entry->private, NULL);",
            "",
            "\twake_up_process(p);",
            "\tput_task_struct(p);",
            "",
            "\treturn !reader; /* wake (readers until) 1 writer */",
            "}"
          ],
          "function_name": "__percpu_init_rwsem, percpu_free_rwsem, __percpu_down_read_trylock, __percpu_down_write_trylock, __percpu_rwsem_trylock, percpu_rwsem_wake_function",
          "description": "实现 PER-CPU 读写信号量的初始化/释放接口，包含读写尝试加锁逻辑，通过 PER-CPU 变量维护读计数器，利用 RCU 同步与内存屏障保证跨 CPU 访问可见性",
          "similarity": 0.5152603387832642
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/percpu-rwsem.c",
          "start_line": 1,
          "end_line": 13,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "#include <linux/atomic.h>",
            "#include <linux/percpu.h>",
            "#include <linux/wait.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/sched.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/errno.h>",
            "#include <trace/events/lock.h>",
            ""
          ],
          "function_name": null,
          "description": "声明并引入实现 PER-CPU 读写信号量所需的内核头文件，包含原子操作、PER-CPU 变量、等待队列、锁跟踪等核心模块",
          "similarity": 0.4710466265678406
        }
      ]
    }
  ]
}