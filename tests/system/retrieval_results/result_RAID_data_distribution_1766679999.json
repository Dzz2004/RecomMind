{
  "query": "RAID data distribution",
  "timestamp": "2025-12-26 00:26:39",
  "retrieved_files": [
    {
      "source_file": "kernel/pid.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:16:06\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `pid.c`\n\n---\n\n# `pid.c` 技术文档\n\n## 1. 文件概述\n\n`pid.c` 是 Linux 内核中实现进程标识符（PID）管理和分配机制的核心文件。它提供了可扩展、时间有界的 PID 分配器，支持 PID 哈希表（pidhash）以及 PID 命名空间（pid namespace）功能。该文件负责 PID 的分配、释放、引用计数管理，并确保在多处理器（SMP）环境下的线程安全性。其设计目标是在高并发场景下高效、无锁地分配和回收 PID，同时支持容器化环境中的 PID 隔离。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct pid`**  \n  表示一个 PID 实例，包含：\n  - 引用计数（`count`）\n  - 多种任务类型链表（`tasks[PIDTYPE_MAX]`），用于关联不同类型的进程（如线程组、会话等）\n  - PID 层级（`level`），用于命名空间嵌套\n  - `numbers[]` 数组：每个命名空间层级对应的 `struct upid`（包含实际 PID 编号 `nr` 和所属命名空间 `ns`）\n  - `rcu` 字段：用于 RCU 安全释放\n  - `wait_pidfd`：用于 pidfd 机制的等待队列\n  - `inodes`：关联的 pidfs inode 列表\n\n- **`struct pid_namespace`**  \n  PID 命名空间结构，包含：\n  - IDR（整数 ID 映射）结构 `idr`，用于高效 PID 分配\n  - `pid_allocated`：当前已分配 PID 数量（含特殊状态如 `PIDNS_ADDING`）\n  - `child_reaper`：命名空间中的 init 进程（子进程回收者）\n  - `level`：命名空间嵌套层级\n  - `pid_cachep`：用于分配 `struct pid` 的 slab 缓存\n\n- **全局变量**\n  - `init_struct_pid`：初始 PID 结构（PID 0，用于 idle 进程）\n  - `init_pid_ns`：初始 PID 命名空间\n  - `pid_max` / `pid_max_min` / `pid_max_max`：PID 分配上限控制\n  - `pidfs_ino`：pidfs 文件系统的 inode 编号起始值\n  - `pidmap_lock`：保护 IDR 和 `pid_allocated` 的自旋锁（SMP 对齐）\n\n### 主要函数\n\n- **`alloc_pid(struct pid_namespace *ns, pid_t *set_tid, size_t set_tid_size)`**  \n  在指定 PID 命名空间中分配一个新的 PID。支持通过 `set_tid` 数组在嵌套命名空间中预设 PID（用于容器恢复等场景）。\n\n- **`free_pid(struct pid *pid)`**  \n  释放 PID 资源，从所有嵌套命名空间的 IDR 中移除，并减少 `pid_allocated` 计数。若命名空间中仅剩 reaper 进程，则唤醒它。\n\n- **`put_pid(struct pid *pid)`**  \n  减少 PID 引用计数，若引用归零则释放内存并减少命名空间引用。\n\n- **`delayed_put_pid(struct rcu_head *rhp)`**  \n  RCU 回调函数，用于安全释放 PID 结构。\n\n## 3. 关键实现\n\n### PID 分配机制\n- 使用 **IDR（Integer ID Allocator）** 替代传统的位图（bitmap），实现 O(1) 分配与释放。\n- 默认采用**循环分配策略**（`idr_alloc_cyclic`），从 `RESERVED_PIDS`（通常为 300）开始，避免低编号 PID 被耗尽。\n- 支持**预设 PID 分配**：通过 `set_tid` 参数在创建进程时指定特定 PID（需具备 `CAP_CHECKPOINT_RESTORE` 权限），用于容器快照恢复。\n\n### 命名空间支持\n- 每个 PID 在嵌套的命名空间中拥有不同的编号（`upid->nr`），通过 `pid->numbers[]` 数组维护层级关系。\n- `pid->level` 表示该 PID 所属的最深命名空间层级。\n- 分配时从最深层命名空间向上遍历至根命名空间，逐层分配 PID。\n\n### 并发与同步\n- **`pidmap_lock`**：保护 IDR 操作和 `pid_allocated` 计数器，使用 `spin_lock_irqsave` 禁用本地中断，防止与 `tasklist_lock` 的死锁。\n- **RCU 释放**：`free_pid` 通过 `call_rcu` 延迟释放 PID 结构，避免在持有锁时执行内存释放。\n- **引用计数**：`struct pid` 使用 `refcount_t` 管理生命周期，确保多任务共享 PID 时的安全释放。\n\n### 特殊状态处理\n- **`PIDNS_ADDING`**：标记命名空间正在添加新进程，防止在 fork 失败时错误减少计数。\n- **Reaper 唤醒**：当命名空间中 PID 数量降至 1 或 2 时，唤醒 `child_reaper`（通常为 init 进程），用于处理命名空间退出（`zap_pid_ns_processes`）。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/pid_namespace.h>`：PID 命名空间定义\n  - `<linux/idr.h>`：IDR 分配器实现\n  - `<linux/rculist.h>`：RCU 安全链表操作\n  - `<linux/sched/task.h>`、`<linux/sched/signal.h>`：任务调度与信号处理\n  - `<linux/pidfs.h>`、`<uapi/linux/pidfd.h>`：pidfd 和 pidfs 支持\n  - `<linux/refcount.h>`：引用计数机制\n\n- **内核模块交互**：\n  - **进程管理子系统**：与 `fork`/`clone` 系统调用集成，分配 PID 并关联到 `task_struct`\n  - **命名空间子系统**：与 `pidns_operations` 协同实现 PID 隔离\n  - **VFS 子系统**：通过 `pidfs_ino` 为 `/proc/[pid]` 提供 inode 编号\n  - **内存管理**：使用 slab 分配器（`kmem_cache_alloc`）管理 `struct pid` 内存\n\n## 5. 使用场景\n\n- **进程创建**：在 `copy_process` 中调用 `alloc_pid` 为新进程分配唯一 PID。\n- **容器运行时**：通过 `clone(CLONE_NEWPID)` 创建 PID 命名空间，实现容器内 PID 隔离。\n- **检查点/恢复（CRIU）**：使用 `set_tid` 参数在恢复进程时精确还原原始 PID。\n- **pidfd 机制**：`pid->wait_pidfd` 支持通过文件描述符等待进程退出（`pidfd_send_signal` 等系统调用）。\n- **命名空间清理**：当容器退出时，`free_pid` 触发 reaper 唤醒，确保孤儿进程被正确回收。",
      "similarity": 0.5470038056373596,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/pid.c",
          "start_line": 109,
          "end_line": 221,
          "content": [
            "void put_pid(struct pid *pid)",
            "{",
            "\tstruct pid_namespace *ns;",
            "",
            "\tif (!pid)",
            "\t\treturn;",
            "",
            "\tns = pid->numbers[pid->level].ns;",
            "\tif (refcount_dec_and_test(&pid->count)) {",
            "\t\tkmem_cache_free(ns->pid_cachep, pid);",
            "\t\tput_pid_ns(ns);",
            "\t}",
            "}",
            "static void delayed_put_pid(struct rcu_head *rhp)",
            "{",
            "\tstruct pid *pid = container_of(rhp, struct pid, rcu);",
            "\tput_pid(pid);",
            "}",
            "void free_pid(struct pid *pid)",
            "{",
            "\t/* We can be called with write_lock_irq(&tasklist_lock) held */",
            "\tint i;",
            "\tunsigned long flags;",
            "",
            "\tspin_lock_irqsave(&pidmap_lock, flags);",
            "\tfor (i = 0; i <= pid->level; i++) {",
            "\t\tstruct upid *upid = pid->numbers + i;",
            "\t\tstruct pid_namespace *ns = upid->ns;",
            "\t\tswitch (--ns->pid_allocated) {",
            "\t\tcase 2:",
            "\t\tcase 1:",
            "\t\t\t/* When all that is left in the pid namespace",
            "\t\t\t * is the reaper wake up the reaper.  The reaper",
            "\t\t\t * may be sleeping in zap_pid_ns_processes().",
            "\t\t\t */",
            "\t\t\twake_up_process(ns->child_reaper);",
            "\t\t\tbreak;",
            "\t\tcase PIDNS_ADDING:",
            "\t\t\t/* Handle a fork failure of the first process */",
            "\t\t\tWARN_ON(ns->child_reaper);",
            "\t\t\tns->pid_allocated = 0;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tidr_remove(&ns->idr, upid->nr);",
            "\t}",
            "\tpidfs_remove_pid(pid);",
            "\tspin_unlock_irqrestore(&pidmap_lock, flags);",
            "",
            "\tcall_rcu(&pid->rcu, delayed_put_pid);",
            "}",
            "void disable_pid_allocation(struct pid_namespace *ns)",
            "{",
            "\tspin_lock_irq(&pidmap_lock);",
            "\tns->pid_allocated &= ~PIDNS_ADDING;",
            "\tspin_unlock_irq(&pidmap_lock);",
            "}",
            "void attach_pid(struct task_struct *task, enum pid_type type)",
            "{",
            "\tstruct pid *pid = *task_pid_ptr(task, type);",
            "\thlist_add_head_rcu(&task->pid_links[type], &pid->tasks[type]);",
            "}",
            "static void __change_pid(struct task_struct *task, enum pid_type type,",
            "\t\t\tstruct pid *new)",
            "{",
            "\tstruct pid **pid_ptr = task_pid_ptr(task, type);",
            "\tstruct pid *pid;",
            "\tint tmp;",
            "",
            "\tpid = *pid_ptr;",
            "",
            "\thlist_del_rcu(&task->pid_links[type]);",
            "\t*pid_ptr = new;",
            "",
            "\tif (type == PIDTYPE_PID) {",
            "\t\tWARN_ON_ONCE(pid_has_task(pid, PIDTYPE_PID));",
            "\t\twake_up_all(&pid->wait_pidfd);",
            "\t}",
            "",
            "\tfor (tmp = PIDTYPE_MAX; --tmp >= 0; )",
            "\t\tif (pid_has_task(pid, tmp))",
            "\t\t\treturn;",
            "",
            "\tfree_pid(pid);",
            "}",
            "void detach_pid(struct task_struct *task, enum pid_type type)",
            "{",
            "\t__change_pid(task, type, NULL);",
            "}",
            "void change_pid(struct task_struct *task, enum pid_type type,",
            "\t\tstruct pid *pid)",
            "{",
            "\t__change_pid(task, type, pid);",
            "\tattach_pid(task, type);",
            "}",
            "void exchange_tids(struct task_struct *left, struct task_struct *right)",
            "{",
            "\tstruct pid *pid1 = left->thread_pid;",
            "\tstruct pid *pid2 = right->thread_pid;",
            "\tstruct hlist_head *head1 = &pid1->tasks[PIDTYPE_PID];",
            "\tstruct hlist_head *head2 = &pid2->tasks[PIDTYPE_PID];",
            "",
            "\t/* Swap the single entry tid lists */",
            "\thlists_swap_heads_rcu(head1, head2);",
            "",
            "\t/* Swap the per task_struct pid */",
            "\trcu_assign_pointer(left->thread_pid, pid2);",
            "\trcu_assign_pointer(right->thread_pid, pid1);",
            "",
            "\t/* Swap the cached value */",
            "\tWRITE_ONCE(left->pid, pid_nr(pid2));",
            "\tWRITE_ONCE(right->pid, pid_nr(pid1));",
            "}"
          ],
          "function_name": "put_pid, delayed_put_pid, free_pid, disable_pid_allocation, attach_pid, __change_pid, detach_pid, change_pid, exchange_tids",
          "description": "实现PID引用计数管理、释放逻辑及任务PID绑定操作，通过锁保护PID分配状态变更，利用RCU机制延迟释放内存，并处理进程ID类型切换和线程ID交换。",
          "similarity": 0.5339245796203613
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/pid.c",
          "start_line": 402,
          "end_line": 488,
          "content": [
            "void transfer_pid(struct task_struct *old, struct task_struct *new,",
            "\t\t\t   enum pid_type type)",
            "{",
            "\tWARN_ON_ONCE(type == PIDTYPE_PID);",
            "\thlist_replace_rcu(&old->pid_links[type], &new->pid_links[type]);",
            "}",
            "pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns)",
            "{",
            "\tstruct upid *upid;",
            "\tpid_t nr = 0;",
            "",
            "\tif (pid && ns->level <= pid->level) {",
            "\t\tupid = &pid->numbers[ns->level];",
            "\t\tif (upid->ns == ns)",
            "\t\t\tnr = upid->nr;",
            "\t}",
            "\treturn nr;",
            "}",
            "pid_t pid_vnr(struct pid *pid)",
            "{",
            "\treturn pid_nr_ns(pid, task_active_pid_ns(current));",
            "}",
            "pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,",
            "\t\t\tstruct pid_namespace *ns)",
            "{",
            "\tpid_t nr = 0;",
            "",
            "\trcu_read_lock();",
            "\tif (!ns)",
            "\t\tns = task_active_pid_ns(current);",
            "\tnr = pid_nr_ns(rcu_dereference(*task_pid_ptr(task, type)), ns);",
            "\trcu_read_unlock();",
            "",
            "\treturn nr;",
            "}",
            "static int pidfd_create(struct pid *pid, unsigned int flags)",
            "{",
            "\tint pidfd;",
            "\tstruct file *pidfd_file;",
            "",
            "\tpidfd = pidfd_prepare(pid, flags, &pidfd_file);",
            "\tif (pidfd < 0)",
            "\t\treturn pidfd;",
            "",
            "\tfd_install(pidfd, pidfd_file);",
            "\treturn pidfd;",
            "}",
            "void __init pid_idr_init(void)",
            "{",
            "\t/* Verify no one has done anything silly: */",
            "\tBUILD_BUG_ON(PID_MAX_LIMIT >= PIDNS_ADDING);",
            "",
            "\t/* bump default and minimum pid_max based on number of cpus */",
            "\tpid_max = min(pid_max_max, max_t(int, pid_max,",
            "\t\t\t\tPIDS_PER_CPU_DEFAULT * num_possible_cpus()));",
            "\tpid_max_min = max_t(int, pid_max_min,",
            "\t\t\t\tPIDS_PER_CPU_MIN * num_possible_cpus());",
            "\tpr_info(\"pid_max: default: %u minimum: %u\\n\", pid_max, pid_max_min);",
            "",
            "\tidr_init(&init_pid_ns.idr);",
            "",
            "\tinit_pid_ns.pid_cachep = kmem_cache_create(\"pid\",",
            "\t\t\tstruct_size_t(struct pid, numbers, 1),",
            "\t\t\t__alignof__(struct pid),",
            "\t\t\tSLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT,",
            "\t\t\tNULL);",
            "}",
            "static int pidfd_getfd(struct pid *pid, int fd)",
            "{",
            "\tstruct task_struct *task;",
            "\tstruct file *file;",
            "\tint ret;",
            "",
            "\ttask = get_pid_task(pid, PIDTYPE_PID);",
            "\tif (!task)",
            "\t\treturn -ESRCH;",
            "",
            "\tfile = __pidfd_fget(task, fd);",
            "\tput_task_struct(task);",
            "\tif (IS_ERR(file))",
            "\t\treturn PTR_ERR(file);",
            "",
            "\tret = receive_fd(file, O_CLOEXEC);",
            "\tfput(file);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "transfer_pid, pid_nr_ns, pid_vnr, __task_pid_nr_ns, pidfd_create, pid_idr_init, pidfd_getfd",
          "description": "提供跨命名空间PID查询接口及文件描述符创建功能，初始化ID分配器并配置PID命名空间层级关系，支持基于IDR的高效PID索引管理。",
          "similarity": 0.4780225157737732
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/pid.c",
          "start_line": 1,
          "end_line": 108,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Generic pidhash and scalable, time-bounded PID allocator",
            " *",
            " * (C) 2002-2003 Nadia Yvette Chambers, IBM",
            " * (C) 2004 Nadia Yvette Chambers, Oracle",
            " * (C) 2002-2004 Ingo Molnar, Red Hat",
            " *",
            " * pid-structures are backing objects for tasks sharing a given ID to chain",
            " * against. There is very little to them aside from hashing them and",
            " * parking tasks using given ID's on a list.",
            " *",
            " * The hash is always changed with the tasklist_lock write-acquired,",
            " * and the hash is only accessed with the tasklist_lock at least",
            " * read-acquired, so there's no additional SMP locking needed here.",
            " *",
            " * We have a list of bitmap pages, which bitmaps represent the PID space.",
            " * Allocating and freeing PIDs is completely lockless. The worst-case",
            " * allocation scenario when all but one out of 1 million PIDs possible are",
            " * allocated already: the scanning of 32 list entries and at most PAGE_SIZE",
            " * bytes. The typical fastpath is a single successful setbit. Freeing is O(1).",
            " *",
            " * Pid namespaces:",
            " *    (C) 2007 Pavel Emelyanov <xemul@openvz.org>, OpenVZ, SWsoft Inc.",
            " *    (C) 2007 Sukadev Bhattiprolu <sukadev@us.ibm.com>, IBM",
            " *     Many thanks to Oleg Nesterov for comments and help",
            " *",
            " */",
            "",
            "#include <linux/mm.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/init.h>",
            "#include <linux/rculist.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/init_task.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/refcount.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/idr.h>",
            "#include <linux/pidfs.h>",
            "#include <linux/seqlock.h>",
            "#include <net/sock.h>",
            "#include <uapi/linux/pidfd.h>",
            "",
            "struct pid init_struct_pid = {",
            "\t.count\t\t= REFCOUNT_INIT(1),",
            "\t.tasks\t\t= {",
            "\t\t{ .first = NULL },",
            "\t\t{ .first = NULL },",
            "\t\t{ .first = NULL },",
            "\t},",
            "\t.level\t\t= 0,",
            "\t.numbers\t= { {",
            "\t\t.nr\t\t= 0,",
            "\t\t.ns\t\t= &init_pid_ns,",
            "\t}, }",
            "};",
            "",
            "int pid_max = PID_MAX_DEFAULT;",
            "",
            "int pid_max_min = RESERVED_PIDS + 1;",
            "int pid_max_max = PID_MAX_LIMIT;",
            "",
            "/*",
            " * PID-map pages start out as NULL, they get allocated upon",
            " * first use and are never deallocated. This way a low pid_max",
            " * value does not cause lots of bitmaps to be allocated, but",
            " * the scheme scales to up to 4 million PIDs, runtime.",
            " */",
            "struct pid_namespace init_pid_ns = {",
            "\t.ns.count = REFCOUNT_INIT(2),",
            "\t.idr = IDR_INIT(init_pid_ns.idr),",
            "\t.pid_allocated = PIDNS_ADDING,",
            "\t.level = 0,",
            "\t.child_reaper = &init_task,",
            "\t.user_ns = &init_user_ns,",
            "\t.ns.inum = PROC_PID_INIT_INO,",
            "#ifdef CONFIG_PID_NS",
            "\t.ns.ops = &pidns_operations,",
            "#endif",
            "#if defined(CONFIG_SYSCTL) && defined(CONFIG_MEMFD_CREATE)",
            "\t.memfd_noexec_scope = MEMFD_NOEXEC_SCOPE_EXEC,",
            "#endif",
            "};",
            "EXPORT_SYMBOL_GPL(init_pid_ns);",
            "",
            "/*",
            " * Note: disable interrupts while the pidmap_lock is held as an",
            " * interrupt might come in and do read_lock(&tasklist_lock).",
            " *",
            " * If we don't disable interrupts there is a nasty deadlock between",
            " * detach_pid()->free_pid() and another cpu that does",
            " * spin_lock(&pidmap_lock) followed by an interrupt routine that does",
            " * read_lock(&tasklist_lock);",
            " *",
            " * After we clean up the tasklist_lock and know there are no",
            " * irq handlers that take it we can leave the interrupts enabled.",
            " * For now it is easier to be safe than to prove it can't happen.",
            " */",
            "",
            "static  __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);",
            "seqcount_spinlock_t pidmap_lock_seq = SEQCNT_SPINLOCK_ZERO(pidmap_lock_seq, &pidmap_lock);",
            ""
          ],
          "function_name": null,
          "description": "定义了PID命名空间和PID结构体的初始状态，包括全局PID最大值限制、PID映射锁及序列化机制，用于支持多层级PID分配和命名空间隔离。",
          "similarity": 0.4695737361907959
        }
      ]
    },
    {
      "source_file": "kernel/relay.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:52:35\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `relay.c`\n\n---\n\n# relay.c 技术文档\n\n## 1. 文件概述\n\n`relay.c` 实现了 Linux 内核中 **relay 通道（relay channel）** 的核心功能，用于高效地将内核空间的数据流式传输到用户空间。该机制通过预分配的环形缓冲区（由多个子缓冲区组成）实现零拷贝或最小拷贝的数据传递，特别适用于高性能追踪（tracing）、日志记录和监控等场景。用户空间可通过标准文件操作（如 `mmap`、`read`）访问这些缓冲区。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct rchan`：relay 通道的主结构体，包含通道配置、回调函数和 per-CPU 缓冲区指针。\n- `struct rchan_buf`：单个 CPU 的 relay 缓冲区结构体，包含实际数据缓冲区、状态信息（生产/消费计数器）和同步原语。\n\n### 关键函数\n- **缓冲区管理**：\n  - `relay_create_buf()`：为指定通道创建并初始化 per-CPU 缓冲区。\n  - `relay_destroy_buf()`：销毁缓冲区并释放资源。\n  - `relay_alloc_buf()`：分配物理页面并映射为连续虚拟地址的缓冲区。\n- **内存映射**：\n  - `relay_mmap_buf()`：将内核缓冲区映射到用户进程地址空间。\n  - `relay_buf_fault()`：处理用户空间访问映射区域时的缺页异常。\n- **状态控制**：\n  - `relay_reset()`：重置通道状态，清空所有缓冲区数据。\n  - `relay_buf_empty()` / `relay_buf_full()`：检查缓冲区是否为空或已满。\n- **资源回收**：\n  - `relay_destroy_channel()`：通过 `kref` 引用计数释放通道结构。\n  - `relay_remove_buf()`：通过 `kref` 释放缓冲区结构。\n- **辅助功能**：\n  - `wakeup_readers()`：通过 `irq_work` 机制唤醒等待读取数据的用户进程。\n\n## 3. 关键实现\n\n### 缓冲区分配策略\n- 使用 `alloc_page()` 分配离散物理页面，通过 `vmap()` 建立连续虚拟地址映射，避免大块连续物理内存分配失败。\n- 页面指针数组 (`page_array`) 用于管理物理页面，支持高效的 `vunmap()` 释放。\n\n### 用户空间映射机制\n- 通过 `vm_operations_struct.fault` 回调 (`relay_buf_fault`) 实现按需映射：用户访问映射区域时，动态将内核 `vmalloc` 区域的页面映射到用户页表。\n- 设置 `VM_DONTEXPAND` 标志防止用户空间扩展映射区域。\n\n### 环形缓冲区管理\n- 采用 **子缓冲区（subbuffer）** 作为基本单元，通过 `subbufs_produced` 和 `subbufs_consumed` 计数器实现生产者-消费者模型。\n- `subbuf_start` 回调允许用户自定义子缓冲区切换逻辑（如添加头部信息）。\n\n### 并发与同步\n- **Per-CPU 缓冲区**：每个 CPU 独立缓冲区避免锁竞争，提升多核性能。\n- **延迟唤醒**：使用 `irq_work` 机制将唤醒操作推迟到软中断上下文，避免在硬中断中调用 `wake_up_interruptible()`。\n- **引用计数**：通过 `kref` 确保通道和缓冲区在异步操作（如文件关闭）中安全释放。\n\n### CPU 热插拔支持\n- 全局链表 `relay_channels` 跟踪所有打开的通道，配合 `relay_channels_mutex` 锁，在 CPU 热插拔事件中动态创建/销毁 per-CPU 缓冲区。\n\n## 4. 依赖关系\n\n- **内存管理**：依赖 `vmalloc`、`vmap`/`vunmap`、`alloc_page` 等内存分配接口。\n- **同步原语**：使用 `mutex`（`relay_channels_mutex`）、`waitqueue`（`read_wait`）、`irq_work` 和 `kref`。\n- **CPU 热插拔**：通过 `for_each_possible_cpu` 和 per-CPU 变量 (`per_cpu_ptr`) 管理多核资源。\n- **VFS 层**：与文件系统交互（`mmap`、`splice`），但具体文件操作在 `relayfs` 或 `debugfs` 中实现。\n- **导出符号**：`relay_buf_full()` 通过 `EXPORT_SYMBOL_GPL` 供其他内核模块使用。\n\n## 5. 使用场景\n\n- **内核追踪系统**：如 `ftrace`、`perf` 使用 relay 通道高效导出追踪数据到用户空间。\n- **实时日志记录**：需要低延迟、高吞吐量的日志场景（如网络数据包捕获）。\n- **性能监控**：将内核统计信息（如调度事件、块设备 I/O）流式传输到用户态分析工具。\n- **调试工具**：通过 `debugfs` 暴露 relay 通道，供用户态调试器实时读取内核状态。",
      "similarity": 0.5362653732299805,
      "chunks": [
        {
          "chunk_id": 5,
          "file_path": "kernel/relay.c",
          "start_line": 956,
          "end_line": 1057,
          "content": [
            "static size_t relay_file_read_subbuf_avail(size_t read_pos,",
            "\t\t\t\t\t   struct rchan_buf *buf)",
            "{",
            "\tsize_t padding, avail = 0;",
            "\tsize_t read_subbuf, read_offset, write_subbuf, write_offset;",
            "\tsize_t subbuf_size = buf->chan->subbuf_size;",
            "",
            "\twrite_subbuf = (buf->data - buf->start) / subbuf_size;",
            "\twrite_offset = buf->offset > subbuf_size ? subbuf_size : buf->offset;",
            "\tread_subbuf = read_pos / subbuf_size;",
            "\tread_offset = read_pos % subbuf_size;",
            "\tpadding = buf->padding[read_subbuf];",
            "",
            "\tif (read_subbuf == write_subbuf) {",
            "\t\tif (read_offset + padding < write_offset)",
            "\t\t\tavail = write_offset - (read_offset + padding);",
            "\t} else",
            "\t\tavail = (subbuf_size - padding) - read_offset;",
            "",
            "\treturn avail;",
            "}",
            "static size_t relay_file_read_start_pos(struct rchan_buf *buf)",
            "{",
            "\tsize_t read_subbuf, padding, padding_start, padding_end;",
            "\tsize_t subbuf_size = buf->chan->subbuf_size;",
            "\tsize_t n_subbufs = buf->chan->n_subbufs;",
            "\tsize_t consumed = buf->subbufs_consumed % n_subbufs;",
            "\tsize_t read_pos = (consumed * subbuf_size + buf->bytes_consumed)",
            "\t\t\t% (n_subbufs * subbuf_size);",
            "",
            "\tread_subbuf = read_pos / subbuf_size;",
            "\tpadding = buf->padding[read_subbuf];",
            "\tpadding_start = (read_subbuf + 1) * subbuf_size - padding;",
            "\tpadding_end = (read_subbuf + 1) * subbuf_size;",
            "\tif (read_pos >= padding_start && read_pos < padding_end) {",
            "\t\tread_subbuf = (read_subbuf + 1) % n_subbufs;",
            "\t\tread_pos = read_subbuf * subbuf_size;",
            "\t}",
            "",
            "\treturn read_pos;",
            "}",
            "static size_t relay_file_read_end_pos(struct rchan_buf *buf,",
            "\t\t\t\t      size_t read_pos,",
            "\t\t\t\t      size_t count)",
            "{",
            "\tsize_t read_subbuf, padding, end_pos;",
            "\tsize_t subbuf_size = buf->chan->subbuf_size;",
            "\tsize_t n_subbufs = buf->chan->n_subbufs;",
            "",
            "\tread_subbuf = read_pos / subbuf_size;",
            "\tpadding = buf->padding[read_subbuf];",
            "\tif (read_pos % subbuf_size + count + padding == subbuf_size)",
            "\t\tend_pos = (read_subbuf + 1) * subbuf_size;",
            "\telse",
            "\t\tend_pos = read_pos + count;",
            "\tif (end_pos >= subbuf_size * n_subbufs)",
            "\t\tend_pos = 0;",
            "",
            "\treturn end_pos;",
            "}",
            "static ssize_t relay_file_read(struct file *filp,",
            "\t\t\t       char __user *buffer,",
            "\t\t\t       size_t count,",
            "\t\t\t       loff_t *ppos)",
            "{",
            "\tstruct rchan_buf *buf = filp->private_data;",
            "\tsize_t read_start, avail;",
            "\tsize_t written = 0;",
            "\tint ret;",
            "",
            "\tif (!count)",
            "\t\treturn 0;",
            "",
            "\tinode_lock(file_inode(filp));",
            "\tdo {",
            "\t\tvoid *from;",
            "",
            "\t\tif (!relay_file_read_avail(buf))",
            "\t\t\tbreak;",
            "",
            "\t\tread_start = relay_file_read_start_pos(buf);",
            "\t\tavail = relay_file_read_subbuf_avail(read_start, buf);",
            "\t\tif (!avail)",
            "\t\t\tbreak;",
            "",
            "\t\tavail = min(count, avail);",
            "\t\tfrom = buf->start + read_start;",
            "\t\tret = avail;",
            "\t\tif (copy_to_user(buffer, from, avail))",
            "\t\t\tbreak;",
            "",
            "\t\tbuffer += ret;",
            "\t\twritten += ret;",
            "\t\tcount -= ret;",
            "",
            "\t\trelay_file_read_consume(buf, read_start, ret);",
            "\t\t*ppos = relay_file_read_end_pos(buf, read_start, ret);",
            "\t} while (count);",
            "\tinode_unlock(file_inode(filp));",
            "",
            "\treturn written;",
            "}"
          ],
          "function_name": "relay_file_read_subbuf_avail, relay_file_read_start_pos, relay_file_read_end_pos, relay_file_read",
          "description": "计算 relay 缓冲区子缓冲区中可读字节数，考虑读取偏移和填充区域；确定读取起始位置并处理填充部分逻辑；计算读取结束位置并限制在缓冲区范围内；实现文件读取逻辑，从内核缓冲区复制数据至用户空间，更新读取状态和文件偏移量。上下文不完整",
          "similarity": 0.4985315501689911
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/relay.c",
          "start_line": 1,
          "end_line": 32,
          "content": [
            "/*",
            " * Public API and common code for kernel->userspace relay file support.",
            " *",
            " * See Documentation/filesystems/relay.rst for an overview.",
            " *",
            " * Copyright (C) 2002-2005 - Tom Zanussi (zanussi@us.ibm.com), IBM Corp",
            " * Copyright (C) 1999-2005 - Karim Yaghmour (karim@opersys.com)",
            " *",
            " * Moved to kernel/relay.c by Paul Mundt, 2006.",
            " * November 2006 - CPU hotplug support by Mathieu Desnoyers",
            " * \t(mathieu.desnoyers@polymtl.ca)",
            " *",
            " * This file is released under the GPL.",
            " */",
            "#include <linux/errno.h>",
            "#include <linux/stddef.h>",
            "#include <linux/slab.h>",
            "#include <linux/export.h>",
            "#include <linux/string.h>",
            "#include <linux/relay.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/mm.h>",
            "#include <linux/cpu.h>",
            "#include <linux/splice.h>",
            "",
            "/* list of open channels, for cpu hotplug */",
            "static DEFINE_MUTEX(relay_channels_mutex);",
            "static LIST_HEAD(relay_channels);",
            "",
            "/*",
            " * fault() vm_op implementation for relay file mapping.",
            " */"
          ],
          "function_name": null,
          "description": "定义了Relay子系统的公共API和通用代码，包含用于管理内核到用户空间数据中继的核心结构体、互斥锁及链表，用于CPU热插拔支持的通道列表管理。",
          "similarity": 0.4791140854358673
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/relay.c",
          "start_line": 1076,
          "end_line": 1186,
          "content": [
            "static void relay_consume_bytes(struct rchan_buf *rbuf, int bytes_consumed)",
            "{",
            "\trbuf->bytes_consumed += bytes_consumed;",
            "",
            "\tif (rbuf->bytes_consumed >= rbuf->chan->subbuf_size) {",
            "\t\trelay_subbufs_consumed(rbuf->chan, rbuf->cpu, 1);",
            "\t\trbuf->bytes_consumed %= rbuf->chan->subbuf_size;",
            "\t}",
            "}",
            "static void relay_pipe_buf_release(struct pipe_inode_info *pipe,",
            "\t\t\t\t   struct pipe_buffer *buf)",
            "{",
            "\tstruct rchan_buf *rbuf;",
            "",
            "\trbuf = (struct rchan_buf *)page_private(buf->page);",
            "\trelay_consume_bytes(rbuf, buf->private);",
            "}",
            "static void relay_page_release(struct splice_pipe_desc *spd, unsigned int i)",
            "{",
            "}",
            "static ssize_t subbuf_splice_actor(struct file *in,",
            "\t\t\t       loff_t *ppos,",
            "\t\t\t       struct pipe_inode_info *pipe,",
            "\t\t\t       size_t len,",
            "\t\t\t       unsigned int flags,",
            "\t\t\t       int *nonpad_ret)",
            "{",
            "\tunsigned int pidx, poff, total_len, subbuf_pages, nr_pages;",
            "\tstruct rchan_buf *rbuf = in->private_data;",
            "\tunsigned int subbuf_size = rbuf->chan->subbuf_size;",
            "\tuint64_t pos = (uint64_t) *ppos;",
            "\tuint32_t alloc_size = (uint32_t) rbuf->chan->alloc_size;",
            "\tsize_t read_start = (size_t) do_div(pos, alloc_size);",
            "\tsize_t read_subbuf = read_start / subbuf_size;",
            "\tsize_t padding = rbuf->padding[read_subbuf];",
            "\tsize_t nonpad_end = read_subbuf * subbuf_size + subbuf_size - padding;",
            "\tstruct page *pages[PIPE_DEF_BUFFERS];",
            "\tstruct partial_page partial[PIPE_DEF_BUFFERS];",
            "\tstruct splice_pipe_desc spd = {",
            "\t\t.pages = pages,",
            "\t\t.nr_pages = 0,",
            "\t\t.nr_pages_max = PIPE_DEF_BUFFERS,",
            "\t\t.partial = partial,",
            "\t\t.ops = &relay_pipe_buf_ops,",
            "\t\t.spd_release = relay_page_release,",
            "\t};",
            "\tssize_t ret;",
            "",
            "\tif (rbuf->subbufs_produced == rbuf->subbufs_consumed)",
            "\t\treturn 0;",
            "\tif (splice_grow_spd(pipe, &spd))",
            "\t\treturn -ENOMEM;",
            "",
            "\t/*",
            "\t * Adjust read len, if longer than what is available",
            "\t */",
            "\tif (len > (subbuf_size - read_start % subbuf_size))",
            "\t\tlen = subbuf_size - read_start % subbuf_size;",
            "",
            "\tsubbuf_pages = rbuf->chan->alloc_size >> PAGE_SHIFT;",
            "\tpidx = (read_start / PAGE_SIZE) % subbuf_pages;",
            "\tpoff = read_start & ~PAGE_MASK;",
            "\tnr_pages = min_t(unsigned int, subbuf_pages, spd.nr_pages_max);",
            "",
            "\tfor (total_len = 0; spd.nr_pages < nr_pages; spd.nr_pages++) {",
            "\t\tunsigned int this_len, this_end, private;",
            "\t\tunsigned int cur_pos = read_start + total_len;",
            "",
            "\t\tif (!len)",
            "\t\t\tbreak;",
            "",
            "\t\tthis_len = min_t(unsigned long, len, PAGE_SIZE - poff);",
            "\t\tprivate = this_len;",
            "",
            "\t\tspd.pages[spd.nr_pages] = rbuf->page_array[pidx];",
            "\t\tspd.partial[spd.nr_pages].offset = poff;",
            "",
            "\t\tthis_end = cur_pos + this_len;",
            "\t\tif (this_end >= nonpad_end) {",
            "\t\t\tthis_len = nonpad_end - cur_pos;",
            "\t\t\tprivate = this_len + padding;",
            "\t\t}",
            "\t\tspd.partial[spd.nr_pages].len = this_len;",
            "\t\tspd.partial[spd.nr_pages].private = private;",
            "",
            "\t\tlen -= this_len;",
            "\t\ttotal_len += this_len;",
            "\t\tpoff = 0;",
            "\t\tpidx = (pidx + 1) % subbuf_pages;",
            "",
            "\t\tif (this_end >= nonpad_end) {",
            "\t\t\tspd.nr_pages++;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "",
            "\tret = 0;",
            "\tif (!spd.nr_pages)",
            "\t\tgoto out;",
            "",
            "\tret = *nonpad_ret = splice_to_pipe(pipe, &spd);",
            "\tif (ret < 0 || ret < total_len)",
            "\t\tgoto out;",
            "",
            "        if (read_start + ret == nonpad_end)",
            "                ret += padding;",
            "",
            "out:",
            "\tsplice_shrink_spd(&spd);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "relay_consume_bytes, relay_pipe_buf_release, relay_page_release, subbuf_splice_actor",
          "description": "记录并更新 relay 缓冲区已消费字节数；释放管道缓冲区并触发 consume_bytes 操作；处理 splice 分页数据时的页面释放逻辑；实现分页数据复制到管道的 actor 函数，处理填充区域和页面分配。上下文不完整",
          "similarity": 0.4743501543998718
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/relay.c",
          "start_line": 33,
          "end_line": 145,
          "content": [
            "static vm_fault_t relay_buf_fault(struct vm_fault *vmf)",
            "{",
            "\tstruct page *page;",
            "\tstruct rchan_buf *buf = vmf->vma->vm_private_data;",
            "\tpgoff_t pgoff = vmf->pgoff;",
            "",
            "\tif (!buf)",
            "\t\treturn VM_FAULT_OOM;",
            "",
            "\tpage = vmalloc_to_page(buf->start + (pgoff << PAGE_SHIFT));",
            "\tif (!page)",
            "\t\treturn VM_FAULT_SIGBUS;",
            "\tget_page(page);",
            "\tvmf->page = page;",
            "",
            "\treturn 0;",
            "}",
            "static void relay_free_page_array(struct page **array)",
            "{",
            "\tkvfree(array);",
            "}",
            "static int relay_mmap_buf(struct rchan_buf *buf, struct vm_area_struct *vma)",
            "{",
            "\tunsigned long length = vma->vm_end - vma->vm_start;",
            "",
            "\tif (!buf)",
            "\t\treturn -EBADF;",
            "",
            "\tif (length != (unsigned long)buf->chan->alloc_size)",
            "\t\treturn -EINVAL;",
            "",
            "\tvma->vm_ops = &relay_file_mmap_ops;",
            "\tvm_flags_set(vma, VM_DONTEXPAND);",
            "\tvma->vm_private_data = buf;",
            "",
            "\treturn 0;",
            "}",
            "static void relay_destroy_channel(struct kref *kref)",
            "{",
            "\tstruct rchan *chan = container_of(kref, struct rchan, kref);",
            "\tfree_percpu(chan->buf);",
            "\tkfree(chan);",
            "}",
            "static void relay_destroy_buf(struct rchan_buf *buf)",
            "{",
            "\tstruct rchan *chan = buf->chan;",
            "\tunsigned int i;",
            "",
            "\tif (likely(buf->start)) {",
            "\t\tvunmap(buf->start);",
            "\t\tfor (i = 0; i < buf->page_count; i++)",
            "\t\t\t__free_page(buf->page_array[i]);",
            "\t\trelay_free_page_array(buf->page_array);",
            "\t}",
            "\t*per_cpu_ptr(chan->buf, buf->cpu) = NULL;",
            "\tkfree(buf->padding);",
            "\tkfree(buf);",
            "\tkref_put(&chan->kref, relay_destroy_channel);",
            "}",
            "static void relay_remove_buf(struct kref *kref)",
            "{",
            "\tstruct rchan_buf *buf = container_of(kref, struct rchan_buf, kref);",
            "\trelay_destroy_buf(buf);",
            "}",
            "static int relay_buf_empty(struct rchan_buf *buf)",
            "{",
            "\treturn (buf->subbufs_produced - buf->subbufs_consumed) ? 0 : 1;",
            "}",
            "int relay_buf_full(struct rchan_buf *buf)",
            "{",
            "\tsize_t ready = buf->subbufs_produced - buf->subbufs_consumed;",
            "\treturn (ready >= buf->chan->n_subbufs) ? 1 : 0;",
            "}",
            "static int relay_subbuf_start(struct rchan_buf *buf, void *subbuf,",
            "\t\t\t      void *prev_subbuf, size_t prev_padding)",
            "{",
            "\tif (!buf->chan->cb->subbuf_start)",
            "\t\treturn !relay_buf_full(buf);",
            "",
            "\treturn buf->chan->cb->subbuf_start(buf, subbuf,",
            "\t\t\t\t\t   prev_subbuf, prev_padding);",
            "}",
            "static void wakeup_readers(struct irq_work *work)",
            "{",
            "\tstruct rchan_buf *buf;",
            "",
            "\tbuf = container_of(work, struct rchan_buf, wakeup_work);",
            "\twake_up_interruptible(&buf->read_wait);",
            "}",
            "static void __relay_reset(struct rchan_buf *buf, unsigned int init)",
            "{",
            "\tsize_t i;",
            "",
            "\tif (init) {",
            "\t\tinit_waitqueue_head(&buf->read_wait);",
            "\t\tkref_init(&buf->kref);",
            "\t\tinit_irq_work(&buf->wakeup_work, wakeup_readers);",
            "\t} else {",
            "\t\tirq_work_sync(&buf->wakeup_work);",
            "\t}",
            "",
            "\tbuf->subbufs_produced = 0;",
            "\tbuf->subbufs_consumed = 0;",
            "\tbuf->bytes_consumed = 0;",
            "\tbuf->finalized = 0;",
            "\tbuf->data = buf->start;",
            "\tbuf->offset = 0;",
            "",
            "\tfor (i = 0; i < buf->chan->n_subbufs; i++)",
            "\t\tbuf->padding[i] = 0;",
            "",
            "\trelay_subbuf_start(buf, buf->data, NULL, 0);",
            "}"
          ],
          "function_name": "relay_buf_fault, relay_free_page_array, relay_mmap_buf, relay_destroy_channel, relay_destroy_buf, relay_remove_buf, relay_buf_empty, relay_buf_full, relay_subbuf_start, wakeup_readers, __relay_reset",
          "description": "实现Relay缓冲区的页面故障处理、内存映射配置、通道销毁逻辑及缓冲区状态控制，包括子缓冲区满判断、唤醒读取线程等核心操作。",
          "similarity": 0.4606977701187134
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/relay.c",
          "start_line": 319,
          "end_line": 456,
          "content": [
            "void relay_reset(struct rchan *chan)",
            "{",
            "\tstruct rchan_buf *buf;",
            "\tunsigned int i;",
            "",
            "\tif (!chan)",
            "\t\treturn;",
            "",
            "\tif (chan->is_global && (buf = *per_cpu_ptr(chan->buf, 0))) {",
            "\t\t__relay_reset(buf, 0);",
            "\t\treturn;",
            "\t}",
            "",
            "\tmutex_lock(&relay_channels_mutex);",
            "\tfor_each_possible_cpu(i)",
            "\t\tif ((buf = *per_cpu_ptr(chan->buf, i)))",
            "\t\t\t__relay_reset(buf, 0);",
            "\tmutex_unlock(&relay_channels_mutex);",
            "}",
            "static inline void relay_set_buf_dentry(struct rchan_buf *buf,",
            "\t\t\t\t\tstruct dentry *dentry)",
            "{",
            "\tbuf->dentry = dentry;",
            "\td_inode(buf->dentry)->i_size = buf->early_bytes;",
            "}",
            "static void relay_close_buf(struct rchan_buf *buf)",
            "{",
            "\tbuf->finalized = 1;",
            "\tirq_work_sync(&buf->wakeup_work);",
            "\tbuf->chan->cb->remove_buf_file(buf->dentry);",
            "\tkref_put(&buf->kref, relay_remove_buf);",
            "}",
            "int relay_prepare_cpu(unsigned int cpu)",
            "{",
            "\tstruct rchan *chan;",
            "\tstruct rchan_buf *buf;",
            "",
            "\tmutex_lock(&relay_channels_mutex);",
            "\tlist_for_each_entry(chan, &relay_channels, list) {",
            "\t\tif (*per_cpu_ptr(chan->buf, cpu))",
            "\t\t\tcontinue;",
            "\t\tbuf = relay_open_buf(chan, cpu);",
            "\t\tif (!buf) {",
            "\t\t\tpr_err(\"relay: cpu %d buffer creation failed\\n\", cpu);",
            "\t\t\tmutex_unlock(&relay_channels_mutex);",
            "\t\t\treturn -ENOMEM;",
            "\t\t}",
            "\t\t*per_cpu_ptr(chan->buf, cpu) = buf;",
            "\t}",
            "\tmutex_unlock(&relay_channels_mutex);",
            "\treturn 0;",
            "}",
            "static void __relay_set_buf_dentry(void *info)",
            "{",
            "\tstruct rchan_percpu_buf_dispatcher *p = info;",
            "",
            "\trelay_set_buf_dentry(p->buf, p->dentry);",
            "}",
            "int relay_late_setup_files(struct rchan *chan,",
            "\t\t\t   const char *base_filename,",
            "\t\t\t   struct dentry *parent)",
            "{",
            "\tint err = 0;",
            "\tunsigned int i, curr_cpu;",
            "\tunsigned long flags;",
            "\tstruct dentry *dentry;",
            "\tstruct rchan_buf *buf;",
            "\tstruct rchan_percpu_buf_dispatcher disp;",
            "",
            "\tif (!chan || !base_filename)",
            "\t\treturn -EINVAL;",
            "",
            "\tstrscpy(chan->base_filename, base_filename, NAME_MAX);",
            "",
            "\tmutex_lock(&relay_channels_mutex);",
            "\t/* Is chan already set up? */",
            "\tif (unlikely(chan->has_base_filename)) {",
            "\t\tmutex_unlock(&relay_channels_mutex);",
            "\t\treturn -EEXIST;",
            "\t}",
            "\tchan->has_base_filename = 1;",
            "\tchan->parent = parent;",
            "",
            "\tif (chan->is_global) {",
            "\t\terr = -EINVAL;",
            "\t\tbuf = *per_cpu_ptr(chan->buf, 0);",
            "\t\tif (!WARN_ON_ONCE(!buf)) {",
            "\t\t\tdentry = relay_create_buf_file(chan, buf, 0);",
            "\t\t\tif (dentry && !WARN_ON_ONCE(!chan->is_global)) {",
            "\t\t\t\trelay_set_buf_dentry(buf, dentry);",
            "\t\t\t\terr = 0;",
            "\t\t\t}",
            "\t\t}",
            "\t\tmutex_unlock(&relay_channels_mutex);",
            "\t\treturn err;",
            "\t}",
            "",
            "\tcurr_cpu = get_cpu();",
            "\t/*",
            "\t * The CPU hotplug notifier ran before us and created buffers with",
            "\t * no files associated. So it's safe to call relay_setup_buf_file()",
            "\t * on all currently online CPUs.",
            "\t */",
            "\tfor_each_online_cpu(i) {",
            "\t\tbuf = *per_cpu_ptr(chan->buf, i);",
            "\t\tif (unlikely(!buf)) {",
            "\t\t\tWARN_ONCE(1, KERN_ERR \"CPU has no buffer!\\n\");",
            "\t\t\terr = -EINVAL;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tdentry = relay_create_buf_file(chan, buf, i);",
            "\t\tif (unlikely(!dentry)) {",
            "\t\t\terr = -EINVAL;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tif (curr_cpu == i) {",
            "\t\t\tlocal_irq_save(flags);",
            "\t\t\trelay_set_buf_dentry(buf, dentry);",
            "\t\t\tlocal_irq_restore(flags);",
            "\t\t} else {",
            "\t\t\tdisp.buf = buf;",
            "\t\t\tdisp.dentry = dentry;",
            "\t\t\tsmp_mb();",
            "\t\t\t/* relay_channels_mutex must be held, so wait. */",
            "\t\t\terr = smp_call_function_single(i,",
            "\t\t\t\t\t\t       __relay_set_buf_dentry,",
            "\t\t\t\t\t\t       &disp, 1);",
            "\t\t}",
            "\t\tif (unlikely(err))",
            "\t\t\tbreak;",
            "\t}",
            "\tput_cpu();",
            "\tmutex_unlock(&relay_channels_mutex);",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "relay_reset, relay_set_buf_dentry, relay_close_buf, relay_prepare_cpu, __relay_set_buf_dentry, relay_late_setup_files",
          "description": "处理Relay缓冲区的重置、Dentry绑定、CPU缓冲区准备及后期文件系统设置，通过互斥锁保护多CPU环境下的缓冲区一致性。",
          "similarity": 0.4435867965221405
        }
      ]
    },
    {
      "source_file": "mm/dmapool.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:56:43\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `dmapool.c`\n\n---\n\n# dmapool.c 技术文档\n\n## 1. 文件概述\n\n`dmapool.c` 实现了 Linux 内核中的 **DMA 池（DMA Pool）分配器**，用于为设备驱动程序提供小块、一致（coherent）且可 DMA 访问的内存。该分配器基于 `dma_alloc_coherent()` 分配整页内存，并将其划分为固定大小的块，以满足频繁分配/释放小块 DMA 内存的需求，避免直接使用页级分配造成的内存浪费。此机制特别适用于需要大量相同大小 DMA 缓冲区的设备驱动（如 USB、网络、存储控制器等）。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct dma_pool`**  \n  表示一个 DMA 池，包含：\n  - `page_list`：已分配物理页的双向链表\n  - `lock`：自旋锁，保护池内操作\n  - `next_block`：空闲块的单向链表头指针\n  - `nr_blocks` / `nr_active` / `nr_pages`：统计信息（总块数、活跃块数、页数）\n  - `dev`：关联的设备\n  - `size` / `allocation` / `boundary`：块大小、页分配大小、边界对齐限制\n  - `name`：池名称（用于调试）\n  - `pools`：挂载到设备 `dma_pools` 列表的节点\n\n- **`struct dma_page`**  \n  表示从 `dma_alloc_coherent()` 分配的一个物理页，包含虚拟地址 `vaddr` 和 DMA 地址 `dma`。\n\n- **`struct dma_block`**  \n  嵌入在每个 DMA 块起始位置的元数据结构，仅包含指向下一个空闲块的指针 `next_block` 和该块的 DMA 地址 `dma`。\n\n### 主要函数\n\n- **`dma_pool_create()`**  \n  创建一个新的 DMA 池，指定名称、设备、块大小、对齐要求和边界限制。\n\n- **`pool_block_pop()` / `pool_block_push()`**  \n  从空闲链表中分配/归还一个 DMA 块。\n\n- **`pool_check_block()` / `pool_block_err()` / `pool_init_page()`**  \n  调试辅助函数（在 `DMAPOOL_DEBUG` 启用时），用于检测内存越界、重复释放等错误，并进行内存毒化（poisoning）。\n\n- **`pools_show()`**  \n  sysfs 接口回调，显示设备下所有 DMA 池的统计信息。\n\n## 3. 关键实现\n\n- **内存组织**：  \n  每次调用 `dma_alloc_coherent()` 分配至少一页（`PAGE_SIZE`）的连续物理内存（`allocation` 字段）。该页被划分为多个 `size` 字节的块。每个块的起始处嵌入 `struct dma_block` 元数据。\n\n- **空闲管理**：  \n  所有空闲块通过 `next_block` 指针组成一个**全局单向链表**（由 `dma_pool.next_block` 指向头节点）。分配时从链表头部弹出，释放时压入头部。**已分配块不被显式跟踪**，仅通过 `nr_active` 计数。\n\n- **边界对齐处理**：  \n  若指定了 `boundary`（如 4KB），则确保单个 DMA 块不会跨越该边界。实现上通过限制每页实际可用区域或调整分配策略（代码片段未完整展示具体划分逻辑）。\n\n- **调试支持（DMAPOOL_DEBUG）**：  \n  在 SLUB 调试开启时启用：\n  - 分配时用 `POOL_POISON_ALLOCATED` 填充用户区域（若未启用 init-on-alloc）\n  - 释放时用 `POOL_POISON_FREED` 填充，并检查是否已被释放（防 double-free）\n  - 提供 `pool_find_page()` 辅助验证 DMA 地址有效性\n\n- **Sysfs 集成**：  \n  首次为设备创建 DMA 池时，自动注册 `pools` sysfs 属性文件，可通过 `/sys/devices/.../pools` 查看池状态（名称、活跃块数、总块数、块大小、页数）。\n\n- **并发控制**：  \n  - `pools_lock`：保护设备 `dma_pools` 列表的增删\n  - `pools_reg_lock`：防止 `dma_pool_create()` 与 `dma_pool_destroy()` 之间的竞争\n  - `dma_pool.lock`：保护池内部的空闲链表和计数器\n\n## 4. 依赖关系\n\n- **核心依赖**：\n  - `<linux/dma-mapping.h>`：提供 `dma_alloc_coherent()` / `dma_free_coherent()` 等底层 DMA 映射接口\n  - `<linux/device.h>`：设备模型及 sysfs 支持\n  - `<linux/slab.h>`：用于分配 `struct dma_pool` 结构体内存\n\n- **调试依赖**：\n  - `CONFIG_SLUB_DEBUG_ON`：启用内存毒化和错误检查\n  - `<linux/poison.h>`：提供 `POOL_POISON_*` 常量\n\n- **同步原语**：\n  - `<linux/mutex.h>` / `<linux/spinlock.h>`：提供互斥锁和自旋锁\n\n## 5. 使用场景\n\n- **设备驱动开发**：  \n  当驱动需要频繁分配/释放**固定大小**的小块（通常小于一页）DMA 缓冲区时，使用 DMA 池可显著提升性能并减少内存碎片。典型场景包括：\n  - USB 主机控制器的传输描述符（TD）池\n  - 网络设备的接收/发送描述符环\n  - 存储控制器的命令/状态块\n\n- **替代方案**：  \n  相比直接调用 `dma_alloc_coherent()` 分配整页内存，DMA 池避免了小块分配的内存浪费；相比通用 slab 分配器（如 kmalloc），它保证了返回内存的 DMA 一致性（无需手动缓存维护）。\n\n- **限制条件**：  \n  - 仅适用于**一致性 DMA 映射**（coherent DMA）\n  - 所有块大小在池创建时固定\n  - 不适用于大块（接近或超过一页）内存分配",
      "similarity": 0.5179192423820496,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/dmapool.c",
          "start_line": 360,
          "end_line": 419,
          "content": [
            "void dma_pool_destroy(struct dma_pool *pool)",
            "{",
            "\tstruct dma_page *page, *tmp;",
            "\tbool empty, busy = false;",
            "",
            "\tif (unlikely(!pool))",
            "\t\treturn;",
            "",
            "\tmutex_lock(&pools_reg_lock);",
            "\tmutex_lock(&pools_lock);",
            "\tlist_del(&pool->pools);",
            "\tempty = list_empty(&pool->dev->dma_pools);",
            "\tmutex_unlock(&pools_lock);",
            "\tif (empty)",
            "\t\tdevice_remove_file(pool->dev, &dev_attr_pools);",
            "\tmutex_unlock(&pools_reg_lock);",
            "",
            "\tif (pool->nr_active) {",
            "\t\tdev_err(pool->dev, \"%s %s busy\\n\", __func__, pool->name);",
            "\t\tbusy = true;",
            "\t}",
            "",
            "\tlist_for_each_entry_safe(page, tmp, &pool->page_list, page_list) {",
            "\t\tif (!busy)",
            "\t\t\tdma_free_coherent(pool->dev, pool->allocation,",
            "\t\t\t\t\t  page->vaddr, page->dma);",
            "\t\tlist_del(&page->page_list);",
            "\t\tkfree(page);",
            "\t}",
            "",
            "\tkfree(pool);",
            "}",
            "void dma_pool_free(struct dma_pool *pool, void *vaddr, dma_addr_t dma)",
            "{",
            "\tstruct dma_block *block = vaddr;",
            "\tunsigned long flags;",
            "",
            "\tspin_lock_irqsave(&pool->lock, flags);",
            "\tif (!pool_block_err(pool, vaddr, dma)) {",
            "\t\tpool_block_push(pool, block, dma);",
            "\t\tpool->nr_active--;",
            "\t}",
            "\tspin_unlock_irqrestore(&pool->lock, flags);",
            "}",
            "static void dmam_pool_release(struct device *dev, void *res)",
            "{",
            "\tstruct dma_pool *pool = *(struct dma_pool **)res;",
            "",
            "\tdma_pool_destroy(pool);",
            "}",
            "static int dmam_pool_match(struct device *dev, void *res, void *match_data)",
            "{",
            "\treturn *(struct dma_pool **)res == match_data;",
            "}",
            "void dmam_pool_destroy(struct dma_pool *pool)",
            "{",
            "\tstruct device *dev = pool->dev;",
            "",
            "\tWARN_ON(devres_release(dev, dmam_pool_release, dmam_pool_match, pool));",
            "}"
          ],
          "function_name": "dma_pool_destroy, dma_pool_free, dmam_pool_release, dmam_pool_match, dmam_pool_destroy",
          "description": "实现DMA池销毁逻辑，包括资源回收、活跃块计数管理及页面内存释放，通过互斥锁保证线程安全，支持设备资源释放回调。",
          "similarity": 0.47196152806282043
        },
        {
          "chunk_id": 1,
          "file_path": "mm/dmapool.c",
          "start_line": 72,
          "end_line": 196,
          "content": [
            "static ssize_t pools_show(struct device *dev, struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct dma_pool *pool;",
            "\tunsigned size;",
            "",
            "\tsize = sysfs_emit(buf, \"poolinfo - 0.1\\n\");",
            "",
            "\tmutex_lock(&pools_lock);",
            "\tlist_for_each_entry(pool, &dev->dma_pools, pools) {",
            "\t\t/* per-pool info, no real statistics yet */",
            "\t\tsize += sysfs_emit_at(buf, size, \"%-16s %4zu %4zu %4u %2zu\\n\",",
            "\t\t\t\t      pool->name, pool->nr_active,",
            "\t\t\t\t      pool->nr_blocks, pool->size,",
            "\t\t\t\t      pool->nr_pages);",
            "\t}",
            "\tmutex_unlock(&pools_lock);",
            "",
            "\treturn size;",
            "}",
            "static void pool_check_block(struct dma_pool *pool, struct dma_block *block,",
            "\t\t\t     gfp_t mem_flags)",
            "{",
            "\tu8 *data = (void *)block;",
            "\tint i;",
            "",
            "\tfor (i = sizeof(struct dma_block); i < pool->size; i++) {",
            "\t\tif (data[i] == POOL_POISON_FREED)",
            "\t\t\tcontinue;",
            "\t\tdev_err(pool->dev, \"%s %s, %p (corrupted)\\n\", __func__,",
            "\t\t\tpool->name, block);",
            "",
            "\t\t/*",
            "\t\t * Dump the first 4 bytes even if they are not",
            "\t\t * POOL_POISON_FREED",
            "\t\t */",
            "\t\tprint_hex_dump(KERN_ERR, \"\", DUMP_PREFIX_OFFSET, 16, 1,",
            "\t\t\t\tdata, pool->size, 1);",
            "\t\tbreak;",
            "\t}",
            "",
            "\tif (!want_init_on_alloc(mem_flags))",
            "\t\tmemset(block, POOL_POISON_ALLOCATED, pool->size);",
            "}",
            "static bool pool_block_err(struct dma_pool *pool, void *vaddr, dma_addr_t dma)",
            "{",
            "\tstruct dma_block *block = pool->next_block;",
            "\tstruct dma_page *page;",
            "",
            "\tpage = pool_find_page(pool, dma);",
            "\tif (!page) {",
            "\t\tdev_err(pool->dev, \"%s %s, %p/%pad (bad dma)\\n\",",
            "\t\t\t__func__, pool->name, vaddr, &dma);",
            "\t\treturn true;",
            "\t}",
            "",
            "\twhile (block) {",
            "\t\tif (block != vaddr) {",
            "\t\t\tblock = block->next_block;",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tdev_err(pool->dev, \"%s %s, dma %pad already free\\n\",",
            "\t\t\t__func__, pool->name, &dma);",
            "\t\treturn true;",
            "\t}",
            "",
            "\tmemset(vaddr, POOL_POISON_FREED, pool->size);",
            "\treturn false;",
            "}",
            "static void pool_init_page(struct dma_pool *pool, struct dma_page *page)",
            "{",
            "\tmemset(page->vaddr, POOL_POISON_FREED, pool->allocation);",
            "}",
            "static void pool_check_block(struct dma_pool *pool, struct dma_block *block,",
            "\t\t\t     gfp_t mem_flags)",
            "{",
            "}",
            "static bool pool_block_err(struct dma_pool *pool, void *vaddr, dma_addr_t dma)",
            "{",
            "\tif (want_init_on_free())",
            "\t\tmemset(vaddr, 0, pool->size);",
            "\treturn false;",
            "}",
            "static void pool_init_page(struct dma_pool *pool, struct dma_page *page)",
            "{",
            "}",
            "static void pool_block_push(struct dma_pool *pool, struct dma_block *block,",
            "\t\t\t    dma_addr_t dma)",
            "{",
            "\tblock->dma = dma;",
            "\tblock->next_block = pool->next_block;",
            "\tpool->next_block = block;",
            "}",
            "static void pool_initialise_page(struct dma_pool *pool, struct dma_page *page)",
            "{",
            "\tunsigned int next_boundary = pool->boundary, offset = 0;",
            "\tstruct dma_block *block, *first = NULL, *last = NULL;",
            "",
            "\tpool_init_page(pool, page);",
            "\twhile (offset + pool->size <= pool->allocation) {",
            "\t\tif (offset + pool->size > next_boundary) {",
            "\t\t\toffset = next_boundary;",
            "\t\t\tnext_boundary += pool->boundary;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tblock = page->vaddr + offset;",
            "\t\tblock->dma = page->dma + offset;",
            "\t\tblock->next_block = NULL;",
            "",
            "\t\tif (last)",
            "\t\t\tlast->next_block = block;",
            "\t\telse",
            "\t\t\tfirst = block;",
            "\t\tlast = block;",
            "",
            "\t\toffset += pool->size;",
            "\t\tpool->nr_blocks++;",
            "\t}",
            "",
            "\tlast->next_block = pool->next_block;",
            "\tpool->next_block = first;",
            "",
            "\tlist_add(&page->page_list, &pool->page_list);",
            "\tpool->nr_pages++;",
            "}"
          ],
          "function_name": "pools_show, pool_check_block, pool_block_err, pool_init_page, pool_check_block, pool_block_err, pool_init_page, pool_block_push, pool_initialise_page",
          "description": "提供DMA池调试显示、块校验、错误检测及页面初始化等功能，部分函数存在重复声明或未完成实现，上下文不完整。",
          "similarity": 0.42823007702827454
        },
        {
          "chunk_id": 0,
          "file_path": "mm/dmapool.c",
          "start_line": 1,
          "end_line": 71,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * DMA Pool allocator",
            " *",
            " * Copyright 2001 David Brownell",
            " * Copyright 2007 Intel Corporation",
            " *   Author: Matthew Wilcox <willy@linux.intel.com>",
            " *",
            " * This allocator returns small blocks of a given size which are DMA-able by",
            " * the given device.  It uses the dma_alloc_coherent page allocator to get",
            " * new pages, then splits them up into blocks of the required size.",
            " * Many older drivers still have their own code to do this.",
            " *",
            " * The current design of this allocator is fairly simple.  The pool is",
            " * represented by the 'struct dma_pool' which keeps a doubly-linked list of",
            " * allocated pages.  Each page in the page_list is split into blocks of at",
            " * least 'size' bytes.  Free blocks are tracked in an unsorted singly-linked",
            " * list of free blocks across all pages.  Used blocks aren't tracked, but we",
            " * keep a count of how many are currently allocated from each page.",
            " */",
            "",
            "#include <linux/device.h>",
            "#include <linux/dma-mapping.h>",
            "#include <linux/dmapool.h>",
            "#include <linux/kernel.h>",
            "#include <linux/list.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/poison.h>",
            "#include <linux/sched.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/stat.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/wait.h>",
            "",
            "#ifdef CONFIG_SLUB_DEBUG_ON",
            "#define DMAPOOL_DEBUG 1",
            "#endif",
            "",
            "struct dma_block {",
            "\tstruct dma_block *next_block;",
            "\tdma_addr_t dma;",
            "};",
            "",
            "struct dma_pool {\t\t/* the pool */",
            "\tstruct list_head page_list;",
            "\tspinlock_t lock;",
            "\tstruct dma_block *next_block;",
            "\tsize_t nr_blocks;",
            "\tsize_t nr_active;",
            "\tsize_t nr_pages;",
            "\tstruct device *dev;",
            "\tunsigned int size;",
            "\tunsigned int allocation;",
            "\tunsigned int boundary;",
            "\tchar name[32];",
            "\tstruct list_head pools;",
            "};",
            "",
            "struct dma_page {\t\t/* cacheable header for 'allocation' bytes */",
            "\tstruct list_head page_list;",
            "\tvoid *vaddr;",
            "\tdma_addr_t dma;",
            "};",
            "",
            "static DEFINE_MUTEX(pools_lock);",
            "static DEFINE_MUTEX(pools_reg_lock);",
            ""
          ],
          "function_name": null,
          "description": "定义DMA池相关结构体及全局锁，用于管理可DMA访问的小块内存分配，包含页面链表、块链表、设备指针及参数配置。",
          "similarity": 0.42331165075302124
        }
      ]
    }
  ]
}