{
  "query": "file system",
  "timestamp": "2025-12-25 23:32:25",
  "retrieved_files": [
    {
      "source_file": "kernel/bpf/hashtab.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:10:56\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\hashtab.c`\n\n---\n\n# bpf/hashtab.c 技术文档\n\n## 1. 文件概述\n\n`bpf/hashtab.c` 是 Linux 内核中 BPF（Berkeley Packet Filter）子系统的核心实现文件之一，负责提供基于哈希表（hash table）的 BPF map 类型支持。该文件实现了多种 BPF map 类型，包括普通哈希表（`BPF_MAP_TYPE_HASH`）、LRU 哈希表（`BPF_MAP_TYPE_LRU_HASH`）、每 CPU 哈希表（`BPF_MAP_TYPE_PERCPU_HASH`）及其 LRU 变体。它支持预分配（pre-allocated）和动态分配（non-preallocated）两种内存管理模式，并集成了 BPF 内存分配器（`bpf_mem_alloc`）、LRU 驱逐机制、每 CPU 自由列表（percpu freelist）等高级特性，以满足高性能、低延迟的 BPF 程序需求。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct bucket`**  \n  哈希桶结构，包含一个 `hlist_nulls_head` 链表头和一个 `raw_spinlock_t` 原始自旋锁，用于保护桶内元素的并发访问。\n\n- **`struct bpf_htab`**  \n  BPF 哈希表的主控制结构，继承自 `struct bpf_map`，包含：\n  - 桶数组指针 `buckets`\n  - 元素存储区 `elems`\n  - 内存分配器 `ma`（主）和 `pcpu_ma`（每 CPU）\n  - LRU 或 percpu_freelist 联合体\n  - 元素计数器（`pcount` 或 `count`）\n  - 哈希种子 `hashrnd`\n  - 锁依赖类键 `lockdep_key`\n  - 每 CPU 锁状态数组 `map_locked`（用于防止递归）\n\n- **`struct htab_elem`**  \n  哈希表元素结构，包含：\n  - 哈希链表节点 `hash_node`\n  - LRU 节点或自由列表节点\n  - 指向每 CPU 指针的指针（用于 per-CPU map）\n  - 哈希值 `hash`\n  - 可变长键 `key[]`（后接值或 per-CPU 指针）\n\n### 关键辅助函数\n\n- `htab_is_prealloc()`：判断是否为预分配模式\n- `htab_is_lru()` / `htab_is_percpu()`：判断 map 类型是否为 LRU 或 per-CPU\n- `htab_init_buckets()`：初始化所有哈希桶\n- `htab_lock_bucket()` / `htab_unlock_bucket()`：带递归保护的桶锁操作\n- `htab_elem_set_ptr()` / `htab_elem_get_ptr()`：操作 per-CPU 指针\n- `get_htab_elem()`：从预分配区域获取第 i 个元素\n- `htab_has_extra_elems()`：判断是否包含额外元素（用于 per-CPU 扩展）\n- `htab_free_prealloced_timers_and_wq()`：释放预分配元素中的 BPF 定时器和工作队列资源\n\n### 批量操作宏\n\n- `BATCH_OPS(_name)`：定义批量操作函数指针，如 `map_lookup_batch`、`map_update_batch` 等。\n\n## 3. 关键实现\n\n### 并发控制与死锁预防\n\n- 使用 **原始自旋锁（`raw_spinlock_t`）** 保护每个哈希桶，确保在任意上下文（如 kprobe、perf、tracepoint）中安全使用。\n- 引入 **每 CPU 递归计数器 `map_locked[]`**，防止 BPF 程序在持有桶锁时再次进入（例如通过 `sys_bpf()` 或嵌套 BPF 调用），避免死锁。\n- 在 `PREEMPT_RT` 实时内核上，由于普通自旋锁可能睡眠，必须使用 `raw_spinlock` 以保证原子性；结合 `bpf_mem_alloc` 后，即使非预分配模式也可安全使用原始锁。\n\n### 内存管理\n\n- **预分配模式（`BPF_F_NO_PREALLOC` 未设置）**：启动时一次性分配所有元素，使用 `pcpu_freelist` 管理空闲元素。\n- **非预分配模式**：按需通过 `bpf_mem_alloc` 动态分配元素，支持 NUMA 感知和内存回收。\n- **Per-CPU 支持**：对于 `PERCPU_HASH` 类型，每个键对应一个 per-CPU 值数组，通过 `htab_elem_get_ptr()` 访问。\n\n### LRU 驱逐机制\n\n- 当 map 类型为 `LRU_HASH` 或 `LRU_PERCPU_HASH` 时，使用 `bpf_lru` 子系统管理元素生命周期，自动驱逐最近最少使用的条目以维持 `max_entries` 限制。\n\n### 扩展字段支持\n\n- 支持 BTF（BPF Type Format）描述的复杂值类型，如 `BPF_TIMER` 和 `BPF_WORKQUEUE`，在销毁 map 时自动释放相关资源（见 `htab_free_prealloced_timers_and_wq`）。\n\n### 哈希与对齐\n\n- 使用 `jhash` 算法计算键的哈希值，并通过 `hashrnd` 引入随机种子防止哈希碰撞攻击。\n- 键和值之间按 8 字节对齐（`__aligned(8)`），确保 per-CPU 指针正确对齐。\n\n## 4. 依赖关系\n\n- **内核头文件**：\n  - `<linux/bpf.h>`、`<linux/btf.h>`：BPF 和 BTF 核心接口\n  - `<linux/jhash.h>`：哈希函数\n  - `<linux/rculist_nulls.h>`：RCU 安全的空指针链表\n  - `<linux/percpu_freelist.h>`、`<linux/bpf_lru_list.h>`：内存管理子系统\n  - `<linux/bpf_mem_alloc.h>`：BPF 专用内存分配器\n\n- **内部模块**：\n  - `map_in_map.h`：支持 map-in-map 功能\n  - `bpf_lru_list.c`：LRU 驱逐实现\n  - `percpu_freelist.c`：每 CPU 自由列表管理\n\n- **BPF 子系统**：\n  - 与 `bpf_map` 通用框架集成，通过 `bpf_map_ops` 注册操作函数\n  - 依赖 `bpf_prog_active` 机制防止 BPF 递归\n\n## 5. 使用场景\n\n- **网络数据包过滤与监控**：eBPF 程序使用 `BPF_MAP_TYPE_HASH` 存储连接状态、统计信息等。\n- **性能分析**：通过 `PERCPU_HASH` 收集每 CPU 的性能计数器，避免锁竞争。\n- **资源限制与缓存**：`LRU_HASH` 用于实现有界缓存（如 DNS 缓存、会话表），自动淘汰旧条目。\n- **内核跟踪**：kprobe、tracepoint 等 attach 的 BPF 程序频繁读写哈希表，要求低延迟和高并发。\n- **用户空间交互**：通过 `bpf(2)` 系统调用进行 map 的创建、更新、查询和删除，支持批量操作提升效率。\n- **高级 BPF 功能**：支持包含定时器（`bpf_timer`）或工作队列（`bpf_workqueue`）的复杂 map 值类型，用于异步任务调度。",
      "similarity": 0.5733566284179688,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 1,
          "end_line": 131,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/* Copyright (c) 2011-2014 PLUMgrid, http://plumgrid.com",
            " * Copyright (c) 2016 Facebook",
            " */",
            "#include <linux/bpf.h>",
            "#include <linux/btf.h>",
            "#include <linux/jhash.h>",
            "#include <linux/filter.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/random.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/btf_ids.h>",
            "#include \"percpu_freelist.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"map_in_map.h\"",
            "#include <linux/bpf_mem_alloc.h>",
            "",
            "#define HTAB_CREATE_FLAG_MASK\t\t\t\t\t\t\\",
            "\t(BPF_F_NO_PREALLOC | BPF_F_NO_COMMON_LRU | BPF_F_NUMA_NODE |\t\\",
            "\t BPF_F_ACCESS_MASK | BPF_F_ZERO_SEED)",
            "",
            "#define BATCH_OPS(_name)\t\t\t\\",
            "\t.map_lookup_batch =\t\t\t\\",
            "\t_name##_map_lookup_batch,\t\t\\",
            "\t.map_lookup_and_delete_batch =\t\t\\",
            "\t_name##_map_lookup_and_delete_batch,\t\\",
            "\t.map_update_batch =\t\t\t\\",
            "\tgeneric_map_update_batch,\t\t\\",
            "\t.map_delete_batch =\t\t\t\\",
            "\tgeneric_map_delete_batch",
            "",
            "/*",
            " * The bucket lock has two protection scopes:",
            " *",
            " * 1) Serializing concurrent operations from BPF programs on different",
            " *    CPUs",
            " *",
            " * 2) Serializing concurrent operations from BPF programs and sys_bpf()",
            " *",
            " * BPF programs can execute in any context including perf, kprobes and",
            " * tracing. As there are almost no limits where perf, kprobes and tracing",
            " * can be invoked from the lock operations need to be protected against",
            " * deadlocks. Deadlocks can be caused by recursion and by an invocation in",
            " * the lock held section when functions which acquire this lock are invoked",
            " * from sys_bpf(). BPF recursion is prevented by incrementing the per CPU",
            " * variable bpf_prog_active, which prevents BPF programs attached to perf",
            " * events, kprobes and tracing to be invoked before the prior invocation",
            " * from one of these contexts completed. sys_bpf() uses the same mechanism",
            " * by pinning the task to the current CPU and incrementing the recursion",
            " * protection across the map operation.",
            " *",
            " * This has subtle implications on PREEMPT_RT. PREEMPT_RT forbids certain",
            " * operations like memory allocations (even with GFP_ATOMIC) from atomic",
            " * contexts. This is required because even with GFP_ATOMIC the memory",
            " * allocator calls into code paths which acquire locks with long held lock",
            " * sections. To ensure the deterministic behaviour these locks are regular",
            " * spinlocks, which are converted to 'sleepable' spinlocks on RT. The only",
            " * true atomic contexts on an RT kernel are the low level hardware",
            " * handling, scheduling, low level interrupt handling, NMIs etc. None of",
            " * these contexts should ever do memory allocations.",
            " *",
            " * As regular device interrupt handlers and soft interrupts are forced into",
            " * thread context, the existing code which does",
            " *   spin_lock*(); alloc(GFP_ATOMIC); spin_unlock*();",
            " * just works.",
            " *",
            " * In theory the BPF locks could be converted to regular spinlocks as well,",
            " * but the bucket locks and percpu_freelist locks can be taken from",
            " * arbitrary contexts (perf, kprobes, tracepoints) which are required to be",
            " * atomic contexts even on RT. Before the introduction of bpf_mem_alloc,",
            " * it is only safe to use raw spinlock for preallocated hash map on a RT kernel,",
            " * because there is no memory allocation within the lock held sections. However",
            " * after hash map was fully converted to use bpf_mem_alloc, there will be",
            " * non-synchronous memory allocation for non-preallocated hash map, so it is",
            " * safe to always use raw spinlock for bucket lock.",
            " */",
            "struct bucket {",
            "\tstruct hlist_nulls_head head;",
            "\traw_spinlock_t raw_lock;",
            "};",
            "",
            "#define HASHTAB_MAP_LOCK_COUNT 8",
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)",
            "",
            "struct bpf_htab {",
            "\tstruct bpf_map map;",
            "\tstruct bpf_mem_alloc ma;",
            "\tstruct bpf_mem_alloc pcpu_ma;",
            "\tstruct bucket *buckets;",
            "\tvoid *elems;",
            "\tunion {",
            "\t\tstruct pcpu_freelist freelist;",
            "\t\tstruct bpf_lru lru;",
            "\t};",
            "\tstruct htab_elem *__percpu *extra_elems;",
            "\t/* number of elements in non-preallocated hashtable are kept",
            "\t * in either pcount or count",
            "\t */",
            "\tstruct percpu_counter pcount;",
            "\tatomic_t count;",
            "\tbool use_percpu_counter;",
            "\tu32 n_buckets;\t/* number of hash buckets */",
            "\tu32 elem_size;\t/* size of each element in bytes */",
            "\tu32 hashrnd;",
            "\tstruct lock_class_key lockdep_key;",
            "\tint __percpu *map_locked[HASHTAB_MAP_LOCK_COUNT];",
            "};",
            "",
            "/* each htab element is struct htab_elem + key + value */",
            "struct htab_elem {",
            "\tunion {",
            "\t\tstruct hlist_nulls_node hash_node;",
            "\t\tstruct {",
            "\t\t\tvoid *padding;",
            "\t\t\tunion {",
            "\t\t\t\tstruct pcpu_freelist_node fnode;",
            "\t\t\t\tstruct htab_elem *batch_flink;",
            "\t\t\t};",
            "\t\t};",
            "\t};",
            "\tunion {",
            "\t\t/* pointer to per-cpu pointer */",
            "\t\tvoid *ptr_to_pptr;",
            "\t\tstruct bpf_lru_node lru_node;",
            "\t};",
            "\tu32 hash;",
            "\tchar key[] __aligned(8);",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义BPF哈希表相关的头文件和宏常量，声明bucket结构体及bpf_htab结构体，包含哈希表的桶锁、元素存储、LRU/PCPU管理等核心成员变量，描述了哈希表的并发控制机制和内存分配策略。",
          "similarity": 0.506267249584198
        },
        {
          "chunk_id": 11,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 1701,
          "end_line": 1938,
          "content": [
            "static int htab_lru_percpu_map_lookup_and_delete_elem(struct bpf_map *map,",
            "\t\t\t\t\t\t      void *key, void *value,",
            "\t\t\t\t\t\t      u64 flags)",
            "{",
            "\treturn __htab_map_lookup_and_delete_elem(map, key, value, true, true,",
            "\t\t\t\t\t\t flags);",
            "}",
            "static int",
            "__htab_map_lookup_and_delete_batch(struct bpf_map *map,",
            "\t\t\t\t   const union bpf_attr *attr,",
            "\t\t\t\t   union bpf_attr __user *uattr,",
            "\t\t\t\t   bool do_delete, bool is_lru_map,",
            "\t\t\t\t   bool is_percpu)",
            "{",
            "\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);",
            "\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;",
            "\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;",
            "\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);",
            "\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);",
            "\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);",
            "\tu32 batch, max_count, size, bucket_size, map_id;",
            "\tstruct htab_elem *node_to_free = NULL;",
            "\tu64 elem_map_flags, map_flags;",
            "\tstruct hlist_nulls_head *head;",
            "\tstruct hlist_nulls_node *n;",
            "\tunsigned long flags = 0;",
            "\tbool locked = false;",
            "\tstruct htab_elem *l;",
            "\tstruct bucket *b;",
            "\tint ret = 0;",
            "",
            "\telem_map_flags = attr->batch.elem_flags;",
            "\tif ((elem_map_flags & ~BPF_F_LOCK) ||",
            "\t    ((elem_map_flags & BPF_F_LOCK) && !btf_record_has_field(map->record, BPF_SPIN_LOCK)))",
            "\t\treturn -EINVAL;",
            "",
            "\tmap_flags = attr->batch.flags;",
            "\tif (map_flags)",
            "\t\treturn -EINVAL;",
            "",
            "\tmax_count = attr->batch.count;",
            "\tif (!max_count)",
            "\t\treturn 0;",
            "",
            "\tif (put_user(0, &uattr->batch.count))",
            "\t\treturn -EFAULT;",
            "",
            "\tbatch = 0;",
            "\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))",
            "\t\treturn -EFAULT;",
            "",
            "\tif (batch >= htab->n_buckets)",
            "\t\treturn -ENOENT;",
            "",
            "\tkey_size = htab->map.key_size;",
            "\troundup_key_size = round_up(htab->map.key_size, 8);",
            "\tvalue_size = htab->map.value_size;",
            "\tsize = round_up(value_size, 8);",
            "\tif (is_percpu)",
            "\t\tvalue_size = size * num_possible_cpus();",
            "\ttotal = 0;",
            "\t/* while experimenting with hash tables with sizes ranging from 10 to",
            "\t * 1000, it was observed that a bucket can have up to 5 entries.",
            "\t */",
            "\tbucket_size = 5;",
            "",
            "alloc:",
            "\t/* We cannot do copy_from_user or copy_to_user inside",
            "\t * the rcu_read_lock. Allocate enough space here.",
            "\t */",
            "\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);",
            "\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);",
            "\tif (!keys || !values) {",
            "\t\tret = -ENOMEM;",
            "\t\tgoto after_loop;",
            "\t}",
            "",
            "again:",
            "\tbpf_disable_instrumentation();",
            "\trcu_read_lock();",
            "again_nocopy:",
            "\tdst_key = keys;",
            "\tdst_val = values;",
            "\tb = &htab->buckets[batch];",
            "\thead = &b->head;",
            "\t/* do not grab the lock unless need it (bucket_cnt > 0). */",
            "\tif (locked) {",
            "\t\tret = htab_lock_bucket(htab, b, batch, &flags);",
            "\t\tif (ret) {",
            "\t\t\trcu_read_unlock();",
            "\t\t\tbpf_enable_instrumentation();",
            "\t\t\tgoto after_loop;",
            "\t\t}",
            "\t}",
            "",
            "\tbucket_cnt = 0;",
            "\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)",
            "\t\tbucket_cnt++;",
            "",
            "\tif (bucket_cnt && !locked) {",
            "\t\tlocked = true;",
            "\t\tgoto again_nocopy;",
            "\t}",
            "",
            "\tif (bucket_cnt > (max_count - total)) {",
            "\t\tif (total == 0)",
            "\t\t\tret = -ENOSPC;",
            "\t\t/* Note that since bucket_cnt > 0 here, it is implicit",
            "\t\t * that the locked was grabbed, so release it.",
            "\t\t */",
            "\t\thtab_unlock_bucket(htab, b, batch, flags);",
            "\t\trcu_read_unlock();",
            "\t\tbpf_enable_instrumentation();",
            "\t\tgoto after_loop;",
            "\t}",
            "",
            "\tif (bucket_cnt > bucket_size) {",
            "\t\tbucket_size = bucket_cnt;",
            "\t\t/* Note that since bucket_cnt > 0 here, it is implicit",
            "\t\t * that the locked was grabbed, so release it.",
            "\t\t */",
            "\t\thtab_unlock_bucket(htab, b, batch, flags);",
            "\t\trcu_read_unlock();",
            "\t\tbpf_enable_instrumentation();",
            "\t\tkvfree(keys);",
            "\t\tkvfree(values);",
            "\t\tgoto alloc;",
            "\t}",
            "",
            "\t/* Next block is only safe to run if you have grabbed the lock */",
            "\tif (!locked)",
            "\t\tgoto next_batch;",
            "",
            "\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {",
            "\t\tmemcpy(dst_key, l->key, key_size);",
            "",
            "\t\tif (is_percpu) {",
            "\t\t\tint off = 0, cpu;",
            "\t\t\tvoid __percpu *pptr;",
            "",
            "\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);",
            "\t\t\tfor_each_possible_cpu(cpu) {",
            "\t\t\t\tcopy_map_value_long(&htab->map, dst_val + off, per_cpu_ptr(pptr, cpu));",
            "\t\t\t\tcheck_and_init_map_value(&htab->map, dst_val + off);",
            "\t\t\t\toff += size;",
            "\t\t\t}",
            "\t\t} else {",
            "\t\t\tvalue = l->key + roundup_key_size;",
            "\t\t\tif (map->map_type == BPF_MAP_TYPE_HASH_OF_MAPS) {",
            "\t\t\t\tstruct bpf_map **inner_map = value;",
            "",
            "\t\t\t\t /* Actual value is the id of the inner map */",
            "\t\t\t\tmap_id = map->ops->map_fd_sys_lookup_elem(*inner_map);",
            "\t\t\t\tvalue = &map_id;",
            "\t\t\t}",
            "",
            "\t\t\tif (elem_map_flags & BPF_F_LOCK)",
            "\t\t\t\tcopy_map_value_locked(map, dst_val, value,",
            "\t\t\t\t\t\t      true);",
            "\t\t\telse",
            "\t\t\t\tcopy_map_value(map, dst_val, value);",
            "\t\t\t/* Zeroing special fields in the temp buffer */",
            "\t\t\tcheck_and_init_map_value(map, dst_val);",
            "\t\t}",
            "\t\tif (do_delete) {",
            "\t\t\thlist_nulls_del_rcu(&l->hash_node);",
            "",
            "\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which",
            "\t\t\t * may cause deadlock. See comments in function",
            "\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()",
            "\t\t\t * after releasing the bucket lock.",
            "\t\t\t *",
            "\t\t\t * For htab of maps, htab_put_fd_value() in",
            "\t\t\t * free_htab_elem() may acquire a spinlock with bucket",
            "\t\t\t * lock being held and it violates the lock rule, so",
            "\t\t\t * invoke free_htab_elem() after unlock as well.",
            "\t\t\t */",
            "\t\t\tl->batch_flink = node_to_free;",
            "\t\t\tnode_to_free = l;",
            "\t\t}",
            "\t\tdst_key += key_size;",
            "\t\tdst_val += value_size;",
            "\t}",
            "",
            "\thtab_unlock_bucket(htab, b, batch, flags);",
            "\tlocked = false;",
            "",
            "\twhile (node_to_free) {",
            "\t\tl = node_to_free;",
            "\t\tnode_to_free = node_to_free->batch_flink;",
            "\t\tif (is_lru_map)",
            "\t\t\thtab_lru_push_free(htab, l);",
            "\t\telse",
            "\t\t\tfree_htab_elem(htab, l);",
            "\t}",
            "",
            "next_batch:",
            "\t/* If we are not copying data, we can go to next bucket and avoid",
            "\t * unlocking the rcu.",
            "\t */",
            "\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {",
            "\t\tbatch++;",
            "\t\tgoto again_nocopy;",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "\tbpf_enable_instrumentation();",
            "\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,",
            "\t    key_size * bucket_cnt) ||",
            "\t    copy_to_user(uvalues + total * value_size, values,",
            "\t    value_size * bucket_cnt))) {",
            "\t\tret = -EFAULT;",
            "\t\tgoto after_loop;",
            "\t}",
            "",
            "\ttotal += bucket_cnt;",
            "\tbatch++;",
            "\tif (batch >= htab->n_buckets) {",
            "\t\tret = -ENOENT;",
            "\t\tgoto after_loop;",
            "\t}",
            "\tgoto again;",
            "",
            "after_loop:",
            "\tif (ret == -EFAULT)",
            "\t\tgoto out;",
            "",
            "\t/* copy # of entries and next batch */",
            "\tubatch = u64_to_user_ptr(attr->batch.out_batch);",
            "\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||",
            "\t    put_user(total, &uattr->batch.count))",
            "\t\tret = -EFAULT;",
            "",
            "out:",
            "\tkvfree(keys);",
            "\tkvfree(values);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "htab_lru_percpu_map_lookup_and_delete_elem, __htab_map_lookup_and_delete_batch",
          "description": "处理批量查找删除操作，通过RCU读锁遍历指定桶内元素，支持普通/PERCPU/LRU类型。动态分配缓冲区复制键值，处理锁竞争和内存溢出情况，返回操作结果及统计信息。",
          "similarity": 0.5012004375457764
        },
        {
          "chunk_id": 12,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 1941,
          "end_line": 2043,
          "content": [
            "static int",
            "htab_percpu_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,",
            "\t\t\t     union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,",
            "\t\t\t\t\t\t  false, true);",
            "}",
            "static int",
            "htab_percpu_map_lookup_and_delete_batch(struct bpf_map *map,",
            "\t\t\t\t\tconst union bpf_attr *attr,",
            "\t\t\t\t\tunion bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,",
            "\t\t\t\t\t\t  false, true);",
            "}",
            "static int",
            "htab_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,",
            "\t\t      union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,",
            "\t\t\t\t\t\t  false, false);",
            "}",
            "static int",
            "htab_map_lookup_and_delete_batch(struct bpf_map *map,",
            "\t\t\t\t const union bpf_attr *attr,",
            "\t\t\t\t union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,",
            "\t\t\t\t\t\t  false, false);",
            "}",
            "static int",
            "htab_lru_percpu_map_lookup_batch(struct bpf_map *map,",
            "\t\t\t\t const union bpf_attr *attr,",
            "\t\t\t\t union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,",
            "\t\t\t\t\t\t  true, true);",
            "}",
            "static int",
            "htab_lru_percpu_map_lookup_and_delete_batch(struct bpf_map *map,",
            "\t\t\t\t\t    const union bpf_attr *attr,",
            "\t\t\t\t\t    union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,",
            "\t\t\t\t\t\t  true, true);",
            "}",
            "static int",
            "htab_lru_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,",
            "\t\t\t  union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,",
            "\t\t\t\t\t\t  true, false);",
            "}",
            "static int",
            "htab_lru_map_lookup_and_delete_batch(struct bpf_map *map,",
            "\t\t\t\t     const union bpf_attr *attr,",
            "\t\t\t\t     union bpf_attr __user *uattr)",
            "{",
            "\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,",
            "\t\t\t\t\t\t  true, false);",
            "}",
            "static int __bpf_hash_map_seq_show(struct seq_file *seq, struct htab_elem *elem)",
            "{",
            "\tstruct bpf_iter_seq_hash_map_info *info = seq->private;",
            "\tu32 roundup_key_size, roundup_value_size;",
            "\tstruct bpf_iter__bpf_map_elem ctx = {};",
            "\tstruct bpf_map *map = info->map;",
            "\tstruct bpf_iter_meta meta;",
            "\tint ret = 0, off = 0, cpu;",
            "\tstruct bpf_prog *prog;",
            "\tvoid __percpu *pptr;",
            "",
            "\tmeta.seq = seq;",
            "\tprog = bpf_iter_get_info(&meta, elem == NULL);",
            "\tif (prog) {",
            "\t\tctx.meta = &meta;",
            "\t\tctx.map = info->map;",
            "\t\tif (elem) {",
            "\t\t\troundup_key_size = round_up(map->key_size, 8);",
            "\t\t\tctx.key = elem->key;",
            "\t\t\tif (!info->percpu_value_buf) {",
            "\t\t\t\tctx.value = elem->key + roundup_key_size;",
            "\t\t\t} else {",
            "\t\t\t\troundup_value_size = round_up(map->value_size, 8);",
            "\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);",
            "\t\t\t\tfor_each_possible_cpu(cpu) {",
            "\t\t\t\t\tcopy_map_value_long(map, info->percpu_value_buf + off,",
            "\t\t\t\t\t\t\t    per_cpu_ptr(pptr, cpu));",
            "\t\t\t\t\tcheck_and_init_map_value(map, info->percpu_value_buf + off);",
            "\t\t\t\t\toff += roundup_value_size;",
            "\t\t\t\t}",
            "\t\t\t\tctx.value = info->percpu_value_buf;",
            "\t\t\t}",
            "\t\t}",
            "\t\tret = bpf_iter_run_prog(prog, &ctx);",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "static int bpf_hash_map_seq_show(struct seq_file *seq, void *v)",
            "{",
            "\treturn __bpf_hash_map_seq_show(seq, v);",
            "}"
          ],
          "function_name": "htab_percpu_map_lookup_batch, htab_percpu_map_lookup_and_delete_batch, htab_map_lookup_batch, htab_map_lookup_and_delete_batch, htab_lru_percpu_map_lookup_batch, htab_lru_percpu_map_lookup_and_delete_batch, htab_lru_map_lookup_batch, htab_lru_map_lookup_and_delete_batch, __bpf_hash_map_seq_show, bpf_hash_map_seq_show",
          "description": "提供多种批量操作接口封装，统一调用__htab_map_lookup_and_delete_batch实现。包含序列化展示函数，处理PERCPU值的特殊复制逻辑，支持迭代器上下文管理。",
          "similarity": 0.4947887659072876
        },
        {
          "chunk_id": 15,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 2555,
          "end_line": 2611,
          "content": [
            "int bpf_fd_htab_map_lookup_elem(struct bpf_map *map, void *key, u32 *value)",
            "{",
            "\tvoid **ptr;",
            "\tint ret = 0;",
            "",
            "\tif (!map->ops->map_fd_sys_lookup_elem)",
            "\t\treturn -ENOTSUPP;",
            "",
            "\trcu_read_lock();",
            "\tptr = htab_map_lookup_elem(map, key);",
            "\tif (ptr)",
            "\t\t*value = map->ops->map_fd_sys_lookup_elem(READ_ONCE(*ptr));",
            "\telse",
            "\t\tret = -ENOENT;",
            "\trcu_read_unlock();",
            "",
            "\treturn ret;",
            "}",
            "int bpf_fd_htab_map_update_elem(struct bpf_map *map, struct file *map_file,",
            "\t\t\t\tvoid *key, void *value, u64 map_flags)",
            "{",
            "\tvoid *ptr;",
            "\tint ret;",
            "\tu32 ufd = *(u32 *)value;",
            "",
            "\tptr = map->ops->map_fd_get_ptr(map, map_file, ufd);",
            "\tif (IS_ERR(ptr))",
            "\t\treturn PTR_ERR(ptr);",
            "",
            "\tret = htab_map_update_elem(map, key, &ptr, map_flags);",
            "\tif (ret)",
            "\t\tmap->ops->map_fd_put_ptr(map, ptr, false);",
            "",
            "\treturn ret;",
            "}",
            "static int htab_of_map_gen_lookup(struct bpf_map *map,",
            "\t\t\t\t  struct bpf_insn *insn_buf)",
            "{",
            "\tstruct bpf_insn *insn = insn_buf;",
            "\tconst int ret = BPF_REG_0;",
            "",
            "\tBUILD_BUG_ON(!__same_type(&__htab_map_lookup_elem,",
            "\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));",
            "\t*insn++ = BPF_EMIT_CALL(__htab_map_lookup_elem);",
            "\t*insn++ = BPF_JMP_IMM(BPF_JEQ, ret, 0, 2);",
            "\t*insn++ = BPF_ALU64_IMM(BPF_ADD, ret,",
            "\t\t\t\toffsetof(struct htab_elem, key) +",
            "\t\t\t\tround_up(map->key_size, 8));",
            "\t*insn++ = BPF_LDX_MEM(BPF_DW, ret, ret, 0);",
            "",
            "\treturn insn - insn_buf;",
            "}",
            "static void htab_of_map_free(struct bpf_map *map)",
            "{",
            "\tbpf_map_meta_free(map->inner_map_meta);",
            "\tfd_htab_map_free(map);",
            "}"
          ],
          "function_name": "bpf_fd_htab_map_lookup_elem, bpf_fd_htab_map_update_elem, htab_of_map_gen_lookup, htab_of_map_free",
          "description": "该代码段实现了基于文件描述符的哈希表操作，包含查找、更新及释放逻辑。  \n`bpf_fd_htab_map_lookup_elem` 和 `bpf_fd_htab_map_update_elem` 分别用于通过文件描述符键查找和更新哈希表项，依赖于 `map->ops` 中的回调函数。  \n`htab_of_map_gen_lookup` 生成 eBPF 指令以调用哈希表查找逻辑，`htab_of_map_free` 释放哈希表相关元数据；部分底层函数（如 `htab_map_lookup_elem`）未展示，上下文不完整。",
          "similarity": 0.48465606570243835
        },
        {
          "chunk_id": 9,
          "file_path": "kernel/bpf/hashtab.c",
          "start_line": 1465,
          "end_line": 1587,
          "content": [
            "static long htab_lru_map_delete_elem(struct bpf_map *map, void *key)",
            "{",
            "\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);",
            "\tstruct hlist_nulls_head *head;",
            "\tstruct bucket *b;",
            "\tstruct htab_elem *l;",
            "\tunsigned long flags;",
            "\tu32 hash, key_size;",
            "\tint ret;",
            "",
            "\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&",
            "\t\t     !rcu_read_lock_bh_held());",
            "",
            "\tkey_size = map->key_size;",
            "",
            "\thash = htab_map_hash(key, key_size, htab->hashrnd);",
            "\tb = __select_bucket(htab, hash);",
            "\thead = &b->head;",
            "",
            "\tret = htab_lock_bucket(htab, b, hash, &flags);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tl = lookup_elem_raw(head, hash, key, key_size);",
            "",
            "\tif (l)",
            "\t\thlist_nulls_del_rcu(&l->hash_node);",
            "\telse",
            "\t\tret = -ENOENT;",
            "",
            "\thtab_unlock_bucket(htab, b, hash, flags);",
            "\tif (l)",
            "\t\thtab_lru_push_free(htab, l);",
            "\treturn ret;",
            "}",
            "static void delete_all_elements(struct bpf_htab *htab)",
            "{",
            "\tint i;",
            "",
            "\t/* It's called from a worker thread, so disable migration here,",
            "\t * since bpf_mem_cache_free() relies on that.",
            "\t */",
            "\tmigrate_disable();",
            "\tfor (i = 0; i < htab->n_buckets; i++) {",
            "\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);",
            "\t\tstruct hlist_nulls_node *n;",
            "\t\tstruct htab_elem *l;",
            "",
            "\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {",
            "\t\t\thlist_nulls_del_rcu(&l->hash_node);",
            "\t\t\thtab_elem_free(htab, l);",
            "\t\t}",
            "\t}",
            "\tmigrate_enable();",
            "}",
            "static void htab_free_malloced_timers_and_wq(struct bpf_htab *htab)",
            "{",
            "\tint i;",
            "",
            "\trcu_read_lock();",
            "\tfor (i = 0; i < htab->n_buckets; i++) {",
            "\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);",
            "\t\tstruct hlist_nulls_node *n;",
            "\t\tstruct htab_elem *l;",
            "",
            "\t\thlist_nulls_for_each_entry(l, n, head, hash_node) {",
            "\t\t\t/* We only free timer on uref dropping to zero */",
            "\t\t\tif (btf_record_has_field(htab->map.record, BPF_TIMER))",
            "\t\t\t\tbpf_obj_free_timer(htab->map.record,",
            "\t\t\t\t\t\t   l->key + round_up(htab->map.key_size, 8));",
            "\t\t\tif (btf_record_has_field(htab->map.record, BPF_WORKQUEUE))",
            "\t\t\t\tbpf_obj_free_workqueue(htab->map.record,",
            "\t\t\t\t\t\t       l->key + round_up(htab->map.key_size, 8));",
            "\t\t}",
            "\t\tcond_resched_rcu();",
            "\t}",
            "\trcu_read_unlock();",
            "}",
            "static void htab_map_free_timers_and_wq(struct bpf_map *map)",
            "{",
            "\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);",
            "",
            "\t/* We only free timer and workqueue on uref dropping to zero */",
            "\tif (btf_record_has_field(htab->map.record, BPF_TIMER | BPF_WORKQUEUE)) {",
            "\t\tif (!htab_is_prealloc(htab))",
            "\t\t\thtab_free_malloced_timers_and_wq(htab);",
            "\t\telse",
            "\t\t\thtab_free_prealloced_timers_and_wq(htab);",
            "\t}",
            "}",
            "static void htab_map_free(struct bpf_map *map)",
            "{",
            "\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);",
            "\tint i;",
            "",
            "\t/* bpf_free_used_maps() or close(map_fd) will trigger this map_free callback.",
            "\t * bpf_free_used_maps() is called after bpf prog is no longer executing.",
            "\t * There is no need to synchronize_rcu() here to protect map elements.",
            "\t */",
            "",
            "\t/* htab no longer uses call_rcu() directly. bpf_mem_alloc does it",
            "\t * underneath and is reponsible for waiting for callbacks to finish",
            "\t * during bpf_mem_alloc_destroy().",
            "\t */",
            "\tif (!htab_is_prealloc(htab)) {",
            "\t\tdelete_all_elements(htab);",
            "\t} else {",
            "\t\thtab_free_prealloced_fields(htab);",
            "\t\tprealloc_destroy(htab);",
            "\t}",
            "",
            "\tbpf_map_free_elem_count(map);",
            "\tfree_percpu(htab->extra_elems);",
            "\tbpf_map_area_free(htab->buckets);",
            "\tbpf_mem_alloc_destroy(&htab->pcpu_ma);",
            "\tbpf_mem_alloc_destroy(&htab->ma);",
            "\tif (htab->use_percpu_counter)",
            "\t\tpercpu_counter_destroy(&htab->pcount);",
            "\tfor (i = 0; i < HASHTAB_MAP_LOCK_COUNT; i++)",
            "\t\tfree_percpu(htab->map_locked[i]);",
            "\tlockdep_unregister_key(&htab->lockdep_key);",
            "\tbpf_map_area_free(htab);",
            "}"
          ],
          "function_name": "htab_lru_map_delete_elem, delete_all_elements, htab_free_malloced_timers_and_wq, htab_map_free_timers_and_wq, htab_map_free",
          "description": "实现哈希表元素全量清除、定时器/工作队列释放及资源回收，包含桶遍历删除、内存缓存销毁、Per-CPU资源释放和锁依赖注册注销",
          "similarity": 0.4773755669593811
        }
      ]
    },
    {
      "source_file": "kernel/bpf/local_storage.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:15:04\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\local_storage.c`\n\n---\n\n# `bpf/local_storage.c` 技术文档\n\n## 1. 文件概述\n\n`bpf/local_storage.c` 是 Linux 内核中 BPF（Berkeley Packet Filter）子系统的一部分，专门用于实现 **cgroup 本地存储（cgroup local storage）** 功能。该文件在 `CONFIG_CGROUP_BPF` 配置启用时编译，提供了一种机制，允许 BPF 程序为每个 cgroup 实例关联私有的、可持久化的存储空间（即“本地存储”）。这种存储可用于在 BPF 程序中跨调用保存状态，例如统计信息、配置参数等。\n\n该文件实现了两种 BPF map 类型：\n- `BPF_MAP_TYPE_CGROUP_STORAGE`\n- `BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE`\n\n分别用于单值存储和 per-CPU 存储，均基于 cgroup 的 inode ID（及可选的 attach type）作为键进行索引。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct bpf_cgroup_storage_map`**  \n  表示 cgroup 存储类型的 BPF map。包含：\n  - `struct bpf_map map`：继承自通用 BPF map 结构\n  - `spinlock_t lock`：保护红黑树和链表的自旋锁\n  - `struct rb_root root`：以键为索引的红黑树，用于快速查找\n  - `struct list_head list`：用于遍历所有存储项的链表\n\n- **`struct bpf_cgroup_storage_key`**  \n  键结构体，包含：\n  - `__u64 cgroup_inode_id`：cgroup 的 inode ID（唯一标识）\n  - `__u32 attach_type`：BPF 程序附加类型（如 `BPF_CGROUP_INET_INGRESS`）\n\n- **`struct bpf_cgroup_storage`**  \n  存储条目，包含：\n  - `struct rb_node node`：红黑树节点\n  - `struct list_head list_map`：链表节点\n  - `union { struct bpf_storage_buffer *buf; void __percpu *percpu_buf; }`：指向实际数据的指针（单值或 per-CPU）\n\n### 主要函数\n\n- **`cgroup_storage_lookup()`**  \n  在红黑树中根据 key 查找对应的 `bpf_cgroup_storage` 条目，支持加锁/不加锁模式。\n\n- **`cgroup_storage_insert()`**  \n  将新的存储条目插入红黑树，若键已存在则返回 `-EEXIST`。\n\n- **`cgroup_storage_lookup_elem()`**  \n  BPF map 的 `lookup` 操作回调，返回存储数据的起始地址。\n\n- **`cgroup_storage_update_elem()`**  \n  BPF map 的 `update` 操作回调，支持原子更新（带 `BPF_F_LOCK`）或替换整个缓冲区。\n\n- **`bpf_percpu_cgroup_storage_copy()`**  \n  用于 `PERCPU_CGROUP_STORAGE` 类型的 lookup，聚合所有 CPU 的数据。\n\n- **`bpf_percpu_cgroup_storage_update()`**  \n  用于 `PERCPU_CGROUP_STORAGE` 类型的 update，将用户提供的数据分发到各 CPU。\n\n- **`cgroup_storage_get_next_key()`**  \n  实现 BPF map 的 `get_next_key` 操作，用于遍历所有存储条目。\n\n- **`cgroup_storage_map_alloc()`**  \n  分配并初始化 cgroup storage 类型的 BPF map。\n\n- **`cgroup_storage_map_free()`**  \n  释放 map 及其所有存储条目（代码未完整显示，但功能明确）。\n\n## 3. 关键实现\n\n### 键值设计与比较逻辑\n\n- 支持两种键格式：\n  1. 仅 `__u64 cgroup_inode_id`（用于非隔离 attach type）\n  2. `struct bpf_cgroup_storage_key`（包含 inode ID + attach type，用于隔离场景）\n- `attach_type_isolated()` 判断是否使用完整键结构。\n- `bpf_cgroup_storage_key_cmp()` 实现红黑树的比较逻辑，先比较 inode ID，再比较 attach type（如适用）。\n\n### 并发控制\n\n- 使用 `spinlock_t lock` 保护红黑树和链表的修改操作（如插入、遍历）。\n- 查找操作可选择是否加锁（`locked` 参数），以支持 RCU 读路径（如 per-CPU update 中使用 `rcu_read_lock()`）。\n- 单值存储更新时使用 `xchg()` + `kfree_rcu()` 实现无锁读取和安全释放。\n\n### 内存管理\n\n- 单值存储使用 `bpf_map_kmalloc_node()` 分配 `bpf_storage_buffer`，包含数据和可能的 BTF 记录。\n- per-CPU 存储使用 `__percpu` 指针，通过 `per_cpu_ptr()` 访问各 CPU 数据。\n- 所有分配考虑 NUMA 节点（通过 `numa_node` 字段）。\n\n### 安全与限制\n\n- `value_size` 限制：\n  - 普通类型：最大 `BPF_LOCAL_STORAGE_MAX_VALUE_SIZE`\n  - per-CPU 类型：额外受限于 `PCPU_MIN_UNIT_SIZE`\n- 键大小必须为 `sizeof(__u64)` 或 `sizeof(bpf_cgroup_storage_key)`\n- `max_entries` 必须为 0（动态扩展）\n- `map_flags` 仅允许 `BPF_F_NUMA_NODE` 和访问权限标志\n\n### per-CPU 数据对齐\n\n- per-CPU 数据按 8 字节对齐（`round_up(value_size, 8)`），确保跨 CPU 访问安全，并防止内核数据泄露（因 per-CPU 区域初始化为零）。\n\n## 4. 依赖关系\n\n- **BPF 子系统**：依赖 `bpf.h`、`bpf_map.h`、`filter.h` 等核心 BPF 头文件。\n- **cgroup 子系统**：依赖 `cgroup-internal.h` 获取 cgroup 内部结构（如 inode ID）。\n- **内存管理**：使用 `slab.h`、`mm.h` 进行内存分配。\n- **RCU 机制**：用于安全释放旧缓冲区（`kfree_rcu`）。\n- **BTF（BPF Type Format）**：支持带锁字段的类型验证（`btf_record_has_field`）。\n- **红黑树**：使用 `rbtree.h` 实现高效查找。\n- **Per-CPU 基础设施**：使用 `percpu.h` 相关宏（隐式包含）。\n\n## 5. 使用场景\n\n- **BPF 程序状态持久化**：  \n  BPF 程序（如 cgroup hook 程序）可为每个 cgroup 维护独立的计数器、配置或状态机。\n\n- **网络策略与限速**：  \n  在 `BPF_CGROUP_INET_*` 程序中，为每个 cgroup 存储流量统计或令牌桶状态。\n\n- **资源监控**：  \n  用户空间通过 BPF map 接口读取各 cgroup 的累计指标（如 I/O 次数、进程数）。\n\n- **安全策略**：  \n  存储 cgroup 特定的安全上下文或访问控制列表。\n\n- **调试与追踪**：  \n  在 BPF tracepoint 或 kprobe 程序中，按 cgroup 聚合事件数据。\n\n> **注意**：该机制仅在 cgroup BPF 支持启用（`CONFIG_CGROUP_BPF=y`）时可用，且必须通过 BPF 系统调用创建对应类型的 map，并由 BPF 程序或用户空间程序操作。",
      "similarity": 0.5706611275672913,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 414,
          "end_line": 530,
          "content": [
            "static void cgroup_storage_seq_show_elem(struct bpf_map *map, void *key,",
            "\t\t\t\t\t struct seq_file *m)",
            "{",
            "\tenum bpf_cgroup_storage_type stype;",
            "\tstruct bpf_cgroup_storage *storage;",
            "\tint cpu;",
            "",
            "\trcu_read_lock();",
            "\tstorage = cgroup_storage_lookup(map_to_storage(map), key, false);",
            "\tif (!storage) {",
            "\t\trcu_read_unlock();",
            "\t\treturn;",
            "\t}",
            "",
            "\tbtf_type_seq_show(map->btf, map->btf_key_type_id, key, m);",
            "\tstype = cgroup_storage_type(map);",
            "\tif (stype == BPF_CGROUP_STORAGE_SHARED) {",
            "\t\tseq_puts(m, \": \");",
            "\t\tbtf_type_seq_show(map->btf, map->btf_value_type_id,",
            "\t\t\t\t  &READ_ONCE(storage->buf)->data[0], m);",
            "\t\tseq_puts(m, \"\\n\");",
            "\t} else {",
            "\t\tseq_puts(m, \": {\\n\");",
            "\t\tfor_each_possible_cpu(cpu) {",
            "\t\t\tseq_printf(m, \"\\tcpu%d: \", cpu);",
            "\t\t\tbtf_type_seq_show(map->btf, map->btf_value_type_id,",
            "\t\t\t\t\t  per_cpu_ptr(storage->percpu_buf, cpu),",
            "\t\t\t\t\t  m);",
            "\t\t\tseq_puts(m, \"\\n\");",
            "\t\t}",
            "\t\tseq_puts(m, \"}\\n\");",
            "\t}",
            "\trcu_read_unlock();",
            "}",
            "static u64 cgroup_storage_map_usage(const struct bpf_map *map)",
            "{",
            "\t/* Currently the dynamically allocated elements are not counted. */",
            "\treturn sizeof(struct bpf_cgroup_storage_map);",
            "}",
            "int bpf_cgroup_storage_assign(struct bpf_prog_aux *aux, struct bpf_map *_map)",
            "{",
            "\tenum bpf_cgroup_storage_type stype = cgroup_storage_type(_map);",
            "",
            "\tif (aux->cgroup_storage[stype] &&",
            "\t    aux->cgroup_storage[stype] != _map)",
            "\t\treturn -EBUSY;",
            "",
            "\taux->cgroup_storage[stype] = _map;",
            "\treturn 0;",
            "}",
            "static size_t bpf_cgroup_storage_calculate_size(struct bpf_map *map, u32 *pages)",
            "{",
            "\tsize_t size;",
            "",
            "\tif (cgroup_storage_type(map) == BPF_CGROUP_STORAGE_SHARED) {",
            "\t\tsize = sizeof(struct bpf_storage_buffer) + map->value_size;",
            "\t\t*pages = round_up(sizeof(struct bpf_cgroup_storage) + size,",
            "\t\t\t\t  PAGE_SIZE) >> PAGE_SHIFT;",
            "\t} else {",
            "\t\tsize = map->value_size;",
            "\t\t*pages = round_up(round_up(size, 8) * num_possible_cpus(),",
            "\t\t\t\t  PAGE_SIZE) >> PAGE_SHIFT;",
            "\t}",
            "",
            "\treturn size;",
            "}",
            "static void free_shared_cgroup_storage_rcu(struct rcu_head *rcu)",
            "{",
            "\tstruct bpf_cgroup_storage *storage =",
            "\t\tcontainer_of(rcu, struct bpf_cgroup_storage, rcu);",
            "",
            "\tkfree(storage->buf);",
            "\tkfree(storage);",
            "}",
            "static void free_percpu_cgroup_storage_rcu(struct rcu_head *rcu)",
            "{",
            "\tstruct bpf_cgroup_storage *storage =",
            "\t\tcontainer_of(rcu, struct bpf_cgroup_storage, rcu);",
            "",
            "\tfree_percpu(storage->percpu_buf);",
            "\tkfree(storage);",
            "}",
            "void bpf_cgroup_storage_free(struct bpf_cgroup_storage *storage)",
            "{",
            "\tenum bpf_cgroup_storage_type stype;",
            "\tstruct bpf_map *map;",
            "",
            "\tif (!storage)",
            "\t\treturn;",
            "",
            "\tmap = &storage->map->map;",
            "\tstype = cgroup_storage_type(map);",
            "\tif (stype == BPF_CGROUP_STORAGE_SHARED)",
            "\t\tcall_rcu(&storage->rcu, free_shared_cgroup_storage_rcu);",
            "\telse",
            "\t\tcall_rcu(&storage->rcu, free_percpu_cgroup_storage_rcu);",
            "}",
            "void bpf_cgroup_storage_link(struct bpf_cgroup_storage *storage,",
            "\t\t\t     struct cgroup *cgroup,",
            "\t\t\t     enum bpf_attach_type type)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map;",
            "",
            "\tif (!storage)",
            "\t\treturn;",
            "",
            "\tstorage->key.attach_type = type;",
            "\tstorage->key.cgroup_inode_id = cgroup_id(cgroup);",
            "",
            "\tmap = storage->map;",
            "",
            "\tspin_lock_bh(&map->lock);",
            "\tWARN_ON(cgroup_storage_insert(map, storage));",
            "\tlist_add(&storage->list_map, &map->list);",
            "\tlist_add(&storage->list_cg, &cgroup->bpf.storages);",
            "\tspin_unlock_bh(&map->lock);",
            "}"
          ],
          "function_name": "cgroup_storage_seq_show_elem, cgroup_storage_map_usage, bpf_cgroup_storage_assign, bpf_cgroup_storage_calculate_size, free_shared_cgroup_storage_rcu, free_percpu_cgroup_storage_rcu, bpf_cgroup_storage_free, bpf_cgroup_storage_link",
          "description": "包含存储元素序列化显示、内存占用统计、存储分配绑定及RCU安全的内存回收机制，区分共享与per-CPU存储的释放路径。",
          "similarity": 0.5147169828414917
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 1,
          "end_line": 33,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bpf_local_storage.h>",
            "#include <linux/btf.h>",
            "#include <linux/bug.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/rbtree.h>",
            "#include <linux/slab.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/btf_ids.h>",
            "",
            "#ifdef CONFIG_CGROUP_BPF",
            "",
            "#include \"../cgroup/cgroup-internal.h\"",
            "",
            "#define LOCAL_STORAGE_CREATE_FLAG_MASK\t\t\t\t\t\\",
            "\t(BPF_F_NUMA_NODE | BPF_F_ACCESS_MASK)",
            "",
            "struct bpf_cgroup_storage_map {",
            "\tstruct bpf_map map;",
            "",
            "\tspinlock_t lock;",
            "\tstruct rb_root root;",
            "\tstruct list_head list;",
            "};",
            "",
            "static struct bpf_cgroup_storage_map *map_to_storage(struct bpf_map *map)",
            "{",
            "\treturn container_of(map, struct bpf_cgroup_storage_map, map);",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义了BPF cgroup存储管理的基础结构，包含红黑树根节点、锁和链表，通过map_to_storage函数将通用map转换为专用存储结构。",
          "similarity": 0.508510172367096
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 211,
          "end_line": 363,
          "content": [
            "int bpf_percpu_cgroup_storage_update(struct bpf_map *_map, void *key,",
            "\t\t\t\t     void *value, u64 map_flags)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map = map_to_storage(_map);",
            "\tstruct bpf_cgroup_storage *storage;",
            "\tint cpu, off = 0;",
            "\tu32 size;",
            "",
            "\tif (map_flags != BPF_ANY && map_flags != BPF_EXIST)",
            "\t\treturn -EINVAL;",
            "",
            "\trcu_read_lock();",
            "\tstorage = cgroup_storage_lookup(map, key, false);",
            "\tif (!storage) {",
            "\t\trcu_read_unlock();",
            "\t\treturn -ENOENT;",
            "\t}",
            "",
            "\t/* the user space will provide round_up(value_size, 8) bytes that",
            "\t * will be copied into per-cpu area. bpf programs can only access",
            "\t * value_size of it. During lookup the same extra bytes will be",
            "\t * returned or zeros which were zero-filled by percpu_alloc,",
            "\t * so no kernel data leaks possible",
            "\t */",
            "\tsize = round_up(_map->value_size, 8);",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tbpf_long_memcpy(per_cpu_ptr(storage->percpu_buf, cpu),",
            "\t\t\t\tvalue + off, size);",
            "\t\toff += size;",
            "\t}",
            "\trcu_read_unlock();",
            "\treturn 0;",
            "}",
            "static int cgroup_storage_get_next_key(struct bpf_map *_map, void *key,",
            "\t\t\t\t       void *_next_key)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map = map_to_storage(_map);",
            "\tstruct bpf_cgroup_storage *storage;",
            "",
            "\tspin_lock_bh(&map->lock);",
            "",
            "\tif (list_empty(&map->list))",
            "\t\tgoto enoent;",
            "",
            "\tif (key) {",
            "\t\tstorage = cgroup_storage_lookup(map, key, true);",
            "\t\tif (!storage)",
            "\t\t\tgoto enoent;",
            "",
            "\t\tstorage = list_next_entry(storage, list_map);",
            "\t\tif (!storage)",
            "\t\t\tgoto enoent;",
            "\t} else {",
            "\t\tstorage = list_first_entry(&map->list,",
            "\t\t\t\t\t struct bpf_cgroup_storage, list_map);",
            "\t}",
            "",
            "\tspin_unlock_bh(&map->lock);",
            "",
            "\tif (attach_type_isolated(&map->map)) {",
            "\t\tstruct bpf_cgroup_storage_key *next = _next_key;",
            "\t\t*next = storage->key;",
            "\t} else {",
            "\t\t__u64 *next = _next_key;",
            "\t\t*next = storage->key.cgroup_inode_id;",
            "\t}",
            "\treturn 0;",
            "",
            "enoent:",
            "\tspin_unlock_bh(&map->lock);",
            "\treturn -ENOENT;",
            "}",
            "static void cgroup_storage_map_free(struct bpf_map *_map)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map = map_to_storage(_map);",
            "\tstruct list_head *storages = &map->list;",
            "\tstruct bpf_cgroup_storage *storage, *stmp;",
            "",
            "\tcgroup_lock();",
            "",
            "\tlist_for_each_entry_safe(storage, stmp, storages, list_map) {",
            "\t\tbpf_cgroup_storage_unlink(storage);",
            "\t\tbpf_cgroup_storage_free(storage);",
            "\t}",
            "",
            "\tcgroup_unlock();",
            "",
            "\tWARN_ON(!RB_EMPTY_ROOT(&map->root));",
            "\tWARN_ON(!list_empty(&map->list));",
            "",
            "\tbpf_map_area_free(map);",
            "}",
            "static long cgroup_storage_delete_elem(struct bpf_map *map, void *key)",
            "{",
            "\treturn -EINVAL;",
            "}",
            "static int cgroup_storage_check_btf(const struct bpf_map *map,",
            "\t\t\t\t    const struct btf *btf,",
            "\t\t\t\t    const struct btf_type *key_type,",
            "\t\t\t\t    const struct btf_type *value_type)",
            "{",
            "\tif (attach_type_isolated(map)) {",
            "\t\tstruct btf_member *m;",
            "\t\tu32 offset, size;",
            "",
            "\t\t/* Key is expected to be of struct bpf_cgroup_storage_key type,",
            "\t\t * which is:",
            "\t\t * struct bpf_cgroup_storage_key {",
            "\t\t *\t__u64\tcgroup_inode_id;",
            "\t\t *\t__u32\tattach_type;",
            "\t\t * };",
            "\t\t */",
            "",
            "\t\t/*",
            "\t\t * Key_type must be a structure with two fields.",
            "\t\t */",
            "\t\tif (BTF_INFO_KIND(key_type->info) != BTF_KIND_STRUCT ||",
            "\t\t    BTF_INFO_VLEN(key_type->info) != 2)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * The first field must be a 64 bit integer at 0 offset.",
            "\t\t */",
            "\t\tm = (struct btf_member *)(key_type + 1);",
            "\t\tsize = sizeof_field(struct bpf_cgroup_storage_key, cgroup_inode_id);",
            "\t\tif (!btf_member_is_reg_int(btf, key_type, m, 0, size))",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\t/*",
            "\t\t * The second field must be a 32 bit integer at 64 bit offset.",
            "\t\t */",
            "\t\tm++;",
            "\t\toffset = offsetof(struct bpf_cgroup_storage_key, attach_type);",
            "\t\tsize = sizeof_field(struct bpf_cgroup_storage_key, attach_type);",
            "\t\tif (!btf_member_is_reg_int(btf, key_type, m, offset, size))",
            "\t\t\treturn -EINVAL;",
            "\t} else {",
            "\t\tu32 int_data;",
            "",
            "\t\t/*",
            "\t\t * Key is expected to be u64, which stores the cgroup_inode_id",
            "\t\t */",
            "",
            "\t\tif (BTF_INFO_KIND(key_type->info) != BTF_KIND_INT)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\tint_data = *(u32 *)(key_type + 1);",
            "\t\tif (BTF_INT_BITS(int_data) != 64 || BTF_INT_OFFSET(int_data))",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "bpf_percpu_cgroup_storage_update, cgroup_storage_get_next_key, cgroup_storage_map_free, cgroup_storage_delete_elem, cgroup_storage_check_btf",
          "description": "提供了存储遍历、资源释放和BTF类型校验功能，其中delete_elem未实际实现直接返回错误码，check_btf验证键值类型合法性。",
          "similarity": 0.48786354064941406
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 34,
          "end_line": 157,
          "content": [
            "static bool attach_type_isolated(const struct bpf_map *map)",
            "{",
            "\treturn map->key_size == sizeof(struct bpf_cgroup_storage_key);",
            "}",
            "static int bpf_cgroup_storage_key_cmp(const struct bpf_cgroup_storage_map *map,",
            "\t\t\t\t      const void *_key1, const void *_key2)",
            "{",
            "\tif (attach_type_isolated(&map->map)) {",
            "\t\tconst struct bpf_cgroup_storage_key *key1 = _key1;",
            "\t\tconst struct bpf_cgroup_storage_key *key2 = _key2;",
            "",
            "\t\tif (key1->cgroup_inode_id < key2->cgroup_inode_id)",
            "\t\t\treturn -1;",
            "\t\telse if (key1->cgroup_inode_id > key2->cgroup_inode_id)",
            "\t\t\treturn 1;",
            "\t\telse if (key1->attach_type < key2->attach_type)",
            "\t\t\treturn -1;",
            "\t\telse if (key1->attach_type > key2->attach_type)",
            "\t\t\treturn 1;",
            "\t} else {",
            "\t\tconst __u64 *cgroup_inode_id1 = _key1;",
            "\t\tconst __u64 *cgroup_inode_id2 = _key2;",
            "",
            "\t\tif (*cgroup_inode_id1 < *cgroup_inode_id2)",
            "\t\t\treturn -1;",
            "\t\telse if (*cgroup_inode_id1 > *cgroup_inode_id2)",
            "\t\t\treturn 1;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int cgroup_storage_insert(struct bpf_cgroup_storage_map *map,",
            "\t\t\t\t struct bpf_cgroup_storage *storage)",
            "{",
            "\tstruct rb_root *root = &map->root;",
            "\tstruct rb_node **new = &(root->rb_node), *parent = NULL;",
            "",
            "\twhile (*new) {",
            "\t\tstruct bpf_cgroup_storage *this;",
            "",
            "\t\tthis = container_of(*new, struct bpf_cgroup_storage, node);",
            "",
            "\t\tparent = *new;",
            "\t\tswitch (bpf_cgroup_storage_key_cmp(map, &storage->key, &this->key)) {",
            "\t\tcase -1:",
            "\t\t\tnew = &((*new)->rb_left);",
            "\t\t\tbreak;",
            "\t\tcase 1:",
            "\t\t\tnew = &((*new)->rb_right);",
            "\t\t\tbreak;",
            "\t\tdefault:",
            "\t\t\treturn -EEXIST;",
            "\t\t}",
            "\t}",
            "",
            "\trb_link_node(&storage->node, parent, new);",
            "\trb_insert_color(&storage->node, root);",
            "",
            "\treturn 0;",
            "}",
            "static long cgroup_storage_update_elem(struct bpf_map *map, void *key,",
            "\t\t\t\t       void *value, u64 flags)",
            "{",
            "\tstruct bpf_cgroup_storage *storage;",
            "\tstruct bpf_storage_buffer *new;",
            "",
            "\tif (unlikely(flags & ~(BPF_F_LOCK | BPF_EXIST)))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (unlikely((flags & BPF_F_LOCK) &&",
            "\t\t     !btf_record_has_field(map->record, BPF_SPIN_LOCK)))",
            "\t\treturn -EINVAL;",
            "",
            "\tstorage = cgroup_storage_lookup((struct bpf_cgroup_storage_map *)map,",
            "\t\t\t\t\tkey, false);",
            "\tif (!storage)",
            "\t\treturn -ENOENT;",
            "",
            "\tif (flags & BPF_F_LOCK) {",
            "\t\tcopy_map_value_locked(map, storage->buf->data, value, false);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tnew = bpf_map_kmalloc_node(map, struct_size(new, data, map->value_size),",
            "\t\t\t\t   __GFP_ZERO | GFP_NOWAIT | __GFP_NOWARN,",
            "\t\t\t\t   map->numa_node);",
            "\tif (!new)",
            "\t\treturn -ENOMEM;",
            "",
            "\tmemcpy(&new->data[0], value, map->value_size);",
            "\tcheck_and_init_map_value(map, new->data);",
            "",
            "\tnew = xchg(&storage->buf, new);",
            "\tkfree_rcu(new, rcu);",
            "",
            "\treturn 0;",
            "}",
            "int bpf_percpu_cgroup_storage_copy(struct bpf_map *_map, void *key,",
            "\t\t\t\t   void *value)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map = map_to_storage(_map);",
            "\tstruct bpf_cgroup_storage *storage;",
            "\tint cpu, off = 0;",
            "\tu32 size;",
            "",
            "\trcu_read_lock();",
            "\tstorage = cgroup_storage_lookup(map, key, false);",
            "\tif (!storage) {",
            "\t\trcu_read_unlock();",
            "\t\treturn -ENOENT;",
            "\t}",
            "",
            "\t/* per_cpu areas are zero-filled and bpf programs can only",
            "\t * access 'value_size' of them, so copying rounded areas",
            "\t * will not leak any kernel data",
            "\t */",
            "\tsize = round_up(_map->value_size, 8);",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tbpf_long_memcpy(value + off,",
            "\t\t\t\tper_cpu_ptr(storage->percpu_buf, cpu), size);",
            "\t\toff += size;",
            "\t}",
            "\trcu_read_unlock();",
            "\treturn 0;",
            "}"
          ],
          "function_name": "attach_type_isolated, bpf_cgroup_storage_key_cmp, cgroup_storage_insert, cgroup_storage_update_elem, bpf_percpu_cgroup_storage_copy",
          "description": "实现了键值比较逻辑、红黑树插入操作、多CPU数据复制及存储更新功能，支持基于cgroup inode ID和attach类型的键区分。",
          "similarity": 0.48096221685409546
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/bpf/local_storage.c",
          "start_line": 595,
          "end_line": 612,
          "content": [
            "void bpf_cgroup_storage_unlink(struct bpf_cgroup_storage *storage)",
            "{",
            "\tstruct bpf_cgroup_storage_map *map;",
            "\tstruct rb_root *root;",
            "",
            "\tif (!storage)",
            "\t\treturn;",
            "",
            "\tmap = storage->map;",
            "",
            "\tspin_lock_bh(&map->lock);",
            "\troot = &map->root;",
            "\trb_erase(&storage->node, root);",
            "",
            "\tlist_del(&storage->list_map);",
            "\tlist_del(&storage->list_cg);",
            "\tspin_unlock_bh(&map->lock);",
            "}"
          ],
          "function_name": "bpf_cgroup_storage_unlink",
          "description": "负责从红黑树和链表中移除存储项，通过自旋锁保护并发访问，同步维护存储结构与cgroup关联列表。",
          "similarity": 0.4652369022369385
        }
      ]
    },
    {
      "source_file": "kernel/bpf/bpf_inode_storage.c",
      "md_summary": "> 自动生成时间: 2025-10-25 11:57:41\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\bpf_inode_storage.c`\n\n---\n\n# `bpf/bpf_inode_storage.c` 技术文档\n\n## 1. 文件概述\n\n`bpf_inode_storage.c` 实现了 BPF（Berkeley Packet Filter）程序对 **inode 级别本地存储（local storage）** 的支持。该机制允许 BPF 程序将任意用户定义的数据与内核中的 `struct inode` 实例关联，从而在不修改 VFS 层或文件系统代码的前提下，为 inode 附加自定义元数据。此功能主要用于 LSM（Linux Security Module）钩子、审计、追踪等场景。\n\n该文件基于通用的 `bpf_local_storage` 框架，为 inode 对象定制了存储管理逻辑，并提供了 BPF 辅助函数（helpers）和 map 操作接口。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `DEFINE_BPF_STORAGE_CACHE(inode_cache)`：为 inode 存储分配的专用内存缓存。\n- `inode_storage_map_ops`：`bpf_map_ops` 操作集，定义了 inode 存储 map 的行为。\n- `bpf_inode_storage_btf_ids`：BTF（BPF Type Format）类型 ID 列表，用于类型安全检查。\n\n### 关键函数\n- **存储访问与管理**\n  - `inode_storage_ptr()`：获取 inode 对应的 BPF 存储指针。\n  - `inode_storage_lookup()`：在指定 inode 和 map 中查找存储数据。\n  - `bpf_inode_storage_free()`：在 inode 销毁时释放其关联的 BPF 存储。\n  - `inode_storage_delete()`：从 inode 中删除指定 map 的存储项。\n\n- **BPF Map 操作接口**\n  - `bpf_fd_inode_storage_lookup_elem()`：通过文件描述符（fd）查找 inode 存储数据。\n  - `bpf_fd_inode_storage_update_elem()`：通过 fd 更新 inode 存储。\n  - `bpf_fd_inode_storage_delete_elem()`：通过 fd 删除 inode 存储。\n\n- **BPF 辅助函数（Helpers）**\n  - `bpf_inode_storage_get()`：BPF 程序调用的辅助函数，用于获取或创建 inode 存储。\n  - `bpf_inode_storage_delete()`：BPF 程序调用的辅助函数，用于删除 inode 存储。\n\n- **Map 生命周期管理**\n  - `inode_storage_map_alloc()`：分配 inode 存储类型的 BPF map。\n  - `inode_storage_map_free()`：释放该类型 map。\n\n## 3. 关键实现\n\n### 存储绑定机制\n- 每个 `struct inode` 通过 `bpf_inode()` 宏访问其内嵌的 `struct bpf_storage_blob`（通常位于 inode 的安全字段或扩展字段中）。\n- `bpf_storage_blob` 包含一个 RCU 保护的 `struct bpf_local_storage *storage` 指针，指向实际的存储容器。\n- 所有存储操作均通过 `bpf_local_storage` 通用框架完成，确保线程安全和内存管理一致性。\n\n### RCU 与锁策略\n- 查找操作使用 `rcu_read_lock()` 保护，避免持有写锁。\n- 更新/删除操作在必要时使用自旋锁（由 `bpf_local_storage_update` 内部处理）。\n- `bpf_inode_storage_get` 要求调用者已持有 RCU 锁（通过 `bpf_rcu_lock_held()` 验证），确保 inode 不会在操作期间被释放。\n\n### 内存分配策略\n- 存储项分配使用 `GFP_ATOMIC`（在 fd-based 接口）或由 verifier 传入的 `gfp_flags`（在 helper 中），以适应不同上下文（如中断、软中断）。\n- 使用专用 SLAB 缓存 `inode_cache` 优化内存分配性能。\n\n### BPF Map 与 Helper 集成\n- 提供两种访问路径：\n  1. **BPF 程序直接调用 helper**（如 `bpf_inode_storage_get`），传入 `struct inode *`。\n  2. **用户空间通过 fd 操作 map**（如 `bpf_map_lookup_elem`），内核自动解析 fd 到 inode。\n- `map_get_next_key` 返回 `-ENOTSUPP`，表明该 map 不支持迭代。\n\n### 类型安全\n- 通过 BTF 类型 ID (`bpf_inode_storage_btf_ids`) 确保 BPF 程序传入的 `inode` 指针类型正确。\n- `arg2_type = ARG_PTR_TO_BTF_ID_OR_NULL` 允许传入空指针（安全处理）。\n\n## 4. 依赖关系\n\n- **核心依赖**\n  - `<linux/bpf_local_storage.h>`：提供通用本地存储框架。\n  - `<linux/bpf.h>`：BPF 核心基础设施。\n  - `<linux/rculist.h>` / `<linux/spinlock.h>`：并发控制原语。\n  - `<linux/fdtable.h>`：fd 解析支持。\n\n- **关联子系统**\n  - **VFS（Virtual File System）**：依赖 `struct inode` 结构及生命周期管理。\n  - **BPF 子系统**：集成到 BPF map 和 helper 机制中。\n  - **LSM（Linux Security Modules）**：常用于在 LSM 钩子中附加安全上下文。\n  - **BTF（BPF Type Format）**：用于运行时类型验证。\n\n- **内存管理**\n  - 依赖 SLAB 分配器创建专用缓存 `inode_cache`。\n  - 与 RCU 机制深度集成，确保存储项安全回收。\n\n## 5. 使用场景\n\n1. **LSM 安全策略扩展**\n   - 在 LSM 钩子（如 `file_open`、`inode_permission`）中，BPF 程序可为 inode 附加自定义安全标签或策略数据。\n\n2. **文件系统审计与监控**\n   - 追踪特定 inode 的访问模式，记录额外审计信息（如首次访问时间、访问者 UID）。\n\n3. **资源配额与限制**\n   - 为 inode 关联配额计数器，实现细粒度资源控制（如单个文件的 I/O 限速）。\n\n4. **调试与性能分析**\n   - 在 BPF 程序中为热点 inode 附加调试信息，辅助性能调优。\n\n5. **用户空间工具集成**\n   - 通过 fd 操作 map，用户空间程序可查询/修改 inode 的 BPF 存储（如 `bpftool` 调试）。\n\n> **注意**：由于 inode 可能被频繁创建/销毁，BPF 程序必须确保在安全上下文中调用 helper（如持有 inode 引用或处于 RCU 临界区），避免访问已释放内存。",
      "similarity": 0.5567190647125244,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/bpf/bpf_inode_storage.c",
          "start_line": 57,
          "end_line": 121,
          "content": [
            "void bpf_inode_storage_free(struct inode *inode)",
            "{",
            "\tstruct bpf_local_storage *local_storage;",
            "\tstruct bpf_storage_blob *bsb;",
            "",
            "\tbsb = bpf_inode(inode);",
            "\tif (!bsb)",
            "\t\treturn;",
            "",
            "\trcu_read_lock();",
            "",
            "\tlocal_storage = rcu_dereference(bsb->storage);",
            "\tif (!local_storage) {",
            "\t\trcu_read_unlock();",
            "\t\treturn;",
            "\t}",
            "",
            "\tbpf_local_storage_destroy(local_storage);",
            "\trcu_read_unlock();",
            "}",
            "static long bpf_fd_inode_storage_update_elem(struct bpf_map *map, void *key,",
            "\t\t\t\t\t     void *value, u64 map_flags)",
            "{",
            "\tstruct bpf_local_storage_data *sdata;",
            "\tCLASS(fd_raw, f)(*(int *)key);",
            "",
            "\tif (fd_empty(f))",
            "\t\treturn -EBADF;",
            "\tif (!inode_storage_ptr(file_inode(fd_file(f))))",
            "\t\treturn -EBADF;",
            "",
            "\tsdata = bpf_local_storage_update(file_inode(fd_file(f)),",
            "\t\t\t\t\t (struct bpf_local_storage_map *)map,",
            "\t\t\t\t\t value, map_flags, false, GFP_ATOMIC);",
            "\treturn PTR_ERR_OR_ZERO(sdata);",
            "}",
            "static int inode_storage_delete(struct inode *inode, struct bpf_map *map)",
            "{",
            "\tstruct bpf_local_storage_data *sdata;",
            "",
            "\tsdata = inode_storage_lookup(inode, map, false);",
            "\tif (!sdata)",
            "\t\treturn -ENOENT;",
            "",
            "\tbpf_selem_unlink(SELEM(sdata), false);",
            "",
            "\treturn 0;",
            "}",
            "static long bpf_fd_inode_storage_delete_elem(struct bpf_map *map, void *key)",
            "{",
            "\tCLASS(fd_raw, f)(*(int *)key);",
            "",
            "\tif (fd_empty(f))",
            "\t\treturn -EBADF;",
            "\treturn inode_storage_delete(file_inode(fd_file(f)), map);",
            "}",
            "static int notsupp_get_next_key(struct bpf_map *map, void *key,",
            "\t\t\t\tvoid *next_key)",
            "{",
            "\treturn -ENOTSUPP;",
            "}",
            "static void inode_storage_map_free(struct bpf_map *map)",
            "{",
            "\tbpf_local_storage_map_free(map, &inode_cache, NULL);",
            "}"
          ],
          "function_name": "bpf_inode_storage_free, bpf_fd_inode_storage_update_elem, inode_storage_delete, bpf_fd_inode_storage_delete_elem, notsupp_get_next_key, inode_storage_map_free",
          "description": "实现inode相关BPF存储资源的释放、更新、删除操作。包含释放存储空间、通过文件描述符更新存储项、删除存储条目等功能，同时注册了不支持的get_next_key操作并实现map销毁时的缓存回收逻辑。",
          "similarity": 0.526909589767456
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/bpf_inode_storage.c",
          "start_line": 1,
          "end_line": 56,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (c) 2019 Facebook",
            " * Copyright 2020 Google LLC.",
            " */",
            "",
            "#include <linux/rculist.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/types.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bpf_local_storage.h>",
            "#include <net/sock.h>",
            "#include <uapi/linux/sock_diag.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/rcupdate_trace.h>",
            "",
            "DEFINE_BPF_STORAGE_CACHE(inode_cache);",
            "",
            "static struct bpf_local_storage __rcu **",
            "inode_storage_ptr(void *owner)",
            "{",
            "\tstruct inode *inode = owner;",
            "\tstruct bpf_storage_blob *bsb;",
            "",
            "\tbsb = bpf_inode(inode);",
            "\tif (!bsb)",
            "\t\treturn NULL;",
            "\treturn &bsb->storage;",
            "}",
            "",
            "static struct bpf_local_storage_data *inode_storage_lookup(struct inode *inode,",
            "\t\t\t\t\t\t\t   struct bpf_map *map,",
            "\t\t\t\t\t\t\t   bool cacheit_lockit)",
            "{",
            "\tstruct bpf_local_storage *inode_storage;",
            "\tstruct bpf_local_storage_map *smap;",
            "\tstruct bpf_storage_blob *bsb;",
            "",
            "\tbsb = bpf_inode(inode);",
            "\tif (!bsb)",
            "\t\treturn NULL;",
            "",
            "\tinode_storage =",
            "\t\trcu_dereference_check(bsb->storage, bpf_rcu_lock_held());",
            "\tif (!inode_storage)",
            "\t\treturn NULL;",
            "",
            "\tsmap = (struct bpf_local_storage_map *)map;",
            "\treturn bpf_local_storage_lookup(inode_storage, smap, cacheit_lockit);",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义inode级别的BPF本地存储缓存inode_cache，并提供用于获取inode存储指针及查询特定map中存储数据的辅助函数。其中inode_storage_lookup通过RCU读锁安全地检索存储实例并调用底层BPF本地存储查找逻辑。",
          "similarity": 0.47671958804130554
        }
      ]
    }
  ]
}