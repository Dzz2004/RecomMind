{
  "query": "Linux内核页表结构设计",
  "timestamp": "2025-12-25 23:22:26",
  "retrieved_files": [
    {
      "source_file": "mm/mmu_gather.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:52:52\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `mmu_gather.c`\n\n---\n\n# mmu_gather.c 技术文档\n\n## 1. 文件概述\n\n`mmu_gather.c` 是 Linux 内核内存管理子系统中的关键组件，负责在页表项（PTE）或更高层级页表被撤销映射（unmap）后，高效地批量释放对应的物理页面和页表结构。该文件实现了 **MMU gather** 机制，用于延迟并批量处理 TLB（Translation Lookaside Buffer）刷新、反向映射（rmap）清理以及页面回收操作，以减少频繁的 TLB 刷新开销和锁竞争，提升性能。\n\n当内核需要释放大量虚拟内存区域（如进程退出、mmap 区域销毁）时，不会立即释放每个页面，而是先将待释放的页面收集到 `mmu_gather` 结构中，待累积到一定数量或显式调用 flush 操作时，再统一执行 TLB 刷新、rmap 解除和页面释放。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `tlb_next_batch(struct mmu_gather *tlb)`  \n  分配新的批处理批次（batch），用于扩展可收集的页面数量上限。\n\n- `tlb_flush_rmaps(struct mmu_gather *tlb, struct vm_area_struct *vma)`  \n  （仅在 SMP 下）处理延迟的反向映射（delayed rmap）移除操作，在 TLB 刷新后调用。\n\n- `__tlb_batch_free_encoded_pages(struct mmu_gather_batch *batch)`  \n  批量释放编码后的页面（包括普通页面和 swap 缓存），支持防软锁定（soft lockup）的调度点。\n\n- `tlb_batch_pages_flush(struct mmu_gather *tlb)`  \n  遍历所有批次，释放其中收集的所有页面。\n\n- `tlb_batch_list_free(struct mmu_gather *tlb)`  \n  释放动态分配的批次内存（非本地批次）。\n\n- `__tlb_remove_folio_pages_size(...)` / `__tlb_remove_folio_pages(...)` / `__tlb_remove_page_size(...)`  \n  将页面（单页或多页 folio）加入当前 gather 批次，支持延迟 rmap 和不同页面大小。\n\n- `tlb_remove_table_sync_one(void)`  \n  （RCU 表释放模式下）触发 IPI 同步，确保软件页表遍历安全。\n\n- `tlb_remove_table_rcu(struct rcu_head *head)`  \n  RCU 回调函数，用于异步释放页表结构。\n\n- `tlb_remove_table_free(struct mmu_table_batch *batch)`  \n  将页表批次提交给 RCU 机制进行延迟释放。\n\n### 关键数据结构\n\n- `struct mmu_gather`  \n  核心上下文结构，包含本地批次（`local`）、当前活跃批次（`active`）、批次计数、延迟 rmap 标志等。\n\n- `struct mmu_gather_batch`  \n  页面批次结构，包含指向编码页面指针数组、当前数量（`nr`）、最大容量（`max`）及下一个批次指针。\n\n- `struct mmu_table_batch`  \n  页表结构批次，用于批量收集待释放的页表（如 PMD、PUD 等）。\n\n- `encoded_page` 相关机制  \n  使用指针低位编码额外信息（如是否延迟 rmap、是否后跟 nr_pages 字段），节省内存并提高缓存效率。\n\n## 3. 关键实现\n\n### 批处理与动态扩展\n- 默认使用栈上或局部存储的 `local` 批次（避免内存分配）。\n- 当 `local` 批次满时，通过 `__get_free_page()` 动态分配新批次（最多 `MAX_GATHER_BATCH_COUNT` 个）。\n- `tlb_next_batch()` 在存在延迟 rmap 时限制扩展，确保语义正确性。\n\n### 延迟反向映射（Delayed Rmap）\n- 当页面仍被其他 VMA 引用但当前 VMA 正在 unmap 时，不立即调用 `folio_remove_rmap_ptes()`，而是标记 `ENCODED_PAGE_BIT_DELAY_RMAP`。\n- 在 `tlb_flush_rmaps()` 中统一处理，确保在 TLB 刷新**之后**才解除 rmap，防止 CPU 访问已释放页面。\n\n### 安全释放与防软锁定\n- 页面释放循环中每处理最多 `MAX_NR_FOLIOS_PER_FREE`（512）个 folio 调用 `cond_resched()`，避免在非抢占内核中长时间占用 CPU。\n- 若启用 `page_poisoning` 或 `init_on_free`，则按实际内存大小（而非 folio 数量）限制单次释放量，因初始化开销与内存大小成正比。\n\n### 页表结构的安全释放（RCU 模式）\n- 在支持软件页表遍历（如 `gup_fast`）的架构上，页表释放需与遍历操作同步。\n- 使用 `call_rcu()` 延迟释放页表，配合 `smp_call_function()` 触发 IPI 确保所有 CPU 完成 TLB 刷新后再释放内存。\n- 若 RCU 批次分配失败，则回退到即时释放（代码未完整展示，但注释提及）。\n\n### 编码页面指针\n- 利用页面指针对齐特性（通常低 2~3 位为 0），将标志位（如 `DELAY_RMAP`、`NR_PAGES_NEXT`）存储在指针低位。\n- 支持多页 folio：若 `nr_pages > 1`，则连续两个条目分别存储页面指针（带标志）和页数。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm_types.h>`、`<linux/mm_inline.h>`、`<linux/rmap.h>` 等，与 folio、page、VMA 管理紧密集成。\n- **TLB 管理**：通过 `<asm/tlb.h>` 与架构相关 TLB 刷新接口交互。\n- **RCU 机制**：在 `CONFIG_MMU_GATHER_RCU_TABLE_FREE` 下依赖 `<linux/rcupdate.h>` 实现页表安全释放。\n- **SMP 支持**：`tlb_flush_rmaps` 和页表同步仅在 `CONFIG_SMP` 下编译。\n- **高阶内存与交换**：使用 `<linux/highmem.h>`、`<linux/swap.h>` 处理高端内存和 swap 缓存释放。\n- **内存分配器**：通过 `__get_free_page(GFP_NOWAIT)` 动态分配批次内存。\n\n## 5. 使用场景\n\n- **进程退出（exit_mmap）**：释放整个地址空间时，大量页面通过 mmu_gather 批量回收。\n- **munmap 系统调用**：解除大块内存映射时，避免逐页 TLB 刷新。\n- **内存回收（reclaim）**：在直接回收或 kswapd 中撤销映射时使用。\n- **透明大页（THP）拆分**：拆分大页时需撤销多个 PTE 映射并释放 sub-page。\n- **页表收缩（shrink_page_list）**：在页面回收路径中解除映射。\n- **KSM（Kernel Samepage Merging）**：合并或取消合并页面时更新 rmap。\n- **页表层级释放**：当上层页表（如 PGD/P4D/PUD/PMD）不再被引用时，通过 `tlb_remove_table` 机制安全释放。",
      "similarity": 0.6410862803459167,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/mmu_gather.c",
          "start_line": 144,
          "end_line": 244,
          "content": [
            "static void tlb_batch_pages_flush(struct mmu_gather *tlb)",
            "{",
            "\tstruct mmu_gather_batch *batch;",
            "",
            "\tfor (batch = &tlb->local; batch && batch->nr; batch = batch->next)",
            "\t\t__tlb_batch_free_encoded_pages(batch);",
            "\ttlb->active = &tlb->local;",
            "}",
            "static void tlb_batch_list_free(struct mmu_gather *tlb)",
            "{",
            "\tstruct mmu_gather_batch *batch, *next;",
            "",
            "\tfor (batch = tlb->local.next; batch; batch = next) {",
            "\t\tnext = batch->next;",
            "\t\tfree_pages((unsigned long)batch, 0);",
            "\t}",
            "\ttlb->local.next = NULL;",
            "}",
            "static bool __tlb_remove_folio_pages_size(struct mmu_gather *tlb,",
            "\t\tstruct page *page, unsigned int nr_pages, bool delay_rmap,",
            "\t\tint page_size)",
            "{",
            "\tint flags = delay_rmap ? ENCODED_PAGE_BIT_DELAY_RMAP : 0;",
            "\tstruct mmu_gather_batch *batch;",
            "",
            "\tVM_BUG_ON(!tlb->end);",
            "",
            "#ifdef CONFIG_MMU_GATHER_PAGE_SIZE",
            "\tVM_WARN_ON(tlb->page_size != page_size);",
            "\tVM_WARN_ON_ONCE(nr_pages != 1 && page_size != PAGE_SIZE);",
            "\tVM_WARN_ON_ONCE(page_folio(page) != page_folio(page + nr_pages - 1));",
            "#endif",
            "",
            "\tbatch = tlb->active;",
            "\t/*",
            "\t * Add the page and check if we are full. If so",
            "\t * force a flush.",
            "\t */",
            "\tif (likely(nr_pages == 1)) {",
            "\t\tbatch->encoded_pages[batch->nr++] = encode_page(page, flags);",
            "\t} else {",
            "\t\tflags |= ENCODED_PAGE_BIT_NR_PAGES_NEXT;",
            "\t\tbatch->encoded_pages[batch->nr++] = encode_page(page, flags);",
            "\t\tbatch->encoded_pages[batch->nr++] = encode_nr_pages(nr_pages);",
            "\t}",
            "\t/*",
            "\t * Make sure that we can always add another \"page\" + \"nr_pages\",",
            "\t * requiring two entries instead of only a single one.",
            "\t */",
            "\tif (batch->nr >= batch->max - 1) {",
            "\t\tif (!tlb_next_batch(tlb))",
            "\t\t\treturn true;",
            "\t\tbatch = tlb->active;",
            "\t}",
            "\tVM_BUG_ON_PAGE(batch->nr > batch->max - 1, page);",
            "",
            "\treturn false;",
            "}",
            "bool __tlb_remove_folio_pages(struct mmu_gather *tlb, struct page *page,",
            "\t\tunsigned int nr_pages, bool delay_rmap)",
            "{",
            "\treturn __tlb_remove_folio_pages_size(tlb, page, nr_pages, delay_rmap,",
            "\t\t\t\t\t     PAGE_SIZE);",
            "}",
            "bool __tlb_remove_page_size(struct mmu_gather *tlb, struct page *page,",
            "\t\tbool delay_rmap, int page_size)",
            "{",
            "\treturn __tlb_remove_folio_pages_size(tlb, page, 1, delay_rmap, page_size);",
            "}",
            "static void __tlb_remove_table_free(struct mmu_table_batch *batch)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < batch->nr; i++)",
            "\t\t__tlb_remove_table(batch->tables[i]);",
            "",
            "\tfree_page((unsigned long)batch);",
            "}",
            "static void tlb_remove_table_smp_sync(void *arg)",
            "{",
            "\t/* Simply deliver the interrupt */",
            "}",
            "void tlb_remove_table_sync_one(void)",
            "{",
            "\t/*",
            "\t * This isn't an RCU grace period and hence the page-tables cannot be",
            "\t * assumed to be actually RCU-freed.",
            "\t *",
            "\t * It is however sufficient for software page-table walkers that rely on",
            "\t * IRQ disabling.",
            "\t */",
            "\tsmp_call_function(tlb_remove_table_smp_sync, NULL, 1);",
            "}",
            "static void tlb_remove_table_rcu(struct rcu_head *head)",
            "{",
            "\t__tlb_remove_table_free(container_of(head, struct mmu_table_batch, rcu));",
            "}",
            "static void tlb_remove_table_free(struct mmu_table_batch *batch)",
            "{",
            "\tcall_rcu(&batch->rcu, tlb_remove_table_rcu);",
            "}"
          ],
          "function_name": "tlb_batch_pages_flush, tlb_batch_list_free, __tlb_remove_folio_pages_size, __tlb_remove_folio_pages, __tlb_remove_page_size, __tlb_remove_table_free, tlb_remove_table_smp_sync, tlb_remove_table_sync_one, tlb_remove_table_rcu, tlb_remove_table_free",
          "description": "实现页表条目批量移除和内存表管理，包含多页面处理、NR_PAGES_NEXT 标记解析及 RCU 安全释放",
          "similarity": 0.6223444938659668
        },
        {
          "chunk_id": 3,
          "file_path": "mm/mmu_gather.c",
          "start_line": 292,
          "end_line": 424,
          "content": [
            "static void tlb_remove_table_free(struct mmu_table_batch *batch)",
            "{",
            "\t__tlb_remove_table_free(batch);",
            "}",
            "static inline void tlb_table_invalidate(struct mmu_gather *tlb)",
            "{",
            "\tif (tlb_needs_table_invalidate()) {",
            "\t\t/*",
            "\t\t * Invalidate page-table caches used by hardware walkers. Then",
            "\t\t * we still need to RCU-sched wait while freeing the pages",
            "\t\t * because software walkers can still be in-flight.",
            "\t\t */",
            "\t\ttlb_flush_mmu_tlbonly(tlb);",
            "\t}",
            "}",
            "static void tlb_remove_table_one(void *table)",
            "{",
            "\ttlb_remove_table_sync_one();",
            "\t__tlb_remove_table(table);",
            "}",
            "static void tlb_table_flush(struct mmu_gather *tlb)",
            "{",
            "\tstruct mmu_table_batch **batch = &tlb->batch;",
            "",
            "\tif (*batch) {",
            "\t\ttlb_table_invalidate(tlb);",
            "\t\ttlb_remove_table_free(*batch);",
            "\t\t*batch = NULL;",
            "\t}",
            "}",
            "void tlb_remove_table(struct mmu_gather *tlb, void *table)",
            "{",
            "\tstruct mmu_table_batch **batch = &tlb->batch;",
            "",
            "\tif (*batch == NULL) {",
            "\t\t*batch = (struct mmu_table_batch *)__get_free_page(GFP_NOWAIT | __GFP_NOWARN);",
            "\t\tif (*batch == NULL) {",
            "\t\t\ttlb_table_invalidate(tlb);",
            "\t\t\ttlb_remove_table_one(table);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\t(*batch)->nr = 0;",
            "\t}",
            "",
            "\t(*batch)->tables[(*batch)->nr++] = table;",
            "\tif ((*batch)->nr == MAX_TABLE_BATCH)",
            "\t\ttlb_table_flush(tlb);",
            "}",
            "static inline void tlb_table_init(struct mmu_gather *tlb)",
            "{",
            "\ttlb->batch = NULL;",
            "}",
            "static inline void tlb_table_flush(struct mmu_gather *tlb) { }",
            "static inline void tlb_table_init(struct mmu_gather *tlb) { }",
            "static void tlb_flush_mmu_free(struct mmu_gather *tlb)",
            "{",
            "\ttlb_table_flush(tlb);",
            "#ifndef CONFIG_MMU_GATHER_NO_GATHER",
            "\ttlb_batch_pages_flush(tlb);",
            "#endif",
            "}",
            "void tlb_flush_mmu(struct mmu_gather *tlb)",
            "{",
            "\ttlb_flush_mmu_tlbonly(tlb);",
            "\ttlb_flush_mmu_free(tlb);",
            "}",
            "static void __tlb_gather_mmu(struct mmu_gather *tlb, struct mm_struct *mm,",
            "\t\t\t     bool fullmm)",
            "{",
            "\ttlb->mm = mm;",
            "\ttlb->fullmm = fullmm;",
            "",
            "#ifndef CONFIG_MMU_GATHER_NO_GATHER",
            "\ttlb->need_flush_all = 0;",
            "\ttlb->local.next = NULL;",
            "\ttlb->local.nr   = 0;",
            "\ttlb->local.max  = ARRAY_SIZE(tlb->__pages);",
            "\ttlb->active     = &tlb->local;",
            "\ttlb->batch_count = 0;",
            "#endif",
            "\ttlb->delayed_rmap = 0;",
            "",
            "\ttlb_table_init(tlb);",
            "#ifdef CONFIG_MMU_GATHER_PAGE_SIZE",
            "\ttlb->page_size = 0;",
            "#endif",
            "",
            "\t__tlb_reset_range(tlb);",
            "\tinc_tlb_flush_pending(tlb->mm);",
            "}",
            "void tlb_gather_mmu(struct mmu_gather *tlb, struct mm_struct *mm)",
            "{",
            "\t__tlb_gather_mmu(tlb, mm, false);",
            "}",
            "void tlb_gather_mmu_fullmm(struct mmu_gather *tlb, struct mm_struct *mm)",
            "{",
            "\t__tlb_gather_mmu(tlb, mm, true);",
            "}",
            "void tlb_finish_mmu(struct mmu_gather *tlb)",
            "{",
            "\t/*",
            "\t * If there are parallel threads are doing PTE changes on same range",
            "\t * under non-exclusive lock (e.g., mmap_lock read-side) but defer TLB",
            "\t * flush by batching, one thread may end up seeing inconsistent PTEs",
            "\t * and result in having stale TLB entries.  So flush TLB forcefully",
            "\t * if we detect parallel PTE batching threads.",
            "\t *",
            "\t * However, some syscalls, e.g. munmap(), may free page tables, this",
            "\t * needs force flush everything in the given range. Otherwise this",
            "\t * may result in having stale TLB entries for some architectures,",
            "\t * e.g. aarch64, that could specify flush what level TLB.",
            "\t */",
            "\tif (mm_tlb_flush_nested(tlb->mm)) {",
            "\t\t/*",
            "\t\t * The aarch64 yields better performance with fullmm by",
            "\t\t * avoiding multiple CPUs spamming TLBI messages at the",
            "\t\t * same time.",
            "\t\t *",
            "\t\t * On x86 non-fullmm doesn't yield significant difference",
            "\t\t * against fullmm.",
            "\t\t */",
            "\t\ttlb->fullmm = 1;",
            "\t\t__tlb_reset_range(tlb);",
            "\t\ttlb->freed_tables = 1;",
            "\t}",
            "",
            "\ttlb_flush_mmu(tlb);",
            "",
            "#ifndef CONFIG_MMU_GATHER_NO_GATHER",
            "\ttlb_batch_list_free(tlb);",
            "#endif",
            "\tdec_tlb_flush_pending(tlb->mm);",
            "}"
          ],
          "function_name": "tlb_remove_table_free, tlb_table_invalidate, tlb_remove_table_one, tlb_table_flush, tlb_remove_table, tlb_table_init, tlb_table_flush, tlb_table_init, tlb_flush_mmu_free, tlb_flush_mmu, __tlb_gather_mmu, tlb_gather_mmu, tlb_gather_mmu_fullmm, tlb_finish_mmu",
          "description": "提供 TLB 无效化、页表批量释放及 MMU 收集器初始化/终止接口，包含跨架构的 TLB 同步机制",
          "similarity": 0.5324475169181824
        },
        {
          "chunk_id": 0,
          "file_path": "mm/mmu_gather.c",
          "start_line": 1,
          "end_line": 17,
          "content": [
            "#include <linux/gfp.h>",
            "#include <linux/highmem.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mmdebug.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/smp.h>",
            "#include <linux/swap.h>",
            "#include <linux/rmap.h>",
            "",
            "#include <asm/pgalloc.h>",
            "#include <asm/tlb.h>",
            "",
            "#ifndef CONFIG_MMU_GATHER_NO_GATHER",
            ""
          ],
          "function_name": null,
          "description": "声明 MMU 聚合功能所需头文件，根据配置条件包含架构相关实现",
          "similarity": 0.5164301991462708
        },
        {
          "chunk_id": 1,
          "file_path": "mm/mmu_gather.c",
          "start_line": 18,
          "end_line": 120,
          "content": [
            "static bool tlb_next_batch(struct mmu_gather *tlb)",
            "{",
            "\tstruct mmu_gather_batch *batch;",
            "",
            "\t/* Limit batching if we have delayed rmaps pending */",
            "\tif (tlb->delayed_rmap && tlb->active != &tlb->local)",
            "\t\treturn false;",
            "",
            "\tbatch = tlb->active;",
            "\tif (batch->next) {",
            "\t\ttlb->active = batch->next;",
            "\t\treturn true;",
            "\t}",
            "",
            "\tif (tlb->batch_count == MAX_GATHER_BATCH_COUNT)",
            "\t\treturn false;",
            "",
            "\tbatch = (void *)__get_free_page(GFP_NOWAIT | __GFP_NOWARN);",
            "\tif (!batch)",
            "\t\treturn false;",
            "",
            "\ttlb->batch_count++;",
            "\tbatch->next = NULL;",
            "\tbatch->nr   = 0;",
            "\tbatch->max  = MAX_GATHER_BATCH;",
            "",
            "\ttlb->active->next = batch;",
            "\ttlb->active = batch;",
            "",
            "\treturn true;",
            "}",
            "static void tlb_flush_rmap_batch(struct mmu_gather_batch *batch, struct vm_area_struct *vma)",
            "{",
            "\tstruct encoded_page **pages = batch->encoded_pages;",
            "",
            "\tfor (int i = 0; i < batch->nr; i++) {",
            "\t\tstruct encoded_page *enc = pages[i];",
            "",
            "\t\tif (encoded_page_flags(enc) & ENCODED_PAGE_BIT_DELAY_RMAP) {",
            "\t\t\tstruct page *page = encoded_page_ptr(enc);",
            "\t\t\tunsigned int nr_pages = 1;",
            "",
            "\t\t\tif (unlikely(encoded_page_flags(enc) &",
            "\t\t\t\t     ENCODED_PAGE_BIT_NR_PAGES_NEXT))",
            "\t\t\t\tnr_pages = encoded_nr_pages(pages[++i]);",
            "",
            "\t\t\tfolio_remove_rmap_ptes(page_folio(page), page, nr_pages,",
            "\t\t\t\t\t       vma);",
            "\t\t}",
            "\t}",
            "}",
            "void tlb_flush_rmaps(struct mmu_gather *tlb, struct vm_area_struct *vma)",
            "{",
            "\tif (!tlb->delayed_rmap)",
            "\t\treturn;",
            "",
            "\ttlb_flush_rmap_batch(&tlb->local, vma);",
            "\tif (tlb->active != &tlb->local)",
            "\t\ttlb_flush_rmap_batch(tlb->active, vma);",
            "\ttlb->delayed_rmap = 0;",
            "}",
            "static void __tlb_batch_free_encoded_pages(struct mmu_gather_batch *batch)",
            "{",
            "\tstruct encoded_page **pages = batch->encoded_pages;",
            "\tunsigned int nr, nr_pages;",
            "",
            "\twhile (batch->nr) {",
            "\t\tif (!page_poisoning_enabled_static() && !want_init_on_free()) {",
            "\t\t\tnr = min(MAX_NR_FOLIOS_PER_FREE, batch->nr);",
            "",
            "\t\t\t/*",
            "\t\t\t * Make sure we cover page + nr_pages, and don't leave",
            "\t\t\t * nr_pages behind when capping the number of entries.",
            "\t\t\t */",
            "\t\t\tif (unlikely(encoded_page_flags(pages[nr - 1]) &",
            "\t\t\t\t     ENCODED_PAGE_BIT_NR_PAGES_NEXT))",
            "\t\t\t\tnr++;",
            "\t\t} else {",
            "\t\t\t/*",
            "\t\t\t * With page poisoning and init_on_free, the time it",
            "\t\t\t * takes to free memory grows proportionally with the",
            "\t\t\t * actual memory size. Therefore, limit based on the",
            "\t\t\t * actual memory size and not the number of involved",
            "\t\t\t * folios.",
            "\t\t\t */",
            "\t\t\tfor (nr = 0, nr_pages = 0;",
            "\t\t\t     nr < batch->nr && nr_pages < MAX_NR_FOLIOS_PER_FREE;",
            "\t\t\t     nr++) {",
            "\t\t\t\tif (unlikely(encoded_page_flags(pages[nr]) &",
            "\t\t\t\t\t     ENCODED_PAGE_BIT_NR_PAGES_NEXT))",
            "\t\t\t\t\tnr_pages += encoded_nr_pages(pages[++nr]);",
            "\t\t\t\telse",
            "\t\t\t\t\tnr_pages++;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tfree_pages_and_swap_cache(pages, nr);",
            "\t\tpages += nr;",
            "\t\tbatch->nr -= nr;",
            "",
            "\t\tcond_resched();",
            "\t}",
            "}"
          ],
          "function_name": "tlb_next_batch, tlb_flush_rmap_batch, tlb_flush_rmaps, __tlb_batch_free_encoded_pages",
          "description": "管理 TLB 批量操作的延迟 RMAP 处理逻辑，包括批次链表管理、编码页面释放及 RMAP 标志清除",
          "similarity": 0.48476678133010864
        }
      ]
    },
    {
      "source_file": "mm/page_ext.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:01:26\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `page_ext.c`\n\n---\n\n# page_ext.c 技术文档\n\n## 1. 文件概述\n\n`page_ext.c` 实现了 Linux 内核中的 **页面扩展（page extension）** 机制，用于在不修改 `struct page` 结构体的前提下，为每个物理页附加额外的元数据。该机制解决了传统方式中因直接扩增 `struct page` 而导致的内核重建成本高、第三方模块兼容性差以及潜在系统行为变更等问题。\n\n页面扩展内存按需分配：仅当至少一个功能模块声明需要扩展数据时，才在启动阶段分配大块连续内存；否则完全跳过分配，避免内存浪费。该机制支持平坦内存（FLATMEM）和稀疏内存（SPARSEMEM）两种内存模型，并提供统一的访问接口。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct page_ext_operations`：客户端模块注册的回调操作集，包含：\n  - `need()`：判断是否需要为本模块分配扩展内存（必选）\n  - `init()`：扩展内存分配完成后执行的初始化函数（可选）\n  - `size`：所需额外内存大小（字节）\n  - `offset`：分配后返回的偏移量（由核心填充）\n  - `need_shared_flags`：是否需要共享基础 `struct page_ext` 结构\n\n### 主要全局变量\n- `page_ext_size`：每个页面对应的扩展数据总大小（含基础结构和各模块私有数据）\n- `total_usage`：已分配的页面扩展内存总量（字节）\n- `early_page_ext`：是否强制在早期（早于常规内存初始化）启用 page_ext（通过内核参数控制）\n\n### 主要函数\n- `invoke_need_callbacks()`：遍历所有注册的 `page_ext_ops`，调用其 `need()` 回调，决定是否分配内存并计算总大小\n- `invoke_init_callbacks()`：在 page_ext 内存分配完成后，调用各模块的 `init()` 回调进行初始化\n- `lookup_page_ext(const struct page *page)`：根据 `page` 指针查找对应的 `page_ext` 扩展数据结构（区分 FLATMEM/SPARSEMEM 实现）\n- `alloc_node_page_ext(int nid)`（FLATMEM）：为指定 NUMA 节点分配 page_ext 内存表\n- `page_ext_init_flatmem()` / `page_ext_init_flatmem_late()`（FLATMEM）：平坦内存模型下的初始化入口\n- `setup_early_page_ext()`：解析内核启动参数 `early_page_ext`\n\n## 3. 关键实现\n\n### 按需内存分配机制\n- 启动时调用 `invoke_need_callbacks()` 遍历所有注册的扩展模块。\n- 若任一模块的 `need()` 返回 `true`，则触发内存分配；否则完全跳过，零开销。\n- 对于声明 `need_shared_flags = true` 的模块（如 32 位下的 `PAGE_IDLE`），强制使用基础 `struct page_ext` 结构，确保标志位共享。\n\n### 内存布局与索引\n- 每个物理页对应一个 `page_ext` 条目，大小为 `page_ext_size`。\n- 条目按 PFN（Page Frame Number）顺序线性排列。\n- 在 FLATMEM 模型中，以节点起始 PFN 对齐到 `MAX_ORDER_NR_PAGES` 为基址，支持 buddy allocator 跨边界访问。\n- 在 SPARSEMEM 模型中，每个内存 section 独立维护 `page_ext` 数组，通过 `__pfn_to_section(pfn)` 定位。\n\n### 稀疏内存特殊处理\n- 定义 `PAGE_EXT_INVALID = 0x1` 标志位，用于标记未初始化的 section。\n- `lookup_page_ext()` 中通过低位掩码检查有效性，避免访问未分配内存。\n- 支持内存热插拔场景下动态分配 section 的 page_ext。\n\n### 早期初始化支持\n- 通过 `early_param(\"early_page_ext\", ...)` 支持内核参数强制提前初始化。\n- `CONFIG_MEM_ALLOC_PROFILING_DEBUG` 下默认启用，确保分配标签（如 task stack）不丢失。\n\n### 安全访问保障\n- `lookup_page_ext()` 中包含 `WARN_ON_ONCE(!rcu_read_lock_held())`，要求调用者持有 RCU 读锁，防止并发释放期间访问悬空指针。\n- 处理内存子系统早期初始化阶段（如 boot-time page free）可能触发的空指针访问，安全返回 `NULL`。\n\n## 4. 依赖关系\n\n### 编译依赖（Kconfig）\n- `CONFIG_PAGE_OWNER`：页面归属跟踪\n- `CONFIG_PAGE_IDLE_FLAG`：页面空闲标记（32 位架构）\n- `CONFIG_MEM_ALLOC_PROFILING`：内存分配打标（PGALLOC_TAG）\n- `CONFIG_PAGE_TABLE_CHECK`：页表一致性检查\n- `CONFIG_SPARSEMEM`：稀疏内存模型支持\n\n### 头文件依赖\n- `<linux/mm.h>` / `<linux/mmzone.h>`：内存管理核心结构\n- `<linux/memblock.h>`：启动阶段内存分配\n- `<linux/vmalloc.h>`：备用分配路径（未在当前片段体现）\n- `<linux/rcupdate.h>`：RCU 锁定语义\n- 各功能模块头文件（如 `page_owner.h`, `page_idle.h` 等）\n\n### 运行时依赖\n- 内存初始化流程（`memmap` 建立之后）\n- NUMA 节点信息（`NODE_DATA(nid)`）\n- 稀疏内存 section 管理（`__pfn_to_section`）\n\n## 5. 使用场景\n\n1. **调试与追踪**：\n   - `PAGE_OWNER`：记录每页的分配/释放调用栈，用于内存泄漏检测\n   - `PAGE_TABLE_CHECK`：验证页表映射一致性\n\n2. **性能分析**：\n   - `PAGE_IDLE`：标记长时间未访问的页面，供内存回收或迁移策略使用（32 位架构因地址空间限制需外部存储）\n\n3. **内存分配剖析**：\n   - `MEM_ALLOC_PROFILING`（PGALLOC_TAG）：为页面打上分配上下文标签，用于内存使用归因分析\n\n4. **内核自检**：\n   - 在 buddy allocator 释放路径中校验页面状态，需访问扩展数据\n\n5. **早期内存分配保障**：\n   - 当需要在常规内存子系统完全初始化前（如 early initcall 阶段）使用带标签的页面时，通过 `early_page_ext` 参数确保 page_ext 提前就绪",
      "similarity": 0.64028400182724,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/page_ext.c",
          "start_line": 69,
          "end_line": 170,
          "content": [
            "static bool need_page_idle(void)",
            "{",
            "\treturn true;",
            "}",
            "static int __init setup_early_page_ext(char *str)",
            "{",
            "\tearly_page_ext = true;",
            "\treturn 0;",
            "}",
            "static bool __init invoke_need_callbacks(void)",
            "{",
            "\tint i;",
            "\tint entries = ARRAY_SIZE(page_ext_ops);",
            "\tbool need = false;",
            "",
            "\tfor (i = 0; i < entries; i++) {",
            "\t\tif (page_ext_ops[i]->need()) {",
            "\t\t\tif (page_ext_ops[i]->need_shared_flags) {",
            "\t\t\t\tpage_ext_size = sizeof(struct page_ext);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "\tfor (i = 0; i < entries; i++) {",
            "\t\tif (page_ext_ops[i]->need()) {",
            "\t\t\tpage_ext_ops[i]->offset = page_ext_size;",
            "\t\t\tpage_ext_size += page_ext_ops[i]->size;",
            "\t\t\tneed = true;",
            "\t\t}",
            "\t}",
            "",
            "\treturn need;",
            "}",
            "static void __init invoke_init_callbacks(void)",
            "{",
            "\tint i;",
            "\tint entries = ARRAY_SIZE(page_ext_ops);",
            "",
            "\tfor (i = 0; i < entries; i++) {",
            "\t\tif (page_ext_ops[i]->init)",
            "\t\t\tpage_ext_ops[i]->init();",
            "\t}",
            "}",
            "void __init page_ext_init_flatmem_late(void)",
            "{",
            "\tinvoke_init_callbacks();",
            "}",
            "void __meminit pgdat_page_ext_init(struct pglist_data *pgdat)",
            "{",
            "\tpgdat->node_page_ext = NULL;",
            "}",
            "static int __init alloc_node_page_ext(int nid)",
            "{",
            "\tstruct page_ext *base;",
            "\tunsigned long table_size;",
            "\tunsigned long nr_pages;",
            "",
            "\tnr_pages = NODE_DATA(nid)->node_spanned_pages;",
            "\tif (!nr_pages)",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * Need extra space if node range is not aligned with",
            "\t * MAX_ORDER_NR_PAGES. When page allocator's buddy algorithm",
            "\t * checks buddy's status, range could be out of exact node range.",
            "\t */",
            "\tif (!IS_ALIGNED(node_start_pfn(nid), MAX_ORDER_NR_PAGES) ||",
            "\t\t!IS_ALIGNED(node_end_pfn(nid), MAX_ORDER_NR_PAGES))",
            "\t\tnr_pages += MAX_ORDER_NR_PAGES;",
            "",
            "\ttable_size = page_ext_size * nr_pages;",
            "",
            "\tbase = memblock_alloc_try_nid(",
            "\t\t\ttable_size, PAGE_SIZE, __pa(MAX_DMA_ADDRESS),",
            "\t\t\tMEMBLOCK_ALLOC_ACCESSIBLE, nid);",
            "\tif (!base)",
            "\t\treturn -ENOMEM;",
            "\tNODE_DATA(nid)->node_page_ext = base;",
            "\ttotal_usage += table_size;",
            "\treturn 0;",
            "}",
            "void __init page_ext_init_flatmem(void)",
            "{",
            "",
            "\tint nid, fail;",
            "",
            "\tif (!invoke_need_callbacks())",
            "\t\treturn;",
            "",
            "\tfor_each_online_node(nid)  {",
            "\t\tfail = alloc_node_page_ext(nid);",
            "\t\tif (fail)",
            "\t\t\tgoto fail;",
            "\t}",
            "\tpr_info(\"allocated %ld bytes of page_ext\\n\", total_usage);",
            "\treturn;",
            "",
            "fail:",
            "\tpr_crit(\"allocation of page_ext failed.\\n\");",
            "\tpanic(\"Out of memory\");",
            "}"
          ],
          "function_name": "need_page_idle, setup_early_page_ext, invoke_need_callbacks, invoke_init_callbacks, page_ext_init_flatmem_late, pgdat_page_ext_init, alloc_node_page_ext, page_ext_init_flatmem",
          "description": "实现页面扩展内存分配逻辑，包含need回调检查、早期扩展启用设置、初始化回调触发、节点级扩展内存分配及失败处理，通过遍历所有节点完成扩展内存表的创建与错误恢复。",
          "similarity": 0.5910553932189941
        },
        {
          "chunk_id": 0,
          "file_path": "mm/page_ext.c",
          "start_line": 1,
          "end_line": 68,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "#include <linux/mm.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/memblock.h>",
            "#include <linux/page_ext.h>",
            "#include <linux/memory.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/page_owner.h>",
            "#include <linux/page_idle.h>",
            "#include <linux/page_table_check.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/pgalloc_tag.h>",
            "",
            "/*",
            " * struct page extension",
            " *",
            " * This is the feature to manage memory for extended data per page.",
            " *",
            " * Until now, we must modify struct page itself to store extra data per page.",
            " * This requires rebuilding the kernel and it is really time consuming process.",
            " * And, sometimes, rebuild is impossible due to third party module dependency.",
            " * At last, enlarging struct page could cause un-wanted system behaviour change.",
            " *",
            " * This feature is intended to overcome above mentioned problems. This feature",
            " * allocates memory for extended data per page in certain place rather than",
            " * the struct page itself. This memory can be accessed by the accessor",
            " * functions provided by this code. During the boot process, it checks whether",
            " * allocation of huge chunk of memory is needed or not. If not, it avoids",
            " * allocating memory at all. With this advantage, we can include this feature",
            " * into the kernel in default and can avoid rebuild and solve related problems.",
            " *",
            " * To help these things to work well, there are two callbacks for clients. One",
            " * is the need callback which is mandatory if user wants to avoid useless",
            " * memory allocation at boot-time. The other is optional, init callback, which",
            " * is used to do proper initialization after memory is allocated.",
            " *",
            " * The need callback is used to decide whether extended memory allocation is",
            " * needed or not. Sometimes users want to deactivate some features in this",
            " * boot and extra memory would be unnecessary. In this case, to avoid",
            " * allocating huge chunk of memory, each clients represent their need of",
            " * extra memory through the need callback. If one of the need callbacks",
            " * returns true, it means that someone needs extra memory so that",
            " * page extension core should allocates memory for page extension. If",
            " * none of need callbacks return true, memory isn't needed at all in this boot",
            " * and page extension core can skip to allocate memory. As result,",
            " * none of memory is wasted.",
            " *",
            " * When need callback returns true, page_ext checks if there is a request for",
            " * extra memory through size in struct page_ext_operations. If it is non-zero,",
            " * extra space is allocated for each page_ext entry and offset is returned to",
            " * user through offset in struct page_ext_operations.",
            " *",
            " * The init callback is used to do proper initialization after page extension",
            " * is completely initialized. In sparse memory system, extra memory is",
            " * allocated some time later than memmap is allocated. In other words, lifetime",
            " * of memory for page extension isn't same with memmap for struct page.",
            " * Therefore, clients can't store extra data until page extension is",
            " * initialized, even if pages are allocated and used freely. This could",
            " * cause inadequate state of extra data per page, so, to prevent it, client",
            " * can utilize this callback to initialize the state of it correctly.",
            " */",
            "",
            "#ifdef CONFIG_SPARSEMEM",
            "#define PAGE_EXT_INVALID       (0x1)",
            "#endif",
            "",
            "#if defined(CONFIG_PAGE_IDLE_FLAG) && !defined(CONFIG_64BIT)"
          ],
          "function_name": null,
          "description": "定义了page extension机制，通过外部内存分配方式管理页扩展数据，提供need回调判断是否需要分配及init回调进行初始化，避免直接修改struct page结构体，支持动态内存分配决策以减少冗余开销。",
          "similarity": 0.5626739859580994
        },
        {
          "chunk_id": 2,
          "file_path": "mm/page_ext.c",
          "start_line": 242,
          "end_line": 359,
          "content": [
            "static bool page_ext_invalid(struct page_ext *page_ext)",
            "{",
            "\treturn !page_ext || (((unsigned long)page_ext & PAGE_EXT_INVALID) == PAGE_EXT_INVALID);",
            "}",
            "static int __meminit init_section_page_ext(unsigned long pfn, int nid)",
            "{",
            "\tstruct mem_section *section;",
            "\tstruct page_ext *base;",
            "\tunsigned long table_size;",
            "",
            "\tsection = __pfn_to_section(pfn);",
            "",
            "\tif (section->page_ext)",
            "\t\treturn 0;",
            "",
            "\ttable_size = page_ext_size * PAGES_PER_SECTION;",
            "\tbase = alloc_page_ext(table_size, nid);",
            "",
            "\t/*",
            "\t * The value stored in section->page_ext is (base - pfn)",
            "\t * and it does not point to the memory block allocated above,",
            "\t * causing kmemleak false positives.",
            "\t */",
            "\tkmemleak_not_leak(base);",
            "",
            "\tif (!base) {",
            "\t\tpr_err(\"page ext allocation failure\\n\");",
            "\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\t/*",
            "\t * The passed \"pfn\" may not be aligned to SECTION.  For the calculation",
            "\t * we need to apply a mask.",
            "\t */",
            "\tpfn &= PAGE_SECTION_MASK;",
            "\tsection->page_ext = (void *)base - page_ext_size * pfn;",
            "\ttotal_usage += table_size;",
            "\treturn 0;",
            "}",
            "static void free_page_ext(void *addr)",
            "{",
            "\tif (is_vmalloc_addr(addr)) {",
            "\t\tvfree(addr);",
            "\t} else {",
            "\t\tstruct page *page = virt_to_page(addr);",
            "\t\tsize_t table_size;",
            "",
            "\t\ttable_size = page_ext_size * PAGES_PER_SECTION;",
            "",
            "\t\tBUG_ON(PageReserved(page));",
            "\t\tkmemleak_free(addr);",
            "\t\tfree_pages_exact(addr, table_size);",
            "\t}",
            "}",
            "static void __free_page_ext(unsigned long pfn)",
            "{",
            "\tstruct mem_section *ms;",
            "\tstruct page_ext *base;",
            "",
            "\tms = __pfn_to_section(pfn);",
            "\tif (!ms || !ms->page_ext)",
            "\t\treturn;",
            "",
            "\tbase = READ_ONCE(ms->page_ext);",
            "\t/*",
            "\t * page_ext here can be valid while doing the roll back",
            "\t * operation in online_page_ext().",
            "\t */",
            "\tif (page_ext_invalid(base))",
            "\t\tbase = (void *)base - PAGE_EXT_INVALID;",
            "\tWRITE_ONCE(ms->page_ext, NULL);",
            "",
            "\tbase = get_entry(base, pfn);",
            "\tfree_page_ext(base);",
            "}",
            "static void __invalidate_page_ext(unsigned long pfn)",
            "{",
            "\tstruct mem_section *ms;",
            "\tvoid *val;",
            "",
            "\tms = __pfn_to_section(pfn);",
            "\tif (!ms || !ms->page_ext)",
            "\t\treturn;",
            "\tval = (void *)ms->page_ext + PAGE_EXT_INVALID;",
            "\tWRITE_ONCE(ms->page_ext, val);",
            "}",
            "static int __meminit online_page_ext(unsigned long start_pfn,",
            "\t\t\t\tunsigned long nr_pages,",
            "\t\t\t\tint nid)",
            "{",
            "\tunsigned long start, end, pfn;",
            "\tint fail = 0;",
            "",
            "\tstart = SECTION_ALIGN_DOWN(start_pfn);",
            "\tend = SECTION_ALIGN_UP(start_pfn + nr_pages);",
            "",
            "\tif (nid == NUMA_NO_NODE) {",
            "\t\t/*",
            "\t\t * In this case, \"nid\" already exists and contains valid memory.",
            "\t\t * \"start_pfn\" passed to us is a pfn which is an arg for",
            "\t\t * online__pages(), and start_pfn should exist.",
            "\t\t */",
            "\t\tnid = pfn_to_nid(start_pfn);",
            "\t\tVM_BUG_ON(!node_online(nid));",
            "\t}",
            "",
            "\tfor (pfn = start; !fail && pfn < end; pfn += PAGES_PER_SECTION)",
            "\t\tfail = init_section_page_ext(pfn, nid);",
            "\tif (!fail)",
            "\t\treturn 0;",
            "",
            "\t/* rollback */",
            "\tend = pfn - PAGES_PER_SECTION;",
            "\tfor (pfn = start; pfn < end; pfn += PAGES_PER_SECTION)",
            "\t\t__free_page_ext(pfn);",
            "",
            "\treturn -ENOMEM;",
            "}"
          ],
          "function_name": "page_ext_invalid, init_section_page_ext, free_page_ext, __free_page_ext, __invalidate_page_ext, online_page_ext",
          "description": "实现页面扩展内存的初始化、释放与无效化操作，包含针对内存段的扩展内存分配、基于虚拟地址的释放处理、无效化标记机制及分段式扩展内存的回收流程。",
          "similarity": 0.5231443643569946
        },
        {
          "chunk_id": 3,
          "file_path": "mm/page_ext.c",
          "start_line": 400,
          "end_line": 506,
          "content": [
            "static void __meminit offline_page_ext(unsigned long start_pfn,",
            "\t\t\t\tunsigned long nr_pages)",
            "{",
            "\tunsigned long start, end, pfn;",
            "",
            "\tstart = SECTION_ALIGN_DOWN(start_pfn);",
            "\tend = SECTION_ALIGN_UP(start_pfn + nr_pages);",
            "",
            "\t/*",
            "\t * Freeing of page_ext is done in 3 steps to avoid",
            "\t * use-after-free of it:",
            "\t * 1) Traverse all the sections and mark their page_ext",
            "\t *    as invalid.",
            "\t * 2) Wait for all the existing users of page_ext who",
            "\t *    started before invalidation to finish.",
            "\t * 3) Free the page_ext.",
            "\t */",
            "\tfor (pfn = start; pfn < end; pfn += PAGES_PER_SECTION)",
            "\t\t__invalidate_page_ext(pfn);",
            "",
            "\tsynchronize_rcu();",
            "",
            "\tfor (pfn = start; pfn < end; pfn += PAGES_PER_SECTION)",
            "\t\t__free_page_ext(pfn);",
            "}",
            "static int __meminit page_ext_callback(struct notifier_block *self,",
            "\t\t\t       unsigned long action, void *arg)",
            "{",
            "\tstruct memory_notify *mn = arg;",
            "\tint ret = 0;",
            "",
            "\tswitch (action) {",
            "\tcase MEM_GOING_ONLINE:",
            "\t\tret = online_page_ext(mn->start_pfn,",
            "\t\t\t\t   mn->nr_pages, mn->status_change_nid);",
            "\t\tbreak;",
            "\tcase MEM_OFFLINE:",
            "\t\toffline_page_ext(mn->start_pfn,",
            "\t\t\t\tmn->nr_pages);",
            "\t\tbreak;",
            "\tcase MEM_CANCEL_ONLINE:",
            "\t\toffline_page_ext(mn->start_pfn,",
            "\t\t\t\tmn->nr_pages);",
            "\t\tbreak;",
            "\tcase MEM_GOING_OFFLINE:",
            "\t\tbreak;",
            "\tcase MEM_ONLINE:",
            "\tcase MEM_CANCEL_OFFLINE:",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn notifier_from_errno(ret);",
            "}",
            "void __init page_ext_init(void)",
            "{",
            "\tunsigned long pfn;",
            "\tint nid;",
            "",
            "\tif (!invoke_need_callbacks())",
            "\t\treturn;",
            "",
            "\tfor_each_node_state(nid, N_MEMORY) {",
            "\t\tunsigned long start_pfn, end_pfn;",
            "",
            "\t\tstart_pfn = node_start_pfn(nid);",
            "\t\tend_pfn = node_end_pfn(nid);",
            "\t\t/*",
            "\t\t * start_pfn and end_pfn may not be aligned to SECTION and the",
            "\t\t * page->flags of out of node pages are not initialized.  So we",
            "\t\t * scan [start_pfn, the biggest section's pfn < end_pfn) here.",
            "\t\t */",
            "\t\tfor (pfn = start_pfn; pfn < end_pfn;",
            "\t\t\tpfn = ALIGN(pfn + 1, PAGES_PER_SECTION)) {",
            "",
            "\t\t\tif (!pfn_valid(pfn))",
            "\t\t\t\tcontinue;",
            "\t\t\t/*",
            "\t\t\t * Nodes's pfns can be overlapping.",
            "\t\t\t * We know some arch can have a nodes layout such as",
            "\t\t\t * -------------pfn-------------->",
            "\t\t\t * N0 | N1 | N2 | N0 | N1 | N2|....",
            "\t\t\t */",
            "\t\t\tif (pfn_to_nid(pfn) != nid)",
            "\t\t\t\tcontinue;",
            "\t\t\tif (init_section_page_ext(pfn, nid))",
            "\t\t\t\tgoto oom;",
            "\t\t\tcond_resched();",
            "\t\t}",
            "\t}",
            "\thotplug_memory_notifier(page_ext_callback, DEFAULT_CALLBACK_PRI);",
            "\tpr_info(\"allocated %ld bytes of page_ext\\n\", total_usage);",
            "\tinvoke_init_callbacks();",
            "\treturn;",
            "",
            "oom:",
            "\tpanic(\"Out of memory\");",
            "}",
            "void __meminit pgdat_page_ext_init(struct pglist_data *pgdat)",
            "{",
            "}",
            "void page_ext_put(struct page_ext *page_ext)",
            "{",
            "\tif (unlikely(!page_ext))",
            "\t\treturn;",
            "",
            "\trcu_read_unlock();",
            "}"
          ],
          "function_name": "offline_page_ext, page_ext_callback, page_ext_init, pgdat_page_ext_init, page_ext_put",
          "description": "实现内存状态变更回调处理及全局初始化，包含在线/离线事件响应、扩展内存的动态分配回收、内存热插拔通知注册及初始化回调执行，通过RCU机制保证并发安全。",
          "similarity": 0.4872869849205017
        }
      ]
    },
    {
      "source_file": "mm/page_table_check.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:06:25\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `page_table_check.c`\n\n---\n\n# page_table_check.c 技术文档\n\n## 1. 文件概述\n\n`page_table_check.c` 是 Linux 内核中用于检测和验证页表映射一致性的调试模块。该模块通过跟踪每个物理页面被匿名（anonymous）或文件（file-backed）方式映射的次数，确保页表操作（如设置或清除 PTE/PMD/PUD 条目）不会破坏内存管理的基本不变量。当检测到不一致（如计数器为负、混合映射类型等）时，会触发 `BUG_ON()` 导致内核崩溃，从而帮助开发者及早发现页表管理中的逻辑错误。\n\n该功能默认可通过 `CONFIG_PAGE_TABLE_CHECK_ENFORCED` 配置选项启用，并支持通过内核启动参数 `page_table_check=0/1` 动态控制。\n\n## 2. 核心功能\n\n### 数据结构\n\n- **`struct page_table_check`**  \n  每个物理页面关联的检查状态结构体，包含两个原子计数器：\n  - `anon_map_count`：记录该页面被匿名映射的次数。\n  - `file_map_count`：记录该页面被文件映射的次数。\n\n- **`page_table_check_ops`**  \n  `struct page_ext_operations` 类型的全局变量，用于将 `page_table_check` 结构集成到内核的 `page_ext` 扩展机制中，定义了大小、初始化条件、初始化函数等。\n\n- **`page_table_check_disabled`**  \n  静态分支键（`static_key`），用于在运行时高效地启用/禁用检查逻辑。默认为 `true`（即禁用），若启用则调用 `static_branch_disable()` 关闭该键以激活检查。\n\n### 主要函数\n\n- **`__page_table_check_zero()`**  \n  在页面分配或释放时调用，验证指定 order 范围内的所有页面的映射计数器均为零。\n\n- **`__page_table_check_pte_clear()` / `__page_table_check_pmd_clear()` / `__page_table_check_pud_clear()`**  \n  在清除用户页表项（PTE/PMD/PUD）时调用，减少对应物理页面的映射计数，并验证类型一致性。\n\n- **`__page_table_check_ptes_set()` / `__page_table_check_pmd_set()` / `__page_table_check_pud_set()`**  \n  在设置新的用户页表项时调用，先清除旧项（如有），再增加新项对应页面的映射计数，并进行类型和写权限检查。\n\n- **`__page_table_check_pte_clear_range()`**  \n  在释放整个 PMD 对应的 PTE 表时，遍历并清除所有 PTE 条目对应的页面计数。\n\n- **`page_table_check_pte_flags()` / `page_table_check_pmd_flags()`**  \n  检查页表项中的特殊标志位（如 `uffd_wp`）与写权限的一致性，防止非法组合。\n\n## 3. 关键实现\n\n### 映射类型互斥性检查\n- 每个物理页面只能属于**匿名页面**（如堆、栈、匿名 mmap）或**文件页面**（如文件 mmap、page cache），不能同时被两种方式映射。\n- 在 `page_table_check_set/clear` 中，通过 `PageAnon(page)` 判断页面类型，并确保另一类型的计数器始终为 0（`BUG_ON(atomic_read(...))`）。\n\n### 计数器边界检查\n- **清除操作**：调用 `atomic_dec_return()` 后检查结果是否 `< 0`，防止过度解除映射。\n- **设置操作**：\n  - 对于**文件页面**：仅检查计数器非负（实际应始终 ≥0）。\n  - 对于**匿名页面**：若为**可写映射**（`rw == true`），则限制 `anon_map_count` 最多为 1（即不允许同一匿名页面被多个进程以可写方式共享，除非是 COW 前的只读共享）。\n\n### 用户地址空间过滤\n- 所有检查函数均跳过 `init_mm`（内核地址空间），仅处理用户空间页表操作。\n- 使用 `pte_user_accessible_page()` 等宏判断页表项是否指向用户可访问的普通内存页面（排除特殊条目如 swap、hwpoison 等）。\n\n### Swap 条目写权限检查\n- 在设置包含 `uffd_wp`（用户故障委托写保护）标志的 swap PTE/PMD 时，通过 `swap_cached_writable()` 检查底层 swap 条目是否缓存了“可写”信息，若存在则报 `WARN_ON_ONCE`，因为 `uffd_wp` 要求页面不可写。\n\n### Page Extension 集成\n- 利用内核的 `page_ext` 机制为每个 `struct page` 附加 `page_table_check` 数据，避免修改核心 `struct page`。\n- 通过 `page_ext_get/put` 和 `page_ext_next` 安全地访问连续页面的扩展数据。\n\n## 4. 依赖关系\n\n- **`<linux/page_ext.h>`**：通过 `page_ext_operations` 机制集成到页面扩展框架。\n- **`<linux/mm.h>`**：使用核心内存管理 API，如 `pfn_to_page()`、`PageAnon()`、`PageSlab()` 等。\n- **`<linux/swap.h>` / `<linux/swapops.h>`**：处理 swap 页表项及其标志位（如 `is_swap_pte()`、`pte_to_swp_entry()`）。\n- **`<linux/kstrtox.h>`**：解析内核启动参数。\n- **页表操作宏**：依赖架构相关的页表操作宏（如 `pte_pfn()`、`pmd_write()` 等），这些由各架构的 `pgtable.h` 提供。\n- **`CONFIG_PAGE_TABLE_CHECK_ENFORCED`**：编译时配置选项，决定默认是否启用检查。\n\n## 5. 使用场景\n\n- **内核开发与调试**：在开发新内存管理功能（如新页表操作、COW 优化、大页处理）时，启用此模块可捕获页表操作中的逻辑错误。\n- **回归测试**：作为内核测试套件的一部分，确保页表修改不会破坏映射一致性。\n- **安全加固**（潜在）：虽然主要用于调试，但其强制的映射类型互斥性也可防止某些内存破坏漏洞的利用。\n- **启动参数控制**：系统管理员可在启动时通过 `page_table_check=1` 临时启用检查以诊断问题，或通过 `=0` 在已知兼容性问题的系统上禁用。",
      "similarity": 0.6385629773139954,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/page_table_check.c",
          "start_line": 27,
          "end_line": 128,
          "content": [
            "static int __init early_page_table_check_param(char *buf)",
            "{",
            "\treturn kstrtobool(buf, &__page_table_check_enabled);",
            "}",
            "static bool __init need_page_table_check(void)",
            "{",
            "\treturn __page_table_check_enabled;",
            "}",
            "static void __init init_page_table_check(void)",
            "{",
            "\tif (!__page_table_check_enabled)",
            "\t\treturn;",
            "\tstatic_branch_disable(&page_table_check_disabled);",
            "}",
            "static void page_table_check_clear(unsigned long pfn, unsigned long pgcnt)",
            "{",
            "\tstruct page_ext *page_ext;",
            "\tstruct page *page;",
            "\tunsigned long i;",
            "\tbool anon;",
            "",
            "\tif (!pfn_valid(pfn))",
            "\t\treturn;",
            "",
            "\tpage = pfn_to_page(pfn);",
            "\tpage_ext = page_ext_get(page);",
            "",
            "\tif (!page_ext)",
            "\t\treturn;",
            "",
            "\tBUG_ON(PageSlab(page));",
            "\tanon = PageAnon(page);",
            "",
            "\tfor (i = 0; i < pgcnt; i++) {",
            "\t\tstruct page_table_check *ptc = get_page_table_check(page_ext);",
            "",
            "\t\tif (anon) {",
            "\t\t\tBUG_ON(atomic_read(&ptc->file_map_count));",
            "\t\t\tBUG_ON(atomic_dec_return(&ptc->anon_map_count) < 0);",
            "\t\t} else {",
            "\t\t\tBUG_ON(atomic_read(&ptc->anon_map_count));",
            "\t\t\tBUG_ON(atomic_dec_return(&ptc->file_map_count) < 0);",
            "\t\t}",
            "\t\tpage_ext = page_ext_next(page_ext);",
            "\t}",
            "\tpage_ext_put(page_ext);",
            "}",
            "static void page_table_check_set(unsigned long pfn, unsigned long pgcnt,",
            "\t\t\t\t bool rw)",
            "{",
            "\tstruct page_ext *page_ext;",
            "\tstruct page *page;",
            "\tunsigned long i;",
            "\tbool anon;",
            "",
            "\tif (!pfn_valid(pfn))",
            "\t\treturn;",
            "",
            "\tpage = pfn_to_page(pfn);",
            "\tpage_ext = page_ext_get(page);",
            "",
            "\tif (!page_ext)",
            "\t\treturn;",
            "",
            "\tBUG_ON(PageSlab(page));",
            "\tanon = PageAnon(page);",
            "",
            "\tfor (i = 0; i < pgcnt; i++) {",
            "\t\tstruct page_table_check *ptc = get_page_table_check(page_ext);",
            "",
            "\t\tif (anon) {",
            "\t\t\tBUG_ON(atomic_read(&ptc->file_map_count));",
            "\t\t\tBUG_ON(atomic_inc_return(&ptc->anon_map_count) > 1 && rw);",
            "\t\t} else {",
            "\t\t\tBUG_ON(atomic_read(&ptc->anon_map_count));",
            "\t\t\tBUG_ON(atomic_inc_return(&ptc->file_map_count) < 0);",
            "\t\t}",
            "\t\tpage_ext = page_ext_next(page_ext);",
            "\t}",
            "\tpage_ext_put(page_ext);",
            "}",
            "void __page_table_check_zero(struct page *page, unsigned int order)",
            "{",
            "\tstruct page_ext *page_ext;",
            "\tunsigned long i;",
            "",
            "\tBUG_ON(PageSlab(page));",
            "",
            "\tpage_ext = page_ext_get(page);",
            "",
            "\tif (!page_ext)",
            "\t\treturn;",
            "",
            "\tfor (i = 0; i < (1ul << order); i++) {",
            "\t\tstruct page_table_check *ptc = get_page_table_check(page_ext);",
            "",
            "\t\tBUG_ON(atomic_read(&ptc->anon_map_count));",
            "\t\tBUG_ON(atomic_read(&ptc->file_map_count));",
            "\t\tpage_ext = page_ext_next(page_ext);",
            "\t}",
            "\tpage_ext_put(page_ext);",
            "}"
          ],
          "function_name": "early_page_table_check_param, need_page_table_check, init_page_table_check, page_table_check_clear, page_table_check_set, __page_table_check_zero",
          "description": "实现页表检查的初始化参数解析、启用判断及核心计数器操作，通过原子操作管理页面映射计数，在页面释放时验证计数一致性",
          "similarity": 0.6045687794685364
        },
        {
          "chunk_id": 0,
          "file_path": "mm/page_table_check.c",
          "start_line": 1,
          "end_line": 26,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "",
            "/*",
            " * Copyright (c) 2021, Google LLC.",
            " * Pasha Tatashin <pasha.tatashin@soleen.com>",
            " */",
            "#include <linux/kstrtox.h>",
            "#include <linux/mm.h>",
            "#include <linux/page_table_check.h>",
            "#include <linux/swap.h>",
            "#include <linux/swapops.h>",
            "",
            "#undef pr_fmt",
            "#define pr_fmt(fmt)\t\"page_table_check: \" fmt",
            "",
            "struct page_table_check {",
            "\tatomic_t anon_map_count;",
            "\tatomic_t file_map_count;",
            "};",
            "",
            "static bool __page_table_check_enabled __initdata =",
            "\t\t\t\tIS_ENABLED(CONFIG_PAGE_TABLE_CHECK_ENFORCED);",
            "",
            "DEFINE_STATIC_KEY_TRUE(page_table_check_disabled);",
            "EXPORT_SYMBOL(page_table_check_disabled);",
            ""
          ],
          "function_name": null,
          "description": "定义page_table_check结构体，包含匿名和文件映射计数器，通过静态键控制检查状态，用于跟踪页表检查启用情况",
          "similarity": 0.556578516960144
        },
        {
          "chunk_id": 2,
          "file_path": "mm/page_table_check.c",
          "start_line": 163,
          "end_line": 269,
          "content": [
            "void __page_table_check_pte_clear(struct mm_struct *mm, pte_t pte)",
            "{",
            "\tif (&init_mm == mm)",
            "\t\treturn;",
            "",
            "\tif (pte_user_accessible_page(pte)) {",
            "\t\tpage_table_check_clear(pte_pfn(pte), PAGE_SIZE >> PAGE_SHIFT);",
            "\t}",
            "}",
            "void __page_table_check_pmd_clear(struct mm_struct *mm, pmd_t pmd)",
            "{",
            "\tif (&init_mm == mm)",
            "\t\treturn;",
            "",
            "\tif (pmd_user_accessible_page(pmd)) {",
            "\t\tpage_table_check_clear(pmd_pfn(pmd), PMD_SIZE >> PAGE_SHIFT);",
            "\t}",
            "}",
            "void __page_table_check_pud_clear(struct mm_struct *mm, pud_t pud)",
            "{",
            "\tif (&init_mm == mm)",
            "\t\treturn;",
            "",
            "\tif (pud_user_accessible_page(pud)) {",
            "\t\tpage_table_check_clear(pud_pfn(pud), PUD_SIZE >> PAGE_SHIFT);",
            "\t}",
            "}",
            "static inline bool swap_cached_writable(swp_entry_t entry)",
            "{",
            "\treturn is_writable_device_exclusive_entry(entry) ||",
            "\t    is_writable_device_private_entry(entry) ||",
            "\t    is_writable_migration_entry(entry);",
            "}",
            "static inline void page_table_check_pte_flags(pte_t pte)",
            "{",
            "\tif (pte_present(pte) && pte_uffd_wp(pte))",
            "\t\tWARN_ON_ONCE(pte_write(pte));",
            "\telse if (is_swap_pte(pte) && pte_swp_uffd_wp(pte))",
            "\t\tWARN_ON_ONCE(swap_cached_writable(pte_to_swp_entry(pte)));",
            "}",
            "void __page_table_check_ptes_set(struct mm_struct *mm, pte_t *ptep, pte_t pte,",
            "\t\tunsigned int nr)",
            "{",
            "\tunsigned int i;",
            "",
            "\tif (&init_mm == mm)",
            "\t\treturn;",
            "",
            "\tpage_table_check_pte_flags(pte);",
            "",
            "\tfor (i = 0; i < nr; i++)",
            "\t\t__page_table_check_pte_clear(mm, ptep_get(ptep + i));",
            "\tif (pte_user_accessible_page(pte))",
            "\t\tpage_table_check_set(pte_pfn(pte), nr, pte_write(pte));",
            "}",
            "static inline void page_table_check_pmd_flags(pmd_t pmd)",
            "{",
            "\tif (pmd_present(pmd) && pmd_uffd_wp(pmd))",
            "\t\tWARN_ON_ONCE(pmd_write(pmd));",
            "\telse if (is_swap_pmd(pmd) && pmd_swp_uffd_wp(pmd))",
            "\t\tWARN_ON_ONCE(swap_cached_writable(pmd_to_swp_entry(pmd)));",
            "}",
            "void __page_table_check_pmd_set(struct mm_struct *mm, pmd_t *pmdp, pmd_t pmd)",
            "{",
            "\tif (&init_mm == mm)",
            "\t\treturn;",
            "",
            "\tpage_table_check_pmd_flags(pmd);",
            "",
            "\t__page_table_check_pmd_clear(mm, *pmdp);",
            "\tif (pmd_user_accessible_page(pmd)) {",
            "\t\tpage_table_check_set(pmd_pfn(pmd), PMD_SIZE >> PAGE_SHIFT,",
            "\t\t\t\t     pmd_write(pmd));",
            "\t}",
            "}",
            "void __page_table_check_pud_set(struct mm_struct *mm, pud_t *pudp, pud_t pud)",
            "{",
            "\tif (&init_mm == mm)",
            "\t\treturn;",
            "",
            "\t__page_table_check_pud_clear(mm, *pudp);",
            "\tif (pud_user_accessible_page(pud)) {",
            "\t\tpage_table_check_set(pud_pfn(pud), PUD_SIZE >> PAGE_SHIFT,",
            "\t\t\t\t     pud_write(pud));",
            "\t}",
            "}",
            "void __page_table_check_pte_clear_range(struct mm_struct *mm,",
            "\t\t\t\t\tunsigned long addr,",
            "\t\t\t\t\tpmd_t pmd)",
            "{",
            "\tif (&init_mm == mm)",
            "\t\treturn;",
            "",
            "\tif (!pmd_bad(pmd) && !pmd_leaf(pmd)) {",
            "\t\tpte_t *ptep = pte_offset_map(&pmd, addr);",
            "\t\tunsigned long i;",
            "",
            "\t\tif (WARN_ON(!ptep))",
            "\t\t\treturn;",
            "\t\tfor (i = 0; i < PTRS_PER_PTE; i++) {",
            "\t\t\t__page_table_check_pte_clear(mm, ptep_get(ptep));",
            "\t\t\taddr += PAGE_SIZE;",
            "\t\t\tptep++;",
            "\t\t}",
            "\t\tpte_unmap(ptep - PTRS_PER_PTE);",
            "\t}",
            "}"
          ],
          "function_name": "__page_table_check_pte_clear, __page_table_check_pmd_clear, __page_table_check_pud_clear, swap_cached_writable, page_table_check_pte_flags, __page_table_check_ptes_set, page_table_check_pmd_flags, __page_table_check_pmd_set, __page_table_check_pud_set, __page_table_check_pte_clear_range",
          "description": "集成到页表操作回调中，在pte/pmd/pud清除时触发检查，验证用户访问权限和交换缓存可写性，确保页表状态与物理页面计数匹配",
          "similarity": 0.5552241206169128
        }
      ]
    }
  ]
}