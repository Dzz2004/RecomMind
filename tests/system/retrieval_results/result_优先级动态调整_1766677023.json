{
  "query": "优先级动态调整",
  "timestamp": "2025-12-25 23:37:03",
  "retrieved_files": [
    {
      "source_file": "kernel/sched/syscalls.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:19:13\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\syscalls.c`\n\n---\n\n# `sched/syscalls.c` 技术文档\n\n## 1. 文件概述\n\n`sched/syscalls.c` 是 Linux 内核调度子系统的核心源文件之一，主要负责实现与调度相关的系统调用接口和优先级管理逻辑。该文件封装了任务优先级计算、nice 值设置、CPU 空闲状态判断等关键功能，为用户空间提供 `nice()` 等系统调用的内核支持，并为调度器内部模块提供优先级操作原语。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `__normal_prio()`：根据调度策略（SCHED_NORMAL/SCHED_BATCH/SCHED_IDLE、SCHED_FIFO/SCHED_RR、SCHED_DEADLINE）计算任务的“正常”优先级。\n- `normal_prio()`：基于任务当前策略、实时优先级和静态 nice 值计算其正常优先级。\n- `effective_prio()`：计算任务当前实际生效的调度优先级，考虑 RT 继承或提升。\n- `set_user_nice()`：安全地修改指定任务的 nice 值，更新其静态优先级和调度权重，并触发调度器重评估。\n- `is_nice_reduction()` / `can_nice()`：检查任务是否具备降低 nice 值（即提高优先级）的权限。\n- `sys_nice()`：实现 `nice(2)` 系统调用，允许当前进程调整自身优先级。\n- `task_prio()`：返回任务在 `/proc` 中对外暴露的用户可见优先级值。\n- `idle_cpu()` / `available_idle_cpu()`：判断指定 CPU 是否处于空闲状态。\n- `idle_task()`：获取指定 CPU 的 idle 任务结构体。\n- `update_other_load_avgs()`（SMP）：更新除 CFS 外其他调度类（RT、DL、IRQ）的负载平均值。\n- `effective_cpu_util()`（SMP）：计算 CPU 的有效利用率，用于频率调节（如 CPUFreq）。\n\n### 关键数据结构\n- 无独立定义的数据结构，主要操作 `struct task_struct` 和 `struct rq`（运行队列）。\n\n## 3. 关键实现\n\n### 优先级计算模型\n- **优先级映射**：\n  - 用户态 nice 值范围 `[-20, 19]` 映射到内核静态优先级 `[100, 139]`（通过 `NICE_TO_PRIO`）。\n  - 实时任务（RT/DL）使用 `[0, 99]` 的高优先级范围（`MAX_RT_PRIO = 100`）。\n  - `task_prio()` 返回值将内核优先级转换为用户可见格式：普通任务为 `[0,39]`，RT 任务为 `[-2,-100]`，DL 任务为 `-101`。\n- **有效优先级**：`effective_prio()` 区分“正常优先级”与“被提升的优先级”。若任务当前优先级为 RT/DL（即 `rt_or_dl_prio(p->prio)` 为真），则保留提升后的值；否则使用 `normal_prio`。\n\n### Nice 值修改安全机制\n- `set_user_nice()` 在修改 nice 值前：\n  1. 获取任务所在 CPU 的运行队列锁（`task_rq_lock`），防止并发调度。\n  2. 对 RT/DL 任务仅更新 `static_prio`（不影响调度行为）。\n  3. 对普通任务，先从运行队列中移除（若已入队或正在运行），更新 `static_prio` 和负载权重（`set_load_weight`），重新计算 `prio`，再重新入队。\n  4. 调用调度类的 `prio_changed` 回调，通知调度器优先级变更。\n\n### 权限控制\n- `can_nice()` 结合资源限制（`RLIMIT_NICE`）和特权（`CAP_SYS_NICE`）判断是否允许降低 nice 值（提高优先级）。\n- `nice_to_rlimit()` 将 nice 值 `[19,-20]` 转换为 rlimit 格式 `[1,40]` 以匹配 `RLIMIT_NICE` 的语义。\n\n### CPU 空闲判断\n- `idle_cpu()` 检查：\n  - 当前运行任务是否为 idle 任务。\n  - 运行队列中无其他可运行任务（`nr_running == 0`）。\n  - （SMP）无待处理的远程唤醒（`ttwu_pending == 0`）。\n- `available_idle_cpu()` 额外检查虚拟化场景下 CPU 是否被抢占（`vcpu_is_preempted`）。\n\n### 负载与利用率计算（SMP）\n- `update_other_load_avgs()` 周期性更新 RT、DL、IRQ 和硬件压力的负载平均值。\n- `effective_cpu_util()` 聚合 CFS、RT、DL、IRQ 的利用率，并考虑 DL 带宽预留，输出用于 CPU 频率调节的有效利用率。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/sched.h>`：核心调度数据结构和 API。\n  - `<linux/cpuset.h>`：CPU 亲和性相关（间接影响调度）。\n  - `\"sched.h\"`（本地）：调度器内部实现细节。\n  - `\"autogroup.h\"`：自动任务分组支持。\n- **调度类依赖**：\n  - 调用各调度类（CFS、RT、DL）的回调函数（如 `prio_changed`、`enqueue_task` 等）。\n- **安全模块**：调用 LSM 钩子 `security_task_setnice()`。\n- **架构相关**：\n  - `arch_scale_cpu_capacity()` / `arch_scale_hw_pressure()`：架构特定的 CPU 容量和硬件压力缩放。\n  - `__ARCH_WANT_SYS_NICE`：控制 `sys_nice` 是否编译进内核。\n\n## 5. 使用场景\n\n- **系统调用处理**：为 `nice(2)` 系统调用提供内核实现，允许用户进程动态调整自身优先级。\n- **调度器内部操作**：\n  - 在 `fork()`、`sched_setscheduler()` 等操作中计算任务优先级。\n  - 调度类在任务入队/出队时更新优先级和负载。\n- **资源监控与管理**：\n  - `/proc/[pid]/stat` 中的优先级字段通过 `task_prio()` 获取。\n  - 负载均衡器和 CPUFreq 驱动使用 `effective_cpu_util()` 获取 CPU 利用率。\n- **空闲检测**：\n  - 负载均衡、任务迁移、节能策略（如 cpuidle）依赖 `idle_cpu()` 和 `available_idle_cpu()` 判断 CPU 状态。\n- **权限控制**：在设置优先级时执行安全检查，防止非特权进程提升调度优先级。",
      "similarity": 0.5891244411468506,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 19,
          "end_line": 130,
          "content": [
            "static inline int __normal_prio(int policy, int rt_prio, int nice)",
            "{",
            "\tint prio;",
            "",
            "\tif (dl_policy(policy))",
            "\t\tprio = MAX_DL_PRIO - 1;",
            "\telse if (rt_policy(policy))",
            "\t\tprio = MAX_RT_PRIO - 1 - rt_prio;",
            "\telse",
            "\t\tprio = NICE_TO_PRIO(nice);",
            "",
            "\treturn prio;",
            "}",
            "static inline int normal_prio(struct task_struct *p)",
            "{",
            "\treturn __normal_prio(p->policy, p->rt_priority, PRIO_TO_NICE(p->static_prio));",
            "}",
            "static int effective_prio(struct task_struct *p)",
            "{",
            "\tp->normal_prio = normal_prio(p);",
            "\t/*",
            "\t * If we are RT tasks or we were boosted to RT priority,",
            "\t * keep the priority unchanged. Otherwise, update priority",
            "\t * to the normal priority:",
            "\t */",
            "\tif (!rt_or_dl_prio(p->prio))",
            "\t\treturn p->normal_prio;",
            "\treturn p->prio;",
            "}",
            "void set_user_nice(struct task_struct *p, long nice)",
            "{",
            "\tbool queued, running;",
            "\tstruct rq *rq;",
            "\tint old_prio;",
            "",
            "\tif (task_nice(p) == nice || nice < MIN_NICE || nice > MAX_NICE)",
            "\t\treturn;",
            "\t/*",
            "\t * We have to be careful, if called from sys_setpriority(),",
            "\t * the task might be in the middle of scheduling on another CPU.",
            "\t */",
            "\tCLASS(task_rq_lock, rq_guard)(p);",
            "\trq = rq_guard.rq;",
            "",
            "\tupdate_rq_clock(rq);",
            "",
            "\t/*",
            "\t * The RT priorities are set via sched_setscheduler(), but we still",
            "\t * allow the 'normal' nice value to be set - but as expected",
            "\t * it won't have any effect on scheduling until the task is",
            "\t * SCHED_DEADLINE, SCHED_FIFO or SCHED_RR:",
            "\t */",
            "\tif (task_has_dl_policy(p) || task_has_rt_policy(p)) {",
            "\t\tp->static_prio = NICE_TO_PRIO(nice);",
            "\t\treturn;",
            "\t}",
            "",
            "\tqueued = task_on_rq_queued(p);",
            "\trunning = task_current(rq, p);",
            "\tif (queued)",
            "\t\tdequeue_task(rq, p, DEQUEUE_SAVE | DEQUEUE_NOCLOCK);",
            "\tif (running)",
            "\t\tput_prev_task(rq, p);",
            "",
            "\tp->static_prio = NICE_TO_PRIO(nice);",
            "\tset_load_weight(p, true);",
            "\told_prio = p->prio;",
            "\tp->prio = effective_prio(p);",
            "",
            "\tif (queued)",
            "\t\tenqueue_task(rq, p, ENQUEUE_RESTORE | ENQUEUE_NOCLOCK);",
            "\tif (running)",
            "\t\tset_next_task(rq, p);",
            "",
            "\t/*",
            "\t * If the task increased its priority or is running and",
            "\t * lowered its priority, then reschedule its CPU:",
            "\t */",
            "\tp->sched_class->prio_changed(rq, p, old_prio);",
            "}",
            "static bool is_nice_reduction(const struct task_struct *p, const int nice)",
            "{",
            "\t/* Convert nice value [19,-20] to rlimit style value [1,40]: */",
            "\tint nice_rlim = nice_to_rlimit(nice);",
            "",
            "\treturn (nice_rlim <= task_rlimit(p, RLIMIT_NICE));",
            "}",
            "int can_nice(const struct task_struct *p, const int nice)",
            "{",
            "\treturn is_nice_reduction(p, nice) || capable(CAP_SYS_NICE);",
            "}",
            "int task_prio(const struct task_struct *p)",
            "{",
            "\treturn p->prio - MAX_RT_PRIO;",
            "}",
            "int idle_cpu(int cpu)",
            "{",
            "\tstruct rq *rq = cpu_rq(cpu);",
            "",
            "\tif (rq->curr != rq->idle)",
            "\t\treturn 0;",
            "",
            "\tif (rq->nr_running)",
            "\t\treturn 0;",
            "",
            "#ifdef CONFIG_SMP",
            "\tif (rq->ttwu_pending)",
            "\t\treturn 0;",
            "#endif",
            "",
            "\treturn 1;",
            "}"
          ],
          "function_name": "__normal_prio, normal_prio, effective_prio, set_user_nice, is_nice_reduction, can_nice, task_prio, idle_cpu",
          "description": "实现优先级计算与调整逻辑，包含正常优先级计算、有效优先级判定、用户nice值修改、优先级变化检测及实时任务优先级处理等功能",
          "similarity": 0.7173407077789307
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 531,
          "end_line": 634,
          "content": [
            "static void __setscheduler_uclamp(struct task_struct *p,",
            "\t\t\t\t  const struct sched_attr *attr)",
            "{",
            "\tenum uclamp_id clamp_id;",
            "",
            "\tfor_each_clamp_id(clamp_id) {",
            "\t\tstruct uclamp_se *uc_se = &p->uclamp_req[clamp_id];",
            "\t\tunsigned int value;",
            "",
            "\t\tif (!uclamp_reset(attr, clamp_id, uc_se))",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * RT by default have a 100% boost value that could be modified",
            "\t\t * at runtime.",
            "\t\t */",
            "\t\tif (unlikely(rt_task(p) && clamp_id == UCLAMP_MIN))",
            "\t\t\tvalue = sysctl_sched_uclamp_util_min_rt_default;",
            "\t\telse",
            "\t\t\tvalue = uclamp_none(clamp_id);",
            "",
            "\t\tuclamp_se_set(uc_se, value, false);",
            "",
            "\t}",
            "",
            "\tif (likely(!(attr->sched_flags & SCHED_FLAG_UTIL_CLAMP)))",
            "\t\treturn;",
            "",
            "\tif (attr->sched_flags & SCHED_FLAG_UTIL_CLAMP_MIN &&",
            "\t    attr->sched_util_min != -1) {",
            "\t\tuclamp_se_set(&p->uclamp_req[UCLAMP_MIN],",
            "\t\t\t      attr->sched_util_min, true);",
            "\t}",
            "",
            "\tif (attr->sched_flags & SCHED_FLAG_UTIL_CLAMP_MAX &&",
            "\t    attr->sched_util_max != -1) {",
            "\t\tuclamp_se_set(&p->uclamp_req[UCLAMP_MAX],",
            "\t\t\t      attr->sched_util_max, true);",
            "\t}",
            "}",
            "static inline int uclamp_validate(struct task_struct *p,",
            "\t\t\t\t  const struct sched_attr *attr)",
            "{",
            "\treturn -EOPNOTSUPP;",
            "}",
            "static void __setscheduler_uclamp(struct task_struct *p,",
            "\t\t\t\t  const struct sched_attr *attr) { }",
            "static int user_check_sched_setscheduler(struct task_struct *p,",
            "\t\t\t\t\t const struct sched_attr *attr,",
            "\t\t\t\t\t int policy, int reset_on_fork)",
            "{",
            "\tif (fair_policy(policy)) {",
            "\t\tif (attr->sched_nice < task_nice(p) &&",
            "\t\t    !is_nice_reduction(p, attr->sched_nice))",
            "\t\t\tgoto req_priv;",
            "\t}",
            "",
            "\tif (rt_policy(policy)) {",
            "\t\tunsigned long rlim_rtprio = task_rlimit(p, RLIMIT_RTPRIO);",
            "",
            "\t\t/* Can't set/change the rt policy: */",
            "\t\tif (policy != p->policy && !rlim_rtprio)",
            "\t\t\tgoto req_priv;",
            "",
            "\t\t/* Can't increase priority: */",
            "\t\tif (attr->sched_priority > p->rt_priority &&",
            "\t\t    attr->sched_priority > rlim_rtprio)",
            "\t\t\tgoto req_priv;",
            "\t}",
            "",
            "\t/*",
            "\t * Can't set/change SCHED_DEADLINE policy at all for now",
            "\t * (safest behavior); in the future we would like to allow",
            "\t * unprivileged DL tasks to increase their relative deadline",
            "\t * or reduce their runtime (both ways reducing utilization)",
            "\t */",
            "\tif (dl_policy(policy))",
            "\t\tgoto req_priv;",
            "",
            "\t/*",
            "\t * Treat SCHED_IDLE as nice 20. Only allow a switch to",
            "\t * SCHED_NORMAL if the RLIMIT_NICE would normally permit it.",
            "\t */",
            "\tif (task_has_idle_policy(p) && !idle_policy(policy)) {",
            "\t\tif (!is_nice_reduction(p, task_nice(p)))",
            "\t\t\tgoto req_priv;",
            "\t}",
            "",
            "\t/* Can't change other user's priorities: */",
            "\tif (!check_same_owner(p))",
            "\t\tgoto req_priv;",
            "",
            "\t/* Normal users shall not reset the sched_reset_on_fork flag: */",
            "\tif (p->sched_reset_on_fork && !reset_on_fork)",
            "\t\tgoto req_priv;",
            "",
            "\treturn 0;",
            "",
            "req_priv:",
            "\tif (!capable(CAP_SYS_NICE))",
            "\t\treturn -EPERM;",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "__setscheduler_uclamp, uclamp_validate, __setscheduler_uclamp, user_check_sched_setscheduler",
          "description": "管理uclamp参数设置与验证，实现调度策略变更权限检查，包含实时任务优先级限制、SCHED_DEADLINE策略限制及跨用户优先级修改控制",
          "similarity": 0.6245436072349548
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 646,
          "end_line": 887,
          "content": [
            "int __sched_setscheduler(struct task_struct *p,",
            "\t\t\t const struct sched_attr *attr,",
            "\t\t\t bool user, bool pi)",
            "{",
            "\tint oldpolicy = -1, policy = attr->sched_policy;",
            "\tint retval, oldprio, newprio, queued, running;",
            "\tconst struct sched_class *prev_class, *next_class;",
            "\tstruct balance_callback *head;",
            "\tstruct rq_flags rf;",
            "\tint reset_on_fork;",
            "\tint queue_flags = DEQUEUE_SAVE | DEQUEUE_MOVE | DEQUEUE_NOCLOCK;",
            "\tstruct rq *rq;",
            "\tbool cpuset_locked = false;",
            "",
            "\t/* The pi code expects interrupts enabled */",
            "\tBUG_ON(pi && in_interrupt());",
            "recheck:",
            "\t/* Double check policy once rq lock held: */",
            "\tif (policy < 0) {",
            "\t\treset_on_fork = p->sched_reset_on_fork;",
            "\t\tpolicy = oldpolicy = p->policy;",
            "\t} else {",
            "\t\treset_on_fork = !!(attr->sched_flags & SCHED_FLAG_RESET_ON_FORK);",
            "",
            "\t\tif (!valid_policy(policy))",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tif (attr->sched_flags & ~(SCHED_FLAG_ALL | SCHED_FLAG_SUGOV))",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * Valid priorities for SCHED_FIFO and SCHED_RR are",
            "\t * 1..MAX_RT_PRIO-1, valid priority for SCHED_NORMAL,",
            "\t * SCHED_BATCH and SCHED_IDLE is 0.",
            "\t */",
            "\tif (attr->sched_priority > MAX_RT_PRIO-1)",
            "\t\treturn -EINVAL;",
            "\tif ((dl_policy(policy) && !__checkparam_dl(attr)) ||",
            "\t    (rt_policy(policy) != (attr->sched_priority != 0)))",
            "\t\treturn -EINVAL;",
            "",
            "\tif (user) {",
            "\t\tretval = user_check_sched_setscheduler(p, attr, policy, reset_on_fork);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "",
            "\t\tif (attr->sched_flags & SCHED_FLAG_SUGOV)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\tretval = security_task_setscheduler(p);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "\t}",
            "",
            "\t/* Update task specific \"requested\" clamps */",
            "\tif (attr->sched_flags & SCHED_FLAG_UTIL_CLAMP) {",
            "\t\tretval = uclamp_validate(p, attr);",
            "\t\tif (retval)",
            "\t\t\treturn retval;",
            "\t}",
            "",
            "\t/*",
            "\t * SCHED_DEADLINE bandwidth accounting relies on stable cpusets",
            "\t * information.",
            "\t */",
            "\tif (dl_policy(policy) || dl_policy(p->policy)) {",
            "\t\tcpuset_locked = true;",
            "\t\tcpuset_lock();",
            "\t}",
            "",
            "\t/*",
            "\t * Make sure no PI-waiters arrive (or leave) while we are",
            "\t * changing the priority of the task:",
            "\t *",
            "\t * To be able to change p->policy safely, the appropriate",
            "\t * runqueue lock must be held.",
            "\t */",
            "\trq = task_rq_lock(p, &rf);",
            "\tupdate_rq_clock(rq);",
            "",
            "\t/*",
            "\t * Changing the policy of the stop threads its a very bad idea:",
            "\t */",
            "\tif (p == rq->stop) {",
            "\t\tretval = -EINVAL;",
            "\t\tgoto unlock;",
            "\t}",
            "",
            "\tretval = scx_check_setscheduler(p, policy);",
            "\tif (retval)",
            "\t\tgoto unlock;",
            "",
            "\t/*",
            "\t * If not changing anything there's no need to proceed further,",
            "\t * but store a possible modification of reset_on_fork.",
            "\t */",
            "\tif (unlikely(policy == p->policy)) {",
            "\t\tif (fair_policy(policy) &&",
            "\t\t    (attr->sched_nice != task_nice(p) ||",
            "\t\t     (attr->sched_runtime != p->se.slice)))",
            "\t\t\tgoto change;",
            "\t\tif (rt_policy(policy) && attr->sched_priority != p->rt_priority)",
            "\t\t\tgoto change;",
            "\t\tif (dl_policy(policy) && dl_param_changed(p, attr))",
            "\t\t\tgoto change;",
            "\t\tif (attr->sched_flags & SCHED_FLAG_UTIL_CLAMP)",
            "\t\t\tgoto change;",
            "",
            "\t\tp->sched_reset_on_fork = reset_on_fork;",
            "\t\tretval = 0;",
            "\t\tgoto unlock;",
            "\t}",
            "change:",
            "",
            "\tif (user) {",
            "#ifdef CONFIG_RT_GROUP_SCHED",
            "\t\t/*",
            "\t\t * Do not allow realtime tasks into groups that have no runtime",
            "\t\t * assigned.",
            "\t\t */",
            "\t\tif (rt_bandwidth_enabled() && rt_policy(policy) &&",
            "\t\t\t\ttask_group(p)->rt_bandwidth.rt_runtime == 0 &&",
            "\t\t\t\t!task_group_is_autogroup(task_group(p))) {",
            "\t\t\tretval = -EPERM;",
            "\t\t\tgoto unlock;",
            "\t\t}",
            "#endif",
            "#ifdef CONFIG_SMP",
            "\t\tif (dl_bandwidth_enabled() && dl_policy(policy) &&",
            "\t\t\t\t!(attr->sched_flags & SCHED_FLAG_SUGOV)) {",
            "\t\t\tcpumask_t *span = rq->rd->span;",
            "",
            "\t\t\t/*",
            "\t\t\t * Don't allow tasks with an affinity mask smaller than",
            "\t\t\t * the entire root_domain to become SCHED_DEADLINE. We",
            "\t\t\t * will also fail if there's no bandwidth available.",
            "\t\t\t */",
            "\t\t\tif (!cpumask_subset(span, p->cpus_ptr) ||",
            "\t\t\t    rq->rd->dl_bw.bw == 0) {",
            "\t\t\t\tretval = -EPERM;",
            "\t\t\t\tgoto unlock;",
            "\t\t\t}",
            "\t\t}",
            "#endif",
            "\t}",
            "",
            "\t/* Re-check policy now with rq lock held: */",
            "\tif (unlikely(oldpolicy != -1 && oldpolicy != p->policy)) {",
            "\t\tpolicy = oldpolicy = -1;",
            "\t\ttask_rq_unlock(rq, p, &rf);",
            "\t\tif (cpuset_locked)",
            "\t\t\tcpuset_unlock();",
            "\t\tgoto recheck;",
            "\t}",
            "",
            "\t/*",
            "\t * If setscheduling to SCHED_DEADLINE (or changing the parameters",
            "\t * of a SCHED_DEADLINE task) we need to check if enough bandwidth",
            "\t * is available.",
            "\t */",
            "\tif ((dl_policy(policy) || dl_task(p)) && sched_dl_overflow(p, policy, attr)) {",
            "\t\tretval = -EBUSY;",
            "\t\tgoto unlock;",
            "\t}",
            "",
            "\tp->sched_reset_on_fork = reset_on_fork;",
            "\toldprio = p->prio;",
            "",
            "\tnewprio = __normal_prio(policy, attr->sched_priority, attr->sched_nice);",
            "\tif (pi) {",
            "\t\t/*",
            "\t\t * Take priority boosted tasks into account. If the new",
            "\t\t * effective priority is unchanged, we just store the new",
            "\t\t * normal parameters and do not touch the scheduler class and",
            "\t\t * the runqueue. This will be done when the task deboost",
            "\t\t * itself.",
            "\t\t */",
            "\t\tnewprio = rt_effective_prio(p, newprio);",
            "\t\tif (newprio == oldprio)",
            "\t\t\tqueue_flags &= ~DEQUEUE_MOVE;",
            "\t}",
            "",
            "\tprev_class = p->sched_class;",
            "\tnext_class = __setscheduler_class(policy, newprio);",
            "",
            "\tif (prev_class != next_class && p->se.sched_delayed)",
            "\t\tdequeue_task(rq, p, DEQUEUE_SLEEP | DEQUEUE_DELAYED | DEQUEUE_NOCLOCK);",
            "",
            "\tqueued = task_on_rq_queued(p);",
            "\trunning = task_current(rq, p);",
            "\tif (queued)",
            "\t\tdequeue_task(rq, p, queue_flags);",
            "\tif (running)",
            "\t\tput_prev_task(rq, p);",
            "",
            "\tif (!(attr->sched_flags & SCHED_FLAG_KEEP_PARAMS)) {",
            "\t\t__setscheduler_params(p, attr);",
            "\t\tp->sched_class = next_class;",
            "\t\tp->prio = newprio;",
            "\t}",
            "\t__setscheduler_uclamp(p, attr);",
            "\tcheck_class_changing(rq, p, prev_class);",
            "",
            "\tif (queued) {",
            "\t\t/*",
            "\t\t * We enqueue to tail when the priority of a task is",
            "\t\t * increased (user space view).",
            "\t\t */",
            "\t\tif (oldprio < p->prio)",
            "\t\t\tqueue_flags |= ENQUEUE_HEAD;",
            "",
            "\t\tenqueue_task(rq, p, queue_flags);",
            "\t}",
            "\tif (running)",
            "\t\tset_next_task(rq, p);",
            "",
            "\tcheck_class_changed(rq, p, prev_class, oldprio);",
            "",
            "\t/* Avoid rq from going away on us: */",
            "\tpreempt_disable();",
            "\thead = splice_balance_callbacks(rq);",
            "\ttask_rq_unlock(rq, p, &rf);",
            "",
            "\tif (pi) {",
            "\t\tif (cpuset_locked)",
            "\t\t\tcpuset_unlock();",
            "\t\trt_mutex_adjust_pi(p);",
            "\t}",
            "",
            "\t/* Run balance callbacks after we've adjusted the PI chain: */",
            "\tbalance_callbacks(rq, head);",
            "\tpreempt_enable();",
            "",
            "\treturn 0;",
            "",
            "unlock:",
            "\ttask_rq_unlock(rq, p, &rf);",
            "\tif (cpuset_locked)",
            "\t\tcpuset_unlock();",
            "\treturn retval;",
            "}"
          ],
          "function_name": "__sched_setscheduler",
          "description": "实现__sched_setscheduler函数，用于修改任务的调度策略及参数。该函数验证新策略有效性，更新任务优先级，切换调度类并调整运行队列状态，处理PI互斥锁及负载均衡回调。核心功能是安全地变更任务调度参数并维护调度器一致性。",
          "similarity": 0.557712972164154
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 889,
          "end_line": 1002,
          "content": [
            "static int _sched_setscheduler(struct task_struct *p, int policy,",
            "\t\t\t       const struct sched_param *param, bool check)",
            "{",
            "\tstruct sched_attr attr = {",
            "\t\t.sched_policy   = policy,",
            "\t\t.sched_priority = param->sched_priority,",
            "\t\t.sched_nice\t= PRIO_TO_NICE(p->static_prio),",
            "\t};",
            "",
            "\tif (p->se.custom_slice)",
            "\t\tattr.sched_runtime = p->se.slice;",
            "",
            "\t/* Fixup the legacy SCHED_RESET_ON_FORK hack. */",
            "\tif ((policy != SETPARAM_POLICY) && (policy & SCHED_RESET_ON_FORK)) {",
            "\t\tattr.sched_flags |= SCHED_FLAG_RESET_ON_FORK;",
            "\t\tpolicy &= ~SCHED_RESET_ON_FORK;",
            "\t\tattr.sched_policy = policy;",
            "\t}",
            "",
            "\treturn __sched_setscheduler(p, &attr, check, true);",
            "}",
            "int sched_setscheduler(struct task_struct *p, int policy,",
            "\t\t       const struct sched_param *param)",
            "{",
            "\treturn _sched_setscheduler(p, policy, param, true);",
            "}",
            "int sched_setattr(struct task_struct *p, const struct sched_attr *attr)",
            "{",
            "\treturn __sched_setscheduler(p, attr, true, true);",
            "}",
            "int sched_setattr_nocheck(struct task_struct *p, const struct sched_attr *attr)",
            "{",
            "\treturn __sched_setscheduler(p, attr, false, true);",
            "}",
            "int sched_setscheduler_nocheck(struct task_struct *p, int policy,",
            "\t\t\t       const struct sched_param *param)",
            "{",
            "\treturn _sched_setscheduler(p, policy, param, false);",
            "}",
            "void sched_set_fifo(struct task_struct *p)",
            "{",
            "\tstruct sched_param sp = { .sched_priority = MAX_RT_PRIO / 2 };",
            "\tWARN_ON_ONCE(sched_setscheduler_nocheck(p, SCHED_FIFO, &sp) != 0);",
            "}",
            "void sched_set_fifo_low(struct task_struct *p)",
            "{",
            "\tstruct sched_param sp = { .sched_priority = 1 };",
            "\tWARN_ON_ONCE(sched_setscheduler_nocheck(p, SCHED_FIFO, &sp) != 0);",
            "}",
            "void sched_set_normal(struct task_struct *p, int nice)",
            "{",
            "\tstruct sched_attr attr = {",
            "\t\t.sched_policy = SCHED_NORMAL,",
            "\t\t.sched_nice = nice,",
            "\t};",
            "\tWARN_ON_ONCE(sched_setattr_nocheck(p, &attr) != 0);",
            "}",
            "static int",
            "do_sched_setscheduler(pid_t pid, int policy, struct sched_param __user *param)",
            "{",
            "\tstruct sched_param lparam;",
            "",
            "\tif (!param || pid < 0)",
            "\t\treturn -EINVAL;",
            "\tif (copy_from_user(&lparam, param, sizeof(struct sched_param)))",
            "\t\treturn -EFAULT;",
            "",
            "\tCLASS(find_get_task, p)(pid);",
            "\tif (!p)",
            "\t\treturn -ESRCH;",
            "",
            "\treturn sched_setscheduler(p, policy, &lparam);",
            "}",
            "static int sched_copy_attr(struct sched_attr __user *uattr, struct sched_attr *attr)",
            "{",
            "\tu32 size;",
            "\tint ret;",
            "",
            "\t/* Zero the full structure, so that a short copy will be nice: */",
            "\tmemset(attr, 0, sizeof(*attr));",
            "",
            "\tret = get_user(size, &uattr->size);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\t/* ABI compatibility quirk: */",
            "\tif (!size)",
            "\t\tsize = SCHED_ATTR_SIZE_VER0;",
            "\tif (size < SCHED_ATTR_SIZE_VER0 || size > PAGE_SIZE)",
            "\t\tgoto err_size;",
            "",
            "\tret = copy_struct_from_user(attr, sizeof(*attr), uattr, size);",
            "\tif (ret) {",
            "\t\tif (ret == -E2BIG)",
            "\t\t\tgoto err_size;",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tif ((attr->sched_flags & SCHED_FLAG_UTIL_CLAMP) &&",
            "\t    size < SCHED_ATTR_SIZE_VER1)",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * XXX: Do we want to be lenient like existing syscalls; or do we want",
            "\t * to be strict and return an error on out-of-bounds values?",
            "\t */",
            "\tattr->sched_nice = clamp(attr->sched_nice, MIN_NICE, MAX_NICE);",
            "",
            "\treturn 0;",
            "",
            "err_size:",
            "\tput_user(sizeof(*attr), &uattr->size);",
            "\treturn -E2BIG;",
            "}"
          ],
          "function_name": "_sched_setscheduler, sched_setscheduler, sched_setattr, sched_setattr_nocheck, sched_setscheduler_nocheck, sched_set_fifo, sched_set_fifo_low, sched_set_normal, do_sched_setscheduler, sched_copy_attr",
          "description": "提供多种调度参数设置接口，包括_sched_setscheduler及其变种函数。通过封装将用户参数转化为sched_attr结构，调用底层__sched_setscheduler实现。包含针对特定调度策略（FIFO/NORMAL）的专用接口，以及参数复制和校验逻辑。",
          "similarity": 0.55711829662323
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/sched/syscalls.c",
          "start_line": 375,
          "end_line": 487,
          "content": [
            "unsigned long sched_cpu_util(int cpu)",
            "{",
            "\treturn effective_cpu_util(cpu, cpu_util_cfs(cpu), NULL, NULL);",
            "}",
            "static void __setscheduler_params(struct task_struct *p,",
            "\t\tconst struct sched_attr *attr)",
            "{",
            "\tint policy = attr->sched_policy;",
            "",
            "\tif (policy == SETPARAM_POLICY)",
            "\t\tpolicy = p->policy;",
            "",
            "\tp->policy = policy;",
            "",
            "\tif (dl_policy(policy)) {",
            "\t\t__setparam_dl(p, attr);",
            "\t} else if (fair_policy(policy)) {",
            "\t\tp->static_prio = NICE_TO_PRIO(attr->sched_nice);",
            "\t\tif (attr->sched_runtime) {",
            "\t\t\tp->se.custom_slice = 1;",
            "\t\t\tp->se.slice = clamp_t(u64, attr->sched_runtime,",
            "\t\t\t\t\t      NSEC_PER_MSEC/10,   /* HZ=1000 * 10 */",
            "\t\t\t\t\t      NSEC_PER_MSEC*100); /* HZ=100  / 10 */",
            "\t\t} else {",
            "\t\t\tp->se.custom_slice = 0;",
            "\t\t\tp->se.slice = sysctl_sched_base_slice;",
            "\t\t}",
            "\t}",
            "",
            "\t/* rt-policy tasks do not have a timerslack */",
            "\tif (rt_or_dl_task_policy(p)) {",
            "\t\tp->timer_slack_ns = 0;",
            "\t} else if (p->timer_slack_ns == 0) {",
            "\t\t/* when switching back to non-rt policy, restore timerslack */",
            "\t\tp->timer_slack_ns = p->default_timer_slack_ns;",
            "\t}",
            "",
            "\t/*",
            "\t * __sched_setscheduler() ensures attr->sched_priority == 0 when",
            "\t * !rt_policy. Always setting this ensures that things like",
            "\t * getparam()/getattr() don't report silly values for !rt tasks.",
            "\t */",
            "\tp->rt_priority = attr->sched_priority;",
            "\tp->normal_prio = normal_prio(p);",
            "\tset_load_weight(p, true);",
            "}",
            "static bool check_same_owner(struct task_struct *p)",
            "{",
            "\tconst struct cred *cred = current_cred(), *pcred;",
            "\tguard(rcu)();",
            "",
            "\tpcred = __task_cred(p);",
            "\treturn (uid_eq(cred->euid, pcred->euid) ||",
            "\t\tuid_eq(cred->euid, pcred->uid));",
            "}",
            "static int uclamp_validate(struct task_struct *p,",
            "\t\t\t   const struct sched_attr *attr)",
            "{",
            "\tint util_min = p->uclamp_req[UCLAMP_MIN].value;",
            "\tint util_max = p->uclamp_req[UCLAMP_MAX].value;",
            "",
            "\tif (attr->sched_flags & SCHED_FLAG_UTIL_CLAMP_MIN) {",
            "\t\tutil_min = attr->sched_util_min;",
            "",
            "\t\tif (util_min + 1 > SCHED_CAPACITY_SCALE + 1)",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tif (attr->sched_flags & SCHED_FLAG_UTIL_CLAMP_MAX) {",
            "\t\tutil_max = attr->sched_util_max;",
            "",
            "\t\tif (util_max + 1 > SCHED_CAPACITY_SCALE + 1)",
            "\t\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tif (util_min != -1 && util_max != -1 && util_min > util_max)",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * We have valid uclamp attributes; make sure uclamp is enabled.",
            "\t *",
            "\t * We need to do that here, because enabling static branches is a",
            "\t * blocking operation which obviously cannot be done while holding",
            "\t * scheduler locks.",
            "\t */",
            "\tsched_uclamp_enable();",
            "",
            "\treturn 0;",
            "}",
            "static bool uclamp_reset(const struct sched_attr *attr,",
            "\t\t\t enum uclamp_id clamp_id,",
            "\t\t\t struct uclamp_se *uc_se)",
            "{",
            "\t/* Reset on sched class change for a non user-defined clamp value. */",
            "\tif (likely(!(attr->sched_flags & SCHED_FLAG_UTIL_CLAMP)) &&",
            "\t    !uc_se->user_defined)",
            "\t\treturn true;",
            "",
            "\t/* Reset on sched_util_{min,max} == -1. */",
            "\tif (clamp_id == UCLAMP_MIN &&",
            "\t    attr->sched_flags & SCHED_FLAG_UTIL_CLAMP_MIN &&",
            "\t    attr->sched_util_min == -1) {",
            "\t\treturn true;",
            "\t}",
            "",
            "\tif (clamp_id == UCLAMP_MAX &&",
            "\t    attr->sched_flags & SCHED_FLAG_UTIL_CLAMP_MAX &&",
            "\t    attr->sched_util_max == -1) {",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "sched_cpu_util, __setscheduler_params, check_same_owner, uclamp_validate, uclamp_reset",
          "description": "实现调度参数配置、uclamp属性验证及调度器上下文检查，包含任务策略切换、时间片设置、用户权限校验及uclamp默认值处理逻辑",
          "similarity": 0.5419439673423767
        }
      ]
    },
    {
      "source_file": "kernel/sched/cpupri.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:04:45\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\cpupri.c`\n\n---\n\n# `sched/cpupri.c` 技术文档\n\n## 1. 文件概述\n\n`sched/cpupri.c` 实现了 **CPU 优先级管理（CPU Priority Management）** 机制，用于实时任务（RT tasks）的全局负载均衡和迁移决策。该机制通过维护一个二维位图结构，快速追踪每个 CPU 当前运行任务的最高优先级，从而在 O(1) 时间复杂度内为新唤醒或迁移的实时任务找到合适的 CPU 目标。该机制特别优化了无 CPU 亲和性限制的任务调度路径，同时支持带亲和性约束的场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数 | 功能描述 |\n|------|--------|\n| `convert_prio(int prio)` | 将任务的调度优先级（`p->prio`）转换为内部 `cpupri` 优先级值（范围：-1 到 100） |\n| `__cpupri_find(struct cpupri *cp, struct task_struct *p, struct cpumask *lowest_mask, int idx)` | 在指定优先级层级 `idx` 中查找满足任务 `p` 的 CPU（考虑亲和性） |\n| `cpupri_find(struct cpupri *cp, struct task_struct *p, struct cpumask *lowest_mask)` | 查找系统中优先级 **低于或等于** 任务 `p` 的 CPU（即任务可运行的 CPU） |\n| `cpupri_find_fitness(...)` | 增强版查找函数，支持通过 `fitness_fn` 自定义 CPU 适配条件（如容量感知） |\n| `cpupri_set(struct cpupri *cp, int cpu, int newpri)` | 更新指定 CPU 的当前最高优先级状态 |\n| `cpupri_init(struct cpupri *cp)` | 初始化 `cpupri` 数据结构（声明但未在片段中实现） |\n\n### 关键数据结构（隐含）\n\n- `struct cpupri`：全局 CPU 优先级管理上下文\n  - `cpu_to_pri[]`：每个 CPU 当前的 `cpupri` 优先级\n  - `pri_to_cpu[]`：每个优先级对应的 `struct cpupri_vec`\n- `struct cpupri_vec`：\n  - `mask`：该优先级下所有 CPU 的位图\n  - `count`：该优先级下活跃 CPU 的数量（原子计数）\n\n### 优先级映射关系\n\n| 任务 `p->prio` | `cpupri` 值 | 含义 |\n|---------------|------------|------|\n| -1 | -1 (`CPUPRI_INVALID`) | 无效状态（CPU 不可调度） |\n| 0–98 | 99–1 | 实时优先级（数值越大，任务优先级越高，`cpupri` 值越小） |\n| 99 (`MAX_RT_PRIO-1`) | 0 (`CPUPRI_NORMAL`) | 普通（非实时）任务 |\n| 100 (`MAX_RT_PRIO`) | 100 (`CPUPRI_HIGHER`) | 高于所有 RT 任务的特殊优先级 |\n\n> **注意**：`cpupri` 值越小，表示 CPU 当前负载的优先级 **越高**。\n\n## 3. 关键实现\n\n### 优先级转换逻辑\n- `convert_prio()` 实现了任务调度优先级到 `cpupri` 内部表示的映射，确保实时任务（`p->prio` ∈ [0, 98]）被正确映射到 `cpupri` ∈ [1, 99]，且高优先级任务对应更小的 `cpupri` 值。\n\n### 快速查找算法\n- 使用 **二维位图**：第一维为优先级（0–100），第二维为 CPU 位图。\n- `cpupri_find_fitness()` 从最低优先级（`idx = 0`）开始遍历，找到第一个存在可用 CPU 的优先级层级。\n- 对于每个层级，通过 `cpumask_any_and()` 快速判断任务亲和性掩码与该优先级 CPU 掩码是否有交集。\n- 若提供 `fitness_fn`（如容量检查），会过滤掉不满足条件的 CPU；若过滤后无 CPU 可用，则继续搜索更高优先级层级。\n\n### 容错与回退策略\n- 如果启用了 `fitness_fn` 但未找到满足条件的 CPU，函数会 **忽略 fitness 条件重新搜索**，确保高优先级任务总能找到运行 CPU（优先保证实时性，而非最优资源匹配）。\n\n### 并发安全更新\n- `cpupri_set()` 使用 **内存屏障（`smp_mb__before/after_atomic()`）** 确保 CPU 位图和计数器的更新顺序：\n  1. **添加 CPU**：先设置位图 → 内存屏障 → 增加计数器\n  2. **移除 CPU**：先减少计数器 → 内存屏障 → 清除位图\n- 此顺序防止 `cpupri_find` 在并发读取时看到不一致状态（如计数器为 0 但位图仍置位）。\n\n### 亲和性处理\n- 所有查找操作均与任务的 `p->cpus_mask`（CPU 亲和性）和 `cpu_active_mask`（活跃 CPU）进行交集运算，确保只返回合法 CPU。\n\n## 4. 依赖关系\n\n- **调度器核心**：依赖 `task_struct`、`p->prio`、`p->cpus_mask` 等调度器基本结构。\n- **实时调度类（`rt.c`）**：`cpupri` 主要服务于 `SCHED_FIFO`/`SCHED_RR` 任务的负载均衡。\n- **CPU 掩码操作**：使用 `cpumask_*` 系列函数（如 `cpumask_and`, `cpumask_clear_cpu`）。\n- **内存屏障原语**：依赖 `smp_rmb()`、`smp_mb__before_atomic()` 等 SMP 同步机制。\n- **原子操作**：使用 `atomic_read/inc/dec` 管理优先级层级的 CPU 计数。\n\n## 5. 使用场景\n\n- **实时任务唤醒/迁移**：当高优先级 RT 任务被唤醒或需要迁移时，调用 `cpupri_find()` 快速定位可运行的最低优先级 CPU（减少抢占开销）。\n- **全局负载均衡**：RT 调度器的 `push_rt_task()` 和 `pull_rt_task()` 机制利用 `cpupri` 决定任务推送/拉取的目标 CPU。\n- **容量感知调度（Capacity Awareness）**：通过 `cpupri_find_fitness()` 的 `fitness_fn` 参数，集成 CPU 性能/能效信息（如 ARM big.LITTLE 架构），在满足优先级前提下选择合适 CPU。\n- **CPU 热插拔**：CPU 上下线时通过 `cpupri_set()` 更新其优先级状态（设为 `CPUPRI_INVALID` 或恢复）。",
      "similarity": 0.5854787230491638,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/cpupri.c",
          "start_line": 42,
          "end_line": 178,
          "content": [
            "static int convert_prio(int prio)",
            "{",
            "\tint cpupri;",
            "",
            "\tswitch (prio) {",
            "\tcase CPUPRI_INVALID:",
            "\t\tcpupri = CPUPRI_INVALID;\t/* -1 */",
            "\t\tbreak;",
            "",
            "\tcase 0 ... 98:",
            "\t\tcpupri = MAX_RT_PRIO-1 - prio;\t/* 1 ... 99 */",
            "\t\tbreak;",
            "",
            "\tcase MAX_RT_PRIO-1:",
            "\t\tcpupri = CPUPRI_NORMAL;\t\t/*  0 */",
            "\t\tbreak;",
            "",
            "\tcase MAX_RT_PRIO:",
            "\t\tcpupri = CPUPRI_HIGHER;\t\t/* 100 */",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn cpupri;",
            "}",
            "static inline int __cpupri_find(struct cpupri *cp, struct task_struct *p,",
            "\t\t\t\tstruct cpumask *lowest_mask, int idx)",
            "{",
            "\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[idx];",
            "\tint skip = 0;",
            "",
            "\tif (!atomic_read(&(vec)->count))",
            "\t\tskip = 1;",
            "\t/*",
            "\t * When looking at the vector, we need to read the counter,",
            "\t * do a memory barrier, then read the mask.",
            "\t *",
            "\t * Note: This is still all racy, but we can deal with it.",
            "\t *  Ideally, we only want to look at masks that are set.",
            "\t *",
            "\t *  If a mask is not set, then the only thing wrong is that we",
            "\t *  did a little more work than necessary.",
            "\t *",
            "\t *  If we read a zero count but the mask is set, because of the",
            "\t *  memory barriers, that can only happen when the highest prio",
            "\t *  task for a run queue has left the run queue, in which case,",
            "\t *  it will be followed by a pull. If the task we are processing",
            "\t *  fails to find a proper place to go, that pull request will",
            "\t *  pull this task if the run queue is running at a lower",
            "\t *  priority.",
            "\t */",
            "\tsmp_rmb();",
            "",
            "\t/* Need to do the rmb for every iteration */",
            "\tif (skip)",
            "\t\treturn 0;",
            "",
            "\tif (cpumask_any_and(&p->cpus_mask, vec->mask) >= nr_cpu_ids)",
            "\t\treturn 0;",
            "",
            "\tif (lowest_mask) {",
            "\t\tcpumask_and(lowest_mask, &p->cpus_mask, vec->mask);",
            "\t\tcpumask_and(lowest_mask, lowest_mask, cpu_active_mask);",
            "",
            "\t\t/*",
            "\t\t * We have to ensure that we have at least one bit",
            "\t\t * still set in the array, since the map could have",
            "\t\t * been concurrently emptied between the first and",
            "\t\t * second reads of vec->mask.  If we hit this",
            "\t\t * condition, simply act as though we never hit this",
            "\t\t * priority level and continue on.",
            "\t\t */",
            "\t\tif (cpumask_empty(lowest_mask))",
            "\t\t\treturn 0;",
            "\t}",
            "",
            "\treturn 1;",
            "}",
            "int cpupri_find(struct cpupri *cp, struct task_struct *p,",
            "\t\tstruct cpumask *lowest_mask)",
            "{",
            "\treturn cpupri_find_fitness(cp, p, lowest_mask, NULL);",
            "}",
            "int cpupri_find_fitness(struct cpupri *cp, struct task_struct *p,",
            "\t\tstruct cpumask *lowest_mask,",
            "\t\tbool (*fitness_fn)(struct task_struct *p, int cpu))",
            "{",
            "\tint task_pri = convert_prio(p->prio);",
            "\tint idx, cpu;",
            "",
            "\tWARN_ON_ONCE(task_pri >= CPUPRI_NR_PRIORITIES);",
            "",
            "\tfor (idx = 0; idx < task_pri; idx++) {",
            "",
            "\t\tif (!__cpupri_find(cp, p, lowest_mask, idx))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (!lowest_mask || !fitness_fn)",
            "\t\t\treturn 1;",
            "",
            "\t\t/* Ensure the capacity of the CPUs fit the task */",
            "\t\tfor_each_cpu(cpu, lowest_mask) {",
            "\t\t\tif (!fitness_fn(p, cpu))",
            "\t\t\t\tcpumask_clear_cpu(cpu, lowest_mask);",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * If no CPU at the current priority can fit the task",
            "\t\t * continue looking",
            "\t\t */",
            "\t\tif (cpumask_empty(lowest_mask))",
            "\t\t\tcontinue;",
            "",
            "\t\treturn 1;",
            "\t}",
            "",
            "\t/*",
            "\t * If we failed to find a fitting lowest_mask, kick off a new search",
            "\t * but without taking into account any fitness criteria this time.",
            "\t *",
            "\t * This rule favours honouring priority over fitting the task in the",
            "\t * correct CPU (Capacity Awareness being the only user now).",
            "\t * The idea is that if a higher priority task can run, then it should",
            "\t * run even if this ends up being on unfitting CPU.",
            "\t *",
            "\t * The cost of this trade-off is not entirely clear and will probably",
            "\t * be good for some workloads and bad for others.",
            "\t *",
            "\t * The main idea here is that if some CPUs were over-committed, we try",
            "\t * to spread which is what the scheduler traditionally did. Sys admins",
            "\t * must do proper RT planning to avoid overloading the system if they",
            "\t * really care.",
            "\t */",
            "\tif (fitness_fn)",
            "\t\treturn cpupri_find(cp, p, lowest_mask);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "convert_prio, __cpupri_find, cpupri_find, cpupri_find_fitness",
          "description": "convert_prio将任务优先级映射为CPU优先级数值；__cpupri_find检查特定优先级下是否存在可用CPU；cpupri_find_fitness遍历优先级层级寻找适配CPU，结合适应性判断与优先级策略决定最终选择",
          "similarity": 0.6140961647033691
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/cpupri.c",
          "start_line": 1,
          "end_line": 41,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " *  kernel/sched/cpupri.c",
            " *",
            " *  CPU priority management",
            " *",
            " *  Copyright (C) 2007-2008 Novell",
            " *",
            " *  Author: Gregory Haskins <ghaskins@novell.com>",
            " *",
            " *  This code tracks the priority of each CPU so that global migration",
            " *  decisions are easy to calculate.  Each CPU can be in a state as follows:",
            " *",
            " *                 (INVALID), NORMAL, RT1, ... RT99, HIGHER",
            " *",
            " *  going from the lowest priority to the highest.  CPUs in the INVALID state",
            " *  are not eligible for routing.  The system maintains this state with",
            " *  a 2 dimensional bitmap (the first for priority class, the second for CPUs",
            " *  in that class).  Therefore a typical application without affinity",
            " *  restrictions can find a suitable CPU with O(1) complexity (e.g. two bit",
            " *  searches).  For tasks with affinity restrictions, the algorithm has a",
            " *  worst case complexity of O(min(101, nr_domcpus)), though the scenario that",
            " *  yields the worst case search is fairly contrived.",
            " */",
            "",
            "/*",
            " * p->rt_priority   p->prio   newpri   cpupri",
            " *",
            " *\t\t\t\t  -1       -1 (CPUPRI_INVALID)",
            " *",
            " *\t\t\t\t  99        0 (CPUPRI_NORMAL)",
            " *",
            " *\t\t1        98       98        1",
            " *\t      ...",
            " *\t       49        50       50       49",
            " *\t       50        49       49       50",
            " *\t      ...",
            " *\t       99         0        0       99",
            " *",
            " *\t\t\t\t 100\t  100 (CPUPRI_HIGHER)",
            " */"
          ],
          "function_name": null,
          "description": "定义CPU优先级管理模块，通过二维位图跟踪各CPU优先级状态，支持NORMAL、RT1至RT99及HIGHER五种优先级分类，INVALID状态表示CPU不可用，用于全局任务调度时快速计算迁移决策",
          "similarity": 0.6046967506408691
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/cpupri.c",
          "start_line": 210,
          "end_line": 304,
          "content": [
            "void cpupri_set(struct cpupri *cp, int cpu, int newpri)",
            "{",
            "\tint *currpri = &cp->cpu_to_pri[cpu];",
            "\tint oldpri = *currpri;",
            "\tint do_mb = 0;",
            "",
            "\tnewpri = convert_prio(newpri);",
            "",
            "\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);",
            "",
            "\tif (newpri == oldpri)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If the CPU was currently mapped to a different value, we",
            "\t * need to map it to the new value then remove the old value.",
            "\t * Note, we must add the new value first, otherwise we risk the",
            "\t * cpu being missed by the priority loop in cpupri_find.",
            "\t */",
            "\tif (likely(newpri != CPUPRI_INVALID)) {",
            "\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];",
            "",
            "\t\tcpumask_set_cpu(cpu, vec->mask);",
            "\t\t/*",
            "\t\t * When adding a new vector, we update the mask first,",
            "\t\t * do a write memory barrier, and then update the count, to",
            "\t\t * make sure the vector is visible when count is set.",
            "\t\t */",
            "\t\tsmp_mb__before_atomic();",
            "\t\tatomic_inc(&(vec)->count);",
            "\t\tdo_mb = 1;",
            "\t}",
            "\tif (likely(oldpri != CPUPRI_INVALID)) {",
            "\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];",
            "",
            "\t\t/*",
            "\t\t * Because the order of modification of the vec->count",
            "\t\t * is important, we must make sure that the update",
            "\t\t * of the new prio is seen before we decrement the",
            "\t\t * old prio. This makes sure that the loop sees",
            "\t\t * one or the other when we raise the priority of",
            "\t\t * the run queue. We don't care about when we lower the",
            "\t\t * priority, as that will trigger an rt pull anyway.",
            "\t\t *",
            "\t\t * We only need to do a memory barrier if we updated",
            "\t\t * the new priority vec.",
            "\t\t */",
            "\t\tif (do_mb)",
            "\t\t\tsmp_mb__after_atomic();",
            "",
            "\t\t/*",
            "\t\t * When removing from the vector, we decrement the counter first",
            "\t\t * do a memory barrier and then clear the mask.",
            "\t\t */",
            "\t\tatomic_dec(&(vec)->count);",
            "\t\tsmp_mb__after_atomic();",
            "\t\tcpumask_clear_cpu(cpu, vec->mask);",
            "\t}",
            "",
            "\t*currpri = newpri;",
            "}",
            "int cpupri_init(struct cpupri *cp)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < CPUPRI_NR_PRIORITIES; i++) {",
            "\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[i];",
            "",
            "\t\tatomic_set(&vec->count, 0);",
            "\t\tif (!zalloc_cpumask_var(&vec->mask, GFP_KERNEL))",
            "\t\t\tgoto cleanup;",
            "\t}",
            "",
            "\tcp->cpu_to_pri = kcalloc(nr_cpu_ids, sizeof(int), GFP_KERNEL);",
            "\tif (!cp->cpu_to_pri)",
            "\t\tgoto cleanup;",
            "",
            "\tfor_each_possible_cpu(i)",
            "\t\tcp->cpu_to_pri[i] = CPUPRI_INVALID;",
            "",
            "\treturn 0;",
            "",
            "cleanup:",
            "\tfor (i--; i >= 0; i--)",
            "\t\tfree_cpumask_var(cp->pri_to_cpu[i].mask);",
            "\treturn -ENOMEM;",
            "}",
            "void cpupri_cleanup(struct cpupri *cp)",
            "{",
            "\tint i;",
            "",
            "\tkfree(cp->cpu_to_pri);",
            "\tfor (i = 0; i < CPUPRI_NR_PRIORITIES; i++)",
            "\t\tfree_cpumask_var(cp->pri_to_cpu[i].mask);",
            "}"
          ],
          "function_name": "cpupri_set, cpupri_init, cpupri_cleanup",
          "description": "cpupri_set更新CPU优先级状态，通过原子操作同步位图与计数器；cpupri_init初始化优先级到CPU的映射表与CPU到优先级的数组；cpupri_cleanup释放所有动态分配的位图资源与优先级数组",
          "similarity": 0.5968276262283325
        }
      ]
    },
    {
      "source_file": "mm/damon/lru_sort.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:47:42\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `damon\\lru_sort.c`\n\n---\n\n# `damon/lru_sort.c` 技术文档\n\n## 1. 文件概述\n\n`damon/lru_sort.c` 是 Linux 内核中基于 DAMON（Data Access MONitor）框架实现的一个内核模块，用于根据内存访问模式动态调整页面在 LRU（Least Recently Used）列表中的优先级。该模块通过监控内存区域的访问频率和空闲时间，将“热”页面标记为高优先级（防止被回收），将“冷”页面标记为低优先级（优先回收），从而优化内存回收效率。模块行为受水位线（watermarks）机制控制，仅在系统空闲内存低于特定阈值时激活。\n\n## 2. 核心功能\n\n### 主要数据结构\n- **`enabled`**: 控制模块是否启用的布尔标志。\n- **`commit_inputs`**: 触发运行时参数重载的布尔标志。\n- **`hot_thres_access_freq`**: 热内存区域的访问频率阈值（单位：千分比，默认 500，即 50%）。\n- **`cold_min_age`**: 冷内存区域的最小未访问时间（单位：微秒，默认 120,000,000，即 120 秒）。\n- **`damon_lru_sort_quota`**: 操作配额限制，控制 DAMON 操作消耗的 CPU 时间（默认每秒最多 10 毫秒）。\n- **`damon_lru_sort_wmarks`**: 水位线配置，基于空闲内存率决定模块是否激活（高/中/低阈值分别为 20%/15%/5%）。\n- **`damon_lru_sort_mon_attrs`**: DAMON 监控属性，包括采样间隔、聚合间隔等。\n- **`monitor_region_start/monitor_region_end`**: 监控的物理内存区域范围（默认为最大 System RAM 区域）。\n- **`kdamond_pid`**: DAMON 工作线程的 PID（启用时有效，否则为 -1）。\n- **`damon_lru_sort_hot_stat` / `damon_lru_sort_cold_stat`**: 热/冷页面操作的统计信息。\n- **`damon_lru_sort_stub_pattern`**: 基础访问模式模板，用于构建热/冷识别规则。\n\n### 主要函数\n- **`damon_lru_sort_new_scheme()`**: 创建通用的 DAMOS（DAMON Operation Scheme）方案。\n- **`damon_lru_sort_new_hot_scheme()`**: 创建用于识别并提升热页面优先级的方案（`DAMOS_LRU_PRIO`）。\n- **`damon_lru_sort_new_cold_scheme()`**: 创建用于识别并降低冷页面优先级的方案（`DAMOS_LRU_DEPRIO`）。\n- **`damon_lru_sort_copy_quota_status()`**: 复制配额使用状态，用于方案更新时保留历史配额信息。\n- **`damon_lru_sort_apply_parameters()`**: 应用当前模块参数到 DAMON 上下文，包括监控属性、操作方案和监控区域。\n- **`damon_lru_sort_turn()`**: 启用或禁用 DAMON LRU 排序功能。\n- **`damon_lru_sort_enabled_store()`**: 处理 `enabled` 参数的写入（代码片段截断，但功能为切换模块状态）。\n\n## 3. 关键实现\n\n- **热/冷页面识别**：\n  - **热页面**：在聚合间隔内访问次数 ≥ `hot_thres_access_freq`（转换为 DAMON 访问计数阈值）。\n  - **冷页面**：未被访问的时间 ≥ `cold_min_age`（转换为以聚合间隔为单位的年龄阈值）。\n  \n- **LRU 优先级调整**：\n  - 热页面通过 `DAMOS_LRU_PRIO` 动作标记为已访问，提升其在 LRU 列表中的位置。\n  - 冷页面通过 `DAMOS_LRU_DEPRIO` 动作标记为未访问，降低其优先级以便优先回收。\n\n- **资源控制**：\n  - 使用 `damos_quota` 限制操作开销（默认每秒最多 10ms CPU 时间），热/冷方案各分配一半配额。\n  - 配额状态在方案更新时保留，避免因参数重载导致配额重置。\n\n- **条件激活**：\n  - 通过 `damos_watermarks` 实现基于空闲内存率的自动启停：\n    - 空闲内存率 ≤ 低水位（5%）时激活；\n    - ≥ 高水位（20%）时停用；\n    - 在中/低水位间保持当前状态。\n\n- **参数动态更新**：\n  - 除 `enabled` 外的参数修改后，需设置 `commit_inputs=Y` 触发重载。\n  - 重载失败（如参数无效）将导致模块自动禁用。\n\n## 4. 依赖关系\n\n- **核心依赖**：\n  - `linux/damon.h`：DAMON 框架核心 API。\n  - `modules-common.h`：DAMON 模块通用宏和辅助函数（如 `DEFINE_DAMON_MODULES_*` 宏）。\n- **内核子系统**：\n  - 内存管理子系统（LRU 列表操作）。\n  - 进程调度（DAMON 工作线程 `kdamond`）。\n- **配置接口**：\n  - 通过 `module_param` 提供 `/sys/module/damon_lru_sort/parameters/` 下的运行时配置。\n\n## 5. 使用场景\n\n- **内存压力下的页面回收优化**：在系统内存紧张时，自动将长期未使用的冷页面置于 LRU 列表前端，加速其回收；同时保护频繁访问的热页面不被误回收。\n- **透明大页（THP）友好**：通过基于访问模式的 LRU 调整，减少对 THP 的干扰。\n- **低开销内存监控**：利用 DAMON 的自适应区域拆分/合并机制，在有限 CPU 开销（默认 ≤10ms/s）下实现高效监控。\n- **容器/虚拟化环境**：适用于多租户场景，动态优化各 workload 的内存使用效率。\n- **嵌入式/实时系统**：通过严格配额控制，确保内存优化操作不影响关键任务实时性。",
      "similarity": 0.5791355967521667,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/damon/lru_sort.c",
          "start_line": 188,
          "end_line": 289,
          "content": [
            "static void damon_lru_sort_copy_quota_status(struct damos_quota *dst,",
            "\t\tstruct damos_quota *src)",
            "{",
            "\tdst->total_charged_sz = src->total_charged_sz;",
            "\tdst->total_charged_ns = src->total_charged_ns;",
            "\tdst->charged_sz = src->charged_sz;",
            "\tdst->charged_from = src->charged_from;",
            "\tdst->charge_target_from = src->charge_target_from;",
            "\tdst->charge_addr_from = src->charge_addr_from;",
            "}",
            "static int damon_lru_sort_apply_parameters(void)",
            "{",
            "\tstruct damos *scheme, *hot_scheme, *cold_scheme;",
            "\tstruct damos *old_hot_scheme = NULL, *old_cold_scheme = NULL;",
            "\tunsigned int hot_thres, cold_thres;",
            "\tint err = 0;",
            "",
            "\terr = damon_set_attrs(ctx, &damon_lru_sort_mon_attrs);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tdamon_for_each_scheme(scheme, ctx) {",
            "\t\tif (!old_hot_scheme) {",
            "\t\t\told_hot_scheme = scheme;",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\told_cold_scheme = scheme;",
            "\t}",
            "",
            "\thot_thres = damon_max_nr_accesses(&damon_lru_sort_mon_attrs) *",
            "\t\thot_thres_access_freq / 1000;",
            "\thot_scheme = damon_lru_sort_new_hot_scheme(hot_thres);",
            "\tif (!hot_scheme)",
            "\t\treturn -ENOMEM;",
            "\tif (old_hot_scheme)",
            "\t\tdamon_lru_sort_copy_quota_status(&hot_scheme->quota,",
            "\t\t\t\t&old_hot_scheme->quota);",
            "",
            "\tcold_thres = cold_min_age / damon_lru_sort_mon_attrs.aggr_interval;",
            "\tcold_scheme = damon_lru_sort_new_cold_scheme(cold_thres);",
            "\tif (!cold_scheme) {",
            "\t\tdamon_destroy_scheme(hot_scheme);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "\tif (old_cold_scheme)",
            "\t\tdamon_lru_sort_copy_quota_status(&cold_scheme->quota,",
            "\t\t\t\t&old_cold_scheme->quota);",
            "",
            "\tdamon_set_schemes(ctx, &hot_scheme, 1);",
            "\tdamon_add_scheme(ctx, cold_scheme);",
            "",
            "\treturn damon_set_region_biggest_system_ram_default(target,",
            "\t\t\t\t\t&monitor_region_start,",
            "\t\t\t\t\t&monitor_region_end);",
            "}",
            "static int damon_lru_sort_turn(bool on)",
            "{",
            "\tint err;",
            "",
            "\tif (!on) {",
            "\t\terr = damon_stop(&ctx, 1);",
            "\t\tif (!err)",
            "\t\t\tkdamond_pid = -1;",
            "\t\treturn err;",
            "\t}",
            "",
            "\terr = damon_lru_sort_apply_parameters();",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\terr = damon_start(&ctx, 1, true);",
            "\tif (err)",
            "\t\treturn err;",
            "\tkdamond_pid = ctx->kdamond->pid;",
            "\treturn 0;",
            "}",
            "static int damon_lru_sort_enabled_store(const char *val,",
            "\t\tconst struct kernel_param *kp)",
            "{",
            "\tbool is_enabled = enabled;",
            "\tbool enable;",
            "\tint err;",
            "",
            "\terr = kstrtobool(val, &enable);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tif (is_enabled == enable)",
            "\t\treturn 0;",
            "",
            "\t/* Called before init function.  The function will handle this. */",
            "\tif (!ctx)",
            "\t\tgoto set_param_out;",
            "",
            "\terr = damon_lru_sort_turn(enable);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "set_param_out:",
            "\tenabled = enable;",
            "\treturn err;",
            "}"
          ],
          "function_name": "damon_lru_sort_copy_quota_status, damon_lru_sort_apply_parameters, damon_lru_sort_turn, damon_lru_sort_enabled_store",
          "description": "实现动态参数应用、方案创建与切换逻辑，通过复制配额状态、构建热点/冷点筛选策略，并通过回调机制控制LRU列表优先级调整。",
          "similarity": 0.6983309984207153
        },
        {
          "chunk_id": 2,
          "file_path": "mm/damon/lru_sort.c",
          "start_line": 303,
          "end_line": 347,
          "content": [
            "static int damon_lru_sort_handle_commit_inputs(void)",
            "{",
            "\tint err;",
            "",
            "\tif (!commit_inputs)",
            "\t\treturn 0;",
            "",
            "\terr = damon_lru_sort_apply_parameters();",
            "\tcommit_inputs = false;",
            "\treturn err;",
            "}",
            "static int damon_lru_sort_after_aggregation(struct damon_ctx *c)",
            "{",
            "\tstruct damos *s;",
            "",
            "\t/* update the stats parameter */",
            "\tdamon_for_each_scheme(s, c) {",
            "\t\tif (s->action == DAMOS_LRU_PRIO)",
            "\t\t\tdamon_lru_sort_hot_stat = s->stat;",
            "\t\telse if (s->action == DAMOS_LRU_DEPRIO)",
            "\t\t\tdamon_lru_sort_cold_stat = s->stat;",
            "\t}",
            "",
            "\treturn damon_lru_sort_handle_commit_inputs();",
            "}",
            "static int damon_lru_sort_after_wmarks_check(struct damon_ctx *c)",
            "{",
            "\treturn damon_lru_sort_handle_commit_inputs();",
            "}",
            "static int __init damon_lru_sort_init(void)",
            "{",
            "\tint err = damon_modules_new_paddr_ctx_target(&ctx, &target);",
            "",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tctx->callback.after_wmarks_check = damon_lru_sort_after_wmarks_check;",
            "\tctx->callback.after_aggregation = damon_lru_sort_after_aggregation;",
            "",
            "\t/* 'enabled' has set before this function, probably via command line */",
            "\tif (enabled)",
            "\t\terr = damon_lru_sort_turn(true);",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "damon_lru_sort_handle_commit_inputs, damon_lru_sort_after_aggregation, damon_lru_sort_after_wmarks_check, damon_lru_sort_init",
          "description": "注册聚合后回调处理参数提交、水位检查后的参数同步，初始化模块时根据启用标志启动监控线程并绑定回调函数链表。",
          "similarity": 0.5035749673843384
        },
        {
          "chunk_id": 0,
          "file_path": "mm/damon/lru_sort.c",
          "start_line": 1,
          "end_line": 187,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * DAMON-based LRU-lists Sorting",
            " *",
            " * Author: SeongJae Park <sj@kernel.org>",
            " */",
            "",
            "#define pr_fmt(fmt) \"damon-lru-sort: \" fmt",
            "",
            "#include <linux/damon.h>",
            "#include <linux/kstrtox.h>",
            "#include <linux/module.h>",
            "",
            "#include \"modules-common.h\"",
            "",
            "#ifdef MODULE_PARAM_PREFIX",
            "#undef MODULE_PARAM_PREFIX",
            "#endif",
            "#define MODULE_PARAM_PREFIX \"damon_lru_sort.\"",
            "",
            "/*",
            " * Enable or disable DAMON_LRU_SORT.",
            " *",
            " * You can enable DAMON_LRU_SORT by setting the value of this parameter as",
            " * ``Y``.  Setting it as ``N`` disables DAMON_LRU_SORT.  Note that",
            " * DAMON_LRU_SORT could do no real monitoring and LRU-lists sorting due to the",
            " * watermarks-based activation condition.  Refer to below descriptions for the",
            " * watermarks parameter for this.",
            " */",
            "static bool enabled __read_mostly;",
            "",
            "/*",
            " * Make DAMON_LRU_SORT reads the input parameters again, except ``enabled``.",
            " *",
            " * Input parameters that updated while DAMON_LRU_SORT is running are not",
            " * applied by default.  Once this parameter is set as ``Y``, DAMON_LRU_SORT",
            " * reads values of parametrs except ``enabled`` again.  Once the re-reading is",
            " * done, this parameter is set as ``N``.  If invalid parameters are found while",
            " * the re-reading, DAMON_LRU_SORT will be disabled.",
            " */",
            "static bool commit_inputs __read_mostly;",
            "module_param(commit_inputs, bool, 0600);",
            "",
            "/*",
            " * Access frequency threshold for hot memory regions identification in permil.",
            " *",
            " * If a memory region is accessed in frequency of this or higher,",
            " * DAMON_LRU_SORT identifies the region as hot, and mark it as accessed on the",
            " * LRU list, so that it could not be reclaimed under memory pressure.  50% by",
            " * default.",
            " */",
            "static unsigned long hot_thres_access_freq = 500;",
            "module_param(hot_thres_access_freq, ulong, 0600);",
            "",
            "/*",
            " * Time threshold for cold memory regions identification in microseconds.",
            " *",
            " * If a memory region is not accessed for this or longer time, DAMON_LRU_SORT",
            " * identifies the region as cold, and mark it as unaccessed on the LRU list, so",
            " * that it could be reclaimed first under memory pressure.  120 seconds by",
            " * default.",
            " */",
            "static unsigned long cold_min_age __read_mostly = 120000000;",
            "module_param(cold_min_age, ulong, 0600);",
            "",
            "static struct damos_quota damon_lru_sort_quota = {",
            "\t/* Use up to 10 ms per 1 sec, by default */",
            "\t.ms = 10,",
            "\t.sz = 0,",
            "\t.reset_interval = 1000,",
            "\t/* Within the quota, mark hotter regions accessed first. */",
            "\t.weight_sz = 0,",
            "\t.weight_nr_accesses = 1,",
            "\t.weight_age = 0,",
            "};",
            "DEFINE_DAMON_MODULES_DAMOS_TIME_QUOTA(damon_lru_sort_quota);",
            "",
            "static struct damos_watermarks damon_lru_sort_wmarks = {",
            "\t.metric = DAMOS_WMARK_FREE_MEM_RATE,",
            "\t.interval = 5000000,\t/* 5 seconds */",
            "\t.high = 200,\t\t/* 20 percent */",
            "\t.mid = 150,\t\t/* 15 percent */",
            "\t.low = 50,\t\t/* 5 percent */",
            "};",
            "DEFINE_DAMON_MODULES_WMARKS_PARAMS(damon_lru_sort_wmarks);",
            "",
            "static struct damon_attrs damon_lru_sort_mon_attrs = {",
            "\t.sample_interval = 5000,\t/* 5 ms */",
            "\t.aggr_interval = 100000,\t/* 100 ms */",
            "\t.ops_update_interval = 0,",
            "\t.min_nr_regions = 10,",
            "\t.max_nr_regions = 1000,",
            "};",
            "DEFINE_DAMON_MODULES_MON_ATTRS_PARAMS(damon_lru_sort_mon_attrs);",
            "",
            "/*",
            " * Start of the target memory region in physical address.",
            " *",
            " * The start physical address of memory region that DAMON_LRU_SORT will do work",
            " * against.  By default, biggest System RAM is used as the region.",
            " */",
            "static unsigned long monitor_region_start __read_mostly;",
            "module_param(monitor_region_start, ulong, 0600);",
            "",
            "/*",
            " * End of the target memory region in physical address.",
            " *",
            " * The end physical address of memory region that DAMON_LRU_SORT will do work",
            " * against.  By default, biggest System RAM is used as the region.",
            " */",
            "static unsigned long monitor_region_end __read_mostly;",
            "module_param(monitor_region_end, ulong, 0600);",
            "",
            "/*",
            " * PID of the DAMON thread",
            " *",
            " * If DAMON_LRU_SORT is enabled, this becomes the PID of the worker thread.",
            " * Else, -1.",
            " */",
            "static int kdamond_pid __read_mostly = -1;",
            "module_param(kdamond_pid, int, 0400);",
            "",
            "static struct damos_stat damon_lru_sort_hot_stat;",
            "DEFINE_DAMON_MODULES_DAMOS_STATS_PARAMS(damon_lru_sort_hot_stat,",
            "\t\tlru_sort_tried_hot_regions, lru_sorted_hot_regions,",
            "\t\thot_quota_exceeds);",
            "",
            "static struct damos_stat damon_lru_sort_cold_stat;",
            "DEFINE_DAMON_MODULES_DAMOS_STATS_PARAMS(damon_lru_sort_cold_stat,",
            "\t\tlru_sort_tried_cold_regions, lru_sorted_cold_regions,",
            "\t\tcold_quota_exceeds);",
            "",
            "static struct damos_access_pattern damon_lru_sort_stub_pattern = {",
            "\t/* Find regions having PAGE_SIZE or larger size */",
            "\t.min_sz_region = PAGE_SIZE,",
            "\t.max_sz_region = ULONG_MAX,",
            "\t/* no matter its access frequency */",
            "\t.min_nr_accesses = 0,",
            "\t.max_nr_accesses = UINT_MAX,",
            "\t/* no matter its age */",
            "\t.min_age_region = 0,",
            "\t.max_age_region = UINT_MAX,",
            "};",
            "",
            "static struct damon_ctx *ctx;",
            "static struct damon_target *target;",
            "",
            "static struct damos *damon_lru_sort_new_scheme(",
            "\t\tstruct damos_access_pattern *pattern, enum damos_action action)",
            "{",
            "\tstruct damos_quota quota = damon_lru_sort_quota;",
            "",
            "\t/* Use half of total quota for hot/cold pages sorting */",
            "\tquota.ms = quota.ms / 2;",
            "",
            "\treturn damon_new_scheme(",
            "\t\t\t/* find the pattern, and */",
            "\t\t\tpattern,",
            "\t\t\t/* (de)prioritize on LRU-lists */",
            "\t\t\taction,",
            "\t\t\t/* for each aggregation interval */",
            "\t\t\t0,",
            "\t\t\t/* under the quota. */",
            "\t\t\t&quota,",
            "\t\t\t/* (De)activate this according to the watermarks. */",
            "\t\t\t&damon_lru_sort_wmarks);",
            "}",
            "",
            "/* Create a DAMON-based operation scheme for hot memory regions */",
            "static struct damos *damon_lru_sort_new_hot_scheme(unsigned int hot_thres)",
            "{",
            "\tstruct damos_access_pattern pattern = damon_lru_sort_stub_pattern;",
            "",
            "\tpattern.min_nr_accesses = hot_thres;",
            "\treturn damon_lru_sort_new_scheme(&pattern, DAMOS_LRU_PRIO);",
            "}",
            "",
            "/* Create a DAMON-based operation scheme for cold memory regions */",
            "static struct damos *damon_lru_sort_new_cold_scheme(unsigned int cold_thres)",
            "{",
            "\tstruct damos_access_pattern pattern = damon_lru_sort_stub_pattern;",
            "",
            "\tpattern.max_nr_accesses = 0;",
            "\tpattern.min_age_region = cold_thres;",
            "\treturn damon_lru_sort_new_scheme(&pattern, DAMOS_LRU_DEPRIO);",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义DAMON_LRU_SORT模块的配置参数和数据结构，包括启用状态、访问频率阈值、冷区域时间阈值、配额策略及水位标记参数，初始化监控上下文和目标内存区域。",
          "similarity": 0.465316504240036
        }
      ]
    }
  ]
}