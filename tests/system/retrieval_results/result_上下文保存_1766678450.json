{
  "query": "上下文保存",
  "timestamp": "2025-12-26 00:00:50",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/lockdep_internals.h",
      "md_summary": "> 自动生成时间: 2025-10-25 14:38:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\lockdep_internals.h`\n\n---\n\n# `locking/lockdep_internals.h` 技术文档\n\n## 1. 文件概述\n\n`lockdep_internals.h` 是 Linux 内核锁依赖（Lock Dependency，简称 lockdep）子系统的内部头文件，定义了 lockdep 运行时验证器所依赖的核心数据结构、枚举、宏和全局变量。该文件不对外暴露 API，仅供 lockdep 子系统内部使用，用于跟踪锁的使用状态、依赖关系、调用链以及统计信息，以检测潜在的死锁、锁顺序违规和中断上下文不一致等问题。\n\n## 2. 核心功能\n\n### 枚举与宏定义\n- `enum lock_usage_bit`：定义锁类（lock class）在不同上下文中的使用状态位（如 IRQ、softirq、hardirq 等）。\n- `LOCK_USAGE_*_MASK`：用于解析锁使用状态位的掩码（读/写方向、上下文类型）。\n- `LOCKF_*` 系列宏与常量：将使用状态位转换为位掩码，便于位运算操作，如 `LOCKF_ENABLED_IRQ`、`LOCKF_USED_IN_IRQ_READ` 等。\n- `LOCKF_IRQ` 与 `LOCKF_IRQ_READ`：组合宏，用于快速判断锁是否在中断上下文中被启用或使用。\n\n### 配置相关宏（内存优化）\n- `CONFIG_LOCKDEP_SMALL`：针对内存受限架构（如 SPARC）启用的小内存配置，限制 lockdep 数据结构的最大规模。\n- `MAX_LOCKDEP_ENTRIES`、`MAX_LOCKDEP_CHAINS_BITS`、`MAX_STACK_TRACE_ENTRIES`、`STACK_TRACE_HASH_SIZE`：定义 lockdep 跟踪能力的上限。\n\n### 锁链（Lock Chain）上下文标志\n- `LOCK_CHAIN_SOFTIRQ_CONTEXT` / `LOCK_CHAIN_HARDIRQ_CONTEXT`：标识锁链所处的中断上下文类型。\n\n### 全局变量声明\n- `lock_classes[]`：所有锁类的静态数组。\n- `lock_chains[]`：所有锁依赖链的静态数组。\n- 各类计数器：如 `nr_lock_classes`、`max_lockdep_depth`、`nr_stack_trace_entries` 等，用于跟踪 lockdep 运行状态。\n- 中断/软中断/进程上下文链数量统计：`nr_hardirq_chains`、`nr_softirq_chains`、`nr_process_chains`。\n- 内存使用统计：`nr_lost_chain_hlocks`、`nr_large_chain_blocks` 等。\n\n### 函数声明\n- `get_usage_chars()`：将锁类的使用状态转换为可读字符串。\n- `__get_key_name()`：获取锁子类键的名称。\n- `lock_chain_get_class()`：从锁链中获取第 i 个锁类。\n- `lockdep_next_lockchain()` / `lock_chain_count()`：遍历和统计锁链。\n- `lockdep_count_forward_deps()` / `lockdep_count_backward_deps()`（仅在 `CONFIG_PROVE_LOCKING` 下有效）：计算锁类的前向/后向依赖数量。\n- `lockdep_stack_trace_count()` / `lockdep_stack_hash_count()`（仅在 `CONFIG_TRACE_IRQFLAGS` 下有效）：返回栈跟踪相关统计。\n\n### 调试统计结构（`CONFIG_DEBUG_LOCKDEP`）\n- `struct lockdep_stats`：每 CPU 的 lockdep 调试统计信息，包括：\n  - 链查找命中/未命中次数\n  - 中断开关事件计数（含冗余事件）\n  - 各类检查次数（循环、前向/后向使用查找等）\n  - 每个锁类的操作计数（`lock_class_ops`）\n- 提供原子操作宏：`debug_atomic_inc/dec/read` 和 `debug_class_ops_inc/read`，用于安全更新和读取统计值。\n\n## 3. 关键实现\n\n### 锁使用状态编码\n- 使用 `lockdep_states.h` 中定义的状态（如 IRQ、SOFTIRQ、HARDIRQ 等）通过宏展开生成两组状态位：\n  - `USED_IN_*`：表示锁在该上下文中被实际使用（加锁）。\n  - `ENABLED_*`：表示锁在该上下文中被启用（即允许在该上下文中获取）。\n- 每个状态同时存在普通（写）和 `_READ`（读）版本，支持读写锁语义。\n- 状态位总数由 `LOCK_USAGE_STATES` 表示，并通过 `static_assert` 确保与 `LOCK_TRACE_STATES` 一致。\n\n### 位掩码构建\n- 利用 C 预处理器的 `#include` 技巧，在枚举和常量定义中重复包含 `lockdep_states.h`，动态生成所有状态对应的位掩码常量（如 `LOCKF_ENABLED_IRQ` 是所有 `LOCKF_ENABLED_*` 的按位或）。\n- 这种设计避免了手动维护大量状态组合，提高了可扩展性和一致性。\n\n### 内存布局优化\n- 通过 `CONFIG_LOCKDEP_SMALL` 宏，为资源受限平台（如 SPARC）提供较小的静态数组尺寸，确保内核镜像不超过 32MB 限制。\n- 默认配置则通过 Kconfig 选项（如 `CONFIG_LOCKDEP_BITS`）动态设定数据结构大小，以平衡内存占用与跟踪能力。\n\n### 调试统计的每 CPU 设计\n- 在 `CONFIG_DEBUG_LOCKDEP` 启用时，统计信息存储在 per-CPU 变量中，避免在 fast path 中因全局锁或缓存行竞争导致性能下降。\n- 提供封装宏确保在中断关闭上下文中更新统计（通过 `WARN_ON_ONCE(!irqs_disabled())` 强制约束）。\n\n## 4. 依赖关系\n\n- **依赖头文件**：\n  - `\"lockdep_states.h\"`：定义 lockdep 支持的上下文状态列表。\n  - `<asm/local.h>`：提供 per-CPU 变量操作原语（仅在 `CONFIG_DEBUG_LOCKDEP` 下）。\n- **被依赖模块**：\n  - `kernel/lockdep.c`：lockdep 主逻辑实现，大量使用本文件定义的数据结构和宏。\n  - `kernel/lockdep_proc.c`：通过本文件声明的全局变量和函数生成 `/proc/lockdep*` 调试信息。\n- **配置依赖**：\n  - `CONFIG_LOCKDEP`：启用 lockdep 子系统。\n  - `CONFIG_PROVE_LOCKING`：启用锁正确性证明（依赖前向/后向依赖计数）。\n  - `CONFIG_TRACE_IRQFLAGS`：启用中断状态跟踪（影响栈跟踪统计）。\n  - `CONFIG_DEBUG_LOCKDEP`：启用详细调试统计。\n\n## 5. 使用场景\n\n- **死锁检测**：通过 `lock_classes` 和 `lock_chains` 构建锁依赖图，运行时检测循环依赖。\n- **锁顺序验证**：记录锁获取顺序，防止违反既定顺序导致的潜在死锁。\n- **中断上下文一致性检查**：利用 `LOCKF_ENABLED_*` 和 `LOCKF_USED_IN_*` 位，确保锁不会在不允许的中断上下文中被获取（如在 hardirq 中获取仅在进程上下文启用的锁）。\n- **性能分析与调试**：通过 `lockdep_stats` 统计 lockdep 自身开销（如链查找效率、冗余检查次数），辅助优化。\n- **内核调试接口**：为 `/proc/lockdep`、`/proc/lockdep_chains` 等提供底层数据支持，供开发者分析锁行为。\n- **内存受限系统适配**：在 SPARC 等平台上，通过 `CONFIG_LOCKDEP_SMALL` 保证 lockdep 功能可用而不突破内存限制。",
      "similarity": 0.5338629484176636,
      "chunks": []
    },
    {
      "source_file": "mm/compaction.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:44:52\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `compaction.c`\n\n---\n\n# compaction.c 技术文档\n\n## 1. 文件概述\n\n`compaction.c` 是 Linux 内核内存管理子系统中实现**内存压缩（Memory Compaction）**功能的核心文件。其主要目标是**减少外部碎片（external fragmentation）**，通过迁移可移动页面，将物理内存中的空闲页聚集形成连续的大块内存区域，从而满足高阶（high-order）内存分配请求（如透明大页 THP 或 HugeTLB）。该机制高度依赖页面迁移（page migration）来完成实际的页面移动工作。\n\n## 2. 核心功能\n\n### 主要函数\n- **`PageMovable()` / `__SetPageMovable()` / `__ClearPageMovable()`**: 管理页面的可移动性标记，用于标识页面是否可通过注册的 `movable_operations` 进行迁移。\n- **`defer_compaction()` / `compaction_deferred()` / `compaction_defer_reset()`**: 实现**压缩延迟（deferred compaction）**机制，避免在压缩失败后频繁重试，提升系统性能。\n- **`compaction_restarting()`**: 判断是否因多次失败后重新启动压缩流程。\n- **`isolation_suitable()`**: 检查指定 pageblock 是否适合进行页面隔离（用于迁移）。\n- **`reset_cached_positions()`**: 重置压缩控制结构中缓存的扫描位置（迁移源和空闲目标页的起始 PFN）。\n- **`release_free_list()`**: 将临时空闲页面列表中的页面释放回伙伴系统。\n- **`skip_offline_sections()` / `skip_offline_sections_reverse()`**: 在 SPARSEMEM 内存模型下跳过离线内存段。\n\n### 关键数据结构与宏\n- **`struct compact_control`**: 压缩操作的控制上下文（定义在 `internal.h` 中），包含扫描范围、迁移/空闲页面列表等。\n- **`COMPACTION_HPAGE_ORDER`**: 用于计算节点/区域“碎片分数（fragmentation score）”的参考阶数，通常为透明大页或 HugeTLB 的阶数。\n- **`COMPACT_MAX_DEFER_SHIFT`**: 压缩延迟的最大次数（64 次）。\n- **`zone->compact_*` 字段**: 包括 `compact_considered`, `compact_defer_shift`, `compact_order_failed`, `compact_cached_*_pfn` 等，用于跟踪压缩状态和优化扫描。\n\n## 3. 关键实现\n\n### 内存压缩流程\n1. **扫描阶段**：从区域两端向中间扫描：\n   - **迁移源扫描器（migrate scanner）**：从低地址向高地址扫描，寻找可迁移的页面。\n   - **空闲目标扫描器（free scanner）**：从高地址向低地址扫描，寻找空闲页面块。\n2. **页面隔离**：将找到的可迁移页面加入迁移列表，空闲页面加入空闲列表。\n3. **页面迁移**：调用 `migrate_pages()` 将迁移列表中的页面移动到空闲列表提供的目标位置。\n4. **结果处理**：迁移成功后，原位置变为空闲，可能形成更大的连续空闲块；失败则回滚。\n\n### 压缩延迟机制（Deferred Compaction）\n- 当压缩未能成功分配指定 `order` 的页面时，调用 `defer_compaction()` 增加延迟计数器 `compact_defer_shift`。\n- 后续分配请求会通过 `compaction_deferred()` 检查是否应跳过压缩（基于 `compact_considered` 计数和 `defer_limit = 1 << compact_defer_shift`）。\n- 若分配成功或预期成功，则通过 `compaction_defer_reset()` 重置延迟状态。\n- 当延迟达到最大值（`COMPACT_MAX_DEFER_SHIFT`）且考虑次数足够多时，`compaction_restarting()` 返回 true，强制重启完整压缩流程。\n\n### 碎片分数与主动压缩\n- 通过 `COMPACTION_HPAGE_ORDER` 定义的阶数评估区域的外部碎片程度。\n- 主动压缩（proactive compaction）定期（`HPAGE_FRAG_CHECK_INTERVAL_MSEC = 500ms`）检查碎片分数，并在需要时触发后台压缩。\n- `is_via_compact_memory()` 用于识别通过 `/proc/sys/vm/compact_memory` 等接口发起的全量压缩请求（`order = -1`）。\n\n### 页面可移动性管理\n- `__SetPageMovable()` 将 `movable_operations` 指针编码到 `page->mapping` 中，并设置 `PAGE_MAPPING_MOVABLE` 标志。\n- `PageMovable()` 验证页面是否被正确标记为可移动，并确保其操作集有效。\n\n## 4. 依赖关系\n\n- **内存管理核心**：依赖 `<linux/mm.h>`, `internal.h`, `mm_inline.h` 提供的伙伴系统、页面分配/释放、zone 管理等基础功能。\n- **页面迁移**：紧密集成 `<linux/migrate.h>`，压缩的核心操作由 `migrate_pages()` 完成。\n- **内存模型**：针对 `CONFIG_SPARSEMEM` 提供离线内存段跳过逻辑。\n- **大页支持**：根据 `CONFIG_TRANSPARENT_HUGEPAGE` 或 `CONFIG_HUGETLBFS` 确定 `COMPACTION_HPAGE_ORDER`。\n- **调试与追踪**：使用 `kasan.h`, `page_owner.h` 进行调试；通过 `trace/events/compaction.h` 提供 ftrace 事件。\n- **系统调用与接口**：通过 sysctl (`/proc/sys/vm/`) 和 sysfs (`/sys/devices/system/node/`) 暴露用户空间控制接口。\n- **进程与调度**：使用 `kthread.h`, `freezer.h` 管理后台压缩线程；`psi.h` 用于压力状态监控。\n\n## 5. 使用场景\n\n1. **高阶内存分配失败时**：当 `alloc_pages()` 请求高阶页面（如 order ≥ 3）失败时，内核会尝试同步内存压缩以满足请求。\n2. **透明大页（THP）分配**：THP 需要连续的 2MB 物理内存，压缩是满足此类请求的关键机制。\n3. **主动后台压缩**：通过 `vm.compaction_proactiveness` sysctl 参数配置，内核定期评估内存碎片并主动压缩，预防分配延迟。\n4. **用户空间触发**：管理员可通过写入 `/proc/sys/vm/compact_memory` 或特定 NUMA 节点的 `compact` sysfs 文件，手动触发全量内存压缩。\n5. **CMA（Contiguous Memory Allocator）**：在 CMA 区域分配大块连续内存前，使用压缩机制迁移占用页面以腾出空间（需 `CONFIG_CMA`）。",
      "similarity": 0.5298998951911926,
      "chunks": [
        {
          "chunk_id": 10,
          "file_path": "mm/compaction.c",
          "start_line": 1888,
          "end_line": 2042,
          "content": [
            "static void compaction_free(struct folio *dst, unsigned long data)",
            "{",
            "\tstruct compact_control *cc = (struct compact_control *)data;",
            "\tint order = folio_order(dst);",
            "\tstruct page *page = &dst->page;",
            "",
            "\tif (folio_put_testzero(dst)) {",
            "\t\tfree_pages_prepare(page, order);",
            "\t\tlist_add(&dst->lru, &cc->freepages[order]);",
            "\t\tcc->nr_freepages += 1 << order;",
            "\t}",
            "\tcc->nr_migratepages += 1 << order;",
            "\t/*",
            "\t * someone else has referenced the page, we cannot take it back to our",
            "\t * free list.",
            "\t */",
            "}",
            "static inline void",
            "update_fast_start_pfn(struct compact_control *cc, unsigned long pfn)",
            "{",
            "\tif (cc->fast_start_pfn == ULONG_MAX)",
            "\t\treturn;",
            "",
            "\tif (!cc->fast_start_pfn)",
            "\t\tcc->fast_start_pfn = pfn;",
            "",
            "\tcc->fast_start_pfn = min(cc->fast_start_pfn, pfn);",
            "}",
            "static inline unsigned long",
            "reinit_migrate_pfn(struct compact_control *cc)",
            "{",
            "\tif (!cc->fast_start_pfn || cc->fast_start_pfn == ULONG_MAX)",
            "\t\treturn cc->migrate_pfn;",
            "",
            "\tcc->migrate_pfn = cc->fast_start_pfn;",
            "\tcc->fast_start_pfn = ULONG_MAX;",
            "",
            "\treturn cc->migrate_pfn;",
            "}",
            "static unsigned long fast_find_migrateblock(struct compact_control *cc)",
            "{",
            "\tunsigned int limit = freelist_scan_limit(cc);",
            "\tunsigned int nr_scanned = 0;",
            "\tunsigned long distance;",
            "\tunsigned long pfn = cc->migrate_pfn;",
            "\tunsigned long high_pfn;",
            "\tint order;",
            "\tbool found_block = false;",
            "",
            "\t/* Skip hints are relied on to avoid repeats on the fast search */",
            "\tif (cc->ignore_skip_hint)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * If the pageblock should be finished then do not select a different",
            "\t * pageblock.",
            "\t */",
            "\tif (cc->finish_pageblock)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * If the migrate_pfn is not at the start of a zone or the start",
            "\t * of a pageblock then assume this is a continuation of a previous",
            "\t * scan restarted due to COMPACT_CLUSTER_MAX.",
            "\t */",
            "\tif (pfn != cc->zone->zone_start_pfn && pfn != pageblock_start_pfn(pfn))",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * For smaller orders, just linearly scan as the number of pages",
            "\t * to migrate should be relatively small and does not necessarily",
            "\t * justify freeing up a large block for a small allocation.",
            "\t */",
            "\tif (cc->order <= PAGE_ALLOC_COSTLY_ORDER)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * Only allow kcompactd and direct requests for movable pages to",
            "\t * quickly clear out a MOVABLE pageblock for allocation. This",
            "\t * reduces the risk that a large movable pageblock is freed for",
            "\t * an unmovable/reclaimable small allocation.",
            "\t */",
            "\tif (cc->direct_compaction && cc->migratetype != MIGRATE_MOVABLE)",
            "\t\treturn pfn;",
            "",
            "\t/*",
            "\t * When starting the migration scanner, pick any pageblock within the",
            "\t * first half of the search space. Otherwise try and pick a pageblock",
            "\t * within the first eighth to reduce the chances that a migration",
            "\t * target later becomes a source.",
            "\t */",
            "\tdistance = (cc->free_pfn - cc->migrate_pfn) >> 1;",
            "\tif (cc->migrate_pfn != cc->zone->zone_start_pfn)",
            "\t\tdistance >>= 2;",
            "\thigh_pfn = pageblock_start_pfn(cc->migrate_pfn + distance);",
            "",
            "\tfor (order = cc->order - 1;",
            "\t     order >= PAGE_ALLOC_COSTLY_ORDER && !found_block && nr_scanned < limit;",
            "\t     order--) {",
            "\t\tstruct free_area *area = &cc->zone->free_area[order];",
            "\t\tstruct list_head *freelist;",
            "\t\tunsigned long flags;",
            "\t\tstruct page *freepage;",
            "",
            "\t\tif (!area->nr_free)",
            "\t\t\tcontinue;",
            "",
            "\t\tspin_lock_irqsave(&cc->zone->lock, flags);",
            "\t\tfreelist = &area->free_list[MIGRATE_MOVABLE];",
            "\t\tlist_for_each_entry(freepage, freelist, buddy_list) {",
            "\t\t\tunsigned long free_pfn;",
            "",
            "\t\t\tif (nr_scanned++ >= limit) {",
            "\t\t\t\tmove_freelist_tail(freelist, freepage);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "",
            "\t\t\tfree_pfn = page_to_pfn(freepage);",
            "\t\t\tif (free_pfn < high_pfn) {",
            "\t\t\t\t/*",
            "\t\t\t\t * Avoid if skipped recently. Ideally it would",
            "\t\t\t\t * move to the tail but even safe iteration of",
            "\t\t\t\t * the list assumes an entry is deleted, not",
            "\t\t\t\t * reordered.",
            "\t\t\t\t */",
            "\t\t\t\tif (get_pageblock_skip(freepage))",
            "\t\t\t\t\tcontinue;",
            "",
            "\t\t\t\t/* Reorder to so a future search skips recent pages */",
            "\t\t\t\tmove_freelist_tail(freelist, freepage);",
            "",
            "\t\t\t\tupdate_fast_start_pfn(cc, free_pfn);",
            "\t\t\t\tpfn = pageblock_start_pfn(free_pfn);",
            "\t\t\t\tif (pfn < cc->zone->zone_start_pfn)",
            "\t\t\t\t\tpfn = cc->zone->zone_start_pfn;",
            "\t\t\t\tcc->fast_search_fail = 0;",
            "\t\t\t\tfound_block = true;",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t}",
            "\t\tspin_unlock_irqrestore(&cc->zone->lock, flags);",
            "\t}",
            "",
            "\tcc->total_migrate_scanned += nr_scanned;",
            "",
            "\t/*",
            "\t * If fast scanning failed then use a cached entry for a page block",
            "\t * that had free pages as the basis for starting a linear scan.",
            "\t */",
            "\tif (!found_block) {",
            "\t\tcc->fast_search_fail++;",
            "\t\tpfn = reinit_migrate_pfn(cc);",
            "\t}",
            "\treturn pfn;",
            "}"
          ],
          "function_name": "compaction_free, update_fast_start_pfn, reinit_migrate_pfn, fast_find_migrateblock",
          "description": "实现内存碎片整理中页面释放与迁移扫描逻辑，compaction_free处理页面回收，update_fast_start_pfn维护快速扫描起点，reinit_migrate_pfn重置迁移扫描位置，fast_find_migrateblock寻找适合迁移的页块，优先考虑可移动类型且未被跳过的页块",
          "similarity": 0.48048165440559387
        },
        {
          "chunk_id": 3,
          "file_path": "mm/compaction.c",
          "start_line": 380,
          "end_line": 487,
          "content": [
            "static void __reset_isolation_suitable(struct zone *zone)",
            "{",
            "\tunsigned long migrate_pfn = zone->zone_start_pfn;",
            "\tunsigned long free_pfn = zone_end_pfn(zone) - 1;",
            "\tunsigned long reset_migrate = free_pfn;",
            "\tunsigned long reset_free = migrate_pfn;",
            "\tbool source_set = false;",
            "\tbool free_set = false;",
            "",
            "\t/* Only flush if a full compaction finished recently */",
            "\tif (!zone->compact_blockskip_flush)",
            "\t\treturn;",
            "",
            "\tzone->compact_blockskip_flush = false;",
            "",
            "\t/*",
            "\t * Walk the zone and update pageblock skip information. Source looks",
            "\t * for PageLRU while target looks for PageBuddy. When the scanner",
            "\t * is found, both PageBuddy and PageLRU are checked as the pageblock",
            "\t * is suitable as both source and target.",
            "\t */",
            "\tfor (; migrate_pfn < free_pfn; migrate_pfn += pageblock_nr_pages,",
            "\t\t\t\t\tfree_pfn -= pageblock_nr_pages) {",
            "\t\tcond_resched();",
            "",
            "\t\t/* Update the migrate PFN */",
            "\t\tif (__reset_isolation_pfn(zone, migrate_pfn, true, source_set) &&",
            "\t\t    migrate_pfn < reset_migrate) {",
            "\t\t\tsource_set = true;",
            "\t\t\treset_migrate = migrate_pfn;",
            "\t\t\tzone->compact_init_migrate_pfn = reset_migrate;",
            "\t\t\tzone->compact_cached_migrate_pfn[0] = reset_migrate;",
            "\t\t\tzone->compact_cached_migrate_pfn[1] = reset_migrate;",
            "\t\t}",
            "",
            "\t\t/* Update the free PFN */",
            "\t\tif (__reset_isolation_pfn(zone, free_pfn, free_set, true) &&",
            "\t\t    free_pfn > reset_free) {",
            "\t\t\tfree_set = true;",
            "\t\t\treset_free = free_pfn;",
            "\t\t\tzone->compact_init_free_pfn = reset_free;",
            "\t\t\tzone->compact_cached_free_pfn = reset_free;",
            "\t\t}",
            "\t}",
            "",
            "\t/* Leave no distance if no suitable block was reset */",
            "\tif (reset_migrate >= reset_free) {",
            "\t\tzone->compact_cached_migrate_pfn[0] = migrate_pfn;",
            "\t\tzone->compact_cached_migrate_pfn[1] = migrate_pfn;",
            "\t\tzone->compact_cached_free_pfn = free_pfn;",
            "\t}",
            "}",
            "void reset_isolation_suitable(pg_data_t *pgdat)",
            "{",
            "\tint zoneid;",
            "",
            "\tfor (zoneid = 0; zoneid < MAX_NR_ZONES; zoneid++) {",
            "\t\tstruct zone *zone = &pgdat->node_zones[zoneid];",
            "\t\tif (!populated_zone(zone))",
            "\t\t\tcontinue;",
            "",
            "\t\t__reset_isolation_suitable(zone);",
            "\t}",
            "}",
            "static bool test_and_set_skip(struct compact_control *cc, struct page *page)",
            "{",
            "\tbool skip;",
            "",
            "\t/* Do not update if skip hint is being ignored */",
            "\tif (cc->ignore_skip_hint)",
            "\t\treturn false;",
            "",
            "\tskip = get_pageblock_skip(page);",
            "\tif (!skip && !cc->no_set_skip_hint)",
            "\t\tset_pageblock_skip(page);",
            "",
            "\treturn skip;",
            "}",
            "static void update_cached_migrate(struct compact_control *cc, unsigned long pfn)",
            "{",
            "\tstruct zone *zone = cc->zone;",
            "",
            "\t/* Set for isolation rather than compaction */",
            "\tif (cc->no_set_skip_hint)",
            "\t\treturn;",
            "",
            "\tpfn = pageblock_end_pfn(pfn);",
            "",
            "\t/* Update where async and sync compaction should restart */",
            "\tif (pfn > zone->compact_cached_migrate_pfn[0])",
            "\t\tzone->compact_cached_migrate_pfn[0] = pfn;",
            "\tif (cc->mode != MIGRATE_ASYNC &&",
            "\t    pfn > zone->compact_cached_migrate_pfn[1])",
            "\t\tzone->compact_cached_migrate_pfn[1] = pfn;",
            "}",
            "static void update_pageblock_skip(struct compact_control *cc,",
            "\t\t\tstruct page *page, unsigned long pfn)",
            "{",
            "\tstruct zone *zone = cc->zone;",
            "",
            "\tif (cc->no_set_skip_hint)",
            "\t\treturn;",
            "",
            "\tset_pageblock_skip(page);",
            "",
            "\tif (pfn < zone->compact_cached_free_pfn)",
            "\t\tzone->compact_cached_free_pfn = pfn;",
            "}"
          ],
          "function_name": "__reset_isolation_suitable, reset_isolation_suitable, test_and_set_skip, update_cached_migrate, update_pageblock_skip",
          "description": "遍历zone更新隔离信息，维护迁移/自由缓存位置，提供跳过标志测试与设置接口，用于动态调整压缩策略",
          "similarity": 0.47960364818573
        },
        {
          "chunk_id": 2,
          "file_path": "mm/compaction.c",
          "start_line": 209,
          "end_line": 347,
          "content": [
            "static bool compaction_restarting(struct zone *zone, int order)",
            "{",
            "\tif (order < zone->compact_order_failed)",
            "\t\treturn false;",
            "",
            "\treturn zone->compact_defer_shift == COMPACT_MAX_DEFER_SHIFT &&",
            "\t\tzone->compact_considered >= 1UL << zone->compact_defer_shift;",
            "}",
            "static inline bool isolation_suitable(struct compact_control *cc,",
            "\t\t\t\t\tstruct page *page)",
            "{",
            "\tif (cc->ignore_skip_hint)",
            "\t\treturn true;",
            "",
            "\treturn !get_pageblock_skip(page);",
            "}",
            "static void reset_cached_positions(struct zone *zone)",
            "{",
            "\tzone->compact_cached_migrate_pfn[0] = zone->zone_start_pfn;",
            "\tzone->compact_cached_migrate_pfn[1] = zone->zone_start_pfn;",
            "\tzone->compact_cached_free_pfn =",
            "\t\t\t\tpageblock_start_pfn(zone_end_pfn(zone) - 1);",
            "}",
            "static unsigned long skip_offline_sections(unsigned long start_pfn)",
            "{",
            "\tunsigned long start_nr = pfn_to_section_nr(start_pfn);",
            "",
            "\tif (online_section_nr(start_nr))",
            "\t\treturn 0;",
            "",
            "\twhile (++start_nr <= __highest_present_section_nr) {",
            "\t\tif (online_section_nr(start_nr))",
            "\t\t\treturn section_nr_to_pfn(start_nr);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static unsigned long skip_offline_sections_reverse(unsigned long start_pfn)",
            "{",
            "\tunsigned long start_nr = pfn_to_section_nr(start_pfn);",
            "",
            "\tif (!start_nr || online_section_nr(start_nr))",
            "\t\treturn 0;",
            "",
            "\twhile (start_nr-- > 0) {",
            "\t\tif (online_section_nr(start_nr))",
            "\t\t\treturn section_nr_to_pfn(start_nr) + PAGES_PER_SECTION;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static unsigned long skip_offline_sections(unsigned long start_pfn)",
            "{",
            "\treturn 0;",
            "}",
            "static unsigned long skip_offline_sections_reverse(unsigned long start_pfn)",
            "{",
            "\treturn 0;",
            "}",
            "static bool pageblock_skip_persistent(struct page *page)",
            "{",
            "\tif (!PageCompound(page))",
            "\t\treturn false;",
            "",
            "\tpage = compound_head(page);",
            "",
            "\tif (compound_order(page) >= pageblock_order)",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "static bool",
            "__reset_isolation_pfn(struct zone *zone, unsigned long pfn, bool check_source,",
            "\t\t\t\t\t\t\tbool check_target)",
            "{",
            "\tstruct page *page = pfn_to_online_page(pfn);",
            "\tstruct page *block_page;",
            "\tstruct page *end_page;",
            "\tunsigned long block_pfn;",
            "",
            "\tif (!page)",
            "\t\treturn false;",
            "\tif (zone != page_zone(page))",
            "\t\treturn false;",
            "\tif (pageblock_skip_persistent(page))",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * If skip is already cleared do no further checking once the",
            "\t * restart points have been set.",
            "\t */",
            "\tif (check_source && check_target && !get_pageblock_skip(page))",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * If clearing skip for the target scanner, do not select a",
            "\t * non-movable pageblock as the starting point.",
            "\t */",
            "\tif (!check_source && check_target &&",
            "\t    get_pageblock_migratetype(page) != MIGRATE_MOVABLE)",
            "\t\treturn false;",
            "",
            "\t/* Ensure the start of the pageblock or zone is online and valid */",
            "\tblock_pfn = pageblock_start_pfn(pfn);",
            "\tblock_pfn = max(block_pfn, zone->zone_start_pfn);",
            "\tblock_page = pfn_to_online_page(block_pfn);",
            "\tif (block_page) {",
            "\t\tpage = block_page;",
            "\t\tpfn = block_pfn;",
            "\t}",
            "",
            "\t/* Ensure the end of the pageblock or zone is online and valid */",
            "\tblock_pfn = pageblock_end_pfn(pfn) - 1;",
            "\tblock_pfn = min(block_pfn, zone_end_pfn(zone) - 1);",
            "\tend_page = pfn_to_online_page(block_pfn);",
            "\tif (!end_page)",
            "\t\treturn false;",
            "",
            "\t/*",
            "\t * Only clear the hint if a sample indicates there is either a",
            "\t * free page or an LRU page in the block. One or other condition",
            "\t * is necessary for the block to be a migration source/target.",
            "\t */",
            "\tdo {",
            "\t\tif (check_source && PageLRU(page)) {",
            "\t\t\tclear_pageblock_skip(page);",
            "\t\t\treturn true;",
            "\t\t}",
            "",
            "\t\tif (check_target && PageBuddy(page)) {",
            "\t\t\tclear_pageblock_skip(page);",
            "\t\t\treturn true;",
            "\t\t}",
            "",
            "\t\tpage += (1 << PAGE_ALLOC_COSTLY_ORDER);",
            "\t} while (page <= end_page);",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "compaction_restarting, isolation_suitable, reset_cached_positions, skip_offline_sections, skip_offline_sections_reverse, skip_offline_sections, skip_offline_sections_reverse, pageblock_skip_persistent, __reset_isolation_pfn",
          "description": "实现压缩重启条件判定、隔离兼容性检查、跳过离线section、页面块持久性跳过标记及隔离信息更新功能",
          "similarity": 0.47587329149246216
        },
        {
          "chunk_id": 0,
          "file_path": "mm/compaction.c",
          "start_line": 1,
          "end_line": 33,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * linux/mm/compaction.c",
            " *",
            " * Memory compaction for the reduction of external fragmentation. Note that",
            " * this heavily depends upon page migration to do all the real heavy",
            " * lifting",
            " *",
            " * Copyright IBM Corp. 2007-2010 Mel Gorman <mel@csn.ul.ie>",
            " */",
            "#include <linux/cpu.h>",
            "#include <linux/swap.h>",
            "#include <linux/migrate.h>",
            "#include <linux/compaction.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/page-isolation.h>",
            "#include <linux/kasan.h>",
            "#include <linux/kthread.h>",
            "#include <linux/freezer.h>",
            "#include <linux/page_owner.h>",
            "#include <linux/psi.h>",
            "#include \"internal.h\"",
            "",
            "#ifdef CONFIG_COMPACTION",
            "/*",
            " * Fragmentation score check interval for proactive compaction purposes.",
            " */",
            "#define HPAGE_FRAG_CHECK_INTERVAL_MSEC\t(500)",
            ""
          ],
          "function_name": null,
          "description": "声明内存压缩模块的头文件，包含相关依赖和定义，启用CONFIG_COMPACTION配置项，定义HPAGE_FRAG_CHECK_INTERVAL_MSEC常量用于主动压缩时间间隔",
          "similarity": 0.47434306144714355
        },
        {
          "chunk_id": 14,
          "file_path": "mm/compaction.c",
          "start_line": 2489,
          "end_line": 2740,
          "content": [
            "static enum compact_result",
            "compaction_suit_allocation_order(struct zone *zone, unsigned int order,",
            "\t\t\t\t int highest_zoneidx, unsigned int alloc_flags)",
            "{",
            "\tunsigned long watermark;",
            "",
            "\twatermark = wmark_pages(zone, alloc_flags & ALLOC_WMARK_MASK);",
            "\tif (zone_watermark_ok(zone, order, watermark, highest_zoneidx,",
            "\t\t\t      alloc_flags))",
            "\t\treturn COMPACT_SUCCESS;",
            "",
            "\tif (!compaction_suitable(zone, order, highest_zoneidx))",
            "\t\treturn COMPACT_SKIPPED;",
            "",
            "\treturn COMPACT_CONTINUE;",
            "}",
            "static enum compact_result",
            "compact_zone(struct compact_control *cc, struct capture_control *capc)",
            "{",
            "\tenum compact_result ret;",
            "\tunsigned long start_pfn = cc->zone->zone_start_pfn;",
            "\tunsigned long end_pfn = zone_end_pfn(cc->zone);",
            "\tunsigned long last_migrated_pfn;",
            "\tconst bool sync = cc->mode != MIGRATE_ASYNC;",
            "\tbool update_cached;",
            "\tunsigned int nr_succeeded = 0, nr_migratepages;",
            "\tint order;",
            "",
            "\t/*",
            "\t * These counters track activities during zone compaction.  Initialize",
            "\t * them before compacting a new zone.",
            "\t */",
            "\tcc->total_migrate_scanned = 0;",
            "\tcc->total_free_scanned = 0;",
            "\tcc->nr_migratepages = 0;",
            "\tcc->nr_freepages = 0;",
            "\tfor (order = 0; order < NR_PAGE_ORDERS; order++)",
            "\t\tINIT_LIST_HEAD(&cc->freepages[order]);",
            "\tINIT_LIST_HEAD(&cc->migratepages);",
            "",
            "\tcc->migratetype = gfp_migratetype(cc->gfp_mask);",
            "",
            "\tif (!is_via_compact_memory(cc->order)) {",
            "\t\tret = compaction_suit_allocation_order(cc->zone, cc->order,",
            "\t\t\t\t\t\t       cc->highest_zoneidx,",
            "\t\t\t\t\t\t       cc->alloc_flags);",
            "\t\tif (ret != COMPACT_CONTINUE)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\t/*",
            "\t * Clear pageblock skip if there were failures recently and compaction",
            "\t * is about to be retried after being deferred.",
            "\t */",
            "\tif (compaction_restarting(cc->zone, cc->order))",
            "\t\t__reset_isolation_suitable(cc->zone);",
            "",
            "\t/*",
            "\t * Setup to move all movable pages to the end of the zone. Used cached",
            "\t * information on where the scanners should start (unless we explicitly",
            "\t * want to compact the whole zone), but check that it is initialised",
            "\t * by ensuring the values are within zone boundaries.",
            "\t */",
            "\tcc->fast_start_pfn = 0;",
            "\tif (cc->whole_zone) {",
            "\t\tcc->migrate_pfn = start_pfn;",
            "\t\tcc->free_pfn = pageblock_start_pfn(end_pfn - 1);",
            "\t} else {",
            "\t\tcc->migrate_pfn = cc->zone->compact_cached_migrate_pfn[sync];",
            "\t\tcc->free_pfn = cc->zone->compact_cached_free_pfn;",
            "\t\tif (cc->free_pfn < start_pfn || cc->free_pfn >= end_pfn) {",
            "\t\t\tcc->free_pfn = pageblock_start_pfn(end_pfn - 1);",
            "\t\t\tcc->zone->compact_cached_free_pfn = cc->free_pfn;",
            "\t\t}",
            "\t\tif (cc->migrate_pfn < start_pfn || cc->migrate_pfn >= end_pfn) {",
            "\t\t\tcc->migrate_pfn = start_pfn;",
            "\t\t\tcc->zone->compact_cached_migrate_pfn[0] = cc->migrate_pfn;",
            "\t\t\tcc->zone->compact_cached_migrate_pfn[1] = cc->migrate_pfn;",
            "\t\t}",
            "",
            "\t\tif (cc->migrate_pfn <= cc->zone->compact_init_migrate_pfn)",
            "\t\t\tcc->whole_zone = true;",
            "\t}",
            "",
            "\tlast_migrated_pfn = 0;",
            "",
            "\t/*",
            "\t * Migrate has separate cached PFNs for ASYNC and SYNC* migration on",
            "\t * the basis that some migrations will fail in ASYNC mode. However,",
            "\t * if the cached PFNs match and pageblocks are skipped due to having",
            "\t * no isolation candidates, then the sync state does not matter.",
            "\t * Until a pageblock with isolation candidates is found, keep the",
            "\t * cached PFNs in sync to avoid revisiting the same blocks.",
            "\t */",
            "\tupdate_cached = !sync &&",
            "\t\tcc->zone->compact_cached_migrate_pfn[0] == cc->zone->compact_cached_migrate_pfn[1];",
            "",
            "\ttrace_mm_compaction_begin(cc, start_pfn, end_pfn, sync);",
            "",
            "\t/* lru_add_drain_all could be expensive with involving other CPUs */",
            "\tlru_add_drain();",
            "",
            "\twhile ((ret = compact_finished(cc)) == COMPACT_CONTINUE) {",
            "\t\tint err;",
            "\t\tunsigned long iteration_start_pfn = cc->migrate_pfn;",
            "",
            "\t\t/*",
            "\t\t * Avoid multiple rescans of the same pageblock which can",
            "\t\t * happen if a page cannot be isolated (dirty/writeback in",
            "\t\t * async mode) or if the migrated pages are being allocated",
            "\t\t * before the pageblock is cleared.  The first rescan will",
            "\t\t * capture the entire pageblock for migration. If it fails,",
            "\t\t * it'll be marked skip and scanning will proceed as normal.",
            "\t\t */",
            "\t\tcc->finish_pageblock = false;",
            "\t\tif (pageblock_start_pfn(last_migrated_pfn) ==",
            "\t\t    pageblock_start_pfn(iteration_start_pfn)) {",
            "\t\t\tcc->finish_pageblock = true;",
            "\t\t}",
            "",
            "rescan:",
            "\t\tswitch (isolate_migratepages(cc)) {",
            "\t\tcase ISOLATE_ABORT:",
            "\t\t\tret = COMPACT_CONTENDED;",
            "\t\t\tputback_movable_pages(&cc->migratepages);",
            "\t\t\tcc->nr_migratepages = 0;",
            "\t\t\tgoto out;",
            "\t\tcase ISOLATE_NONE:",
            "\t\t\tif (update_cached) {",
            "\t\t\t\tcc->zone->compact_cached_migrate_pfn[1] =",
            "\t\t\t\t\tcc->zone->compact_cached_migrate_pfn[0];",
            "\t\t\t}",
            "",
            "\t\t\t/*",
            "\t\t\t * We haven't isolated and migrated anything, but",
            "\t\t\t * there might still be unflushed migrations from",
            "\t\t\t * previous cc->order aligned block.",
            "\t\t\t */",
            "\t\t\tgoto check_drain;",
            "\t\tcase ISOLATE_SUCCESS:",
            "\t\t\tupdate_cached = false;",
            "\t\t\tlast_migrated_pfn = max(cc->zone->zone_start_pfn,",
            "\t\t\t\tpageblock_start_pfn(cc->migrate_pfn - 1));",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Record the number of pages to migrate since the",
            "\t\t * compaction_alloc/free() will update cc->nr_migratepages",
            "\t\t * properly.",
            "\t\t */",
            "\t\tnr_migratepages = cc->nr_migratepages;",
            "\t\terr = migrate_pages(&cc->migratepages, compaction_alloc,",
            "\t\t\t\tcompaction_free, (unsigned long)cc, cc->mode,",
            "\t\t\t\tMR_COMPACTION, &nr_succeeded);",
            "",
            "\t\ttrace_mm_compaction_migratepages(nr_migratepages, nr_succeeded);",
            "",
            "\t\t/* All pages were either migrated or will be released */",
            "\t\tcc->nr_migratepages = 0;",
            "\t\tif (err) {",
            "\t\t\tputback_movable_pages(&cc->migratepages);",
            "\t\t\t/*",
            "\t\t\t * migrate_pages() may return -ENOMEM when scanners meet",
            "\t\t\t * and we want compact_finished() to detect it",
            "\t\t\t */",
            "\t\t\tif (err == -ENOMEM && !compact_scanners_met(cc)) {",
            "\t\t\t\tret = COMPACT_CONTENDED;",
            "\t\t\t\tgoto out;",
            "\t\t\t}",
            "\t\t\t/*",
            "\t\t\t * If an ASYNC or SYNC_LIGHT fails to migrate a page",
            "\t\t\t * within the pageblock_order-aligned block and",
            "\t\t\t * fast_find_migrateblock may be used then scan the",
            "\t\t\t * remainder of the pageblock. This will mark the",
            "\t\t\t * pageblock \"skip\" to avoid rescanning in the near",
            "\t\t\t * future. This will isolate more pages than necessary",
            "\t\t\t * for the request but avoid loops due to",
            "\t\t\t * fast_find_migrateblock revisiting blocks that were",
            "\t\t\t * recently partially scanned.",
            "\t\t\t */",
            "\t\t\tif (!pageblock_aligned(cc->migrate_pfn) &&",
            "\t\t\t    !cc->ignore_skip_hint && !cc->finish_pageblock &&",
            "\t\t\t    (cc->mode < MIGRATE_SYNC)) {",
            "\t\t\t\tcc->finish_pageblock = true;",
            "",
            "\t\t\t\t/*",
            "\t\t\t\t * Draining pcplists does not help THP if",
            "\t\t\t\t * any page failed to migrate. Even after",
            "\t\t\t\t * drain, the pageblock will not be free.",
            "\t\t\t\t */",
            "\t\t\t\tif (cc->order == COMPACTION_HPAGE_ORDER)",
            "\t\t\t\t\tlast_migrated_pfn = 0;",
            "",
            "\t\t\t\tgoto rescan;",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\t/* Stop if a page has been captured */",
            "\t\tif (capc && capc->page) {",
            "\t\t\tret = COMPACT_SUCCESS;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "check_drain:",
            "\t\t/*",
            "\t\t * Has the migration scanner moved away from the previous",
            "\t\t * cc->order aligned block where we migrated from? If yes,",
            "\t\t * flush the pages that were freed, so that they can merge and",
            "\t\t * compact_finished() can detect immediately if allocation",
            "\t\t * would succeed.",
            "\t\t */",
            "\t\tif (cc->order > 0 && last_migrated_pfn) {",
            "\t\t\tunsigned long current_block_start =",
            "\t\t\t\tblock_start_pfn(cc->migrate_pfn, cc->order);",
            "",
            "\t\t\tif (last_migrated_pfn < current_block_start) {",
            "\t\t\t\tlru_add_drain_cpu_zone(cc->zone);",
            "\t\t\t\t/* No more flushing until we migrate again */",
            "\t\t\t\tlast_migrated_pfn = 0;",
            "\t\t\t}",
            "\t\t}",
            "\t}",
            "",
            "out:",
            "\t/*",
            "\t * Release free pages and update where the free scanner should restart,",
            "\t * so we don't leave any returned pages behind in the next attempt.",
            "\t */",
            "\tif (cc->nr_freepages > 0) {",
            "\t\tunsigned long free_pfn = release_free_list(cc->freepages);",
            "",
            "\t\tcc->nr_freepages = 0;",
            "\t\tVM_BUG_ON(free_pfn == 0);",
            "\t\t/* The cached pfn is always the first in a pageblock */",
            "\t\tfree_pfn = pageblock_start_pfn(free_pfn);",
            "\t\t/*",
            "\t\t * Only go back, not forward. The cached pfn might have been",
            "\t\t * already reset to zone end in compact_finished()",
            "\t\t */",
            "\t\tif (free_pfn > cc->zone->compact_cached_free_pfn)",
            "\t\t\tcc->zone->compact_cached_free_pfn = free_pfn;",
            "\t}",
            "",
            "\tcount_compact_events(COMPACTMIGRATE_SCANNED, cc->total_migrate_scanned);",
            "\tcount_compact_events(COMPACTFREE_SCANNED, cc->total_free_scanned);",
            "",
            "\ttrace_mm_compaction_end(cc, start_pfn, end_pfn, sync, ret);",
            "",
            "\tVM_BUG_ON(!list_empty(&cc->migratepages));",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "compaction_suit_allocation_order, compact_zone",
          "description": "compaction_suit_allocation_order检查分配顺序兼容性，compact_zone执行核心压缩流程，迁移页面并调整缓存扫描起点，处理页块扫描和迁移结果",
          "similarity": 0.4687938094139099
        }
      ]
    },
    {
      "source_file": "kernel/kexec_handover.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:26:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kexec_handover.c`\n\n---\n\n# kexec_handover.c 技术文档\n\n## 文件概述\n\n`kexec_handover.c` 实现了 **Kexec Handover (KHO)** 机制中的内存保留元数据处理功能。该机制允许在通过 `kexec` 加载新内核时，将当前内核中某些关键内存区域（如已分配的页）的状态信息传递给后继内核，从而实现内存状态的延续。本文件主要负责：\n\n- 跟踪需跨内核保留的物理内存页（按分配阶 order 分类）\n- 使用两级 `xarray` 高效管理稀疏位图\n- 将内存保留信息序列化为链表结构，嵌入到设备树（FDT）中供后继内核解析\n- 提供接口供后继内核恢复 `struct folio` 对象\n\n## 核心功能\n\n### 主要数据结构\n\n| 结构体 | 说明 |\n|--------|------|\n| `kho_mem_phys_bits` | 包含 4096 位（512 字节）的位图，用于标记某一段物理地址范围内哪些页需保留 |\n| `kho_mem_phys` | 按物理地址分块管理 `kho_mem_phys_bits`，使用 `xarray` 实现稀疏存储 |\n| `kho_mem_track` | 按分配阶（order）组织多个 `kho_mem_phys`，顶层使用 `xarray` 索引 |\n| `khoser_mem_chunk` | 序列化后的内存保留信息块，每页大小，包含多个位图指针及起始物理地址 |\n| `kho_serialization` | KHO 序列化上下文，包含 FDT、调试目录及内存跟踪结构 |\n\n### 主要函数\n\n| 函数 | 功能 |\n|------|------|\n| `kho_is_enabled()` | 查询 KHO 功能是否启用（通过 `kho=` 内核参数控制） |\n| `__kho_preserve_order()` | 将指定 PFN 和 order 的内存标记为需保留 |\n| `__kho_unpreserve()` | 取消对指定物理页范围的保留标记 |\n| `kho_restore_folio()` | 根据物理地址恢复 `struct folio`，供后继内核使用 |\n| `kho_mem_serialize()` | 将 `xarray` 中的保留内存信息序列化为页链表 |\n| `xa_load_or_alloc()` | 辅助函数：若 `xarray` 中无元素则分配并插入 |\n\n## 关键实现\n\n### 两级稀疏位图管理\n\n为高效跟踪大内存系统中稀疏分布的保留页，KHO 采用两级 `xarray` 结构：\n\n1. **第一级（按 order 索引）**：`kho_mem_track::orders`，键为分配阶（0 ~ MAX_ORDER）\n2. **第二级（按高地址索引）**：每个 order 对应一个 `kho_mem_phys::phys_bits`，键为 `pfn_high / 4096`（即每 4096 个高位 PFN 一组）\n\n每个位图块（`kho_mem_phys_bits`）管理 `4096 << (order + PAGE_SHIFT)` 字节的物理地址空间。例如：\n- order=0（4KB 页）：每块覆盖 16MB\n- order=9（2MB 页）：每块覆盖 8GB\n\n### 序列化为页链表\n\n在 `kexec` 前，调用 `kho_mem_serialize()` 将 `xarray` 转换为连续的页链表（`khoser_mem_chunk`），每页结构如下：\n\n```c\nstruct khoser_mem_chunk {\n    struct khoser_mem_chunk_hdr hdr;  // 包含 next 指针、order、元素数量\n    struct khoser_mem_bitmap_ptr bitmaps[KHOSER_BITMAP_SIZE]; // 最多 508 个条目（4KB 页）\n};\n```\n\n每个 `khoser_mem_bitmap_ptr` 记录：\n- `phys_start`：该位图对应的起始物理地址\n- `bitmap`：指向 `kho_mem_phys_bits` 的指针（使用 `KHOSER_STORE_PTR` 宏处理指针序列化）\n\n### 内存恢复机制\n\n后继内核通过 `kho_restore_folio(phys)` 恢复页：\n1. 通过 `pfn_to_online_page()` 获取 `struct page`\n2. 若为高阶页（`page->private != 0`），调用 `prep_compound_page()` 初始化复合页\n3. 若为普通页，调用 `kho_restore_page()` 清除 `PG_reserved` 并调整页计数器\n\n## 依赖关系\n\n### 内核头文件依赖\n- `<linux/kexec.h>`：kexec 核心接口\n- `<linux/xarray.h>`（隐式通过 `xarray.h`）：稀疏数组管理\n- `<linux/page-isolation.h>`：页隔离与释放\n- `<linux/libfdt.h>`：设备树操作\n- `\"../mm/internal.h\"`：访问内存管理内部 API（如 `prep_compound_page`）\n- `\"kexec_internal.h\"`：kexec 内部实现\n\n### 架构依赖\n- `asm/early_ioremap.h`：早期 I/O 映射（用于访问保留内存）\n- `PAGE_SHIFT` / `MAX_PAGE_ORDER`：架构相关页大小定义\n\n### 导出符号\n- `kho_is_enabled()`：供其他模块查询 KHO 状态\n- `kho_restore_folio()`：供后继内核恢复页结构\n\n## 使用场景\n\n1. **Kexec 内核热替换**  \n   当系统通过 `kexec -e` 切换到新内核时，当前内核将关键内存（如 CMA 区域、已分配的 DMA 缓冲区）标记为保留，并通过 FDT 传递元数据。\n\n2. **内存状态延续**  \n   后继内核启动早期（在内存初始化完成前）解析 FDT 中的 `preserved-memory-map` 属性，调用 `kho_restore_folio()` 恢复页描述符，避免重复分配或覆盖关键数据。\n\n3. **调试与验证**  \n   通过 debugfs 挂载点（`sub_fdt_dir`）可检查序列化后的 FDT 子树，验证保留内存信息的正确性。\n\n4. **大内存系统优化**  \n   在 TB 级内存系统中，两级位图设计确保内存开销可控（例如 16GB 内存仅需 512KB 位图跟踪 order=0 页）。",
      "similarity": 0.5289648771286011,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/kexec_handover.c",
          "start_line": 37,
          "end_line": 137,
          "content": [
            "bool kho_is_enabled(void)",
            "{",
            "\treturn kho_enable;",
            "}",
            "static int __init kho_parse_enable(char *p)",
            "{",
            "\treturn kstrtobool(p, &kho_enable);",
            "}",
            "static void __kho_unpreserve(struct kho_mem_track *track, unsigned long pfn,",
            "\t\t\t     unsigned long end_pfn)",
            "{",
            "\tstruct kho_mem_phys_bits *bits;",
            "\tstruct kho_mem_phys *physxa;",
            "",
            "\twhile (pfn < end_pfn) {",
            "\t\tconst unsigned int order =",
            "\t\t\tmin(count_trailing_zeros(pfn), ilog2(end_pfn - pfn));",
            "\t\tconst unsigned long pfn_high = pfn >> order;",
            "",
            "\t\tphysxa = xa_load(&track->orders, order);",
            "\t\tif (!physxa)",
            "\t\t\tcontinue;",
            "",
            "\t\tbits = xa_load(&physxa->phys_bits, pfn_high / PRESERVE_BITS);",
            "\t\tif (!bits)",
            "\t\t\tcontinue;",
            "",
            "\t\tclear_bit(pfn_high % PRESERVE_BITS, bits->preserve);",
            "",
            "\t\tpfn += 1 << order;",
            "\t}",
            "}",
            "static int __kho_preserve_order(struct kho_mem_track *track, unsigned long pfn,",
            "\t\t\t\tunsigned int order)",
            "{",
            "\tstruct kho_mem_phys_bits *bits;",
            "\tstruct kho_mem_phys *physxa, *new_physxa;",
            "\tconst unsigned long pfn_high = pfn >> order;",
            "",
            "\tmight_sleep();",
            "",
            "\tphysxa = xa_load(&track->orders, order);",
            "\tif (!physxa) {",
            "\t\tint err;",
            "",
            "\t\tnew_physxa = kzalloc(sizeof(*physxa), GFP_KERNEL);",
            "\t\tif (!new_physxa)",
            "\t\t\treturn -ENOMEM;",
            "",
            "\t\txa_init(&new_physxa->phys_bits);",
            "\t\tphysxa = xa_cmpxchg(&track->orders, order, NULL, new_physxa,",
            "\t\t\t\t    GFP_KERNEL);",
            "",
            "\t\terr = xa_err(physxa);",
            "\t\tif (err || physxa) {",
            "\t\t\txa_destroy(&new_physxa->phys_bits);",
            "\t\t\tkfree(new_physxa);",
            "",
            "\t\t\tif (err)",
            "\t\t\t\treturn err;",
            "\t\t} else {",
            "\t\t\tphysxa = new_physxa;",
            "\t\t}",
            "\t}",
            "",
            "\tbits = xa_load_or_alloc(&physxa->phys_bits, pfn_high / PRESERVE_BITS,",
            "\t\t\t\tsizeof(*bits));",
            "\tif (IS_ERR(bits))",
            "\t\treturn PTR_ERR(bits);",
            "",
            "\tset_bit(pfn_high % PRESERVE_BITS, bits->preserve);",
            "",
            "\treturn 0;",
            "}",
            "static void kho_restore_page(struct page *page, unsigned int order)",
            "{",
            "\tunsigned int nr_pages = (1 << order);",
            "",
            "\t/* Head page gets refcount of 1. */",
            "\tset_page_count(page, 1);",
            "",
            "\t/* For higher order folios, tail pages get a page count of zero. */",
            "\tfor (unsigned int i = 1; i < nr_pages; i++)",
            "\t\tset_page_count(page + i, 0);",
            "",
            "\tif (order > 0)",
            "\t\tprep_compound_page(page, order);",
            "",
            "\tadjust_managed_page_count(page, nr_pages);",
            "}",
            "static void kho_mem_ser_free(struct khoser_mem_chunk *first_chunk)",
            "{",
            "\tstruct khoser_mem_chunk *chunk = first_chunk;",
            "",
            "\twhile (chunk) {",
            "\t\tstruct khoser_mem_chunk *tmp = chunk;",
            "",
            "\t\tchunk = KHOSER_LOAD_PTR(chunk->hdr.next);",
            "\t\tkfree(tmp);",
            "\t}",
            "}"
          ],
          "function_name": "kho_is_enabled, kho_parse_enable, __kho_unpreserve, __kho_preserve_order, kho_restore_page, kho_mem_ser_free",
          "description": "实现内存保留状态管理逻辑，通过位图追踪物理内存保留状态，提供内存保留/释放、页面恢复、序列化释放等核心函数，支持动态调整保留区域。",
          "similarity": 0.5349106192588806
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/kexec_handover.c",
          "start_line": 463,
          "end_line": 582,
          "content": [
            "static void __init scratch_size_update(void)",
            "{",
            "\tphys_addr_t size;",
            "",
            "\tif (!scratch_scale)",
            "\t\treturn;",
            "",
            "\tsize = memblock_reserved_kern_size(ARCH_LOW_ADDRESS_LIMIT,",
            "\t\t\t\t\t   NUMA_NO_NODE);",
            "\tsize = size * scratch_scale / 100;",
            "\tscratch_size_lowmem = round_up(size, CMA_MIN_ALIGNMENT_BYTES);",
            "",
            "\tsize = memblock_reserved_kern_size(MEMBLOCK_ALLOC_ANYWHERE,",
            "\t\t\t\t\t   NUMA_NO_NODE);",
            "\tsize = size * scratch_scale / 100 - scratch_size_lowmem;",
            "\tscratch_size_global = round_up(size, CMA_MIN_ALIGNMENT_BYTES);",
            "}",
            "static phys_addr_t __init scratch_size_node(int nid)",
            "{",
            "\tphys_addr_t size;",
            "",
            "\tif (scratch_scale) {",
            "\t\tsize = memblock_reserved_kern_size(MEMBLOCK_ALLOC_ANYWHERE,",
            "\t\t\t\t\t\t   nid);",
            "\t\tsize = size * scratch_scale / 100;",
            "\t} else {",
            "\t\tsize = scratch_size_pernode;",
            "\t}",
            "",
            "\treturn round_up(size, CMA_MIN_ALIGNMENT_BYTES);",
            "}",
            "static void __init kho_reserve_scratch(void)",
            "{",
            "\tphys_addr_t addr, size;",
            "\tint nid, i = 0;",
            "",
            "\tif (!kho_enable)",
            "\t\treturn;",
            "",
            "\tscratch_size_update();",
            "",
            "\t/* FIXME: deal with node hot-plug/remove */",
            "\tkho_scratch_cnt = num_online_nodes() + 2;",
            "\tsize = kho_scratch_cnt * sizeof(*kho_scratch);",
            "\tkho_scratch = memblock_alloc(size, PAGE_SIZE);",
            "\tif (!kho_scratch)",
            "\t\tgoto err_disable_kho;",
            "",
            "\t/*",
            "\t * reserve scratch area in low memory for lowmem allocations in the",
            "\t * next kernel",
            "\t */",
            "\tsize = scratch_size_lowmem;",
            "\taddr = memblock_phys_alloc_range(size, CMA_MIN_ALIGNMENT_BYTES, 0,",
            "\t\t\t\t\t ARCH_LOW_ADDRESS_LIMIT);",
            "\tif (!addr)",
            "\t\tgoto err_free_scratch_desc;",
            "",
            "\tkho_scratch[i].addr = addr;",
            "\tkho_scratch[i].size = size;",
            "\ti++;",
            "",
            "\t/* reserve large contiguous area for allocations without nid */",
            "\tsize = scratch_size_global;",
            "\taddr = memblock_phys_alloc(size, CMA_MIN_ALIGNMENT_BYTES);",
            "\tif (!addr)",
            "\t\tgoto err_free_scratch_areas;",
            "",
            "\tkho_scratch[i].addr = addr;",
            "\tkho_scratch[i].size = size;",
            "\ti++;",
            "",
            "\tfor_each_online_node(nid) {",
            "\t\tsize = scratch_size_node(nid);",
            "\t\taddr = memblock_alloc_range_nid(size, CMA_MIN_ALIGNMENT_BYTES,",
            "\t\t\t\t\t\t0, MEMBLOCK_ALLOC_ACCESSIBLE,",
            "\t\t\t\t\t\tnid, true);",
            "\t\tif (!addr)",
            "\t\t\tgoto err_free_scratch_areas;",
            "",
            "\t\tkho_scratch[i].addr = addr;",
            "\t\tkho_scratch[i].size = size;",
            "\t\ti++;",
            "\t}",
            "",
            "\treturn;",
            "",
            "err_free_scratch_areas:",
            "\tfor (i--; i >= 0; i--)",
            "\t\tmemblock_phys_free(kho_scratch[i].addr, kho_scratch[i].size);",
            "err_free_scratch_desc:",
            "\tmemblock_free(kho_scratch, kho_scratch_cnt * sizeof(*kho_scratch));",
            "err_disable_kho:",
            "\tpr_warn(\"Failed to reserve scratch area, disabling kexec handover\\n\");",
            "\tkho_enable = false;",
            "}",
            "static int kho_debugfs_fdt_add(struct list_head *list, struct dentry *dir,",
            "\t\t\t       const char *name, const void *fdt)",
            "{",
            "\tstruct fdt_debugfs *f;",
            "\tstruct dentry *file;",
            "",
            "\tf = kmalloc(sizeof(*f), GFP_KERNEL);",
            "\tif (!f)",
            "\t\treturn -ENOMEM;",
            "",
            "\tf->wrapper.data = (void *)fdt;",
            "\tf->wrapper.size = fdt_totalsize(fdt);",
            "",
            "\tfile = debugfs_create_blob(name, 0400, dir, &f->wrapper);",
            "\tif (IS_ERR(file)) {",
            "\t\tkfree(f);",
            "\t\treturn PTR_ERR(file);",
            "\t}",
            "",
            "\tf->file = file;",
            "\tlist_add(&f->list, list);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "scratch_size_update, scratch_size_node, kho_reserve_scratch, kho_debugfs_fdt_add",
          "description": "实现备用内存区域的动态分配与调试支持，根据预设比例计算各节点可用内存，通过memblock接口完成物理内存预留，并维护调试文件系统入口。",
          "similarity": 0.5043812990188599
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/kexec_handover.c",
          "start_line": 289,
          "end_line": 428,
          "content": [
            "static int kho_mem_serialize(struct kho_serialization *ser)",
            "{",
            "\tstruct khoser_mem_chunk *first_chunk = NULL;",
            "\tstruct khoser_mem_chunk *chunk = NULL;",
            "\tstruct kho_mem_phys *physxa;",
            "\tunsigned long order;",
            "",
            "\txa_for_each(&ser->track.orders, order, physxa) {",
            "\t\tstruct kho_mem_phys_bits *bits;",
            "\t\tunsigned long phys;",
            "",
            "\t\tchunk = new_chunk(chunk, order);",
            "\t\tif (!chunk)",
            "\t\t\tgoto err_free;",
            "",
            "\t\tif (!first_chunk)",
            "\t\t\tfirst_chunk = chunk;",
            "",
            "\t\txa_for_each(&physxa->phys_bits, phys, bits) {",
            "\t\t\tstruct khoser_mem_bitmap_ptr *elm;",
            "",
            "\t\t\tif (chunk->hdr.num_elms == ARRAY_SIZE(chunk->bitmaps)) {",
            "\t\t\t\tchunk = new_chunk(chunk, order);",
            "\t\t\t\tif (!chunk)",
            "\t\t\t\t\tgoto err_free;",
            "\t\t\t}",
            "",
            "\t\t\telm = &chunk->bitmaps[chunk->hdr.num_elms];",
            "\t\t\tchunk->hdr.num_elms++;",
            "\t\t\telm->phys_start = (phys * PRESERVE_BITS)",
            "\t\t\t\t\t  << (order + PAGE_SHIFT);",
            "\t\t\tKHOSER_STORE_PTR(elm->bitmap, bits);",
            "\t\t}",
            "\t}",
            "",
            "\tser->preserved_mem_map = first_chunk;",
            "",
            "\treturn 0;",
            "",
            "err_free:",
            "\tkho_mem_ser_free(first_chunk);",
            "\treturn -ENOMEM;",
            "}",
            "static void deserialize_bitmap(unsigned int order,",
            "\t\t\t       struct khoser_mem_bitmap_ptr *elm)",
            "{",
            "\tstruct kho_mem_phys_bits *bitmap = KHOSER_LOAD_PTR(elm->bitmap);",
            "\tunsigned long bit;",
            "",
            "\tfor_each_set_bit(bit, bitmap->preserve, PRESERVE_BITS) {",
            "\t\tint sz = 1 << (order + PAGE_SHIFT);",
            "\t\tphys_addr_t phys =",
            "\t\t\telm->phys_start + (bit << (order + PAGE_SHIFT));",
            "\t\tstruct page *page = phys_to_page(phys);",
            "",
            "\t\tmemblock_reserve(phys, sz);",
            "\t\tmemblock_reserved_mark_noinit(phys, sz);",
            "\t\tpage->private = order;",
            "\t}",
            "}",
            "static void __init kho_mem_deserialize(const void *fdt)",
            "{",
            "\tstruct khoser_mem_chunk *chunk;",
            "\tconst phys_addr_t *mem;",
            "\tint len;",
            "",
            "\tmem = fdt_getprop(fdt, 0, PROP_PRESERVED_MEMORY_MAP, &len);",
            "",
            "\tif (!mem || len != sizeof(*mem)) {",
            "\t\tpr_err(\"failed to get preserved memory bitmaps\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tchunk = *mem ? phys_to_virt(*mem) : NULL;",
            "\twhile (chunk) {",
            "\t\tunsigned int i;",
            "",
            "\t\tfor (i = 0; i != chunk->hdr.num_elms; i++)",
            "\t\t\tdeserialize_bitmap(chunk->hdr.order,",
            "\t\t\t\t\t   &chunk->bitmaps[i]);",
            "\t\tchunk = KHOSER_LOAD_PTR(chunk->hdr.next);",
            "\t}",
            "}",
            "static int __init kho_parse_scratch_size(char *p)",
            "{",
            "\tsize_t len;",
            "\tunsigned long sizes[3];",
            "\tint i;",
            "",
            "\tif (!p)",
            "\t\treturn -EINVAL;",
            "",
            "\tlen = strlen(p);",
            "\tif (!len)",
            "\t\treturn -EINVAL;",
            "",
            "\t/* parse nn% */",
            "\tif (p[len - 1] == '%') {",
            "\t\t/* unsigned int max is 4,294,967,295, 10 chars */",
            "\t\tchar s_scale[11] = {};",
            "\t\tint ret = 0;",
            "",
            "\t\tif (len > ARRAY_SIZE(s_scale))",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\tmemcpy(s_scale, p, len - 1);",
            "\t\tret = kstrtouint(s_scale, 10, &scratch_scale);",
            "\t\tif (!ret)",
            "\t\t\tpr_notice(\"scratch scale is %d%%\\n\", scratch_scale);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\t/* parse ll[KMG],mm[KMG],nn[KMG] */",
            "\tfor (i = 0; i < ARRAY_SIZE(sizes); i++) {",
            "\t\tchar *endp = p;",
            "",
            "\t\tif (i > 0) {",
            "\t\t\tif (*p != ',')",
            "\t\t\t\treturn -EINVAL;",
            "\t\t\tp += 1;",
            "\t\t}",
            "",
            "\t\tsizes[i] = memparse(p, &endp);",
            "\t\tif (!sizes[i] || endp == p)",
            "\t\t\treturn -EINVAL;",
            "\t\tp = endp;",
            "\t}",
            "",
            "\tscratch_size_lowmem = sizes[0];",
            "\tscratch_size_global = sizes[1];",
            "\tscratch_size_pernode = sizes[2];",
            "\tscratch_scale = 0;",
            "",
            "\tpr_notice(\"scratch areas: lowmem: %lluMiB global: %lluMiB pernode: %lldMiB\\n\",",
            "\t\t  (u64)(scratch_size_lowmem >> 20),",
            "\t\t  (u64)(scratch_size_global >> 20),",
            "\t\t  (u64)(scratch_size_pernode >> 20));",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "kho_mem_serialize, deserialize_bitmap, kho_mem_deserialize, kho_parse_scratch_size",
          "description": "实现内存序列化与反序列化机制，将保留内存信息编码至设备树属性，解析备用内存规模参数，支持多级内存保留策略配置。",
          "similarity": 0.5039525628089905
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/kexec_handover.c",
          "start_line": 617,
          "end_line": 733,
          "content": [
            "int kho_add_subtree(struct kho_serialization *ser, const char *name, void *fdt)",
            "{",
            "\tint err = 0;",
            "\tu64 phys = (u64)virt_to_phys(fdt);",
            "\tvoid *root = page_to_virt(ser->fdt);",
            "",
            "\terr |= fdt_begin_node(root, name);",
            "\terr |= fdt_property(root, PROP_SUB_FDT, &phys, sizeof(phys));",
            "\terr |= fdt_end_node(root);",
            "",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\treturn kho_debugfs_fdt_add(&ser->fdt_list, ser->sub_fdt_dir, name, fdt);",
            "}",
            "int register_kho_notifier(struct notifier_block *nb)",
            "{",
            "\treturn blocking_notifier_chain_register(&kho_out.chain_head, nb);",
            "}",
            "int unregister_kho_notifier(struct notifier_block *nb)",
            "{",
            "\treturn blocking_notifier_chain_unregister(&kho_out.chain_head, nb);",
            "}",
            "int kho_preserve_folio(struct folio *folio)",
            "{",
            "\tconst unsigned long pfn = folio_pfn(folio);",
            "\tconst unsigned int order = folio_order(folio);",
            "\tstruct kho_mem_track *track = &kho_out.ser.track;",
            "",
            "\tif (kho_out.finalized)",
            "\t\treturn -EBUSY;",
            "",
            "\treturn __kho_preserve_order(track, pfn, order);",
            "}",
            "int kho_preserve_phys(phys_addr_t phys, size_t size)",
            "{",
            "\tunsigned long pfn = PHYS_PFN(phys);",
            "\tunsigned long failed_pfn = 0;",
            "\tconst unsigned long start_pfn = pfn;",
            "\tconst unsigned long end_pfn = PHYS_PFN(phys + size);",
            "\tint err = 0;",
            "\tstruct kho_mem_track *track = &kho_out.ser.track;",
            "",
            "\tif (kho_out.finalized)",
            "\t\treturn -EBUSY;",
            "",
            "\tif (!PAGE_ALIGNED(phys) || !PAGE_ALIGNED(size))",
            "\t\treturn -EINVAL;",
            "",
            "\twhile (pfn < end_pfn) {",
            "\t\tconst unsigned int order =",
            "\t\t\tmin(count_trailing_zeros(pfn), ilog2(end_pfn - pfn));",
            "",
            "\t\terr = __kho_preserve_order(track, pfn, order);",
            "\t\tif (err) {",
            "\t\t\tfailed_pfn = pfn;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tpfn += 1 << order;",
            "\t}",
            "",
            "\tif (err)",
            "\t\t__kho_unpreserve(track, start_pfn, failed_pfn);",
            "",
            "\treturn err;",
            "}",
            "static int kho_out_update_debugfs_fdt(void)",
            "{",
            "\tint err = 0;",
            "\tstruct fdt_debugfs *ff, *tmp;",
            "",
            "\tif (kho_out.finalized) {",
            "\t\terr = kho_debugfs_fdt_add(&kho_out.ser.fdt_list, kho_out.dir,",
            "\t\t\t\t\t  \"fdt\", page_to_virt(kho_out.ser.fdt));",
            "\t} else {",
            "\t\tlist_for_each_entry_safe(ff, tmp, &kho_out.ser.fdt_list, list) {",
            "\t\t\tdebugfs_remove(ff->file);",
            "\t\t\tlist_del(&ff->list);",
            "\t\t\tkfree(ff);",
            "\t\t}",
            "\t}",
            "",
            "\treturn err;",
            "}",
            "static int kho_abort(void)",
            "{",
            "\tint err;",
            "\tunsigned long order;",
            "\tstruct kho_mem_phys *physxa;",
            "",
            "\txa_for_each(&kho_out.ser.track.orders, order, physxa) {",
            "\t\tstruct kho_mem_phys_bits *bits;",
            "\t\tunsigned long phys;",
            "",
            "\t\txa_for_each(&physxa->phys_bits, phys, bits)",
            "\t\t\tkfree(bits);",
            "",
            "\t\txa_destroy(&physxa->phys_bits);",
            "\t\tkfree(physxa);",
            "\t}",
            "\txa_destroy(&kho_out.ser.track.orders);",
            "",
            "\tif (kho_out.ser.preserved_mem_map) {",
            "\t\tkho_mem_ser_free(kho_out.ser.preserved_mem_map);",
            "\t\tkho_out.ser.preserved_mem_map = NULL;",
            "\t}",
            "",
            "\terr = blocking_notifier_call_chain(&kho_out.chain_head, KEXEC_KHO_ABORT,",
            "\t\t\t\t\t   NULL);",
            "\terr = notifier_to_errno(err);",
            "",
            "\tif (err)",
            "\t\tpr_err(\"Failed to abort KHO finalization: %d\\n\", err);",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "kho_add_subtree, register_kho_notifier, unregister_kho_notifier, kho_preserve_folio, kho_preserve_phys, kho_out_update_debugfs_fdt, kho_abort",
          "description": "实现设备树子节点注入、内存保留通知注册、物理内存保留操作、调试信息更新及异常终止处理等核心控制流，协调各组件完成无缝内核切换准备。",
          "similarity": 0.4438372850418091
        },
        {
          "chunk_id": 8,
          "file_path": "kernel/kexec_handover.c",
          "start_line": 1230,
          "end_line": 1290,
          "content": [
            "int kho_fill_kimage(struct kimage *image)",
            "{",
            "\tssize_t scratch_size;",
            "\tint err = 0;",
            "\tstruct kexec_buf scratch;",
            "",
            "\tif (!kho_enable)",
            "\t\treturn 0;",
            "",
            "\timage->kho.fdt = page_to_phys(kho_out.ser.fdt);",
            "",
            "\tscratch_size = sizeof(*kho_scratch) * kho_scratch_cnt;",
            "\tscratch = (struct kexec_buf){",
            "\t\t.image = image,",
            "\t\t.buffer = kho_scratch,",
            "\t\t.bufsz = scratch_size,",
            "\t\t.mem = KEXEC_BUF_MEM_UNKNOWN,",
            "\t\t.memsz = scratch_size,",
            "\t\t.buf_align = SZ_64K, /* Makes it easier to map */",
            "\t\t.buf_max = ULONG_MAX,",
            "\t\t.top_down = true,",
            "\t};",
            "\terr = kexec_add_buffer(&scratch);",
            "\tif (err)",
            "\t\treturn err;",
            "\timage->kho.scratch = &image->segment[image->nr_segments - 1];",
            "",
            "\treturn 0;",
            "}",
            "static int kho_walk_scratch(struct kexec_buf *kbuf,",
            "\t\t\t    int (*func)(struct resource *, void *))",
            "{",
            "\tint ret = 0;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < kho_scratch_cnt; i++) {",
            "\t\tstruct resource res = {",
            "\t\t\t.start = kho_scratch[i].addr,",
            "\t\t\t.end = kho_scratch[i].addr + kho_scratch[i].size - 1,",
            "\t\t};",
            "",
            "\t\t/* Try to fit the kimage into our KHO scratch region */",
            "\t\tret = func(&res, kbuf);",
            "\t\tif (ret)",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "int kho_locate_mem_hole(struct kexec_buf *kbuf,",
            "\t\t\tint (*func)(struct resource *, void *))",
            "{",
            "\tint ret;",
            "",
            "\tif (!kho_enable || kbuf->image->type == KEXEC_TYPE_CRASH)",
            "\t\treturn 1;",
            "",
            "\tret = kho_walk_scratch(kbuf, func);",
            "",
            "\treturn ret == 1 ? 0 : -EADDRNOTAVAIL;",
            "}"
          ],
          "function_name": "kho_fill_kimage, kho_walk_scratch, kho_locate_mem_hole",
          "description": "kho_fill_kimage 将内核镜像填充到预分配的 Scratch 区域。kho_walk_scratch 遍历所有 Scratch 区域寻找可容纳镜像的连续空间。kho_locate_mem_hole 尝试在 Scratch 区域定位可用内存孔，用于 kexec 加载新内核镜像。",
          "similarity": 0.4246036410331726
        }
      ]
    }
  ]
}