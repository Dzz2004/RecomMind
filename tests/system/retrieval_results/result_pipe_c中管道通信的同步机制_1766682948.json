{
  "query": "pipe.c中管道通信的同步机制",
  "timestamp": "2025-12-26 01:15:48",
  "retrieved_files": [
    {
      "source_file": "kernel/watch_queue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:50:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `watch_queue.c`\n\n---\n\n# watch_queue.c 技术文档\n\n## 文件概述\n\n`watch_queue.c` 实现了 Linux 内核中的**监视队列**（Watch Queue）机制，这是一种基于管道（pipe）构建的通用事件通知系统。该机制允许内核子系统（如文件系统、密钥管理、设备驱动等）向用户空间异步发送结构化通知。用户空间通过创建特殊类型的管道并关联监视队列，即可接收来自内核的各类事件通知。该文件定义了通知的投递、过滤、缓冲管理及与管道集成的核心逻辑。\n\n## 核心功能\n\n### 主要函数\n\n- **`__post_watch_notification()`**  \n  核心通知投递函数。遍历指定 `watch_list` 中所有匹配 `id` 的监视器（`watch`），对每个关联的 `watch_queue` 应用过滤规则、安全检查，并将通知写入底层管道。\n\n- **`post_one_notification()`**  \n  将单个通知写入指定 `watch_queue` 的底层管道缓冲区。负责从预分配的通知页中获取空闲槽位、填充数据、更新管道头指针并唤醒等待读取的进程。\n\n- **`filter_watch_notification()`**  \n  根据 `watch_filter` 中的类型、子类型和信息掩码规则，判断是否允许特定通知通过。\n\n- **`watch_queue_set_size()`**  \n  为监视队列分配预分配的通知缓冲区（页数组和位图），并调整底层管道的环形缓冲区大小。\n\n- **`watch_queue_pipe_buf_release()`**  \n  管道缓冲区释放回调。当用户空间读取完通知后，将对应的通知槽位在位图中标记为空闲，供后续复用。\n\n### 关键数据结构\n\n- **`struct watch_queue`**  \n  表示一个监视队列，包含：\n  - 指向底层 `pipe_inode_info` 的指针\n  - 预分配的通知页数组（`notes`）\n  - 通知槽位空闲位图（`notes_bitmap`）\n  - 通知过滤器（`filter`）\n  - 保护锁（`lock`）\n\n- **`struct watch_notification`**  \n  通用通知记录格式，包含类型（`type`）、子类型（`subtype`）、信息字段（`info`，含长度和ID）及可变负载。\n\n- **`struct watch_filter` / `struct watch_type_filter`**  \n  定义通知过滤规则，支持按类型、子类型及信息字段的位掩码进行精确过滤。\n\n- **`watch_queue_pipe_buf_ops`**  \n  自定义的 `pipe_buf_operations`，用于管理监视队列专用管道缓冲区的生命周期。\n\n## 关键实现\n\n### 基于管道的通知传输\n- 监视队列复用内核管道（`pipe_inode_info`）作为通知传输通道，利用其成熟的读写、轮询、异步通知机制。\n- 通过自定义 `pipe_buf_operations`（`watch_queue_pipe_buf_ops`）实现通知槽位的回收：当用户读取通知后，`release` 回调将对应槽位在 `notes_bitmap` 中置位，标记为空闲。\n\n### 预分配通知缓冲区\n- 通知数据存储在预分配的内核页（`notes`）中，每页划分为多个固定大小（128字节）的槽位（`WATCH_QUEUE_NOTE_SIZE`）。\n- 使用位图（`notes_bitmap`）跟踪槽位使用状态，1 表示空闲。投递通知时通过 `find_first_bit()` 快速查找空闲槽位。\n- 缓冲区大小由用户通过 `watch_queue_set_size()` 设置（1-512个通知），并受管道缓冲区配额限制。\n\n### 通知投递流程\n1. **匹配监视器**：遍历 `watch_list`，查找 `id` 匹配的 `watch`。\n2. **应用过滤**：若队列配置了过滤器，调用 `filter_watch_notification()` 决定是否丢弃。\n3. **安全检查**：调用 LSM 钩子 `security_post_notification()` 进行权限验证。\n4. **写入管道**：\n   - 获取空闲通知槽位，复制通知数据。\n   - 构造 `pipe_buffer` 指向该槽位，设置自定义操作集。\n   - 更新管道 `head` 指针，唤醒等待读取的进程。\n   - 若缓冲区满，标记前一个缓冲区为 `PIPE_BUF_FLAG_LOSS` 表示丢包。\n\n### 并发与同步\n- **RCU 保护**：`watch_list` 和 `watch_queue` 的访问通过 RCU 机制保护，确保遍历时结构体不被释放。\n- **自旋锁**：\n  - `wqueue->lock`：保护 `wqueue` 状态（如 `pipe` 指针有效性）。\n  - `pipe->rd_wait.lock`：保护管道环形缓冲区的读写操作。\n- **原子操作**：管道 `head` 指针使用 `smp_store_release()` 更新，确保与 `pipe_read()` 的同步。\n\n## 依赖关系\n\n- **管道子系统**（`fs/pipe.c`）  \n  依赖管道的核心数据结构（`pipe_inode_info`、`pipe_buffer`）和操作接口（`pipe_buf()`、`pipe_full()`、`generic_pipe_buf_*`）。\n\n- **内存管理**  \n  使用 `alloc_page()`、`kmap_atomic()` 管理通知缓冲区页，`bitmap_alloc()` 管理槽位位图。\n\n- **安全模块**（LSM）  \n  通过 `security_post_notification()` 钩子集成安全策略。\n\n- **用户空间接口**  \n  与 `fs/watch_queue.c` 中的系统调用（如 `watch_queue_set_size()`）协同工作，后者负责创建监视队列并与管道关联。\n\n- **头文件依赖**  \n  `linux/watch_queue.h`（核心数据结构定义）、`linux/pipe_fs_i.h`（管道内部接口）。\n\n## 使用场景\n\n- **文件系统事件监控**  \n  如 `fsnotify` 子系统可通过监视队列向用户空间报告文件访问、修改等事件。\n\n- **密钥管理通知**  \n  内核密钥环（`KEYS`）子系统使用该机制通知密钥状态变更（如过期、撤销）。\n\n- **设备事件上报**  \n  设备驱动可利用监视队列异步上报硬件状态变化或错误事件。\n\n- **通用内核事件分发**  \n  任何需要向特权用户空间守护进程（如 `systemd`）发送结构化事件的内核子系统均可集成此机制。\n\n- **用户空间消费**  \n  应用程序通过 `open(\"/dev/watch_queue\")` 获取监视队列文件描述符，调用 `ioctl()` 设置缓冲区大小和过滤器，然后像读取普通管道一样接收通知。",
      "similarity": 0.6358646750450134,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/watch_queue.c",
          "start_line": 42,
          "end_line": 154,
          "content": [
            "static inline bool lock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_lock_bh(&wqueue->lock);",
            "\tif (unlikely(!wqueue->pipe)) {",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "\t\treturn false;",
            "\t}",
            "\treturn true;",
            "}",
            "static inline void unlock_wqueue(struct watch_queue *wqueue)",
            "{",
            "\tspin_unlock_bh(&wqueue->lock);",
            "}",
            "static void watch_queue_pipe_buf_release(struct pipe_inode_info *pipe,",
            "\t\t\t\t\t struct pipe_buffer *buf)",
            "{",
            "\tstruct watch_queue *wqueue = (struct watch_queue *)buf->private;",
            "\tstruct page *page;",
            "\tunsigned int bit;",
            "",
            "\t/* We need to work out which note within the page this refers to, but",
            "\t * the note might have been maximum size, so merely ANDing the offset",
            "\t * off doesn't work.  OTOH, the note must've been more than zero size.",
            "\t */",
            "\tbit = buf->offset + buf->len;",
            "\tif ((bit & (WATCH_QUEUE_NOTE_SIZE - 1)) == 0)",
            "\t\tbit -= WATCH_QUEUE_NOTE_SIZE;",
            "\tbit /= WATCH_QUEUE_NOTE_SIZE;",
            "",
            "\tpage = buf->page;",
            "\tbit += page->index;",
            "",
            "\tset_bit(bit, wqueue->notes_bitmap);",
            "\tgeneric_pipe_buf_release(pipe, buf);",
            "}",
            "static bool post_one_notification(struct watch_queue *wqueue,",
            "\t\t\t\t  struct watch_notification *n)",
            "{",
            "\tvoid *p;",
            "\tstruct pipe_inode_info *pipe = wqueue->pipe;",
            "\tstruct pipe_buffer *buf;",
            "\tstruct page *page;",
            "\tunsigned int head, tail, note, offset, len;",
            "\tbool done = false;",
            "",
            "\tspin_lock_irq(&pipe->rd_wait.lock);",
            "",
            "\thead = pipe->head;",
            "\ttail = pipe->tail;",
            "\tif (pipe_full(head, tail, pipe->ring_size))",
            "\t\tgoto lost;",
            "",
            "\tnote = find_first_bit(wqueue->notes_bitmap, wqueue->nr_notes);",
            "\tif (note >= wqueue->nr_notes)",
            "\t\tgoto lost;",
            "",
            "\tpage = wqueue->notes[note / WATCH_QUEUE_NOTES_PER_PAGE];",
            "\toffset = note % WATCH_QUEUE_NOTES_PER_PAGE * WATCH_QUEUE_NOTE_SIZE;",
            "\tget_page(page);",
            "\tlen = n->info & WATCH_INFO_LENGTH;",
            "\tp = kmap_atomic(page);",
            "\tmemcpy(p + offset, n, len);",
            "\tkunmap_atomic(p);",
            "",
            "\tbuf = pipe_buf(pipe, head);",
            "\tbuf->page = page;",
            "\tbuf->private = (unsigned long)wqueue;",
            "\tbuf->ops = &watch_queue_pipe_buf_ops;",
            "\tbuf->offset = offset;",
            "\tbuf->len = len;",
            "\tbuf->flags = PIPE_BUF_FLAG_WHOLE;",
            "\tsmp_store_release(&pipe->head, head + 1); /* vs pipe_read() */",
            "",
            "\tif (!test_and_clear_bit(note, wqueue->notes_bitmap)) {",
            "\t\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\t\tBUG();",
            "\t}",
            "\twake_up_interruptible_sync_poll_locked(&pipe->rd_wait, EPOLLIN | EPOLLRDNORM);",
            "\tdone = true;",
            "",
            "out:",
            "\tspin_unlock_irq(&pipe->rd_wait.lock);",
            "\tif (done)",
            "\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);",
            "\treturn done;",
            "",
            "lost:",
            "\tbuf = pipe_buf(pipe, head - 1);",
            "\tbuf->flags |= PIPE_BUF_FLAG_LOSS;",
            "\tgoto out;",
            "}",
            "static bool filter_watch_notification(const struct watch_filter *wf,",
            "\t\t\t\t      const struct watch_notification *n)",
            "{",
            "\tconst struct watch_type_filter *wt;",
            "\tunsigned int st_bits = sizeof(wt->subtype_filter[0]) * 8;",
            "\tunsigned int st_index = n->subtype / st_bits;",
            "\tunsigned int st_bit = 1U << (n->subtype % st_bits);",
            "\tint i;",
            "",
            "\tif (!test_bit(n->type, wf->type_filter))",
            "\t\treturn false;",
            "",
            "\tfor (i = 0; i < wf->nr_filters; i++) {",
            "\t\twt = &wf->filters[i];",
            "\t\tif (n->type == wt->type &&",
            "\t\t    (wt->subtype_filter[st_index] & st_bit) &&",
            "\t\t    (n->info & wt->info_mask) == wt->info_filter)",
            "\t\t\treturn true;",
            "\t}",
            "",
            "\treturn false; /* If there is a filter, the default is to reject. */",
            "}"
          ],
          "function_name": "lock_wqueue, unlock_wqueue, watch_queue_pipe_buf_release, post_one_notification, filter_watch_notification",
          "description": "实现了watch_queue的锁操作、缓冲区释放、通知提交及过滤逻辑。lock_wqueue/unlock_wqueue用于保护队列访问，watch_queue_pipe_buf_release处理缓冲区回收并更新位图，post_one_notification将通知数据写入管道，filter_watch_notification进行类型和子类型的匹配判断。",
          "similarity": 0.530462384223938
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/watch_queue.c",
          "start_line": 602,
          "end_line": 680,
          "content": [
            "void watch_queue_clear(struct watch_queue *wqueue)",
            "{",
            "\tstruct watch_list *wlist;",
            "\tstruct watch *watch;",
            "\tbool release;",
            "",
            "\trcu_read_lock();",
            "\tspin_lock_bh(&wqueue->lock);",
            "",
            "\t/*",
            "\t * This pipe can be freed by callers like free_pipe_info().",
            "\t * Removing this reference also prevents new notifications.",
            "\t */",
            "\twqueue->pipe = NULL;",
            "",
            "\twhile (!hlist_empty(&wqueue->watches)) {",
            "\t\twatch = hlist_entry(wqueue->watches.first, struct watch, queue_node);",
            "\t\thlist_del_init_rcu(&watch->queue_node);",
            "\t\t/* We now own a ref on the watch. */",
            "\t\tspin_unlock_bh(&wqueue->lock);",
            "",
            "\t\t/* We can't do the next bit under the queue lock as we need to",
            "\t\t * get the list lock - which would cause a deadlock if someone",
            "\t\t * was removing from the opposite direction at the same time or",
            "\t\t * posting a notification.",
            "\t\t */",
            "\t\twlist = rcu_dereference(watch->watch_list);",
            "\t\tif (wlist) {",
            "\t\t\tvoid (*release_watch)(struct watch *);",
            "",
            "\t\t\tspin_lock(&wlist->lock);",
            "",
            "\t\t\trelease = !hlist_unhashed(&watch->list_node);",
            "\t\t\tif (release) {",
            "\t\t\t\thlist_del_init_rcu(&watch->list_node);",
            "\t\t\t\trcu_assign_pointer(watch->watch_list, NULL);",
            "",
            "\t\t\t\t/* We now own a second ref on the watch. */",
            "\t\t\t}",
            "",
            "\t\t\trelease_watch = wlist->release_watch;",
            "\t\t\tspin_unlock(&wlist->lock);",
            "",
            "\t\t\tif (release) {",
            "\t\t\t\tif (release_watch) {",
            "\t\t\t\t\trcu_read_unlock();",
            "\t\t\t\t\t/* This might need to call dput(), so",
            "\t\t\t\t\t * we have to drop all the locks.",
            "\t\t\t\t\t */",
            "\t\t\t\t\t(*release_watch)(watch);",
            "\t\t\t\t\trcu_read_lock();",
            "\t\t\t\t}",
            "\t\t\t\tput_watch(watch);",
            "\t\t\t}",
            "\t\t}",
            "",
            "\t\tput_watch(watch);",
            "\t\tspin_lock_bh(&wqueue->lock);",
            "\t}",
            "",
            "\tspin_unlock_bh(&wqueue->lock);",
            "\trcu_read_unlock();",
            "}",
            "int watch_queue_init(struct pipe_inode_info *pipe)",
            "{",
            "\tstruct watch_queue *wqueue;",
            "",
            "\twqueue = kzalloc(sizeof(*wqueue), GFP_KERNEL);",
            "\tif (!wqueue)",
            "\t\treturn -ENOMEM;",
            "",
            "\twqueue->pipe = pipe;",
            "\tkref_init(&wqueue->usage);",
            "\tspin_lock_init(&wqueue->lock);",
            "\tINIT_HLIST_HEAD(&wqueue->watches);",
            "",
            "\tpipe->watch_queue = wqueue;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "watch_queue_clear, watch_queue_init",
          "description": "该代码实现了监视队列的初始化与清理功能。  \n`watch_queue_clear`通过RCU和自旋锁机制安全地移除所有监视项并释放资源，`watch_queue_init`初始化监视队列结构并绑定至管道对象。  \n上下文不完整：`release_watch`等关键函数依赖外部定义，部分RCU回调逻辑未完全展示。",
          "similarity": 0.49493321776390076
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/watch_queue.c",
          "start_line": 193,
          "end_line": 304,
          "content": [
            "void __post_watch_notification(struct watch_list *wlist,",
            "\t\t\t       struct watch_notification *n,",
            "\t\t\t       const struct cred *cred,",
            "\t\t\t       u64 id)",
            "{",
            "\tconst struct watch_filter *wf;",
            "\tstruct watch_queue *wqueue;",
            "\tstruct watch *watch;",
            "",
            "\tif (((n->info & WATCH_INFO_LENGTH) >> WATCH_INFO_LENGTH__SHIFT) == 0) {",
            "\t\tWARN_ON(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\trcu_read_lock();",
            "",
            "\thlist_for_each_entry_rcu(watch, &wlist->watchers, list_node) {",
            "\t\tif (watch->id != id)",
            "\t\t\tcontinue;",
            "\t\tn->info &= ~WATCH_INFO_ID;",
            "\t\tn->info |= watch->info_id;",
            "",
            "\t\twqueue = rcu_dereference(watch->queue);",
            "\t\twf = rcu_dereference(wqueue->filter);",
            "\t\tif (wf && !filter_watch_notification(wf, n))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (security_post_notification(watch->cred, cred, n) < 0)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (lock_wqueue(wqueue)) {",
            "\t\t\tpost_one_notification(wqueue, n);",
            "\t\t\tunlock_wqueue(wqueue);",
            "\t\t}",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "}",
            "long watch_queue_set_size(struct pipe_inode_info *pipe, unsigned int nr_notes)",
            "{",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tstruct page **pages;",
            "\tunsigned long *bitmap;",
            "\tunsigned long user_bufs;",
            "\tint ret, i, nr_pages;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "\tif (wqueue->notes)",
            "\t\treturn -EBUSY;",
            "",
            "\tif (nr_notes < 1 ||",
            "\t    nr_notes > 512) /* TODO: choose a better hard limit */",
            "\t\treturn -EINVAL;",
            "",
            "\tnr_pages = (nr_notes + WATCH_QUEUE_NOTES_PER_PAGE - 1);",
            "\tnr_pages /= WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tuser_bufs = account_pipe_buffers(pipe->user, pipe->nr_accounted, nr_pages);",
            "",
            "\tif (nr_pages > pipe->max_usage &&",
            "\t    (too_many_pipe_buffers_hard(user_bufs) ||",
            "\t     too_many_pipe_buffers_soft(user_bufs)) &&",
            "\t    pipe_is_unprivileged_user()) {",
            "\t\tret = -EPERM;",
            "\t\tgoto error;",
            "\t}",
            "",
            "\tnr_notes = nr_pages * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\tret = pipe_resize_ring(pipe, roundup_pow_of_two(nr_notes));",
            "\tif (ret < 0)",
            "\t\tgoto error;",
            "",
            "\t/*",
            "\t * pipe_resize_ring() does not update nr_accounted for watch_queue",
            "\t * pipes, because the above vastly overprovisions. Set nr_accounted on",
            "\t * and max_usage this pipe to the number that was actually charged to",
            "\t * the user above via account_pipe_buffers.",
            "\t */",
            "\tpipe->max_usage = nr_pages;",
            "\tpipe->nr_accounted = nr_pages;",
            "",
            "\tret = -ENOMEM;",
            "\tpages = kcalloc(sizeof(struct page *), nr_pages, GFP_KERNEL);",
            "\tif (!pages)",
            "\t\tgoto error;",
            "",
            "\tfor (i = 0; i < nr_pages; i++) {",
            "\t\tpages[i] = alloc_page(GFP_KERNEL);",
            "\t\tif (!pages[i])",
            "\t\t\tgoto error_p;",
            "\t\tpages[i]->index = i * WATCH_QUEUE_NOTES_PER_PAGE;",
            "\t}",
            "",
            "\tbitmap = bitmap_alloc(nr_notes, GFP_KERNEL);",
            "\tif (!bitmap)",
            "\t\tgoto error_p;",
            "",
            "\tbitmap_fill(bitmap, nr_notes);",
            "\twqueue->notes = pages;",
            "\twqueue->notes_bitmap = bitmap;",
            "\twqueue->nr_pages = nr_pages;",
            "\twqueue->nr_notes = nr_notes;",
            "\treturn 0;",
            "",
            "error_p:",
            "\twhile (--i >= 0)",
            "\t\t__free_page(pages[i]);",
            "\tkfree(pages);",
            "error:",
            "\t(void) account_pipe_buffers(pipe->user, nr_pages, pipe->nr_accounted);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__post_watch_notification, watch_queue_set_size",
          "description": "__post_watch_notification遍历watch列表并应用过滤器后提交通知，watch_queue_set_size动态调整管道容量，通过计算所需页数和位图分配，限制最大容量为512个笔记，支持扩展性需求。",
          "similarity": 0.45962151885032654
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/watch_queue.c",
          "start_line": 315,
          "end_line": 422,
          "content": [
            "long watch_queue_set_filter(struct pipe_inode_info *pipe,",
            "\t\t\t    struct watch_notification_filter __user *_filter)",
            "{",
            "\tstruct watch_notification_type_filter *tf;",
            "\tstruct watch_notification_filter filter;",
            "\tstruct watch_type_filter *q;",
            "\tstruct watch_filter *wfilter;",
            "\tstruct watch_queue *wqueue = pipe->watch_queue;",
            "\tint ret, nr_filter = 0, i;",
            "",
            "\tif (!wqueue)",
            "\t\treturn -ENODEV;",
            "",
            "\tif (!_filter) {",
            "\t\t/* Remove the old filter */",
            "\t\twfilter = NULL;",
            "\t\tgoto set;",
            "\t}",
            "",
            "\t/* Grab the user's filter specification */",
            "\tif (copy_from_user(&filter, _filter, sizeof(filter)) != 0)",
            "\t\treturn -EFAULT;",
            "\tif (filter.nr_filters == 0 ||",
            "\t    filter.nr_filters > 16 ||",
            "\t    filter.__reserved != 0)",
            "\t\treturn -EINVAL;",
            "",
            "\ttf = memdup_array_user(_filter->filters, filter.nr_filters, sizeof(*tf));",
            "\tif (IS_ERR(tf))",
            "\t\treturn PTR_ERR(tf);",
            "",
            "\tret = -EINVAL;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif ((tf[i].info_filter & ~tf[i].info_mask) ||",
            "\t\t    tf[i].info_mask & WATCH_INFO_LENGTH)",
            "\t\t\tgoto err_filter;",
            "\t\t/* Ignore any unknown types */",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "\t\tnr_filter++;",
            "\t}",
            "",
            "\t/* Now we need to build the internal filter from only the relevant",
            "\t * user-specified filters.",
            "\t */",
            "\tret = -ENOMEM;",
            "\twfilter = kzalloc(struct_size(wfilter, filters, nr_filter), GFP_KERNEL);",
            "\tif (!wfilter)",
            "\t\tgoto err_filter;",
            "\twfilter->nr_filters = nr_filter;",
            "",
            "\tq = wfilter->filters;",
            "\tfor (i = 0; i < filter.nr_filters; i++) {",
            "\t\tif (tf[i].type >= WATCH_TYPE__NR)",
            "\t\t\tcontinue;",
            "",
            "\t\tq->type\t\t\t= tf[i].type;",
            "\t\tq->info_filter\t\t= tf[i].info_filter;",
            "\t\tq->info_mask\t\t= tf[i].info_mask;",
            "\t\tq->subtype_filter[0]\t= tf[i].subtype_filter[0];",
            "\t\t__set_bit(q->type, wfilter->type_filter);",
            "\t\tq++;",
            "\t}",
            "",
            "\tkfree(tf);",
            "set:",
            "\tpipe_lock(pipe);",
            "\twfilter = rcu_replace_pointer(wqueue->filter, wfilter,",
            "\t\t\t\t      lockdep_is_held(&pipe->mutex));",
            "\tpipe_unlock(pipe);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\treturn 0;",
            "",
            "err_filter:",
            "\tkfree(tf);",
            "\treturn ret;",
            "}",
            "static void __put_watch_queue(struct kref *kref)",
            "{",
            "\tstruct watch_queue *wqueue =",
            "\t\tcontainer_of(kref, struct watch_queue, usage);",
            "\tstruct watch_filter *wfilter;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < wqueue->nr_pages; i++)",
            "\t\t__free_page(wqueue->notes[i]);",
            "\tkfree(wqueue->notes);",
            "\tbitmap_free(wqueue->notes_bitmap);",
            "",
            "\twfilter = rcu_access_pointer(wqueue->filter);",
            "\tif (wfilter)",
            "\t\tkfree_rcu(wfilter, rcu);",
            "\tkfree_rcu(wqueue, rcu);",
            "}",
            "void put_watch_queue(struct watch_queue *wqueue)",
            "{",
            "\tkref_put(&wqueue->usage, __put_watch_queue);",
            "}",
            "static void free_watch(struct rcu_head *rcu)",
            "{",
            "\tstruct watch *watch = container_of(rcu, struct watch, rcu);",
            "",
            "\tput_watch_queue(rcu_access_pointer(watch->queue));",
            "\tatomic_dec(&watch->cred->user->nr_watches);",
            "\tput_cred(watch->cred);",
            "\tkfree(watch);",
            "}"
          ],
          "function_name": "watch_queue_set_filter, __put_watch_queue, put_watch_queue, free_watch",
          "description": "watch_queue_set_filter设置过滤规则并转换为内核内部结构，__put_watch_queue释放watch_queue相关资源包括页面、位图和过滤器，put_watch_queue通过引用计数管理watch_queue生命周期，free_watch执行RCU回调完成最终释放。",
          "similarity": 0.4535664916038513
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/watch_queue.c",
          "start_line": 432,
          "end_line": 556,
          "content": [
            "static void __put_watch(struct kref *kref)",
            "{",
            "\tstruct watch *watch = container_of(kref, struct watch, usage);",
            "",
            "\tcall_rcu(&watch->rcu, free_watch);",
            "}",
            "static void put_watch(struct watch *watch)",
            "{",
            "\tkref_put(&watch->usage, __put_watch);",
            "}",
            "void init_watch(struct watch *watch, struct watch_queue *wqueue)",
            "{",
            "\tkref_init(&watch->usage);",
            "\tINIT_HLIST_NODE(&watch->list_node);",
            "\tINIT_HLIST_NODE(&watch->queue_node);",
            "\trcu_assign_pointer(watch->queue, wqueue);",
            "}",
            "static int add_one_watch(struct watch *watch, struct watch_list *wlist, struct watch_queue *wqueue)",
            "{",
            "\tconst struct cred *cred;",
            "\tstruct watch *w;",
            "",
            "\thlist_for_each_entry(w, &wlist->watchers, list_node) {",
            "\t\tstruct watch_queue *wq = rcu_access_pointer(w->queue);",
            "\t\tif (wqueue == wq && watch->id == w->id)",
            "\t\t\treturn -EBUSY;",
            "\t}",
            "",
            "\tcred = current_cred();",
            "\tif (atomic_inc_return(&cred->user->nr_watches) > task_rlimit(current, RLIMIT_NOFILE)) {",
            "\t\tatomic_dec(&cred->user->nr_watches);",
            "\t\treturn -EAGAIN;",
            "\t}",
            "",
            "\twatch->cred = get_cred(cred);",
            "\trcu_assign_pointer(watch->watch_list, wlist);",
            "",
            "\tkref_get(&wqueue->usage);",
            "\tkref_get(&watch->usage);",
            "\thlist_add_head(&watch->queue_node, &wqueue->watches);",
            "\thlist_add_head_rcu(&watch->list_node, &wlist->watchers);",
            "\treturn 0;",
            "}",
            "int add_watch_to_object(struct watch *watch, struct watch_list *wlist)",
            "{",
            "\tstruct watch_queue *wqueue;",
            "\tint ret = -ENOENT;",
            "",
            "\trcu_read_lock();",
            "",
            "\twqueue = rcu_access_pointer(watch->queue);",
            "\tif (lock_wqueue(wqueue)) {",
            "\t\tspin_lock(&wlist->lock);",
            "\t\tret = add_one_watch(watch, wlist, wqueue);",
            "\t\tspin_unlock(&wlist->lock);",
            "\t\tunlock_wqueue(wqueue);",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "\treturn ret;",
            "}",
            "int remove_watch_from_object(struct watch_list *wlist, struct watch_queue *wq,",
            "\t\t\t     u64 id, bool all)",
            "{",
            "\tstruct watch_notification_removal n;",
            "\tstruct watch_queue *wqueue;",
            "\tstruct watch *watch;",
            "\tint ret = -EBADSLT;",
            "",
            "\trcu_read_lock();",
            "",
            "again:",
            "\tspin_lock(&wlist->lock);",
            "\thlist_for_each_entry(watch, &wlist->watchers, list_node) {",
            "\t\tif (all ||",
            "\t\t    (watch->id == id && rcu_access_pointer(watch->queue) == wq))",
            "\t\t\tgoto found;",
            "\t}",
            "\tspin_unlock(&wlist->lock);",
            "\tgoto out;",
            "",
            "found:",
            "\tret = 0;",
            "\thlist_del_init_rcu(&watch->list_node);",
            "\trcu_assign_pointer(watch->watch_list, NULL);",
            "\tspin_unlock(&wlist->lock);",
            "",
            "\t/* We now own the reference on watch that used to belong to wlist. */",
            "",
            "\tn.watch.type = WATCH_TYPE_META;",
            "\tn.watch.subtype = WATCH_META_REMOVAL_NOTIFICATION;",
            "\tn.watch.info = watch->info_id | watch_sizeof(n.watch);",
            "\tn.id = id;",
            "\tif (id != 0)",
            "\t\tn.watch.info = watch->info_id | watch_sizeof(n);",
            "",
            "\twqueue = rcu_dereference(watch->queue);",
            "",
            "\tif (lock_wqueue(wqueue)) {",
            "\t\tpost_one_notification(wqueue, &n.watch);",
            "",
            "\t\tif (!hlist_unhashed(&watch->queue_node)) {",
            "\t\t\thlist_del_init_rcu(&watch->queue_node);",
            "\t\t\tput_watch(watch);",
            "\t\t}",
            "",
            "\t\tunlock_wqueue(wqueue);",
            "\t}",
            "",
            "\tif (wlist->release_watch) {",
            "\t\tvoid (*release_watch)(struct watch *);",
            "",
            "\t\trelease_watch = wlist->release_watch;",
            "\t\trcu_read_unlock();",
            "\t\t(*release_watch)(watch);",
            "\t\trcu_read_lock();",
            "\t}",
            "\tput_watch(watch);",
            "",
            "\tif (all && !hlist_empty(&wlist->watchers))",
            "\t\tgoto again;",
            "out:",
            "\trcu_read_unlock();",
            "\treturn ret;",
            "}"
          ],
          "function_name": "__put_watch, put_watch, init_watch, add_one_watch, add_watch_to_object, remove_watch_from_object",
          "description": "__put_watch通过RCU回调释放watch对象，init_watch初始化watch结构并绑定至watch_queue，add_one_watch将watch加入列表并增加引用计数，remove_watch_from_object安全移除watch并触发移除通知，维护watch列表的并发一致性。",
          "similarity": 0.45016375184059143
        }
      ]
    },
    {
      "source_file": "kernel/rcu/sync.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:44:18\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `rcu\\sync.c`\n\n---\n\n# rcu/sync.c 技术文档\n\n## 文件概述\n\n`rcu/sync.c` 实现了一个基于 RCU（Read-Copy-Update）机制的轻量级读写同步基础设施，称为 `rcu_sync`。该机制允许写者（更新者）在需要时强制所有读者切换到“慢路径”（slow path），并在更新完成后经过一个 RCU 宽限期（grace period）后，允许读者重新使用“快路径”（fast path）。该设计特别适用于需要频繁但短暂地禁用读者快路径的场景，避免了传统读写锁的开销，同时利用 RCU 的无锁读取特性提升性能。\n\n## 核心功能\n\n### 数据结构\n\n- **`struct rcu_sync`**  \n  核心同步控制结构，包含以下关键字段：\n  - `gp_state`：当前同步状态（`GP_IDLE`, `GP_ENTER`, `GP_PASSED`, `GP_EXIT`, `GP_REPLAY`）\n  - `gp_count`：嵌套的 `rcu_sync_enter()` 调用计数\n  - `cb_head`：用于 RCU 回调的 `rcu_head`\n  - `gp_wait`：等待队列，用于阻塞等待状态转换完成\n\n### 主要函数\n\n| 函数 | 功能描述 |\n|------|--------|\n| `rcu_sync_init()` | 初始化 `rcu_sync` 结构体 |\n| `rcu_sync_enter_start()` | 预激活同步机制，使 `rcu_sync_is_idle()` 返回 false，且后续 enter/exit 成为 NO-OP |\n| `rcu_sync_enter()` | 强制读者进入慢路径，确保后续读者不会使用快路径 |\n| `rcu_sync_exit()` | 标记更新结束，安排在宽限期后恢复读者快路径 |\n| `rcu_sync_dtor()` | 销毁 `rcu_sync` 结构，确保所有 RCU 回调已完成 |\n| `rcu_sync_func()` | RCU 回调函数，根据当前状态推进状态机 |\n\n## 关键实现\n\n### 状态机设计\n\n`rcu_sync` 使用五种状态实现高效的状态转换：\n\n- **`GP_IDLE`**：初始状态，读者可使用快路径。\n- **`GP_ENTER`**：正在进入同步状态，需等待宽限期。\n- **`GP_PASSED`**：宽限期已过，读者已全部进入慢路径。\n- **`GP_EXIT`**：正在退出同步，需等待另一个宽限期以恢复快路径。\n- **`GP_REPLAY`**：在退出过程中又有新的 enter/exit 对发生，需重新调度回调。\n\n### 嵌套与优化\n\n- **嵌套支持**：通过 `gp_count` 支持 `rcu_sync_enter()` 的嵌套调用。只有当 `gp_count` 从 1 递减到 0 时，才触发退出流程。\n- **宽限期合并**：连续的 `enter/exit` 调用可避免多次等待宽限期。例如：\n  - 若在 `GP_PASSED` 状态下调用 `exit`，直接进入 `GP_EXIT` 并调度回调。\n  - 若在回调执行前再次调用 `enter/exit`，状态转为 `GP_REPLAY`，并在回调中重新调度，避免冗余宽限期。\n- **快速路径优化**：首次 `enter` 时若处于 `GP_IDLE`，直接调用 `synchronize_rcu()` 而非异步 `call_rcu()`，可利用 `rcu_expedited` 或 `rcu_blocking_is_gp()` 加速。\n\n### 同步与唤醒\n\n- 写者调用 `rcu_sync_enter()` 后，若非首次进入，会阻塞在 `wait_event()`，直到状态变为 `GP_PASSED` 或更高。\n- `rcu_sync_func()` 在宽限期后执行，根据 `gp_count` 和当前状态决定是唤醒等待者、重调度回调，还是恢复到 `GP_IDLE`。\n\n## 依赖关系\n\n- **`<linux/rcu_sync.h>`**：定义 `struct rcu_sync` 及相关 API。\n- **`<linux/sched.h>`**：提供 `wait_event()`、`wake_up_locked()` 等调度和等待队列原语。\n- **RCU 子系统**：\n  - `call_rcu_hurry()` / `call_rcu()`：用于注册宽限期后的回调。\n  - `synchronize_rcu()`：用于同步等待宽限期。\n  - `rcu_barrier()`：在析构时确保所有回调完成。\n- **自旋锁**：使用 `spin_lock_irqsave()` 保护状态和计数器，确保中断上下文安全。\n\n## 使用场景\n\n- **文件系统元数据更新**：如 overlayfs、btrfs 等在修改共享元数据结构时，临时禁止读者使用快路径缓存。\n- **动态配置更新**：内核模块或子系统在热更新全局配置时，确保读者看到一致状态。\n- **轻量级写者同步**：适用于写操作较少但需高效读者路径的场景，避免传统 rwlock 的读者竞争开销。\n- **替代 `synchronize_rcu()` 的批量操作**：当多个连续更新可合并为一次宽限期等待时，提升性能。",
      "similarity": 0.5997166633605957,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/rcu/sync.c",
          "start_line": 21,
          "end_line": 136,
          "content": [
            "void rcu_sync_init(struct rcu_sync *rsp)",
            "{",
            "\tmemset(rsp, 0, sizeof(*rsp));",
            "\tinit_waitqueue_head(&rsp->gp_wait);",
            "}",
            "void rcu_sync_enter_start(struct rcu_sync *rsp)",
            "{",
            "\trsp->gp_count++;",
            "\trsp->gp_state = GP_PASSED;",
            "}",
            "static void rcu_sync_call(struct rcu_sync *rsp)",
            "{",
            "\tcall_rcu_hurry(&rsp->cb_head, rcu_sync_func);",
            "}",
            "static void rcu_sync_func(struct rcu_head *rhp)",
            "{",
            "\tstruct rcu_sync *rsp = container_of(rhp, struct rcu_sync, cb_head);",
            "\tunsigned long flags;",
            "",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_state) == GP_IDLE);",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_state) == GP_PASSED);",
            "",
            "\tspin_lock_irqsave(&rsp->rss_lock, flags);",
            "\tif (rsp->gp_count) {",
            "\t\t/*",
            "\t\t * We're at least a GP after the GP_IDLE->GP_ENTER transition.",
            "\t\t */",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_PASSED);",
            "\t\twake_up_locked(&rsp->gp_wait);",
            "\t} else if (rsp->gp_state == GP_REPLAY) {",
            "\t\t/*",
            "\t\t * A new rcu_sync_exit() has happened; requeue the callback to",
            "\t\t * catch a later GP.",
            "\t\t */",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_EXIT);",
            "\t\trcu_sync_call(rsp);",
            "\t} else {",
            "\t\t/*",
            "\t\t * We're at least a GP after the last rcu_sync_exit(); everybody",
            "\t\t * will now have observed the write side critical section.",
            "\t\t * Let 'em rip!",
            "\t\t */",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_IDLE);",
            "\t}",
            "\tspin_unlock_irqrestore(&rsp->rss_lock, flags);",
            "}",
            "void rcu_sync_enter(struct rcu_sync *rsp)",
            "{",
            "\tint gp_state;",
            "",
            "\tspin_lock_irq(&rsp->rss_lock);",
            "\tgp_state = rsp->gp_state;",
            "\tif (gp_state == GP_IDLE) {",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_ENTER);",
            "\t\tWARN_ON_ONCE(rsp->gp_count);",
            "\t\t/*",
            "\t\t * Note that we could simply do rcu_sync_call(rsp) here and",
            "\t\t * avoid the \"if (gp_state == GP_IDLE)\" block below.",
            "\t\t *",
            "\t\t * However, synchronize_rcu() can be faster if rcu_expedited",
            "\t\t * or rcu_blocking_is_gp() is true.",
            "\t\t *",
            "\t\t * Another reason is that we can't wait for rcu callback if",
            "\t\t * we are called at early boot time but this shouldn't happen.",
            "\t\t */",
            "\t}",
            "\trsp->gp_count++;",
            "\tspin_unlock_irq(&rsp->rss_lock);",
            "",
            "\tif (gp_state == GP_IDLE) {",
            "\t\t/*",
            "\t\t * See the comment above, this simply does the \"synchronous\"",
            "\t\t * call_rcu(rcu_sync_func) which does GP_ENTER -> GP_PASSED.",
            "\t\t */",
            "\t\tsynchronize_rcu();",
            "\t\trcu_sync_func(&rsp->cb_head);",
            "\t\t/* Not really needed, wait_event() would see GP_PASSED. */",
            "\t\treturn;",
            "\t}",
            "",
            "\twait_event(rsp->gp_wait, READ_ONCE(rsp->gp_state) >= GP_PASSED);",
            "}",
            "void rcu_sync_exit(struct rcu_sync *rsp)",
            "{",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_state) == GP_IDLE);",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_count) == 0);",
            "",
            "\tspin_lock_irq(&rsp->rss_lock);",
            "\tif (!--rsp->gp_count) {",
            "\t\tif (rsp->gp_state == GP_PASSED) {",
            "\t\t\tWRITE_ONCE(rsp->gp_state, GP_EXIT);",
            "\t\t\trcu_sync_call(rsp);",
            "\t\t} else if (rsp->gp_state == GP_EXIT) {",
            "\t\t\tWRITE_ONCE(rsp->gp_state, GP_REPLAY);",
            "\t\t}",
            "\t}",
            "\tspin_unlock_irq(&rsp->rss_lock);",
            "}",
            "void rcu_sync_dtor(struct rcu_sync *rsp)",
            "{",
            "\tint gp_state;",
            "",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_count));",
            "\tWARN_ON_ONCE(READ_ONCE(rsp->gp_state) == GP_PASSED);",
            "",
            "\tspin_lock_irq(&rsp->rss_lock);",
            "\tif (rsp->gp_state == GP_REPLAY)",
            "\t\tWRITE_ONCE(rsp->gp_state, GP_EXIT);",
            "\tgp_state = rsp->gp_state;",
            "\tspin_unlock_irq(&rsp->rss_lock);",
            "",
            "\tif (gp_state != GP_IDLE) {",
            "\t\trcu_barrier();",
            "\t\tWARN_ON_ONCE(rsp->gp_state != GP_IDLE);",
            "\t}",
            "}"
          ],
          "function_name": "rcu_sync_init, rcu_sync_enter_start, rcu_sync_call, rcu_sync_func, rcu_sync_enter, rcu_sync_exit, rcu_sync_dtor",
          "description": "实现了RCU同步核心函数，包括初始化、状态管理、回调触发和退出处理，通过spinlock保护状态机并利用RCU回调实现延迟同步，用于协调读者-写者并发访问的安全转换",
          "similarity": 0.561158299446106
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/rcu/sync.c",
          "start_line": 1,
          "end_line": 20,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0+",
            "/*",
            " * RCU-based infrastructure for lightweight reader-writer locking",
            " *",
            " * Copyright (c) 2015, Red Hat, Inc.",
            " *",
            " * Author: Oleg Nesterov <oleg@redhat.com>",
            " */",
            "",
            "#include <linux/rcu_sync.h>",
            "#include <linux/sched.h>",
            "",
            "enum { GP_IDLE = 0, GP_ENTER, GP_PASSED, GP_EXIT, GP_REPLAY };",
            "",
            "#define\trss_lock\tgp_wait.lock",
            "",
            "/**",
            " * rcu_sync_init() - Initialize an rcu_sync structure",
            " * @rsp: Pointer to rcu_sync structure to be initialized",
            " */"
          ],
          "function_name": null,
          "description": "定义了RCU同步基础设施的枚举常量和rcu_sync_init函数声明，用于初始化rcu_sync结构体，但代码上下文不完整",
          "similarity": 0.5223935842514038
        }
      ]
    },
    {
      "source_file": "kernel/relay.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:52:35\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `relay.c`\n\n---\n\n# relay.c 技术文档\n\n## 1. 文件概述\n\n`relay.c` 实现了 Linux 内核中 **relay 通道（relay channel）** 的核心功能，用于高效地将内核空间的数据流式传输到用户空间。该机制通过预分配的环形缓冲区（由多个子缓冲区组成）实现零拷贝或最小拷贝的数据传递，特别适用于高性能追踪（tracing）、日志记录和监控等场景。用户空间可通过标准文件操作（如 `mmap`、`read`）访问这些缓冲区。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct rchan`：relay 通道的主结构体，包含通道配置、回调函数和 per-CPU 缓冲区指针。\n- `struct rchan_buf`：单个 CPU 的 relay 缓冲区结构体，包含实际数据缓冲区、状态信息（生产/消费计数器）和同步原语。\n\n### 关键函数\n- **缓冲区管理**：\n  - `relay_create_buf()`：为指定通道创建并初始化 per-CPU 缓冲区。\n  - `relay_destroy_buf()`：销毁缓冲区并释放资源。\n  - `relay_alloc_buf()`：分配物理页面并映射为连续虚拟地址的缓冲区。\n- **内存映射**：\n  - `relay_mmap_buf()`：将内核缓冲区映射到用户进程地址空间。\n  - `relay_buf_fault()`：处理用户空间访问映射区域时的缺页异常。\n- **状态控制**：\n  - `relay_reset()`：重置通道状态，清空所有缓冲区数据。\n  - `relay_buf_empty()` / `relay_buf_full()`：检查缓冲区是否为空或已满。\n- **资源回收**：\n  - `relay_destroy_channel()`：通过 `kref` 引用计数释放通道结构。\n  - `relay_remove_buf()`：通过 `kref` 释放缓冲区结构。\n- **辅助功能**：\n  - `wakeup_readers()`：通过 `irq_work` 机制唤醒等待读取数据的用户进程。\n\n## 3. 关键实现\n\n### 缓冲区分配策略\n- 使用 `alloc_page()` 分配离散物理页面，通过 `vmap()` 建立连续虚拟地址映射，避免大块连续物理内存分配失败。\n- 页面指针数组 (`page_array`) 用于管理物理页面，支持高效的 `vunmap()` 释放。\n\n### 用户空间映射机制\n- 通过 `vm_operations_struct.fault` 回调 (`relay_buf_fault`) 实现按需映射：用户访问映射区域时，动态将内核 `vmalloc` 区域的页面映射到用户页表。\n- 设置 `VM_DONTEXPAND` 标志防止用户空间扩展映射区域。\n\n### 环形缓冲区管理\n- 采用 **子缓冲区（subbuffer）** 作为基本单元，通过 `subbufs_produced` 和 `subbufs_consumed` 计数器实现生产者-消费者模型。\n- `subbuf_start` 回调允许用户自定义子缓冲区切换逻辑（如添加头部信息）。\n\n### 并发与同步\n- **Per-CPU 缓冲区**：每个 CPU 独立缓冲区避免锁竞争，提升多核性能。\n- **延迟唤醒**：使用 `irq_work` 机制将唤醒操作推迟到软中断上下文，避免在硬中断中调用 `wake_up_interruptible()`。\n- **引用计数**：通过 `kref` 确保通道和缓冲区在异步操作（如文件关闭）中安全释放。\n\n### CPU 热插拔支持\n- 全局链表 `relay_channels` 跟踪所有打开的通道，配合 `relay_channels_mutex` 锁，在 CPU 热插拔事件中动态创建/销毁 per-CPU 缓冲区。\n\n## 4. 依赖关系\n\n- **内存管理**：依赖 `vmalloc`、`vmap`/`vunmap`、`alloc_page` 等内存分配接口。\n- **同步原语**：使用 `mutex`（`relay_channels_mutex`）、`waitqueue`（`read_wait`）、`irq_work` 和 `kref`。\n- **CPU 热插拔**：通过 `for_each_possible_cpu` 和 per-CPU 变量 (`per_cpu_ptr`) 管理多核资源。\n- **VFS 层**：与文件系统交互（`mmap`、`splice`），但具体文件操作在 `relayfs` 或 `debugfs` 中实现。\n- **导出符号**：`relay_buf_full()` 通过 `EXPORT_SYMBOL_GPL` 供其他内核模块使用。\n\n## 5. 使用场景\n\n- **内核追踪系统**：如 `ftrace`、`perf` 使用 relay 通道高效导出追踪数据到用户空间。\n- **实时日志记录**：需要低延迟、高吞吐量的日志场景（如网络数据包捕获）。\n- **性能监控**：将内核统计信息（如调度事件、块设备 I/O）流式传输到用户态分析工具。\n- **调试工具**：通过 `debugfs` 暴露 relay 通道，供用户态调试器实时读取内核状态。",
      "similarity": 0.5918503999710083,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "kernel/relay.c",
          "start_line": 1076,
          "end_line": 1186,
          "content": [
            "static void relay_consume_bytes(struct rchan_buf *rbuf, int bytes_consumed)",
            "{",
            "\trbuf->bytes_consumed += bytes_consumed;",
            "",
            "\tif (rbuf->bytes_consumed >= rbuf->chan->subbuf_size) {",
            "\t\trelay_subbufs_consumed(rbuf->chan, rbuf->cpu, 1);",
            "\t\trbuf->bytes_consumed %= rbuf->chan->subbuf_size;",
            "\t}",
            "}",
            "static void relay_pipe_buf_release(struct pipe_inode_info *pipe,",
            "\t\t\t\t   struct pipe_buffer *buf)",
            "{",
            "\tstruct rchan_buf *rbuf;",
            "",
            "\trbuf = (struct rchan_buf *)page_private(buf->page);",
            "\trelay_consume_bytes(rbuf, buf->private);",
            "}",
            "static void relay_page_release(struct splice_pipe_desc *spd, unsigned int i)",
            "{",
            "}",
            "static ssize_t subbuf_splice_actor(struct file *in,",
            "\t\t\t       loff_t *ppos,",
            "\t\t\t       struct pipe_inode_info *pipe,",
            "\t\t\t       size_t len,",
            "\t\t\t       unsigned int flags,",
            "\t\t\t       int *nonpad_ret)",
            "{",
            "\tunsigned int pidx, poff, total_len, subbuf_pages, nr_pages;",
            "\tstruct rchan_buf *rbuf = in->private_data;",
            "\tunsigned int subbuf_size = rbuf->chan->subbuf_size;",
            "\tuint64_t pos = (uint64_t) *ppos;",
            "\tuint32_t alloc_size = (uint32_t) rbuf->chan->alloc_size;",
            "\tsize_t read_start = (size_t) do_div(pos, alloc_size);",
            "\tsize_t read_subbuf = read_start / subbuf_size;",
            "\tsize_t padding = rbuf->padding[read_subbuf];",
            "\tsize_t nonpad_end = read_subbuf * subbuf_size + subbuf_size - padding;",
            "\tstruct page *pages[PIPE_DEF_BUFFERS];",
            "\tstruct partial_page partial[PIPE_DEF_BUFFERS];",
            "\tstruct splice_pipe_desc spd = {",
            "\t\t.pages = pages,",
            "\t\t.nr_pages = 0,",
            "\t\t.nr_pages_max = PIPE_DEF_BUFFERS,",
            "\t\t.partial = partial,",
            "\t\t.ops = &relay_pipe_buf_ops,",
            "\t\t.spd_release = relay_page_release,",
            "\t};",
            "\tssize_t ret;",
            "",
            "\tif (rbuf->subbufs_produced == rbuf->subbufs_consumed)",
            "\t\treturn 0;",
            "\tif (splice_grow_spd(pipe, &spd))",
            "\t\treturn -ENOMEM;",
            "",
            "\t/*",
            "\t * Adjust read len, if longer than what is available",
            "\t */",
            "\tif (len > (subbuf_size - read_start % subbuf_size))",
            "\t\tlen = subbuf_size - read_start % subbuf_size;",
            "",
            "\tsubbuf_pages = rbuf->chan->alloc_size >> PAGE_SHIFT;",
            "\tpidx = (read_start / PAGE_SIZE) % subbuf_pages;",
            "\tpoff = read_start & ~PAGE_MASK;",
            "\tnr_pages = min_t(unsigned int, subbuf_pages, spd.nr_pages_max);",
            "",
            "\tfor (total_len = 0; spd.nr_pages < nr_pages; spd.nr_pages++) {",
            "\t\tunsigned int this_len, this_end, private;",
            "\t\tunsigned int cur_pos = read_start + total_len;",
            "",
            "\t\tif (!len)",
            "\t\t\tbreak;",
            "",
            "\t\tthis_len = min_t(unsigned long, len, PAGE_SIZE - poff);",
            "\t\tprivate = this_len;",
            "",
            "\t\tspd.pages[spd.nr_pages] = rbuf->page_array[pidx];",
            "\t\tspd.partial[spd.nr_pages].offset = poff;",
            "",
            "\t\tthis_end = cur_pos + this_len;",
            "\t\tif (this_end >= nonpad_end) {",
            "\t\t\tthis_len = nonpad_end - cur_pos;",
            "\t\t\tprivate = this_len + padding;",
            "\t\t}",
            "\t\tspd.partial[spd.nr_pages].len = this_len;",
            "\t\tspd.partial[spd.nr_pages].private = private;",
            "",
            "\t\tlen -= this_len;",
            "\t\ttotal_len += this_len;",
            "\t\tpoff = 0;",
            "\t\tpidx = (pidx + 1) % subbuf_pages;",
            "",
            "\t\tif (this_end >= nonpad_end) {",
            "\t\t\tspd.nr_pages++;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "",
            "\tret = 0;",
            "\tif (!spd.nr_pages)",
            "\t\tgoto out;",
            "",
            "\tret = *nonpad_ret = splice_to_pipe(pipe, &spd);",
            "\tif (ret < 0 || ret < total_len)",
            "\t\tgoto out;",
            "",
            "        if (read_start + ret == nonpad_end)",
            "                ret += padding;",
            "",
            "out:",
            "\tsplice_shrink_spd(&spd);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "relay_consume_bytes, relay_pipe_buf_release, relay_page_release, subbuf_splice_actor",
          "description": "记录并更新 relay 缓冲区已消费字节数；释放管道缓冲区并触发 consume_bytes 操作；处理 splice 分页数据时的页面释放逻辑；实现分页数据复制到管道的 actor 函数，处理填充区域和页面分配。上下文不完整",
          "similarity": 0.5624107122421265
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/relay.c",
          "start_line": 659,
          "end_line": 772,
          "content": [
            "size_t relay_switch_subbuf(struct rchan_buf *buf, size_t length)",
            "{",
            "\tvoid *old, *new;",
            "\tsize_t old_subbuf, new_subbuf;",
            "",
            "\tif (unlikely(length > buf->chan->subbuf_size))",
            "\t\tgoto toobig;",
            "",
            "\tif (buf->offset != buf->chan->subbuf_size + 1) {",
            "\t\tbuf->prev_padding = buf->chan->subbuf_size - buf->offset;",
            "\t\told_subbuf = buf->subbufs_produced % buf->chan->n_subbufs;",
            "\t\tbuf->padding[old_subbuf] = buf->prev_padding;",
            "\t\tbuf->subbufs_produced++;",
            "\t\tif (buf->dentry)",
            "\t\t\td_inode(buf->dentry)->i_size +=",
            "\t\t\t\tbuf->chan->subbuf_size -",
            "\t\t\t\tbuf->padding[old_subbuf];",
            "\t\telse",
            "\t\t\tbuf->early_bytes += buf->chan->subbuf_size -",
            "\t\t\t\t\t    buf->padding[old_subbuf];",
            "\t\tsmp_mb();",
            "\t\tif (waitqueue_active(&buf->read_wait)) {",
            "\t\t\t/*",
            "\t\t\t * Calling wake_up_interruptible() from here",
            "\t\t\t * will deadlock if we happen to be logging",
            "\t\t\t * from the scheduler (trying to re-grab",
            "\t\t\t * rq->lock), so defer it.",
            "\t\t\t */",
            "\t\t\tirq_work_queue(&buf->wakeup_work);",
            "\t\t}",
            "\t}",
            "",
            "\told = buf->data;",
            "\tnew_subbuf = buf->subbufs_produced % buf->chan->n_subbufs;",
            "\tnew = buf->start + new_subbuf * buf->chan->subbuf_size;",
            "\tbuf->offset = 0;",
            "\tif (!relay_subbuf_start(buf, new, old, buf->prev_padding)) {",
            "\t\tbuf->offset = buf->chan->subbuf_size + 1;",
            "\t\treturn 0;",
            "\t}",
            "\tbuf->data = new;",
            "\tbuf->padding[new_subbuf] = 0;",
            "",
            "\tif (unlikely(length + buf->offset > buf->chan->subbuf_size))",
            "\t\tgoto toobig;",
            "",
            "\treturn length;",
            "",
            "toobig:",
            "\tbuf->chan->last_toobig = length;",
            "\treturn 0;",
            "}",
            "void relay_subbufs_consumed(struct rchan *chan,",
            "\t\t\t    unsigned int cpu,",
            "\t\t\t    size_t subbufs_consumed)",
            "{",
            "\tstruct rchan_buf *buf;",
            "",
            "\tif (!chan || cpu >= NR_CPUS)",
            "\t\treturn;",
            "",
            "\tbuf = *per_cpu_ptr(chan->buf, cpu);",
            "\tif (!buf || subbufs_consumed > chan->n_subbufs)",
            "\t\treturn;",
            "",
            "\tif (subbufs_consumed > buf->subbufs_produced - buf->subbufs_consumed)",
            "\t\tbuf->subbufs_consumed = buf->subbufs_produced;",
            "\telse",
            "\t\tbuf->subbufs_consumed += subbufs_consumed;",
            "}",
            "void relay_close(struct rchan *chan)",
            "{",
            "\tstruct rchan_buf *buf;",
            "\tunsigned int i;",
            "",
            "\tif (!chan)",
            "\t\treturn;",
            "",
            "\tmutex_lock(&relay_channels_mutex);",
            "\tif (chan->is_global && (buf = *per_cpu_ptr(chan->buf, 0)))",
            "\t\trelay_close_buf(buf);",
            "\telse",
            "\t\tfor_each_possible_cpu(i)",
            "\t\t\tif ((buf = *per_cpu_ptr(chan->buf, i)))",
            "\t\t\t\trelay_close_buf(buf);",
            "",
            "\tif (chan->last_toobig)",
            "\t\tprintk(KERN_WARNING \"relay: one or more items not logged \"",
            "\t\t       \"[item size (%zd) > sub-buffer size (%zd)]\\n\",",
            "\t\t       chan->last_toobig, chan->subbuf_size);",
            "",
            "\tlist_del(&chan->list);",
            "\tkref_put(&chan->kref, relay_destroy_channel);",
            "\tmutex_unlock(&relay_channels_mutex);",
            "}",
            "void relay_flush(struct rchan *chan)",
            "{",
            "\tstruct rchan_buf *buf;",
            "\tunsigned int i;",
            "",
            "\tif (!chan)",
            "\t\treturn;",
            "",
            "\tif (chan->is_global && (buf = *per_cpu_ptr(chan->buf, 0))) {",
            "\t\trelay_switch_subbuf(buf, 0);",
            "\t\treturn;",
            "\t}",
            "",
            "\tmutex_lock(&relay_channels_mutex);",
            "\tfor_each_possible_cpu(i)",
            "\t\tif ((buf = *per_cpu_ptr(chan->buf, i)))",
            "\t\t\trelay_switch_subbuf(buf, 0);",
            "\tmutex_unlock(&relay_channels_mutex);",
            "}"
          ],
          "function_name": "relay_switch_subbuf, relay_subbufs_consumed, relay_close, relay_flush",
          "description": "实现子缓冲区切换逻辑、消费计数更新、通道关闭及刷新操作，包含数据溢出检测、缓冲区状态同步及日志完整性保障机制。",
          "similarity": 0.5083426833152771
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/relay.c",
          "start_line": 1,
          "end_line": 32,
          "content": [
            "/*",
            " * Public API and common code for kernel->userspace relay file support.",
            " *",
            " * See Documentation/filesystems/relay.rst for an overview.",
            " *",
            " * Copyright (C) 2002-2005 - Tom Zanussi (zanussi@us.ibm.com), IBM Corp",
            " * Copyright (C) 1999-2005 - Karim Yaghmour (karim@opersys.com)",
            " *",
            " * Moved to kernel/relay.c by Paul Mundt, 2006.",
            " * November 2006 - CPU hotplug support by Mathieu Desnoyers",
            " * \t(mathieu.desnoyers@polymtl.ca)",
            " *",
            " * This file is released under the GPL.",
            " */",
            "#include <linux/errno.h>",
            "#include <linux/stddef.h>",
            "#include <linux/slab.h>",
            "#include <linux/export.h>",
            "#include <linux/string.h>",
            "#include <linux/relay.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/mm.h>",
            "#include <linux/cpu.h>",
            "#include <linux/splice.h>",
            "",
            "/* list of open channels, for cpu hotplug */",
            "static DEFINE_MUTEX(relay_channels_mutex);",
            "static LIST_HEAD(relay_channels);",
            "",
            "/*",
            " * fault() vm_op implementation for relay file mapping.",
            " */"
          ],
          "function_name": null,
          "description": "定义了Relay子系统的公共API和通用代码，包含用于管理内核到用户空间数据中继的核心结构体、互斥锁及链表，用于CPU热插拔支持的通道列表管理。",
          "similarity": 0.4937061667442322
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/relay.c",
          "start_line": 1200,
          "end_line": 1236,
          "content": [
            "static ssize_t relay_file_splice_read(struct file *in,",
            "\t\t\t\t      loff_t *ppos,",
            "\t\t\t\t      struct pipe_inode_info *pipe,",
            "\t\t\t\t      size_t len,",
            "\t\t\t\t      unsigned int flags)",
            "{",
            "\tssize_t spliced;",
            "\tint ret;",
            "\tint nonpad_ret = 0;",
            "",
            "\tret = 0;",
            "\tspliced = 0;",
            "",
            "\twhile (len && !spliced) {",
            "\t\tret = subbuf_splice_actor(in, ppos, pipe, len, flags, &nonpad_ret);",
            "\t\tif (ret < 0)",
            "\t\t\tbreak;",
            "\t\telse if (!ret) {",
            "\t\t\tif (flags & SPLICE_F_NONBLOCK)",
            "\t\t\t\tret = -EAGAIN;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\t*ppos += ret;",
            "\t\tif (ret > len)",
            "\t\t\tlen = 0;",
            "\t\telse",
            "\t\t\tlen -= ret;",
            "\t\tspliced += nonpad_ret;",
            "\t\tnonpad_ret = 0;",
            "\t}",
            "",
            "\tif (spliced)",
            "\t\treturn spliced;",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "relay_file_splice_read",
          "description": "通过循环调用 subbuf_splice_actor 实现 splice 式读取，累计非填充数据量并更新文件偏移量，支持非阻塞模式下的读取操作。",
          "similarity": 0.49213626980781555
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/relay.c",
          "start_line": 319,
          "end_line": 456,
          "content": [
            "void relay_reset(struct rchan *chan)",
            "{",
            "\tstruct rchan_buf *buf;",
            "\tunsigned int i;",
            "",
            "\tif (!chan)",
            "\t\treturn;",
            "",
            "\tif (chan->is_global && (buf = *per_cpu_ptr(chan->buf, 0))) {",
            "\t\t__relay_reset(buf, 0);",
            "\t\treturn;",
            "\t}",
            "",
            "\tmutex_lock(&relay_channels_mutex);",
            "\tfor_each_possible_cpu(i)",
            "\t\tif ((buf = *per_cpu_ptr(chan->buf, i)))",
            "\t\t\t__relay_reset(buf, 0);",
            "\tmutex_unlock(&relay_channels_mutex);",
            "}",
            "static inline void relay_set_buf_dentry(struct rchan_buf *buf,",
            "\t\t\t\t\tstruct dentry *dentry)",
            "{",
            "\tbuf->dentry = dentry;",
            "\td_inode(buf->dentry)->i_size = buf->early_bytes;",
            "}",
            "static void relay_close_buf(struct rchan_buf *buf)",
            "{",
            "\tbuf->finalized = 1;",
            "\tirq_work_sync(&buf->wakeup_work);",
            "\tbuf->chan->cb->remove_buf_file(buf->dentry);",
            "\tkref_put(&buf->kref, relay_remove_buf);",
            "}",
            "int relay_prepare_cpu(unsigned int cpu)",
            "{",
            "\tstruct rchan *chan;",
            "\tstruct rchan_buf *buf;",
            "",
            "\tmutex_lock(&relay_channels_mutex);",
            "\tlist_for_each_entry(chan, &relay_channels, list) {",
            "\t\tif (*per_cpu_ptr(chan->buf, cpu))",
            "\t\t\tcontinue;",
            "\t\tbuf = relay_open_buf(chan, cpu);",
            "\t\tif (!buf) {",
            "\t\t\tpr_err(\"relay: cpu %d buffer creation failed\\n\", cpu);",
            "\t\t\tmutex_unlock(&relay_channels_mutex);",
            "\t\t\treturn -ENOMEM;",
            "\t\t}",
            "\t\t*per_cpu_ptr(chan->buf, cpu) = buf;",
            "\t}",
            "\tmutex_unlock(&relay_channels_mutex);",
            "\treturn 0;",
            "}",
            "static void __relay_set_buf_dentry(void *info)",
            "{",
            "\tstruct rchan_percpu_buf_dispatcher *p = info;",
            "",
            "\trelay_set_buf_dentry(p->buf, p->dentry);",
            "}",
            "int relay_late_setup_files(struct rchan *chan,",
            "\t\t\t   const char *base_filename,",
            "\t\t\t   struct dentry *parent)",
            "{",
            "\tint err = 0;",
            "\tunsigned int i, curr_cpu;",
            "\tunsigned long flags;",
            "\tstruct dentry *dentry;",
            "\tstruct rchan_buf *buf;",
            "\tstruct rchan_percpu_buf_dispatcher disp;",
            "",
            "\tif (!chan || !base_filename)",
            "\t\treturn -EINVAL;",
            "",
            "\tstrscpy(chan->base_filename, base_filename, NAME_MAX);",
            "",
            "\tmutex_lock(&relay_channels_mutex);",
            "\t/* Is chan already set up? */",
            "\tif (unlikely(chan->has_base_filename)) {",
            "\t\tmutex_unlock(&relay_channels_mutex);",
            "\t\treturn -EEXIST;",
            "\t}",
            "\tchan->has_base_filename = 1;",
            "\tchan->parent = parent;",
            "",
            "\tif (chan->is_global) {",
            "\t\terr = -EINVAL;",
            "\t\tbuf = *per_cpu_ptr(chan->buf, 0);",
            "\t\tif (!WARN_ON_ONCE(!buf)) {",
            "\t\t\tdentry = relay_create_buf_file(chan, buf, 0);",
            "\t\t\tif (dentry && !WARN_ON_ONCE(!chan->is_global)) {",
            "\t\t\t\trelay_set_buf_dentry(buf, dentry);",
            "\t\t\t\terr = 0;",
            "\t\t\t}",
            "\t\t}",
            "\t\tmutex_unlock(&relay_channels_mutex);",
            "\t\treturn err;",
            "\t}",
            "",
            "\tcurr_cpu = get_cpu();",
            "\t/*",
            "\t * The CPU hotplug notifier ran before us and created buffers with",
            "\t * no files associated. So it's safe to call relay_setup_buf_file()",
            "\t * on all currently online CPUs.",
            "\t */",
            "\tfor_each_online_cpu(i) {",
            "\t\tbuf = *per_cpu_ptr(chan->buf, i);",
            "\t\tif (unlikely(!buf)) {",
            "\t\t\tWARN_ONCE(1, KERN_ERR \"CPU has no buffer!\\n\");",
            "\t\t\terr = -EINVAL;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tdentry = relay_create_buf_file(chan, buf, i);",
            "\t\tif (unlikely(!dentry)) {",
            "\t\t\terr = -EINVAL;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tif (curr_cpu == i) {",
            "\t\t\tlocal_irq_save(flags);",
            "\t\t\trelay_set_buf_dentry(buf, dentry);",
            "\t\t\tlocal_irq_restore(flags);",
            "\t\t} else {",
            "\t\t\tdisp.buf = buf;",
            "\t\t\tdisp.dentry = dentry;",
            "\t\t\tsmp_mb();",
            "\t\t\t/* relay_channels_mutex must be held, so wait. */",
            "\t\t\terr = smp_call_function_single(i,",
            "\t\t\t\t\t\t       __relay_set_buf_dentry,",
            "\t\t\t\t\t\t       &disp, 1);",
            "\t\t}",
            "\t\tif (unlikely(err))",
            "\t\t\tbreak;",
            "\t}",
            "\tput_cpu();",
            "\tmutex_unlock(&relay_channels_mutex);",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "relay_reset, relay_set_buf_dentry, relay_close_buf, relay_prepare_cpu, __relay_set_buf_dentry, relay_late_setup_files",
          "description": "处理Relay缓冲区的重置、Dentry绑定、CPU缓冲区准备及后期文件系统设置，通过互斥锁保护多CPU环境下的缓冲区一致性。",
          "similarity": 0.4905267357826233
        }
      ]
    }
  ]
}