{
  "query": "file system cache",
  "timestamp": "2025-12-26 00:21:37",
  "retrieved_files": [
    {
      "source_file": "mm/kfence/core.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:23:33\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kfence\\core.c`\n\n---\n\n# `kfence/core.c` 技术文档\n\n## 1. 文件概述\n\n`kfence/core.c` 是 Linux 内核中 **KFENCE（Kernel Electric Fence）** 动态内存错误检测机制的核心实现文件。KFENCE 是一种低开销的运行时内存安全检测器，用于捕获堆内存中的越界访问、释放后使用（Use-After-Free）、重复释放等常见内存错误。\n\n该文件实现了 KFENCE 的对象分配器、故障处理逻辑、元数据管理、统计计数、参数控制以及与内核其他子系统的集成（如 debugfs、panic notifier 等）。其设计目标是在极低性能开销（通常 <1%）的前提下提供接近 100% 的内存错误检出能力。\n\n## 2. 核心功能\n\n### 主要全局变量\n- `kfence_enabled`：KFENCE 是否启用的全局开关。\n- `__kfence_pool`：KFENCE 使用的专用内存池，包含交错排列的保护页（guard pages）和实际对象页。\n- `kfence_metadata` / `kfence_metadata_init`：每个 KFENCE 对象对应的元数据数组，记录分配状态、地址、栈追踪等信息。\n- `kfence_freelist`：空闲 KFENCE 对象链表，受 `kfence_freelist_lock` 自旋锁保护。\n- `kfence_allocation_key`：静态键（static key），用于在 KFENCE 禁用时快速跳过分配路径。\n- `kfence_allocation_gate`：原子变量，用于控制采样周期内仅允许一次 KFENCE 分配。\n- `alloc_covered[]`：基于 Counting Bloom Filter 的分配覆盖跟踪结构，避免相同调用栈过度占用池资源。\n- `counters[]`：各类统计计数器（已分配数、总分配/释放次数、bug 数等）。\n\n### 主要模块参数（可通过 `/sys/module/kfence/parameters/` 调整）\n- `sample_interval`：采样间隔（纳秒），控制 KFENCE 分配频率；设为 0 可动态禁用 KFENCE。\n- `skip_covered_thresh`：当池使用率超过此百分比（默认 75%）时，跳过已覆盖（重复栈）的分配。\n- `burst`：每次采样允许的超额分配数量（用于应对突发分配）。\n- `deferrable`：是否使用可延迟定时器（降低功耗）。\n- `check_on_panic`：在内核 panic 时是否检查所有对象的 canary 值。\n\n### 关键辅助函数\n- `should_skip_covered()`：判断当前是否应跳过“已覆盖”的分配请求。\n- `get_alloc_stack_hash()`：获取分配调用栈的哈希值（用于唯一性识别）。\n- `alloc_covered_add()` / `alloc_covered_contains()`：操作 Counting Bloom Filter，记录或查询某调用栈是否已被覆盖。\n\n### 宏定义\n- `KFENCE_WARN_ON(cond)`：增强版 `WARN_ON`，触发警告时自动禁用 KFENCE 并标记 `disabled_by_warn`。\n\n## 3. 关键实现\n\n### 内存布局与保护机制\nKFENCE 内存池 (`__kfence_pool`) 由交替的 **保护页（不可访问）** 和 **对象页（可分配）** 组成。每个对象页前后均有保护页隔离。任何对保护页的访问都会触发页错误，由 KFENCE 的页错误处理程序捕获并报告越界访问。\n\n### 元数据初始化安全\n通过分离 `kfence_metadata_init`（初始化阶段使用）和 `kfence_metadata`（初始化完成后赋值），确保在 `kfence_shutdown_cache()` 等路径中不会访问未完全初始化的元数据，防止 UAF 或未定义行为。\n\n### 分配去重（Coverage Skipping）\n采用 **Counting Bloom Filter** 跟踪已分配对象的调用栈哈希：\n- 使用双哈希函数（`ALLOC_COVERED_HNUM=2`）减少冲突。\n- 当池使用率超过 `kfence_skip_covered_thresh`（默认 75%）时，若新分配的调用栈已在 Bloom Filter 中存在，则跳过此次 KFENCE 分配，转而使用普通分配器，避免池被重复模式占满。\n\n### 动态启停与采样控制\n- 通过 `sample_interval` 模块参数支持运行时启用/禁用。\n- 使用 `kfence_allocation_gate` 原子变量配合高精度定时器实现基于时间的采样，确保分配稀疏性。\n- 若因严重错误（如元数据损坏）触发 `KFENCE_WARN_ON`，则永久禁用 KFENCE。\n\n### 统计与调试支持\n- 提供 8 类原子计数器，通过 debugfs 导出（通常位于 `/sys/kernel/debug/kfence/`）。\n- 支持 panic 时全量 canary 检查（`kfence_check_on_panic`），辅助诊断延迟暴露的内存破坏。\n\n## 4. 依赖关系\n\n- **架构相关代码**：依赖 `<asm/kfence.h>` 提供的架构特定实现（如页错误处理、内存属性设置）。\n- **内存管理子系统**：使用 `memblock` 在启动早期预留内存池；与 SLAB/SLUB 分配器集成，在 `kmalloc` 路径中插入 KFENCE 分配逻辑。\n- **调试基础设施**：集成 `debugfs` 导出统计信息；使用 `panic_notifier` 实现 panic 时检查；依赖 `kcsan-checks.h` 确保与 KCSAN 兼容。\n- **同步原语**：使用 `raw_spinlock_t` 保护空闲链表；利用 `static_key` 优化热路径性能。\n- **随机数与哈希**：使用 `jhash` 和启动时随机种子 `stack_hash_seed` 生成调用栈哈希，增强跨重启的检测多样性。\n\n## 5. 使用场景\n\n- **开发与测试阶段**：作为内核内存错误检测工具，替代或补充 KASAN（尤其适用于资源受限或无法承受 KASAN 开销的场景）。\n- **生产环境监控**：因其极低开销（默认采样率下 <1% CPU），可用于长期运行的生产系统中捕获偶发内存错误。\n- **安全漏洞挖掘**：帮助发现内核驱动或子系统中的堆溢出、UAF 等安全漏洞。\n- **内核稳定性分析**：通过 debugfs 统计数据评估系统内存分配行为及潜在风险点。\n- **panic 事后分析**：结合 `check_on_panic` 选项，在系统崩溃时验证 KFENCE 对象完整性，辅助根因定位。",
      "similarity": 0.5761401057243347,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "mm/kfence/core.c",
          "start_line": 993,
          "end_line": 1099,
          "content": [
            "static int kfence_enable_late(void)",
            "{",
            "\tif (!__kfence_pool)",
            "\t\treturn kfence_init_late();",
            "",
            "\tWRITE_ONCE(kfence_enabled, true);",
            "\tqueue_delayed_work(system_unbound_wq, &kfence_timer, 0);",
            "\tpr_info(\"re-enabled\\n\");",
            "\treturn 0;",
            "}",
            "void kfence_shutdown_cache(struct kmem_cache *s)",
            "{",
            "\tunsigned long flags;",
            "\tstruct kfence_metadata *meta;",
            "\tint i;",
            "",
            "\t/* Pairs with release in kfence_init_pool(). */",
            "\tif (!smp_load_acquire(&kfence_metadata))",
            "\t\treturn;",
            "",
            "\tfor (i = 0; i < CONFIG_KFENCE_NUM_OBJECTS; i++) {",
            "\t\tbool in_use;",
            "",
            "\t\tmeta = &kfence_metadata[i];",
            "",
            "\t\t/*",
            "\t\t * If we observe some inconsistent cache and state pair where we",
            "\t\t * should have returned false here, cache destruction is racing",
            "\t\t * with either kmem_cache_alloc() or kmem_cache_free(). Taking",
            "\t\t * the lock will not help, as different critical section",
            "\t\t * serialization will have the same outcome.",
            "\t\t */",
            "\t\tif (READ_ONCE(meta->cache) != s || !kfence_obj_allocated(meta))",
            "\t\t\tcontinue;",
            "",
            "\t\traw_spin_lock_irqsave(&meta->lock, flags);",
            "\t\tin_use = meta->cache == s && kfence_obj_allocated(meta);",
            "\t\traw_spin_unlock_irqrestore(&meta->lock, flags);",
            "",
            "\t\tif (in_use) {",
            "\t\t\t/*",
            "\t\t\t * This cache still has allocations, and we should not",
            "\t\t\t * release them back into the freelist so they can still",
            "\t\t\t * safely be used and retain the kernel's default",
            "\t\t\t * behaviour of keeping the allocations alive (leak the",
            "\t\t\t * cache); however, they effectively become \"zombie",
            "\t\t\t * allocations\" as the KFENCE objects are the only ones",
            "\t\t\t * still in use and the owning cache is being destroyed.",
            "\t\t\t *",
            "\t\t\t * We mark them freed, so that any subsequent use shows",
            "\t\t\t * more useful error messages that will include stack",
            "\t\t\t * traces of the user of the object, the original",
            "\t\t\t * allocation, and caller to shutdown_cache().",
            "\t\t\t */",
            "\t\t\tkfence_guarded_free((void *)meta->addr, meta, /*zombie=*/true);",
            "\t\t}",
            "\t}",
            "",
            "\tfor (i = 0; i < CONFIG_KFENCE_NUM_OBJECTS; i++) {",
            "\t\tmeta = &kfence_metadata[i];",
            "",
            "\t\t/* See above. */",
            "\t\tif (READ_ONCE(meta->cache) != s || READ_ONCE(meta->state) != KFENCE_OBJECT_FREED)",
            "\t\t\tcontinue;",
            "",
            "\t\traw_spin_lock_irqsave(&meta->lock, flags);",
            "\t\tif (meta->cache == s && meta->state == KFENCE_OBJECT_FREED)",
            "\t\t\tmeta->cache = NULL;",
            "\t\traw_spin_unlock_irqrestore(&meta->lock, flags);",
            "\t}",
            "}",
            "size_t kfence_ksize(const void *addr)",
            "{",
            "\tconst struct kfence_metadata *meta = addr_to_metadata((unsigned long)addr);",
            "",
            "\t/*",
            "\t * Read locklessly -- if there is a race with __kfence_alloc(), this is",
            "\t * either a use-after-free or invalid access.",
            "\t */",
            "\treturn meta ? meta->size : 0;",
            "}",
            "void __kfence_free(void *addr)",
            "{",
            "\tstruct kfence_metadata *meta = addr_to_metadata((unsigned long)addr);",
            "",
            "#ifdef CONFIG_MEMCG",
            "\tKFENCE_WARN_ON(meta->obj_exts.objcg);",
            "#endif",
            "\t/*",
            "\t * If the objects of the cache are SLAB_TYPESAFE_BY_RCU, defer freeing",
            "\t * the object, as the object page may be recycled for other-typed",
            "\t * objects once it has been freed. meta->cache may be NULL if the cache",
            "\t * was destroyed.",
            "\t * Save the stack trace here so that reports show where the user freed",
            "\t * the object.",
            "\t */",
            "\tif (unlikely(meta->cache && (meta->cache->flags & SLAB_TYPESAFE_BY_RCU))) {",
            "\t\tunsigned long flags;",
            "",
            "\t\traw_spin_lock_irqsave(&meta->lock, flags);",
            "\t\tmetadata_update_state(meta, KFENCE_OBJECT_RCU_FREEING, NULL, 0);",
            "\t\traw_spin_unlock_irqrestore(&meta->lock, flags);",
            "\t\tcall_rcu(&meta->rcu_head, rcu_guarded_free);",
            "\t} else {",
            "\t\tkfence_guarded_free(addr, meta, false);",
            "\t}",
            "}"
          ],
          "function_name": "kfence_enable_late, kfence_shutdown_cache, kfence_ksize, __kfence_free",
          "description": "延迟启用KFENCE，安全关闭缓存时处理残留对象，提供对象大小查询接口，实现带RCU延迟释放的自由操作。",
          "similarity": 0.538210928440094
        },
        {
          "chunk_id": 1,
          "file_path": "mm/kfence/core.c",
          "start_line": 64,
          "end_line": 194,
          "content": [
            "static int param_set_sample_interval(const char *val, const struct kernel_param *kp)",
            "{",
            "\tunsigned long num;",
            "\tint ret = kstrtoul(val, 0, &num);",
            "",
            "\tif (ret < 0)",
            "\t\treturn ret;",
            "",
            "\t/* Using 0 to indicate KFENCE is disabled. */",
            "\tif (!num && READ_ONCE(kfence_enabled)) {",
            "\t\tpr_info(\"disabled\\n\");",
            "\t\tWRITE_ONCE(kfence_enabled, false);",
            "\t}",
            "",
            "\t*((unsigned long *)kp->arg) = num;",
            "",
            "\tif (num && !READ_ONCE(kfence_enabled) && system_state != SYSTEM_BOOTING)",
            "\t\treturn disabled_by_warn ? -EINVAL : kfence_enable_late();",
            "\treturn 0;",
            "}",
            "static int param_get_sample_interval(char *buffer, const struct kernel_param *kp)",
            "{",
            "\tif (!READ_ONCE(kfence_enabled))",
            "\t\treturn sprintf(buffer, \"0\\n\");",
            "",
            "\treturn param_get_ulong(buffer, kp);",
            "}",
            "static inline bool should_skip_covered(void)",
            "{",
            "\tunsigned long thresh = (CONFIG_KFENCE_NUM_OBJECTS * kfence_skip_covered_thresh) / 100;",
            "",
            "\treturn atomic_long_read(&counters[KFENCE_COUNTER_ALLOCATED]) > thresh;",
            "}",
            "static u32 get_alloc_stack_hash(unsigned long *stack_entries, size_t num_entries)",
            "{",
            "\tnum_entries = min(num_entries, UNIQUE_ALLOC_STACK_DEPTH);",
            "\tnum_entries = filter_irq_stacks(stack_entries, num_entries);",
            "\treturn jhash(stack_entries, num_entries * sizeof(stack_entries[0]), stack_hash_seed);",
            "}",
            "static void alloc_covered_add(u32 alloc_stack_hash, int val)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < ALLOC_COVERED_HNUM; i++) {",
            "\t\tatomic_add(val, &alloc_covered[alloc_stack_hash & ALLOC_COVERED_MASK]);",
            "\t\talloc_stack_hash = ALLOC_COVERED_HNEXT(alloc_stack_hash);",
            "\t}",
            "}",
            "static bool alloc_covered_contains(u32 alloc_stack_hash)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < ALLOC_COVERED_HNUM; i++) {",
            "\t\tif (!atomic_read(&alloc_covered[alloc_stack_hash & ALLOC_COVERED_MASK]))",
            "\t\t\treturn false;",
            "\t\talloc_stack_hash = ALLOC_COVERED_HNEXT(alloc_stack_hash);",
            "\t}",
            "",
            "\treturn true;",
            "}",
            "static bool kfence_protect(unsigned long addr)",
            "{",
            "\treturn !KFENCE_WARN_ON(!kfence_protect_page(ALIGN_DOWN(addr, PAGE_SIZE), true));",
            "}",
            "static bool kfence_unprotect(unsigned long addr)",
            "{",
            "\treturn !KFENCE_WARN_ON(!kfence_protect_page(ALIGN_DOWN(addr, PAGE_SIZE), false));",
            "}",
            "static inline unsigned long metadata_to_pageaddr(const struct kfence_metadata *meta)",
            "{",
            "\tunsigned long offset = (meta - kfence_metadata + 1) * PAGE_SIZE * 2;",
            "\tunsigned long pageaddr = (unsigned long)&__kfence_pool[offset];",
            "",
            "\t/* The checks do not affect performance; only called from slow-paths. */",
            "",
            "\t/* Only call with a pointer into kfence_metadata. */",
            "\tif (KFENCE_WARN_ON(meta < kfence_metadata ||",
            "\t\t\t   meta >= kfence_metadata + CONFIG_KFENCE_NUM_OBJECTS))",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * This metadata object only ever maps to 1 page; verify that the stored",
            "\t * address is in the expected range.",
            "\t */",
            "\tif (KFENCE_WARN_ON(ALIGN_DOWN(meta->addr, PAGE_SIZE) != pageaddr))",
            "\t\treturn 0;",
            "",
            "\treturn pageaddr;",
            "}",
            "static inline bool kfence_obj_allocated(const struct kfence_metadata *meta)",
            "{",
            "\tenum kfence_object_state state = READ_ONCE(meta->state);",
            "",
            "\treturn state == KFENCE_OBJECT_ALLOCATED || state == KFENCE_OBJECT_RCU_FREEING;",
            "}",
            "static noinline void",
            "metadata_update_state(struct kfence_metadata *meta, enum kfence_object_state next,",
            "\t\t      unsigned long *stack_entries, size_t num_stack_entries)",
            "{",
            "\tstruct kfence_track *track =",
            "\t\tnext == KFENCE_OBJECT_ALLOCATED ? &meta->alloc_track : &meta->free_track;",
            "",
            "\tlockdep_assert_held(&meta->lock);",
            "",
            "\t/* Stack has been saved when calling rcu, skip. */",
            "\tif (READ_ONCE(meta->state) == KFENCE_OBJECT_RCU_FREEING)",
            "\t\tgoto out;",
            "",
            "\tif (stack_entries) {",
            "\t\tmemcpy(track->stack_entries, stack_entries,",
            "\t\t       num_stack_entries * sizeof(stack_entries[0]));",
            "\t} else {",
            "\t\t/*",
            "\t\t * Skip over 1 (this) functions; noinline ensures we do not",
            "\t\t * accidentally skip over the caller by never inlining.",
            "\t\t */",
            "\t\tnum_stack_entries = stack_trace_save(track->stack_entries, KFENCE_STACK_DEPTH, 1);",
            "\t}",
            "\ttrack->num_stack_entries = num_stack_entries;",
            "\ttrack->pid = task_pid_nr(current);",
            "\ttrack->cpu = raw_smp_processor_id();",
            "\ttrack->ts_nsec = local_clock(); /* Same source as printk timestamps. */",
            "",
            "out:",
            "\t/*",
            "\t * Pairs with READ_ONCE() in",
            "\t *\tkfence_shutdown_cache(),",
            "\t *\tkfence_handle_page_fault().",
            "\t */",
            "\tWRITE_ONCE(meta->state, next);",
            "}"
          ],
          "function_name": "param_set_sample_interval, param_get_sample_interval, should_skip_covered, get_alloc_stack_hash, alloc_covered_add, alloc_covered_contains, kfence_protect, kfence_unprotect, metadata_to_pageaddr, kfence_obj_allocated, metadata_update_state",
          "description": "实现KFENCE参数设置、分配栈哈希计算、覆盖区域管理及对象保护/解保护逻辑，包含元数据状态更新与地址验证辅助函数。",
          "similarity": 0.5002290606498718
        },
        {
          "chunk_id": 3,
          "file_path": "mm/kfence/core.c",
          "start_line": 583,
          "end_line": 708,
          "content": [
            "static void rcu_guarded_free(struct rcu_head *h)",
            "{",
            "\tstruct kfence_metadata *meta = container_of(h, struct kfence_metadata, rcu_head);",
            "",
            "\tkfence_guarded_free((void *)meta->addr, meta, false);",
            "}",
            "static unsigned long kfence_init_pool(void)",
            "{",
            "\tunsigned long addr;",
            "\tstruct page *pages;",
            "\tint i;",
            "",
            "\tif (!arch_kfence_init_pool())",
            "\t\treturn (unsigned long)__kfence_pool;",
            "",
            "\taddr = (unsigned long)__kfence_pool;",
            "\tpages = virt_to_page(__kfence_pool);",
            "",
            "\t/*",
            "\t * Set up object pages: they must have PG_slab set, to avoid freeing",
            "\t * these as real pages.",
            "\t *",
            "\t * We also want to avoid inserting kfence_free() in the kfree()",
            "\t * fast-path in SLUB, and therefore need to ensure kfree() correctly",
            "\t * enters __slab_free() slow-path.",
            "\t */",
            "\tfor (i = 0; i < KFENCE_POOL_SIZE / PAGE_SIZE; i++) {",
            "\t\tstruct slab *slab = page_slab(nth_page(pages, i));",
            "",
            "\t\tif (!i || (i % 2))",
            "\t\t\tcontinue;",
            "",
            "\t\t__folio_set_slab(slab_folio(slab));",
            "#ifdef CONFIG_MEMCG",
            "\t\tslab->obj_exts = (unsigned long)&kfence_metadata_init[i / 2 - 1].obj_exts |",
            "\t\t\t\t MEMCG_DATA_OBJEXTS;",
            "#endif",
            "\t}",
            "",
            "\t/*",
            "\t * Protect the first 2 pages. The first page is mostly unnecessary, and",
            "\t * merely serves as an extended guard page. However, adding one",
            "\t * additional page in the beginning gives us an even number of pages,",
            "\t * which simplifies the mapping of address to metadata index.",
            "\t */",
            "\tfor (i = 0; i < 2; i++) {",
            "\t\tif (unlikely(!kfence_protect(addr)))",
            "\t\t\treturn addr;",
            "",
            "\t\taddr += PAGE_SIZE;",
            "\t}",
            "",
            "\tfor (i = 0; i < CONFIG_KFENCE_NUM_OBJECTS; i++) {",
            "\t\tstruct kfence_metadata *meta = &kfence_metadata_init[i];",
            "",
            "\t\t/* Initialize metadata. */",
            "\t\tINIT_LIST_HEAD(&meta->list);",
            "\t\traw_spin_lock_init(&meta->lock);",
            "\t\tmeta->state = KFENCE_OBJECT_UNUSED;",
            "\t\tmeta->addr = addr; /* Initialize for validation in metadata_to_pageaddr(). */",
            "\t\tlist_add_tail(&meta->list, &kfence_freelist);",
            "",
            "\t\t/* Protect the right redzone. */",
            "\t\tif (unlikely(!kfence_protect(addr + PAGE_SIZE)))",
            "\t\t\tgoto reset_slab;",
            "",
            "\t\taddr += 2 * PAGE_SIZE;",
            "\t}",
            "",
            "\t/*",
            "\t * Make kfence_metadata visible only when initialization is successful.",
            "\t * Otherwise, if the initialization fails and kfence_metadata is freed,",
            "\t * it may cause UAF in kfence_shutdown_cache().",
            "\t */",
            "\tsmp_store_release(&kfence_metadata, kfence_metadata_init);",
            "\treturn 0;",
            "",
            "reset_slab:",
            "\tfor (i = 0; i < KFENCE_POOL_SIZE / PAGE_SIZE; i++) {",
            "\t\tstruct slab *slab = page_slab(nth_page(pages, i));",
            "",
            "\t\tif (!i || (i % 2))",
            "\t\t\tcontinue;",
            "#ifdef CONFIG_MEMCG",
            "\t\tslab->obj_exts = 0;",
            "#endif",
            "\t\t__folio_clear_slab(slab_folio(slab));",
            "\t}",
            "",
            "\treturn addr;",
            "}",
            "static bool __init kfence_init_pool_early(void)",
            "{",
            "\tunsigned long addr;",
            "",
            "\tif (!__kfence_pool)",
            "\t\treturn false;",
            "",
            "\taddr = kfence_init_pool();",
            "",
            "\tif (!addr) {",
            "\t\t/*",
            "\t\t * The pool is live and will never be deallocated from this point on.",
            "\t\t * Ignore the pool object from the kmemleak phys object tree, as it would",
            "\t\t * otherwise overlap with allocations returned by kfence_alloc(), which",
            "\t\t * are registered with kmemleak through the slab post-alloc hook.",
            "\t\t */",
            "\t\tkmemleak_ignore_phys(__pa(__kfence_pool));",
            "\t\treturn true;",
            "\t}",
            "",
            "\t/*",
            "\t * Only release unprotected pages, and do not try to go back and change",
            "\t * page attributes due to risk of failing to do so as well. If changing",
            "\t * page attributes for some pages fails, it is very likely that it also",
            "\t * fails for the first page, and therefore expect addr==__kfence_pool in",
            "\t * most failure cases.",
            "\t */",
            "\tmemblock_free_late(__pa(addr), KFENCE_POOL_SIZE - (addr - (unsigned long)__kfence_pool));",
            "\t__kfence_pool = NULL;",
            "",
            "\tmemblock_free_late(__pa(kfence_metadata_init), KFENCE_METADATA_SIZE);",
            "\tkfence_metadata_init = NULL;",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "rcu_guarded_free, kfence_init_pool, kfence_init_pool_early",
          "description": "初始化KFENCE内存池与元数据结构，配置Slab属性并设置页面保护，处理早期启动阶段的内存分配与错误恢复逻辑。",
          "similarity": 0.49698132276535034
        },
        {
          "chunk_id": 4,
          "file_path": "mm/kfence/core.c",
          "start_line": 719,
          "end_line": 819,
          "content": [
            "static int stats_show(struct seq_file *seq, void *v)",
            "{",
            "\tint i;",
            "",
            "\tseq_printf(seq, \"enabled: %i\\n\", READ_ONCE(kfence_enabled));",
            "\tfor (i = 0; i < KFENCE_COUNTER_COUNT; i++)",
            "\t\tseq_printf(seq, \"%s: %ld\\n\", counter_names[i], atomic_long_read(&counters[i]));",
            "",
            "\treturn 0;",
            "}",
            "static void stop_object(struct seq_file *seq, void *v)",
            "{",
            "}",
            "static int show_object(struct seq_file *seq, void *v)",
            "{",
            "\tstruct kfence_metadata *meta = &kfence_metadata[(long)v - 1];",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&meta->lock, flags);",
            "\tkfence_print_object(seq, meta);",
            "\traw_spin_unlock_irqrestore(&meta->lock, flags);",
            "\tseq_puts(seq, \"---------------------------------\\n\");",
            "",
            "\treturn 0;",
            "}",
            "static int kfence_debugfs_init(void)",
            "{",
            "\tstruct dentry *kfence_dir;",
            "",
            "\tif (!READ_ONCE(kfence_enabled))",
            "\t\treturn 0;",
            "",
            "\tkfence_dir = debugfs_create_dir(\"kfence\", NULL);",
            "\tdebugfs_create_file(\"stats\", 0444, kfence_dir, NULL, &stats_fops);",
            "\tdebugfs_create_file(\"objects\", 0400, kfence_dir, NULL, &objects_fops);",
            "\treturn 0;",
            "}",
            "static void kfence_check_all_canary(void)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < CONFIG_KFENCE_NUM_OBJECTS; i++) {",
            "\t\tstruct kfence_metadata *meta = &kfence_metadata[i];",
            "",
            "\t\tif (kfence_obj_allocated(meta))",
            "\t\t\tcheck_canary(meta);",
            "\t}",
            "}",
            "static int kfence_check_canary_callback(struct notifier_block *nb,",
            "\t\t\t\t\tunsigned long reason, void *arg)",
            "{",
            "\tkfence_check_all_canary();",
            "\treturn NOTIFY_OK;",
            "}",
            "static void wake_up_kfence_timer(struct irq_work *work)",
            "{",
            "\twake_up(&allocation_wait);",
            "}",
            "static void toggle_allocation_gate(struct work_struct *work)",
            "{",
            "\tif (!READ_ONCE(kfence_enabled))",
            "\t\treturn;",
            "",
            "\tatomic_set(&kfence_allocation_gate, -kfence_burst);",
            "#ifdef CONFIG_KFENCE_STATIC_KEYS",
            "\t/* Enable static key, and await allocation to happen. */",
            "\tstatic_branch_enable(&kfence_allocation_key);",
            "",
            "\twait_event_idle(allocation_wait, atomic_read(&kfence_allocation_gate) > 0);",
            "",
            "\t/* Disable static key and reset timer. */",
            "\tstatic_branch_disable(&kfence_allocation_key);",
            "#endif",
            "\tqueue_delayed_work(system_unbound_wq, &kfence_timer,",
            "\t\t\t   msecs_to_jiffies(kfence_sample_interval));",
            "}",
            "void __init kfence_alloc_pool_and_metadata(void)",
            "{",
            "\tif (!kfence_sample_interval)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If the pool has already been initialized by arch, there is no need to",
            "\t * re-allocate the memory pool.",
            "\t */",
            "\tif (!__kfence_pool)",
            "\t\t__kfence_pool = memblock_alloc(KFENCE_POOL_SIZE, PAGE_SIZE);",
            "",
            "\tif (!__kfence_pool) {",
            "\t\tpr_err(\"failed to allocate pool\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* The memory allocated by memblock has been zeroed out. */",
            "\tkfence_metadata_init = memblock_alloc(KFENCE_METADATA_SIZE, PAGE_SIZE);",
            "\tif (!kfence_metadata_init) {",
            "\t\tpr_err(\"failed to allocate metadata\\n\");",
            "\t\tmemblock_free(__kfence_pool, KFENCE_POOL_SIZE);",
            "\t\t__kfence_pool = NULL;",
            "\t}",
            "}"
          ],
          "function_name": "stats_show, stop_object, show_object, kfence_debugfs_init, kfence_check_all_canary, kfence_check_canary_callback, wake_up_kfence_timer, toggle_allocation_gate, kfence_alloc_pool_and_metadata",
          "description": "实现调试信息展示、全量canary检查及动态分配门控机制，通过debugfs暴露统计信息，并管理周期性内存完整性验证任务。",
          "similarity": 0.4874529242515564
        },
        {
          "chunk_id": 5,
          "file_path": "mm/kfence/core.c",
          "start_line": 889,
          "end_line": 989,
          "content": [
            "static void kfence_init_enable(void)",
            "{",
            "\tif (!IS_ENABLED(CONFIG_KFENCE_STATIC_KEYS))",
            "\t\tstatic_branch_enable(&kfence_allocation_key);",
            "",
            "\tif (kfence_deferrable)",
            "\t\tINIT_DEFERRABLE_WORK(&kfence_timer, toggle_allocation_gate);",
            "\telse",
            "\t\tINIT_DELAYED_WORK(&kfence_timer, toggle_allocation_gate);",
            "",
            "\tif (kfence_check_on_panic)",
            "\t\tatomic_notifier_chain_register(&panic_notifier_list, &kfence_check_canary_notifier);",
            "",
            "\tWRITE_ONCE(kfence_enabled, true);",
            "\tqueue_delayed_work(system_unbound_wq, &kfence_timer, 0);",
            "",
            "\tpr_info(\"initialized - using %lu bytes for %d objects at 0x%p-0x%p\\n\", KFENCE_POOL_SIZE,",
            "\t\tCONFIG_KFENCE_NUM_OBJECTS, (void *)__kfence_pool,",
            "\t\t(void *)(__kfence_pool + KFENCE_POOL_SIZE));",
            "}",
            "void __init kfence_init(void)",
            "{",
            "\tstack_hash_seed = get_random_u32();",
            "",
            "\t/* Setting kfence_sample_interval to 0 on boot disables KFENCE. */",
            "\tif (!kfence_sample_interval)",
            "\t\treturn;",
            "",
            "\tif (!kfence_init_pool_early()) {",
            "\t\tpr_err(\"%s failed\\n\", __func__);",
            "\t\treturn;",
            "\t}",
            "",
            "\tkfence_init_enable();",
            "}",
            "static int kfence_init_late(void)",
            "{",
            "\tconst unsigned long nr_pages_pool = KFENCE_POOL_SIZE / PAGE_SIZE;",
            "\tconst unsigned long nr_pages_meta = KFENCE_METADATA_SIZE / PAGE_SIZE;",
            "\tunsigned long addr = (unsigned long)__kfence_pool;",
            "\tunsigned long free_size = KFENCE_POOL_SIZE;",
            "\tint err = -ENOMEM;",
            "",
            "#ifdef CONFIG_CONTIG_ALLOC",
            "\tstruct page *pages;",
            "",
            "\tpages = alloc_contig_pages(nr_pages_pool, GFP_KERNEL, first_online_node,",
            "\t\t\t\t   NULL);",
            "\tif (!pages)",
            "\t\treturn -ENOMEM;",
            "",
            "\t__kfence_pool = page_to_virt(pages);",
            "\tpages = alloc_contig_pages(nr_pages_meta, GFP_KERNEL, first_online_node,",
            "\t\t\t\t   NULL);",
            "\tif (pages)",
            "\t\tkfence_metadata_init = page_to_virt(pages);",
            "#else",
            "\tif (nr_pages_pool > MAX_ORDER_NR_PAGES ||",
            "\t    nr_pages_meta > MAX_ORDER_NR_PAGES) {",
            "\t\tpr_warn(\"KFENCE_NUM_OBJECTS too large for buddy allocator\\n\");",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\t__kfence_pool = alloc_pages_exact(KFENCE_POOL_SIZE, GFP_KERNEL);",
            "\tif (!__kfence_pool)",
            "\t\treturn -ENOMEM;",
            "",
            "\tkfence_metadata_init = alloc_pages_exact(KFENCE_METADATA_SIZE, GFP_KERNEL);",
            "#endif",
            "",
            "\tif (!kfence_metadata_init)",
            "\t\tgoto free_pool;",
            "",
            "\tmemzero_explicit(kfence_metadata_init, KFENCE_METADATA_SIZE);",
            "\taddr = kfence_init_pool();",
            "\tif (!addr) {",
            "\t\tkfence_init_enable();",
            "\t\tkfence_debugfs_init();",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tpr_err(\"%s failed\\n\", __func__);",
            "\tfree_size = KFENCE_POOL_SIZE - (addr - (unsigned long)__kfence_pool);",
            "\terr = -EBUSY;",
            "",
            "#ifdef CONFIG_CONTIG_ALLOC",
            "\tfree_contig_range(page_to_pfn(virt_to_page((void *)kfence_metadata_init)),",
            "\t\t\t  nr_pages_meta);",
            "free_pool:",
            "\tfree_contig_range(page_to_pfn(virt_to_page((void *)addr)),",
            "\t\t\t  free_size / PAGE_SIZE);",
            "#else",
            "\tfree_pages_exact((void *)kfence_metadata_init, KFENCE_METADATA_SIZE);",
            "free_pool:",
            "\tfree_pages_exact((void *)addr, free_size);",
            "#endif",
            "",
            "\tkfence_metadata_init = NULL;",
            "\t__kfence_pool = NULL;",
            "\treturn err;",
            "}"
          ],
          "function_name": "kfence_init_enable, kfence_init, kfence_init_late",
          "description": "初始化KFENCE模块，配置静态键、定时器工作队列及Panic通知，分配并映射KFENCE内存池，设置启用标志并打印调试信息。",
          "similarity": 0.4795376658439636
        }
      ]
    },
    {
      "source_file": "mm/fadvise.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:59:19\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `fadvise.c`\n\n---\n\n# fadvise.c 技术文档\n\n## 1. 文件概述\n\n`fadvise.c` 是 Linux 内核中实现 POSIX `posix_fadvise()` 系统调用的核心文件，位于 `mm/` 子系统目录下。该文件提供了一种机制，允许应用程序向内核提供关于其未来如何访问文件数据的“建议”（advice），从而帮助内核优化页面缓存（page cache）行为、预读（readahead）策略和内存回收策略。通过这些提示，内核可以更高效地管理内存资源，提升 I/O 性能。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`generic_fadvise(struct file *file, loff_t offset, loff_t len, int advice)`**  \n  实现 POSIX fadvise 建议的通用处理逻辑，是大多数文件系统的默认实现。\n\n- **`vfs_fadvise(struct file *file, loff_t offset, loff_t len, int advice)`**  \n  虚拟文件系统（VFS）层的 fadvise 入口，优先调用文件操作结构体中自定义的 `fadvise` 方法，若未提供则回退到 `generic_fadvise`。\n\n- **`ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)`**  \n  系统调用的内核服务例程，负责从用户空间获取文件描述符并调用 `vfs_fadvise`。\n\n- **系统调用接口**：\n  - `SYSCALL_DEFINE4(fadvise64_64, ...)`\n  - `SYSCALL_DEFINE4(fadvise64, ...)`（架构可选）\n  - `COMPAT_SYSCALL_DEFINE6(fadvise64_64, ...)`（兼容 32 位）\n\n### 支持的建议类型（POSIX_FADV_*）\n\n| 建议类型 | 作用 |\n|--------|------|\n| `POSIX_FADV_NORMAL` | 恢复默认预读行为 |\n| `POSIX_FADV_RANDOM` | 禁用顺序预读，标记为随机访问 |\n| `POSIX_FADV_SEQUENTIAL` | 启用双倍预读，优化顺序访问 |\n| `POSIX_FADV_WILLNEED` | 主动触发预读，将数据加载到 page cache |\n| `POSIX_FADV_NOREUSE` | 标记页面为“不再重用”，影响 LRU 行为（当前仅设置标志） |\n| `POSIX_FADV_DONTNEED` | 异步写回脏页并从 page cache 中移除指定范围的干净页 |\n\n## 3. 关键实现\n\n### 3.1 输入参数处理\n- 使用无符号 64 位算术计算 `endbyte = offset + len - 1`，防止有符号整数溢出。\n- 若 `len == 0` 或发生溢出，则将范围设为 `[offset, LLONG_MAX]`，表示“尽可能多”。\n\n### 3.2 特殊文件系统处理\n- 对 **FIFO** 返回 `-ESPIPE`（不支持）。\n- 对 **DAX（Direct Access）设备** 或使用 `noop_backing_dev_info` 的文件系统（如 tmpfs、ramfs），所有建议均被忽略（返回 0），因为这些存储不涉及传统块设备 I/O 和 page cache。\n\n### 3.3 各建议的具体实现\n- **NORMAL / RANDOM / SEQUENTIAL**：  \n  通过修改 `file->f_mode` 中的 `FMODE_RANDOM` 标志和调整 `file->f_ra.ra_pages`（预读页数）来控制后续 readahead 行为。\n  \n- **WILLNEED**：  \n  计算起止页号（`start_index`, `end_index`），调用 `force_page_cache_readahead()` 主动触发预读。\n\n- **NOREUSE**：  \n  仅设置 `FMODE_NOREUSE` 标志，目前内核未基于此标志做特殊处理（注释表明未来可能用于去激活页面并清除引用位）。\n\n- **DONTNEED**（最复杂）：\n  1. 调用 `__filemap_fdatawrite_range()` 异步回写指定范围内的脏页。\n  2. **精确计算要丢弃的完整页范围**：\n     - 起始页：向上对齐（跳过首部 partial page）\n     - 结束页：向下对齐（跳过尾部 partial page），除非 `endbyte` 恰好是文件末尾或页边界。\n  3. 调用 `lru_add_drain()` 清空本地 CPU 的 LRU 批量添加队列，提高后续无效化效率。\n  4. 使用 `mapping_try_invalidate()` 尝试移除 page cache 中的页面。\n  5. 若有失败（通常因页面在远程 CPU 的 LRU 上），则调用 `lru_add_drain_all()` 并重试 `invalidate_mapping_pages()`。\n\n### 3.4 锁与并发\n- 修改 `file->f_mode` 时使用 `file->f_lock` 自旋锁保护，确保线程安全。\n\n## 4. 依赖关系\n\n### 头文件依赖\n- `<linux/mm.h>`、`<linux/pagemap.h>`：页面缓存、地址空间操作\n- `<linux/writeback.h>`、`<linux/backing-dev.h>`：回写控制、后备设备信息\n- `<linux/file.h>`、`<linux/fs.h>`：VFS 层文件和 inode 结构\n- `\"internal.h\"`：MM 子系统内部函数（如 `force_page_cache_readahead`）\n\n### 内核子系统交互\n- **VFS 层**：通过 `file->f_op->fadvise` 支持文件系统自定义行为\n- **Memory Management (MM)**：操作 page cache、LRU 链表、预读机制\n- **Block Layer**：通过 backing_dev_info 获取设备 I/O 特性（如 `ra_pages`）\n- **DAX 子系统**：识别 DAX inode 并跳过缓存操作\n\n## 5. 使用场景\n\n- **应用程序性能优化**：\n  - 数据库系统在批量扫描前使用 `FADV_SEQUENTIAL`\n  - 流媒体应用使用 `FADV_WILLNEED` 预加载即将播放的数据\n  - 临时文件处理后使用 `FADV_DONTNEED` 释放缓存内存\n\n- **内存压力缓解**：\n  - 在内存紧张时，应用主动丢弃不再需要的缓存页（`FADV_DONTNEED`）\n\n- **I/O 模式适配**：\n  - 随机访问大文件时禁用预读（`FADV_RANDOM`），避免污染 page cache\n\n- **系统调用路径**：\n  - 用户空间调用 `posix_fadvise()` → 内核系统调用入口 → `vfs_fadvise()` → `generic_fadvise()`（或文件系统特定实现）",
      "similarity": 0.5735023021697998,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "mm/fadvise.c",
          "start_line": 1,
          "end_line": 30,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * mm/fadvise.c",
            " *",
            " * Copyright (C) 2002, Linus Torvalds",
            " *",
            " * 11Jan2003\tAndrew Morton",
            " *\t\tInitial version.",
            " */",
            "",
            "#include <linux/kernel.h>",
            "#include <linux/file.h>",
            "#include <linux/fs.h>",
            "#include <linux/mm.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/fadvise.h>",
            "#include <linux/writeback.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swap.h>",
            "",
            "#include <asm/unistd.h>",
            "",
            "#include \"internal.h\"",
            "",
            "/*",
            " * POSIX_FADV_WILLNEED could set PG_Referenced, and POSIX_FADV_NOREUSE could",
            " * deactivate the pages and clear PG_Referenced.",
            " */",
            ""
          ],
          "function_name": null,
          "description": "该代码段属于`mm/fadvise.c`文件的头部，主要定义与POSIX文件预读 advisory 建议相关的内核机制，通过设置或清除页面状态标志（如PG_Referenced）影响缓存行为。代码片段未包含完整函数实现，而是声明了与文件访问模式控制相关的常量及依赖项。此模块核心功能是实现`fadvise`系统调用的内核态逻辑，用于指导页面缓存管理策略。",
          "similarity": 0.4962359666824341
        },
        {
          "chunk_id": 1,
          "file_path": "mm/fadvise.c",
          "start_line": 31,
          "end_line": 177,
          "content": [
            "int generic_fadvise(struct file *file, loff_t offset, loff_t len, int advice)",
            "{",
            "\tstruct inode *inode;",
            "\tstruct address_space *mapping;",
            "\tstruct backing_dev_info *bdi;",
            "\tloff_t endbyte;\t\t\t/* inclusive */",
            "\tpgoff_t start_index;",
            "\tpgoff_t end_index;",
            "\tunsigned long nrpages;",
            "",
            "\tinode = file_inode(file);",
            "\tif (S_ISFIFO(inode->i_mode))",
            "\t\treturn -ESPIPE;",
            "",
            "\tmapping = file->f_mapping;",
            "\tif (!mapping || len < 0)",
            "\t\treturn -EINVAL;",
            "",
            "\tbdi = inode_to_bdi(mapping->host);",
            "",
            "\tif (IS_DAX(inode) || (bdi == &noop_backing_dev_info)) {",
            "\t\tswitch (advice) {",
            "\t\tcase POSIX_FADV_NORMAL:",
            "\t\tcase POSIX_FADV_RANDOM:",
            "\t\tcase POSIX_FADV_SEQUENTIAL:",
            "\t\tcase POSIX_FADV_WILLNEED:",
            "\t\tcase POSIX_FADV_NOREUSE:",
            "\t\tcase POSIX_FADV_DONTNEED:",
            "\t\t\t/* no bad return value, but ignore advice */",
            "\t\t\tbreak;",
            "\t\tdefault:",
            "\t\t\treturn -EINVAL;",
            "\t\t}",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t/*",
            "\t * Careful about overflows. Len == 0 means \"as much as possible\".  Use",
            "\t * unsigned math because signed overflows are undefined and UBSan",
            "\t * complains.",
            "\t */",
            "\tendbyte = (u64)offset + (u64)len;",
            "\tif (!len || endbyte < len)",
            "\t\tendbyte = LLONG_MAX;",
            "\telse",
            "\t\tendbyte--;\t\t/* inclusive */",
            "",
            "\tswitch (advice) {",
            "\tcase POSIX_FADV_NORMAL:",
            "\t\tfile->f_ra.ra_pages = bdi->ra_pages;",
            "\t\tspin_lock(&file->f_lock);",
            "\t\tfile->f_mode &= ~(FMODE_RANDOM | FMODE_NOREUSE);",
            "\t\tspin_unlock(&file->f_lock);",
            "\t\tbreak;",
            "\tcase POSIX_FADV_RANDOM:",
            "\t\tspin_lock(&file->f_lock);",
            "\t\tfile->f_mode |= FMODE_RANDOM;",
            "\t\tspin_unlock(&file->f_lock);",
            "\t\tbreak;",
            "\tcase POSIX_FADV_SEQUENTIAL:",
            "\t\tfile->f_ra.ra_pages = bdi->ra_pages * 2;",
            "\t\tspin_lock(&file->f_lock);",
            "\t\tfile->f_mode &= ~FMODE_RANDOM;",
            "\t\tspin_unlock(&file->f_lock);",
            "\t\tbreak;",
            "\tcase POSIX_FADV_WILLNEED:",
            "\t\t/* First and last PARTIAL page! */",
            "\t\tstart_index = offset >> PAGE_SHIFT;",
            "\t\tend_index = endbyte >> PAGE_SHIFT;",
            "",
            "\t\t/* Careful about overflow on the \"+1\" */",
            "\t\tnrpages = end_index - start_index + 1;",
            "\t\tif (!nrpages)",
            "\t\t\tnrpages = ~0UL;",
            "",
            "\t\tforce_page_cache_readahead(mapping, file, start_index, nrpages);",
            "\t\tbreak;",
            "\tcase POSIX_FADV_NOREUSE:",
            "\t\tspin_lock(&file->f_lock);",
            "\t\tfile->f_mode |= FMODE_NOREUSE;",
            "\t\tspin_unlock(&file->f_lock);",
            "\t\tbreak;",
            "\tcase POSIX_FADV_DONTNEED:",
            "\t\t__filemap_fdatawrite_range(mapping, offset, endbyte,",
            "\t\t\t\t\t   WB_SYNC_NONE);",
            "",
            "\t\t/*",
            "\t\t * First and last FULL page! Partial pages are deliberately",
            "\t\t * preserved on the expectation that it is better to preserve",
            "\t\t * needed memory than to discard unneeded memory.",
            "\t\t */",
            "\t\tstart_index = (offset+(PAGE_SIZE-1)) >> PAGE_SHIFT;",
            "\t\tend_index = (endbyte >> PAGE_SHIFT);",
            "\t\t/*",
            "\t\t * The page at end_index will be inclusively discarded according",
            "\t\t * by invalidate_mapping_pages(), so subtracting 1 from",
            "\t\t * end_index means we will skip the last page.  But if endbyte",
            "\t\t * is page aligned or is at the end of file, we should not skip",
            "\t\t * that page - discarding the last page is safe enough.",
            "\t\t */",
            "\t\tif ((endbyte & ~PAGE_MASK) != ~PAGE_MASK &&",
            "\t\t\t\tendbyte != inode->i_size - 1) {",
            "\t\t\t/* First page is tricky as 0 - 1 = -1, but pgoff_t",
            "\t\t\t * is unsigned, so the end_index >= start_index",
            "\t\t\t * check below would be true and we'll discard the whole",
            "\t\t\t * file cache which is not what was asked.",
            "\t\t\t */",
            "\t\t\tif (end_index == 0)",
            "\t\t\t\tbreak;",
            "",
            "\t\t\tend_index--;",
            "\t\t}",
            "",
            "\t\tif (end_index >= start_index) {",
            "\t\t\tunsigned long nr_failed = 0;",
            "",
            "\t\t\t/*",
            "\t\t\t * It's common to FADV_DONTNEED right after",
            "\t\t\t * the read or write that instantiates the",
            "\t\t\t * pages, in which case there will be some",
            "\t\t\t * sitting on the local LRU cache. Try to",
            "\t\t\t * avoid the expensive remote drain and the",
            "\t\t\t * second cache tree walk below by flushing",
            "\t\t\t * them out right away.",
            "\t\t\t */",
            "\t\t\tlru_add_drain();",
            "",
            "\t\t\tmapping_try_invalidate(mapping, start_index, end_index,",
            "\t\t\t\t\t&nr_failed);",
            "",
            "\t\t\t/*",
            "\t\t\t * The failures may be due to the folio being",
            "\t\t\t * in the LRU cache of a remote CPU. Drain all",
            "\t\t\t * caches and try again.",
            "\t\t\t */",
            "\t\t\tif (nr_failed) {",
            "\t\t\t\tlru_add_drain_all();",
            "\t\t\t\tinvalidate_mapping_pages(mapping, start_index,",
            "\t\t\t\t\t\tend_index);",
            "\t\t\t}",
            "\t\t}",
            "\t\tbreak;",
            "\tdefault:",
            "\t\treturn -EINVAL;",
            "\t}",
            "\treturn 0;",
            "}"
          ],
          "function_name": "generic_fadvise",
          "description": "该代码实现了`generic_fadvise`函数，用于处理文件读取建议（advice）对内存管理和I/O调度的影响。  \n函数根据传入的建议类型（如POSIX_FADV_DONTNEED、SEQUENTIAL等），调整文件读取模式或触发页面无效化操作，同时处理特殊设备（如DAX或noop BDI）的兼容性。  \n对于非特殊设备，依据建议类型修改文件读取策略或直接无效化指定范围的页缓存，但对DAX设备及noop BDI直接忽略建议以避免不必要的操作。",
          "similarity": 0.49408164620399475
        },
        {
          "chunk_id": 2,
          "file_path": "mm/fadvise.c",
          "start_line": 180,
          "end_line": 199,
          "content": [
            "int vfs_fadvise(struct file *file, loff_t offset, loff_t len, int advice)",
            "{",
            "\tif (file->f_op->fadvise)",
            "\t\treturn file->f_op->fadvise(file, offset, len, advice);",
            "",
            "\treturn generic_fadvise(file, offset, len, advice);",
            "}",
            "int ksys_fadvise64_64(int fd, loff_t offset, loff_t len, int advice)",
            "{",
            "\tstruct fd f = fdget(fd);",
            "\tint ret;",
            "",
            "\tif (!f.file)",
            "\t\treturn -EBADF;",
            "",
            "\tret = vfs_fadvise(f.file, offset, len, advice);",
            "",
            "\tfdput(f);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "vfs_fadvise, ksys_fadvise64_64",
          "description": "该代码段实现了文件预读建议（fadvise）的通用处理逻辑。  \n`vfs_fadvise` 作为分发函数，优先调用文件系统特定的 `fadvise` 方法，否则使用通用实现 `generic_fadvise`。  \n`ksys_fadvise64_64` 是系统调用入口，负责解析文件描述符并转发请求至 `vfs_fadvise`，但缺少 `generic_fadvise` 具体实现细节，上下文不完整。",
          "similarity": 0.4631251096725464
        }
      ]
    },
    {
      "source_file": "mm/shuffle.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:21:18\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `shuffle.c`\n\n---\n\n# shuffle.c 技术文档\n\n## 1. 文件概述\n\n`shuffle.c` 实现了 Linux 内核内存管理子系统中的**页面分配随机化（Page Allocation Shuffling）**功能。该机制通过在内存初始化阶段对空闲页面链表进行 Fisher-Yates 洗牌操作，降低物理页帧分配的可预测性，从而增强系统安全性，抵御基于内存布局预测的攻击（如堆喷射、地址泄露等）。该功能默认关闭，可通过内核启动参数 `shuffle=1` 启用。\n\n## 2. 核心功能\n\n### 数据结构与全局变量\n- `page_alloc_shuffle_key`：静态分支键（static key），用于运行时启用/禁用洗牌逻辑，减少未启用时的性能开销。\n- `shuffle_param`：模块参数布尔值，控制是否启用洗牌功能。\n- `shuffle_param_ops`：自定义模块参数操作集，用于处理 `shuffle` 参数的设置和读取。\n\n### 主要函数\n- `shuffle_param_set()`：解析并设置 `shuffle` 内核参数，若启用则激活 `page_alloc_shuffle_key`。\n- `shuffle_valid_page()`：验证指定 PFN 的页面是否满足洗牌条件（属于 buddy 系统、同 zone、空闲、相同 order 和 migratetype）。\n- `__shuffle_zone()`：对指定内存区域（zone）执行 Fisher-Yates 洗牌算法，随机交换同阶空闲页面。\n- `__shuffle_free_memory()`：遍历节点（pgdat）中所有 zone，依次调用 `shuffle_zone()` 进行洗牌。\n- `shuffle_pick_tail()`：提供轻量级随机位生成器，用于在分配时决定从链表头部还是尾部取页（增强运行时随机性）。\n\n## 3. 关键实现\n\n### 洗牌算法（Fisher-Yates）\n- **粒度**：以 `SHUFFLE_ORDER`（通常为 0，即单页）为单位进行洗牌。\n- **范围**：遍历 zone 内所有按 order 对齐的 PFN，对每个有效页面 `page_i` 随机选择另一个有效页面 `page_j` 进行交换。\n- **有效性校验**：通过 `shuffle_valid_page()` 确保交换双方均为 buddy 系统管理的空闲页，且具有相同的迁移类型（migratetype）。\n- **重试机制**：最多尝试 `SHUFFLE_RETRY`（10 次）寻找有效的随机目标页，避免因内存空洞导致失败。\n- **锁优化**：每处理 100 个页面后释放 zone 自旋锁并调度，防止长时间持锁影响系统响应。\n\n### 随机性来源\n- 使用 `get_random_long()` 获取高质量伪随机数作为洗牌索引。\n- `shuffle_pick_tail()` 使用无锁的 64 位随机状态生成器，每次返回最低位并右移，用于运行时分配策略的微调。\n\n### 安全性权衡\n- 明确承认不消除模运算偏差（modulo bias）或 PRNG 偏差，目标是“提高攻击门槛”而非完美随机。\n- 仅在内存初始化阶段（`__meminit`）执行一次洗牌，不影响运行时分配性能。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/mm.h>`、`<linux/mmzone.h>`：内存管理核心数据结构（`struct zone`, `struct page`）。\n  - `<linux/random.h>`：提供 `get_random_long()` 和 `get_random_u64()`。\n  - `\"internal.h\"`、`\"shuffle.h\"`：内核 MM 子系统内部接口及洗牌功能声明。\n- **功能依赖**：\n  - Buddy 分配器：依赖 `PageBuddy()`、`buddy_order()` 等接口判断页面状态。\n  - 页面迁移类型（Migratetype）：确保洗牌不破坏不同迁移类型页面的隔离。\n  - 静态分支（Static Keys）：通过 `static_branch_enable()` 动态启用洗牌路径。\n\n## 5. 使用场景\n\n- **安全加固**：在需要防范物理地址预测攻击的场景（如虚拟化宿主机、安全敏感设备）中启用，增加攻击者利用内存布局漏洞的难度。\n- **内核初始化**：在 `free_area_init_core()` 等内存子系统初始化流程中调用 `__shuffle_free_memory()`，对初始空闲内存进行一次性洗牌。\n- **运行时分配辅助**：`shuffle_pick_tail()` 被页面分配器调用，决定从空闲链表头/尾取页，进一步增加分配时序的不可预测性。\n- **调试支持**：通过 `pr_debug()` 输出洗牌失败或迁移类型不匹配的日志，便于问题诊断（需开启 `DEBUG_SHUFFLE`）。",
      "similarity": 0.5689785480499268,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/shuffle.c",
          "start_line": 16,
          "end_line": 121,
          "content": [
            "static __meminit int shuffle_param_set(const char *val,",
            "\t\tconst struct kernel_param *kp)",
            "{",
            "\tif (param_set_bool(val, kp))",
            "\t\treturn -EINVAL;",
            "\tif (*(bool *)kp->arg)",
            "\t\tstatic_branch_enable(&page_alloc_shuffle_key);",
            "\treturn 0;",
            "}",
            "void __meminit __shuffle_zone(struct zone *z)",
            "{",
            "\tunsigned long i, flags;",
            "\tunsigned long start_pfn = z->zone_start_pfn;",
            "\tunsigned long end_pfn = zone_end_pfn(z);",
            "\tconst int order = SHUFFLE_ORDER;",
            "\tconst int order_pages = 1 << order;",
            "",
            "\tspin_lock_irqsave(&z->lock, flags);",
            "\tstart_pfn = ALIGN(start_pfn, order_pages);",
            "\tfor (i = start_pfn; i < end_pfn; i += order_pages) {",
            "\t\tunsigned long j;",
            "\t\tint migratetype, retry;",
            "\t\tstruct page *page_i, *page_j;",
            "",
            "\t\t/*",
            "\t\t * We expect page_i, in the sub-range of a zone being added",
            "\t\t * (@start_pfn to @end_pfn), to more likely be valid compared to",
            "\t\t * page_j randomly selected in the span @zone_start_pfn to",
            "\t\t * @spanned_pages.",
            "\t\t */",
            "\t\tpage_i = shuffle_valid_page(z, i, order);",
            "\t\tif (!page_i)",
            "\t\t\tcontinue;",
            "",
            "\t\tfor (retry = 0; retry < SHUFFLE_RETRY; retry++) {",
            "\t\t\t/*",
            "\t\t\t * Pick a random order aligned page in the zone span as",
            "\t\t\t * a swap target. If the selected pfn is a hole, retry",
            "\t\t\t * up to SHUFFLE_RETRY attempts find a random valid pfn",
            "\t\t\t * in the zone.",
            "\t\t\t */",
            "\t\t\tj = z->zone_start_pfn +",
            "\t\t\t\tALIGN_DOWN(get_random_long() % z->spanned_pages,",
            "\t\t\t\t\t\torder_pages);",
            "\t\t\tpage_j = shuffle_valid_page(z, j, order);",
            "\t\t\tif (page_j && page_j != page_i)",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t\tif (retry >= SHUFFLE_RETRY) {",
            "\t\t\tpr_debug(\"%s: failed to swap %#lx\\n\", __func__, i);",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * Each migratetype corresponds to its own list, make sure the",
            "\t\t * types match otherwise we're moving pages to lists where they",
            "\t\t * do not belong.",
            "\t\t */",
            "\t\tmigratetype = get_pageblock_migratetype(page_i);",
            "\t\tif (get_pageblock_migratetype(page_j) != migratetype) {",
            "\t\t\tpr_debug(\"%s: migratetype mismatch %#lx\\n\", __func__, i);",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tlist_swap(&page_i->lru, &page_j->lru);",
            "",
            "\t\tpr_debug(\"%s: swap: %#lx -> %#lx\\n\", __func__, i, j);",
            "",
            "\t\t/* take it easy on the zone lock */",
            "\t\tif ((i % (100 * order_pages)) == 0) {",
            "\t\t\tspin_unlock_irqrestore(&z->lock, flags);",
            "\t\t\tcond_resched();",
            "\t\t\tspin_lock_irqsave(&z->lock, flags);",
            "\t\t}",
            "\t}",
            "\tspin_unlock_irqrestore(&z->lock, flags);",
            "}",
            "void __meminit __shuffle_free_memory(pg_data_t *pgdat)",
            "{",
            "\tstruct zone *z;",
            "",
            "\tfor (z = pgdat->node_zones; z < pgdat->node_zones + MAX_NR_ZONES; z++)",
            "\t\tshuffle_zone(z);",
            "}",
            "bool shuffle_pick_tail(void)",
            "{",
            "\tstatic u64 rand;",
            "\tstatic u8 rand_bits;",
            "\tbool ret;",
            "",
            "\t/*",
            "\t * The lack of locking is deliberate. If 2 threads race to",
            "\t * update the rand state it just adds to the entropy.",
            "\t */",
            "\tif (rand_bits == 0) {",
            "\t\trand_bits = 64;",
            "\t\trand = get_random_u64();",
            "\t}",
            "",
            "\tret = rand & 1;",
            "",
            "\trand_bits--;",
            "\trand >>= 1;",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "shuffle_param_set, __shuffle_zone, __shuffle_free_memory, shuffle_pick_tail",
          "description": "shuffle_param_set设置参数并启用/禁用静态键；__shuffle_zone在内存区随机交换页面以打乱物理顺序；__shuffle_free_memory初始化时调用__shuffle_zone；shuffle_pick_tail生成随机布尔值用于选择尾部页",
          "similarity": 0.49326246976852417
        },
        {
          "chunk_id": 0,
          "file_path": "mm/shuffle.c",
          "start_line": 1,
          "end_line": 15,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "// Copyright(c) 2018 Intel Corporation. All rights reserved.",
            "",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/random.h>",
            "#include <linux/moduleparam.h>",
            "#include \"internal.h\"",
            "#include \"shuffle.h\"",
            "",
            "DEFINE_STATIC_KEY_FALSE(page_alloc_shuffle_key);",
            "",
            "static bool shuffle_param;",
            ""
          ],
          "function_name": null,
          "description": "定义静态键用于控制页面分配随机化功能，并声明参数变量shuffle_param，用于启用或禁用相关机制",
          "similarity": 0.3009384274482727
        }
      ]
    }
  ]
}