{
  "query": "Buddy System",
  "timestamp": "2025-12-26 00:02:32",
  "retrieved_files": [
    {
      "source_file": "mm/z3fold.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:35:52\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `z3fold.c`\n\n---\n\n# z3fold.c 技术文档\n\n## 1. 文件概述\n\n`z3fold.c` 实现了一个专用于存储压缩页面的特殊用途内存分配器——**z3fold**。该分配器继承自 `zbud` 的设计理念，但进行了优化：每个物理页最多可容纳**三个**压缩对象（而 zbud 仅支持两个），从而提升了压缩密度，同时保留了“每页存储整数个对象”的确定性特性。这种设计在需要高效内存回收（reclaim）的场景下，相比无固定对象数量限制的高密度方案更具优势。z3fold 不直接对外暴露 API，而是通过 **zpool** 接口被上层（如 zswap、zram）调用。\n\n## 2. 核心功能\n\n### 主要数据结构\n- **`struct z3fold_header`**: 存储在每个 z3fold 页面起始位置的元数据结构（HEADLESS 页除外）。包含：\n  - 页面引用计数 (`refcount`) 和自旋锁 (`page_lock`)\n  - 指向所属池 (`pool`) 和 CPU 亲和性 (`cpu`)\n  - 三个 buddy 区域（first, middle, last）的大小及起始位置\n  - 状态标志（如映射计数 `mapped_count`、外部句柄标记 `foreign_handles`）\n  - 用于后台优化的工作队列项 (`work`)\n- **`struct z3fold_buddy_slots`**: 管理页面内对象句柄的槽位结构，包含读写锁 (`lock`) 和指向所属池的反向链接。\n- **`struct z3fold_pool`**: 代表一个 z3fold 内存池，包含：\n  - 每 CPU 的 `unbuddied` 列表数组（按空闲区域大小分类）\n  - 待释放的 `stale` 页面列表\n  - 专用 slab 缓存 (`c_handle`) 用于分配 `buddy_slots`\n  - 后台工作队列 (`compact_wq`, `release_wq`) 用于页面整理和安全释放\n\n### 关键枚举与宏\n- **`enum buddy`**: 定义页面内对象的三种类型：`FIRST`（页首）、`MIDDLE`（中间）、`LAST`（页尾），以及特殊的 `HEADLESS`（无头部元数据页）。\n- **`NCHUNKS_ORDER`**: 核心配置参数（默认为 6），决定内部分配粒度为 `PAGE_SIZE / 64`。\n- **页面标志 (`enum z3fold_page_flags`)**: 如 `PAGE_HEADLESS`、`NEEDS_COMPACTING`、`PAGE_STALE` 等，用于管理页面状态。\n- **句柄标志 (`enum z3fold_handle_flags`)**: 控制句柄行为（如 `HANDLES_NOFREE`）。\n\n### 核心辅助函数\n- **`size_to_chunks()`**: 将字节大小转换为 chunk 单位。\n- **`alloc_slots()` / `slots_to_pool()`**: 管理 `buddy_slots` 的分配与池关联。\n- **`handle_to_slots()` / `get_z3fold_header()`**: 从用户句柄解析出底层元数据结构，并处理并发访问与迁移。\n- **`z3fold_page_lock/unlock/trylock()`**: 提供页面级细粒度锁操作。\n\n## 3. 关键实现\n\n### 内存布局与分配策略\n- **Chunk 粒度**: 页面被划分为 `TOTAL_CHUNKS = PAGE_SIZE / CHUNK_SIZE` 个固定大小的 chunk（默认 64 字节）。前 `ZHDR_CHUNKS` 个 chunk 被 `z3fold_header` 占用，剩余 `NCHUNKS`（约 62-63）个用于存储数据。\n- **三 Buddy 设计**: \n  - **First Buddy**: 从 `header` 之后开始分配。\n  - **Last Buddy**: 从页面末尾向前分配。\n  - **Middle Buddy**: 在 First 和 Last 之间动态分配，最大化利用碎片空间。\n- **HEADLESS 页**: 当对象大小接近整个页面时，跳过 header 直接使用整页，减少元数据开销。\n\n### 并发与迁移安全\n- **双层锁机制**: \n  - `z3fold_header.page_lock` 保护单个页面的元数据修改。\n  - `z3fold_buddy_slots.lock` (rwlock) 保护句柄到地址的映射，支持高并发读取。\n- **迁移处理**: 在 `get_z3fold_header()` 中检查 `PAGE_MIGRATED` 标志，若页面正在迁移则重试获取锁，确保访问安全。\n\n### 后台优化\n- **页面整理 (`compact_page_work`)**: 通过工作队列异步移动 Middle Buddy 对象，尝试合并空闲区域以容纳更大对象。\n- **安全释放**: 使用独立工作队列 (`release_wq`) 延迟释放被标记为 `PAGE_STALE` 的页面，避免在中断上下文或持有锁时执行高开销操作。\n\n### 句柄编码\n- 用户句柄 (`handle`) 是一个 `unsigned long`，其低 2 位 (`HANDLE_FLAG_MASK`) 用于存储标志（如 `PAGE_HEADLESS`），其余位编码 `buddy_slots` 地址或直接指向页面。这允许在不解引用的情况下快速判断页面类型。\n\n## 4. 依赖关系\n\n- **核心依赖**: \n  - `<linux/zpool.h>`: 作为 zpool 驱动注册，提供 `zpool_ops` 接口。\n  - `<linux/slab.h>`: 使用 kmem_cache 分配 `z3fold_buddy_slots`。\n  - `<linux/workqueue.h>`: 依赖内核工作队列机制执行后台任务。\n- **内存管理子系统**: \n  - 依赖 `alloc_pages()`/`__free_pages()` 进行底层页分配。\n  - 使用 `page->private` 存储页面标志位。\n  - 与内存压缩 (`compaction.h`) 和迁移 (`migrate.h`) 机制交互。\n- **同步原语**: 大量使用 `spinlock_t` 和 `rwlock_t` 保证 SMP 安全。\n\n## 5. 使用场景\n\nz3fold 主要作为 **zpool** 的后端分配器，服务于需要高效压缩内存的子系统：\n- **zswap**: 作为交换页的压缩缓存，z3fold 的高密度存储可显著减少实际交换 I/O。\n- **zram**: 作为基于 RAM 的块设备，z3fold 提升其有效存储容量。\n- **其他内存压缩框架**: 任何需要将变长小对象（尤其是压缩数据）高效打包进物理页的场景。\n\n其**确定性回收特性**（每页对象数固定、布局简单）使其在内存压力大时能快速找到可回收页面，优于更复杂的分配器（如 zsmalloc），特别适合嵌入式或实时系统。",
      "similarity": 0.4594937562942505,
      "chunks": [
        {
          "chunk_id": 5,
          "file_path": "mm/z3fold.c",
          "start_line": 1092,
          "end_line": 1219,
          "content": [
            "static void z3fold_free(struct z3fold_pool *pool, unsigned long handle)",
            "{",
            "\tstruct z3fold_header *zhdr;",
            "\tstruct page *page;",
            "\tenum buddy bud;",
            "\tbool page_claimed;",
            "",
            "\tzhdr = get_z3fold_header(handle);",
            "\tpage = virt_to_page(zhdr);",
            "\tpage_claimed = test_and_set_bit(PAGE_CLAIMED, &page->private);",
            "",
            "\tif (test_bit(PAGE_HEADLESS, &page->private)) {",
            "\t\t/* if a headless page is under reclaim, just leave.",
            "\t\t * NB: we use test_and_set_bit for a reason: if the bit",
            "\t\t * has not been set before, we release this page",
            "\t\t * immediately so we don't care about its value any more.",
            "\t\t */",
            "\t\tif (!page_claimed) {",
            "\t\t\tput_z3fold_header(zhdr);",
            "\t\t\tfree_z3fold_page(page, true);",
            "\t\t\tatomic64_dec(&pool->pages_nr);",
            "\t\t}",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* Non-headless case */",
            "\tbud = handle_to_buddy(handle);",
            "",
            "\tswitch (bud) {",
            "\tcase FIRST:",
            "\t\tzhdr->first_chunks = 0;",
            "\t\tbreak;",
            "\tcase MIDDLE:",
            "\t\tzhdr->middle_chunks = 0;",
            "\t\tbreak;",
            "\tcase LAST:",
            "\t\tzhdr->last_chunks = 0;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tpr_err(\"%s: unknown bud %d\\n\", __func__, bud);",
            "\t\tWARN_ON(1);",
            "\t\tput_z3fold_header(zhdr);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (!page_claimed)",
            "\t\tfree_handle(handle, zhdr);",
            "\tif (put_z3fold_locked_list(zhdr))",
            "\t\treturn;",
            "\tif (page_claimed) {",
            "\t\t/* the page has not been claimed by us */",
            "\t\tput_z3fold_header(zhdr);",
            "\t\treturn;",
            "\t}",
            "\tif (test_and_set_bit(NEEDS_COMPACTING, &page->private)) {",
            "\t\tclear_bit(PAGE_CLAIMED, &page->private);",
            "\t\tput_z3fold_header(zhdr);",
            "\t\treturn;",
            "\t}",
            "\tif (zhdr->cpu < 0 || !cpu_online(zhdr->cpu)) {",
            "\t\tzhdr->cpu = -1;",
            "\t\tkref_get(&zhdr->refcount);",
            "\t\tclear_bit(PAGE_CLAIMED, &page->private);",
            "\t\tdo_compact_page(zhdr, true);",
            "\t\treturn;",
            "\t}",
            "\tkref_get(&zhdr->refcount);",
            "\tclear_bit(PAGE_CLAIMED, &page->private);",
            "\tqueue_work_on(zhdr->cpu, pool->compact_wq, &zhdr->work);",
            "\tput_z3fold_header(zhdr);",
            "}",
            "static void z3fold_unmap(struct z3fold_pool *pool, unsigned long handle)",
            "{",
            "\tstruct z3fold_header *zhdr;",
            "\tstruct page *page;",
            "\tenum buddy buddy;",
            "",
            "\tzhdr = get_z3fold_header(handle);",
            "\tpage = virt_to_page(zhdr);",
            "",
            "\tif (test_bit(PAGE_HEADLESS, &page->private))",
            "\t\treturn;",
            "",
            "\tbuddy = handle_to_buddy(handle);",
            "\tif (buddy == MIDDLE)",
            "\t\tclear_bit(MIDDLE_CHUNK_MAPPED, &page->private);",
            "\tzhdr->mapped_count--;",
            "\tput_z3fold_header(zhdr);",
            "}",
            "static u64 z3fold_get_pool_size(struct z3fold_pool *pool)",
            "{",
            "\treturn atomic64_read(&pool->pages_nr);",
            "}",
            "static bool z3fold_page_isolate(struct page *page, isolate_mode_t mode)",
            "{",
            "\tstruct z3fold_header *zhdr;",
            "\tstruct z3fold_pool *pool;",
            "",
            "\tVM_BUG_ON_PAGE(PageIsolated(page), page);",
            "",
            "\tif (test_bit(PAGE_HEADLESS, &page->private))",
            "\t\treturn false;",
            "",
            "\tzhdr = page_address(page);",
            "\tz3fold_page_lock(zhdr);",
            "\tif (test_bit(NEEDS_COMPACTING, &page->private) ||",
            "\t    test_bit(PAGE_STALE, &page->private))",
            "\t\tgoto out;",
            "",
            "\tif (zhdr->mapped_count != 0 || zhdr->foreign_handles != 0)",
            "\t\tgoto out;",
            "",
            "\tif (test_and_set_bit(PAGE_CLAIMED, &page->private))",
            "\t\tgoto out;",
            "\tpool = zhdr_to_pool(zhdr);",
            "\tspin_lock(&pool->lock);",
            "\tif (!list_empty(&zhdr->buddy))",
            "\t\tlist_del_init(&zhdr->buddy);",
            "\tspin_unlock(&pool->lock);",
            "",
            "\tkref_get(&zhdr->refcount);",
            "\tz3fold_page_unlock(zhdr);",
            "\treturn true;",
            "",
            "out:",
            "\tz3fold_page_unlock(zhdr);",
            "\treturn false;",
            "}"
          ],
          "function_name": "z3fold_free, z3fold_unmap, z3fold_get_pool_size, z3fold_page_isolate",
          "description": "z3fold_free处理Z3Fold页面释放逻辑，根据headless或非headless情况区分处理，清除buddy类型计数并触发页压缩或直接回收。z3fold_unmap减少映射计数并清除中间块映射标志。z3fold_get_pool_size返回当前池中页面总数。z3fold_page_isolate尝试将页面隔离至Z3Fold结构，检查是否满足条件并将其加入buddy链表。",
          "similarity": 0.40556883811950684
        },
        {
          "chunk_id": 3,
          "file_path": "mm/z3fold.c",
          "start_line": 538,
          "end_line": 668,
          "content": [
            "static inline void add_to_unbuddied(struct z3fold_pool *pool,",
            "\t\t\t\tstruct z3fold_header *zhdr)",
            "{",
            "\tif (zhdr->first_chunks == 0 || zhdr->last_chunks == 0 ||",
            "\t\t\tzhdr->middle_chunks == 0) {",
            "\t\tstruct list_head *unbuddied;",
            "\t\tint freechunks = num_free_chunks(zhdr);",
            "",
            "\t\tmigrate_disable();",
            "\t\tunbuddied = this_cpu_ptr(pool->unbuddied);",
            "\t\tspin_lock(&pool->lock);",
            "\t\tlist_add(&zhdr->buddy, &unbuddied[freechunks]);",
            "\t\tspin_unlock(&pool->lock);",
            "\t\tzhdr->cpu = smp_processor_id();",
            "\t\tmigrate_enable();",
            "\t}",
            "}",
            "static inline enum buddy get_free_buddy(struct z3fold_header *zhdr, int chunks)",
            "{",
            "\tenum buddy bud = HEADLESS;",
            "",
            "\tif (zhdr->middle_chunks) {",
            "\t\tif (!zhdr->first_chunks &&",
            "\t\t    chunks <= zhdr->start_middle - ZHDR_CHUNKS)",
            "\t\t\tbud = FIRST;",
            "\t\telse if (!zhdr->last_chunks)",
            "\t\t\tbud = LAST;",
            "\t} else {",
            "\t\tif (!zhdr->first_chunks)",
            "\t\t\tbud = FIRST;",
            "\t\telse if (!zhdr->last_chunks)",
            "\t\t\tbud = LAST;",
            "\t\telse",
            "\t\t\tbud = MIDDLE;",
            "\t}",
            "",
            "\treturn bud;",
            "}",
            "static inline bool buddy_single(struct z3fold_header *zhdr)",
            "{",
            "\treturn !((zhdr->first_chunks && zhdr->middle_chunks) ||",
            "\t\t\t(zhdr->first_chunks && zhdr->last_chunks) ||",
            "\t\t\t(zhdr->middle_chunks && zhdr->last_chunks));",
            "}",
            "static int z3fold_compact_page(struct z3fold_header *zhdr)",
            "{",
            "\tstruct page *page = virt_to_page(zhdr);",
            "",
            "\tif (test_bit(MIDDLE_CHUNK_MAPPED, &page->private))",
            "\t\treturn 0; /* can't move middle chunk, it's used */",
            "",
            "\tif (unlikely(PageIsolated(page)))",
            "\t\treturn 0;",
            "",
            "\tif (zhdr->middle_chunks == 0)",
            "\t\treturn 0; /* nothing to compact */",
            "",
            "\tif (zhdr->first_chunks == 0 && zhdr->last_chunks == 0) {",
            "\t\t/* move to the beginning */",
            "\t\tmchunk_memmove(zhdr, ZHDR_CHUNKS);",
            "\t\tzhdr->first_chunks = zhdr->middle_chunks;",
            "\t\tzhdr->middle_chunks = 0;",
            "\t\tzhdr->start_middle = 0;",
            "\t\tzhdr->first_num++;",
            "\t\treturn 1;",
            "\t}",
            "",
            "\t/*",
            "\t * moving data is expensive, so let's only do that if",
            "\t * there's substantial gain (at least BIG_CHUNK_GAP chunks)",
            "\t */",
            "\tif (zhdr->first_chunks != 0 && zhdr->last_chunks == 0 &&",
            "\t    zhdr->start_middle - (zhdr->first_chunks + ZHDR_CHUNKS) >=",
            "\t\t\tBIG_CHUNK_GAP) {",
            "\t\tmchunk_memmove(zhdr, zhdr->first_chunks + ZHDR_CHUNKS);",
            "\t\tzhdr->start_middle = zhdr->first_chunks + ZHDR_CHUNKS;",
            "\t\treturn 1;",
            "\t} else if (zhdr->last_chunks != 0 && zhdr->first_chunks == 0 &&",
            "\t\t   TOTAL_CHUNKS - (zhdr->last_chunks + zhdr->start_middle",
            "\t\t\t\t\t+ zhdr->middle_chunks) >=",
            "\t\t\tBIG_CHUNK_GAP) {",
            "\t\tunsigned short new_start = TOTAL_CHUNKS - zhdr->last_chunks -",
            "\t\t\tzhdr->middle_chunks;",
            "\t\tmchunk_memmove(zhdr, new_start);",
            "\t\tzhdr->start_middle = new_start;",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static void do_compact_page(struct z3fold_header *zhdr, bool locked)",
            "{",
            "\tstruct z3fold_pool *pool = zhdr_to_pool(zhdr);",
            "\tstruct page *page;",
            "",
            "\tpage = virt_to_page(zhdr);",
            "\tif (locked)",
            "\t\tWARN_ON(z3fold_page_trylock(zhdr));",
            "\telse",
            "\t\tz3fold_page_lock(zhdr);",
            "\tif (WARN_ON(!test_and_clear_bit(NEEDS_COMPACTING, &page->private))) {",
            "\t\tz3fold_page_unlock(zhdr);",
            "\t\treturn;",
            "\t}",
            "\tspin_lock(&pool->lock);",
            "\tlist_del_init(&zhdr->buddy);",
            "\tspin_unlock(&pool->lock);",
            "",
            "\tif (put_z3fold_locked(zhdr))",
            "\t\treturn;",
            "",
            "\tif (test_bit(PAGE_STALE, &page->private) ||",
            "\t    test_and_set_bit(PAGE_CLAIMED, &page->private)) {",
            "\t\tz3fold_page_unlock(zhdr);",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (!zhdr->foreign_handles && buddy_single(zhdr) &&",
            "\t    zhdr->mapped_count == 0 && compact_single_buddy(zhdr)) {",
            "\t\tif (!put_z3fold_locked(zhdr)) {",
            "\t\t\tclear_bit(PAGE_CLAIMED, &page->private);",
            "\t\t\tz3fold_page_unlock(zhdr);",
            "\t\t}",
            "\t\treturn;",
            "\t}",
            "",
            "\tz3fold_compact_page(zhdr);",
            "\tadd_to_unbuddied(pool, zhdr);",
            "\tclear_bit(PAGE_CLAIMED, &page->private);",
            "\tz3fold_page_unlock(zhdr);",
            "}"
          ],
          "function_name": "add_to_unbuddied, get_free_buddy, buddy_single, z3fold_compact_page, do_compact_page",
          "description": "实现页面迁移优化算法，通过检测可移动块位置、执行块数据迁移、维护未分块页面列表等机制提升空间利用率。",
          "similarity": 0.37528058886528015
        },
        {
          "chunk_id": 1,
          "file_path": "mm/z3fold.c",
          "start_line": 186,
          "end_line": 288,
          "content": [
            "static int size_to_chunks(size_t size)",
            "{",
            "\treturn (size + CHUNK_SIZE - 1) >> CHUNK_SHIFT;",
            "}",
            "static inline void z3fold_page_lock(struct z3fold_header *zhdr)",
            "{",
            "\tspin_lock(&zhdr->page_lock);",
            "}",
            "static inline int z3fold_page_trylock(struct z3fold_header *zhdr)",
            "{",
            "\treturn spin_trylock(&zhdr->page_lock);",
            "}",
            "static inline void z3fold_page_unlock(struct z3fold_header *zhdr)",
            "{",
            "\tspin_unlock(&zhdr->page_lock);",
            "}",
            "static inline void put_z3fold_header(struct z3fold_header *zhdr)",
            "{",
            "\tstruct page *page = virt_to_page(zhdr);",
            "",
            "\tif (!test_bit(PAGE_HEADLESS, &page->private))",
            "\t\tz3fold_page_unlock(zhdr);",
            "}",
            "static inline void free_handle(unsigned long handle, struct z3fold_header *zhdr)",
            "{",
            "\tstruct z3fold_buddy_slots *slots;",
            "\tint i;",
            "\tbool is_free;",
            "",
            "\tif (WARN_ON(*(unsigned long *)handle == 0))",
            "\t\treturn;",
            "",
            "\tslots = handle_to_slots(handle);",
            "\twrite_lock(&slots->lock);",
            "\t*(unsigned long *)handle = 0;",
            "",
            "\tif (test_bit(HANDLES_NOFREE, &slots->pool)) {",
            "\t\twrite_unlock(&slots->lock);",
            "\t\treturn; /* simple case, nothing else to do */",
            "\t}",
            "",
            "\tif (zhdr->slots != slots)",
            "\t\tzhdr->foreign_handles--;",
            "",
            "\tis_free = true;",
            "\tfor (i = 0; i <= BUDDY_MASK; i++) {",
            "\t\tif (slots->slot[i]) {",
            "\t\t\tis_free = false;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "\twrite_unlock(&slots->lock);",
            "",
            "\tif (is_free) {",
            "\t\tstruct z3fold_pool *pool = slots_to_pool(slots);",
            "",
            "\t\tif (zhdr->slots == slots)",
            "\t\t\tzhdr->slots = NULL;",
            "\t\tkmem_cache_free(pool->c_handle, slots);",
            "\t}",
            "}",
            "static void free_z3fold_page(struct page *page, bool headless)",
            "{",
            "\tif (!headless) {",
            "\t\tlock_page(page);",
            "\t\t__ClearPageMovable(page);",
            "\t\tunlock_page(page);",
            "\t}",
            "\t__free_page(page);",
            "}",
            "static inline int __idx(struct z3fold_header *zhdr, enum buddy bud)",
            "{",
            "\treturn (bud + zhdr->first_num) & BUDDY_MASK;",
            "}",
            "static unsigned long __encode_handle(struct z3fold_header *zhdr,",
            "\t\t\t\tstruct z3fold_buddy_slots *slots,",
            "\t\t\t\tenum buddy bud)",
            "{",
            "\tunsigned long h = (unsigned long)zhdr;",
            "\tint idx = 0;",
            "",
            "\t/*",
            "\t * For a headless page, its handle is its pointer with the extra",
            "\t * PAGE_HEADLESS bit set",
            "\t */",
            "\tif (bud == HEADLESS)",
            "\t\treturn h | (1 << PAGE_HEADLESS);",
            "",
            "\t/* otherwise, return pointer to encoded handle */",
            "\tidx = __idx(zhdr, bud);",
            "\th += idx;",
            "\tif (bud == LAST)",
            "\t\th |= (zhdr->last_chunks << BUDDY_SHIFT);",
            "",
            "\twrite_lock(&slots->lock);",
            "\tslots->slot[idx] = h;",
            "\twrite_unlock(&slots->lock);",
            "\treturn (unsigned long)&slots->slot[idx];",
            "}",
            "static unsigned long encode_handle(struct z3fold_header *zhdr, enum buddy bud)",
            "{",
            "\treturn __encode_handle(zhdr, zhdr->slots, bud);",
            "}"
          ],
          "function_name": "size_to_chunks, z3fold_page_lock, z3fold_page_trylock, z3fold_page_unlock, put_z3fold_header, free_handle, free_z3fold_page, __idx, __encode_handle, encode_handle",
          "description": "实现页面锁操作、句柄管理及页面释放逻辑，包含将物理页转换为压缩块、跟踪空闲块、处理句柄与槽位映射等关键辅助函数。",
          "similarity": 0.361449658870697
        },
        {
          "chunk_id": 6,
          "file_path": "mm/z3fold.c",
          "start_line": 1285,
          "end_line": 1393,
          "content": [
            "static int z3fold_page_migrate(struct page *newpage, struct page *page,",
            "\t\tenum migrate_mode mode)",
            "{",
            "\tstruct z3fold_header *zhdr, *new_zhdr;",
            "\tstruct z3fold_pool *pool;",
            "",
            "\tVM_BUG_ON_PAGE(!PageIsolated(page), page);",
            "\tVM_BUG_ON_PAGE(!test_bit(PAGE_CLAIMED, &page->private), page);",
            "\tVM_BUG_ON_PAGE(!PageLocked(newpage), newpage);",
            "",
            "\tzhdr = page_address(page);",
            "\tpool = zhdr_to_pool(zhdr);",
            "",
            "\tif (!z3fold_page_trylock(zhdr))",
            "\t\treturn -EAGAIN;",
            "\tif (zhdr->mapped_count != 0 || zhdr->foreign_handles != 0) {",
            "\t\tclear_bit(PAGE_CLAIMED, &page->private);",
            "\t\tz3fold_page_unlock(zhdr);",
            "\t\treturn -EBUSY;",
            "\t}",
            "\tif (work_pending(&zhdr->work)) {",
            "\t\tz3fold_page_unlock(zhdr);",
            "\t\treturn -EAGAIN;",
            "\t}",
            "\tnew_zhdr = page_address(newpage);",
            "\tmemcpy(new_zhdr, zhdr, PAGE_SIZE);",
            "\tnewpage->private = page->private;",
            "\tset_bit(PAGE_MIGRATED, &page->private);",
            "\tz3fold_page_unlock(zhdr);",
            "\tspin_lock_init(&new_zhdr->page_lock);",
            "\tINIT_WORK(&new_zhdr->work, compact_page_work);",
            "\t/*",
            "\t * z3fold_page_isolate() ensures that new_zhdr->buddy is empty,",
            "\t * so we only have to reinitialize it.",
            "\t */",
            "\tINIT_LIST_HEAD(&new_zhdr->buddy);",
            "\t__ClearPageMovable(page);",
            "",
            "\tget_page(newpage);",
            "\tz3fold_page_lock(new_zhdr);",
            "\tif (new_zhdr->first_chunks)",
            "\t\tencode_handle(new_zhdr, FIRST);",
            "\tif (new_zhdr->last_chunks)",
            "\t\tencode_handle(new_zhdr, LAST);",
            "\tif (new_zhdr->middle_chunks)",
            "\t\tencode_handle(new_zhdr, MIDDLE);",
            "\tset_bit(NEEDS_COMPACTING, &newpage->private);",
            "\tnew_zhdr->cpu = smp_processor_id();",
            "\t__SetPageMovable(newpage, &z3fold_mops);",
            "\tz3fold_page_unlock(new_zhdr);",
            "",
            "\tqueue_work_on(new_zhdr->cpu, pool->compact_wq, &new_zhdr->work);",
            "",
            "\t/* PAGE_CLAIMED and PAGE_MIGRATED are cleared now. */",
            "\tpage->private = 0;",
            "\tput_page(page);",
            "\treturn 0;",
            "}",
            "static void z3fold_page_putback(struct page *page)",
            "{",
            "\tstruct z3fold_header *zhdr;",
            "\tstruct z3fold_pool *pool;",
            "",
            "\tzhdr = page_address(page);",
            "\tpool = zhdr_to_pool(zhdr);",
            "",
            "\tz3fold_page_lock(zhdr);",
            "\tif (!list_empty(&zhdr->buddy))",
            "\t\tlist_del_init(&zhdr->buddy);",
            "\tINIT_LIST_HEAD(&page->lru);",
            "\tif (put_z3fold_locked(zhdr))",
            "\t\treturn;",
            "\tif (list_empty(&zhdr->buddy))",
            "\t\tadd_to_unbuddied(pool, zhdr);",
            "\tclear_bit(PAGE_CLAIMED, &page->private);",
            "\tz3fold_page_unlock(zhdr);",
            "}",
            "static void z3fold_zpool_destroy(void *pool)",
            "{",
            "\tz3fold_destroy_pool(pool);",
            "}",
            "static int z3fold_zpool_malloc(void *pool, size_t size, gfp_t gfp,",
            "\t\t\tunsigned long *handle)",
            "{",
            "\treturn z3fold_alloc(pool, size, gfp, handle);",
            "}",
            "static void z3fold_zpool_free(void *pool, unsigned long handle)",
            "{",
            "\tz3fold_free(pool, handle);",
            "}",
            "static void z3fold_zpool_unmap(void *pool, unsigned long handle)",
            "{",
            "\tz3fold_unmap(pool, handle);",
            "}",
            "static u64 z3fold_zpool_total_size(void *pool)",
            "{",
            "\treturn z3fold_get_pool_size(pool) * PAGE_SIZE;",
            "}",
            "static int __init init_z3fold(void)",
            "{",
            "\t/*",
            "\t * Make sure the z3fold header is not larger than the page size and",
            "\t * there has remaining spaces for its buddy.",
            "\t */",
            "\tBUILD_BUG_ON(ZHDR_SIZE_ALIGNED > PAGE_SIZE - CHUNK_SIZE);",
            "\tzpool_register_driver(&z3fold_zpool_driver);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "z3fold_page_migrate, z3fold_page_putback, z3fold_zpool_destroy, z3fold_zpool_malloc, z3fold_zpool_free, z3fold_zpool_unmap, z3fold_zpool_total_size, init_z3fold",
          "description": "z3fold_page_migrate执行页面迁移，复制页头信息并更新新页面状态。z3fold_page_putback将页面从buddy列表移除并重新插入LRU列表。z3fold_zpool_*系列函数实现内存池的销毁、分配、释放、解映射和总大小查询。init_z3fold注册Z3Fold内存池驱动。",
          "similarity": 0.3554309606552124
        },
        {
          "chunk_id": 2,
          "file_path": "mm/z3fold.c",
          "start_line": 402,
          "end_line": 513,
          "content": [
            "static unsigned short handle_to_chunks(unsigned long handle)",
            "{",
            "\tstruct z3fold_buddy_slots *slots = handle_to_slots(handle);",
            "\tunsigned long addr;",
            "",
            "\tread_lock(&slots->lock);",
            "\taddr = *(unsigned long *)handle;",
            "\tread_unlock(&slots->lock);",
            "\treturn (addr & ~PAGE_MASK) >> BUDDY_SHIFT;",
            "}",
            "static enum buddy handle_to_buddy(unsigned long handle)",
            "{",
            "\tstruct z3fold_header *zhdr;",
            "\tstruct z3fold_buddy_slots *slots = handle_to_slots(handle);",
            "\tunsigned long addr;",
            "",
            "\tread_lock(&slots->lock);",
            "\tWARN_ON(handle & (1 << PAGE_HEADLESS));",
            "\taddr = *(unsigned long *)handle;",
            "\tread_unlock(&slots->lock);",
            "\tzhdr = (struct z3fold_header *)(addr & PAGE_MASK);",
            "\treturn (addr - zhdr->first_num) & BUDDY_MASK;",
            "}",
            "static void __release_z3fold_page(struct z3fold_header *zhdr, bool locked)",
            "{",
            "\tstruct page *page = virt_to_page(zhdr);",
            "\tstruct z3fold_pool *pool = zhdr_to_pool(zhdr);",
            "",
            "\tWARN_ON(!list_empty(&zhdr->buddy));",
            "\tset_bit(PAGE_STALE, &page->private);",
            "\tclear_bit(NEEDS_COMPACTING, &page->private);",
            "\tspin_lock(&pool->lock);",
            "\tspin_unlock(&pool->lock);",
            "",
            "\tif (locked)",
            "\t\tz3fold_page_unlock(zhdr);",
            "",
            "\tspin_lock(&pool->stale_lock);",
            "\tlist_add(&zhdr->buddy, &pool->stale);",
            "\tqueue_work(pool->release_wq, &pool->work);",
            "\tspin_unlock(&pool->stale_lock);",
            "",
            "\tatomic64_dec(&pool->pages_nr);",
            "}",
            "static void release_z3fold_page_locked(struct kref *ref)",
            "{",
            "\tstruct z3fold_header *zhdr = container_of(ref, struct z3fold_header,",
            "\t\t\t\t\t\trefcount);",
            "\tWARN_ON(z3fold_page_trylock(zhdr));",
            "\t__release_z3fold_page(zhdr, true);",
            "}",
            "static void release_z3fold_page_locked_list(struct kref *ref)",
            "{",
            "\tstruct z3fold_header *zhdr = container_of(ref, struct z3fold_header,",
            "\t\t\t\t\t       refcount);",
            "\tstruct z3fold_pool *pool = zhdr_to_pool(zhdr);",
            "",
            "\tspin_lock(&pool->lock);",
            "\tlist_del_init(&zhdr->buddy);",
            "\tspin_unlock(&pool->lock);",
            "",
            "\tWARN_ON(z3fold_page_trylock(zhdr));",
            "\t__release_z3fold_page(zhdr, true);",
            "}",
            "static inline int put_z3fold_locked(struct z3fold_header *zhdr)",
            "{",
            "\treturn kref_put(&zhdr->refcount, release_z3fold_page_locked);",
            "}",
            "static inline int put_z3fold_locked_list(struct z3fold_header *zhdr)",
            "{",
            "\treturn kref_put(&zhdr->refcount, release_z3fold_page_locked_list);",
            "}",
            "static void free_pages_work(struct work_struct *w)",
            "{",
            "\tstruct z3fold_pool *pool = container_of(w, struct z3fold_pool, work);",
            "",
            "\tspin_lock(&pool->stale_lock);",
            "\twhile (!list_empty(&pool->stale)) {",
            "\t\tstruct z3fold_header *zhdr = list_first_entry(&pool->stale,",
            "\t\t\t\t\t\tstruct z3fold_header, buddy);",
            "\t\tstruct page *page = virt_to_page(zhdr);",
            "",
            "\t\tlist_del(&zhdr->buddy);",
            "\t\tif (WARN_ON(!test_bit(PAGE_STALE, &page->private)))",
            "\t\t\tcontinue;",
            "\t\tspin_unlock(&pool->stale_lock);",
            "\t\tcancel_work_sync(&zhdr->work);",
            "\t\tfree_z3fold_page(page, false);",
            "\t\tcond_resched();",
            "\t\tspin_lock(&pool->stale_lock);",
            "\t}",
            "\tspin_unlock(&pool->stale_lock);",
            "}",
            "static int num_free_chunks(struct z3fold_header *zhdr)",
            "{",
            "\tint nfree;",
            "\t/*",
            "\t * If there is a middle object, pick up the bigger free space",
            "\t * either before or after it. Otherwise just subtract the number",
            "\t * of chunks occupied by the first and the last objects.",
            "\t */",
            "\tif (zhdr->middle_chunks != 0) {",
            "\t\tint nfree_before = zhdr->first_chunks ?",
            "\t\t\t0 : zhdr->start_middle - ZHDR_CHUNKS;",
            "\t\tint nfree_after = zhdr->last_chunks ?",
            "\t\t\t0 : TOTAL_CHUNKS -",
            "\t\t\t\t(zhdr->start_middle + zhdr->middle_chunks);",
            "\t\tnfree = max(nfree_before, nfree_after);",
            "\t} else",
            "\t\tnfree = NCHUNKS - zhdr->first_chunks - zhdr->last_chunks;",
            "\treturn nfree;",
            "}"
          ],
          "function_name": "handle_to_chunks, handle_to_buddy, __release_z3fold_page, release_z3fold_page_locked, release_z3fold_page_locked_list, put_z3fold_locked, put_z3fold_locked_list, free_pages_work, num_free_chunks",
          "description": "实现页面回收流程和空闲块统计功能，通过标记STALE状态、从链表移除并触发后台释放工作，计算页面中可用块数量以支持压缩决策。",
          "similarity": 0.35160207748413086
        }
      ]
    },
    {
      "source_file": "mm/zbud.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:36:35\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `zbud.c`\n\n---\n\n# zbud.c 技术文档\n\n## 1. 文件概述\n\n`zbud.c` 实现了一个专用于存储压缩页面（compressed pages）的特殊用途内存分配器——**zbud**。尽管名称中包含“buddy”，但它并非传统的伙伴系统分配器，而是通过将两个压缩页面（称为“zpages”）配对存放在同一个物理内存页（称为“zbud page”）中来实现高效管理。\n\n该设计在牺牲一定存储密度的前提下，提供了简单且可预测的内存回收特性，特别适用于需要频繁进行内存回收（reclaim）的场景（如 zswap、zcache 等压缩交换子系统）。zbud 保证其空间利用率不会低于 1:1（即不会比直接使用未压缩页面占用更多物理页），从而确保“不会造成损害”。\n\n此外，zbud 的 API 与传统分配器不同：`zbud_alloc()` 返回一个不透明句柄（handle），用户必须通过 `zbud_map()` 映射该句柄才能获得可访问的数据指针，并在操作完成后调用 `zbud_unmap()` 解除映射。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct zbud_pool`**  \n  表示一个 zbud 内存池，包含：\n  - `lock`：自旋锁，保护池内所有字段及其中 zbud 页面的元数据。\n  - `unbuddied[NCHUNKS]`：数组，每个元素是一个链表头，用于管理仅包含一个 buddy（单配对）的 zbud 页面；索引表示页面中空闲块的数量。\n  - `buddied`：链表头，管理已包含两个 buddy（满配对）的 zbud 页面（复用 `unbuddied[0]`）。\n  - `pages_nr`：池中 zbud 页面的总数。\n\n- **`struct zbud_header`**  \n  位于每个 zbud 页面的第一个 chunk 中，作为页面元数据，包含：\n  - `buddy`：用于将页面链接到 `unbuddied` 或 `buddied` 链表。\n  - `first_chunks`：第一个 buddy 占用的 chunk 数（为 0 表示空闲）。\n  - `last_chunks`：最后一个 buddy 占用的 chunk 数（为 0 表示空闲）。\n\n### 主要函数\n\n- **`zbud_create_pool(gfp_t gfp)`**  \n  创建并初始化一个新的 zbud 内存池。\n\n- **`zbud_destroy_pool(struct zbud_pool *pool)`**  \n  销毁指定的 zbud 内存池（要求池已清空）。\n\n- **`zbud_alloc(struct zbud_pool *pool, size_t size, gfp_t gfp, unsigned long *handle)`**  \n  在池中分配指定大小的内存区域，返回不透明句柄。\n\n- **`zbud_free(struct zbud_pool *pool, unsigned long handle)`**  \n  释放由句柄标识的分配区域。\n\n- **`zbud_map(struct zbud_pool *pool, unsigned long handle)`**  \n  将句柄映射为可访问的虚拟地址指针。\n\n- **`zbud_unmap(struct zbud_pool *pool, unsigned long handle)`**  \n  解除句柄的映射。\n\n- **辅助函数**：\n  - `size_to_chunks()`：将字节大小转换为 chunk 数量。\n  - `init_zbud_page()` / `free_zbud_page()`：初始化/释放 zbud 页面。\n  - `encode_handle()` / `handle_to_zbud_header()`：句柄编码与解码。\n  - `num_free_chunks()`：计算 zbud 页面中的空闲 chunk 数。\n\n## 3. 关键实现\n\n### 内存布局与配对机制\n\n- 每个 **zbud 页面**（物理页）被划分为固定大小的 **chunks**（默认 `PAGE_SIZE / 64`，由 `NCHUNKS_ORDER=6` 决定）。\n- 第一个 chunk 被 `zbud_header` 占用，剩余 `NCHUNKS = 63` 个 chunks 可用于存储数据。\n- **First buddy** 从页面起始位置（跳过 header）向右分配（左对齐）。\n- **Last buddy** 从页面末尾向左分配（右对齐）。\n- 当任一 buddy 被释放时，其空间会与中间的 slack space 合并，形成页面内最大的连续空闲区域，便于后续分配。\n\n### 空闲管理策略\n\n- 使用 **`unbuddied[NCHUNKS]` 数组** 管理单配对页面：\n  - 索引 `i` 对应空闲 chunk 数为 `i` 的页面。\n  - 分配时优先遍历满足需求的最小空闲列表（best-fit 策略）。\n- **`buddied` 链表** 管理已满（双配对）的页面，无法再分配。\n\n### 句柄机制\n\n- 句柄本质是数据在页面内的虚拟地址，但通过 `encode_handle()` 封装：\n  - First buddy 句柄 = `zhdr 地址 + ZHDR_SIZE_ALIGNED`\n  - Last buddy 句柄 = `页面起始地址 + PAGE_SIZE - (last_chunks << CHUNK_SHIFT)`\n- 通过 `handle & PAGE_MASK` 可快速还原出 `zbud_header` 指针。\n\n### 密度保证\n\n- 由于每个 zbud 页面至少可容纳一个压缩页，因此 **zpages : zbud pages ≥ 1**，确保不会因压缩反而增加内存消耗。\n\n## 4. 依赖关系\n\n- **内核头文件**：\n  - `<linux/atomic.h>`、`<linux/spinlock.h>`：提供原子操作和自旋锁支持。\n  - `<linux/list.h>`：链表操作。\n  - `<linux/mm.h>`、`<linux/slab.h>`：内存页和 slab 分配器接口。\n  - `<linux/zpool.h>`：zbud 作为 zpool API 的一种后端实现，需符合其接口规范。\n- **架构依赖**：使用 `PAGE_SHIFT`、`PAGE_MASK` 等与页大小相关的宏，依赖体系结构定义。\n- **内存属性限制**：分配时禁止使用 `__GFP_HIGHMEM`，因高内存页无法直接映射访问。\n\n## 5. 使用场景\n\n- **zswap**：Linux 内核的交换页压缩缓存机制，使用 zbud（或 z3fold/zsmalloc）作为后端分配器存储压缩后的交换页。\n- **zcache**（历史项目）：早期基于 transcendent memory 的压缩缓存，zbud 最初为其设计。\n- **其他需要确定性回收行为的压缩内存池**：适用于对内存回收延迟敏感、且能接受较低存储密度的场景。\n- **作为 zpool 的注册后端**：通过 `zpool_register_driver()` 注册，供上层子系统按需选择。",
      "similarity": 0.45017439126968384,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/zbud.c",
          "start_line": 127,
          "end_line": 252,
          "content": [
            "static int size_to_chunks(size_t size)",
            "{",
            "\treturn (size + CHUNK_SIZE - 1) >> CHUNK_SHIFT;",
            "}",
            "static void free_zbud_page(struct zbud_header *zhdr)",
            "{",
            "\t__free_page(virt_to_page(zhdr));",
            "}",
            "static unsigned long encode_handle(struct zbud_header *zhdr, enum buddy bud)",
            "{",
            "\tunsigned long handle;",
            "",
            "\t/*",
            "\t * For now, the encoded handle is actually just the pointer to the data",
            "\t * but this might not always be the case.  A little information hiding.",
            "\t * Add CHUNK_SIZE to the handle if it is the first allocation to jump",
            "\t * over the zbud header in the first chunk.",
            "\t */",
            "\thandle = (unsigned long)zhdr;",
            "\tif (bud == FIRST)",
            "\t\t/* skip over zbud header */",
            "\t\thandle += ZHDR_SIZE_ALIGNED;",
            "\telse /* bud == LAST */",
            "\t\thandle += PAGE_SIZE - (zhdr->last_chunks  << CHUNK_SHIFT);",
            "\treturn handle;",
            "}",
            "static int num_free_chunks(struct zbud_header *zhdr)",
            "{",
            "\t/*",
            "\t * Rather than branch for different situations, just use the fact that",
            "\t * free buddies have a length of zero to simplify everything.",
            "\t */",
            "\treturn NCHUNKS - zhdr->first_chunks - zhdr->last_chunks;",
            "}",
            "static void zbud_destroy_pool(struct zbud_pool *pool)",
            "{",
            "\tkfree(pool);",
            "}",
            "static int zbud_alloc(struct zbud_pool *pool, size_t size, gfp_t gfp,",
            "\t\t\tunsigned long *handle)",
            "{",
            "\tint chunks, i, freechunks;",
            "\tstruct zbud_header *zhdr = NULL;",
            "\tenum buddy bud;",
            "\tstruct page *page;",
            "",
            "\tif (!size || (gfp & __GFP_HIGHMEM))",
            "\t\treturn -EINVAL;",
            "\tif (size > PAGE_SIZE - ZHDR_SIZE_ALIGNED - CHUNK_SIZE)",
            "\t\treturn -ENOSPC;",
            "\tchunks = size_to_chunks(size);",
            "\tspin_lock(&pool->lock);",
            "",
            "\t/* First, try to find an unbuddied zbud page. */",
            "\tfor_each_unbuddied_list(i, chunks) {",
            "\t\tif (!list_empty(&pool->unbuddied[i])) {",
            "\t\t\tzhdr = list_first_entry(&pool->unbuddied[i],",
            "\t\t\t\t\tstruct zbud_header, buddy);",
            "\t\t\tlist_del(&zhdr->buddy);",
            "\t\t\tif (zhdr->first_chunks == 0)",
            "\t\t\t\tbud = FIRST;",
            "\t\t\telse",
            "\t\t\t\tbud = LAST;",
            "\t\t\tgoto found;",
            "\t\t}",
            "\t}",
            "",
            "\t/* Couldn't find unbuddied zbud page, create new one */",
            "\tspin_unlock(&pool->lock);",
            "\tpage = alloc_page(gfp);",
            "\tif (!page)",
            "\t\treturn -ENOMEM;",
            "\tspin_lock(&pool->lock);",
            "\tpool->pages_nr++;",
            "\tzhdr = init_zbud_page(page);",
            "\tbud = FIRST;",
            "",
            "found:",
            "\tif (bud == FIRST)",
            "\t\tzhdr->first_chunks = chunks;",
            "\telse",
            "\t\tzhdr->last_chunks = chunks;",
            "",
            "\tif (zhdr->first_chunks == 0 || zhdr->last_chunks == 0) {",
            "\t\t/* Add to unbuddied list */",
            "\t\tfreechunks = num_free_chunks(zhdr);",
            "\t\tlist_add(&zhdr->buddy, &pool->unbuddied[freechunks]);",
            "\t} else {",
            "\t\t/* Add to buddied list */",
            "\t\tlist_add(&zhdr->buddy, &pool->buddied);",
            "\t}",
            "",
            "\t*handle = encode_handle(zhdr, bud);",
            "\tspin_unlock(&pool->lock);",
            "",
            "\treturn 0;",
            "}",
            "static void zbud_free(struct zbud_pool *pool, unsigned long handle)",
            "{",
            "\tstruct zbud_header *zhdr;",
            "\tint freechunks;",
            "",
            "\tspin_lock(&pool->lock);",
            "\tzhdr = handle_to_zbud_header(handle);",
            "",
            "\t/* If first buddy, handle will be page aligned */",
            "\tif ((handle - ZHDR_SIZE_ALIGNED) & ~PAGE_MASK)",
            "\t\tzhdr->last_chunks = 0;",
            "\telse",
            "\t\tzhdr->first_chunks = 0;",
            "",
            "\t/* Remove from existing buddy list */",
            "\tlist_del(&zhdr->buddy);",
            "",
            "\tif (zhdr->first_chunks == 0 && zhdr->last_chunks == 0) {",
            "\t\t/* zbud page is empty, free */",
            "\t\tfree_zbud_page(zhdr);",
            "\t\tpool->pages_nr--;",
            "\t} else {",
            "\t\t/* Add to unbuddied list */",
            "\t\tfreechunks = num_free_chunks(zhdr);",
            "\t\tlist_add(&zhdr->buddy, &pool->unbuddied[freechunks]);",
            "\t}",
            "",
            "\tspin_unlock(&pool->lock);",
            "}"
          ],
          "function_name": "size_to_chunks, free_zbud_page, encode_handle, num_free_chunks, zbud_destroy_pool, zbud_alloc, zbud_free",
          "description": "实现了zbud分配器的关键功能，包含大小转块计算、页面释放、句柄编码、空闲块统计等辅助函数，核心函数zbud_alloc尝试从空闲列表获取页或新建页面并分割存储，zbud_free处理释放逻辑并重新加入空闲列表。",
          "similarity": 0.3965952694416046
        },
        {
          "chunk_id": 0,
          "file_path": "mm/zbud.c",
          "start_line": 1,
          "end_line": 126,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * zbud.c",
            " *",
            " * Copyright (C) 2013, Seth Jennings, IBM",
            " *",
            " * Concepts based on zcache internal zbud allocator by Dan Magenheimer.",
            " *",
            " * zbud is an special purpose allocator for storing compressed pages.  Contrary",
            " * to what its name may suggest, zbud is not a buddy allocator, but rather an",
            " * allocator that \"buddies\" two compressed pages together in a single memory",
            " * page.",
            " *",
            " * While this design limits storage density, it has simple and deterministic",
            " * reclaim properties that make it preferable to a higher density approach when",
            " * reclaim will be used.",
            " *",
            " * zbud works by storing compressed pages, or \"zpages\", together in pairs in a",
            " * single memory page called a \"zbud page\".  The first buddy is \"left",
            " * justified\" at the beginning of the zbud page, and the last buddy is \"right",
            " * justified\" at the end of the zbud page.  The benefit is that if either",
            " * buddy is freed, the freed buddy space, coalesced with whatever slack space",
            " * that existed between the buddies, results in the largest possible free region",
            " * within the zbud page.",
            " *",
            " * zbud also provides an attractive lower bound on density. The ratio of zpages",
            " * to zbud pages can not be less than 1.  This ensures that zbud can never \"do",
            " * harm\" by using more pages to store zpages than the uncompressed zpages would",
            " * have used on their own.",
            " *",
            " * zbud pages are divided into \"chunks\".  The size of the chunks is fixed at",
            " * compile time and determined by NCHUNKS_ORDER below.  Dividing zbud pages",
            " * into chunks allows organizing unbuddied zbud pages into a manageable number",
            " * of unbuddied lists according to the number of free chunks available in the",
            " * zbud page.",
            " *",
            " * The zbud API differs from that of conventional allocators in that the",
            " * allocation function, zbud_alloc(), returns an opaque handle to the user,",
            " * not a dereferenceable pointer.  The user must map the handle using",
            " * zbud_map() in order to get a usable pointer by which to access the",
            " * allocation data and unmap the handle with zbud_unmap() when operations",
            " * on the allocation data are complete.",
            " */",
            "",
            "#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt",
            "",
            "#include <linux/atomic.h>",
            "#include <linux/list.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/preempt.h>",
            "#include <linux/slab.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/zpool.h>",
            "",
            "/*****************",
            " * Structures",
            "*****************/",
            "/*",
            " * NCHUNKS_ORDER determines the internal allocation granularity, effectively",
            " * adjusting internal fragmentation.  It also determines the number of",
            " * freelists maintained in each pool. NCHUNKS_ORDER of 6 means that the",
            " * allocation granularity will be in chunks of size PAGE_SIZE/64. As one chunk",
            " * in allocated page is occupied by zbud header, NCHUNKS will be calculated to",
            " * 63 which shows the max number of free chunks in zbud page, also there will be",
            " * 63 freelists per pool.",
            " */",
            "#define NCHUNKS_ORDER\t6",
            "",
            "#define CHUNK_SHIFT\t(PAGE_SHIFT - NCHUNKS_ORDER)",
            "#define CHUNK_SIZE\t(1 << CHUNK_SHIFT)",
            "#define ZHDR_SIZE_ALIGNED CHUNK_SIZE",
            "#define NCHUNKS\t\t((PAGE_SIZE - ZHDR_SIZE_ALIGNED) >> CHUNK_SHIFT)",
            "",
            "struct zbud_pool;",
            "",
            "/**",
            " * struct zbud_pool - stores metadata for each zbud pool",
            " * @lock:\tprotects all pool fields and first|last_chunk fields of any",
            " *\t\tzbud page in the pool",
            " * @unbuddied:\tarray of lists tracking zbud pages that only contain one buddy;",
            " *\t\tthe lists each zbud page is added to depends on the size of",
            " *\t\tits free region.",
            " * @buddied:\tlist tracking the zbud pages that contain two buddies;",
            " *\t\tthese zbud pages are full",
            " * @pages_nr:\tnumber of zbud pages in the pool.",
            " *",
            " * This structure is allocated at pool creation time and maintains metadata",
            " * pertaining to a particular zbud pool.",
            " */",
            "struct zbud_pool {",
            "\tspinlock_t lock;",
            "\tunion {",
            "\t\t/*",
            "\t\t * Reuse unbuddied[0] as buddied on the ground that",
            "\t\t * unbuddied[0] is unused.",
            "\t\t */",
            "\t\tstruct list_head buddied;",
            "\t\tstruct list_head unbuddied[NCHUNKS];",
            "\t};",
            "\tu64 pages_nr;",
            "};",
            "",
            "/*",
            " * struct zbud_header - zbud page metadata occupying the first chunk of each",
            " *\t\t\tzbud page.",
            " * @buddy:\tlinks the zbud page into the unbuddied/buddied lists in the pool",
            " * @first_chunks:\tthe size of the first buddy in chunks, 0 if free",
            " * @last_chunks:\tthe size of the last buddy in chunks, 0 if free",
            " */",
            "struct zbud_header {",
            "\tstruct list_head buddy;",
            "\tunsigned int first_chunks;",
            "\tunsigned int last_chunks;",
            "};",
            "",
            "/*****************",
            " * Helpers",
            "*****************/",
            "/* Just to make the code easier to read */",
            "enum buddy {",
            "\tFIRST,",
            "\tLAST",
            "};",
            "",
            "/* Converts an allocation size in bytes to size in zbud chunks */"
          ],
          "function_name": null,
          "description": "定义了zbud内存分配器的核心结构体和宏，其中NCHUNKS_ORDER决定分配粒度，struct zbud_pool维护池元数据及空闲列表，struct zbud_header存储页元信息，为后续分配和回收提供基础数据结构。",
          "similarity": 0.37800833582878113
        },
        {
          "chunk_id": 2,
          "file_path": "mm/zbud.c",
          "start_line": 363,
          "end_line": 405,
          "content": [
            "static void zbud_unmap(struct zbud_pool *pool, unsigned long handle)",
            "{",
            "}",
            "static u64 zbud_get_pool_size(struct zbud_pool *pool)",
            "{",
            "\treturn pool->pages_nr;",
            "}",
            "static void zbud_zpool_destroy(void *pool)",
            "{",
            "\tzbud_destroy_pool(pool);",
            "}",
            "static int zbud_zpool_malloc(void *pool, size_t size, gfp_t gfp,",
            "\t\t\tunsigned long *handle)",
            "{",
            "\treturn zbud_alloc(pool, size, gfp, handle);",
            "}",
            "static void zbud_zpool_free(void *pool, unsigned long handle)",
            "{",
            "\tzbud_free(pool, handle);",
            "}",
            "static void zbud_zpool_unmap(void *pool, unsigned long handle)",
            "{",
            "\tzbud_unmap(pool, handle);",
            "}",
            "static u64 zbud_zpool_total_size(void *pool)",
            "{",
            "\treturn zbud_get_pool_size(pool) * PAGE_SIZE;",
            "}",
            "static int __init init_zbud(void)",
            "{",
            "\t/* Make sure the zbud header will fit in one chunk */",
            "\tBUILD_BUG_ON(sizeof(struct zbud_header) > ZHDR_SIZE_ALIGNED);",
            "\tpr_info(\"loaded\\n\");",
            "",
            "\tzpool_register_driver(&zbud_zpool_driver);",
            "",
            "\treturn 0;",
            "}",
            "static void __exit exit_zbud(void)",
            "{",
            "\tzpool_unregister_driver(&zbud_zpool_driver);",
            "\tpr_info(\"unloaded\\n\");",
            "}"
          ],
          "function_name": "zbud_unmap, zbud_get_pool_size, zbud_zpool_destroy, zbud_zpool_malloc, zbud_zpool_free, zbud_zpool_unmap, zbud_zpool_total_size, init_zbud, exit_zbud",
          "description": "提供了zpool驱动接口实现，包含池大小查询、内存释放、句柄解码等操作，通过zpool_register_driver注册驱动，init_zbud和exit_zbud分别负责模块加载时的初始化和卸载清理工作。",
          "similarity": 0.35916292667388916
        }
      ]
    },
    {
      "source_file": "kernel/bpf/ringbuf.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:29:46\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\ringbuf.c`\n\n---\n\n# `bpf/ringbuf.c` 技术文档\n\n## 1. 文件概述\n\n`bpf/ringbuf.c` 实现了 BPF（Berkeley Packet Filter）子系统中的**环形缓冲区（Ring Buffer）**机制，用于在内核与用户空间之间高效、安全地传递数据。该机制支持两种生产者模式：**内核生产者**（如 BPF 程序）和**用户空间生产者**，并提供内存映射（`mmap`）、等待队列通知、并发控制等核心功能，是 BPF 数据输出（如 perf event 替代方案）的关键基础设施。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct bpf_ringbuf`**  \n  环形缓冲区的核心结构体，包含：\n  - `waitq`：等待队列，用于通知用户空间有新数据\n  - `work`：IRQ 工作项，用于异步唤醒等待队列\n  - `mask`：环形缓冲区大小掩码（`data_sz - 1`），用于快速取模\n  - `pages` / `nr_pages`：物理页数组，支持双映射\n  - `spinlock`：用于内核生产者的自旋锁（SMP 对齐）\n  - `busy`：原子变量，用于用户空间生产者的互斥访问（避免持有自旋锁过久）\n  - `consumer_pos` / `producer_pos` / `pending_pos`：消费者、生产者和待提交位置（各自独占一页，支持不同 mmap 权限）\n  - `data[]`：实际数据存储区域（页对齐）\n\n- **`struct bpf_ringbuf_map`**  \n  封装标准 `bpf_map`，关联一个 `bpf_ringbuf` 实例。\n\n- **`struct bpf_ringbuf_hdr`**  \n  8 字节记录头，包含：\n  - `len`：记录有效载荷长度\n  - `pg_off`：记录在页内的偏移（用于跨页处理）\n\n### 主要函数\n\n- **`bpf_ringbuf_area_alloc()`**  \n  分配并初始化环形缓冲区的虚拟内存区域，采用**双映射数据页**技术简化环绕处理。\n\n- **`bpf_ringbuf_alloc()`**  \n  初始化 `bpf_ringbuf` 结构体，设置锁、等待队列、IRQ 工作项及初始位置。\n\n- **`bpf_ringbuf_free()`**  \n  释放环形缓冲区占用的虚拟内存和物理页。\n\n- **`ringbuf_map_alloc()`**  \n  BPF map 分配器回调，验证参数并创建 `bpf_ringbuf_map`。\n\n- **`ringbuf_map_free()`**  \n  BPF map 释放器回调，清理资源。\n\n- **`ringbuf_map_*_elem()` / `ringbuf_map_get_next_key()`**  \n  禁用标准 map 操作（返回 `-ENOTSUPP`），因为 ringbuf 不支持键值操作。\n\n- **`bpf_ringbuf_notify()`**  \n  IRQ 工作回调，唤醒所有等待数据的用户进程。\n\n## 3. 关键实现\n\n### 双映射数据页（Double-Mapped Data Pages）\n\n为简化环形缓冲区**环绕（wrap-around）**时的数据读取逻辑，数据页被**连续映射两次**：\n```\n[meta pages][data pages][data pages (same as first copy)]\n```\n当读取跨越缓冲区末尾时，可直接线性读取第二份映射，无需特殊处理。此设计同时适用于内核和用户空间 `mmap`。\n\n### 权限隔离与安全\n\n- **`consumer_pos` 和 `producer_pos` 各占独立页**，允许通过 `mmap` 设置不同权限：\n  - **内核生产者模式**：`producer_pos` 和数据页对用户空间为**只读**，防止篡改。\n  - **用户空间生产者模式**：仅 `consumer_pos` 对用户空间为**只读**，内核需严格验证用户提交的记录。\n\n### 并发控制策略\n\n- **内核生产者**：使用 `raw_spinlock_t` 保证多生产者安全。\n- **用户空间生产者**：使用 `atomic_t busy` 原子变量，避免在 BPF 程序回调期间长期持有 IRQ 自旋锁（可能导致死锁或延迟）。若 `busy` 被占用，`__bpf_user_ringbuf_peek()` 返回 `-EBUSY`。\n\n### 内存布局与对齐\n\n- 非 `mmap` 部分（`waitq` 到 `pending_pos`）大小由 `RINGBUF_PGOFF` 定义。\n- `consumer_pos`、`producer_pos` 和 `data` 均按 `PAGE_SIZE` 对齐，确保可独立映射。\n- 总元数据页数：`RINGBUF_NR_META_PAGES = RINGBUF_PGOFF + 2`（含 consumer/producer 页）。\n\n### 大小限制\n\n- 最大记录大小：`RINGBUF_MAX_RECORD_SZ = UINT_MAX / 4`（约 1GB）。\n- 最大缓冲区大小受 `bpf_ringbuf_hdr.pg_off`（32 位页偏移）限制，理论最大约 **64GB**。\n\n## 4. 依赖关系\n\n- **BPF 子系统**：依赖 `bpf_map` 基础设施（`bpf_map_area_alloc/free`、`bpf_map_init_from_attr`）。\n- **内存管理**：使用 `alloc_pages_node`、`vmap`/`vunmap`、`__free_page` 管理物理页和虚拟映射。\n- **同步机制**：依赖 `wait_queue`、`irq_work`、`raw_spinlock` 和 `atomic_t`。\n- **BTF（BPF Type Format）**：包含 BTF 相关头文件，可能用于未来类型验证（当前未直接使用）。\n- **用户 API**：与 `uapi/linux/bpf.h` 中的 `BPF_F_NUMA_NODE` 等标志交互。\n\n## 5. 使用场景\n\n- **BPF 程序输出数据**：替代 `bpf_perf_event_output()`，提供更低开销、更高吞吐的内核到用户空间数据通道。\n- **用户空间主动提交数据**：允许用户程序通过 ringbuf 向内核提交样本（需内核验证）。\n- **实时监控与追踪**：用于 eBPF 监控工具（如 `bpftrace`、`libbpf` 应用）高效收集内核事件。\n- **NUMA 感知分配**：支持通过 `BPF_F_NUMA_NODE` 标志在指定 NUMA 节点分配内存，优化性能。",
      "similarity": 0.44464099407196045,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/bpf/ringbuf.c",
          "start_line": 1,
          "end_line": 149,
          "content": [
            "#include <linux/bpf.h>",
            "#include <linux/btf.h>",
            "#include <linux/err.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/wait.h>",
            "#include <linux/poll.h>",
            "#include <linux/kmemleak.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/btf_ids.h>",
            "",
            "#define RINGBUF_CREATE_FLAG_MASK (BPF_F_NUMA_NODE)",
            "",
            "/* non-mmap()'able part of bpf_ringbuf (everything up to consumer page) */",
            "#define RINGBUF_PGOFF \\",
            "\t(offsetof(struct bpf_ringbuf, consumer_pos) >> PAGE_SHIFT)",
            "/* consumer page and producer page */",
            "#define RINGBUF_POS_PAGES 2",
            "#define RINGBUF_NR_META_PAGES (RINGBUF_PGOFF + RINGBUF_POS_PAGES)",
            "",
            "#define RINGBUF_MAX_RECORD_SZ (UINT_MAX/4)",
            "",
            "struct bpf_ringbuf {",
            "\twait_queue_head_t waitq;",
            "\tstruct irq_work work;",
            "\tu64 mask;",
            "\tstruct page **pages;",
            "\tint nr_pages;",
            "\traw_spinlock_t spinlock ____cacheline_aligned_in_smp;",
            "\t/* For user-space producer ring buffers, an atomic_t busy bit is used",
            "\t * to synchronize access to the ring buffers in the kernel, rather than",
            "\t * the spinlock that is used for kernel-producer ring buffers. This is",
            "\t * done because the ring buffer must hold a lock across a BPF program's",
            "\t * callback:",
            "\t *",
            "\t *    __bpf_user_ringbuf_peek() // lock acquired",
            "\t * -> program callback_fn()",
            "\t * -> __bpf_user_ringbuf_sample_release() // lock released",
            "\t *",
            "\t * It is unsafe and incorrect to hold an IRQ spinlock across what could",
            "\t * be a long execution window, so we instead simply disallow concurrent",
            "\t * access to the ring buffer by kernel consumers, and return -EBUSY from",
            "\t * __bpf_user_ringbuf_peek() if the busy bit is held by another task.",
            "\t */",
            "\tatomic_t busy ____cacheline_aligned_in_smp;",
            "\t/* Consumer and producer counters are put into separate pages to",
            "\t * allow each position to be mapped with different permissions.",
            "\t * This prevents a user-space application from modifying the",
            "\t * position and ruining in-kernel tracking. The permissions of the",
            "\t * pages depend on who is producing samples: user-space or the",
            "\t * kernel. Note that the pending counter is placed in the same",
            "\t * page as the producer, so that it shares the same cache line.",
            "\t *",
            "\t * Kernel-producer",
            "\t * ---------------",
            "\t * The producer position and data pages are mapped as r/o in",
            "\t * userspace. For this approach, bits in the header of samples are",
            "\t * used to signal to user-space, and to other producers, whether a",
            "\t * sample is currently being written.",
            "\t *",
            "\t * User-space producer",
            "\t * -------------------",
            "\t * Only the page containing the consumer position is mapped r/o in",
            "\t * user-space. User-space producers also use bits of the header to",
            "\t * communicate to the kernel, but the kernel must carefully check and",
            "\t * validate each sample to ensure that they're correctly formatted, and",
            "\t * fully contained within the ring buffer.",
            "\t */",
            "\tunsigned long consumer_pos __aligned(PAGE_SIZE);",
            "\tunsigned long producer_pos __aligned(PAGE_SIZE);",
            "\tunsigned long pending_pos;",
            "\tchar data[] __aligned(PAGE_SIZE);",
            "};",
            "",
            "struct bpf_ringbuf_map {",
            "\tstruct bpf_map map;",
            "\tstruct bpf_ringbuf *rb;",
            "};",
            "",
            "/* 8-byte ring buffer record header structure */",
            "struct bpf_ringbuf_hdr {",
            "\tu32 len;",
            "\tu32 pg_off;",
            "};",
            "",
            "static struct bpf_ringbuf *bpf_ringbuf_area_alloc(size_t data_sz, int numa_node)",
            "{",
            "\tconst gfp_t flags = GFP_KERNEL_ACCOUNT | __GFP_RETRY_MAYFAIL |",
            "\t\t\t    __GFP_NOWARN | __GFP_ZERO;",
            "\tint nr_meta_pages = RINGBUF_NR_META_PAGES;",
            "\tint nr_data_pages = data_sz >> PAGE_SHIFT;",
            "\tint nr_pages = nr_meta_pages + nr_data_pages;",
            "\tstruct page **pages, *page;",
            "\tstruct bpf_ringbuf *rb;",
            "\tsize_t array_size;",
            "\tint i;",
            "",
            "\t/* Each data page is mapped twice to allow \"virtual\"",
            "\t * continuous read of samples wrapping around the end of ring",
            "\t * buffer area:",
            "\t * ------------------------------------------------------",
            "\t * | meta pages |  real data pages  |  same data pages  |",
            "\t * ------------------------------------------------------",
            "\t * |            | 1 2 3 4 5 6 7 8 9 | 1 2 3 4 5 6 7 8 9 |",
            "\t * ------------------------------------------------------",
            "\t * |            | TA             DA | TA             DA |",
            "\t * ------------------------------------------------------",
            "\t *                               ^^^^^^^",
            "\t *                                  |",
            "\t * Here, no need to worry about special handling of wrapped-around",
            "\t * data due to double-mapped data pages. This works both in kernel and",
            "\t * when mmap()'ed in user-space, simplifying both kernel and",
            "\t * user-space implementations significantly.",
            "\t */",
            "\tarray_size = (nr_meta_pages + 2 * nr_data_pages) * sizeof(*pages);",
            "\tpages = bpf_map_area_alloc(array_size, numa_node);",
            "\tif (!pages)",
            "\t\treturn NULL;",
            "",
            "\tfor (i = 0; i < nr_pages; i++) {",
            "\t\tpage = alloc_pages_node(numa_node, flags, 0);",
            "\t\tif (!page) {",
            "\t\t\tnr_pages = i;",
            "\t\t\tgoto err_free_pages;",
            "\t\t}",
            "\t\tpages[i] = page;",
            "\t\tif (i >= nr_meta_pages)",
            "\t\t\tpages[nr_data_pages + i] = page;",
            "\t}",
            "",
            "\trb = vmap(pages, nr_meta_pages + 2 * nr_data_pages,",
            "\t\t  VM_MAP | VM_USERMAP, PAGE_KERNEL);",
            "\tif (rb) {",
            "\t\tkmemleak_not_leak(pages);",
            "\t\trb->pages = pages;",
            "\t\trb->nr_pages = nr_pages;",
            "\t\treturn rb;",
            "\t}",
            "",
            "err_free_pages:",
            "\tfor (i = 0; i < nr_pages; i++)",
            "\t\t__free_page(pages[i]);",
            "\tbpf_map_area_free(pages);",
            "\treturn NULL;",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义了bpf_ringbuf结构体及其相关宏，用于管理BPF环形缓冲区的元数据和数据区域。通过页面数组实现环形缓冲区的虚拟连续读取，支持用户态和内核态生产者的差异化权限控制，其中包含消费者/生产者位置指针、忙位原子变量及锁保护的元数据。",
          "similarity": 0.37285685539245605
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/bpf/ringbuf.c",
          "start_line": 335,
          "end_line": 447,
          "content": [
            "static u64 ringbuf_map_mem_usage(const struct bpf_map *map)",
            "{",
            "\tstruct bpf_ringbuf *rb;",
            "\tint nr_data_pages;",
            "\tint nr_meta_pages;",
            "\tu64 usage = sizeof(struct bpf_ringbuf_map);",
            "",
            "\trb = container_of(map, struct bpf_ringbuf_map, map)->rb;",
            "\tusage += (u64)rb->nr_pages << PAGE_SHIFT;",
            "\tnr_meta_pages = RINGBUF_NR_META_PAGES;",
            "\tnr_data_pages = map->max_entries >> PAGE_SHIFT;",
            "\tusage += (nr_meta_pages + 2 * nr_data_pages) * sizeof(struct page *);",
            "\treturn usage;",
            "}",
            "static size_t bpf_ringbuf_rec_pg_off(struct bpf_ringbuf *rb,",
            "\t\t\t\t     struct bpf_ringbuf_hdr *hdr)",
            "{",
            "\treturn ((void *)hdr - (void *)rb) >> PAGE_SHIFT;",
            "}",
            "static void bpf_ringbuf_commit(void *sample, u64 flags, bool discard)",
            "{",
            "\tunsigned long rec_pos, cons_pos;",
            "\tstruct bpf_ringbuf_hdr *hdr;",
            "\tstruct bpf_ringbuf *rb;",
            "\tu32 new_len;",
            "",
            "\thdr = sample - BPF_RINGBUF_HDR_SZ;",
            "\trb = bpf_ringbuf_restore_from_rec(hdr);",
            "\tnew_len = hdr->len ^ BPF_RINGBUF_BUSY_BIT;",
            "\tif (discard)",
            "\t\tnew_len |= BPF_RINGBUF_DISCARD_BIT;",
            "",
            "\t/* update record header with correct final size prefix */",
            "\txchg(&hdr->len, new_len);",
            "",
            "\t/* if consumer caught up and is waiting for our record, notify about",
            "\t * new data availability",
            "\t */",
            "\trec_pos = (void *)hdr - (void *)rb->data;",
            "\tcons_pos = smp_load_acquire(&rb->consumer_pos) & rb->mask;",
            "",
            "\tif (flags & BPF_RB_FORCE_WAKEUP)",
            "\t\tirq_work_queue(&rb->work);",
            "\telse if (cons_pos == rec_pos && !(flags & BPF_RB_NO_WAKEUP))",
            "\t\tirq_work_queue(&rb->work);",
            "}",
            "static int __bpf_user_ringbuf_peek(struct bpf_ringbuf *rb, void **sample, u32 *size)",
            "{",
            "\tint err;",
            "\tu32 hdr_len, sample_len, total_len, flags, *hdr;",
            "\tu64 cons_pos, prod_pos;",
            "",
            "\t/* Synchronizes with smp_store_release() in user-space producer. */",
            "\tprod_pos = smp_load_acquire(&rb->producer_pos);",
            "\tif (prod_pos % 8)",
            "\t\treturn -EINVAL;",
            "",
            "\t/* Synchronizes with smp_store_release() in __bpf_user_ringbuf_sample_release() */",
            "\tcons_pos = smp_load_acquire(&rb->consumer_pos);",
            "\tif (cons_pos >= prod_pos)",
            "\t\treturn -ENODATA;",
            "",
            "\thdr = (u32 *)((uintptr_t)rb->data + (uintptr_t)(cons_pos & rb->mask));",
            "\t/* Synchronizes with smp_store_release() in user-space producer. */",
            "\thdr_len = smp_load_acquire(hdr);",
            "\tflags = hdr_len & (BPF_RINGBUF_BUSY_BIT | BPF_RINGBUF_DISCARD_BIT);",
            "\tsample_len = hdr_len & ~flags;",
            "\ttotal_len = round_up(sample_len + BPF_RINGBUF_HDR_SZ, 8);",
            "",
            "\t/* The sample must fit within the region advertised by the producer position. */",
            "\tif (total_len > prod_pos - cons_pos)",
            "\t\treturn -EINVAL;",
            "",
            "\t/* The sample must fit within the data region of the ring buffer. */",
            "\tif (total_len > ringbuf_total_data_sz(rb))",
            "\t\treturn -E2BIG;",
            "",
            "\t/* The sample must fit into a struct bpf_dynptr. */",
            "\terr = bpf_dynptr_check_size(sample_len);",
            "\tif (err)",
            "\t\treturn -E2BIG;",
            "",
            "\tif (flags & BPF_RINGBUF_DISCARD_BIT) {",
            "\t\t/* If the discard bit is set, the sample should be skipped.",
            "\t\t *",
            "\t\t * Update the consumer pos, and return -EAGAIN so the caller",
            "\t\t * knows to skip this sample and try to read the next one.",
            "\t\t */",
            "\t\tsmp_store_release(&rb->consumer_pos, cons_pos + total_len);",
            "\t\treturn -EAGAIN;",
            "\t}",
            "",
            "\tif (flags & BPF_RINGBUF_BUSY_BIT)",
            "\t\treturn -ENODATA;",
            "",
            "\t*sample = (void *)((uintptr_t)rb->data +",
            "\t\t\t   (uintptr_t)((cons_pos + BPF_RINGBUF_HDR_SZ) & rb->mask));",
            "\t*size = sample_len;",
            "\treturn 0;",
            "}",
            "static void __bpf_user_ringbuf_sample_release(struct bpf_ringbuf *rb, size_t size, u64 flags)",
            "{",
            "\tu64 consumer_pos;",
            "\tu32 rounded_size = round_up(size + BPF_RINGBUF_HDR_SZ, 8);",
            "",
            "\t/* Using smp_load_acquire() is unnecessary here, as the busy-bit",
            "\t * prevents another task from writing to consumer_pos after it was read",
            "\t * by this task with smp_load_acquire() in __bpf_user_ringbuf_peek().",
            "\t */",
            "\tconsumer_pos = rb->consumer_pos;",
            "\t /* Synchronizes with smp_load_acquire() in user-space producer. */",
            "\tsmp_store_release(&rb->consumer_pos, consumer_pos + rounded_size);",
            "}"
          ],
          "function_name": "ringbuf_map_mem_usage, bpf_ringbuf_rec_pg_off, bpf_ringbuf_commit, __bpf_user_ringbuf_peek, __bpf_user_ringbuf_sample_release",
          "description": "提供了环形缓冲区的内存占用统计、记录位置转换、样本提交及消费操作。包含用户态生产者与消费者的同步机制，通过忙位防止竞态条件，确保样本数据完整性校验和消费进度更新的有序性。",
          "similarity": 0.3616607189178467
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/bpf/ringbuf.c",
          "start_line": 150,
          "end_line": 258,
          "content": [
            "static void bpf_ringbuf_notify(struct irq_work *work)",
            "{",
            "\tstruct bpf_ringbuf *rb = container_of(work, struct bpf_ringbuf, work);",
            "",
            "\twake_up_all(&rb->waitq);",
            "}",
            "static void bpf_ringbuf_free(struct bpf_ringbuf *rb)",
            "{",
            "\t/* copy pages pointer and nr_pages to local variable, as we are going",
            "\t * to unmap rb itself with vunmap() below",
            "\t */",
            "\tstruct page **pages = rb->pages;",
            "\tint i, nr_pages = rb->nr_pages;",
            "",
            "\tvunmap(rb);",
            "\tfor (i = 0; i < nr_pages; i++)",
            "\t\t__free_page(pages[i]);",
            "\tbpf_map_area_free(pages);",
            "}",
            "static void ringbuf_map_free(struct bpf_map *map)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "\tbpf_ringbuf_free(rb_map->rb);",
            "\tbpf_map_area_free(rb_map);",
            "}",
            "static long ringbuf_map_update_elem(struct bpf_map *map, void *key, void *value,",
            "\t\t\t\t    u64 flags)",
            "{",
            "\treturn -ENOTSUPP;",
            "}",
            "static long ringbuf_map_delete_elem(struct bpf_map *map, void *key)",
            "{",
            "\treturn -ENOTSUPP;",
            "}",
            "static int ringbuf_map_get_next_key(struct bpf_map *map, void *key,",
            "\t\t\t\t    void *next_key)",
            "{",
            "\treturn -ENOTSUPP;",
            "}",
            "static int ringbuf_map_mmap_kern(struct bpf_map *map, struct vm_area_struct *vma)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "",
            "\tif (vma->vm_flags & VM_WRITE) {",
            "\t\t/* allow writable mapping for the consumer_pos only */",
            "\t\tif (vma->vm_pgoff != 0 || vma->vm_end - vma->vm_start != PAGE_SIZE)",
            "\t\t\treturn -EPERM;",
            "\t}",
            "\t/* remap_vmalloc_range() checks size and offset constraints */",
            "\treturn remap_vmalloc_range(vma, rb_map->rb,",
            "\t\t\t\t   vma->vm_pgoff + RINGBUF_PGOFF);",
            "}",
            "static int ringbuf_map_mmap_user(struct bpf_map *map, struct vm_area_struct *vma)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "",
            "\tif (vma->vm_flags & VM_WRITE) {",
            "\t\tif (vma->vm_pgoff == 0)",
            "\t\t\t/* Disallow writable mappings to the consumer pointer,",
            "\t\t\t * and allow writable mappings to both the producer",
            "\t\t\t * position, and the ring buffer data itself.",
            "\t\t\t */",
            "\t\t\treturn -EPERM;",
            "\t}",
            "\t/* remap_vmalloc_range() checks size and offset constraints */",
            "\treturn remap_vmalloc_range(vma, rb_map->rb, vma->vm_pgoff + RINGBUF_PGOFF);",
            "}",
            "static unsigned long ringbuf_avail_data_sz(struct bpf_ringbuf *rb)",
            "{",
            "\tunsigned long cons_pos, prod_pos;",
            "",
            "\tcons_pos = smp_load_acquire(&rb->consumer_pos);",
            "\tprod_pos = smp_load_acquire(&rb->producer_pos);",
            "\treturn prod_pos - cons_pos;",
            "}",
            "static u32 ringbuf_total_data_sz(const struct bpf_ringbuf *rb)",
            "{",
            "\treturn rb->mask + 1;",
            "}",
            "static __poll_t ringbuf_map_poll_kern(struct bpf_map *map, struct file *filp,",
            "\t\t\t\t      struct poll_table_struct *pts)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "\tpoll_wait(filp, &rb_map->rb->waitq, pts);",
            "",
            "\tif (ringbuf_avail_data_sz(rb_map->rb))",
            "\t\treturn EPOLLIN | EPOLLRDNORM;",
            "\treturn 0;",
            "}",
            "static __poll_t ringbuf_map_poll_user(struct bpf_map *map, struct file *filp,",
            "\t\t\t\t      struct poll_table_struct *pts)",
            "{",
            "\tstruct bpf_ringbuf_map *rb_map;",
            "",
            "\trb_map = container_of(map, struct bpf_ringbuf_map, map);",
            "\tpoll_wait(filp, &rb_map->rb->waitq, pts);",
            "",
            "\tif (ringbuf_avail_data_sz(rb_map->rb) < ringbuf_total_data_sz(rb_map->rb))",
            "\t\treturn EPOLLOUT | EPOLLWRNORM;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "bpf_ringbuf_notify, bpf_ringbuf_free, ringbuf_map_free, ringbuf_map_update_elem, ringbuf_map_delete_elem, ringbuf_map_get_next_key, ringbuf_map_mmap_kern, ringbuf_map_mmap_user, ringbuf_avail_data_sz, ringbuf_total_data_sz, ringbuf_map_poll_kern, ringbuf_map_poll_user",
          "description": "实现了环形缓冲区的事件通知、资源释放、内存映射控制及I/O监控功能。包含针对用户态和内核态的差异化mmap处理逻辑，通过spinlock和atomic_t实现并发控制，提供poll接口检测缓冲区可用数据状态。",
          "similarity": 0.3406493067741394
        }
      ]
    }
  ]
}