{
  "query": "perf事件缓存与命中率分析",
  "timestamp": "2025-12-26 01:41:53",
  "retrieved_files": [
    {
      "source_file": "kernel/events/ring_buffer.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:25:08\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `events\\ring_buffer.c`\n\n---\n\n# `events/ring_buffer.c` 技术文档\n\n## 1. 文件概述\n\n`events/ring_buffer.c` 是 Linux 内核性能事件（perf events）子系统中用于实现高性能、无锁环形缓冲区（ring buffer）的核心文件。该文件提供了在内核态向用户态高效传递性能采样数据的机制，支持前向（forward）和后向（backward）两种写入模式，并确保在中断（IRQ）和不可屏蔽中断（NMI）上下文中安全使用。其设计重点在于高并发场景下的数据一致性、内存屏障语义以及与用户空间 mmap 映射的协同工作。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `perf_output_wakeup(struct perf_output_handle *handle)`  \n  触发事件唤醒机制，设置 poll 状态并调度 IRQ work 以通知用户空间有新数据可读。\n\n- `perf_output_get_handle(struct perf_output_handle *handle)`  \n  获取输出句柄，增加嵌套计数（`nest`），用于支持嵌套写入（如 NMI 中再次写入）。\n\n- `perf_output_put_handle(struct perf_output_handle *handle)`  \n  释放输出句柄，仅在最外层嵌套结束时更新用户页中的 `data_head`，并根据需要触发唤醒。\n\n- `__perf_output_begin(..., bool backward)`  \n  通用的输出开始函数，尝试为指定大小的数据在环形缓冲区中预留空间，支持前向/后向写入模式。\n\n- `perf_output_begin_forward(...)` / `perf_output_begin_backward(...)` / `perf_output_begin(...)`  \n  封装函数，分别用于前向写入、后向写入和根据事件属性自动选择方向的写入初始化。\n\n- `perf_output_copy(...)` / `perf_output_skip(...)`  \n  分别用于将数据拷贝到缓冲区或跳过指定字节数（预留空间）。\n\n- `perf_output_end(...)`  \n  结束一次输出操作，调用 `perf_output_put_handle` 并释放 RCU 锁。\n\n- `ring_buffer_init(...)`（未完整展示）  \n  初始化 `perf_buffer` 结构体，设置水位线等参数。\n\n### 关键数据结构（隐含）\n\n- `struct perf_buffer`：环形缓冲区的内核表示，包含 `head`、`tail`、`nest`、`lost`、`user_page` 等字段。\n- `struct perf_output_handle`：一次输出操作的上下文句柄，包含缓冲区页、地址、大小等信息。\n- `struct perf_event`：性能事件对象，关联其输出缓冲区。\n\n## 3. 关键实现\n\n### 嵌套写入与 NMI 安全性\n- 使用 `rb->nest` 计数器跟踪嵌套层数（如普通上下文写入过程中被 NMI 中断并再次写入）。\n- 仅当 `nest == 1`（最外层）退出时才更新用户可见的 `data_head`，防止中间状态暴露给用户空间。\n- 通过 `barrier()` 和 `volatile` 访问确保嵌套计数与 head 更新的顺序性。\n\n### 内存屏障与用户空间同步\n- 采用经典的 **生产者-消费者内存模型**：\n  - 内核（生产者）：先写数据，`smp_wmb()`，再更新 `data_head`。\n  - 用户空间（消费者）：先读 `data_head`，`smp_rmb()`，再读数据，最后写 `data_tail`。\n- 代码注释中明确标出屏障配对关系（A-D），确保跨 CPU 的数据一致性。\n\n### 环形缓冲区空间管理\n- 使用 `CIRC_SPACE` 宏计算可用空间，区分前向（`head >= tail`）和后向（`tail >= head`）模式。\n- 非覆盖模式（`!overwrite`）下，若空间不足则返回 `-ENOSPC` 并增加 `lost` 计数。\n- 使用 `local_try_cmpxchg` 原子地推进 `rb->head`，避免锁竞争。\n\n### 丢失事件处理\n- 若检测到 `rb->lost > 0`，自动在用户数据前插入 `PERF_RECORD_LOST` 记录，报告丢失样本数。\n- 通过 `perf_event_header__init_id` 和 `perf_event__output_id_sample` 确保 ID 信息正确。\n\n### 水位线与唤醒机制\n- 当 `head - wakeup > watermark` 时，推进 `wakeup` 指针并触发 `perf_output_wakeup`。\n- 唤醒通过设置 `poll` 事件位和调度 `irq_work` 实现，避免在原子上下文中直接唤醒。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/perf_event.h>`：perf 事件核心定义。\n  - `<linux/circ_buf.h>`：提供 `CIRC_SPACE` 等环形缓冲区宏。\n  - `<linux/nospec.h>`：防范推测执行漏洞。\n  - `\"internal.h\"`：perf 子系统内部头文件，包含 `__output_copy` 等辅助函数。\n- **内核子系统**：\n  - RCU（Read-Copy-Update）：用于安全访问 `event->rb`。\n  - IRQ Work：用于延迟执行唤醒操作。\n  - Slab/Vmalloc：用于分配缓冲区内存（虽未在片段中体现，但 `perf_buffer` 初始化时使用）。\n- **用户空间接口**：通过 `mmap()` 映射 `user_page` 和数据页，依赖约定的内存屏障语义。\n\n## 5. 使用场景\n\n- **性能监控工具**：如 `perf record`、`perf stat` 等通过此机制接收内核采样数据。\n- **动态追踪**：eBPF 程序或 kprobe 事件通过 perf ring buffer 向用户空间传递追踪信息。\n- **硬件性能计数器溢出处理**：当 PMU 计数器溢出时，中断处理程序使用此接口记录样本。\n- **NMI 上下文采样**：支持在不可屏蔽中断中安全写入（如 NMI watchdog 触发的栈回溯）。\n- **前向/后向缓冲区**：前向用于常规流式输出；后向用于“最后 N 个事件”场景（如崩溃前状态捕获）。",
      "similarity": 0.6355470418930054,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 20,
          "end_line": 125,
          "content": [
            "static void perf_output_wakeup(struct perf_output_handle *handle)",
            "{",
            "\tatomic_set(&handle->rb->poll, EPOLLIN | EPOLLRDNORM);",
            "",
            "\thandle->event->pending_wakeup = 1;",
            "\tirq_work_queue(&handle->event->pending_irq);",
            "}",
            "static void perf_output_get_handle(struct perf_output_handle *handle)",
            "{",
            "\tstruct perf_buffer *rb = handle->rb;",
            "",
            "\tpreempt_disable();",
            "",
            "\t/*",
            "\t * Avoid an explicit LOAD/STORE such that architectures with memops",
            "\t * can use them.",
            "\t */",
            "\t(*(volatile unsigned int *)&rb->nest)++;",
            "\thandle->wakeup = local_read(&rb->wakeup);",
            "}",
            "static void perf_output_put_handle(struct perf_output_handle *handle)",
            "{",
            "\tstruct perf_buffer *rb = handle->rb;",
            "\tunsigned long head;",
            "\tunsigned int nest;",
            "",
            "\t/*",
            "\t * If this isn't the outermost nesting, we don't have to update",
            "\t * @rb->user_page->data_head.",
            "\t */",
            "\tnest = READ_ONCE(rb->nest);",
            "\tif (nest > 1) {",
            "\t\tWRITE_ONCE(rb->nest, nest - 1);",
            "\t\tgoto out;",
            "\t}",
            "",
            "again:",
            "\t/*",
            "\t * In order to avoid publishing a head value that goes backwards,",
            "\t * we must ensure the load of @rb->head happens after we've",
            "\t * incremented @rb->nest.",
            "\t *",
            "\t * Otherwise we can observe a @rb->head value before one published",
            "\t * by an IRQ/NMI happening between the load and the increment.",
            "\t */",
            "\tbarrier();",
            "\thead = local_read(&rb->head);",
            "",
            "\t/*",
            "\t * IRQ/NMI can happen here and advance @rb->head, causing our",
            "\t * load above to be stale.",
            "\t */",
            "",
            "\t/*",
            "\t * Since the mmap() consumer (userspace) can run on a different CPU:",
            "\t *",
            "\t *   kernel\t\t\t\tuser",
            "\t *",
            "\t *   if (LOAD ->data_tail) {\t\tLOAD ->data_head",
            "\t *\t\t\t(A)\t\tsmp_rmb()\t(C)",
            "\t *\tSTORE $data\t\t\tLOAD $data",
            "\t *\tsmp_wmb()\t(B)\t\tsmp_mb()\t(D)",
            "\t *\tSTORE ->data_head\t\tSTORE ->data_tail",
            "\t *   }",
            "\t *",
            "\t * Where A pairs with D, and B pairs with C.",
            "\t *",
            "\t * In our case (A) is a control dependency that separates the load of",
            "\t * the ->data_tail and the stores of $data. In case ->data_tail",
            "\t * indicates there is no room in the buffer to store $data we do not.",
            "\t *",
            "\t * D needs to be a full barrier since it separates the data READ",
            "\t * from the tail WRITE.",
            "\t *",
            "\t * For B a WMB is sufficient since it separates two WRITEs, and for C",
            "\t * an RMB is sufficient since it separates two READs.",
            "\t *",
            "\t * See perf_output_begin().",
            "\t */",
            "\tsmp_wmb(); /* B, matches C */",
            "\tWRITE_ONCE(rb->user_page->data_head, head);",
            "",
            "\t/*",
            "\t * We must publish the head before decrementing the nest count,",
            "\t * otherwise an IRQ/NMI can publish a more recent head value and our",
            "\t * write will (temporarily) publish a stale value.",
            "\t */",
            "\tbarrier();",
            "\tWRITE_ONCE(rb->nest, 0);",
            "",
            "\t/*",
            "\t * Ensure we decrement @rb->nest before we validate the @rb->head.",
            "\t * Otherwise we cannot be sure we caught the 'last' nested update.",
            "\t */",
            "\tbarrier();",
            "\tif (unlikely(head != local_read(&rb->head))) {",
            "\t\tWRITE_ONCE(rb->nest, 1);",
            "\t\tgoto again;",
            "\t}",
            "",
            "\tif (handle->wakeup != local_read(&rb->wakeup))",
            "\t\tperf_output_wakeup(handle);",
            "",
            "out:",
            "\tpreempt_enable();",
            "}"
          ],
          "function_name": "perf_output_wakeup, perf_output_get_handle, perf_output_put_handle",
          "description": "实现环形缓冲区的唤醒机制和嵌套计数管理，通过原子操作和内存屏障保证多线程下的数据一致性，维护缓冲区状态转换过程中的竞态防护。",
          "similarity": 0.5340230464935303
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 137,
          "end_line": 266,
          "content": [
            "static __always_inline bool",
            "ring_buffer_has_space(unsigned long head, unsigned long tail,",
            "\t\t      unsigned long data_size, unsigned int size,",
            "\t\t      bool backward)",
            "{",
            "\tif (!backward)",
            "\t\treturn CIRC_SPACE(head, tail, data_size) >= size;",
            "\telse",
            "\t\treturn CIRC_SPACE(tail, head, data_size) >= size;",
            "}",
            "static __always_inline int",
            "__perf_output_begin(struct perf_output_handle *handle,",
            "\t\t    struct perf_sample_data *data,",
            "\t\t    struct perf_event *event, unsigned int size,",
            "\t\t    bool backward)",
            "{",
            "\tstruct perf_buffer *rb;",
            "\tunsigned long tail, offset, head;",
            "\tint have_lost, page_shift;",
            "\tstruct {",
            "\t\tstruct perf_event_header header;",
            "\t\tu64\t\t\t id;",
            "\t\tu64\t\t\t lost;",
            "\t} lost_event;",
            "",
            "\trcu_read_lock();",
            "\t/*",
            "\t * For inherited events we send all the output towards the parent.",
            "\t */",
            "\tif (event->parent)",
            "\t\tevent = event->parent;",
            "",
            "\trb = rcu_dereference(event->rb);",
            "\tif (unlikely(!rb))",
            "\t\tgoto out;",
            "",
            "\tif (unlikely(rb->paused)) {",
            "\t\tif (rb->nr_pages) {",
            "\t\t\tlocal_inc(&rb->lost);",
            "\t\t\tatomic64_inc(&event->lost_samples);",
            "\t\t}",
            "\t\tgoto out;",
            "\t}",
            "",
            "\thandle->rb    = rb;",
            "\thandle->event = event;",
            "\thandle->flags = 0;",
            "",
            "\thave_lost = local_read(&rb->lost);",
            "\tif (unlikely(have_lost)) {",
            "\t\tsize += sizeof(lost_event);",
            "\t\tif (event->attr.sample_id_all)",
            "\t\t\tsize += event->id_header_size;",
            "\t}",
            "",
            "\tperf_output_get_handle(handle);",
            "",
            "\toffset = local_read(&rb->head);",
            "\tdo {",
            "\t\thead = offset;",
            "\t\ttail = READ_ONCE(rb->user_page->data_tail);",
            "\t\tif (!rb->overwrite) {",
            "\t\t\tif (unlikely(!ring_buffer_has_space(head, tail,",
            "\t\t\t\t\t\t\t    perf_data_size(rb),",
            "\t\t\t\t\t\t\t    size, backward)))",
            "\t\t\t\tgoto fail;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * The above forms a control dependency barrier separating the",
            "\t\t * @tail load above from the data stores below. Since the @tail",
            "\t\t * load is required to compute the branch to fail below.",
            "\t\t *",
            "\t\t * A, matches D; the full memory barrier userspace SHOULD issue",
            "\t\t * after reading the data and before storing the new tail",
            "\t\t * position.",
            "\t\t *",
            "\t\t * See perf_output_put_handle().",
            "\t\t */",
            "",
            "\t\tif (!backward)",
            "\t\t\thead += size;",
            "\t\telse",
            "\t\t\thead -= size;",
            "\t} while (!local_try_cmpxchg(&rb->head, &offset, head));",
            "",
            "\tif (backward) {",
            "\t\toffset = head;",
            "\t\thead = (u64)(-head);",
            "\t}",
            "",
            "\t/*",
            "\t * We rely on the implied barrier() by local_cmpxchg() to ensure",
            "\t * none of the data stores below can be lifted up by the compiler.",
            "\t */",
            "",
            "\tif (unlikely(head - local_read(&rb->wakeup) > rb->watermark))",
            "\t\tlocal_add(rb->watermark, &rb->wakeup);",
            "",
            "\tpage_shift = PAGE_SHIFT + page_order(rb);",
            "",
            "\thandle->page = (offset >> page_shift) & (rb->nr_pages - 1);",
            "\toffset &= (1UL << page_shift) - 1;",
            "\thandle->addr = rb->data_pages[handle->page] + offset;",
            "\thandle->size = (1UL << page_shift) - offset;",
            "",
            "\tif (unlikely(have_lost)) {",
            "\t\tlost_event.header.size = sizeof(lost_event);",
            "\t\tlost_event.header.type = PERF_RECORD_LOST;",
            "\t\tlost_event.header.misc = 0;",
            "\t\tlost_event.id          = event->id;",
            "\t\tlost_event.lost        = local_xchg(&rb->lost, 0);",
            "",
            "\t\t/* XXX mostly redundant; @data is already fully initializes */",
            "\t\tperf_event_header__init_id(&lost_event.header, data, event);",
            "\t\tperf_output_put(handle, lost_event);",
            "\t\tperf_event__output_id_sample(event, handle, data);",
            "\t}",
            "",
            "\treturn 0;",
            "",
            "fail:",
            "\tlocal_inc(&rb->lost);",
            "\tatomic64_inc(&event->lost_samples);",
            "\tperf_output_put_handle(handle);",
            "out:",
            "\trcu_read_unlock();",
            "",
            "\treturn -ENOSPC;",
            "}"
          ],
          "function_name": "ring_buffer_has_space, __perf_output_begin",
          "description": "提供空间检测算法和数据写入入口点，通过循环缓冲区计算公式判断可用容量，在成功获取写入位置后进行实际数据填充并更新缓冲区状态。",
          "similarity": 0.5250565409660339
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 542,
          "end_line": 727,
          "content": [
            "int perf_aux_output_skip(struct perf_output_handle *handle, unsigned long size)",
            "{",
            "\tstruct perf_buffer *rb = handle->rb;",
            "",
            "\tif (size > handle->size)",
            "\t\treturn -ENOSPC;",
            "",
            "\trb->aux_head += size;",
            "",
            "\tWRITE_ONCE(rb->user_page->aux_head, rb->aux_head);",
            "\tif (rb_need_aux_wakeup(rb)) {",
            "\t\tperf_output_wakeup(handle);",
            "\t\thandle->wakeup = rb->aux_wakeup + rb->aux_watermark;",
            "\t}",
            "",
            "\thandle->head = rb->aux_head;",
            "\thandle->size -= size;",
            "",
            "\treturn 0;",
            "}",
            "long perf_output_copy_aux(struct perf_output_handle *aux_handle,",
            "\t\t\t  struct perf_output_handle *handle,",
            "\t\t\t  unsigned long from, unsigned long to)",
            "{",
            "\tstruct perf_buffer *rb = aux_handle->rb;",
            "\tunsigned long tocopy, remainder, len = 0;",
            "\tvoid *addr;",
            "",
            "\tfrom &= (rb->aux_nr_pages << PAGE_SHIFT) - 1;",
            "\tto &= (rb->aux_nr_pages << PAGE_SHIFT) - 1;",
            "",
            "\tdo {",
            "\t\ttocopy = PAGE_SIZE - offset_in_page(from);",
            "\t\tif (to > from)",
            "\t\t\ttocopy = min(tocopy, to - from);",
            "\t\tif (!tocopy)",
            "\t\t\tbreak;",
            "",
            "\t\taddr = rb->aux_pages[from >> PAGE_SHIFT];",
            "\t\taddr += offset_in_page(from);",
            "",
            "\t\tremainder = perf_output_copy(handle, addr, tocopy);",
            "\t\tif (remainder)",
            "\t\t\treturn -EFAULT;",
            "",
            "\t\tlen += tocopy;",
            "\t\tfrom += tocopy;",
            "\t\tfrom &= (rb->aux_nr_pages << PAGE_SHIFT) - 1;",
            "\t} while (to != from);",
            "",
            "\treturn len;",
            "}",
            "static void rb_free_aux_page(struct perf_buffer *rb, int idx)",
            "{",
            "\tstruct page *page = virt_to_page(rb->aux_pages[idx]);",
            "",
            "\tClearPagePrivate(page);",
            "\tpage->mapping = NULL;",
            "\t__free_page(page);",
            "}",
            "static void __rb_free_aux(struct perf_buffer *rb)",
            "{",
            "\tint pg;",
            "",
            "\t/*",
            "\t * Should never happen, the last reference should be dropped from",
            "\t * perf_mmap_close() path, which first stops aux transactions (which",
            "\t * in turn are the atomic holders of aux_refcount) and then does the",
            "\t * last rb_free_aux().",
            "\t */",
            "\tWARN_ON_ONCE(in_atomic());",
            "",
            "\tif (rb->aux_priv) {",
            "\t\trb->free_aux(rb->aux_priv);",
            "\t\trb->free_aux = NULL;",
            "\t\trb->aux_priv = NULL;",
            "\t}",
            "",
            "\tif (rb->aux_nr_pages) {",
            "\t\tfor (pg = 0; pg < rb->aux_nr_pages; pg++)",
            "\t\t\trb_free_aux_page(rb, pg);",
            "",
            "\t\tkfree(rb->aux_pages);",
            "\t\trb->aux_nr_pages = 0;",
            "\t}",
            "}",
            "int rb_alloc_aux(struct perf_buffer *rb, struct perf_event *event,",
            "\t\t pgoff_t pgoff, int nr_pages, long watermark, int flags)",
            "{",
            "\tbool overwrite = !(flags & RING_BUFFER_WRITABLE);",
            "\tint node = (event->cpu == -1) ? -1 : cpu_to_node(event->cpu);",
            "\tint ret = -ENOMEM, max_order;",
            "",
            "\tif (!has_aux(event))",
            "\t\treturn -EOPNOTSUPP;",
            "",
            "\tif (!overwrite) {",
            "\t\t/*",
            "\t\t * Watermark defaults to half the buffer, and so does the",
            "\t\t * max_order, to aid PMU drivers in double buffering.",
            "\t\t */",
            "\t\tif (!watermark)",
            "\t\t\twatermark = min_t(unsigned long,",
            "\t\t\t\t\t  U32_MAX,",
            "\t\t\t\t\t  (unsigned long)nr_pages << (PAGE_SHIFT - 1));",
            "",
            "\t\t/*",
            "\t\t * Use aux_watermark as the basis for chunking to",
            "\t\t * help PMU drivers honor the watermark.",
            "\t\t */",
            "\t\tmax_order = get_order(watermark);",
            "\t} else {",
            "\t\t/*",
            "\t\t * We need to start with the max_order that fits in nr_pages,",
            "\t\t * not the other way around, hence ilog2() and not get_order.",
            "\t\t */",
            "\t\tmax_order = ilog2(nr_pages);",
            "\t\twatermark = 0;",
            "\t}",
            "",
            "\t/*",
            "\t * kcalloc_node() is unable to allocate buffer if the size is larger",
            "\t * than: PAGE_SIZE << MAX_PAGE_ORDER; directly bail out in this case.",
            "\t */",
            "\tif (get_order((unsigned long)nr_pages * sizeof(void *)) > MAX_PAGE_ORDER)",
            "\t\treturn -ENOMEM;",
            "\trb->aux_pages = kcalloc_node(nr_pages, sizeof(void *), GFP_KERNEL,",
            "\t\t\t\t     node);",
            "\tif (!rb->aux_pages)",
            "\t\treturn -ENOMEM;",
            "",
            "\trb->free_aux = event->pmu->free_aux;",
            "\tfor (rb->aux_nr_pages = 0; rb->aux_nr_pages < nr_pages;) {",
            "\t\tstruct page *page;",
            "\t\tint last, order;",
            "",
            "\t\torder = min(max_order, ilog2(nr_pages - rb->aux_nr_pages));",
            "\t\tpage = rb_alloc_aux_page(node, order);",
            "\t\tif (!page)",
            "\t\t\tgoto out;",
            "",
            "\t\tfor (last = rb->aux_nr_pages + (1 << page_private(page));",
            "\t\t     last > rb->aux_nr_pages; rb->aux_nr_pages++)",
            "\t\t\trb->aux_pages[rb->aux_nr_pages] = page_address(page++);",
            "\t}",
            "",
            "\t/*",
            "\t * In overwrite mode, PMUs that don't support SG may not handle more",
            "\t * than one contiguous allocation, since they rely on PMI to do double",
            "\t * buffering. In this case, the entire buffer has to be one contiguous",
            "\t * chunk.",
            "\t */",
            "\tif ((event->pmu->capabilities & PERF_PMU_CAP_AUX_NO_SG) &&",
            "\t    overwrite) {",
            "\t\tstruct page *page = virt_to_page(rb->aux_pages[0]);",
            "",
            "\t\tif (page_private(page) != max_order)",
            "\t\t\tgoto out;",
            "\t}",
            "",
            "\trb->aux_priv = event->pmu->setup_aux(event, rb->aux_pages, nr_pages,",
            "\t\t\t\t\t     overwrite);",
            "\tif (!rb->aux_priv)",
            "\t\tgoto out;",
            "",
            "\tret = 0;",
            "",
            "\t/*",
            "\t * aux_pages (and pmu driver's private data, aux_priv) will be",
            "\t * referenced in both producer's and consumer's contexts, thus",
            "\t * we keep a refcount here to make sure either of the two can",
            "\t * reference them safely.",
            "\t */",
            "\trefcount_set(&rb->aux_refcount, 1);",
            "",
            "\trb->aux_overwrite = overwrite;",
            "\trb->aux_watermark = watermark;",
            "",
            "out:",
            "\tif (!ret)",
            "\t\trb->aux_pgoff = pgoff;",
            "\telse",
            "\t\t__rb_free_aux(rb);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "perf_aux_output_skip, perf_output_copy_aux, rb_free_aux_page, __rb_free_aux, rb_alloc_aux",
          "description": "实现辅助数据通道的管理函数，包含数据跳过、页框回收及辅助内存分配逻辑，处理非覆盖模式下的数据迁移和资源释放操作。",
          "similarity": 0.5157257318496704
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 775,
          "end_line": 822,
          "content": [
            "void rb_free_aux(struct perf_buffer *rb)",
            "{",
            "\tif (refcount_dec_and_test(&rb->aux_refcount))",
            "\t\t__rb_free_aux(rb);",
            "}",
            "static void perf_mmap_free_page(void *addr)",
            "{",
            "\tstruct page *page = virt_to_page(addr);",
            "",
            "\tpage->mapping = NULL;",
            "\t__free_page(page);",
            "}",
            "void rb_free(struct perf_buffer *rb)",
            "{",
            "\tint i;",
            "",
            "\tperf_mmap_free_page(rb->user_page);",
            "\tfor (i = 0; i < rb->nr_pages; i++)",
            "\t\tperf_mmap_free_page(rb->data_pages[i]);",
            "\tkfree(rb);",
            "}",
            "static void perf_mmap_unmark_page(void *addr)",
            "{",
            "\tstruct page *page = vmalloc_to_page(addr);",
            "",
            "\tpage->mapping = NULL;",
            "}",
            "static void rb_free_work(struct work_struct *work)",
            "{",
            "\tstruct perf_buffer *rb;",
            "\tvoid *base;",
            "\tint i, nr;",
            "",
            "\trb = container_of(work, struct perf_buffer, work);",
            "\tnr = data_page_nr(rb);",
            "",
            "\tbase = rb->user_page;",
            "\t/* The '<=' counts in the user page. */",
            "\tfor (i = 0; i <= nr; i++)",
            "\t\tperf_mmap_unmark_page(base + (i * PAGE_SIZE));",
            "",
            "\tvfree(base);",
            "\tkfree(rb);",
            "}",
            "void rb_free(struct perf_buffer *rb)",
            "{",
            "\tschedule_work(&rb->work);",
            "}"
          ],
          "function_name": "rb_free_aux, perf_mmap_free_page, rb_free, perf_mmap_unmark_page, rb_free_work, rb_free",
          "description": "该代码段主要实现 ring buffer 的内存释放逻辑，包含同步与异步两种释放路径。  \n`rb_free` 函数通过 `perf_mmap_free_page` 释放用户页及数据页，而 `rb_free_work` 工作队列则通过 `perf_mmap_unmark_page` 异步解绑并释放页面，二者均用于清理 mmap 分配的虚拟内存区域。  \n由于缺少 `__rb_free_aux` 等关键函数定义且存在同名函数覆盖可能性，上下文信息不完整。",
          "similarity": 0.4972945749759674
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/events/ring_buffer.c",
          "start_line": 269,
          "end_line": 408,
          "content": [
            "int perf_output_begin_forward(struct perf_output_handle *handle,",
            "\t\t\t      struct perf_sample_data *data,",
            "\t\t\t      struct perf_event *event, unsigned int size)",
            "{",
            "\treturn __perf_output_begin(handle, data, event, size, false);",
            "}",
            "int perf_output_begin_backward(struct perf_output_handle *handle,",
            "\t\t\t       struct perf_sample_data *data,",
            "\t\t\t       struct perf_event *event, unsigned int size)",
            "{",
            "\treturn __perf_output_begin(handle, data, event, size, true);",
            "}",
            "int perf_output_begin(struct perf_output_handle *handle,",
            "\t\t      struct perf_sample_data *data,",
            "\t\t      struct perf_event *event, unsigned int size)",
            "{",
            "",
            "\treturn __perf_output_begin(handle, data, event, size,",
            "\t\t\t\t   unlikely(is_write_backward(event)));",
            "}",
            "unsigned int perf_output_copy(struct perf_output_handle *handle,",
            "\t\t      const void *buf, unsigned int len)",
            "{",
            "\treturn __output_copy(handle, buf, len);",
            "}",
            "unsigned int perf_output_skip(struct perf_output_handle *handle,",
            "\t\t\t      unsigned int len)",
            "{",
            "\treturn __output_skip(handle, NULL, len);",
            "}",
            "void perf_output_end(struct perf_output_handle *handle)",
            "{",
            "\tperf_output_put_handle(handle);",
            "\trcu_read_unlock();",
            "}",
            "static void",
            "ring_buffer_init(struct perf_buffer *rb, long watermark, int flags)",
            "{",
            "\tlong max_size = perf_data_size(rb);",
            "",
            "\tif (watermark)",
            "\t\trb->watermark = min(max_size, watermark);",
            "",
            "\tif (!rb->watermark)",
            "\t\trb->watermark = max_size / 2;",
            "",
            "\tif (flags & RING_BUFFER_WRITABLE)",
            "\t\trb->overwrite = 0;",
            "\telse",
            "\t\trb->overwrite = 1;",
            "",
            "\trefcount_set(&rb->refcount, 1);",
            "",
            "\tINIT_LIST_HEAD(&rb->event_list);",
            "\tspin_lock_init(&rb->event_lock);",
            "",
            "\t/*",
            "\t * perf_output_begin() only checks rb->paused, therefore",
            "\t * rb->paused must be true if we have no pages for output.",
            "\t */",
            "\tif (!rb->nr_pages)",
            "\t\trb->paused = 1;",
            "",
            "\tmutex_init(&rb->aux_mutex);",
            "}",
            "void perf_aux_output_flag(struct perf_output_handle *handle, u64 flags)",
            "{",
            "\t/*",
            "\t * OVERWRITE is determined by perf_aux_output_end() and can't",
            "\t * be passed in directly.",
            "\t */",
            "\tif (WARN_ON_ONCE(flags & PERF_AUX_FLAG_OVERWRITE))",
            "\t\treturn;",
            "",
            "\thandle->aux_flags |= flags;",
            "}",
            "static __always_inline bool rb_need_aux_wakeup(struct perf_buffer *rb)",
            "{",
            "\tif (rb->aux_overwrite)",
            "\t\treturn false;",
            "",
            "\tif (rb->aux_head - rb->aux_wakeup >= rb->aux_watermark) {",
            "\t\trb->aux_wakeup = rounddown(rb->aux_head, rb->aux_watermark);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "void perf_aux_output_end(struct perf_output_handle *handle, unsigned long size)",
            "{",
            "\tbool wakeup = !!(handle->aux_flags & PERF_AUX_FLAG_TRUNCATED);",
            "\tstruct perf_buffer *rb = handle->rb;",
            "\tunsigned long aux_head;",
            "",
            "\t/* in overwrite mode, driver provides aux_head via handle */",
            "\tif (rb->aux_overwrite) {",
            "\t\thandle->aux_flags |= PERF_AUX_FLAG_OVERWRITE;",
            "",
            "\t\taux_head = handle->head;",
            "\t\trb->aux_head = aux_head;",
            "\t} else {",
            "\t\thandle->aux_flags &= ~PERF_AUX_FLAG_OVERWRITE;",
            "",
            "\t\taux_head = rb->aux_head;",
            "\t\trb->aux_head += size;",
            "\t}",
            "",
            "\t/*",
            "\t * Only send RECORD_AUX if we have something useful to communicate",
            "\t *",
            "\t * Note: the OVERWRITE records by themselves are not considered",
            "\t * useful, as they don't communicate any *new* information,",
            "\t * aside from the short-lived offset, that becomes history at",
            "\t * the next event sched-in and therefore isn't useful.",
            "\t * The userspace that needs to copy out AUX data in overwrite",
            "\t * mode should know to use user_page::aux_head for the actual",
            "\t * offset. So, from now on we don't output AUX records that",
            "\t * have *only* OVERWRITE flag set.",
            "\t */",
            "\tif (size || (handle->aux_flags & ~(u64)PERF_AUX_FLAG_OVERWRITE))",
            "\t\tperf_event_aux_event(handle->event, aux_head, size,",
            "\t\t\t\t     handle->aux_flags);",
            "",
            "\tWRITE_ONCE(rb->user_page->aux_head, rb->aux_head);",
            "\tif (rb_need_aux_wakeup(rb))",
            "\t\twakeup = true;",
            "",
            "\tif (wakeup) {",
            "\t\tif (handle->aux_flags & PERF_AUX_FLAG_TRUNCATED)",
            "\t\t\tperf_event_disable_inatomic(handle->event);",
            "\t\tperf_output_wakeup(handle);",
            "\t}",
            "",
            "\thandle->event = NULL;",
            "",
            "\tWRITE_ONCE(rb->aux_nest, 0);",
            "\t/* can't be last */",
            "\trb_free_aux(rb);",
            "\tring_buffer_put(rb);",
            "}"
          ],
          "function_name": "perf_output_begin_forward, perf_output_begin_backward, perf_output_begin, perf_output_copy, perf_output_skip, perf_output_end, ring_buffer_init, perf_aux_output_flag, rb_need_aux_wakeup, perf_aux_output_end",
          "description": "封装数据写入接口并实现缓冲区初始化逻辑，管理覆盖模式切换、水位线监控及辅助输出标志位，支持双向写入模式选择和资源引用计数控制。",
          "similarity": 0.49234843254089355
        }
      ]
    },
    {
      "source_file": "kernel/events/internal.h",
      "md_summary": "> 自动生成时间: 2025-10-25 13:24:29\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `events\\internal.h`\n\n---\n\n# `events/internal.h` 技术文档\n\n## 1. 文件概述\n\n`events/internal.h` 是 Linux 内核性能事件子系统（perf events）的内部头文件，定义了用于管理 perf 环形缓冲区（ring buffer）和辅助缓冲区（AUX buffer）的核心数据结构、辅助函数和内存操作接口。该文件为 perf 事件的采样数据记录、用户空间 mmap 映射、缓冲区分配与释放、跨页数据拷贝等关键功能提供底层支持，仅供内核 perf 子系统内部使用，不对外暴露给其他模块。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct perf_buffer`**  \n  表示 perf 事件的主数据环形缓冲区，包含：\n  - 引用计数（`refcount`）和 RCU 回收机制（`rcu_head`）\n  - 缓冲区页面管理（`nr_pages`, `page_order`, `data_pages[]`）\n  - 写入控制（`head`, `paused`, `overwrite`, `nest`）\n  - 唤醒机制（`poll`, `watermark`, `wakeup`）\n  - 事件丢失统计（`lost`）\n  - 用户空间 mmap 相关字段（`mmap_count`, `mmap_user`, `user_page`）\n  - AUX 辅助缓冲区支持（`aux_*` 字段，用于如 Intel PT 等硬件追踪）\n\n### 主要函数/宏\n\n- **缓冲区生命周期管理**\n  - `rb_alloc()` / `rb_free()`：分配/释放主环形缓冲区\n  - `rb_alloc_aux()` / `rb_free_aux()`：分配/释放 AUX 辅助缓冲区\n  - `ring_buffer_get()` / `ring_buffer_put()`：引用计数管理\n\n- **缓冲区操作**\n  - `rb_toggle_paused()`：暂停/恢复写入\n  - `rb_has_aux()`：判断是否启用 AUX 缓冲区\n  - `perf_event_wakeup()`：唤醒等待 perf 事件的用户进程\n  - `perf_event_aux_event()`：记录 AUX 相关事件\n\n- **内存拷贝与输出**\n  - `__output_copy()` / `__output_copy_user()` / `__output_skip()`：跨页安全的数据拷贝接口\n  - `__DEFINE_OUTPUT_COPY_BODY`：通用跨页拷贝宏模板\n  - `perf_mmap_to_page()`：将 mmap 偏移转换为物理页\n\n- **辅助功能**\n  - `get_recursion_context()` / `put_recursion_context()`：中断上下文递归保护\n  - `arch_perf_have_user_stack_dump()` / `perf_user_stack_pointer()`：用户栈转储支持\n\n## 3. 关键实现\n\n### 环形缓冲区跨页写入机制\n通过 `__DEFINE_OUTPUT_COPY_BODY` 宏实现通用的跨页写入逻辑：\n- 自动处理缓冲区写入指针（`handle->addr`）跨越页面边界的情况\n- 支持多种拷贝后端（内核内存拷贝、用户空间拷贝、跳过模式）\n- 利用 `handle->page` 和 `handle->size` 跟踪当前页面和剩余空间\n- 页面大小支持通过 `page_order` 扩展（`CONFIG_PERF_USE_VMALLOC`）\n\n### 用户空间安全拷贝\n- `arch_perf_out_copy_user` 默认使用 `__copy_from_user_inatomic()`，并在拷贝期间禁用页错误（`pagefault_disable()`），确保在原子上下文中安全访问用户内存\n\n### 递归写入保护\n- 使用 `recursion` 数组按中断上下文级别（`interrupt_context_level()`）跟踪写入状态，防止同一上下文多次进入 perf 写入路径导致死锁或数据损坏\n\n### AUX 缓冲区支持\n- 独立于主数据缓冲区，通过 `aux_pages` 和 `aux_priv` 管理硬件追踪数据（如 Intel Processor Trace）\n- 提供独立的 watermark、overwrite 和 mmap 控制\n\n### 内存分配策略\n- 默认使用连续物理页（`kmalloc` + `alloc_pages`）\n- 在存在 d-cache 别名问题的架构上（如某些 ARM），启用 `CONFIG_PERF_USE_VMALLOC` 使用 vmalloc 分配虚拟连续内存\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/hardirq.h>`：提供中断上下文判断（`interrupt_context_level()`）\n  - `<linux/uaccess.h>`：提供用户空间内存访问函数（`__copy_from_user_inatomic`）\n  - `<linux/refcount.h>`：提供引用计数操作\n\n- **内核配置依赖**：\n  - `CONFIG_PERF_EVENTS`：perf 事件子系统基础\n  - `CONFIG_PERF_USE_VMALLOC`：控制缓冲区内存分配策略\n  - `CONFIG_HAVE_PERF_USER_STACK_DUMP`：控制用户栈转储功能\n\n- **关联模块**：\n  - `kernel/events/core.c`：perf 事件核心实现，使用本文件定义的缓冲区接口\n  - `kernel/events/ring_buffer.c`：环形缓冲区具体实现（`rb_alloc`, `rb_free` 等）\n  - 架构特定代码（如 x86, ARM）：可能重写 `arch_perf_out_copy_user` 或提供 `user_stack_pointer`\n\n## 5. 使用场景\n\n- **性能采样数据记录**：当 perf 事件触发采样（如周期性时钟中断、硬件性能计数器溢出）时，内核通过 `__output_copy` 系列函数将采样数据（如 IP、栈帧、上下文信息）写入环形缓冲区\n- **用户空间 mmap 映射**：用户程序通过 `mmap()` 映射 perf 事件文件描述符，直接读取 `perf_buffer` 中的 `data_pages` 和 `user_page`（包含 head/tail 指针）\n- **硬件追踪数据收集**：在启用 Intel PT 等特性时，CPU 生成的追踪数据通过 AUX 缓冲区机制写入 `aux_pages`，由用户空间工具（如 `perf`）解析\n- **低延迟事件通知**：当缓冲区数据量达到 `watermark` 时，通过 `perf_event_wakeup` 唤醒阻塞在 `poll()`/`select()` 上的用户进程\n- **中断/软中断上下文安全写入**：通过递归保护机制，确保在 NMI、IRQ 等高优先级上下文中也能安全记录 perf 事件",
      "similarity": 0.6076004505157471,
      "chunks": []
    },
    {
      "source_file": "kernel/events/callchain.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:21:29\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `events\\callchain.c`\n\n---\n\n# `events/callchain.c` 技术文档\n\n## 1. 文件概述\n\n`events/callchain.c` 是 Linux 内核性能事件（perf events）子系统中用于管理调用链（callchain）的核心实现文件。该文件负责为性能采样事件分配、管理和回收调用栈缓冲区，并提供统一接口用于在内核态和用户态采集函数调用链信息。调用链用于记录函数调用的层次结构，是性能分析（如火焰图）的关键数据来源。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct callchain_cpus_entries`**  \n  每 CPU 调用链条目数组的容器结构，通过 RCU 机制安全地管理生命周期。\n\n- **`struct perf_callchain_entry_ctx`**  \n  调用链构建上下文，包含当前条目指针、最大栈深度、已记录项数等状态信息（定义在 `internal.h` 中）。\n\n- **`struct perf_callchain_entry`**  \n  实际存储调用地址的结构（定义在 `<linux/perf_event.h>`），包含 `nr`（有效项数）和 `ip[]`（指令指针数组）。\n\n### 主要全局变量\n\n- `sysctl_perf_event_max_stack`：系统级调用栈最大深度（默认 `PERF_MAX_STACK_DEPTH`）。\n- `sysctl_perf_event_max_contexts_per_stack`：每个栈中允许的最大上下文标记数（如 `PERF_CONTEXT_KERNEL`/`USER`）。\n- `callchain_cpus_entries`：指向每 CPU 调用链缓冲区的全局指针，通过 RCU 保护。\n- `callchain_recursion`：每 CPU 递归上下文标记数组，防止在 NMI 或中断上下文中重复进入调用链采集。\n- `nr_callchain_events`：引用计数，跟踪当前活跃的需要调用链的 perf 事件数量。\n- `callchain_mutex`：保护缓冲区分配/释放和 sysctl 修改的互斥锁。\n\n### 主要函数\n\n- **`get_callchain_buffers()` / `put_callchain_buffers()`**  \n  引用计数式地分配和释放全局调用链缓冲区。\n\n- **`get_callchain_entry()` / `put_callchain_entry()`**  \n  获取/释放当前 CPU 上可用的调用链条目，支持多上下文（如中断、NMI）隔离。\n\n- **`get_perf_callchain()`**  \n  高层接口，根据寄存器状态采集内核态和/或用户态的完整调用链。\n\n- **`perf_callchain_kernel()` / `perf_callchain_user()`**  \n  弱符号函数，由各架构实现具体的栈回溯逻辑（如 x86 使用 `dump_trace()`）。\n\n- **`perf_event_max_stack_handler()`**  \n  sysctl 处理函数，允许动态调整最大栈深度（仅在无活跃事件时生效）。\n\n## 3. 关键实现\n\n### 调用链缓冲区管理\n\n- 使用 **每 CPU 独立缓冲区** 避免锁竞争，每个 CPU 分配 `PERF_NR_CONTEXTS` 个 `perf_callchain_entry`（支持中断、NMI 等多上下文）。\n- 缓冲区大小由 `perf_callchain_entry__sizeof()` 动态计算，结合 `sysctl_perf_event_max_stack` 和上下文标记数量。\n- 通过 **RCU 机制** 安全释放旧缓冲区，确保在可能的 NMI 上下文中仍可安全访问。\n\n### 递归上下文保护\n\n- `callchain_recursion` 数组标记当前 CPU 的调用链采集上下文（0=普通，1=NMI 等）。\n- `get_recursion_context()`/`put_recursion_context()` 确保同一上下文不会嵌套调用链采集，防止缓冲区覆盖。\n\n### 架构无关接口\n\n- `perf_callchain_kernel()` 和 `perf_callchain_user()` 为 **弱符号**，允许各架构（如 x86、ARM）提供具体实现。\n- 内核态回溯通常基于 `regs` 寄存器状态和内核栈；用户态回溯需切换到用户栈并解析 DWARF 或 frame pointer。\n\n### 安全限制\n\n- `get_callchain_buffers()` 检查请求的 `event_max_stack` 不超过全局上限，超限返回 `-EOVERFLOW`。\n- sysctl 修改需在无活跃事件时进行（`nr_callchain_events == 0`），否则返回 `-EBUSY`。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/perf_event.h>`：perf 事件核心定义。\n  - `<linux/slab.h>`：内存分配（`kmalloc`/`kfree`）。\n  - `<linux/sched/task_stack.h>`：任务栈相关辅助函数。\n  - `\"internal.h\"`：perf 子系统内部头文件，包含 `perf_callchain_entry_ctx` 等。\n\n- **架构依赖**：\n  - 各架构需实现 `perf_callchain_kernel()` 和 `perf_callchain_user()`（如 `arch/x86/events/core.c`）。\n\n- **子系统依赖**：\n  - RCU 机制（`call_rcu`, `rcu_dereference`）。\n  - Per-CPU 变量（`DEFINE_PER_CPU`, `this_cpu_ptr`）。\n  - 内存节点分配（`kmalloc_node`）。\n\n## 5. 使用场景\n\n- **性能分析工具**：`perf record -g` 采集调用链时，内核通过此模块记录函数调用栈。\n- **动态跟踪**：eBPF 程序或 ftrace 在需要栈回溯时调用 `get_perf_callchain()`。\n- **系统监控**：当 perf 事件配置为 `PERF_SAMPLE_CALLCHAIN` 时，采样中断处理中调用此模块。\n- **安全审计**：某些 LSM 模块可能利用调用链信息进行行为分析。\n- **调试场景**：内核 oops 或 lockdep 在需要栈信息时可能间接使用此机制。",
      "similarity": 0.6011021733283997,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/events/callchain.c",
          "start_line": 145,
          "end_line": 215,
          "content": [
            "void put_callchain_buffers(void)",
            "{",
            "\tif (atomic_dec_and_mutex_lock(&nr_callchain_events, &callchain_mutex)) {",
            "\t\trelease_callchain_buffers();",
            "\t\tmutex_unlock(&callchain_mutex);",
            "\t}",
            "}",
            "void",
            "put_callchain_entry(int rctx)",
            "{",
            "\tput_recursion_context(this_cpu_ptr(callchain_recursion), rctx);",
            "}",
            "static void fixup_uretprobe_trampoline_entries(struct perf_callchain_entry *entry,",
            "\t\t\t\t\t       int start_entry_idx)",
            "{",
            "#ifdef CONFIG_UPROBES",
            "\tstruct uprobe_task *utask = current->utask;",
            "\tstruct return_instance *ri;",
            "\t__u64 *cur_ip, *last_ip, tramp_addr;",
            "",
            "\tif (likely(!utask || !utask->return_instances))",
            "\t\treturn;",
            "",
            "\tcur_ip = &entry->ip[start_entry_idx];",
            "\tlast_ip = &entry->ip[entry->nr - 1];",
            "\tri = utask->return_instances;",
            "\ttramp_addr = uprobe_get_trampoline_vaddr();",
            "",
            "\t/*",
            "\t * If there are pending uretprobes for the current thread, they are",
            "\t * recorded in a list inside utask->return_instances; each such",
            "\t * pending uretprobe replaces traced user function's return address on",
            "\t * the stack, so when stack trace is captured, instead of seeing",
            "\t * actual function's return address, we'll have one or many uretprobe",
            "\t * trampoline addresses in the stack trace, which are not helpful and",
            "\t * misleading to users.",
            "\t * So here we go over the pending list of uretprobes, and each",
            "\t * encountered trampoline address is replaced with actual return",
            "\t * address.",
            "\t */",
            "\twhile (ri && cur_ip <= last_ip) {",
            "\t\tif (*cur_ip == tramp_addr) {",
            "\t\t\t*cur_ip = ri->orig_ret_vaddr;",
            "\t\t\tri = ri->next;",
            "\t\t}",
            "\t\tcur_ip++;",
            "\t}",
            "#endif",
            "}",
            "int perf_event_max_stack_handler(struct ctl_table *table, int write,",
            "\t\t\t\t void *buffer, size_t *lenp, loff_t *ppos)",
            "{",
            "\tint *value = table->data;",
            "\tint new_value = *value, ret;",
            "\tstruct ctl_table new_table = *table;",
            "",
            "\tnew_table.data = &new_value;",
            "\tret = proc_dointvec_minmax(&new_table, write, buffer, lenp, ppos);",
            "\tif (ret || !write)",
            "\t\treturn ret;",
            "",
            "\tmutex_lock(&callchain_mutex);",
            "\tif (atomic_read(&nr_callchain_events))",
            "\t\tret = -EBUSY;",
            "\telse",
            "\t\t*value = new_value;",
            "",
            "\tmutex_unlock(&callchain_mutex);",
            "",
            "\treturn ret;",
            "}"
          ],
          "function_name": "put_callchain_buffers, put_callchain_entry, fixup_uretprobe_trampoline_entries, perf_event_max_stack_handler",
          "description": "提供调用链缓冲区的引用计数管理、URETPROBE陷阱地址修复逻辑，以及性能事件最大栈深度的动态配置处理函数，确保栈追踪数据的准确性与系统调参的原子性操作。",
          "similarity": 0.547884464263916
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/events/callchain.c",
          "start_line": 26,
          "end_line": 131,
          "content": [
            "static inline size_t perf_callchain_entry__sizeof(void)",
            "{",
            "\treturn (sizeof(struct perf_callchain_entry) +",
            "\t\tsizeof(__u64) * (sysctl_perf_event_max_stack +",
            "\t\t\t\t sysctl_perf_event_max_contexts_per_stack));",
            "}",
            "__weak void perf_callchain_kernel(struct perf_callchain_entry_ctx *entry,",
            "\t\t\t\t  struct pt_regs *regs)",
            "{",
            "}",
            "__weak void perf_callchain_user(struct perf_callchain_entry_ctx *entry,",
            "\t\t\t\tstruct pt_regs *regs)",
            "{",
            "}",
            "static void release_callchain_buffers_rcu(struct rcu_head *head)",
            "{",
            "\tstruct callchain_cpus_entries *entries;",
            "\tint cpu;",
            "",
            "\tentries = container_of(head, struct callchain_cpus_entries, rcu_head);",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tkfree(entries->cpu_entries[cpu]);",
            "",
            "\tkfree(entries);",
            "}",
            "static void release_callchain_buffers(void)",
            "{",
            "\tstruct callchain_cpus_entries *entries;",
            "",
            "\tentries = callchain_cpus_entries;",
            "\tRCU_INIT_POINTER(callchain_cpus_entries, NULL);",
            "\tcall_rcu(&entries->rcu_head, release_callchain_buffers_rcu);",
            "}",
            "static int alloc_callchain_buffers(void)",
            "{",
            "\tint cpu;",
            "\tint size;",
            "\tstruct callchain_cpus_entries *entries;",
            "",
            "\t/*",
            "\t * We can't use the percpu allocation API for data that can be",
            "\t * accessed from NMI. Use a temporary manual per cpu allocation",
            "\t * until that gets sorted out.",
            "\t */",
            "\tsize = offsetof(struct callchain_cpus_entries, cpu_entries[nr_cpu_ids]);",
            "",
            "\tentries = kzalloc(size, GFP_KERNEL);",
            "\tif (!entries)",
            "\t\treturn -ENOMEM;",
            "",
            "\tsize = perf_callchain_entry__sizeof() * PERF_NR_CONTEXTS;",
            "",
            "\tfor_each_possible_cpu(cpu) {",
            "\t\tentries->cpu_entries[cpu] = kmalloc_node(size, GFP_KERNEL,",
            "\t\t\t\t\t\t\t cpu_to_node(cpu));",
            "\t\tif (!entries->cpu_entries[cpu])",
            "\t\t\tgoto fail;",
            "\t}",
            "",
            "\trcu_assign_pointer(callchain_cpus_entries, entries);",
            "",
            "\treturn 0;",
            "",
            "fail:",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tkfree(entries->cpu_entries[cpu]);",
            "\tkfree(entries);",
            "",
            "\treturn -ENOMEM;",
            "}",
            "int get_callchain_buffers(int event_max_stack)",
            "{",
            "\tint err = 0;",
            "\tint count;",
            "",
            "\tmutex_lock(&callchain_mutex);",
            "",
            "\tcount = atomic_inc_return(&nr_callchain_events);",
            "\tif (WARN_ON_ONCE(count < 1)) {",
            "\t\terr = -EINVAL;",
            "\t\tgoto exit;",
            "\t}",
            "",
            "\t/*",
            "\t * If requesting per event more than the global cap,",
            "\t * return a different error to help userspace figure",
            "\t * this out.",
            "\t *",
            "\t * And also do it here so that we have &callchain_mutex held.",
            "\t */",
            "\tif (event_max_stack > sysctl_perf_event_max_stack) {",
            "\t\terr = -EOVERFLOW;",
            "\t\tgoto exit;",
            "\t}",
            "",
            "\tif (count == 1)",
            "\t\terr = alloc_callchain_buffers();",
            "exit:",
            "\tif (err)",
            "\t\tatomic_dec(&nr_callchain_events);",
            "",
            "\tmutex_unlock(&callchain_mutex);",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "perf_callchain_entry__sizeof, perf_callchain_kernel, perf_callchain_user, release_callchain_buffers_rcu, release_callchain_buffers, alloc_callchain_buffers, get_callchain_buffers",
          "description": "实现调用链缓冲区的动态分配与释放逻辑，包含缓冲区大小计算、跨CPU内存分配、RCU安全释放机制及根据当前事件栈需求进行缓冲区初始化和清理的操作。",
          "similarity": 0.5123203992843628
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/events/callchain.c",
          "start_line": 1,
          "end_line": 25,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Performance events callchain code, extracted from core.c:",
            " *",
            " *  Copyright (C) 2008 Thomas Gleixner <tglx@linutronix.de>",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Ingo Molnar",
            " *  Copyright (C) 2008-2011 Red Hat, Inc., Peter Zijlstra",
            " *  Copyright  ©  2009 Paul Mackerras, IBM Corp. <paulus@au1.ibm.com>",
            " */",
            "",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/uprobes.h>",
            "",
            "#include \"internal.h\"",
            "",
            "struct callchain_cpus_entries {",
            "\tstruct rcu_head\t\t\trcu_head;",
            "\tstruct perf_callchain_entry\t*cpu_entries[];",
            "};",
            "",
            "int sysctl_perf_event_max_stack __read_mostly = PERF_MAX_STACK_DEPTH;",
            "int sysctl_perf_event_max_contexts_per_stack __read_mostly = PERF_MAX_CONTEXTS_PER_STACK;",
            ""
          ],
          "function_name": null,
          "description": "定义callchain_cpus_entries结构体用于存储每个CPU的调用链条目数组，并声明两个sysctl全局变量用于配置性能事件的最大栈深度和每个栈的最大上下文数。",
          "similarity": 0.39934873580932617
        }
      ]
    }
  ]
}