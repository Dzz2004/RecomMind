{
  "query": "条件变量与互斥锁配合使用场景",
  "timestamp": "2025-12-26 00:55:44",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/mutex.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:42:50\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\mutex.c`\n\n---\n\n# Linux 内核互斥锁（mutex）实现文档\n\n## 1. 文件概述\n\n`locking/mutex.c` 是 Linux 内核中互斥锁（mutex）的核心实现文件，提供了基于阻塞的互斥同步原语。该文件实现了高效、可睡眠的互斥锁机制，支持自旋优化、锁移交（handoff）、调试功能以及与调度器、死锁检测等子系统的深度集成。互斥锁用于保护临界区，确保同一时间只有一个任务可以持有锁，适用于需要长时间持有锁或可能睡眠的场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `__mutex_init()`：初始化互斥锁对象\n- `mutex_is_locked()`：检查互斥锁是否已被持有\n- `mutex_get_owner()`：获取当前锁持有者的任务指针（仅用于调试）\n- `__mutex_trylock()`：尝试获取互斥锁（非阻塞）\n- `__mutex_trylock_fast()`：快速路径尝试获取未竞争的锁\n- `__mutex_unlock_fast()`：快速路径释放锁\n- `__mutex_lock_slowpath()`：慢速路径获取锁（包含睡眠和等待逻辑）\n- `__mutex_handoff()`：将锁所有权移交给指定任务\n- `__mutex_add_waiter()` / `__mutex_remove_waiter()`：管理等待队列\n\n### 关键数据结构\n\n- `struct mutex`：互斥锁核心结构体\n  - `atomic_long_t owner`：原子存储锁持有者指针和状态标志\n  - `raw_spinlock_t wait_lock`：保护等待队列的自旋锁\n  - `struct list_head wait_list`：等待获取锁的任务队列\n  - `struct optimistic_spin_queue osq`：用于自旋优化的队列（CONFIG_MUTEX_SPIN_ON_OWNER）\n\n### 状态标志位\n\n- `MUTEX_FLAG_WAITERS (0x01)`：表示存在等待者，解锁时需唤醒\n- `MUTEX_FLAG_HANDOFF (0x02)`：表示需要将锁移交给队首等待者\n- `MUTEX_FLAG_PICKUP (0x04)`：表示锁已被移交给特定任务，等待其获取\n\n## 3. 关键实现\n\n### 锁状态编码\n互斥锁的 `owner` 字段采用指针-标志位混合编码：利用 `task_struct` 指针的低 3 位（因内存对齐保证为 0）存储状态标志。这种设计避免了额外的内存访问，提高了原子操作效率。\n\n### 快慢路径分离\n- **快速路径**：针对无竞争场景，直接通过原子比较交换（cmpxchg）获取/释放锁，避免函数调用开销\n- **慢速路径**：处理竞争情况，包含自旋等待、任务阻塞、唤醒等复杂逻辑\n\n### 自适应自旋（Adaptive Spinning）\n在 `CONFIG_MUTEX_SPIN_ON_OWNER` 配置下，当检测到锁持有者正在运行时，当前任务会先自旋等待而非立即睡眠，减少上下文切换开销。使用 OSQ（Optimistic Spin Queue）机制协调多个自旋任务。\n\n### 锁移交机制（Handoff）\n通过 `MUTEX_FLAG_HANDOFF` 和 `MUTEX_FLAG_PICKUP` 标志实现高效的锁移交：\n1. 解锁者设置 `HANDOFF` 标志并唤醒队首等待者\n2. 被唤醒任务在获取锁时检测到 `HANDOFF`，设置 `PICKUP` 标志\n3. 解锁者通过 `__mutex_handoff()` 直接将所有权转移给指定任务\n避免了唤醒后再次竞争的问题，提高实时性。\n\n### 调试支持\n- `CONFIG_DEBUG_MUTEXES`：提供锁状态验证、死锁检测\n- `CONFIG_DETECT_HUNG_TASK_BLOCKER`：集成 hung task 检测，记录阻塞源\n- `lockdep`：通过 `debug_mutex_*` 函数集成锁依赖验证\n\n## 4. 依赖关系\n\n### 头文件依赖\n- `<linux/mutex.h>` / `<linux/ww_mutex.h>`：互斥锁接口定义\n- `<linux/sched/*.h>`：调度器相关功能（睡眠、唤醒、实时任务）\n- `<linux/spinlock.h>`：底层自旋锁实现\n- `<linux/osq_lock.h>`：乐观自旋队列支持\n- `<linux/hung_task.h>`：hung task 检测集成\n- `<trace/events/lock.h>`：锁事件跟踪点\n\n### 子系统交互\n- **调度器**：通过 `schedule()` 实现任务阻塞，`wake_q` 机制批量唤醒\n- **内存管理**：依赖 `task_struct` 的内存对齐特性\n- **实时补丁（PREEMPT_RT）**：非 RT 配置下编译此文件（`#ifndef CONFIG_PREEMPT_RT`）\n- **调试子系统**：与 lockdep、hung task detector 深度集成\n\n## 5. 使用场景\n\n### 典型应用场景\n- **长临界区保护**：当临界区执行时间较长或包含可能睡眠的操作（如内存分配、I/O）\n- **驱动程序同步**：设备驱动中保护硬件寄存器访问或共享数据结构\n- **文件系统操作**：保护 inode、dentry 等元数据结构\n- **内核子系统互斥**：如网络协议栈、块设备层等需要互斥访问的场景\n\n### 使用约束\n- **不可递归**：同一任务重复获取会导致死锁\n- **必须配对使用**：获取锁的任务必须负责释放\n- **禁止中断上下文使用**：因可能睡眠，只能在进程上下文使用\n- **内存生命周期**：锁对象内存不能在持有锁时释放\n\n### 性能考量\n- 无竞争场景：纳秒级延迟（快速路径原子操作）\n- 有竞争场景：微秒级延迟（自旋优化）或毫秒级（任务切换）\n- 适用于中低频竞争场景，高频竞争建议使用读写锁或 RCU",
      "similarity": 0.5682770609855652,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 46,
          "end_line": 151,
          "content": [
            "void",
            "__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)",
            "{",
            "\tatomic_long_set(&lock->owner, 0);",
            "\traw_spin_lock_init(&lock->wait_lock);",
            "\tINIT_LIST_HEAD(&lock->wait_list);",
            "#ifdef CONFIG_MUTEX_SPIN_ON_OWNER",
            "\tosq_lock_init(&lock->osq);",
            "#endif",
            "",
            "\tdebug_mutex_init(lock, name, key);",
            "}",
            "bool mutex_is_locked(struct mutex *lock)",
            "{",
            "\treturn __mutex_owner(lock) != NULL;",
            "}",
            "static inline unsigned long __owner_flags(unsigned long owner)",
            "{",
            "\treturn owner & MUTEX_FLAGS;",
            "}",
            "unsigned long mutex_get_owner(struct mutex *lock)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\treturn (unsigned long)__owner_task(owner);",
            "}",
            "static inline bool __mutex_trylock_or_handoff(struct mutex *lock, bool handoff)",
            "{",
            "\treturn !__mutex_trylock_common(lock, handoff);",
            "}",
            "static inline bool __mutex_trylock(struct mutex *lock)",
            "{",
            "\treturn !__mutex_trylock_common(lock, false);",
            "}",
            "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "\tunsigned long zero = 0UL;",
            "",
            "\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "static __always_inline bool __mutex_unlock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "",
            "\treturn atomic_long_try_cmpxchg_release(&lock->owner, &curr, 0UL);",
            "}",
            "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_or(flag, &lock->owner);",
            "}",
            "static inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_andnot(flag, &lock->owner);",
            "}",
            "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;",
            "}",
            "static void",
            "__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,",
            "\t\t   struct list_head *list)",
            "{",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_set_blocker(lock, BLOCKER_TYPE_MUTEX);",
            "#endif",
            "\tdebug_mutex_add_waiter(lock, waiter, current);",
            "",
            "\tlist_add_tail(&waiter->list, list);",
            "\tif (__mutex_waiter_is_first(lock, waiter))",
            "\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);",
            "}",
            "static void",
            "__mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\tlist_del(&waiter->list);",
            "\tif (likely(list_empty(&lock->wait_list)))",
            "\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);",
            "",
            "\tdebug_mutex_remove_waiter(lock, waiter, current);",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_clear_blocker();",
            "#endif",
            "}",
            "static void __mutex_handoff(struct mutex *lock, struct task_struct *task)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\tfor (;;) {",
            "\t\tunsigned long new;",
            "",
            "\t\tMUTEX_WARN_ON(__owner_task(owner) != current);",
            "\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);",
            "",
            "\t\tnew = (owner & MUTEX_FLAG_WAITERS);",
            "\t\tnew |= (unsigned long)task;",
            "\t\tif (task)",
            "\t\t\tnew |= MUTEX_FLAG_PICKUP;",
            "",
            "\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, new))",
            "\t\t\tbreak;",
            "\t}",
            "}"
          ],
          "function_name": "__mutex_init, mutex_is_locked, __owner_flags, mutex_get_owner, __mutex_trylock_or_handoff, __mutex_trylock, __mutex_trylock_fast, __mutex_unlock_fast, __mutex_set_flag, __mutex_clear_flag, __mutex_waiter_is_first, __mutex_add_waiter, __mutex_remove_waiter, __mutex_handoff",
          "description": "实现互斥锁核心操作，包括初始化、状态检查、快速尝试加锁、标志位操作及等待者链表管理。",
          "similarity": 0.6875632405281067
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 1059,
          "end_line": 1129,
          "content": [
            "static noinline int __sched",
            "__mutex_lock_interruptible_slowpath(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "static noinline int __sched",
            "__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0,",
            "\t\t\t       _RET_IP_, ctx);",
            "}",
            "static noinline int __sched",
            "__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,",
            "\t\t\t\t\t    struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0,",
            "\t\t\t       _RET_IP_, ctx);",
            "}",
            "int __sched mutex_trylock(struct mutex *lock)",
            "{",
            "\tbool locked;",
            "",
            "\tMUTEX_WARN_ON(lock->magic != lock);",
            "",
            "\tlocked = __mutex_trylock(lock);",
            "\tif (locked)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn locked;",
            "}",
            "int __sched",
            "ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(&lock->base)) {",
            "\t\tif (ctx)",
            "\t\t\tww_mutex_set_context_fastpath(lock, ctx);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn __ww_mutex_lock_slowpath(lock, ctx);",
            "}",
            "int __sched",
            "ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(&lock->base)) {",
            "\t\tif (ctx)",
            "\t\t\tww_mutex_set_context_fastpath(lock, ctx);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn __ww_mutex_lock_interruptible_slowpath(lock, ctx);",
            "}",
            "int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock)",
            "{",
            "\t/* dec if we can't possibly hit 0 */",
            "\tif (atomic_add_unless(cnt, -1, 1))",
            "\t\treturn 0;",
            "\t/* we might hit 0, so take the lock */",
            "\tmutex_lock(lock);",
            "\tif (!atomic_dec_and_test(cnt)) {",
            "\t\t/* when we actually did the dec, we didn't hit 0 */",
            "\t\tmutex_unlock(lock);",
            "\t\treturn 0;",
            "\t}",
            "\t/* we hit 0, and we hold the lock */",
            "\treturn 1;",
            "}"
          ],
          "function_name": "__mutex_lock_interruptible_slowpath, __ww_mutex_lock_slowpath, __ww_mutex_lock_interruptible_slowpath, mutex_trylock, ww_mutex_lock, ww_mutex_lock_interruptible, atomic_dec_and_mutex_lock",
          "description": "提供互斥锁快速路径与慢速路径切换支持，包含原子计数器递减与锁获取协同机制",
          "similarity": 0.6858021020889282
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 895,
          "end_line": 996,
          "content": [
            "int __sched",
            "ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tret = __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE,",
            "\t\t\t      0, _RET_IP_, ctx);",
            "",
            "\tif (!ret && ctx && ctx->acquired > 1)",
            "\t\treturn ww_mutex_deadlock_injection(lock, ctx);",
            "",
            "\treturn ret;",
            "}",
            "static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)",
            "{",
            "\tstruct task_struct *next = NULL;",
            "\tDEFINE_WAKE_Q(wake_q);",
            "\tunsigned long owner;",
            "",
            "\tmutex_release(&lock->dep_map, ip);",
            "",
            "\t/*",
            "\t * Release the lock before (potentially) taking the spinlock such that",
            "\t * other contenders can get on with things ASAP.",
            "\t *",
            "\t * Except when HANDOFF, in that case we must not clear the owner field,",
            "\t * but instead set it to the top waiter.",
            "\t */",
            "\towner = atomic_long_read(&lock->owner);",
            "\tfor (;;) {",
            "\t\tMUTEX_WARN_ON(__owner_task(owner) != current);",
            "\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);",
            "",
            "\t\tif (owner & MUTEX_FLAG_HANDOFF)",
            "\t\t\tbreak;",
            "",
            "\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, __owner_flags(owner))) {",
            "\t\t\tif (owner & MUTEX_FLAG_WAITERS)",
            "\t\t\t\tbreak;",
            "",
            "\t\t\treturn;",
            "\t\t}",
            "\t}",
            "",
            "\traw_spin_lock(&lock->wait_lock);",
            "\tdebug_mutex_unlock(lock);",
            "\tif (!list_empty(&lock->wait_list)) {",
            "\t\t/* get the first entry from the wait-list: */",
            "\t\tstruct mutex_waiter *waiter =",
            "\t\t\tlist_first_entry(&lock->wait_list,",
            "\t\t\t\t\t struct mutex_waiter, list);",
            "",
            "\t\tnext = waiter->task;",
            "",
            "\t\tdebug_mutex_wake_waiter(lock, waiter);",
            "\t\twake_q_add(&wake_q, next);",
            "\t}",
            "",
            "\tif (owner & MUTEX_FLAG_HANDOFF)",
            "\t\t__mutex_handoff(lock, next);",
            "",
            "\traw_spin_unlock(&lock->wait_lock);",
            "",
            "\twake_up_q(&wake_q);",
            "}",
            "int __sched mutex_lock_interruptible(struct mutex *lock)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(lock))",
            "\t\treturn 0;",
            "",
            "\treturn __mutex_lock_interruptible_slowpath(lock);",
            "}",
            "int __sched mutex_lock_killable(struct mutex *lock)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(lock))",
            "\t\treturn 0;",
            "",
            "\treturn __mutex_lock_killable_slowpath(lock);",
            "}",
            "void __sched mutex_lock_io(struct mutex *lock)",
            "{",
            "\tint token;",
            "",
            "\ttoken = io_schedule_prepare();",
            "\tmutex_lock(lock);",
            "\tio_schedule_finish(token);",
            "}",
            "static noinline void __sched",
            "__mutex_lock_slowpath(struct mutex *lock)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "static noinline int __sched",
            "__mutex_lock_killable_slowpath(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);",
            "}"
          ],
          "function_name": "ww_mutex_lock_interruptible, __mutex_unlock_slowpath, mutex_lock_interruptible, mutex_lock_killable, mutex_lock_io, __mutex_lock_slowpath, __mutex_lock_killable_slowpath",
          "description": "实现带死锁检测的递归互斥锁中断获取逻辑，处理锁状态转换、唤醒等待线程及异常注入场景",
          "similarity": 0.6518774032592773
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 1,
          "end_line": 45,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * kernel/locking/mutex.c",
            " *",
            " * Mutexes: blocking mutual exclusion locks",
            " *",
            " * Started by Ingo Molnar:",
            " *",
            " *  Copyright (C) 2004, 2005, 2006 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>",
            " *",
            " * Many thanks to Arjan van de Ven, Thomas Gleixner, Steven Rostedt and",
            " * David Howells for suggestions and improvements.",
            " *",
            " *  - Adaptive spinning for mutexes by Peter Zijlstra. (Ported to mainline",
            " *    from the -rt tree, where it was originally implemented for rtmutexes",
            " *    by Steven Rostedt, based on work by Gregory Haskins, Peter Morreale",
            " *    and Sven Dietrich.",
            " *",
            " * Also see Documentation/locking/mutex-design.rst.",
            " */",
            "#include <linux/mutex.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/osq_lock.h>",
            "#include <linux/hung_task.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/lock.h>",
            "",
            "#ifndef CONFIG_PREEMPT_RT",
            "#include \"mutex.h\"",
            "",
            "#ifdef CONFIG_DEBUG_MUTEXES",
            "# define MUTEX_WARN_ON(cond) DEBUG_LOCKS_WARN_ON(cond)",
            "#else",
            "# define MUTEX_WARN_ON(cond)",
            "#endif",
            ""
          ],
          "function_name": null,
          "description": "声明互斥锁模块的头文件和基本配置，初始化互斥锁结构体并设置等待队列及调试信息。",
          "similarity": 0.6328411102294922
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 455,
          "end_line": 722,
          "content": [
            "static __always_inline bool",
            "mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t      struct mutex_waiter *waiter)",
            "{",
            "\tif (!waiter) {",
            "\t\t/*",
            "\t\t * The purpose of the mutex_can_spin_on_owner() function is",
            "\t\t * to eliminate the overhead of osq_lock() and osq_unlock()",
            "\t\t * in case spinning isn't possible. As a waiter-spinner",
            "\t\t * is not going to take OSQ lock anyway, there is no need",
            "\t\t * to call mutex_can_spin_on_owner().",
            "\t\t */",
            "\t\tif (!mutex_can_spin_on_owner(lock))",
            "\t\t\tgoto fail;",
            "",
            "\t\t/*",
            "\t\t * In order to avoid a stampede of mutex spinners trying to",
            "\t\t * acquire the mutex all at once, the spinners need to take a",
            "\t\t * MCS (queued) lock first before spinning on the owner field.",
            "\t\t */",
            "\t\tif (!osq_lock(&lock->osq))",
            "\t\t\tgoto fail;",
            "\t}",
            "",
            "\tfor (;;) {",
            "\t\tstruct task_struct *owner;",
            "",
            "\t\t/* Try to acquire the mutex... */",
            "\t\towner = __mutex_trylock_or_owner(lock);",
            "\t\tif (!owner)",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * There's an owner, wait for it to either",
            "\t\t * release the lock or go to sleep.",
            "\t\t */",
            "\t\tif (!mutex_spin_on_owner(lock, owner, ww_ctx, waiter))",
            "\t\t\tgoto fail_unlock;",
            "",
            "\t\t/*",
            "\t\t * The cpu_relax() call is a compiler barrier which forces",
            "\t\t * everything in this loop to be re-loaded. We don't need",
            "\t\t * memory barriers as we'll eventually observe the right",
            "\t\t * values at the cost of a few extra spins.",
            "\t\t */",
            "\t\tcpu_relax();",
            "\t}",
            "",
            "\tif (!waiter)",
            "\t\tosq_unlock(&lock->osq);",
            "",
            "\treturn true;",
            "",
            "",
            "fail_unlock:",
            "\tif (!waiter)",
            "\t\tosq_unlock(&lock->osq);",
            "",
            "fail:",
            "\t/*",
            "\t * If we fell out of the spin path because of need_resched(),",
            "\t * reschedule now, before we try-lock the mutex. This avoids getting",
            "\t * scheduled out right after we obtained the mutex.",
            "\t */",
            "\tif (need_resched()) {",
            "\t\t/*",
            "\t\t * We _should_ have TASK_RUNNING here, but just in case",
            "\t\t * we do not, make it so, otherwise we might get stuck.",
            "\t\t */",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t\tschedule_preempt_disabled();",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static __always_inline bool",
            "mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t      struct mutex_waiter *waiter)",
            "{",
            "\treturn false;",
            "}",
            "void __sched mutex_unlock(struct mutex *lock)",
            "{",
            "#ifndef CONFIG_DEBUG_LOCK_ALLOC",
            "\tif (__mutex_unlock_fast(lock))",
            "\t\treturn;",
            "#endif",
            "\t__mutex_unlock_slowpath(lock, _RET_IP_);",
            "}",
            "void __sched ww_mutex_unlock(struct ww_mutex *lock)",
            "{",
            "\t__ww_mutex_unlock(lock);",
            "\tmutex_unlock(&lock->base);",
            "}",
            "static __always_inline int __sched",
            "__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t\t    struct lockdep_map *nest_lock, unsigned long ip,",
            "\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)",
            "{",
            "\tstruct mutex_waiter waiter;",
            "\tstruct ww_mutex *ww;",
            "\tint ret;",
            "",
            "\tif (!use_ww_ctx)",
            "\t\tww_ctx = NULL;",
            "",
            "\tmight_sleep();",
            "",
            "\tMUTEX_WARN_ON(lock->magic != lock);",
            "",
            "\tww = container_of(lock, struct ww_mutex, base);",
            "\tif (ww_ctx) {",
            "\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))",
            "\t\t\treturn -EALREADY;",
            "",
            "\t\t/*",
            "\t\t * Reset the wounded flag after a kill. No other process can",
            "\t\t * race and wound us here since they can't have a valid owner",
            "\t\t * pointer if we don't have any locks held.",
            "\t\t */",
            "\t\tif (ww_ctx->acquired == 0)",
            "\t\t\tww_ctx->wounded = 0;",
            "",
            "#ifdef CONFIG_DEBUG_LOCK_ALLOC",
            "\t\tnest_lock = &ww_ctx->dep_map;",
            "#endif",
            "\t}",
            "",
            "\tpreempt_disable();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);",
            "",
            "\ttrace_contention_begin(lock, LCB_F_MUTEX | LCB_F_SPIN);",
            "\tif (__mutex_trylock(lock) ||",
            "\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {",
            "\t\t/* got the lock, yay! */",
            "\t\tlock_acquired(&lock->dep_map, ip);",
            "\t\tif (ww_ctx)",
            "\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);",
            "\t\ttrace_contention_end(lock, 0);",
            "\t\tpreempt_enable();",
            "\t\treturn 0;",
            "\t}",
            "",
            "\traw_spin_lock(&lock->wait_lock);",
            "\t/*",
            "\t * After waiting to acquire the wait_lock, try again.",
            "\t */",
            "\tif (__mutex_trylock(lock)) {",
            "\t\tif (ww_ctx)",
            "\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);",
            "",
            "\t\tgoto skip_wait;",
            "\t}",
            "",
            "\tdebug_mutex_lock_common(lock, &waiter);",
            "\twaiter.task = current;",
            "\tif (use_ww_ctx)",
            "\t\twaiter.ww_ctx = ww_ctx;",
            "",
            "\tlock_contended(&lock->dep_map, ip);",
            "",
            "\tif (!use_ww_ctx) {",
            "\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */",
            "\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);",
            "\t} else {",
            "\t\t/*",
            "\t\t * Add in stamp order, waking up waiters that must kill",
            "\t\t * themselves.",
            "\t\t */",
            "\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);",
            "\t\tif (ret)",
            "\t\t\tgoto err_early_kill;",
            "\t}",
            "",
            "\tset_current_state(state);",
            "\ttrace_contention_begin(lock, LCB_F_MUTEX);",
            "\tfor (;;) {",
            "\t\tbool first;",
            "",
            "\t\t/*",
            "\t\t * Once we hold wait_lock, we're serialized against",
            "\t\t * mutex_unlock() handing the lock off to us, do a trylock",
            "\t\t * before testing the error conditions to make sure we pick up",
            "\t\t * the handoff.",
            "\t\t */",
            "\t\tif (__mutex_trylock(lock))",
            "\t\t\tgoto acquired;",
            "",
            "\t\t/*",
            "\t\t * Check for signals and kill conditions while holding",
            "\t\t * wait_lock. This ensures the lock cancellation is ordered",
            "\t\t * against mutex_unlock() and wake-ups do not go missing.",
            "\t\t */",
            "\t\tif (signal_pending_state(state, current)) {",
            "\t\t\tret = -EINTR;",
            "\t\t\tgoto err;",
            "\t\t}",
            "",
            "\t\tif (ww_ctx) {",
            "\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);",
            "\t\t\tif (ret)",
            "\t\t\t\tgoto err;",
            "\t\t}",
            "",
            "\t\traw_spin_unlock(&lock->wait_lock);",
            "\t\tschedule_preempt_disabled();",
            "",
            "\t\tfirst = __mutex_waiter_is_first(lock, &waiter);",
            "",
            "\t\tset_current_state(state);",
            "\t\t/*",
            "\t\t * Here we order against unlock; we must either see it change",
            "\t\t * state back to RUNNING and fall through the next schedule(),",
            "\t\t * or we must see its unlock and acquire.",
            "\t\t */",
            "\t\tif (__mutex_trylock_or_handoff(lock, first))",
            "\t\t\tbreak;",
            "",
            "\t\tif (first) {",
            "\t\t\ttrace_contention_begin(lock, LCB_F_MUTEX | LCB_F_SPIN);",
            "\t\t\tif (mutex_optimistic_spin(lock, ww_ctx, &waiter))",
            "\t\t\t\tbreak;",
            "\t\t\ttrace_contention_begin(lock, LCB_F_MUTEX);",
            "\t\t}",
            "",
            "\t\traw_spin_lock(&lock->wait_lock);",
            "\t}",
            "\traw_spin_lock(&lock->wait_lock);",
            "acquired:",
            "\t__set_current_state(TASK_RUNNING);",
            "",
            "\tif (ww_ctx) {",
            "\t\t/*",
            "\t\t * Wound-Wait; we stole the lock (!first_waiter), check the",
            "\t\t * waiters as anyone might want to wound us.",
            "\t\t */",
            "\t\tif (!ww_ctx->is_wait_die &&",
            "\t\t    !__mutex_waiter_is_first(lock, &waiter))",
            "\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);",
            "\t}",
            "",
            "\t__mutex_remove_waiter(lock, &waiter);",
            "",
            "\tdebug_mutex_free_waiter(&waiter);",
            "",
            "skip_wait:",
            "\t/* got the lock - cleanup and rejoice! */",
            "\tlock_acquired(&lock->dep_map, ip);",
            "\ttrace_contention_end(lock, 0);",
            "",
            "\tif (ww_ctx)",
            "\t\tww_mutex_lock_acquired(ww, ww_ctx);",
            "",
            "\traw_spin_unlock(&lock->wait_lock);",
            "\tpreempt_enable();",
            "\treturn 0;",
            "",
            "err:",
            "\t__set_current_state(TASK_RUNNING);",
            "\t__mutex_remove_waiter(lock, &waiter);",
            "err_early_kill:",
            "\ttrace_contention_end(lock, ret);",
            "\traw_spin_unlock(&lock->wait_lock);",
            "\tdebug_mutex_free_waiter(&waiter);",
            "\tmutex_release(&lock->dep_map, ip);",
            "\tpreempt_enable();",
            "\treturn ret;",
            "}"
          ],
          "function_name": "mutex_optimistic_spin, mutex_optimistic_spin, mutex_unlock, ww_mutex_unlock, __mutex_lock_common",
          "description": "实现乐观自旋逻辑和锁解除操作，通过原子操作和同步机制管理锁竞争，支持带资源检查的锁操作。",
          "similarity": 0.5821301341056824
        }
      ]
    },
    {
      "source_file": "kernel/locking/semaphore.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:52:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\semaphore.c`\n\n---\n\n# `locking/semaphore.c` 技术文档\n\n## 1. 文件概述\n\n`locking/semaphore.c` 实现了 Linux 内核中的**计数信号量（counting semaphore）**机制。计数信号量允许多个任务（最多为初始计数值）同时持有该锁，当计数值耗尽时，后续请求者将被阻塞，直到有其他任务释放信号量。与互斥锁（mutex）不同，信号量支持更灵活的并发控制，适用于资源池、限流等场景。该文件提供了多种获取和释放信号量的接口，包括可中断、可超时、不可中断等变体，并支持在中断上下文中调用部分函数。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数名 | 功能描述 |\n|--------|--------|\n| `down(struct semaphore *sem)` | 不可中断地获取信号量，若不可用则睡眠。**已弃用**，建议使用可中断版本。 |\n| `down_interruptible(struct semaphore *sem)` | 可被普通信号中断的获取操作，成功返回 0，被信号中断返回 `-EINTR`。 |\n| `down_killable(struct semaphore *sem)` | 可被致命信号（fatal signal）中断的获取操作，返回值同上。 |\n| `down_trylock(struct semaphore *sem)` | 非阻塞尝试获取信号量，成功返回 0，失败返回 1（**注意返回值与 mutex/spinlock 相反**）。 |\n| `down_timeout(struct semaphore *sem, long timeout)` | 带超时的获取操作，超时返回 `-ETIME`，成功返回 0。 |\n| `up(struct semaphore *sem)` | 释放信号量，可由任意上下文（包括中断）调用，唤醒等待队列中的任务。 |\n\n### 静态辅助函数\n\n- `__down*()` 系列：处理信号量争用时的阻塞逻辑。\n- `__up()`：在有等待者时执行唤醒逻辑。\n- `___down_common()`：通用的阻塞等待实现，支持不同睡眠状态和超时。\n- `__sem_acquire()`：原子减少计数并记录持有者（用于 hung task 检测）。\n\n### 数据结构\n\n- `struct semaphore`（定义在 `<linux/semaphore.h>`）：\n  - `count`：当前可用资源数（>0 表示可立即获取）。\n  - `wait_list`：等待该信号量的任务链表。\n  - `lock`：保护上述成员的原始自旋锁（`raw_spinlock_t`）。\n  - `last_holder`（条件编译）：记录最后持有者，用于 `CONFIG_DETECT_HUNG_TASK_BLOCKER`。\n\n- `struct semaphore_waiter`：\n  - 用于将任务加入等待队列，包含任务指针和唤醒标志（`up`）。\n\n## 3. 关键实现\n\n### 中断安全与自旋锁\n- 所有对外接口（包括 `down*` 和 `up`）均使用 `raw_spin_lock_irqsave()` 获取自旋锁，确保在中断上下文安全。\n- 即使 `down()` 等函数通常在进程上下文调用，也使用 `irqsave` 变体，因为内核某些部分依赖在中断上下文成功调用 `down()`（当确定信号量可用时）。\n\n### 计数语义\n- `sem->count` 表示**还可被获取的次数**。初始值由 `sema_init()` 设置。\n- 获取时：若 `count > 0`，直接减 1；否则加入等待队列。\n- 释放时：若等待队列为空，`count++`；否则唤醒队首任务。\n\n### 等待与唤醒机制\n- 使用 `wake_q`（批量唤醒队列）优化唤醒路径，避免在持有自旋锁时调用 `wake_up_process()`。\n- 等待任务通过 `schedule_timeout()` 睡眠，并在循环中检查：\n  - 是否收到信号（根据睡眠状态判断）。\n  - 是否超时。\n  - 是否被 `__up()` 标记为 `waiter.up = true`（表示已被选中唤醒）。\n\n### Hung Task 支持\n- 当启用 `CONFIG_DETECT_HUNG_TASK_BLOCKER` 时：\n  - 获取信号量时记录当前任务为 `last_holder`。\n  - 释放时若当前任务是持有者，则清除记录。\n  - 提供 `sem_last_holder()` 供 hung task 检测模块查询阻塞源头。\n\n### 返回值约定\n- `down_trylock()` 返回 **0 表示成功**，**1 表示失败**，这与 `mutex_trylock()` 和 `spin_trylock()` **相反**，需特别注意。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/semaphore.h>`：信号量结构体和 API 声明。\n  - `<linux/spinlock.h>`：原始自旋锁实现。\n  - `<linux/sched.h>`、`<linux/sched/wake_q.h>`：任务调度和批量唤醒。\n  - `<trace/events/lock.h>`：锁争用跟踪点。\n  - `<linux/hung_task.h>`：hung task 检测支持。\n\n- **内核配置依赖**：\n  - `CONFIG_DETECT_HUNG_TASK_BLOCKER`：启用信号量持有者跟踪。\n\n- **与其他同步原语关系**：\n  - 与 `mutex.c` 形成对比：mutex 是二值、不可递归、带调试信息的互斥锁；信号量是计数、可被任意任务释放、更轻量。\n  - 底层依赖调度器（`schedule_timeout`）和中断管理（`irqsave`）。\n\n## 5. 使用场景\n\n- **资源池管理**：如限制同时访问某类硬件设备的任务数量。\n- **读写并发控制**：配合其他机制实现多读者/单写者模型。\n- **内核驱动**：设备驱动中控制对共享资源的并发访问。\n- **中断上下文释放**：因 `up()` 可在中断中调用，适用于中断处理程序释放资源的场景。\n- **不可睡眠路径**：使用 `down_trylock()` 在原子上下文尝试获取资源。\n\n> **注意**：由于信号量不强制所有权（任意任务可调用 `up()`），且缺乏死锁检测等调试特性，现代内核开发中更推荐使用 `mutex` 或 `rwsem`，除非明确需要计数语义或多释放者特性。",
      "similarity": 0.5516653656959534,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/semaphore.c",
          "start_line": 252,
          "end_line": 323,
          "content": [
            "static inline int __sched ___down_common(struct semaphore *sem, long state,",
            "\t\t\t\t\t\t\t\tlong timeout)",
            "{",
            "\tstruct semaphore_waiter waiter;",
            "",
            "\tlist_add_tail(&waiter.list, &sem->wait_list);",
            "\twaiter.task = current;",
            "\twaiter.up = false;",
            "",
            "\tfor (;;) {",
            "\t\tif (signal_pending_state(state, current))",
            "\t\t\tgoto interrupted;",
            "\t\tif (unlikely(timeout <= 0))",
            "\t\t\tgoto timed_out;",
            "\t\t__set_current_state(state);",
            "\t\traw_spin_unlock_irq(&sem->lock);",
            "\t\ttimeout = schedule_timeout(timeout);",
            "\t\traw_spin_lock_irq(&sem->lock);",
            "\t\tif (waiter.up) {",
            "\t\t\thung_task_sem_set_holder(sem);",
            "\t\t\treturn 0;",
            "\t\t}",
            "\t}",
            "",
            " timed_out:",
            "\tlist_del(&waiter.list);",
            "\treturn -ETIME;",
            "",
            " interrupted:",
            "\tlist_del(&waiter.list);",
            "\treturn -EINTR;",
            "}",
            "static inline int __sched __down_common(struct semaphore *sem, long state,",
            "\t\t\t\t\tlong timeout)",
            "{",
            "\tint ret;",
            "",
            "\thung_task_set_blocker(sem, BLOCKER_TYPE_SEM);",
            "",
            "\ttrace_contention_begin(sem, 0);",
            "\tret = ___down_common(sem, state, timeout);",
            "\ttrace_contention_end(sem, ret);",
            "",
            "\thung_task_clear_blocker();",
            "",
            "\treturn ret;",
            "}",
            "static noinline void __sched __down(struct semaphore *sem)",
            "{",
            "\t__down_common(sem, TASK_UNINTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);",
            "}",
            "static noinline int __sched __down_interruptible(struct semaphore *sem)",
            "{",
            "\treturn __down_common(sem, TASK_INTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);",
            "}",
            "static noinline int __sched __down_killable(struct semaphore *sem)",
            "{",
            "\treturn __down_common(sem, TASK_KILLABLE, MAX_SCHEDULE_TIMEOUT);",
            "}",
            "static noinline int __sched __down_timeout(struct semaphore *sem, long timeout)",
            "{",
            "\treturn __down_common(sem, TASK_UNINTERRUPTIBLE, timeout);",
            "}",
            "static noinline void __sched __up(struct semaphore *sem,",
            "\t\t\t\t  struct wake_q_head *wake_q)",
            "{",
            "\tstruct semaphore_waiter *waiter = list_first_entry(&sem->wait_list,",
            "\t\t\t\t\t\tstruct semaphore_waiter, list);",
            "\tlist_del(&waiter->list);",
            "\twaiter->up = true;",
            "\twake_q_add(wake_q, waiter->task);",
            "}"
          ],
          "function_name": "___down_common, __down_common, __down, __down_interruptible, __down_killable, __down_timeout, __up",
          "description": "实现了信号量的阻塞等待通用逻辑，包含___down_common/__down_common等辅助函数，处理信号量不足时的任务挂起、超时检测、信号处理及唤醒机制，通过循环等待并结合schedule_timeout实现阻塞式资源竞争解决",
          "similarity": 0.5377373695373535
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/semaphore.c",
          "start_line": 46,
          "end_line": 160,
          "content": [
            "static inline void hung_task_sem_set_holder(struct semaphore *sem)",
            "{",
            "\tWRITE_ONCE((sem)->last_holder, (unsigned long)current);",
            "}",
            "static inline void hung_task_sem_clear_if_holder(struct semaphore *sem)",
            "{",
            "\tif (READ_ONCE((sem)->last_holder) == (unsigned long)current)",
            "\t\tWRITE_ONCE((sem)->last_holder, 0UL);",
            "}",
            "unsigned long sem_last_holder(struct semaphore *sem)",
            "{",
            "\treturn READ_ONCE(sem->last_holder);",
            "}",
            "static inline void hung_task_sem_set_holder(struct semaphore *sem)",
            "{",
            "}",
            "static inline void hung_task_sem_clear_if_holder(struct semaphore *sem)",
            "{",
            "}",
            "unsigned long sem_last_holder(struct semaphore *sem)",
            "{",
            "\treturn 0UL;",
            "}",
            "static inline void __sem_acquire(struct semaphore *sem)",
            "{",
            "\tsem->count--;",
            "\thung_task_sem_set_holder(sem);",
            "}",
            "void __sched down(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\t__down(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "}",
            "int __sched down_interruptible(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tint result = 0;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\tresult = __down_interruptible(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn result;",
            "}",
            "int __sched down_killable(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tint result = 0;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\tresult = __down_killable(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn result;",
            "}",
            "int __sched down_trylock(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tint count;",
            "",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tcount = sem->count - 1;",
            "\tif (likely(count >= 0))",
            "\t\t__sem_acquire(sem);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn (count < 0);",
            "}",
            "int __sched down_timeout(struct semaphore *sem, long timeout)",
            "{",
            "\tunsigned long flags;",
            "\tint result = 0;",
            "",
            "\tmight_sleep();",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "\tif (likely(sem->count > 0))",
            "\t\t__sem_acquire(sem);",
            "\telse",
            "\t\tresult = __down_timeout(sem, timeout);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "",
            "\treturn result;",
            "}",
            "void __sched up(struct semaphore *sem)",
            "{",
            "\tunsigned long flags;",
            "\tDEFINE_WAKE_Q(wake_q);",
            "",
            "\traw_spin_lock_irqsave(&sem->lock, flags);",
            "",
            "\thung_task_sem_clear_if_holder(sem);",
            "",
            "\tif (likely(list_empty(&sem->wait_list)))",
            "\t\tsem->count++;",
            "\telse",
            "\t\t__up(sem, &wake_q);",
            "\traw_spin_unlock_irqrestore(&sem->lock, flags);",
            "\tif (!wake_q_empty(&wake_q))",
            "\t\twake_up_q(&wake_q);",
            "}"
          ],
          "function_name": "hung_task_sem_set_holder, hung_task_sem_clear_if_holder, sem_last_holder, hung_task_sem_set_holder, hung_task_sem_clear_if_holder, sem_last_holder, __sem_acquire, down, down_interruptible, down_killable, down_trylock, down_timeout, up",
          "description": "实现了信号量的获取与释放核心逻辑，包括down/down_interruptible/down_killable/down_trylock/down_timeout等接口，通过spinlock保护共享资源，维护等待队列并处理任务状态变更，其中包含Hung Task检测相关函数的条件性实现",
          "similarity": 0.5160104632377625
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/semaphore.c",
          "start_line": 1,
          "end_line": 45,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Copyright (c) 2008 Intel Corporation",
            " * Author: Matthew Wilcox <willy@linux.intel.com>",
            " *",
            " * This file implements counting semaphores.",
            " * A counting semaphore may be acquired 'n' times before sleeping.",
            " * See mutex.c for single-acquisition sleeping locks which enforce",
            " * rules which allow code to be debugged more easily.",
            " */",
            "",
            "/*",
            " * Some notes on the implementation:",
            " *",
            " * The spinlock controls access to the other members of the semaphore.",
            " * down_trylock() and up() can be called from interrupt context, so we",
            " * have to disable interrupts when taking the lock.  It turns out various",
            " * parts of the kernel expect to be able to use down() on a semaphore in",
            " * interrupt context when they know it will succeed, so we have to use",
            " * irqsave variants for down(), down_interruptible() and down_killable()",
            " * too.",
            " *",
            " * The ->count variable represents how many more tasks can acquire this",
            " * semaphore.  If it's zero, there may be tasks waiting on the wait_list.",
            " */",
            "",
            "#include <linux/compiler.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>",
            "#include <linux/sched.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/semaphore.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/ftrace.h>",
            "#include <trace/events/lock.h>",
            "#include <linux/hung_task.h>",
            "",
            "static noinline void __down(struct semaphore *sem);",
            "static noinline int __down_interruptible(struct semaphore *sem);",
            "static noinline int __down_killable(struct semaphore *sem);",
            "static noinline int __down_timeout(struct semaphore *sem, long timeout);",
            "static noinline void __up(struct semaphore *sem, struct wake_q_head *wake_q);",
            "",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER"
          ],
          "function_name": null,
          "description": "此代码块定义了计数信号量的基础框架，包含实现计数信号量所需的头文件和注释，声明了多个内联函数及辅助函数，用于处理信号量的获取、释放及Hung Task检测相关逻辑，但由于代码截断，CONFIG_DETECT_HUNG_TASK_BLOCKER部分缺失，上下文不完整",
          "similarity": 0.4632399082183838
        }
      ]
    },
    {
      "source_file": "kernel/locking/test-ww_mutex.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:55:51\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\test-ww_mutex.c`\n\n---\n\n# `locking/test-ww_mutex.c` 技术文档\n\n## 1. 文件概述\n\n`test-ww_mutex.c` 是 Linux 内核中用于测试 **Wound/Wait 互斥锁（ww_mutex）** 机制的模块化单元测试文件。该文件通过模拟多种并发场景（如自锁、ABBA 死锁、循环死锁等），验证 ww_mutex 的正确性、互斥性以及死锁检测与恢复机制是否按预期工作。该测试模块主要用于内核开发和调试阶段，确保 ww_mutex 的实现符合设计规范。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct test_mutex`  \n  用于测试基本互斥行为的结构体，包含工作项、ww_mutex、完成量（completion）和测试标志。\n\n- `struct test_abba`  \n  用于模拟 ABBA 死锁场景的结构体，包含两个 ww_mutex、完成量、解析标志、trylock 标志及结果。\n\n- `struct test_cycle`  \n  用于测试多线程循环依赖死锁场景的结构体，支持 N 个线程形成环形依赖。\n\n- `ww_class`  \n  全局定义的 `ww_class`，用于标识 ww_mutex 所属的锁类，是 ww_mutex 正常工作的必要条件。\n\n### 主要函数\n\n- `test_mutex_work()`  \n  工作队列回调函数，执行 ww_mutex 的加锁/尝试加锁操作。\n\n- `__test_mutex()` / `test_mutex()`  \n  测试基本互斥语义，覆盖多种标志组合（自旋、trylock、带上下文等）。\n\n- `test_aa()`  \n  测试同一上下文对同一 ww_mutex 的重复加锁行为，验证 `-EALREADY` 返回值。\n\n- `test_abba_work()` / `test_abba()`  \n  测试经典的 ABBA 死锁场景，支持是否启用死锁解析（resolve）。\n\n- `test_cycle_work()` / `__test_cycle()`  \n  测试 N 线程环形依赖死锁，并验证 ww_mutex 的死锁自动解析能力。\n\n## 3. 关键实现\n\n### Wound/Wait 机制测试\n\n- 所有测试均基于 `ww_acquire_ctx` 上下文进行加锁，确保符合 ww_mutex 的使用规范。\n- 通过 `ww_mutex_lock()` 和 `ww_mutex_trylock()` 的组合，验证不同加锁路径的行为一致性。\n\n### 死锁检测与解析\n\n- 在 `test_abba()` 和 `__test_cycle()` 中，当检测到 `-EDEADLK` 时，主动调用 `ww_mutex_unlock()` 释放已持有锁，再通过 `ww_mutex_lock_slow()` 重新按顺序获取锁，模拟死锁恢复流程。\n- `test_abba()` 支持两种模式：  \n  - **不解析**：期望两个线程均返回 `-EDEADLK`；  \n  - **解析**：期望死锁被成功解除，返回 0。\n\n### 防止测试干扰\n\n- 使用 `CONFIG_DEBUG_WW_MUTEX_SLOWPATH` 宏控制是否禁用死锁注入（`deadlock_inject_countdown = ~0U`），确保测试结果可复现。\n- 所有工作项均使用 `INIT_WORK_ONSTACK` 初始化，并在测试结束时调用 `destroy_work_on_stack()`，避免内存泄漏。\n\n### 超时与同步机制\n\n- 使用 `completion` 机制协调主线程与工作线程的执行顺序。\n- 设置 `TIMEOUT = HZ / 16` 作为最大等待时间，防止测试挂起。\n- 在 `TEST_MTX_SPIN` 模式下，主动轮询完成状态并调用 `cond_resched()`，避免软死锁。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/ww_mutex.h>`：提供 ww_mutex 核心 API。\n  - `<linux/completion.h>`、`<linux/workqueue.h>`：用于线程同步与调度。\n  - `<linux/kthread.h>`、`<linux/slab.h>`：支持动态内存分配与内核线程。\n  - `<linux/prandom.h>`：虽未直接使用，但为潜在扩展预留。\n\n- **内核配置依赖**：\n  - 依赖 `CONFIG_WW_MUTEX` 编译选项。\n  - 调试模式下依赖 `CONFIG_DEBUG_WW_MUTEX_SLOWPATH`。\n\n- **运行时依赖**：\n  - 使用全局工作队列 `wq`（在文件外初始化），用于并发执行测试任务。\n\n## 5. 使用场景\n\n- **内核开发与回归测试**：在修改 ww_mutex 实现后，运行此模块验证功能正确性。\n- **死锁行为验证**：用于确认 ww_mutex 能正确检测并处理 ABBA、循环依赖等复杂死锁。\n- **API 兼容性测试**：确保 `ww_mutex_lock`、`ww_mutex_trylock`、`ww_mutex_lock_slow` 等接口行为符合预期。\n- **调试辅助**：当系统出现 ww_mutex 相关死锁时，可参考此测试逻辑复现问题。",
      "similarity": 0.5428847074508667,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 40,
          "end_line": 171,
          "content": [
            "static void test_mutex_work(struct work_struct *work)",
            "{",
            "\tstruct test_mutex *mtx = container_of(work, typeof(*mtx), work);",
            "",
            "\tcomplete(&mtx->ready);",
            "\twait_for_completion(&mtx->go);",
            "",
            "\tif (mtx->flags & TEST_MTX_TRY) {",
            "\t\twhile (!ww_mutex_trylock(&mtx->mutex, NULL))",
            "\t\t\tcond_resched();",
            "\t} else {",
            "\t\tww_mutex_lock(&mtx->mutex, NULL);",
            "\t}",
            "\tcomplete(&mtx->done);",
            "\tww_mutex_unlock(&mtx->mutex);",
            "}",
            "static int __test_mutex(unsigned int flags)",
            "{",
            "#define TIMEOUT (HZ / 16)",
            "\tstruct test_mutex mtx;",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint ret;",
            "",
            "\tww_mutex_init(&mtx.mutex, &ww_class);",
            "\tww_acquire_init(&ctx, &ww_class);",
            "",
            "\tINIT_WORK_ONSTACK(&mtx.work, test_mutex_work);",
            "\tinit_completion(&mtx.ready);",
            "\tinit_completion(&mtx.go);",
            "\tinit_completion(&mtx.done);",
            "\tmtx.flags = flags;",
            "",
            "\tschedule_work(&mtx.work);",
            "",
            "\twait_for_completion(&mtx.ready);",
            "\tww_mutex_lock(&mtx.mutex, (flags & TEST_MTX_CTX) ? &ctx : NULL);",
            "\tcomplete(&mtx.go);",
            "\tif (flags & TEST_MTX_SPIN) {",
            "\t\tunsigned long timeout = jiffies + TIMEOUT;",
            "",
            "\t\tret = 0;",
            "\t\tdo {",
            "\t\t\tif (completion_done(&mtx.done)) {",
            "\t\t\t\tret = -EINVAL;",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t\tcond_resched();",
            "\t\t} while (time_before(jiffies, timeout));",
            "\t} else {",
            "\t\tret = wait_for_completion_timeout(&mtx.done, TIMEOUT);",
            "\t}",
            "\tww_mutex_unlock(&mtx.mutex);",
            "\tww_acquire_fini(&ctx);",
            "",
            "\tif (ret) {",
            "\t\tpr_err(\"%s(flags=%x): mutual exclusion failure\\n\",",
            "\t\t       __func__, flags);",
            "\t\tret = -EINVAL;",
            "\t}",
            "",
            "\tflush_work(&mtx.work);",
            "\tdestroy_work_on_stack(&mtx.work);",
            "\treturn ret;",
            "#undef TIMEOUT",
            "}",
            "static int test_mutex(void)",
            "{",
            "\tint ret;",
            "\tint i;",
            "",
            "\tfor (i = 0; i < __TEST_MTX_LAST; i++) {",
            "\t\tret = __test_mutex(i);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int test_aa(bool trylock)",
            "{",
            "\tstruct ww_mutex mutex;",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint ret;",
            "\tconst char *from = trylock ? \"trylock\" : \"lock\";",
            "",
            "\tww_mutex_init(&mutex, &ww_class);",
            "\tww_acquire_init(&ctx, &ww_class);",
            "",
            "\tif (!trylock) {",
            "\t\tret = ww_mutex_lock(&mutex, &ctx);",
            "\t\tif (ret) {",
            "\t\t\tpr_err(\"%s: initial lock failed!\\n\", __func__);",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t} else {",
            "\t\tret = !ww_mutex_trylock(&mutex, &ctx);",
            "\t\tif (ret) {",
            "\t\t\tpr_err(\"%s: initial trylock failed!\\n\", __func__);",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t}",
            "",
            "\tif (ww_mutex_trylock(&mutex, NULL))  {",
            "\t\tpr_err(\"%s: trylocked itself without context from %s!\\n\", __func__, from);",
            "\t\tww_mutex_unlock(&mutex);",
            "\t\tret = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (ww_mutex_trylock(&mutex, &ctx))  {",
            "\t\tpr_err(\"%s: trylocked itself with context from %s!\\n\", __func__, from);",
            "\t\tww_mutex_unlock(&mutex);",
            "\t\tret = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tret = ww_mutex_lock(&mutex, &ctx);",
            "\tif (ret != -EALREADY) {",
            "\t\tpr_err(\"%s: missed deadlock for recursing, ret=%d from %s\\n\",",
            "\t\t       __func__, ret, from);",
            "\t\tif (!ret)",
            "\t\t\tww_mutex_unlock(&mutex);",
            "\t\tret = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tww_mutex_unlock(&mutex);",
            "\tret = 0;",
            "out:",
            "\tww_acquire_fini(&ctx);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "test_mutex_work, __test_mutex, test_mutex, test_aa",
          "description": "实现ww_mutex的多种测试场景，包括尝试加锁、死锁检测、递归锁冲突验证，通过工作队列模拟并发操作并校验互斥行为",
          "similarity": 0.6487323045730591
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 186,
          "end_line": 302,
          "content": [
            "static void test_abba_work(struct work_struct *work)",
            "{",
            "\tstruct test_abba *abba = container_of(work, typeof(*abba), work);",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint err;",
            "",
            "\tww_acquire_init_noinject(&ctx, &ww_class);",
            "\tif (!abba->trylock)",
            "\t\tww_mutex_lock(&abba->b_mutex, &ctx);",
            "\telse",
            "\t\tWARN_ON(!ww_mutex_trylock(&abba->b_mutex, &ctx));",
            "",
            "\tWARN_ON(READ_ONCE(abba->b_mutex.ctx) != &ctx);",
            "",
            "\tcomplete(&abba->b_ready);",
            "\twait_for_completion(&abba->a_ready);",
            "",
            "\terr = ww_mutex_lock(&abba->a_mutex, &ctx);",
            "\tif (abba->resolve && err == -EDEADLK) {",
            "\t\tww_mutex_unlock(&abba->b_mutex);",
            "\t\tww_mutex_lock_slow(&abba->a_mutex, &ctx);",
            "\t\terr = ww_mutex_lock(&abba->b_mutex, &ctx);",
            "\t}",
            "",
            "\tif (!err)",
            "\t\tww_mutex_unlock(&abba->a_mutex);",
            "\tww_mutex_unlock(&abba->b_mutex);",
            "\tww_acquire_fini(&ctx);",
            "",
            "\tabba->result = err;",
            "}",
            "static int test_abba(bool trylock, bool resolve)",
            "{",
            "\tstruct test_abba abba;",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint err, ret;",
            "",
            "\tww_mutex_init(&abba.a_mutex, &ww_class);",
            "\tww_mutex_init(&abba.b_mutex, &ww_class);",
            "\tINIT_WORK_ONSTACK(&abba.work, test_abba_work);",
            "\tinit_completion(&abba.a_ready);",
            "\tinit_completion(&abba.b_ready);",
            "\tabba.trylock = trylock;",
            "\tabba.resolve = resolve;",
            "",
            "\tschedule_work(&abba.work);",
            "",
            "\tww_acquire_init_noinject(&ctx, &ww_class);",
            "\tif (!trylock)",
            "\t\tww_mutex_lock(&abba.a_mutex, &ctx);",
            "\telse",
            "\t\tWARN_ON(!ww_mutex_trylock(&abba.a_mutex, &ctx));",
            "",
            "\tWARN_ON(READ_ONCE(abba.a_mutex.ctx) != &ctx);",
            "",
            "\tcomplete(&abba.a_ready);",
            "\twait_for_completion(&abba.b_ready);",
            "",
            "\terr = ww_mutex_lock(&abba.b_mutex, &ctx);",
            "\tif (resolve && err == -EDEADLK) {",
            "\t\tww_mutex_unlock(&abba.a_mutex);",
            "\t\tww_mutex_lock_slow(&abba.b_mutex, &ctx);",
            "\t\terr = ww_mutex_lock(&abba.a_mutex, &ctx);",
            "\t}",
            "",
            "\tif (!err)",
            "\t\tww_mutex_unlock(&abba.b_mutex);",
            "\tww_mutex_unlock(&abba.a_mutex);",
            "\tww_acquire_fini(&ctx);",
            "",
            "\tflush_work(&abba.work);",
            "\tdestroy_work_on_stack(&abba.work);",
            "",
            "\tret = 0;",
            "\tif (resolve) {",
            "\t\tif (err || abba.result) {",
            "\t\t\tpr_err(\"%s: failed to resolve ABBA deadlock, A err=%d, B err=%d\\n\",",
            "\t\t\t       __func__, err, abba.result);",
            "\t\t\tret = -EINVAL;",
            "\t\t}",
            "\t} else {",
            "\t\tif (err != -EDEADLK && abba.result != -EDEADLK) {",
            "\t\t\tpr_err(\"%s: missed ABBA deadlock, A err=%d, B err=%d\\n\",",
            "\t\t\t       __func__, err, abba.result);",
            "\t\t\tret = -EINVAL;",
            "\t\t}",
            "\t}",
            "\treturn ret;",
            "}",
            "static void test_cycle_work(struct work_struct *work)",
            "{",
            "\tstruct test_cycle *cycle = container_of(work, typeof(*cycle), work);",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint err, erra = 0;",
            "",
            "\tww_acquire_init_noinject(&ctx, &ww_class);",
            "\tww_mutex_lock(&cycle->a_mutex, &ctx);",
            "",
            "\tcomplete(cycle->a_signal);",
            "\twait_for_completion(&cycle->b_signal);",
            "",
            "\terr = ww_mutex_lock(cycle->b_mutex, &ctx);",
            "\tif (err == -EDEADLK) {",
            "\t\terr = 0;",
            "\t\tww_mutex_unlock(&cycle->a_mutex);",
            "\t\tww_mutex_lock_slow(cycle->b_mutex, &ctx);",
            "\t\terra = ww_mutex_lock(&cycle->a_mutex, &ctx);",
            "\t}",
            "",
            "\tif (!err)",
            "\t\tww_mutex_unlock(cycle->b_mutex);",
            "\tif (!erra)",
            "\t\tww_mutex_unlock(&cycle->a_mutex);",
            "\tww_acquire_fini(&ctx);",
            "",
            "\tcycle->result = err ?: erra;",
            "}"
          ],
          "function_name": "test_abba_work, test_abba, test_cycle_work",
          "description": "测试ABBA死锁场景及环形依赖问题，通过交替顺序加锁模拟死锁条件，验证系统能否检测并解除死锁状态",
          "similarity": 0.6101970672607422
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 489,
          "end_line": 629,
          "content": [
            "static void stress_reorder_work(struct work_struct *work)",
            "{",
            "\tstruct stress *stress = container_of(work, typeof(*stress), work);",
            "\tLIST_HEAD(locks);",
            "\tstruct ww_acquire_ctx ctx;",
            "\tstruct reorder_lock *ll, *ln;",
            "\tint *order;",
            "\tint n, err;",
            "",
            "\torder = get_random_order(stress->nlocks);",
            "\tif (!order)",
            "\t\treturn;",
            "",
            "\tfor (n = 0; n < stress->nlocks; n++) {",
            "\t\tll = kmalloc(sizeof(*ll), GFP_KERNEL);",
            "\t\tif (!ll)",
            "\t\t\tgoto out;",
            "",
            "\t\tll->lock = &stress->locks[order[n]];",
            "\t\tlist_add(&ll->link, &locks);",
            "\t}",
            "\tkfree(order);",
            "\torder = NULL;",
            "",
            "\tdo {",
            "\t\tww_acquire_init(&ctx, &ww_class);",
            "",
            "\t\tlist_for_each_entry(ll, &locks, link) {",
            "\t\t\terr = ww_mutex_lock(ll->lock, &ctx);",
            "\t\t\tif (!err)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tln = ll;",
            "\t\t\tlist_for_each_entry_continue_reverse(ln, &locks, link)",
            "\t\t\t\tww_mutex_unlock(ln->lock);",
            "",
            "\t\t\tif (err != -EDEADLK) {",
            "\t\t\t\tpr_err_once(\"stress (%s) failed with %d\\n\",",
            "\t\t\t\t\t    __func__, err);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "",
            "\t\t\tww_mutex_lock_slow(ll->lock, &ctx);",
            "\t\t\tlist_move(&ll->link, &locks); /* restarts iteration */",
            "\t\t}",
            "",
            "\t\tdummy_load(stress);",
            "\t\tlist_for_each_entry(ll, &locks, link)",
            "\t\t\tww_mutex_unlock(ll->lock);",
            "",
            "\t\tww_acquire_fini(&ctx);",
            "\t} while (!time_after(jiffies, stress->timeout));",
            "",
            "out:",
            "\tlist_for_each_entry_safe(ll, ln, &locks, link)",
            "\t\tkfree(ll);",
            "\tkfree(order);",
            "}",
            "static void stress_one_work(struct work_struct *work)",
            "{",
            "\tstruct stress *stress = container_of(work, typeof(*stress), work);",
            "\tconst int nlocks = stress->nlocks;",
            "\tstruct ww_mutex *lock = stress->locks + get_random_u32_below(nlocks);",
            "\tint err;",
            "",
            "\tdo {",
            "\t\terr = ww_mutex_lock(lock, NULL);",
            "\t\tif (!err) {",
            "\t\t\tdummy_load(stress);",
            "\t\t\tww_mutex_unlock(lock);",
            "\t\t} else {",
            "\t\t\tpr_err_once(\"stress (%s) failed with %d\\n\",",
            "\t\t\t\t    __func__, err);",
            "\t\t\tbreak;",
            "\t\t}",
            "\t} while (!time_after(jiffies, stress->timeout));",
            "}",
            "static int stress(int nlocks, int nthreads, unsigned int flags)",
            "{",
            "\tstruct ww_mutex *locks;",
            "\tstruct stress *stress_array;",
            "\tint n, count;",
            "",
            "\tlocks = kmalloc_array(nlocks, sizeof(*locks), GFP_KERNEL);",
            "\tif (!locks)",
            "\t\treturn -ENOMEM;",
            "",
            "\tstress_array = kmalloc_array(nthreads, sizeof(*stress_array),",
            "\t\t\t\t     GFP_KERNEL);",
            "\tif (!stress_array) {",
            "\t\tkfree(locks);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\tfor (n = 0; n < nlocks; n++)",
            "\t\tww_mutex_init(&locks[n], &ww_class);",
            "",
            "\tcount = 0;",
            "\tfor (n = 0; nthreads; n++) {",
            "\t\tstruct stress *stress;",
            "\t\tvoid (*fn)(struct work_struct *work);",
            "",
            "\t\tfn = NULL;",
            "\t\tswitch (n & 3) {",
            "\t\tcase 0:",
            "\t\t\tif (flags & STRESS_INORDER)",
            "\t\t\t\tfn = stress_inorder_work;",
            "\t\t\tbreak;",
            "\t\tcase 1:",
            "\t\t\tif (flags & STRESS_REORDER)",
            "\t\t\t\tfn = stress_reorder_work;",
            "\t\t\tbreak;",
            "\t\tcase 2:",
            "\t\t\tif (flags & STRESS_ONE)",
            "\t\t\t\tfn = stress_one_work;",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tif (!fn)",
            "\t\t\tcontinue;",
            "",
            "\t\tstress = &stress_array[count++];",
            "",
            "\t\tINIT_WORK(&stress->work, fn);",
            "\t\tstress->locks = locks;",
            "\t\tstress->nlocks = nlocks;",
            "\t\tstress->timeout = jiffies + 2*HZ;",
            "",
            "\t\tqueue_work(wq, &stress->work);",
            "\t\tnthreads--;",
            "\t}",
            "",
            "\tflush_workqueue(wq);",
            "",
            "\tfor (n = 0; n < nlocks; n++)",
            "\t\tww_mutex_destroy(&locks[n]);",
            "\tkfree(stress_array);",
            "\tkfree(locks);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "stress_reorder_work, stress_one_work, stress",
          "description": "实施大规模并发压力测试，支持按序加锁、重排序加锁和单锁测试模式，验证系统在高强度并发下的稳定性与死锁预防能力",
          "similarity": 0.5805813074111938
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 315,
          "end_line": 444,
          "content": [
            "static int __test_cycle(unsigned int nthreads)",
            "{",
            "\tstruct test_cycle *cycles;",
            "\tunsigned int n, last = nthreads - 1;",
            "\tint ret;",
            "",
            "\tcycles = kmalloc_array(nthreads, sizeof(*cycles), GFP_KERNEL);",
            "\tif (!cycles)",
            "\t\treturn -ENOMEM;",
            "",
            "\tfor (n = 0; n < nthreads; n++) {",
            "\t\tstruct test_cycle *cycle = &cycles[n];",
            "",
            "\t\tww_mutex_init(&cycle->a_mutex, &ww_class);",
            "\t\tif (n == last)",
            "\t\t\tcycle->b_mutex = &cycles[0].a_mutex;",
            "\t\telse",
            "\t\t\tcycle->b_mutex = &cycles[n + 1].a_mutex;",
            "",
            "\t\tif (n == 0)",
            "\t\t\tcycle->a_signal = &cycles[last].b_signal;",
            "\t\telse",
            "\t\t\tcycle->a_signal = &cycles[n - 1].b_signal;",
            "\t\tinit_completion(&cycle->b_signal);",
            "",
            "\t\tINIT_WORK(&cycle->work, test_cycle_work);",
            "\t\tcycle->result = 0;",
            "\t}",
            "",
            "\tfor (n = 0; n < nthreads; n++)",
            "\t\tqueue_work(wq, &cycles[n].work);",
            "",
            "\tflush_workqueue(wq);",
            "",
            "\tret = 0;",
            "\tfor (n = 0; n < nthreads; n++) {",
            "\t\tstruct test_cycle *cycle = &cycles[n];",
            "",
            "\t\tif (!cycle->result)",
            "\t\t\tcontinue;",
            "",
            "\t\tpr_err(\"cyclic deadlock not resolved, ret[%d/%d] = %d\\n\",",
            "\t\t       n, nthreads, cycle->result);",
            "\t\tret = -EINVAL;",
            "\t\tbreak;",
            "\t}",
            "",
            "\tfor (n = 0; n < nthreads; n++)",
            "\t\tww_mutex_destroy(&cycles[n].a_mutex);",
            "\tkfree(cycles);",
            "\treturn ret;",
            "}",
            "static int test_cycle(unsigned int ncpus)",
            "{",
            "\tunsigned int n;",
            "\tint ret;",
            "",
            "\tfor (n = 2; n <= ncpus + 1; n++) {",
            "\t\tret = __test_cycle(n);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static inline u32 prandom_u32_below(u32 ceil)",
            "{",
            "\tu32 ret;",
            "",
            "\tspin_lock(&rng_lock);",
            "\tret = prandom_u32_state(&rng) % ceil;",
            "\tspin_unlock(&rng_lock);",
            "\treturn ret;",
            "}",
            "static void dummy_load(struct stress *stress)",
            "{",
            "\tusleep_range(1000, 2000);",
            "}",
            "static void stress_inorder_work(struct work_struct *work)",
            "{",
            "\tstruct stress *stress = container_of(work, typeof(*stress), work);",
            "\tconst int nlocks = stress->nlocks;",
            "\tstruct ww_mutex *locks = stress->locks;",
            "\tstruct ww_acquire_ctx ctx;",
            "\tint *order;",
            "",
            "\torder = get_random_order(nlocks);",
            "\tif (!order)",
            "\t\treturn;",
            "",
            "\tdo {",
            "\t\tint contended = -1;",
            "\t\tint n, err;",
            "",
            "\t\tww_acquire_init(&ctx, &ww_class);",
            "retry:",
            "\t\terr = 0;",
            "\t\tfor (n = 0; n < nlocks; n++) {",
            "\t\t\tif (n == contended)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\terr = ww_mutex_lock(&locks[order[n]], &ctx);",
            "\t\t\tif (err < 0)",
            "\t\t\t\tbreak;",
            "\t\t}",
            "\t\tif (!err)",
            "\t\t\tdummy_load(stress);",
            "",
            "\t\tif (contended > n)",
            "\t\t\tww_mutex_unlock(&locks[order[contended]]);",
            "\t\tcontended = n;",
            "\t\twhile (n--)",
            "\t\t\tww_mutex_unlock(&locks[order[n]]);",
            "",
            "\t\tif (err == -EDEADLK) {",
            "\t\t\tww_mutex_lock_slow(&locks[order[contended]], &ctx);",
            "\t\t\tgoto retry;",
            "\t\t}",
            "",
            "\t\tif (err) {",
            "\t\t\tpr_err_once(\"stress (%s) failed with %d\\n\",",
            "\t\t\t\t    __func__, err);",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tww_acquire_fini(&ctx);",
            "\t} while (!time_after(jiffies, stress->timeout));",
            "",
            "\tkfree(order);",
            "}"
          ],
          "function_name": "__test_cycle, test_cycle, prandom_u32_below, dummy_load, stress_inorder_work",
          "description": "执行多线程环形死锁测试，动态分配资源并模拟复杂锁竞争场景，包含随机数生成和负载控制机制",
          "similarity": 0.5598487854003906
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/locking/test-ww_mutex.c",
          "start_line": 638,
          "end_line": 691,
          "content": [
            "static int __init test_ww_mutex_init(void)",
            "{",
            "\tint ncpus = num_online_cpus();",
            "\tint ret, i;",
            "",
            "\tprintk(KERN_INFO \"Beginning ww mutex selftests\\n\");",
            "",
            "\tprandom_seed_state(&rng, get_random_u64());",
            "",
            "\twq = alloc_workqueue(\"test-ww_mutex\", WQ_UNBOUND, 0);",
            "\tif (!wq)",
            "\t\treturn -ENOMEM;",
            "",
            "\tret = test_mutex();",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = test_aa(false);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = test_aa(true);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tfor (i = 0; i < 4; i++) {",
            "\t\tret = test_abba(i & 1, i & 2);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "\t}",
            "",
            "\tret = test_cycle(ncpus);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = stress(16, 2*ncpus, STRESS_INORDER);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = stress(16, 2*ncpus, STRESS_REORDER);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tret = stress(2047, hweight32(STRESS_ALL)*ncpus, STRESS_ALL);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tprintk(KERN_INFO \"All ww mutex selftests passed\\n\");",
            "\treturn 0;",
            "}",
            "static void __exit test_ww_mutex_exit(void)",
            "{",
            "\tdestroy_workqueue(wq);",
            "}"
          ],
          "function_name": "test_ww_mutex_init, test_ww_mutex_exit",
          "description": "该代码段为ww_mutex子系统的自检模块，通过初始化函数注册并启动多线程测试任务，依次执行mutex、AA锁、ABBA死锁检测及压力测试等场景验证。其中`test_ww_mutex_init`负责创建工作队列并调用系列测试函数，`test_ww_mutex_exit`用于释放资源，但具体测试函数实现未在当前片段中展示，存在上下文缺失。",
          "similarity": 0.4833321273326874
        }
      ]
    }
  ]
}