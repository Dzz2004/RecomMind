{
  "query": "performance tuning techniques",
  "timestamp": "2025-12-26 01:39:32",
  "retrieved_files": [
    {
      "source_file": "kernel/sched/cpufreq_schedutil.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:03:51\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\cpufreq_schedutil.c`\n\n---\n\n# `sched/cpufreq_schedutil.c` 技术文档\n\n## 1. 文件概述\n\n`sched/cpufreq_schedutil.c` 实现了 Linux 内核中基于调度器提供的 CPU 利用率数据的 **schedutil CPUFreq 调速器（governor）**。该调速器通过实时获取调度器计算的 CPU 利用率（包括 CFS、RT、DL 任务以及 I/O 等待状态），动态调整 CPU 频率，以在性能与能效之间取得平衡。其核心优势在于直接利用调度器的 `util` 信息，避免传统调速器依赖采样机制带来的延迟和不准确性。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct sugov_tunables`**  \n  调速器可调参数，包含：\n  - `rate_limit_us`：频率更新的最小时间间隔（微秒），防止过于频繁的频率切换。\n\n- **`struct sugov_policy`**  \n  每个 `cpufreq_policy` 对应的 schedutil 策略实例，包含：\n  - `policy`：关联的 CPUFreq 策略。\n  - `update_lock`：保护频率更新的自旋锁。\n  - `last_freq_update_time` / `freq_update_delay_ns`：控制频率更新速率。\n  - `next_freq` / `cached_raw_freq`：目标频率与原始计算频率缓存。\n  - `irq_work` / `worker` / `thread`：用于慢速切换平台（非 fast-switch）的异步工作队列机制。\n  - `limits_changed` / `need_freq_update`：标志策略限制（如 min/max freq）是否变更。\n\n- **`struct sugov_cpu`**  \n  每个 CPU 的 schedutil 状态，包含：\n  - `update_util`：注册到调度器的回调接口（`update_util_data`）。\n  - `util` / `bw_min`：当前有效利用率及带宽最小值。\n  - `iowait_boost` / `iowait_boost_pending`：I/O 等待唤醒时的频率提升机制。\n  - `last_update`：上次更新时间戳。\n\n### 主要函数\n\n- **`sugov_should_update_freq()`**  \n  判断是否应执行频率更新，考虑硬件是否支持本 CPU 更新、策略限制变更、以及频率更新间隔限制。\n\n- **`sugov_update_next_freq()`**  \n  更新目标频率，处理策略限制变更场景，避免不必要的驱动回调。\n\n- **`get_next_freq()`**  \n  核心频率计算函数，根据 CPU 利用率、最大容量和参考频率，计算目标频率，并通过 `cpufreq_driver_resolve_freq()` 映射到驱动支持的频率。\n\n- **`sugov_get_util()`**  \n  获取当前 CPU 的综合利用率，整合 CFS/RT/DL 任务利用率、boost 值，并调用 `sugov_effective_cpu_perf()` 计算有效性能目标。\n\n- **`sugov_effective_cpu_perf()`**  \n  计算最终的有效性能目标，确保不低于最小性能要求，并限制不超过实际需求。\n\n- **`sugov_iowait_reset()` / `sugov_iowait_boost()`**  \n  实现 I/O 等待唤醒时的动态频率提升机制：短时间内连续 I/O 唤醒会逐步提升 boost 值（从 `IOWAIT_BOOST_MIN` 到最大 OPP），超过一个 tick 无 I/O 唤醒则重置。\n\n- **`get_capacity_ref_freq()`**  \n  获取用于计算 CPU 容量的参考频率，优先使用架构特定的 `arch_scale_freq_ref()`，其次为最大频率或当前频率。\n\n- **`sugov_deferred_update()`**  \n  在不支持 fast-switch 的平台上，通过 `irq_work` 触发异步频率更新。\n\n## 3. 关键实现\n\n### 频率计算算法\n- **频率不变性支持**：若系统支持频率不变调度（`arch_scale_freq_invariant()`），则直接使用调度器提供的频率不变利用率 `util`，按比例计算目标频率：  \n  `next_freq = C * max_freq * util / max`  \n  其中常数 `C = 1.25`，使在 `util/max = 0.8` 时达到 `max_freq`，提供性能余量。\n- **非频率不变性**：使用原始利用率 `util_raw` 乘以 `(curr_freq / max_freq)` 近似频率不变利用率，再计算目标频率。\n\n### I/O 等待 Boost 机制\n- 当任务因 I/O 完成而唤醒时，标记 `SCHED_CPUFREQ_IOWAIT`。\n- 若在 **一个 tick 内** 多次发生 I/O 唤醒，则 `iowait_boost` 值倍增（上限为最大 OPP 对应的利用率）。\n- 若超过一个 tick 无 I/O 唤醒，则重置 boost 值为 `IOWAIT_BOOST_MIN`（`SCHED_CAPACITY_SCALE / 8`），避免对偶发 I/O 过度响应，提升能效。\n\n### 快速切换（Fast-Switch）与异步更新\n- **Fast-Switch 平台**：支持在调度上下文中直接调用 `cpufreq_driver_fast_switch()` 更新频率，延迟最低。\n- **非 Fast-Switch 平台**：通过 `irq_work` 触发内核线程（`kthread_worker`）异步执行频率更新，避免在中断上下文或持有 rq 锁时调用可能阻塞的驱动接口。\n\n### 策略限制变更处理\n- 当用户空间修改 policy 的 min/max 频率时，`sugov_limits()` 设置 `limits_changed` 标志。\n- 下次更新时，强制重新计算频率，并通过内存屏障（`smp_mb()`）确保读取到最新的策略限制。\n\n## 4. 依赖关系\n\n- **调度器子系统**：\n  - 依赖 `update_util_data` 回调机制（通过 `cpufreq_add_update_util_hook()` 注册）。\n  - 调用 `cpu_util_cfs_boost()`、`effective_cpu_util()` 等函数获取综合利用率。\n  - 使用 `scx_cpuperf_target()`（若启用了 SCHED_CLASS_EXT）。\n- **CPUFreq 核心**：\n  - 依赖 `cpufreq_policy`、`cpufreq_driver_resolve_freq()`、`cpufreq_driver_fast_switch()` 等接口。\n  - 使用 `cpufreq_this_cpu_can_update()` 判断硬件更新能力。\n- **架构相关支持**：\n  - 依赖 `arch_scale_freq_ref()` 和 `arch_scale_freq_invariant()` 提供频率不变性信息。\n- **内核基础设施**：\n  - 使用 `irq_work`、`kthread_worker` 实现异步更新。\n  - 依赖 `TICK_NSEC` 定义 tick 时间。\n\n## 5. 使用场景\n\n- **默认高性能能效平衡场景**：现代 Linux 发行版通常将 `schedutil` 作为默认 CPUFreq 调速器，适用于大多数桌面、服务器和移动设备。\n- **实时性要求较高的系统**：由于其低延迟特性（尤其在 fast-switch 平台上），适合对响应时间敏感的应用。\n- **能效敏感设备**：通过 I/O boost 机制和精确的利用率跟踪，在保证交互性能的同时降低空闲功耗。\n- **异构多核系统（如 big.LITTLE）**：结合调度器的 CPU capacity 信息，为不同性能核提供差异化频率调整。",
      "similarity": 0.5480032563209534,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 508,
          "end_line": 651,
          "content": [
            "static void",
            "sugov_update_shared(struct update_util_data *hook, u64 time, unsigned int flags)",
            "{",
            "\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);",
            "\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;",
            "\tunsigned int next_f;",
            "",
            "\traw_spin_lock(&sg_policy->update_lock);",
            "",
            "\tsugov_iowait_boost(sg_cpu, time, flags);",
            "\tsg_cpu->last_update = time;",
            "",
            "\tignore_dl_rate_limit(sg_cpu);",
            "",
            "\tif (sugov_should_update_freq(sg_policy, time)) {",
            "\t\tnext_f = sugov_next_freq_shared(sg_cpu, time);",
            "",
            "\t\tif (!sugov_update_next_freq(sg_policy, time, next_f))",
            "\t\t\tgoto unlock;",
            "",
            "\t\tif (sg_policy->policy->fast_switch_enabled)",
            "\t\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);",
            "\t\telse",
            "\t\t\tsugov_deferred_update(sg_policy);",
            "\t}",
            "unlock:",
            "\traw_spin_unlock(&sg_policy->update_lock);",
            "}",
            "static void sugov_work(struct kthread_work *work)",
            "{",
            "\tstruct sugov_policy *sg_policy = container_of(work, struct sugov_policy, work);",
            "\tunsigned int freq;",
            "\tunsigned long flags;",
            "",
            "\t/*",
            "\t * Hold sg_policy->update_lock shortly to handle the case where:",
            "\t * in case sg_policy->next_freq is read here, and then updated by",
            "\t * sugov_deferred_update() just before work_in_progress is set to false",
            "\t * here, we may miss queueing the new update.",
            "\t *",
            "\t * Note: If a work was queued after the update_lock is released,",
            "\t * sugov_work() will just be called again by kthread_work code; and the",
            "\t * request will be proceed before the sugov thread sleeps.",
            "\t */",
            "\traw_spin_lock_irqsave(&sg_policy->update_lock, flags);",
            "\tfreq = sg_policy->next_freq;",
            "\tsg_policy->work_in_progress = false;",
            "\traw_spin_unlock_irqrestore(&sg_policy->update_lock, flags);",
            "",
            "\tmutex_lock(&sg_policy->work_lock);",
            "\t__cpufreq_driver_target(sg_policy->policy, freq, CPUFREQ_RELATION_L);",
            "\tmutex_unlock(&sg_policy->work_lock);",
            "}",
            "static void sugov_irq_work(struct irq_work *irq_work)",
            "{",
            "\tstruct sugov_policy *sg_policy;",
            "",
            "\tsg_policy = container_of(irq_work, struct sugov_policy, irq_work);",
            "",
            "\tkthread_queue_work(&sg_policy->worker, &sg_policy->work);",
            "}",
            "static ssize_t rate_limit_us_show(struct gov_attr_set *attr_set, char *buf)",
            "{",
            "\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);",
            "",
            "\treturn sprintf(buf, \"%u\\n\", tunables->rate_limit_us);",
            "}",
            "static ssize_t",
            "rate_limit_us_store(struct gov_attr_set *attr_set, const char *buf, size_t count)",
            "{",
            "\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);",
            "\tstruct sugov_policy *sg_policy;",
            "\tunsigned int rate_limit_us;",
            "",
            "\tif (kstrtouint(buf, 10, &rate_limit_us))",
            "\t\treturn -EINVAL;",
            "",
            "\ttunables->rate_limit_us = rate_limit_us;",
            "",
            "\tlist_for_each_entry(sg_policy, &attr_set->policy_list, tunables_hook)",
            "\t\tsg_policy->freq_update_delay_ns = rate_limit_us * NSEC_PER_USEC;",
            "",
            "\treturn count;",
            "}",
            "static void sugov_tunables_free(struct kobject *kobj)",
            "{",
            "\tstruct gov_attr_set *attr_set = to_gov_attr_set(kobj);",
            "",
            "\tkfree(to_sugov_tunables(attr_set));",
            "}",
            "static void sugov_policy_free(struct sugov_policy *sg_policy)",
            "{",
            "\tkfree(sg_policy);",
            "}",
            "static int sugov_kthread_create(struct sugov_policy *sg_policy)",
            "{",
            "\tstruct task_struct *thread;",
            "\tstruct sched_attr attr = {",
            "\t\t.size\t\t= sizeof(struct sched_attr),",
            "\t\t.sched_policy\t= SCHED_DEADLINE,",
            "\t\t.sched_flags\t= SCHED_FLAG_SUGOV,",
            "\t\t.sched_nice\t= 0,",
            "\t\t.sched_priority\t= 0,",
            "\t\t/*",
            "\t\t * Fake (unused) bandwidth; workaround to \"fix\"",
            "\t\t * priority inheritance.",
            "\t\t */",
            "\t\t.sched_runtime\t=  1000000,",
            "\t\t.sched_deadline = 10000000,",
            "\t\t.sched_period\t= 10000000,",
            "\t};",
            "\tstruct cpufreq_policy *policy = sg_policy->policy;",
            "\tint ret;",
            "",
            "\t/* kthread only required for slow path */",
            "\tif (policy->fast_switch_enabled)",
            "\t\treturn 0;",
            "",
            "\tkthread_init_work(&sg_policy->work, sugov_work);",
            "\tkthread_init_worker(&sg_policy->worker);",
            "\tthread = kthread_create(kthread_worker_fn, &sg_policy->worker,",
            "\t\t\t\t\"sugov:%d\",",
            "\t\t\t\tcpumask_first(policy->related_cpus));",
            "\tif (IS_ERR(thread)) {",
            "\t\tpr_err(\"failed to create sugov thread: %ld\\n\", PTR_ERR(thread));",
            "\t\treturn PTR_ERR(thread);",
            "\t}",
            "",
            "\tret = sched_setattr_nocheck(thread, &attr);",
            "\tif (ret) {",
            "\t\tkthread_stop(thread);",
            "\t\tpr_warn(\"%s: failed to set SCHED_DEADLINE\\n\", __func__);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tsg_policy->thread = thread;",
            "\tkthread_bind_mask(thread, policy->related_cpus);",
            "\tinit_irq_work(&sg_policy->irq_work, sugov_irq_work);",
            "\tmutex_init(&sg_policy->work_lock);",
            "",
            "\twake_up_process(thread);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "sugov_update_shared, sugov_work, sugov_irq_work, rate_limit_us_show, rate_limit_us_store, sugov_tunables_free, sugov_policy_free, sugov_kthread_create",
          "description": "管理频率调节的工作线程和参数配置，sugov_kthread_create创建慢速切换场景的后台线程，rate_limit_us_*/提供速率限制配置接口，sugov_work/sugov_irq_work处理异步频率更新任务。",
          "similarity": 0.5908710956573486
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 701,
          "end_line": 809,
          "content": [
            "static void sugov_kthread_stop(struct sugov_policy *sg_policy)",
            "{",
            "\t/* kthread only required for slow path */",
            "\tif (sg_policy->policy->fast_switch_enabled)",
            "\t\treturn;",
            "",
            "\tkthread_flush_worker(&sg_policy->worker);",
            "\tkthread_stop(sg_policy->thread);",
            "\tmutex_destroy(&sg_policy->work_lock);",
            "}",
            "static void sugov_clear_global_tunables(void)",
            "{",
            "\tif (!have_governor_per_policy())",
            "\t\tglobal_tunables = NULL;",
            "}",
            "static int sugov_init(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy;",
            "\tstruct sugov_tunables *tunables;",
            "\tint ret = 0;",
            "",
            "\t/* State should be equivalent to EXIT */",
            "\tif (policy->governor_data)",
            "\t\treturn -EBUSY;",
            "",
            "\tcpufreq_enable_fast_switch(policy);",
            "",
            "\tsg_policy = sugov_policy_alloc(policy);",
            "\tif (!sg_policy) {",
            "\t\tret = -ENOMEM;",
            "\t\tgoto disable_fast_switch;",
            "\t}",
            "",
            "\tret = sugov_kthread_create(sg_policy);",
            "\tif (ret)",
            "\t\tgoto free_sg_policy;",
            "",
            "\tmutex_lock(&global_tunables_lock);",
            "",
            "\tif (global_tunables) {",
            "\t\tif (WARN_ON(have_governor_per_policy())) {",
            "\t\t\tret = -EINVAL;",
            "\t\t\tgoto stop_kthread;",
            "\t\t}",
            "\t\tpolicy->governor_data = sg_policy;",
            "\t\tsg_policy->tunables = global_tunables;",
            "",
            "\t\tgov_attr_set_get(&global_tunables->attr_set, &sg_policy->tunables_hook);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\ttunables = sugov_tunables_alloc(sg_policy);",
            "\tif (!tunables) {",
            "\t\tret = -ENOMEM;",
            "\t\tgoto stop_kthread;",
            "\t}",
            "",
            "\ttunables->rate_limit_us = cpufreq_policy_transition_delay_us(policy);",
            "",
            "\tpolicy->governor_data = sg_policy;",
            "\tsg_policy->tunables = tunables;",
            "",
            "\tret = kobject_init_and_add(&tunables->attr_set.kobj, &sugov_tunables_ktype,",
            "\t\t\t\t   get_governor_parent_kobj(policy), \"%s\",",
            "\t\t\t\t   schedutil_gov.name);",
            "\tif (ret)",
            "\t\tgoto fail;",
            "",
            "out:",
            "\tmutex_unlock(&global_tunables_lock);",
            "\treturn 0;",
            "",
            "fail:",
            "\tkobject_put(&tunables->attr_set.kobj);",
            "\tpolicy->governor_data = NULL;",
            "\tsugov_clear_global_tunables();",
            "",
            "stop_kthread:",
            "\tsugov_kthread_stop(sg_policy);",
            "\tmutex_unlock(&global_tunables_lock);",
            "",
            "free_sg_policy:",
            "\tsugov_policy_free(sg_policy);",
            "",
            "disable_fast_switch:",
            "\tcpufreq_disable_fast_switch(policy);",
            "",
            "\tpr_err(\"initialization failed (error %d)\\n\", ret);",
            "\treturn ret;",
            "}",
            "static void sugov_exit(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy = policy->governor_data;",
            "\tstruct sugov_tunables *tunables = sg_policy->tunables;",
            "\tunsigned int count;",
            "",
            "\tmutex_lock(&global_tunables_lock);",
            "",
            "\tcount = gov_attr_set_put(&tunables->attr_set, &sg_policy->tunables_hook);",
            "\tpolicy->governor_data = NULL;",
            "\tif (!count)",
            "\t\tsugov_clear_global_tunables();",
            "",
            "\tmutex_unlock(&global_tunables_lock);",
            "",
            "\tsugov_kthread_stop(sg_policy);",
            "\tsugov_policy_free(sg_policy);",
            "\tcpufreq_disable_fast_switch(policy);",
            "}"
          ],
          "function_name": "sugov_kthread_stop, sugov_clear_global_tunables, sugov_init, sugov_exit",
          "description": "sugov_kthread_stop 停止慢速路径相关内核线程并释放锁资源；sugov_clear_global_tunables 清除全局调谐参数指针；sugov_init 初始化CPU频率策略模块，分配策略结构体并创建内核线程；sugov_exit 释放策略资源，停止线程并禁用快速切换功能",
          "similarity": 0.5732039213180542
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 827,
          "end_line": 916,
          "content": [
            "static int sugov_start(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy = policy->governor_data;",
            "\tvoid (*uu)(struct update_util_data *data, u64 time, unsigned int flags);",
            "\tunsigned int cpu;",
            "",
            "\tsg_policy->freq_update_delay_ns\t= sg_policy->tunables->rate_limit_us * NSEC_PER_USEC;",
            "\tsg_policy->last_freq_update_time\t= 0;",
            "\tsg_policy->next_freq\t\t\t= 0;",
            "\tsg_policy->work_in_progress\t\t= false;",
            "\tsg_policy->limits_changed\t\t= false;",
            "\tsg_policy->cached_raw_freq\t\t= 0;",
            "",
            "\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);",
            "",
            "\tfor_each_cpu(cpu, policy->cpus) {",
            "\t\tstruct sugov_cpu *sg_cpu = &per_cpu(sugov_cpu, cpu);",
            "",
            "\t\tmemset(sg_cpu, 0, sizeof(*sg_cpu));",
            "\t\tsg_cpu->cpu\t\t\t= cpu;",
            "\t\tsg_cpu->sg_policy\t\t= sg_policy;",
            "\t}",
            "",
            "\tif (policy_is_shared(policy))",
            "\t\tuu = sugov_update_shared;",
            "\telse if (policy->fast_switch_enabled && cpufreq_driver_has_adjust_perf())",
            "\t\tuu = sugov_update_single_perf;",
            "\telse",
            "\t\tuu = sugov_update_single_freq;",
            "",
            "\tfor_each_cpu(cpu, policy->cpus) {",
            "\t\tstruct sugov_cpu *sg_cpu = &per_cpu(sugov_cpu, cpu);",
            "",
            "\t\tcpufreq_add_update_util_hook(cpu, &sg_cpu->update_util, uu);",
            "\t}",
            "\treturn 0;",
            "}",
            "static void sugov_stop(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy = policy->governor_data;",
            "\tunsigned int cpu;",
            "",
            "\tfor_each_cpu(cpu, policy->cpus)",
            "\t\tcpufreq_remove_update_util_hook(cpu);",
            "",
            "\tsynchronize_rcu();",
            "",
            "\tif (!policy->fast_switch_enabled) {",
            "\t\tirq_work_sync(&sg_policy->irq_work);",
            "\t\tkthread_cancel_work_sync(&sg_policy->work);",
            "\t}",
            "}",
            "static void sugov_limits(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy = policy->governor_data;",
            "",
            "\tif (!policy->fast_switch_enabled) {",
            "\t\tmutex_lock(&sg_policy->work_lock);",
            "\t\tcpufreq_policy_apply_limits(policy);",
            "\t\tmutex_unlock(&sg_policy->work_lock);",
            "\t}",
            "",
            "\t/*",
            "\t * The limits_changed update below must take place before the updates",
            "\t * of policy limits in cpufreq_set_policy() or a policy limits update",
            "\t * might be missed, so use a memory barrier to ensure it.",
            "\t *",
            "\t * This pairs with the memory barrier in sugov_should_update_freq().",
            "\t */",
            "\tsmp_wmb();",
            "",
            "\tWRITE_ONCE(sg_policy->limits_changed, true);",
            "}",
            "static void rebuild_sd_workfn(struct work_struct *work)",
            "{",
            "\trebuild_sched_domains_energy();",
            "}",
            "void sched_cpufreq_governor_change(struct cpufreq_policy *policy,",
            "\t\t\t\t  struct cpufreq_governor *old_gov)",
            "{",
            "\tif (old_gov == &schedutil_gov || policy->governor == &schedutil_gov) {",
            "\t\t/*",
            "\t\t * When called from the cpufreq_register_driver() path, the",
            "\t\t * cpu_hotplug_lock is already held, so use a work item to",
            "\t\t * avoid nested locking in rebuild_sched_domains().",
            "\t\t */",
            "\t\tschedule_work(&rebuild_sd_work);",
            "\t}",
            "",
            "}"
          ],
          "function_name": "sugov_start, sugov_stop, sugov_limits, rebuild_sd_workfn, sched_cpufreq_governor_change",
          "description": "sugov_start 注册CPU利用率更新钩子函数并初始化频率更新参数；sugov_stop 移除所有CPU的更新钩子并同步RCU状态；sugov_limits 应用频率限制并标记策略变更；rebuild_sd_workfn 触发调度域能量重新构建；sched_cpufreq_governor_change 在策略切换时安排调度域重建工作",
          "similarity": 0.5584977269172668
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 62,
          "end_line": 168,
          "content": [
            "static bool sugov_should_update_freq(struct sugov_policy *sg_policy, u64 time)",
            "{",
            "\ts64 delta_ns;",
            "",
            "\t/*",
            "\t * Since cpufreq_update_util() is called with rq->lock held for",
            "\t * the @target_cpu, our per-CPU data is fully serialized.",
            "\t *",
            "\t * However, drivers cannot in general deal with cross-CPU",
            "\t * requests, so while get_next_freq() will work, our",
            "\t * sugov_update_commit() call may not for the fast switching platforms.",
            "\t *",
            "\t * Hence stop here for remote requests if they aren't supported",
            "\t * by the hardware, as calculating the frequency is pointless if",
            "\t * we cannot in fact act on it.",
            "\t *",
            "\t * This is needed on the slow switching platforms too to prevent CPUs",
            "\t * going offline from leaving stale IRQ work items behind.",
            "\t */",
            "\tif (!cpufreq_this_cpu_can_update(sg_policy->policy))",
            "\t\treturn false;",
            "",
            "\tif (unlikely(READ_ONCE(sg_policy->limits_changed))) {",
            "\t\tWRITE_ONCE(sg_policy->limits_changed, false);",
            "\t\tsg_policy->need_freq_update = true;",
            "",
            "\t\t/*",
            "\t\t * The above limits_changed update must occur before the reads",
            "\t\t * of policy limits in cpufreq_driver_resolve_freq() or a policy",
            "\t\t * limits update might be missed, so use a memory barrier to",
            "\t\t * ensure it.",
            "\t\t *",
            "\t\t * This pairs with the write memory barrier in sugov_limits().",
            "\t\t */",
            "\t\tsmp_mb();",
            "",
            "\t\treturn true;",
            "\t}",
            "",
            "\tdelta_ns = time - sg_policy->last_freq_update_time;",
            "",
            "\treturn delta_ns >= sg_policy->freq_update_delay_ns;",
            "}",
            "static bool sugov_update_next_freq(struct sugov_policy *sg_policy, u64 time,",
            "\t\t\t\t   unsigned int next_freq)",
            "{",
            "\tif (sg_policy->need_freq_update) {",
            "\t\tsg_policy->need_freq_update = false;",
            "\t\t/*",
            "\t\t * The policy limits have changed, but if the return value of",
            "\t\t * cpufreq_driver_resolve_freq() after applying the new limits",
            "\t\t * is still equal to the previously selected frequency, the",
            "\t\t * driver callback need not be invoked unless the driver",
            "\t\t * specifically wants that to happen on every update of the",
            "\t\t * policy limits.",
            "\t\t */",
            "\t\tif (sg_policy->next_freq == next_freq &&",
            "\t\t    !cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS))",
            "\t\t\treturn false;",
            "\t} else if (sg_policy->next_freq == next_freq) {",
            "\t\treturn false;",
            "\t}",
            "",
            "\tsg_policy->next_freq = next_freq;",
            "\tsg_policy->last_freq_update_time = time;",
            "",
            "\treturn true;",
            "}",
            "static void sugov_deferred_update(struct sugov_policy *sg_policy)",
            "{",
            "\tif (!sg_policy->work_in_progress) {",
            "\t\tsg_policy->work_in_progress = true;",
            "\t\tirq_work_queue(&sg_policy->irq_work);",
            "\t}",
            "}",
            "static __always_inline",
            "unsigned long get_capacity_ref_freq(struct cpufreq_policy *policy)",
            "{",
            "\tunsigned int freq = arch_scale_freq_ref(policy->cpu);",
            "",
            "\tif (freq)",
            "\t\treturn freq;",
            "",
            "\tif (arch_scale_freq_invariant())",
            "\t\treturn policy->cpuinfo.max_freq;",
            "",
            "\t/*",
            "\t * Apply a 25% margin so that we select a higher frequency than",
            "\t * the current one before the CPU is fully busy:",
            "\t */",
            "\treturn policy->cur + (policy->cur >> 2);",
            "}",
            "static unsigned int get_next_freq(struct sugov_policy *sg_policy,",
            "\t\t\t\t  unsigned long util, unsigned long max)",
            "{",
            "\tstruct cpufreq_policy *policy = sg_policy->policy;",
            "\tunsigned int freq;",
            "",
            "\tfreq = get_capacity_ref_freq(policy);",
            "\tfreq = map_util_freq(util, freq, max);",
            "",
            "\tif (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)",
            "\t\treturn sg_policy->next_freq;",
            "",
            "\tsg_policy->cached_raw_freq = freq;",
            "\treturn cpufreq_driver_resolve_freq(policy, freq);",
            "}"
          ],
          "function_name": "sugov_should_update_freq, sugov_update_next_freq, sugov_deferred_update, get_capacity_ref_freq, get_next_freq",
          "description": "实现了频率更新核心逻辑，sugov_should_update_freq判断是否需要更新频率，sugov_update_next_freq计算并记录目标频率，sugov_deferred_update触发异步更新，get_capacity_ref_freq获取基准频率，get_next_freq结合利用率计算最终目标频率。",
          "similarity": 0.5511959791183472
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 381,
          "end_line": 496,
          "content": [
            "static inline bool sugov_hold_freq(struct sugov_cpu *sg_cpu) { return false; }",
            "static inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu)",
            "{",
            "\tif (cpu_bw_dl(cpu_rq(sg_cpu->cpu)) > sg_cpu->bw_min)",
            "\t\tWRITE_ONCE(sg_cpu->sg_policy->limits_changed, true);",
            "}",
            "static inline bool sugov_update_single_common(struct sugov_cpu *sg_cpu,",
            "\t\t\t\t\t      u64 time, unsigned long max_cap,",
            "\t\t\t\t\t      unsigned int flags)",
            "{",
            "\tunsigned long boost;",
            "",
            "\tsugov_iowait_boost(sg_cpu, time, flags);",
            "\tsg_cpu->last_update = time;",
            "",
            "\tignore_dl_rate_limit(sg_cpu);",
            "",
            "\tif (!sugov_should_update_freq(sg_cpu->sg_policy, time))",
            "\t\treturn false;",
            "",
            "\tboost = sugov_iowait_apply(sg_cpu, time, max_cap);",
            "\tsugov_get_util(sg_cpu, boost);",
            "",
            "\treturn true;",
            "}",
            "static void sugov_update_single_freq(struct update_util_data *hook, u64 time,",
            "\t\t\t\t     unsigned int flags)",
            "{",
            "\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);",
            "\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;",
            "\tunsigned int cached_freq = sg_policy->cached_raw_freq;",
            "\tunsigned long max_cap;",
            "\tunsigned int next_f;",
            "",
            "\tmax_cap = arch_scale_cpu_capacity(sg_cpu->cpu);",
            "",
            "\tif (!sugov_update_single_common(sg_cpu, time, max_cap, flags))",
            "\t\treturn;",
            "",
            "\tnext_f = get_next_freq(sg_policy, sg_cpu->util, max_cap);",
            "",
            "\tif (sugov_hold_freq(sg_cpu) && next_f < sg_policy->next_freq &&",
            "\t    !sg_policy->need_freq_update) {",
            "\t\tnext_f = sg_policy->next_freq;",
            "",
            "\t\t/* Restore cached freq as next_freq has changed */",
            "\t\tsg_policy->cached_raw_freq = cached_freq;",
            "\t}",
            "",
            "\tif (!sugov_update_next_freq(sg_policy, time, next_f))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * This code runs under rq->lock for the target CPU, so it won't run",
            "\t * concurrently on two different CPUs for the same target and it is not",
            "\t * necessary to acquire the lock in the fast switch case.",
            "\t */",
            "\tif (sg_policy->policy->fast_switch_enabled) {",
            "\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);",
            "\t} else {",
            "\t\traw_spin_lock(&sg_policy->update_lock);",
            "\t\tsugov_deferred_update(sg_policy);",
            "\t\traw_spin_unlock(&sg_policy->update_lock);",
            "\t}",
            "}",
            "static void sugov_update_single_perf(struct update_util_data *hook, u64 time,",
            "\t\t\t\t     unsigned int flags)",
            "{",
            "\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);",
            "\tunsigned long prev_util = sg_cpu->util;",
            "\tunsigned long max_cap;",
            "",
            "\t/*",
            "\t * Fall back to the \"frequency\" path if frequency invariance is not",
            "\t * supported, because the direct mapping between the utilization and",
            "\t * the performance levels depends on the frequency invariance.",
            "\t */",
            "\tif (!arch_scale_freq_invariant()) {",
            "\t\tsugov_update_single_freq(hook, time, flags);",
            "\t\treturn;",
            "\t}",
            "",
            "\tmax_cap = arch_scale_cpu_capacity(sg_cpu->cpu);",
            "",
            "\tif (!sugov_update_single_common(sg_cpu, time, max_cap, flags))",
            "\t\treturn;",
            "",
            "\tif (sugov_hold_freq(sg_cpu) && sg_cpu->util < prev_util)",
            "\t\tsg_cpu->util = prev_util;",
            "",
            "\tcpufreq_driver_adjust_perf(sg_cpu->cpu, sg_cpu->bw_min,",
            "\t\t\t\t   sg_cpu->util, max_cap);",
            "",
            "\tsg_cpu->sg_policy->last_freq_update_time = time;",
            "}",
            "static unsigned int sugov_next_freq_shared(struct sugov_cpu *sg_cpu, u64 time)",
            "{",
            "\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;",
            "\tstruct cpufreq_policy *policy = sg_policy->policy;",
            "\tunsigned long util = 0, max_cap;",
            "\tunsigned int j;",
            "",
            "\tmax_cap = arch_scale_cpu_capacity(sg_cpu->cpu);",
            "",
            "\tfor_each_cpu(j, policy->cpus) {",
            "\t\tstruct sugov_cpu *j_sg_cpu = &per_cpu(sugov_cpu, j);",
            "\t\tunsigned long boost;",
            "",
            "\t\tboost = sugov_iowait_apply(j_sg_cpu, time, max_cap);",
            "\t\tsugov_get_util(j_sg_cpu, boost);",
            "",
            "\t\tutil = max(j_sg_cpu->util, util);",
            "\t}",
            "",
            "\treturn get_next_freq(sg_policy, util, max_cap);",
            "}"
          ],
          "function_name": "sugov_hold_freq, ignore_dl_rate_limit, sugov_update_single_common, sugov_update_single_freq, sugov_update_single_perf, sugov_next_freq_shared",
          "description": "实现单核/多核频率调整逻辑，sugov_update_single_freq处理单核频率更新，sugov_update_single_perf处理性能调优路径，sugov_next_freq_shared计算多核共享场景下的全局目标频率。",
          "similarity": 0.5475124716758728
        }
      ]
    },
    {
      "source_file": "kernel/time/tick-sched.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:51:52\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `time\\tick-sched.c`\n\n---\n\n# `time/tick-sched.c` 技术文档\n\n## 1. 文件概述\n\n`tick-sched.c` 是 Linux 内核中实现 **无滴答（tickless）调度** 的核心文件，主要用于支持 **NO_HZ（无周期性时钟中断）** 功能。该机制允许系统在空闲或特定负载条件下动态停止周期性的时钟中断（tick），从而降低功耗、减少 CPU 干扰，并提升实时性能。文件同时支持 **低分辨率定时器（NO_HZ_COMMON）** 和 **高分辨率定时器（HIGH_RES_TIMERS）** 场景下的无滴答行为。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct tick_sched`  \n  每个 CPU 的无滴答调度控制结构，记录当前 CPU 的 tick 状态，包括是否处于空闲、tick 是否已停止、依赖项、空闲 jiffies 计数等。\n\n- `tick_cpu_sched`（per-CPU 变量）  \n  每个 CPU 对应的 `tick_sched` 实例。\n\n- `last_jiffies_update`（全局）  \n  记录上一次 jiffies 更新的时间点，用于在无滴答期间计算应推进的 jiffies 数量。\n\n- `tick_nohz_full_mask`（仅 CONFIG_NO_HZ_FULL）  \n  标识启用了 **完全无滴答（NO_HZ_FULL）** 模式的 CPU 集合。\n\n- `tick_dep_mask`（原子变量，仅 CONFIG_NO_HZ_FULL）  \n  全局 tick 依赖掩码，用于跟踪系统级阻止 tick 停止的原因（如 POSIX 定时器、RCU、调度器等）。\n\n### 主要函数\n\n- `tick_get_tick_sched(int cpu)`  \n  获取指定 CPU 的 `tick_sched` 结构指针。\n\n- `tick_do_update_jiffies64(ktime_t now)`  \n  在无滴答模式下，根据当前时间 `now` 计算并更新全局 `jiffies_64` 值，确保时间推进的准确性。支持 32/64 位架构的内存序优化。\n\n- `tick_init_jiffy_update(void)`  \n  初始化 jiffies 更新机制，确保 `last_jiffies_update` 与 `TICK_NSEC` 对齐。\n\n- `tick_sched_do_timer(struct tick_sched *ts, ktime_t now)`  \n  处理与全局时间维护相关的逻辑，包括：\n  - 在 `tick_do_timer_cpu` 为 `NONE` 时接管 jiffies 更新职责；\n  - 调用 `tick_do_update_jiffies64()`；\n  - 检测 jiffies 更新是否停滞（如因虚拟机暂停），并在停滞过久时强制更新。\n\n- `tick_sched_handle(struct tick_sched *ts, struct pt_regs *regs)`  \n  处理每个 tick 中断的常规任务，包括：\n  - 更新进程时间统计（`update_process_times`）；\n  - 触发性能剖析（`profile_tick`）；\n  - 在 tick 停止期间维护软锁定看门狗（`touch_softlockup_watchdog_sched`）；\n  - 更新空闲任务的 jiffies 计数。\n\n- `check_tick_dependency(atomic_t *dep)`  \n  （仅 CONFIG_NO_HZ_FULL）检查 tick 依赖掩码，判断是否存在阻止 tick 停止的条件（如 POSIX 定时器、RCU、调度器活动等）。\n\n- `can_stop_full_tick(int cpu, struct tick_sched *ts)`  \n  （片段未完整）用于判断在 NO_HZ_FULL 模式下是否可以安全停止指定 CPU 的 tick。\n\n## 3. 关键实现\n\n### 无滴答 Jiffies 更新机制\n\n- 使用 `jiffies_lock` 和 `jiffies_seq`（顺序锁）保护 `jiffies_64` 和 `last_jiffies_update` 的更新。\n- 在 64 位系统上，通过 `smp_load_acquire()` / `smp_store_release()` 实现无锁快速路径检查，避免不必要的锁竞争。\n- 在 32 位系统上，由于 64 位变量非原子写入，必须通过 `seqcount` 保证读取一致性。\n- 支持“慢路径”处理：当系统长时间睡眠（delta ≥ TICK_NSEC），通过除法计算应推进的 tick 数量。\n\n### Jiffies 停滞检测\n\n- 通过 `ts->last_tick_jiffies` 和 `ts->stalled_jiffies` 跟踪 jiffies 是否长时间未更新。\n- 若连续 `MAX_STALLED_JIFFIES`（默认 5）次未更新，则强制调用 `tick_do_update_jiffies64()`，防止时间漂移（如虚拟机暂停或 stop_machine 场景）。\n\n### NO_HZ_FULL 依赖管理\n\n- 使用位掩码（`TICK_DEP_MASK_*`）标识阻止 tick 停止的原因。\n- 每次尝试停止 tick 前，检查全局和 per-CPU 的依赖掩码。\n- 通过 tracepoint `trace_tick_stop()` 记录阻止原因，便于调试。\n\n### 空闲状态处理\n\n- 当 `tick_stopped` 为真时（即处于无滴答空闲状态）：\n  - 调用 `touch_softlockup_watchdog_sched()` 防止软锁定误报；\n  - 若当前任务为空闲任务，则递增 `ts->idle_jiffies`，用于后续空闲时间统计校正；\n  - 重置 `ts->next_tick = 0`，确保下次 tick 编程不会跳过。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/hrtimer.h>`：高分辨率定时器支持。\n  - `<linux/sched/nohz.h>`：NO_HZ 相关调度接口。\n  - `<linux/sched/clock.h>`、`<linux/kernel_stat.h>`：时间与统计信息。\n  - `<linux/seqlock.h>`（隐含）：通过 `jiffies_seq` 实现顺序锁。\n  - `\"tick-internal.h\"`：内部 tick 管理函数和变量（如 `tick_next_period`, `tick_do_timer_cpu`）。\n\n- **内核子系统交互**：\n  - **时间子系统**：与 `timekeeping.c` 协同更新 `wall_time`（通过 `update_wall_time()`）。\n  - **调度器**：通过 `update_process_times()` 更新进程 CPU 时间。\n  - **RCU**：NO_HZ_FULL 模式下需确保 RCU 宽限期推进。\n  - **性能剖析**：触发 `CPU_PROFILING` 事件。\n  - **软锁定检测**：维护看门狗状态。\n\n## 5. 使用场景\n\n- **移动/嵌入式设备**：在 CPU 空闲时停止 tick，显著降低功耗。\n- **高性能计算/实时系统**：减少周期性中断对关键任务的干扰，提升确定性（尤其在 NO_HZ_FULL 模式下）。\n- **虚拟化环境**：处理 VM 暂停导致的长时间无 tick 场景，通过停滞检测机制恢复时间同步。\n- **服务器负载波动**：在低负载期间进入无滴答状态，提升能效比。\n- **内核调试与追踪**：通过 `trace_tick_stop` 等 tracepoint 分析 tick 停止失败原因。",
      "similarity": 0.5372434258460999,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/time/tick-sched.c",
          "start_line": 303,
          "end_line": 407,
          "content": [
            "static bool can_stop_full_tick(int cpu, struct tick_sched *ts)",
            "{",
            "\tlockdep_assert_irqs_disabled();",
            "",
            "\tif (unlikely(!cpu_online(cpu)))",
            "\t\treturn false;",
            "",
            "\tif (check_tick_dependency(&tick_dep_mask))",
            "\t\treturn false;",
            "",
            "\tif (check_tick_dependency(&ts->tick_dep_mask))",
            "\t\treturn false;",
            "",
            "\tif (check_tick_dependency(&current->tick_dep_mask))",
            "\t\treturn false;",
            "",
            "\tif (check_tick_dependency(&current->signal->tick_dep_mask))",
            "\t\treturn false;",
            "",
            "\treturn true;",
            "}",
            "static void nohz_full_kick_func(struct irq_work *work)",
            "{",
            "\t/* Empty, the tick restart happens on tick_nohz_irq_exit() */",
            "}",
            "static void tick_nohz_full_kick(void)",
            "{",
            "\tif (!tick_nohz_full_cpu(smp_processor_id()))",
            "\t\treturn;",
            "",
            "\tirq_work_queue(this_cpu_ptr(&nohz_full_kick_work));",
            "}",
            "void tick_nohz_full_kick_cpu(int cpu)",
            "{",
            "\tif (!tick_nohz_full_cpu(cpu))",
            "\t\treturn;",
            "",
            "\tirq_work_queue_on(&per_cpu(nohz_full_kick_work, cpu), cpu);",
            "}",
            "static void tick_nohz_kick_task(struct task_struct *tsk)",
            "{",
            "\tint cpu;",
            "",
            "\t/*",
            "\t * If the task is not running, run_posix_cpu_timers()",
            "\t * has nothing to elapse, IPI can then be spared.",
            "\t *",
            "\t * activate_task()                      STORE p->tick_dep_mask",
            "\t *   STORE p->on_rq",
            "\t * __schedule() (switch to task 'p')    smp_mb() (atomic_fetch_or())",
            "\t *   LOCK rq->lock                      LOAD p->on_rq",
            "\t *   smp_mb__after_spin_lock()",
            "\t *   tick_nohz_task_switch()",
            "\t *     LOAD p->tick_dep_mask",
            "\t *",
            "\t * XXX given a task picks up the dependency on schedule(), should we",
            "\t * only care about tasks that are currently on the CPU instead of all",
            "\t * that are on the runqueue?",
            "\t *",
            "\t * That is, does this want to be: task_on_cpu() / task_curr()?",
            "\t */",
            "\tif (!sched_task_on_rq(tsk))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If the task concurrently migrates to another CPU,",
            "\t * we guarantee it sees the new tick dependency upon",
            "\t * schedule.",
            "\t *",
            "\t * set_task_cpu(p, cpu);",
            "\t *   STORE p->cpu = @cpu",
            "\t * __schedule() (switch to task 'p')",
            "\t *   LOCK rq->lock",
            "\t *   smp_mb__after_spin_lock()          STORE p->tick_dep_mask",
            "\t *   tick_nohz_task_switch()            smp_mb() (atomic_fetch_or())",
            "\t *      LOAD p->tick_dep_mask           LOAD p->cpu",
            "\t */",
            "\tcpu = task_cpu(tsk);",
            "",
            "\tpreempt_disable();",
            "\tif (cpu_online(cpu))",
            "\t\ttick_nohz_full_kick_cpu(cpu);",
            "\tpreempt_enable();",
            "}",
            "static void tick_nohz_full_kick_all(void)",
            "{",
            "\tint cpu;",
            "",
            "\tif (!tick_nohz_full_running)",
            "\t\treturn;",
            "",
            "\tpreempt_disable();",
            "\tfor_each_cpu_and(cpu, tick_nohz_full_mask, cpu_online_mask)",
            "\t\ttick_nohz_full_kick_cpu(cpu);",
            "\tpreempt_enable();",
            "}",
            "static void tick_nohz_dep_set_all(atomic_t *dep,",
            "\t\t\t\t  enum tick_dep_bits bit)",
            "{",
            "\tint prev;",
            "",
            "\tprev = atomic_fetch_or(BIT(bit), dep);",
            "\tif (!prev)",
            "\t\ttick_nohz_full_kick_all();",
            "}"
          ],
          "function_name": "can_stop_full_tick, nohz_full_kick_func, tick_nohz_full_kick, tick_nohz_full_kick_cpu, tick_nohz_kick_task, tick_nohz_full_kick_all, tick_nohz_dep_set_all",
          "description": "实现nohz_full模式下tick重启的控制逻辑，通过irq_work机制在安全上下文唤醒tick处理，管理CPU亲和性约束",
          "similarity": 0.5207103490829468
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/time/tick-sched.c",
          "start_line": 1,
          "end_line": 56,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " *  Copyright(C) 2005-2006, Thomas Gleixner <tglx@linutronix.de>",
            " *  Copyright(C) 2005-2007, Red Hat, Inc., Ingo Molnar",
            " *  Copyright(C) 2006-2007  Timesys Corp., Thomas Gleixner",
            " *",
            " *  No idle tick implementation for low and high resolution timers",
            " *",
            " *  Started by: Thomas Gleixner and Ingo Molnar",
            " */",
            "#include <linux/cpu.h>",
            "#include <linux/err.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/percpu.h>",
            "#include <linux/nmi.h>",
            "#include <linux/profile.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/module.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/mm.h>",
            "",
            "#include <asm/irq_regs.h>",
            "",
            "#include \"tick-internal.h\"",
            "",
            "#include <trace/events/timer.h>",
            "",
            "/*",
            " * Per-CPU nohz control structure",
            " */",
            "static DEFINE_PER_CPU(struct tick_sched, tick_cpu_sched);",
            "",
            "struct tick_sched *tick_get_tick_sched(int cpu)",
            "{",
            "\treturn &per_cpu(tick_cpu_sched, cpu);",
            "}",
            "",
            "#if defined(CONFIG_NO_HZ_COMMON) || defined(CONFIG_HIGH_RES_TIMERS)",
            "/*",
            " * The time, when the last jiffy update happened. Write access must hold",
            " * jiffies_lock and jiffies_seq. tick_nohz_next_event() needs to get a",
            " * consistent view of jiffies and last_jiffies_update.",
            " */",
            "static ktime_t last_jiffies_update;",
            "",
            "/*",
            " * Must be called with interrupts disabled !",
            " */"
          ],
          "function_name": null,
          "description": "定义Per-CPU的tick_sched结构体及辅助函数，用于管理动态tick调度器的基础框架，包含对nohz_common和high_res_timers的支持",
          "similarity": 0.5206595659255981
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/time/tick-sched.c",
          "start_line": 436,
          "end_line": 574,
          "content": [
            "void tick_nohz_dep_set(enum tick_dep_bits bit)",
            "{",
            "\ttick_nohz_dep_set_all(&tick_dep_mask, bit);",
            "}",
            "void tick_nohz_dep_clear(enum tick_dep_bits bit)",
            "{",
            "\tatomic_andnot(BIT(bit), &tick_dep_mask);",
            "}",
            "void tick_nohz_dep_set_cpu(int cpu, enum tick_dep_bits bit)",
            "{",
            "\tint prev;",
            "\tstruct tick_sched *ts;",
            "",
            "\tts = per_cpu_ptr(&tick_cpu_sched, cpu);",
            "",
            "\tprev = atomic_fetch_or(BIT(bit), &ts->tick_dep_mask);",
            "\tif (!prev) {",
            "\t\tpreempt_disable();",
            "\t\t/* Perf needs local kick that is NMI safe */",
            "\t\tif (cpu == smp_processor_id()) {",
            "\t\t\ttick_nohz_full_kick();",
            "\t\t} else {",
            "\t\t\t/* Remote irq work not NMI-safe */",
            "\t\t\tif (!WARN_ON_ONCE(in_nmi()))",
            "\t\t\t\ttick_nohz_full_kick_cpu(cpu);",
            "\t\t}",
            "\t\tpreempt_enable();",
            "\t}",
            "}",
            "void tick_nohz_dep_clear_cpu(int cpu, enum tick_dep_bits bit)",
            "{",
            "\tstruct tick_sched *ts = per_cpu_ptr(&tick_cpu_sched, cpu);",
            "",
            "\tatomic_andnot(BIT(bit), &ts->tick_dep_mask);",
            "}",
            "void tick_nohz_dep_set_task(struct task_struct *tsk, enum tick_dep_bits bit)",
            "{",
            "\tif (!atomic_fetch_or(BIT(bit), &tsk->tick_dep_mask))",
            "\t\ttick_nohz_kick_task(tsk);",
            "}",
            "void tick_nohz_dep_clear_task(struct task_struct *tsk, enum tick_dep_bits bit)",
            "{",
            "\tatomic_andnot(BIT(bit), &tsk->tick_dep_mask);",
            "}",
            "void tick_nohz_dep_set_signal(struct task_struct *tsk,",
            "\t\t\t      enum tick_dep_bits bit)",
            "{",
            "\tint prev;",
            "\tstruct signal_struct *sig = tsk->signal;",
            "",
            "\tprev = atomic_fetch_or(BIT(bit), &sig->tick_dep_mask);",
            "\tif (!prev) {",
            "\t\tstruct task_struct *t;",
            "",
            "\t\tlockdep_assert_held(&tsk->sighand->siglock);",
            "\t\t__for_each_thread(sig, t)",
            "\t\t\ttick_nohz_kick_task(t);",
            "\t}",
            "}",
            "void tick_nohz_dep_clear_signal(struct signal_struct *sig, enum tick_dep_bits bit)",
            "{",
            "\tatomic_andnot(BIT(bit), &sig->tick_dep_mask);",
            "}",
            "void __tick_nohz_task_switch(void)",
            "{",
            "\tstruct tick_sched *ts;",
            "",
            "\tif (!tick_nohz_full_cpu(smp_processor_id()))",
            "\t\treturn;",
            "",
            "\tts = this_cpu_ptr(&tick_cpu_sched);",
            "",
            "\tif (ts->tick_stopped) {",
            "\t\tif (atomic_read(&current->tick_dep_mask) ||",
            "\t\t    atomic_read(&current->signal->tick_dep_mask))",
            "\t\t\ttick_nohz_full_kick();",
            "\t}",
            "}",
            "void __init tick_nohz_full_setup(cpumask_var_t cpumask)",
            "{",
            "\talloc_bootmem_cpumask_var(&tick_nohz_full_mask);",
            "\tcpumask_copy(tick_nohz_full_mask, cpumask);",
            "\ttick_nohz_full_running = true;",
            "}",
            "bool tick_nohz_cpu_hotpluggable(unsigned int cpu)",
            "{",
            "\t/*",
            "\t * The tick_do_timer_cpu CPU handles housekeeping duty (unbound",
            "\t * timers, workqueues, timekeeping, ...) on behalf of full dynticks",
            "\t * CPUs. It must remain online when nohz full is enabled.",
            "\t */",
            "\tif (tick_nohz_full_running && tick_do_timer_cpu == cpu)",
            "\t\treturn false;",
            "\treturn true;",
            "}",
            "static int tick_nohz_cpu_down(unsigned int cpu)",
            "{",
            "\treturn tick_nohz_cpu_hotpluggable(cpu) ? 0 : -EBUSY;",
            "}",
            "void __init tick_nohz_init(void)",
            "{",
            "\tint cpu, ret;",
            "",
            "\tif (!tick_nohz_full_running)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Full dynticks uses irq work to drive the tick rescheduling on safe",
            "\t * locking contexts. But then we need irq work to raise its own",
            "\t * interrupts to avoid circular dependency on the tick",
            "\t */",
            "\tif (!arch_irq_work_has_interrupt()) {",
            "\t\tpr_warn(\"NO_HZ: Can't run full dynticks because arch doesn't support irq work self-IPIs\\n\");",
            "\t\tcpumask_clear(tick_nohz_full_mask);",
            "\t\ttick_nohz_full_running = false;",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (IS_ENABLED(CONFIG_PM_SLEEP_SMP) &&",
            "\t\t\t!IS_ENABLED(CONFIG_PM_SLEEP_SMP_NONZERO_CPU)) {",
            "\t\tcpu = smp_processor_id();",
            "",
            "\t\tif (cpumask_test_cpu(cpu, tick_nohz_full_mask)) {",
            "\t\t\tpr_warn(\"NO_HZ: Clearing %d from nohz_full range \"",
            "\t\t\t\t\"for timekeeping\\n\", cpu);",
            "\t\t\tcpumask_clear_cpu(cpu, tick_nohz_full_mask);",
            "\t\t}",
            "\t}",
            "",
            "\tfor_each_cpu(cpu, tick_nohz_full_mask)",
            "\t\tct_cpu_track_user(cpu);",
            "",
            "\tret = cpuhp_setup_state_nocalls(CPUHP_AP_ONLINE_DYN,",
            "\t\t\t\t\t\"kernel/nohz:predown\", NULL,",
            "\t\t\t\t\ttick_nohz_cpu_down);",
            "\tWARN_ON(ret < 0);",
            "\tpr_info(\"NO_HZ: Full dynticks CPUs: %*pbl.\\n\",",
            "\t\tcpumask_pr_args(tick_nohz_full_mask));",
            "}"
          ],
          "function_name": "tick_nohz_dep_set, tick_nohz_dep_clear, tick_nohz_dep_set_cpu, tick_nohz_dep_clear_cpu, tick_nohz_dep_set_task, tick_nohz_dep_clear_task, tick_nohz_dep_set_signal, tick_nohz_dep_clear_signal, __tick_nohz_task_switch, tick_nohz_full_setup, tick_nohz_cpu_hotpluggable, tick_nohz_cpu_down, tick_nohz_init",
          "description": "提供tick依赖项的增删改查接口，初始化nohz_full模式所需的数据结构和CPU掩码，处理动态tick模式的热插拔和资源分配",
          "similarity": 0.5189164876937866
        },
        {
          "chunk_id": 8,
          "file_path": "kernel/time/tick-sched.c",
          "start_line": 1114,
          "end_line": 1229,
          "content": [
            "void tick_nohz_idle_stop_tick(void)",
            "{",
            "\tstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);",
            "\tint cpu = smp_processor_id();",
            "\tktime_t expires;",
            "",
            "\t/*",
            "\t * If tick_nohz_get_sleep_length() ran tick_nohz_next_event(), the",
            "\t * tick timer expiration time is known already.",
            "\t */",
            "\tif (ts->timer_expires_base)",
            "\t\texpires = ts->timer_expires;",
            "\telse if (can_stop_idle_tick(cpu, ts))",
            "\t\texpires = tick_nohz_next_event(ts, cpu);",
            "\telse",
            "\t\treturn;",
            "",
            "\tts->idle_calls++;",
            "",
            "\tif (expires > 0LL) {",
            "\t\tint was_stopped = ts->tick_stopped;",
            "",
            "\t\ttick_nohz_stop_tick(ts, cpu);",
            "",
            "\t\tts->idle_sleeps++;",
            "\t\tts->idle_expires = expires;",
            "",
            "\t\tif (!was_stopped && ts->tick_stopped) {",
            "\t\t\tts->idle_jiffies = ts->last_jiffies;",
            "\t\t\tnohz_balance_enter_idle(cpu);",
            "\t\t}",
            "\t} else {",
            "\t\ttick_nohz_retain_tick(ts);",
            "\t}",
            "}",
            "void tick_nohz_idle_retain_tick(void)",
            "{",
            "\ttick_nohz_retain_tick(this_cpu_ptr(&tick_cpu_sched));",
            "\t/*",
            "\t * Undo the effect of get_next_timer_interrupt() called from",
            "\t * tick_nohz_next_event().",
            "\t */",
            "\ttimer_clear_idle();",
            "}",
            "void tick_nohz_idle_enter(void)",
            "{",
            "\tstruct tick_sched *ts;",
            "",
            "\tlockdep_assert_irqs_enabled();",
            "",
            "\tlocal_irq_disable();",
            "",
            "\tts = this_cpu_ptr(&tick_cpu_sched);",
            "",
            "\tWARN_ON_ONCE(ts->timer_expires_base);",
            "",
            "\tts->inidle = 1;",
            "\ttick_nohz_start_idle(ts);",
            "",
            "\tlocal_irq_enable();",
            "}",
            "void tick_nohz_irq_exit(void)",
            "{",
            "\tstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);",
            "",
            "\tif (ts->inidle)",
            "\t\ttick_nohz_start_idle(ts);",
            "\telse",
            "\t\ttick_nohz_full_update_tick(ts);",
            "}",
            "bool tick_nohz_idle_got_tick(void)",
            "{",
            "\tstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);",
            "",
            "\tif (ts->got_idle_tick) {",
            "\t\tts->got_idle_tick = 0;",
            "\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "ktime_t tick_nohz_get_next_hrtimer(void)",
            "{",
            "\treturn __this_cpu_read(tick_cpu_device.evtdev)->next_event;",
            "}",
            "ktime_t tick_nohz_get_sleep_length(ktime_t *delta_next)",
            "{",
            "\tstruct clock_event_device *dev = __this_cpu_read(tick_cpu_device.evtdev);",
            "\tstruct tick_sched *ts = this_cpu_ptr(&tick_cpu_sched);",
            "\tint cpu = smp_processor_id();",
            "\t/*",
            "\t * The idle entry time is expected to be a sufficient approximation of",
            "\t * the current time at this point.",
            "\t */",
            "\tktime_t now = ts->idle_entrytime;",
            "\tktime_t next_event;",
            "",
            "\tWARN_ON_ONCE(!ts->inidle);",
            "",
            "\t*delta_next = ktime_sub(dev->next_event, now);",
            "",
            "\tif (!can_stop_idle_tick(cpu, ts))",
            "\t\treturn *delta_next;",
            "",
            "\tnext_event = tick_nohz_next_event(ts, cpu);",
            "\tif (!next_event)",
            "\t\treturn *delta_next;",
            "",
            "\t/*",
            "\t * If the next highres timer to expire is earlier than next_event, the",
            "\t * idle governor needs to know that.",
            "\t */",
            "\tnext_event = min_t(u64, next_event,",
            "\t\t\t   hrtimer_next_event_without(&ts->sched_timer));",
            "",
            "\treturn ktime_sub(next_event, now);",
            "}"
          ],
          "function_name": "tick_nohz_idle_stop_tick, tick_nohz_idle_retain_tick, tick_nohz_idle_enter, tick_nohz_irq_exit, tick_nohz_idle_got_tick, tick_nohz_get_next_hrtimer, tick_nohz_get_sleep_length",
          "description": "tick_nohz_idle_stop_tick尝试停止空闲定时器并更新睡眠时间统计，tick_nohz_idle_enter/tick_nohz_irq_exit管理空闲状态下的中断处理，tick_nohz_get_sleep_length计算剩余睡眠时间并考虑高精度定时器的影响，tick_nohz_get_next_hrtimer获取下一个高精度定时器时间",
          "similarity": 0.5078018307685852
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/time/tick-sched.c",
          "start_line": 185,
          "end_line": 291,
          "content": [
            "static void tick_sched_do_timer(struct tick_sched *ts, ktime_t now)",
            "{",
            "\tint cpu = smp_processor_id();",
            "",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "\t/*",
            "\t * Check if the do_timer duty was dropped. We don't care about",
            "\t * concurrency: This happens only when the CPU in charge went",
            "\t * into a long sleep. If two CPUs happen to assign themselves to",
            "\t * this duty, then the jiffies update is still serialized by",
            "\t * jiffies_lock.",
            "\t *",
            "\t * If nohz_full is enabled, this should not happen because the",
            "\t * tick_do_timer_cpu never relinquishes.",
            "\t */",
            "\tif (unlikely(tick_do_timer_cpu == TICK_DO_TIMER_NONE)) {",
            "#ifdef CONFIG_NO_HZ_FULL",
            "\t\tWARN_ON_ONCE(tick_nohz_full_running);",
            "#endif",
            "\t\ttick_do_timer_cpu = cpu;",
            "\t}",
            "#endif",
            "",
            "\t/* Check, if the jiffies need an update */",
            "\tif (tick_do_timer_cpu == cpu)",
            "\t\ttick_do_update_jiffies64(now);",
            "",
            "\t/*",
            "\t * If jiffies update stalled for too long (timekeeper in stop_machine()",
            "\t * or VMEXIT'ed for several msecs), force an update.",
            "\t */",
            "\tif (ts->last_tick_jiffies != jiffies) {",
            "\t\tts->stalled_jiffies = 0;",
            "\t\tts->last_tick_jiffies = READ_ONCE(jiffies);",
            "\t} else {",
            "\t\tif (++ts->stalled_jiffies == MAX_STALLED_JIFFIES) {",
            "\t\t\ttick_do_update_jiffies64(now);",
            "\t\t\tts->stalled_jiffies = 0;",
            "\t\t\tts->last_tick_jiffies = READ_ONCE(jiffies);",
            "\t\t}",
            "\t}",
            "",
            "\tif (ts->inidle)",
            "\t\tts->got_idle_tick = 1;",
            "}",
            "static void tick_sched_handle(struct tick_sched *ts, struct pt_regs *regs)",
            "{",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "\t/*",
            "\t * When we are idle and the tick is stopped, we have to touch",
            "\t * the watchdog as we might not schedule for a really long",
            "\t * time. This happens on complete idle SMP systems while",
            "\t * waiting on the login prompt. We also increment the \"start of",
            "\t * idle\" jiffy stamp so the idle accounting adjustment we do",
            "\t * when we go busy again does not account too much ticks.",
            "\t */",
            "\tif (ts->tick_stopped) {",
            "\t\ttouch_softlockup_watchdog_sched();",
            "\t\tif (is_idle_task(current))",
            "\t\t\tts->idle_jiffies++;",
            "\t\t/*",
            "\t\t * In case the current tick fired too early past its expected",
            "\t\t * expiration, make sure we don't bypass the next clock reprogramming",
            "\t\t * to the same deadline.",
            "\t\t */",
            "\t\tts->next_tick = 0;",
            "\t}",
            "#endif",
            "\tupdate_process_times(user_mode(regs));",
            "\tprofile_tick(CPU_PROFILING);",
            "}",
            "static bool check_tick_dependency(atomic_t *dep)",
            "{",
            "\tint val = atomic_read(dep);",
            "",
            "\tif (val & TICK_DEP_MASK_POSIX_TIMER) {",
            "\t\ttrace_tick_stop(0, TICK_DEP_MASK_POSIX_TIMER);",
            "\t\treturn true;",
            "\t}",
            "",
            "\tif (val & TICK_DEP_MASK_PERF_EVENTS) {",
            "\t\ttrace_tick_stop(0, TICK_DEP_MASK_PERF_EVENTS);",
            "\t\treturn true;",
            "\t}",
            "",
            "\tif (val & TICK_DEP_MASK_SCHED) {",
            "\t\ttrace_tick_stop(0, TICK_DEP_MASK_SCHED);",
            "\t\treturn true;",
            "\t}",
            "",
            "\tif (val & TICK_DEP_MASK_CLOCK_UNSTABLE) {",
            "\t\ttrace_tick_stop(0, TICK_DEP_MASK_CLOCK_UNSTABLE);",
            "\t\treturn true;",
            "\t}",
            "",
            "\tif (val & TICK_DEP_MASK_RCU) {",
            "\t\ttrace_tick_stop(0, TICK_DEP_MASK_RCU);",
            "\t\treturn true;",
            "\t}",
            "",
            "\tif (val & TICK_DEP_MASK_RCU_EXP) {",
            "\t\ttrace_tick_stop(0, TICK_DEP_MASK_RCU_EXP);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "tick_sched_do_timer, tick_sched_handle, check_tick_dependency",
          "description": "处理tick中断服务程序，包含jiffies更新检测、空闲超时监控以及依赖项检查逻辑，维护tick依赖状态标识",
          "similarity": 0.5010644197463989
        }
      ]
    },
    {
      "source_file": "kernel/sched/features.h",
      "md_summary": "> 自动生成时间: 2025-10-25 16:09:45\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\features.h`\n\n---\n\n# `sched/features.h` 技术文档\n\n## 1. 文件概述\n\n`sched/features.h` 是 Linux 内核调度器（CFS 和 EEVDF 调度类）中用于定义和管理**调度特性（Scheduling Features）** 的头文件。该文件通过宏 `SCHED_FEAT(name, enabled)` 声明一系列可配置的调度行为开关，用于控制调度器在运行时的各种策略，如任务放置、抢占、迁移、缓存局部性优化、延迟处理、利用率估计等。这些特性通常在编译时默认启用或禁用，但部分可通过 `/sys/kernel/debug/sched_features` 在运行时动态调整。\n\n## 2. 核心功能\n\n本文件不包含函数或数据结构定义，而是通过一系列 `SCHED_FEAT(feature_name, default_value)` 宏声明调度器的**可配置特性标志**。每个特性对应一个布尔开关，控制调度器某一方面的行为逻辑。主要特性包括：\n\n- **任务放置策略**：`PLACE_LAG`、`PLACE_DEADLINE_INITIAL`、`PLACE_REL_DEADLINE`\n- **抢占控制**：`RUN_TO_PARITY`、`PREEMPT_SHORT`、`WAKEUP_PREEMPTION`\n- **缓存局部性优化**：`NEXT_BUDDY`、`CACHE_HOT_BUDDY`\n- **延迟出队机制**：`DELAY_DEQUEUE`、`DELAY_ZERO`\n- **高精度定时器支持**：`HRTICK`、`HRTICK_DL`\n- **CPU 容量与负载管理**：`NONTASK_CAPACITY`、`ATTACH_AGE_LOAD`\n- **唤醒优化**：`TTWU_QUEUE`、`SIS_UTIL`\n- **实时任务调度优化**：`RT_PUSH_IPI`、`RT_RUNTIME_SHARE`\n- **利用率估计**：`UTIL_EST`、`UTIL_EST_FASTUP`\n- **调试与告警**：`WARN_DOUBLE_CLOCK`、`LATENCY_WARN`\n\n## 3. 关键实现\n\n- **`SCHED_FEAT` 宏机制**：  \n  该宏在 `kernel/sched/features.h` 中定义（通常通过 `#define SCHED_FEAT(x, enabled) SCHED_FEAT_##x`），最终在 `kernel/sched/core.c` 中展开为位图（`sysctl_sched_features`）中的位标志。调度器代码通过 `sched_feat(FEAT_NAME)` 宏查询某特性是否启用。\n\n- **EEVDF 相关特性**：\n  - `PLACE_LAG`：启用后，任务在睡眠/唤醒周期中保留其虚拟运行时间（avg_vruntime）的“滞后”（lag），确保公平性。这是 EEVDF（Earliest Eligible Virtual Deadline First）调度器的核心策略之一。\n  - `PLACE_DEADLINE_INITIAL`：新任务初始虚拟截止时间设为当前时间加半个时间片，避免新任务因虚拟截止时间过早而过度抢占。\n  - `PLACE_REL_DEADLINE`：任务迁移时保持其相对于当前虚拟时间的截止时间偏移，维持调度公平性。\n\n- **抢占抑制与唤醒抢占**：\n  - `RUN_TO_PARITY`：禁止唤醒抢占，直到当前任务达到“零滞后点”（即其虚拟运行时间追平队列平均值）或耗尽时间片。\n  - `PREEMPT_SHORT`：允许具有更短时间片的唤醒任务抢占当前任务，即使 `RESPECT_SLICE` 被设置。\n  - `WAKEUP_PREEMPTION`：启用唤醒时的抢占检查，是 CFS/EEVDF 实现低延迟响应的关键。\n\n- **缓存局部性优化**：\n  - `NEXT_BUDDY`（默认关闭）：优先调度最近被唤醒但未成功抢占的任务，因其可能复用刚访问的数据。\n  - `CACHE_HOT_BUDDY`：将 buddy 任务视为缓存热任务，降低其被迁移的概率。\n\n- **延迟出队（`DELAY_DEQUEUE`）**：  \n  非就绪任务（如睡眠中）不会立即从运行队列移除，使其保留在调度竞争中以“消耗”负滞后（negative lag），当选中时自然具有正滞后，提升调度平滑性。`DELAY_ZERO` 则在出队或唤醒时将滞后裁剪为 0。\n\n- **TTWU_QUEUE 优化**：  \n  在非 `PREEMPT_RT` 配置下，默认启用远程唤醒排队机制，通过调度 IPI 异步处理跨 CPU 唤醒，减少运行队列锁竞争。\n\n- **利用率估计（Utilization Estimation）**：  \n  `UTIL_EST` 启用基于 PELT（Per-Entity Load Tracking）信号的 CPU 利用率估计，`UTIL_EST_FASTUP` 允许利用率快速上升以响应突发负载，用于 EAS（Energy Aware Scheduling）等场景。\n\n- **RT 调度优化**：  \n  `RT_PUSH_IPI` 在支持 `HAVE_RT_PUSH_IPI` 的平台上启用，通过 IPI 推送高优先级 RT 任务，避免多 CPU 同时争抢单个运行队列锁导致的“惊群”问题。\n\n## 4. 依赖关系\n\n- **依赖头文件**：通常由 `kernel/sched/sched.h` 或 `kernel/sched/core.c` 包含。\n- **依赖配置选项**：\n  - `CONFIG_PREEMPT_RT`：影响 `TTWU_QUEUE` 默认值。\n  - `HAVE_RT_PUSH_IPI`：决定 `RT_PUSH_IPI` 特性是否定义。\n- **依赖调度核心模块**：特性标志在 `kernel/sched/core.c`、`kernel/sched/fair.c`（CFS/EEVDF）、`kernel/sched/rt.c`（实时调度）中被实际使用。\n- **依赖调试接口**：部分特性（如 `WARN_DOUBLE_CLOCK`、`LATENCY_WARN`）依赖内核调试基础设施。\n\n## 5. 使用场景\n\n- **调度策略调优**：系统管理员或开发者可通过 `/sys/kernel/debug/sched_features` 动态开启/关闭特性，以优化特定工作负载（如低延迟、高吞吐、能效）下的调度行为。\n- **EEVDF 调度器支持**：`PLACE_LAG`、`PLACE_DEADLINE_INITIAL` 等特性是 Linux 6.6+ 引入的 EEVDF 调度器实现公平性和响应性的关键。\n- **实时系统优化**：`RT_PUSH_IPI`、`RT_RUNTIME_SHARE` 等用于改善实时任务的调度延迟和 CPU 资源分配。\n- **能效调度（EAS）**：`UTIL_EST` 和 `UTIL_EST_FASTUP` 为 EAS 提供准确的 CPU 利用率预测，用于任务放置决策。\n- **性能调试**：`LATENCY_WARN`、`WARN_DOUBLE_CLOCK` 等特性用于检测调度器内部异常或性能瓶颈。\n- **多核扩展性优化**：`TTWU_QUEUE`、`SIS_UTIL` 减少跨 CPU 唤醒和 LLC 域扫描开销，提升大规模系统可扩展性。",
      "similarity": 0.5371668338775635,
      "chunks": []
    }
  ]
}