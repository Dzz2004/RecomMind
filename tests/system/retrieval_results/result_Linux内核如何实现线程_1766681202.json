{
  "query": "Linux内核如何实现线程",
  "timestamp": "2025-12-26 00:46:42",
  "retrieved_files": [
    {
      "source_file": "kernel/rseq.c",
      "md_summary": "> 自动生成时间: 2025-10-25 15:54:26\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `rseq.c`\n\n---\n\n# rseq.c 技术文档\n\n## 文件概述\n\n`rseq.c` 实现了 Linux 内核对 **Restartable Sequences（可重启序列）** 系统调用的支持。该机制允许用户空间程序在不使用重量级原子操作的前提下，高效地执行与调度器抢占、信号投递和 CPU 迁移相关的**伪原子操作**，特别适用于高性能的每 CPU（per-CPU）数据结构操作。该文件负责管理用户空间注册的 `struct rseq` TLS（线程局部存储）区域，并在任务被抢占、迁移或收到信号时，安全地中止并重定向用户空间执行流。\n\n## 核心功能\n\n### 主要数据结构\n- `struct rseq`：用户空间注册的 TLS 结构，包含 `cpu_id_start`、`cpu_id`、`node_id`、`mm_cid` 和 `rseq_cs`（critical section 描述符指针）等字段。\n- `struct rseq_cs`：用户空间关键区（critical section）的描述结构，包含起始地址、提交地址、中止地址和标志位。\n\n### 主要函数\n- `rseq_update_cpu_node_id(struct task_struct *t)`  \n  更新任务的 `rseq` TLS 区域中的 CPU ID、NUMA 节点 ID 和内存上下文 ID（mm_cid），用于反映当前执行上下文。\n  \n- `rseq_reset_rseq_cpu_node_id(struct task_struct *t)`  \n  将任务的 `rseq` TLS 区域重置为初始状态（`cpu_id` 设为 `RSEQ_CPU_ID_UNINITIALIZED`）。\n\n- `rseq_get_rseq_cs_ptr_val(struct rseq __user *rseq, u64 *rseq_cs)`  \n  从用户空间 `rseq` 结构中安全读取 `rseq_cs` 指针值。\n\n- `rseq_get_rseq_cs(struct task_struct *t, struct rseq_cs *rseq_cs)`  \n  若 `rseq_cs` 指针有效，则从用户空间复制并验证 `struct rseq_cs` 内容（代码片段未完整展示）。\n\n- `rseq_validate_ro_fields(struct task_struct *t)`（仅在 `CONFIG_DEBUG_RSEQ` 下启用）  \n  验证用户空间 `rseq` 结构中应为只读的字段是否与内核副本一致，防止用户空间篡改。\n\n### 宏定义\n- `rseq_unsafe_put_user()`：在写入用户空间 `rseq` 字段的同时，同步更新内核中的副本（调试模式下），确保状态一致性。\n- `RSEQ_CS_NO_RESTART_FLAGS`：定义关键区中禁止因抢占、信号或迁移而重启的标志组合。\n\n## 关键实现\n\n### 可重启序列执行模型\n用户空间关键区执行流程如下：\n1. 将关键区描述符地址写入 TLS 的 `rseq->rseq_cs`；\n2. 比较 `cpu_id_start` 与当前 `cpu_id`，不一致则跳转至 `abort_ip`；\n3. 执行关键区操作；\n4. 成功提交后继续正常执行。\n\n若在步骤 1–3 之间发生**抢占、CPU 迁移或信号投递**，内核会：\n- 清空 `rseq->rseq_cs`（设为 NULL）；\n- 将用户空间返回地址设置为 `abort_ip`；\n- 恢复执行时跳转至中止处理逻辑。\n\n### 安全访问与调试支持\n- 使用 `user_read_access_begin/end()` 和 `user_write_access_begin/end()` 确保对用户空间内存的安全访问。\n- 在 `CONFIG_DEBUG_RSEQ` 模式下，内核维护 `rseq` 字段的内核副本，并在每次更新前后校验用户空间只读字段的一致性，防止恶意或错误的用户空间修改。\n- 通过 `trace_rseq_update()` 提供跟踪点，便于性能分析和调试。\n\n### 兼容性处理\n- 原始 `rseq` 结构大小为 32 字节（`ORIG_RSEQ_SIZE`）；\n- 对于扩展字段（如 `mm_cid`），仅在 `t->rseq_len > ORIG_RSEQ_SIZE` 时才进行更新或重置，确保向后兼容。\n\n## 依赖关系\n\n- **调度子系统**：依赖 `raw_smp_processor_id()` 获取当前 CPU，`task_mm_cid()` 获取内存上下文 ID。\n- **内存管理**：使用 `cpu_to_node()` 获取 NUMA 节点信息。\n- **用户空间访问**：依赖 `uaccess.h` 提供的安全用户空间读写原语（如 `unsafe_get_user`/`unsafe_put_user`）。\n- **跟踪系统**：通过 `trace/events/rseq.h` 集成内核跟踪基础设施。\n- **架构支持**：依赖 `asm/ptrace.h` 处理信号/抢占后的用户空间返回地址重定向（完整实现位于架构相关代码中）。\n\n## 使用场景\n\n- **高性能 per-CPU 操作**：如无锁计数器、每 CPU 队列等，避免传统原子操作或锁的开销。\n- **实时/低延迟应用**：减少因内核同步原语引入的延迟抖动。\n- **用户空间调度器/运行时**：如 Go、Java 虚拟机等，用于实现高效的线程本地状态管理。\n- **系统调用 `sys_rseq()`**：由用户空间通过 `rseq(2)` 系统调用注册或注销 `rseq` TLS 区域，本文件提供内核侧支持逻辑（注册/注销时调用 `rseq_update_cpu_node_id` 或 `rseq_reset_rseq_cpu_node_id`）。",
      "similarity": 0.655261754989624,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/rseq.c",
          "start_line": 1,
          "end_line": 34,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0+",
            "/*",
            " * Restartable sequences system call",
            " *",
            " * Copyright (C) 2015, Google, Inc.,",
            " * Paul Turner <pjt@google.com> and Andrew Hunter <ahh@google.com>",
            " * Copyright (C) 2015-2018, EfficiOS Inc.,",
            " * Mathieu Desnoyers <mathieu.desnoyers@efficios.com>",
            " */",
            "",
            "#include <linux/sched.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/rseq.h>",
            "#include <linux/types.h>",
            "#include <linux/ratelimit.h>",
            "#include <asm/ptrace.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/rseq.h>",
            "",
            "/* The original rseq structure size (including padding) is 32 bytes. */",
            "#define ORIG_RSEQ_SIZE\t\t32",
            "",
            "#define RSEQ_CS_NO_RESTART_FLAGS (RSEQ_CS_FLAG_NO_RESTART_ON_PREEMPT | \\",
            "\t\t\t\t  RSEQ_CS_FLAG_NO_RESTART_ON_SIGNAL | \\",
            "\t\t\t\t  RSEQ_CS_FLAG_NO_RESTART_ON_MIGRATE)",
            "",
            "#ifdef CONFIG_DEBUG_RSEQ",
            "static struct rseq *rseq_kernel_fields(struct task_struct *t)",
            "{",
            "\treturn (struct rseq *) t->rseq_fields;",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义rseq内核字段访问函数，用于获取当前任务的rseq结构体指针，供后续验证和操作使用。",
          "similarity": 0.5710486173629761
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/rseq.c",
          "start_line": 35,
          "end_line": 159,
          "content": [
            "static int rseq_validate_ro_fields(struct task_struct *t)",
            "{",
            "\tstatic DEFINE_RATELIMIT_STATE(_rs,",
            "\t\t\t\t      DEFAULT_RATELIMIT_INTERVAL,",
            "\t\t\t\t      DEFAULT_RATELIMIT_BURST);",
            "\tu32 cpu_id_start, cpu_id, node_id, mm_cid;",
            "\tstruct rseq __user *rseq = t->rseq;",
            "",
            "\t/*",
            "\t * Validate fields which are required to be read-only by",
            "\t * user-space.",
            "\t */",
            "\tif (!user_read_access_begin(rseq, t->rseq_len))",
            "\t\tgoto efault;",
            "\tunsafe_get_user(cpu_id_start, &rseq->cpu_id_start, efault_end);",
            "\tunsafe_get_user(cpu_id, &rseq->cpu_id, efault_end);",
            "\tunsafe_get_user(node_id, &rseq->node_id, efault_end);",
            "\tunsafe_get_user(mm_cid, &rseq->mm_cid, efault_end);",
            "\tuser_read_access_end();",
            "",
            "\tif ((cpu_id_start != rseq_kernel_fields(t)->cpu_id_start ||",
            "\t    cpu_id != rseq_kernel_fields(t)->cpu_id ||",
            "\t    node_id != rseq_kernel_fields(t)->node_id ||",
            "\t    mm_cid != rseq_kernel_fields(t)->mm_cid) && __ratelimit(&_rs)) {",
            "",
            "\t\tpr_warn(\"Detected rseq corruption for pid: %d, name: %s\\n\"",
            "\t\t\t\"\\tcpu_id_start: %u ?= %u\\n\"",
            "\t\t\t\"\\tcpu_id:       %u ?= %u\\n\"",
            "\t\t\t\"\\tnode_id:      %u ?= %u\\n\"",
            "\t\t\t\"\\tmm_cid:       %u ?= %u\\n\",",
            "\t\t\tt->pid, t->comm,",
            "\t\t\tcpu_id_start, rseq_kernel_fields(t)->cpu_id_start,",
            "\t\t\tcpu_id, rseq_kernel_fields(t)->cpu_id,",
            "\t\t\tnode_id, rseq_kernel_fields(t)->node_id,",
            "\t\t\tmm_cid, rseq_kernel_fields(t)->mm_cid);",
            "\t}",
            "",
            "\t/* For now, only print a console warning on mismatch. */",
            "\treturn 0;",
            "",
            "efault_end:",
            "\tuser_read_access_end();",
            "efault:",
            "\treturn -EFAULT;",
            "}",
            "static int rseq_validate_ro_fields(struct task_struct *t)",
            "{",
            "\treturn 0;",
            "}",
            "static int rseq_update_cpu_node_id(struct task_struct *t)",
            "{",
            "\tstruct rseq __user *rseq = t->rseq;",
            "\tu32 cpu_id = raw_smp_processor_id();",
            "\tu32 node_id = cpu_to_node(cpu_id);",
            "\tu32 mm_cid = task_mm_cid(t);",
            "",
            "\t/*",
            "\t * Validate read-only rseq fields.",
            "\t */",
            "\tif (rseq_validate_ro_fields(t))",
            "\t\tgoto efault;",
            "\tWARN_ON_ONCE((int) mm_cid < 0);",
            "\tif (!user_write_access_begin(rseq, t->rseq_len))",
            "\t\tgoto efault;",
            "",
            "\trseq_unsafe_put_user(t, cpu_id, cpu_id_start, efault_end);",
            "\trseq_unsafe_put_user(t, cpu_id, cpu_id, efault_end);",
            "\trseq_unsafe_put_user(t, node_id, node_id, efault_end);",
            "\trseq_unsafe_put_user(t, mm_cid, mm_cid, efault_end);",
            "",
            "\t/*",
            "\t * Additional feature fields added after ORIG_RSEQ_SIZE",
            "\t * need to be conditionally updated only if",
            "\t * t->rseq_len != ORIG_RSEQ_SIZE.",
            "\t */",
            "\tuser_write_access_end();",
            "\ttrace_rseq_update(t);",
            "\treturn 0;",
            "",
            "efault_end:",
            "\tuser_write_access_end();",
            "efault:",
            "\treturn -EFAULT;",
            "}",
            "static int rseq_reset_rseq_cpu_node_id(struct task_struct *t)",
            "{",
            "\tstruct rseq __user *rseq = t->rseq;",
            "\tu32 cpu_id_start = 0, cpu_id = RSEQ_CPU_ID_UNINITIALIZED, node_id = 0,",
            "\t    mm_cid = 0;",
            "",
            "\t/*",
            "\t * Validate read-only rseq fields.",
            "\t */",
            "\tif (rseq_validate_ro_fields(t))",
            "\t\tgoto efault;",
            "",
            "\tif (!user_write_access_begin(rseq, t->rseq_len))",
            "\t\tgoto efault;",
            "",
            "\t/*",
            "\t * Reset all fields to their initial state.",
            "\t *",
            "\t * All fields have an initial state of 0 except cpu_id which is set to",
            "\t * RSEQ_CPU_ID_UNINITIALIZED, so that any user coming in after",
            "\t * unregistration can figure out that rseq needs to be registered",
            "\t * again.",
            "\t */",
            "\trseq_unsafe_put_user(t, cpu_id_start, cpu_id_start, efault_end);",
            "\trseq_unsafe_put_user(t, cpu_id, cpu_id, efault_end);",
            "\trseq_unsafe_put_user(t, node_id, node_id, efault_end);",
            "\trseq_unsafe_put_user(t, mm_cid, mm_cid, efault_end);",
            "",
            "\t/*",
            "\t * Additional feature fields added after ORIG_RSEQ_SIZE",
            "\t * need to be conditionally reset only if",
            "\t * t->rseq_len != ORIG_RSEQ_SIZE.",
            "\t */",
            "\tuser_write_access_end();",
            "\treturn 0;",
            "",
            "efault_end:",
            "\tuser_write_access_end();",
            "efault:",
            "\treturn -EFAULT;",
            "}"
          ],
          "function_name": "rseq_validate_ro_fields, rseq_validate_ro_fields, rseq_update_cpu_node_id, rseq_reset_rseq_cpu_node_id",
          "description": "实现rseq只读字段校验、CPU/节点ID更新及重置功能，检测并防止用户态对只读字段的篡改。",
          "similarity": 0.52573561668396
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/rseq.c",
          "start_line": 355,
          "end_line": 442,
          "content": [
            "static int clear_rseq_cs(struct rseq __user *rseq)",
            "{",
            "\t/*",
            "\t * The rseq_cs field is set to NULL on preemption or signal",
            "\t * delivery on top of rseq assembly block, as well as on top",
            "\t * of code outside of the rseq assembly block. This performs",
            "\t * a lazy clear of the rseq_cs field.",
            "\t *",
            "\t * Set rseq_cs to NULL.",
            "\t */",
            "#ifdef CONFIG_64BIT",
            "\treturn put_user(0UL, &rseq->rseq_cs);",
            "#else",
            "\tif (clear_user(&rseq->rseq_cs, sizeof(rseq->rseq_cs)))",
            "\t\treturn -EFAULT;",
            "\treturn 0;",
            "#endif",
            "}",
            "static bool in_rseq_cs(unsigned long ip, struct rseq_cs *rseq_cs)",
            "{",
            "\treturn ip - rseq_cs->start_ip < rseq_cs->post_commit_offset;",
            "}",
            "static int rseq_ip_fixup(struct pt_regs *regs)",
            "{",
            "\tunsigned long ip = instruction_pointer(regs);",
            "\tstruct task_struct *t = current;",
            "\tstruct rseq_cs rseq_cs;",
            "\tint ret;",
            "",
            "\tret = rseq_get_rseq_cs(t, &rseq_cs);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\t/*",
            "\t * Handle potentially not being within a critical section.",
            "\t * If not nested over a rseq critical section, restart is useless.",
            "\t * Clear the rseq_cs pointer and return.",
            "\t */",
            "\tif (!in_rseq_cs(ip, &rseq_cs))",
            "\t\treturn clear_rseq_cs(t->rseq);",
            "\tret = rseq_need_restart(t, rseq_cs.flags);",
            "\tif (ret <= 0)",
            "\t\treturn ret;",
            "\tret = clear_rseq_cs(t->rseq);",
            "\tif (ret)",
            "\t\treturn ret;",
            "\ttrace_rseq_ip_fixup(ip, rseq_cs.start_ip, rseq_cs.post_commit_offset,",
            "\t\t\t    rseq_cs.abort_ip);",
            "\tinstruction_pointer_set(regs, (unsigned long)rseq_cs.abort_ip);",
            "\treturn 0;",
            "}",
            "void __rseq_handle_notify_resume(struct ksignal *ksig, struct pt_regs *regs)",
            "{",
            "\tstruct task_struct *t = current;",
            "\tint ret, sig;",
            "",
            "\tif (unlikely(t->flags & PF_EXITING))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * regs is NULL if and only if the caller is in a syscall path.  Skip",
            "\t * fixup and leave rseq_cs as is so that rseq_sycall() will detect and",
            "\t * kill a misbehaving userspace on debug kernels.",
            "\t */",
            "\tif (regs) {",
            "\t\tret = rseq_ip_fixup(regs);",
            "\t\tif (unlikely(ret < 0))",
            "\t\t\tgoto error;",
            "\t}",
            "\tif (unlikely(rseq_update_cpu_node_id(t)))",
            "\t\tgoto error;",
            "\treturn;",
            "",
            "error:",
            "\tsig = ksig ? ksig->sig : 0;",
            "\tforce_sigsegv(sig);",
            "}",
            "void rseq_syscall(struct pt_regs *regs)",
            "{",
            "\tunsigned long ip = instruction_pointer(regs);",
            "\tstruct task_struct *t = current;",
            "\tstruct rseq_cs rseq_cs;",
            "",
            "\tif (!t->rseq)",
            "\t\treturn;",
            "\tif (rseq_get_rseq_cs(t, &rseq_cs) || in_rseq_cs(ip, &rseq_cs))",
            "\t\tforce_sig(SIGSEGV);",
            "}"
          ],
          "function_name": "clear_rseq_cs, in_rseq_cs, rseq_ip_fixup, __rseq_handle_notify_resume, rseq_syscall",
          "description": "实现rseq异常处理流程，包括临界区IP修复、通知恢复处理和系统调用保护，确保rseq执行的安全边界。",
          "similarity": 0.5256763696670532
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/rseq.c",
          "start_line": 242,
          "end_line": 346,
          "content": [
            "static int rseq_get_rseq_cs_ptr_val(struct rseq __user *rseq, u64 *rseq_cs)",
            "{",
            "\tif (!rseq_cs)",
            "\t\treturn -EFAULT;",
            "",
            "#ifdef CONFIG_64BIT",
            "\tif (get_user(*rseq_cs, &rseq->rseq_cs))",
            "\t\treturn -EFAULT;",
            "#else",
            "\tif (copy_from_user(rseq_cs, &rseq->rseq_cs, sizeof(*rseq_cs)))",
            "\t\treturn -EFAULT;",
            "#endif",
            "",
            "\treturn 0;",
            "}",
            "static int rseq_get_rseq_cs(struct task_struct *t, struct rseq_cs *rseq_cs)",
            "{",
            "\tstruct rseq_cs __user *urseq_cs;",
            "\tu64 ptr;",
            "\tu32 __user *usig;",
            "\tu32 sig;",
            "\tint ret;",
            "",
            "\tret = rseq_get_rseq_cs_ptr_val(t->rseq, &ptr);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\t/* If the rseq_cs pointer is NULL, return a cleared struct rseq_cs. */",
            "\tif (!ptr) {",
            "\t\tmemset(rseq_cs, 0, sizeof(*rseq_cs));",
            "\t\treturn 0;",
            "\t}",
            "\t/* Check that the pointer value fits in the user-space process space. */",
            "\tif (ptr >= TASK_SIZE)",
            "\t\treturn -EINVAL;",
            "\turseq_cs = (struct rseq_cs __user *)(unsigned long)ptr;",
            "\tif (copy_from_user(rseq_cs, urseq_cs, sizeof(*rseq_cs)))",
            "\t\treturn -EFAULT;",
            "",
            "\tif (rseq_cs->start_ip >= TASK_SIZE ||",
            "\t    rseq_cs->start_ip + rseq_cs->post_commit_offset >= TASK_SIZE ||",
            "\t    rseq_cs->abort_ip >= TASK_SIZE ||",
            "\t    rseq_cs->version > 0)",
            "\t\treturn -EINVAL;",
            "\t/* Check for overflow. */",
            "\tif (rseq_cs->start_ip + rseq_cs->post_commit_offset < rseq_cs->start_ip)",
            "\t\treturn -EINVAL;",
            "\t/* Ensure that abort_ip is not in the critical section. */",
            "\tif (rseq_cs->abort_ip - rseq_cs->start_ip < rseq_cs->post_commit_offset)",
            "\t\treturn -EINVAL;",
            "",
            "\tusig = (u32 __user *)(unsigned long)(rseq_cs->abort_ip - sizeof(u32));",
            "\tret = get_user(sig, usig);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tif (current->rseq_sig != sig) {",
            "\t\tprintk_ratelimited(KERN_WARNING",
            "\t\t\t\"Possible attack attempt. Unexpected rseq signature 0x%x, expecting 0x%x (pid=%d, addr=%p).\\n\",",
            "\t\t\tsig, current->rseq_sig, current->pid, usig);",
            "\t\treturn -EINVAL;",
            "\t}",
            "\treturn 0;",
            "}",
            "static bool rseq_warn_flags(const char *str, u32 flags)",
            "{",
            "\tu32 test_flags;",
            "",
            "\tif (!flags)",
            "\t\treturn false;",
            "\ttest_flags = flags & RSEQ_CS_NO_RESTART_FLAGS;",
            "\tif (test_flags)",
            "\t\tpr_warn_once(\"Deprecated flags (%u) in %s ABI structure\", test_flags, str);",
            "\ttest_flags = flags & ~RSEQ_CS_NO_RESTART_FLAGS;",
            "\tif (test_flags)",
            "\t\tpr_warn_once(\"Unknown flags (%u) in %s ABI structure\", test_flags, str);",
            "\treturn true;",
            "}",
            "static int rseq_need_restart(struct task_struct *t, u32 cs_flags)",
            "{",
            "\tu32 flags, event_mask;",
            "\tint ret;",
            "",
            "\tif (rseq_warn_flags(\"rseq_cs\", cs_flags))",
            "\t\treturn -EINVAL;",
            "",
            "\t/* Get thread flags. */",
            "\tret = get_user(flags, &t->rseq->flags);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tif (rseq_warn_flags(\"rseq\", flags))",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * Load and clear event mask atomically with respect to",
            "\t * scheduler preemption.",
            "\t */",
            "\tpreempt_disable();",
            "\tevent_mask = t->rseq_event_mask;",
            "\tt->rseq_event_mask = 0;",
            "\tpreempt_enable();",
            "",
            "\treturn !!event_mask;",
            "}"
          ],
          "function_name": "rseq_get_rseq_cs_ptr_val, rseq_get_rseq_cs, rseq_warn_flags, rseq_need_restart",
          "description": "提供rseq_cs指针解析、结构体验证、标志位检查及是否需要重启的判定逻辑，保障安全性和兼容性。",
          "similarity": 0.48148950934410095
        }
      ]
    },
    {
      "source_file": "kernel/workqueue.c",
      "md_summary": "> 自动生成时间: 2025-10-25 17:53:20\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `workqueue.c`\n\n---\n\n# workqueue.c 技术文档\n\n## 1. 文件概述\n\n`workqueue.c` 是 Linux 内核中实现通用异步执行机制的核心文件，提供基于共享工作线程池（worker pool）的延迟任务调度功能。工作项（work items）在进程上下文中执行，支持 CPU 绑定和非绑定两种模式。每个 CPU 默认拥有两个标准工作池（普通优先级和高优先级），同时支持动态创建非绑定工作池以满足不同工作队列的需求。该机制替代了早期的 taskqueue/keventd 实现，具有更高的可扩展性和资源利用率。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct worker_pool`**  \n  工作线程池结构体，管理一组工作线程（workers），包含：\n  - `lock`：保护池状态的自旋锁\n  - `cpu` / `node`：关联的 CPU 和 NUMA 节点（绑定池）\n  - `worklist`：待处理工作项队列\n  - `idle_list` / `busy_hash`：空闲和忙碌工作线程的管理结构\n  - `nr_workers` / `nr_idle`：工作线程数量统计\n  - `attrs`：工作线程属性（如优先级、CPU 亲和性）\n  - `mayday_timer`：紧急情况下的救援请求定时器\n\n- **`struct pool_workqueue`**  \n  工作队列与工作池之间的关联结构，每个工作队列在每个池中都有一个对应的 `pool_workqueue` 实例，用于：\n  - 管理工作项的入队和执行\n  - 实现 `max_active` 限制（控制并发执行数）\n  - 支持 flush 操作（等待所有工作完成）\n  - 统计性能指标（如启动/完成次数、CPU 时间等）\n\n- **`struct worker`**（定义在 `workqueue_internal.h`）  \n  工作线程的运行时上下文，包含状态标志（如 `WORKER_IDLE`, `WORKER_UNBOUND`）、当前执行的工作项等。\n\n### 关键枚举与常量\n\n- **池/工作线程标志**：\n  - `POOL_DISASSOCIATED`：CPU 离线时池进入非绑定状态\n  - `WORKER_UNBOUND`：工作线程可在任意 CPU 上运行\n  - `WORKER_CPU_INTENSIVE`：标记 CPU 密集型任务，影响并发控制\n\n- **配置参数**：\n  - `NR_STD_WORKER_POOLS = 2`：每 CPU 标准池数量（普通 + 高优先级）\n  - `IDLE_WORKER_TIMEOUT = 300 * HZ`：空闲线程保留时间（5 分钟）\n  - `MAYDAY_INITIAL_TIMEOUT`：工作积压时触发救援的延迟（10ms）\n\n- **统计指标**（`pool_workqueue_stats`）：\n  - `PWQ_STAT_STARTED` / `PWQ_STAT_COMPLETED`：工作项执行统计\n  - `PWQ_STAT_MAYDAY` / `PWQ_STAT_RESCUED`：紧急救援事件计数\n\n## 3. 关键实现\n\n### 工作池管理\n- **绑定池（Bound Pool）**：与特定 CPU 关联，工作线程默认绑定到该 CPU。当 CPU 离线时，池进入 `DISASSOCIATED` 状态，工作线程转为非绑定模式。\n- **非绑定池（Unbound Pool）**：动态创建，通过哈希表（`unbound_pool_hash`）按属性（`workqueue_attrs`）去重，支持跨 CPU 调度。\n- **并发控制**：通过 `nr_running` 计数器和 `max_active` 限制，防止工作项过度并发执行。\n\n### 工作线程生命周期\n- **空闲管理**：空闲线程加入 `idle_list`，超时（`IDLE_WORKER_TIMEOUT`）后被回收。\n- **动态伸缩**：当工作积压时，通过 `mayday_timer` 触发新线程创建；若创建失败，向全局救援线程（rescuer）求助。\n- **状态标志**：使用位标志（如 `WORKER_IDLE`, `WORKER_PREP`）高效管理线程状态，避免锁竞争。\n\n### 内存与同步\n- **RCU 保护**：工作池销毁通过 RCU 延迟释放，确保 `get_work_pool()` 等读取路径无锁安全。\n- **锁分层**：\n  - `pool->lock`（自旋锁）：保护池内部状态\n  - `wq_pool_mutex`：全局池管理互斥锁\n  - `wq_pool_attach_mutex`：防止 CPU 绑定状态变更冲突\n\n### 工作项调度\n- **数据指针复用**：`work_struct->data` 的高有效位存储 `pool_workqueue` 指针，低有效位用于标志位（如 `WORK_STRUCT_INACTIVE`）。\n- **优先级支持**：高优先级工作池使用 `HIGHPRI_NICE_LEVEL = MIN_NICE` 提升调度优先级。\n\n## 4. 依赖关系\n\n- **内核子系统**：\n  - **调度器**（`<linux/sched.h>`）：创建工作线程（kworker），管理 CPU 亲和性\n  - **内存管理**（`<linux/slab.h>`）：分配工作池、工作队列等结构\n  - **CPU 热插拔**（`<linux/cpu.h>`）：处理 CPU 上下线时的池绑定状态切换\n  - **RCU**（`<linux/rculist.h>`）：实现无锁读取路径\n  - **定时器**（`<linux/timer.h>`）：实现空闲超时和救援机制\n\n- **内部依赖**：\n  - `workqueue_internal.h`：定义 `struct worker` 等内部结构\n  - `Documentation/core-api/workqueue.rst`：详细设计文档\n\n## 5. 使用场景\n\n- **驱动程序延迟操作**：硬件中断后调度下半部处理（如网络包处理、磁盘 I/O 完成回调）。\n- **内核子系统异步任务**：文件系统元数据更新、内存回收、电源管理状态切换。\n- **高优先级任务**：使用 `WQ_HIGHPRI` 标志创建工作队列，确保关键任务及时执行（如死锁恢复）。\n- **CPU 密集型任务**：标记 `WQ_CPU_INTENSIVE` 避免占用过多并发槽位，提升系统响应性。\n- **NUMA 感知调度**：非绑定工作队列可指定 NUMA 节点，优化内存访问延迟。",
      "similarity": 0.651833713054657,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/workqueue.c",
          "start_line": 895,
          "end_line": 1037,
          "content": [
            "static inline void worker_clr_flags(struct worker *worker, unsigned int flags)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "\tunsigned int oflags = worker->flags;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\tworker->flags &= ~flags;",
            "",
            "\t/*",
            "\t * If transitioning out of NOT_RUNNING, increment nr_running.  Note",
            "\t * that the nested NOT_RUNNING is not a noop.  NOT_RUNNING is mask",
            "\t * of multiple flags, not a single flag.",
            "\t */",
            "\tif ((flags & WORKER_NOT_RUNNING) && (oflags & WORKER_NOT_RUNNING))",
            "\t\tif (!(worker->flags & WORKER_NOT_RUNNING))",
            "\t\t\tpool->nr_running++;",
            "}",
            "static void worker_enter_idle(struct worker *worker)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "",
            "\tif (WARN_ON_ONCE(worker->flags & WORKER_IDLE) ||",
            "\t    WARN_ON_ONCE(!list_empty(&worker->entry) &&",
            "\t\t\t (worker->hentry.next || worker->hentry.pprev)))",
            "\t\treturn;",
            "",
            "\t/* can't use worker_set_flags(), also called from create_worker() */",
            "\tworker->flags |= WORKER_IDLE;",
            "\tpool->nr_idle++;",
            "\tworker->last_active = jiffies;",
            "",
            "\t/* idle_list is LIFO */",
            "\tlist_add(&worker->entry, &pool->idle_list);",
            "",
            "\tif (too_many_workers(pool) && !timer_pending(&pool->idle_timer))",
            "\t\tmod_timer(&pool->idle_timer, jiffies + IDLE_WORKER_TIMEOUT);",
            "",
            "\t/* Sanity check nr_running. */",
            "\tWARN_ON_ONCE(pool->nr_workers == pool->nr_idle && pool->nr_running);",
            "}",
            "static void worker_leave_idle(struct worker *worker)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "",
            "\tif (WARN_ON_ONCE(!(worker->flags & WORKER_IDLE)))",
            "\t\treturn;",
            "\tworker_clr_flags(worker, WORKER_IDLE);",
            "\tpool->nr_idle--;",
            "\tlist_del_init(&worker->entry);",
            "}",
            "static void move_linked_works(struct work_struct *work, struct list_head *head,",
            "\t\t\t      struct work_struct **nextp)",
            "{",
            "\tstruct work_struct *n;",
            "",
            "\t/*",
            "\t * Linked worklist will always end before the end of the list,",
            "\t * use NULL for list head.",
            "\t */",
            "\tlist_for_each_entry_safe_from(work, n, NULL, entry) {",
            "\t\tlist_move_tail(&work->entry, head);",
            "\t\tif (!(*work_data_bits(work) & WORK_STRUCT_LINKED))",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\t/*",
            "\t * If we're already inside safe list traversal and have moved",
            "\t * multiple works to the scheduled queue, the next position",
            "\t * needs to be updated.",
            "\t */",
            "\tif (nextp)",
            "\t\t*nextp = n;",
            "}",
            "static bool assign_work(struct work_struct *work, struct worker *worker,",
            "\t\t\tstruct work_struct **nextp)",
            "{",
            "\tstruct worker_pool *pool = worker->pool;",
            "\tstruct worker *collision;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\t/*",
            "\t * A single work shouldn't be executed concurrently by multiple workers.",
            "\t * __queue_work() ensures that @work doesn't jump to a different pool",
            "\t * while still running in the previous pool. Here, we should ensure that",
            "\t * @work is not executed concurrently by multiple workers from the same",
            "\t * pool. Check whether anyone is already processing the work. If so,",
            "\t * defer the work to the currently executing one.",
            "\t */",
            "\tcollision = find_worker_executing_work(pool, work);",
            "\tif (unlikely(collision)) {",
            "\t\tmove_linked_works(work, &collision->scheduled, nextp);",
            "\t\treturn false;",
            "\t}",
            "",
            "\tmove_linked_works(work, &worker->scheduled, nextp);",
            "\treturn true;",
            "}",
            "static bool kick_pool(struct worker_pool *pool)",
            "{",
            "\tstruct worker *worker = first_idle_worker(pool);",
            "\tstruct task_struct *p;",
            "",
            "\tlockdep_assert_held(&pool->lock);",
            "",
            "\tif (!need_more_worker(pool) || !worker)",
            "\t\treturn false;",
            "",
            "\tp = worker->task;",
            "",
            "#ifdef CONFIG_SMP",
            "\t/*",
            "\t * Idle @worker is about to execute @work and waking up provides an",
            "\t * opportunity to migrate @worker at a lower cost by setting the task's",
            "\t * wake_cpu field. Let's see if we want to move @worker to improve",
            "\t * execution locality.",
            "\t *",
            "\t * We're waking the worker that went idle the latest and there's some",
            "\t * chance that @worker is marked idle but hasn't gone off CPU yet. If",
            "\t * so, setting the wake_cpu won't do anything. As this is a best-effort",
            "\t * optimization and the race window is narrow, let's leave as-is for",
            "\t * now. If this becomes pronounced, we can skip over workers which are",
            "\t * still on cpu when picking an idle worker.",
            "\t *",
            "\t * If @pool has non-strict affinity, @worker might have ended up outside",
            "\t * its affinity scope. Repatriate.",
            "\t */",
            "\tif (!pool->attrs->affn_strict &&",
            "\t    !cpumask_test_cpu(p->wake_cpu, pool->attrs->__pod_cpumask)) {",
            "\t\tstruct work_struct *work = list_first_entry(&pool->worklist,",
            "\t\t\t\t\t\tstruct work_struct, entry);",
            "\t\tint wake_cpu = cpumask_any_and_distribute(pool->attrs->__pod_cpumask,",
            "\t\t\t\t\t\t\t  cpu_online_mask);",
            "\t\tif (wake_cpu < nr_cpu_ids) {",
            "\t\t\tp->wake_cpu = wake_cpu;",
            "\t\t\tget_work_pwq(work)->stats[PWQ_STAT_REPATRIATED]++;",
            "\t\t}",
            "\t}",
            "#endif",
            "\twake_up_process(p);",
            "\treturn true;",
            "}"
          ],
          "function_name": "worker_clr_flags, worker_enter_idle, worker_leave_idle, move_linked_works, assign_work, kick_pool",
          "description": "实现工作者线程空闲状态切换和工作项迁移机制，包含空闲工作者列表管理、链接工作项批量转移功能，以及唤醒工作者线程的调度逻辑，支持跨CPU亲和性迁移优化，确保工作项正确分发到可用工作者线程。",
          "similarity": 0.5536346435546875
        },
        {
          "chunk_id": 29,
          "file_path": "kernel/workqueue.c",
          "start_line": 5864,
          "end_line": 5966,
          "content": [
            "int workqueue_unbound_exclude_cpumask(cpumask_var_t exclude_cpumask)",
            "{",
            "\tcpumask_var_t cpumask;",
            "\tint ret = 0;",
            "",
            "\tif (!zalloc_cpumask_var(&cpumask, GFP_KERNEL))",
            "\t\treturn -ENOMEM;",
            "",
            "\tlockdep_assert_cpus_held();",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\t/* Save the current isolated cpumask & export it via sysfs */",
            "\tcpumask_copy(wq_isolated_cpumask, exclude_cpumask);",
            "",
            "\t/*",
            "\t * If the operation fails, it will fall back to",
            "\t * wq_requested_unbound_cpumask which is initially set to",
            "\t * (HK_TYPE_WQ ∩ HK_TYPE_DOMAIN) house keeping mask and rewritten",
            "\t * by any subsequent write to workqueue/cpumask sysfs file.",
            "\t */",
            "\tif (!cpumask_andnot(cpumask, wq_requested_unbound_cpumask, exclude_cpumask))",
            "\t\tcpumask_copy(cpumask, wq_requested_unbound_cpumask);",
            "\tif (!cpumask_equal(cpumask, wq_unbound_cpumask))",
            "\t\tret = workqueue_apply_unbound_cpumask(cpumask);",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tfree_cpumask_var(cpumask);",
            "\treturn ret;",
            "}",
            "static int parse_affn_scope(const char *val)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < ARRAY_SIZE(wq_affn_names); i++) {",
            "\t\tif (!strncasecmp(val, wq_affn_names[i], strlen(wq_affn_names[i])))",
            "\t\t\treturn i;",
            "\t}",
            "\treturn -EINVAL;",
            "}",
            "static int wq_affn_dfl_set(const char *val, const struct kernel_param *kp)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tint affn, cpu;",
            "",
            "\taffn = parse_affn_scope(val);",
            "\tif (affn < 0)",
            "\t\treturn affn;",
            "\tif (affn == WQ_AFFN_DFL)",
            "\t\treturn -EINVAL;",
            "",
            "\tcpus_read_lock();",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\twq_affn_dfl = affn;",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tfor_each_online_cpu(cpu) {",
            "\t\t\twq_update_pod(wq, cpu, cpu, true);",
            "\t\t}",
            "\t}",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\tcpus_read_unlock();",
            "",
            "\treturn 0;",
            "}",
            "static int wq_affn_dfl_get(char *buffer, const struct kernel_param *kp)",
            "{",
            "\treturn scnprintf(buffer, PAGE_SIZE, \"%s\\n\", wq_affn_names[wq_affn_dfl]);",
            "}",
            "static ssize_t per_cpu_show(struct device *dev, struct device_attribute *attr,",
            "\t\t\t    char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "",
            "\treturn scnprintf(buf, PAGE_SIZE, \"%d\\n\", (bool)!(wq->flags & WQ_UNBOUND));",
            "}",
            "static ssize_t max_active_show(struct device *dev,",
            "\t\t\t       struct device_attribute *attr, char *buf)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "",
            "\treturn scnprintf(buf, PAGE_SIZE, \"%d\\n\", wq->saved_max_active);",
            "}",
            "static ssize_t max_active_store(struct device *dev,",
            "\t\t\t\tstruct device_attribute *attr, const char *buf,",
            "\t\t\t\tsize_t count)",
            "{",
            "\tstruct workqueue_struct *wq = dev_to_wq(dev);",
            "\tint val;",
            "",
            "\tif (sscanf(buf, \"%d\", &val) != 1 || val <= 0)",
            "\t\treturn -EINVAL;",
            "",
            "\tworkqueue_set_max_active(wq, val);",
            "\treturn count;",
            "}",
            "static void apply_wqattrs_lock(void)",
            "{",
            "\t/* CPUs should stay stable across pwq creations and installations */",
            "\tcpus_read_lock();",
            "\tmutex_lock(&wq_pool_mutex);",
            "}"
          ],
          "function_name": "workqueue_unbound_exclude_cpumask, parse_affn_scope, wq_affn_dfl_set, wq_affn_dfl_get, per_cpu_show, max_active_show, max_active_store, apply_wqattrs_lock",
          "description": "配置非绑定工作者的CPU排除掩码和默认亲和性策略，暴露工作队列属性供sysfs访问并管理最大并发数参数",
          "similarity": 0.5488815307617188
        },
        {
          "chunk_id": 8,
          "file_path": "kernel/workqueue.c",
          "start_line": 1832,
          "end_line": 1933,
          "content": [
            "bool queue_work_on(int cpu, struct workqueue_struct *wq,",
            "\t\t   struct work_struct *work)",
            "{",
            "\tbool ret = false;",
            "\tunsigned long flags;",
            "",
            "\tlocal_irq_save(flags);",
            "",
            "\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {",
            "\t\t__queue_work(cpu, wq, work);",
            "\t\tret = true;",
            "\t}",
            "",
            "\tlocal_irq_restore(flags);",
            "\treturn ret;",
            "}",
            "static int select_numa_node_cpu(int node)",
            "{",
            "\tint cpu;",
            "",
            "\t/* Delay binding to CPU if node is not valid or online */",
            "\tif (node < 0 || node >= MAX_NUMNODES || !node_online(node))",
            "\t\treturn WORK_CPU_UNBOUND;",
            "",
            "\t/* Use local node/cpu if we are already there */",
            "\tcpu = raw_smp_processor_id();",
            "\tif (node == cpu_to_node(cpu))",
            "\t\treturn cpu;",
            "",
            "\t/* Use \"random\" otherwise know as \"first\" online CPU of node */",
            "\tcpu = cpumask_any_and(cpumask_of_node(node), cpu_online_mask);",
            "",
            "\t/* If CPU is valid return that, otherwise just defer */",
            "\treturn cpu < nr_cpu_ids ? cpu : WORK_CPU_UNBOUND;",
            "}",
            "bool queue_work_node(int node, struct workqueue_struct *wq,",
            "\t\t     struct work_struct *work)",
            "{",
            "\tunsigned long flags;",
            "\tbool ret = false;",
            "",
            "\t/*",
            "\t * This current implementation is specific to unbound workqueues.",
            "\t * Specifically we only return the first available CPU for a given",
            "\t * node instead of cycling through individual CPUs within the node.",
            "\t *",
            "\t * If this is used with a per-cpu workqueue then the logic in",
            "\t * workqueue_select_cpu_near would need to be updated to allow for",
            "\t * some round robin type logic.",
            "\t */",
            "\tWARN_ON_ONCE(!(wq->flags & WQ_UNBOUND));",
            "",
            "\tlocal_irq_save(flags);",
            "",
            "\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {",
            "\t\tint cpu = select_numa_node_cpu(node);",
            "",
            "\t\t__queue_work(cpu, wq, work);",
            "\t\tret = true;",
            "\t}",
            "",
            "\tlocal_irq_restore(flags);",
            "\treturn ret;",
            "}",
            "void delayed_work_timer_fn(struct timer_list *t)",
            "{",
            "\tstruct delayed_work *dwork = from_timer(dwork, t, timer);",
            "",
            "\t/* should have been called from irqsafe timer with irq already off */",
            "\t__queue_work(dwork->cpu, dwork->wq, &dwork->work);",
            "}",
            "static void __queue_delayed_work(int cpu, struct workqueue_struct *wq,",
            "\t\t\t\tstruct delayed_work *dwork, unsigned long delay)",
            "{",
            "\tstruct timer_list *timer = &dwork->timer;",
            "\tstruct work_struct *work = &dwork->work;",
            "",
            "\tWARN_ON_ONCE(!wq);",
            "\tWARN_ON_ONCE(timer->function != delayed_work_timer_fn);",
            "\tWARN_ON_ONCE(timer_pending(timer));",
            "\tWARN_ON_ONCE(!list_empty(&work->entry));",
            "",
            "\t/*",
            "\t * If @delay is 0, queue @dwork->work immediately.  This is for",
            "\t * both optimization and correctness.  The earliest @timer can",
            "\t * expire is on the closest next tick and delayed_work users depend",
            "\t * on that there's no such delay when @delay is 0.",
            "\t */",
            "\tif (!delay) {",
            "\t\t__queue_work(cpu, wq, &dwork->work);",
            "\t\treturn;",
            "\t}",
            "",
            "\tdwork->wq = wq;",
            "\tdwork->cpu = cpu;",
            "\ttimer->expires = jiffies + delay;",
            "",
            "\tif (unlikely(cpu != WORK_CPU_UNBOUND))",
            "\t\tadd_timer_on(timer, cpu);",
            "\telse",
            "\t\tadd_timer(timer);",
            "}"
          ],
          "function_name": "queue_work_on, select_numa_node_cpu, queue_work_node, delayed_work_timer_fn, __queue_delayed_work",
          "description": "该代码块实现基于NUMA节点的延迟工作调度。queue_work_on指定CPU提交工作；select_numa_node_cpu选择节点对应的CPU；delayed_work_timer_fn作为延迟工作超时时的回调；__queue_delayed_work设置定时器并安排工作项执行。",
          "similarity": 0.5459192991256714
        },
        {
          "chunk_id": 33,
          "file_path": "kernel/workqueue.c",
          "start_line": 6492,
          "end_line": 6592,
          "content": [
            "static void panic_on_wq_watchdog(void)",
            "{",
            "\tstatic unsigned int wq_stall;",
            "",
            "\tif (wq_panic_on_stall) {",
            "\t\twq_stall++;",
            "\t\tBUG_ON(wq_stall >= wq_panic_on_stall);",
            "\t}",
            "}",
            "static void wq_watchdog_reset_touched(void)",
            "{",
            "\tint cpu;",
            "",
            "\twq_watchdog_touched = jiffies;",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tper_cpu(wq_watchdog_touched_cpu, cpu) = jiffies;",
            "}",
            "static void wq_watchdog_timer_fn(struct timer_list *unused)",
            "{",
            "\tunsigned long thresh = READ_ONCE(wq_watchdog_thresh) * HZ;",
            "\tbool lockup_detected = false;",
            "\tbool cpu_pool_stall = false;",
            "\tunsigned long now = jiffies;",
            "\tstruct worker_pool *pool;",
            "\tint pi;",
            "",
            "\tif (!thresh)",
            "\t\treturn;",
            "",
            "\trcu_read_lock();",
            "",
            "\tfor_each_pool(pool, pi) {",
            "\t\tunsigned long pool_ts, touched, ts;",
            "",
            "\t\tpool->cpu_stall = false;",
            "\t\tif (list_empty(&pool->worklist))",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * If a virtual machine is stopped by the host it can look to",
            "\t\t * the watchdog like a stall.",
            "\t\t */",
            "\t\tkvm_check_and_clear_guest_paused();",
            "",
            "\t\t/* get the latest of pool and touched timestamps */",
            "\t\tif (pool->cpu >= 0)",
            "\t\t\ttouched = READ_ONCE(per_cpu(wq_watchdog_touched_cpu, pool->cpu));",
            "\t\telse",
            "\t\t\ttouched = READ_ONCE(wq_watchdog_touched);",
            "\t\tpool_ts = READ_ONCE(pool->watchdog_ts);",
            "",
            "\t\tif (time_after(pool_ts, touched))",
            "\t\t\tts = pool_ts;",
            "\t\telse",
            "\t\t\tts = touched;",
            "",
            "\t\t/* did we stall? */",
            "\t\tif (time_after(now, ts + thresh)) {",
            "\t\t\tlockup_detected = true;",
            "\t\t\tif (pool->cpu >= 0) {",
            "\t\t\t\tpool->cpu_stall = true;",
            "\t\t\t\tcpu_pool_stall = true;",
            "\t\t\t}",
            "\t\t\tpr_emerg(\"BUG: workqueue lockup - pool\");",
            "\t\t\tpr_cont_pool_info(pool);",
            "\t\t\tpr_cont(\" stuck for %us!\\n\",",
            "\t\t\t\tjiffies_to_msecs(now - pool_ts) / 1000);",
            "\t\t}",
            "",
            "",
            "\t}",
            "",
            "\trcu_read_unlock();",
            "",
            "\tif (lockup_detected)",
            "\t\tshow_all_workqueues();",
            "",
            "\tif (cpu_pool_stall)",
            "\t\tshow_cpu_pools_hogs();",
            "",
            "\tif (lockup_detected)",
            "\t\tpanic_on_wq_watchdog();",
            "",
            "\twq_watchdog_reset_touched();",
            "\tmod_timer(&wq_watchdog_timer, jiffies + thresh);",
            "}",
            "notrace void wq_watchdog_touch(int cpu)",
            "{",
            "\tunsigned long thresh = READ_ONCE(wq_watchdog_thresh) * HZ;",
            "\tunsigned long touch_ts = READ_ONCE(wq_watchdog_touched);",
            "\tunsigned long now = jiffies;",
            "",
            "\tif (cpu >= 0)",
            "\t\tper_cpu(wq_watchdog_touched_cpu, cpu) = now;",
            "\telse",
            "\t\tWARN_ONCE(1, \"%s should be called with valid CPU\", __func__);",
            "",
            "\t/* Don't unnecessarily store to global cacheline */",
            "\tif (time_after(now, touch_ts + thresh / 4))",
            "\t\tWRITE_ONCE(wq_watchdog_touched, jiffies);",
            "}"
          ],
          "function_name": "panic_on_wq_watchdog, wq_watchdog_reset_touched, wq_watchdog_timer_fn, wq_watchdog_touch",
          "description": "实现工作队列看门狗机制，通过定时器周期性检测任务阻塞状态，当检测到CPU池超时时触发警告日志和panic，包含超时阈值管理、时间戳更新及阻塞状态标识逻辑。",
          "similarity": 0.5449425578117371
        },
        {
          "chunk_id": 28,
          "file_path": "kernel/workqueue.c",
          "start_line": 5717,
          "end_line": 5828,
          "content": [
            "void freeze_workqueues_begin(void)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tstruct pool_workqueue *pwq;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tWARN_ON_ONCE(workqueue_freezing);",
            "\tworkqueue_freezing = true;",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tmutex_lock(&wq->mutex);",
            "\t\tfor_each_pwq(pwq, wq)",
            "\t\t\tpwq_adjust_max_active(pwq);",
            "\t\tmutex_unlock(&wq->mutex);",
            "\t}",
            "",
            "\tmutex_unlock(&wq_pool_mutex);",
            "}",
            "bool freeze_workqueues_busy(void)",
            "{",
            "\tbool busy = false;",
            "\tstruct workqueue_struct *wq;",
            "\tstruct pool_workqueue *pwq;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tWARN_ON_ONCE(!workqueue_freezing);",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tif (!(wq->flags & WQ_FREEZABLE))",
            "\t\t\tcontinue;",
            "\t\t/*",
            "\t\t * nr_active is monotonically decreasing.  It's safe",
            "\t\t * to peek without lock.",
            "\t\t */",
            "\t\trcu_read_lock();",
            "\t\tfor_each_pwq(pwq, wq) {",
            "\t\t\tWARN_ON_ONCE(pwq->nr_active < 0);",
            "\t\t\tif (pwq->nr_active) {",
            "\t\t\t\tbusy = true;",
            "\t\t\t\trcu_read_unlock();",
            "\t\t\t\tgoto out_unlock;",
            "\t\t\t}",
            "\t\t}",
            "\t\trcu_read_unlock();",
            "\t}",
            "out_unlock:",
            "\tmutex_unlock(&wq_pool_mutex);",
            "\treturn busy;",
            "}",
            "void thaw_workqueues(void)",
            "{",
            "\tstruct workqueue_struct *wq;",
            "\tstruct pool_workqueue *pwq;",
            "",
            "\tmutex_lock(&wq_pool_mutex);",
            "",
            "\tif (!workqueue_freezing)",
            "\t\tgoto out_unlock;",
            "",
            "\tworkqueue_freezing = false;",
            "",
            "\t/* restore max_active and repopulate worklist */",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tmutex_lock(&wq->mutex);",
            "\t\tfor_each_pwq(pwq, wq)",
            "\t\t\tpwq_adjust_max_active(pwq);",
            "\t\tmutex_unlock(&wq->mutex);",
            "\t}",
            "",
            "out_unlock:",
            "\tmutex_unlock(&wq_pool_mutex);",
            "}",
            "static int workqueue_apply_unbound_cpumask(const cpumask_var_t unbound_cpumask)",
            "{",
            "\tLIST_HEAD(ctxs);",
            "\tint ret = 0;",
            "\tstruct workqueue_struct *wq;",
            "\tstruct apply_wqattrs_ctx *ctx, *n;",
            "",
            "\tlockdep_assert_held(&wq_pool_mutex);",
            "",
            "\tlist_for_each_entry(wq, &workqueues, list) {",
            "\t\tif (!(wq->flags & WQ_UNBOUND))",
            "\t\t\tcontinue;",
            "\t\t/* creating multiple pwqs breaks ordering guarantee */",
            "\t\tif (wq->flags & __WQ_ORDERED)",
            "\t\t\tcontinue;",
            "",
            "\t\tctx = apply_wqattrs_prepare(wq, wq->unbound_attrs, unbound_cpumask);",
            "\t\tif (IS_ERR(ctx)) {",
            "\t\t\tret = PTR_ERR(ctx);",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tlist_add_tail(&ctx->list, &ctxs);",
            "\t}",
            "",
            "\tlist_for_each_entry_safe(ctx, n, &ctxs, list) {",
            "\t\tif (!ret)",
            "\t\t\tapply_wqattrs_commit(ctx);",
            "\t\tapply_wqattrs_cleanup(ctx);",
            "\t}",
            "",
            "\tif (!ret) {",
            "\t\tmutex_lock(&wq_pool_attach_mutex);",
            "\t\tcpumask_copy(wq_unbound_cpumask, unbound_cpumask);",
            "\t\tmutex_unlock(&wq_pool_attach_mutex);",
            "\t}",
            "\treturn ret;",
            "}"
          ],
          "function_name": "freeze_workqueues_begin, freeze_workqueues_busy, thaw_workqueues, workqueue_apply_unbound_cpumask",
          "description": "实现工作队列冻结/解冻逻辑，检查是否存在活跃任务并调整最大并发数，动态修改非绑定工作者的CPU掩码配置",
          "similarity": 0.5441224575042725
        }
      ]
    },
    {
      "source_file": "kernel/kthread.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:30:24\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `kthread.c`\n\n---\n\n# kthread.c 技术文档\n\n## 文件概述\n\n`kthread.c` 是 Linux 内核中实现内核线程（kernel thread, kthread）管理机制的核心文件。它提供了创建、控制、同步和销毁内核线程的基础设施，确保内核线程在干净、受控的环境中运行，即使是从用户空间（如 modprobe、CPU 热插拔等）触发创建也能保证一致性。该文件实现了 kthread 的生命周期管理、状态控制（如停止、暂停）、数据访问接口以及与调度器、cgroup、freezer 等子系统的集成。\n\n## 核心功能\n\n### 主要数据结构\n\n- **`struct kthread_create_info`**  \n  用于在 `kthread_create()` 和后台守护线程 `kthreadd` 之间传递创建参数和结果，包含线程函数、数据、节点信息、任务结构体指针和完成量。\n\n- **`struct kthread`**  \n  内核线程的私有控制块，挂载在 `task_struct->worker_private` 上，包含：\n  - 状态标志位（`KTHREAD_IS_PER_CPU`, `KTHREAD_SHOULD_STOP`, `KTHREAD_SHOULD_PARK`）\n  - CPU 绑定信息\n  - 线程函数指针和用户数据\n  - 用于同步的 `parked` 和 `exited` 完成量\n  - 完整线程名（当 `task->comm` 被截断时使用）\n  - （可选）块设备 cgroup 上下文（`blkcg_css`）\n\n- **全局变量**\n  - `kthread_create_lock`：保护 `kthread_create_list` 的自旋锁\n  - `kthread_create_list`：待创建内核线程的请求队列\n  - `kthreadd_task`：负责实际创建内核线程的守护进程任务结构体\n\n### 主要函数\n\n- **状态查询函数**\n  - `kthread_should_stop()`：检查是否应停止线程（由 `kthread_stop()` 触发）\n  - `kthread_should_park()`：检查是否应暂停线程（由 `kthread_park()` 触发）\n  - `kthread_should_stop_or_park()`：同时检查停止或暂停请求\n  - `kthread_freezable_should_stop()`：支持冻结的 kthread 停止检查，集成 freezer 机制\n\n- **数据访问函数**\n  - `kthread_func()`：获取线程创建时指定的函数指针\n  - `kthread_data()`：获取线程创建时传入的私有数据\n  - `kthread_probe_data()`：安全地探测可能的 kthread 数据（使用 `copy_from_kernel_nofault` 避免崩溃）\n  - `get_kthread_comm()`：获取完整的线程名称（优先使用 `full_name`）\n\n- **生命周期管理**\n  - `set_kthread_struct()`：为新任务分配并初始化 `struct kthread`\n  - `free_kthread_struct()`：释放 `struct kthread` 及其资源\n  - `kthread_parkme()`：将当前线程置于 `TASK_PARKED` 状态并等待唤醒\n  - `kthread_exit()`：终止当前 kthread 并返回结果（未在代码片段中完整显示）\n\n- **辅助函数**\n  - `to_kthread()` / `__to_kthread()`：从 `task_struct` 安全转换为 `struct kthread`，后者不假设任务一定是 kthread\n\n## 关键实现\n\n### kthread 私有数据管理\n- 每个 kthread 通过 `task_struct->worker_private` 指向其 `struct kthread` 实例。\n- `to_kthread()` 在访问前验证 `PF_KTHREAD` 标志，确保类型安全。\n- `__to_kthread()` 更加保守，仅在同时满足 `worker_private != NULL` 且 `PF_KTHREAD` 时才返回有效指针，以应对 `kernel_thread()` 可能执行 `exec()` 导致标志失效的情况。\n\n### 线程暂停机制（Parking）\n- 使用 `TASK_PARKED` 特殊任务状态，避免与常规调度状态冲突。\n- 在设置状态和检查标志之间使用原子操作，防止唤醒丢失。\n- 调用 `schedule_preempt_disabled()` 禁用抢占，确保 `kthread_park()` 调用者能可靠检测到线程已暂停。\n\n### 安全数据访问\n- `kthread_probe_data()` 使用 `copy_from_kernel_nofault()` 安全读取数据指针，即使目标内存无效也不会导致内核 oops，适用于调试或不确定上下文。\n\n### 冻结集成\n- `kthread_freezable_should_stop()` 在检查停止标志前先处理冻结请求，调用 `__refrigerator()` 进入冻结状态，避免 freezer 与 kthread_stop 死锁。\n\n### 名称管理\n- 当线程名超过 `TASK_COMM_LEN` 时，原始名称存储在 `kthread->full_name` 中，`get_kthread_comm()` 优先返回完整名称。\n\n## 依赖关系\n\n- **调度子系统**：依赖 `sched.h` 提供任务状态管理、调度原语（`schedule()`）、CPU 隔离等。\n- **内存管理**：使用 `slab.h` 分配 `kthread` 结构，`mm.h` 处理内存上下文。\n- **同步机制**：依赖 `completion.h` 实现线程创建和状态同步。\n- **cgroup 子系统**：条件编译支持 `CONFIG_BLK_CGROUP`，集成块设备 cgroup 控制。\n- **冻结子系统**：通过 `freezer.h` 与系统 suspend/hibernate 机制协作。\n- **追踪系统**：集成 `trace/events/sched.h` 提供调度事件追踪。\n- **用户空间接口**：通过 `uaccess.h` 支持安全内核空间访问（用于 `kthread_probe_data`）。\n\n## 使用场景\n\n- **内核模块加载**：`modprobe` 触发的模块可能创建 kthread，需通过 `kthreadd` 确保干净环境。\n- **设备驱动**：驱动程序使用 `kthread_run()` 创建工作线程处理中断下半部或轮询任务。\n- **系统服务线程**：如 `kswapd`（内存回收）、`kcompactd`（内存压缩）等核心内核线程。\n- **CPU 热插拔**：在 CPU 上下线时创建或迁移 per-CPU kthread。\n- **电源管理**：通过 `kthread_freezable_should_stop()` 支持系统 suspend 时冻结 kthread。\n- **动态资源管理**：使用 `kthread_park/unpark` 暂停/恢复线程以节省资源（如空闲时暂停工作线程）。\n- **调试与监控**：工具通过 `kthread_func()` 和 `kthread_data()` 获取线程上下文信息。",
      "similarity": 0.6481252908706665,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/kthread.c",
          "start_line": 299,
          "end_line": 413,
          "content": [
            "void kthread_parkme(void)",
            "{",
            "\t__kthread_parkme(to_kthread(current));",
            "}",
            "void __noreturn kthread_exit(long result)",
            "{",
            "\tstruct kthread *kthread = to_kthread(current);",
            "\tkthread->result = result;",
            "\tdo_exit(0);",
            "}",
            "void __noreturn kthread_complete_and_exit(struct completion *comp, long code)",
            "{",
            "\tif (comp)",
            "\t\tcomplete(comp);",
            "",
            "\tkthread_exit(code);",
            "}",
            "static int kthread(void *_create)",
            "{",
            "\tstatic const struct sched_param param = { .sched_priority = 0 };",
            "\t/* Copy data: it's on kthread's stack */",
            "\tstruct kthread_create_info *create = _create;",
            "\tint (*threadfn)(void *data) = create->threadfn;",
            "\tvoid *data = create->data;",
            "\tstruct completion *done;",
            "\tstruct kthread *self;",
            "\tint ret;",
            "",
            "\tself = to_kthread(current);",
            "",
            "\t/* Release the structure when caller killed by a fatal signal. */",
            "\tdone = xchg(&create->done, NULL);",
            "\tif (!done) {",
            "\t\tkfree(create->full_name);",
            "\t\tkfree(create);",
            "\t\tkthread_exit(-EINTR);",
            "\t}",
            "",
            "\tself->full_name = create->full_name;",
            "\tself->threadfn = threadfn;",
            "\tself->data = data;",
            "",
            "\t/*",
            "\t * The new thread inherited kthreadd's priority and CPU mask. Reset",
            "\t * back to default in case they have been changed.",
            "\t */",
            "\tsched_setscheduler_nocheck(current, SCHED_NORMAL, &param);",
            "\tset_cpus_allowed_ptr(current, housekeeping_cpumask(HK_TYPE_KTHREAD));",
            "",
            "\t/* OK, tell user we're spawned, wait for stop or wakeup */",
            "\t__set_current_state(TASK_UNINTERRUPTIBLE);",
            "\tcreate->result = current;",
            "\t/*",
            "\t * Thread is going to call schedule(), do not preempt it,",
            "\t * or the creator may spend more time in wait_task_inactive().",
            "\t */",
            "\tpreempt_disable();",
            "\tcomplete(done);",
            "\tschedule_preempt_disabled();",
            "\tpreempt_enable();",
            "",
            "\tret = -EINTR;",
            "\tif (!test_bit(KTHREAD_SHOULD_STOP, &self->flags)) {",
            "\t\tcgroup_kthread_ready();",
            "\t\t__kthread_parkme(self);",
            "\t\tret = threadfn(data);",
            "\t}",
            "\tkthread_exit(ret);",
            "}",
            "int tsk_fork_get_node(struct task_struct *tsk)",
            "{",
            "#ifdef CONFIG_NUMA",
            "\tif (tsk == kthreadd_task)",
            "\t\treturn tsk->pref_node_fork;",
            "#endif",
            "\treturn NUMA_NO_NODE;",
            "}",
            "static void create_kthread(struct kthread_create_info *create)",
            "{",
            "\tint pid;",
            "",
            "#ifdef CONFIG_NUMA",
            "\tcurrent->pref_node_fork = create->node;",
            "#endif",
            "\t/* We want our own signal handler (we take no signals by default). */",
            "\tpid = kernel_thread(kthread, create, create->full_name,",
            "\t\t\t    CLONE_FS | CLONE_FILES | SIGCHLD);",
            "\tif (pid < 0) {",
            "\t\t/* Release the structure when caller killed by a fatal signal. */",
            "\t\tstruct completion *done = xchg(&create->done, NULL);",
            "",
            "\t\tkfree(create->full_name);",
            "\t\tif (!done) {",
            "\t\t\tkfree(create);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\tcreate->result = ERR_PTR(pid);",
            "\t\tcomplete(done);",
            "\t}",
            "}",
            "static void __kthread_bind_mask(struct task_struct *p, const struct cpumask *mask, unsigned int state)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tif (!wait_task_inactive(p, state)) {",
            "\t\tWARN_ON(1);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* It's safe because the task is inactive. */",
            "\traw_spin_lock_irqsave(&p->pi_lock, flags);",
            "\tdo_set_cpus_allowed(p, mask);",
            "\tp->flags |= PF_NO_SETAFFINITY;",
            "\traw_spin_unlock_irqrestore(&p->pi_lock, flags);",
            "}"
          ],
          "function_name": "kthread_parkme, kthread_exit, kthread_complete_and_exit, kthread, tsk_fork_get_node, create_kthread, __kthread_bind_mask",
          "description": "处理线程执行流程、节点绑定及异常退出，kthread作为内核线程入口执行指定函数，create_kthread创建新线程并绑定CPU，__kthread_bind_mask调整线程CPU亲和性。",
          "similarity": 0.6566898226737976
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/kthread.c",
          "start_line": 102,
          "end_line": 211,
          "content": [
            "void get_kthread_comm(char *buf, size_t buf_size, struct task_struct *tsk)",
            "{",
            "\tstruct kthread *kthread = to_kthread(tsk);",
            "",
            "\tif (!kthread || !kthread->full_name) {",
            "\t\t__get_task_comm(buf, buf_size, tsk);",
            "\t\treturn;",
            "\t}",
            "",
            "\tstrscpy_pad(buf, kthread->full_name, buf_size);",
            "}",
            "bool set_kthread_struct(struct task_struct *p)",
            "{",
            "\tstruct kthread *kthread;",
            "",
            "\tif (WARN_ON_ONCE(to_kthread(p)))",
            "\t\treturn false;",
            "",
            "\tkthread = kzalloc(sizeof(*kthread), GFP_KERNEL);",
            "\tif (!kthread)",
            "\t\treturn false;",
            "",
            "\tinit_completion(&kthread->exited);",
            "\tinit_completion(&kthread->parked);",
            "\tp->vfork_done = &kthread->exited;",
            "",
            "\tp->worker_private = kthread;",
            "\treturn true;",
            "}",
            "void free_kthread_struct(struct task_struct *k)",
            "{",
            "\tstruct kthread *kthread;",
            "",
            "\t/*",
            "\t * Can be NULL if kmalloc() in set_kthread_struct() failed.",
            "\t */",
            "\tkthread = to_kthread(k);",
            "\tif (!kthread)",
            "\t\treturn;",
            "",
            "#ifdef CONFIG_BLK_CGROUP",
            "\tWARN_ON_ONCE(kthread->blkcg_css);",
            "#endif",
            "\tk->worker_private = NULL;",
            "\tkfree(kthread->full_name);",
            "\tkfree(kthread);",
            "}",
            "bool kthread_should_stop(void)",
            "{",
            "\treturn test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);",
            "}",
            "static bool __kthread_should_park(struct task_struct *k)",
            "{",
            "\treturn test_bit(KTHREAD_SHOULD_PARK, &to_kthread(k)->flags);",
            "}",
            "bool kthread_should_park(void)",
            "{",
            "\treturn __kthread_should_park(current);",
            "}",
            "bool kthread_should_stop_or_park(void)",
            "{",
            "\tstruct kthread *kthread = __to_kthread(current);",
            "",
            "\tif (!kthread)",
            "\t\treturn false;",
            "",
            "\treturn kthread->flags & (BIT(KTHREAD_SHOULD_STOP) | BIT(KTHREAD_SHOULD_PARK));",
            "}",
            "bool kthread_freezable_should_stop(bool *was_frozen)",
            "{",
            "\tbool frozen = false;",
            "",
            "\tmight_sleep();",
            "",
            "\tif (unlikely(freezing(current)))",
            "\t\tfrozen = __refrigerator(true);",
            "",
            "\tif (was_frozen)",
            "\t\t*was_frozen = frozen;",
            "",
            "\treturn kthread_should_stop();",
            "}",
            "static void __kthread_parkme(struct kthread *self)",
            "{",
            "\tfor (;;) {",
            "\t\t/*",
            "\t\t * TASK_PARKED is a special state; we must serialize against",
            "\t\t * possible pending wakeups to avoid store-store collisions on",
            "\t\t * task->state.",
            "\t\t *",
            "\t\t * Such a collision might possibly result in the task state",
            "\t\t * changin from TASK_PARKED and us failing the",
            "\t\t * wait_task_inactive() in kthread_park().",
            "\t\t */",
            "\t\tset_special_state(TASK_PARKED);",
            "\t\tif (!test_bit(KTHREAD_SHOULD_PARK, &self->flags))",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * Thread is going to call schedule(), do not preempt it,",
            "\t\t * or the caller of kthread_park() may spend more time in",
            "\t\t * wait_task_inactive().",
            "\t\t */",
            "\t\tpreempt_disable();",
            "\t\tcomplete(&self->parked);",
            "\t\tschedule_preempt_disabled();",
            "\t\tpreempt_enable();",
            "\t}",
            "\t__set_current_state(TASK_RUNNING);",
            "}"
          ],
          "function_name": "get_kthread_comm, set_kthread_struct, free_kthread_struct, kthread_should_stop, __kthread_should_park, kthread_should_park, kthread_should_stop_or_park, kthread_freezable_should_stop, __kthread_parkme",
          "description": "实现内核线程的名称获取、结构体分配与释放、状态检测等功能，set_kthread_struct分配并初始化线程结构体，kthread_should_stop系列函数检测线程终止或停放标志。",
          "similarity": 0.6380387544631958
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/kthread.c",
          "start_line": 1,
          "end_line": 101,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/* Kernel thread helper functions.",
            " *   Copyright (C) 2004 IBM Corporation, Rusty Russell.",
            " *   Copyright (C) 2009 Red Hat, Inc.",
            " *",
            " * Creation is done via kthreadd, so that we get a clean environment",
            " * even if we're invoked from userspace (think modprobe, hotplug cpu,",
            " * etc.).",
            " */",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/mm.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/sched.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/kthread.h>",
            "#include <linux/completion.h>",
            "#include <linux/err.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/unistd.h>",
            "#include <linux/file.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/slab.h>",
            "#include <linux/freezer.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/numa.h>",
            "#include <linux/sched/isolation.h>",
            "#include <trace/events/sched.h>",
            "",
            "#ifdef CONFIG_IEE",
            "#include <asm/iee-token.h>",
            "#endif",
            "",
            "static DEFINE_SPINLOCK(kthread_create_lock);",
            "static LIST_HEAD(kthread_create_list);",
            "struct task_struct *kthreadd_task;",
            "",
            "struct kthread_create_info",
            "{",
            "\t/* Information passed to kthread() from kthreadd. */",
            "\tchar *full_name;",
            "\tint (*threadfn)(void *data);",
            "\tvoid *data;",
            "\tint node;",
            "",
            "\t/* Result passed back to kthread_create() from kthreadd. */",
            "\tstruct task_struct *result;",
            "\tstruct completion *done;",
            "",
            "\tstruct list_head list;",
            "};",
            "",
            "struct kthread {",
            "\tunsigned long flags;",
            "\tunsigned int cpu;",
            "\tint result;",
            "\tint (*threadfn)(void *);",
            "\tvoid *data;",
            "\tstruct completion parked;",
            "\tstruct completion exited;",
            "#ifdef CONFIG_BLK_CGROUP",
            "\tstruct cgroup_subsys_state *blkcg_css;",
            "#endif",
            "\t/* To store the full name if task comm is truncated. */",
            "\tchar *full_name;",
            "};",
            "",
            "enum KTHREAD_BITS {",
            "\tKTHREAD_IS_PER_CPU = 0,",
            "\tKTHREAD_SHOULD_STOP,",
            "\tKTHREAD_SHOULD_PARK,",
            "};",
            "",
            "static inline struct kthread *to_kthread(struct task_struct *k)",
            "{",
            "\tWARN_ON(!(k->flags & PF_KTHREAD));",
            "\treturn k->worker_private;",
            "}",
            "",
            "/*",
            " * Variant of to_kthread() that doesn't assume @p is a kthread.",
            " *",
            " * Per construction; when:",
            " *",
            " *   (p->flags & PF_KTHREAD) && p->worker_private",
            " *",
            " * the task is both a kthread and struct kthread is persistent. However",
            " * PF_KTHREAD on it's own is not, kernel_thread() can exec() (See umh.c and",
            " * begin_new_exec()).",
            " */",
            "static inline struct kthread *__to_kthread(struct task_struct *p)",
            "{",
            "\tvoid *kthread = p->worker_private;",
            "\tif (kthread && !(p->flags & PF_KTHREAD))",
            "\t\tkthread = NULL;",
            "\treturn kthread;",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义内核线程辅助函数所需的数据结构和全局变量，包括用于管理线程创建的锁、链表头、任务结构体及标志位枚举，核心功能是为后续内核线程创建和管理提供基础设施。",
          "similarity": 0.6121670007705688
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/kthread.c",
          "start_line": 731,
          "end_line": 846,
          "content": [
            "int kthread_stop_put(struct task_struct *k)",
            "{",
            "\tint ret;",
            "",
            "\tret = kthread_stop(k);",
            "\tput_task_struct(k);",
            "\treturn ret;",
            "}",
            "int kthreadd(void *unused)",
            "{",
            "\tstruct task_struct *tsk = current;",
            "",
            "\t/* Setup a clean context for our children to inherit. */",
            "\tset_task_comm(tsk, \"kthreadd\");",
            "\tignore_signals(tsk);",
            "\tset_cpus_allowed_ptr(tsk, housekeeping_cpumask(HK_TYPE_KTHREAD));",
            "\tset_mems_allowed(node_states[N_MEMORY]);",
            "",
            "\tcurrent->flags |= PF_NOFREEZE;",
            "\tcgroup_init_kthreadd();",
            "",
            "\tfor (;;) {",
            "\t\tset_current_state(TASK_INTERRUPTIBLE);",
            "\t\tif (list_empty(&kthread_create_list))",
            "\t\t\tschedule();",
            "\t\t__set_current_state(TASK_RUNNING);",
            "",
            "\t\tspin_lock(&kthread_create_lock);",
            "\t\twhile (!list_empty(&kthread_create_list)) {",
            "\t\t\tstruct kthread_create_info *create;",
            "",
            "\t\t\tcreate = list_entry(kthread_create_list.next,",
            "\t\t\t\t\t    struct kthread_create_info, list);",
            "\t\t\tlist_del_init(&create->list);",
            "\t\t\tspin_unlock(&kthread_create_lock);",
            "",
            "\t\t\tcreate_kthread(create);",
            "",
            "\t\t\tspin_lock(&kthread_create_lock);",
            "\t\t}",
            "\t\tspin_unlock(&kthread_create_lock);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void __kthread_init_worker(struct kthread_worker *worker,",
            "\t\t\t\tconst char *name,",
            "\t\t\t\tstruct lock_class_key *key)",
            "{",
            "\tmemset(worker, 0, sizeof(struct kthread_worker));",
            "\traw_spin_lock_init(&worker->lock);",
            "\tlockdep_set_class_and_name(&worker->lock, key, name);",
            "\tINIT_LIST_HEAD(&worker->work_list);",
            "\tINIT_LIST_HEAD(&worker->delayed_work_list);",
            "}",
            "int kthread_worker_fn(void *worker_ptr)",
            "{",
            "\tstruct kthread_worker *worker = worker_ptr;",
            "\tstruct kthread_work *work;",
            "",
            "\t/*",
            "\t * FIXME: Update the check and remove the assignment when all kthread",
            "\t * worker users are created using kthread_create_worker*() functions.",
            "\t */",
            "\tWARN_ON(worker->task && worker->task != current);",
            "\tworker->task = current;",
            "",
            "\tif (worker->flags & KTW_FREEZABLE)",
            "\t\tset_freezable();",
            "",
            "repeat:",
            "\tset_current_state(TASK_INTERRUPTIBLE);\t/* mb paired w/ kthread_stop */",
            "",
            "\tif (kthread_should_stop()) {",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t\traw_spin_lock_irq(&worker->lock);",
            "\t\tworker->task = NULL;",
            "\t\traw_spin_unlock_irq(&worker->lock);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\twork = NULL;",
            "\traw_spin_lock_irq(&worker->lock);",
            "\tif (!list_empty(&worker->work_list)) {",
            "\t\twork = list_first_entry(&worker->work_list,",
            "\t\t\t\t\tstruct kthread_work, node);",
            "\t\tlist_del_init(&work->node);",
            "\t}",
            "\tworker->current_work = work;",
            "\traw_spin_unlock_irq(&worker->lock);",
            "",
            "\tif (work) {",
            "\t\tkthread_work_func_t func = work->func;",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t\ttrace_sched_kthread_work_execute_start(work);",
            "\t\twork->func(work);",
            "\t\t/*",
            "\t\t * Avoid dereferencing work after this point.  The trace",
            "\t\t * event only cares about the address.",
            "\t\t */",
            "\t\ttrace_sched_kthread_work_execute_end(work, func);",
            "\t} else if (!freezing(current)) {",
            "\t\tschedule();",
            "\t} else {",
            "\t\t/*",
            "\t\t * Handle the case where the current remains",
            "\t\t * TASK_INTERRUPTIBLE. try_to_freeze() expects",
            "\t\t * the current to be TASK_RUNNING.",
            "\t\t */",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t}",
            "",
            "\ttry_to_freeze();",
            "\tcond_resched();",
            "\tgoto repeat;",
            "}"
          ],
          "function_name": "kthread_stop_put, kthreadd, __kthread_init_worker, kthread_worker_fn",
          "description": "实现kthreadd主线程逻辑及工作队列管理，kthreadd持续处理线程创建请求，kthread_worker_fn作为工作队列执行入口，支持可冻结状态下的任务调度。",
          "similarity": 0.580757200717926
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/kthread.c",
          "start_line": 982,
          "end_line": 1095,
          "content": [
            "static inline bool queuing_blocked(struct kthread_worker *worker,",
            "\t\t\t\t   struct kthread_work *work)",
            "{",
            "\tlockdep_assert_held(&worker->lock);",
            "",
            "\treturn !list_empty(&work->node) || work->canceling;",
            "}",
            "static void kthread_insert_work_sanity_check(struct kthread_worker *worker,",
            "\t\t\t\t\t     struct kthread_work *work)",
            "{",
            "\tlockdep_assert_held(&worker->lock);",
            "\tWARN_ON_ONCE(!list_empty(&work->node));",
            "\t/* Do not use a work with >1 worker, see kthread_queue_work() */",
            "\tWARN_ON_ONCE(work->worker && work->worker != worker);",
            "}",
            "static void kthread_insert_work(struct kthread_worker *worker,",
            "\t\t\t\tstruct kthread_work *work,",
            "\t\t\t\tstruct list_head *pos)",
            "{",
            "\tkthread_insert_work_sanity_check(worker, work);",
            "",
            "\ttrace_sched_kthread_work_queue_work(worker, work);",
            "",
            "\tlist_add_tail(&work->node, pos);",
            "\twork->worker = worker;",
            "\tif (!worker->current_work && likely(worker->task))",
            "\t\twake_up_process(worker->task);",
            "}",
            "bool kthread_queue_work(struct kthread_worker *worker,",
            "\t\t\tstruct kthread_work *work)",
            "{",
            "\tbool ret = false;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&worker->lock, flags);",
            "\tif (!queuing_blocked(worker, work)) {",
            "\t\tkthread_insert_work(worker, work, &worker->work_list);",
            "\t\tret = true;",
            "\t}",
            "\traw_spin_unlock_irqrestore(&worker->lock, flags);",
            "\treturn ret;",
            "}",
            "void kthread_delayed_work_timer_fn(struct timer_list *t)",
            "{",
            "\tstruct kthread_delayed_work *dwork = from_timer(dwork, t, timer);",
            "\tstruct kthread_work *work = &dwork->work;",
            "\tstruct kthread_worker *worker = work->worker;",
            "\tunsigned long flags;",
            "",
            "\t/*",
            "\t * This might happen when a pending work is reinitialized.",
            "\t * It means that it is used a wrong way.",
            "\t */",
            "\tif (WARN_ON_ONCE(!worker))",
            "\t\treturn;",
            "",
            "\traw_spin_lock_irqsave(&worker->lock, flags);",
            "\t/* Work must not be used with >1 worker, see kthread_queue_work(). */",
            "\tWARN_ON_ONCE(work->worker != worker);",
            "",
            "\t/* Move the work from worker->delayed_work_list. */",
            "\tWARN_ON_ONCE(list_empty(&work->node));",
            "\tlist_del_init(&work->node);",
            "\tif (!work->canceling)",
            "\t\tkthread_insert_work(worker, work, &worker->work_list);",
            "",
            "\traw_spin_unlock_irqrestore(&worker->lock, flags);",
            "}",
            "static void __kthread_queue_delayed_work(struct kthread_worker *worker,",
            "\t\t\t\t\t struct kthread_delayed_work *dwork,",
            "\t\t\t\t\t unsigned long delay)",
            "{",
            "\tstruct timer_list *timer = &dwork->timer;",
            "\tstruct kthread_work *work = &dwork->work;",
            "",
            "\tWARN_ON_ONCE(timer->function != kthread_delayed_work_timer_fn);",
            "",
            "\t/*",
            "\t * If @delay is 0, queue @dwork->work immediately.  This is for",
            "\t * both optimization and correctness.  The earliest @timer can",
            "\t * expire is on the closest next tick and delayed_work users depend",
            "\t * on that there's no such delay when @delay is 0.",
            "\t */",
            "\tif (!delay) {",
            "\t\tkthread_insert_work(worker, work, &worker->work_list);",
            "\t\treturn;",
            "\t}",
            "",
            "\t/* Be paranoid and try to detect possible races already now. */",
            "\tkthread_insert_work_sanity_check(worker, work);",
            "",
            "\tlist_add(&work->node, &worker->delayed_work_list);",
            "\twork->worker = worker;",
            "\ttimer->expires = jiffies + delay;",
            "\tadd_timer(timer);",
            "}",
            "bool kthread_queue_delayed_work(struct kthread_worker *worker,",
            "\t\t\t\tstruct kthread_delayed_work *dwork,",
            "\t\t\t\tunsigned long delay)",
            "{",
            "\tstruct kthread_work *work = &dwork->work;",
            "\tunsigned long flags;",
            "\tbool ret = false;",
            "",
            "\traw_spin_lock_irqsave(&worker->lock, flags);",
            "",
            "\tif (!queuing_blocked(worker, work)) {",
            "\t\t__kthread_queue_delayed_work(worker, dwork, delay);",
            "\t\tret = true;",
            "\t}",
            "",
            "\traw_spin_unlock_irqrestore(&worker->lock, flags);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "queuing_blocked, kthread_insert_work_sanity_check, kthread_insert_work, kthread_queue_work, kthread_delayed_work_timer_fn, __kthread_queue_delayed_work, kthread_queue_delayed_work",
          "description": "实现kthread_worker与kthread_work的队列管理，包含插入/延迟插入逻辑、锁保护及任务唤醒机制，处理工作项状态校验和延迟定时器回调",
          "similarity": 0.5631287097930908
        }
      ]
    }
  ]
}