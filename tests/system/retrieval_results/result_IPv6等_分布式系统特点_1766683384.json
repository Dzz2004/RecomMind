{
  "query": "IPv6等 分布式系统特点",
  "timestamp": "2025-12-26 01:23:04",
  "retrieved_files": [
    {
      "source_file": "kernel/irq/ipi-mux.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:57:27\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\ipi-mux.c`\n\n---\n\n# `irq/ipi-mux.c` 技术文档\n\n## 1. 文件概述\n\n`ipi-mux.c` 实现了一个虚拟 IPI（Inter-Processor Interrupt，处理器间中断）多路复用机制，允许多个逻辑 IPI 共享一个底层硬件 IPI。该机制通过软件方式在每个 CPU 上维护一个位图，记录哪些虚拟 IPI 处于挂起（pending）或使能（enabled）状态，并在需要时触发底层硬件 IPI。此设计适用于硬件 IPI 资源受限但需要支持多个逻辑 IPI 的系统架构（如某些 RISC-V 或定制 SoC 平台）。\n\n## 2. 核心功能\n\n### 数据结构\n\n- **`struct ipi_mux_cpu`**  \n  每个 CPU 的私有状态结构，包含两个原子变量：\n  - `enable`：表示当前 CPU 上哪些虚拟 IPI 已被使能（unmasked）。\n  - `bits`：表示当前 CPU 上哪些虚拟 IPI 处于挂起状态（pending）。\n\n- **全局变量**\n  - `ipi_mux_pcpu`：指向 per-CPU 的 `ipi_mux_cpu` 实例。\n  - `ipi_mux_domain`：指向虚拟 IPI 的 IRQ domain。\n  - `ipi_mux_send`：回调函数，用于向指定 CPU 发送底层硬件 IPI。\n\n### 主要函数\n\n- **`ipi_mux_mask()` / `ipi_mux_unmask()`**  \n  实现虚拟 IPI 的屏蔽与解除屏蔽逻辑，通过操作 `enable` 字段控制中断使能状态。\n\n- **`ipi_mux_send_mask()`**  \n  实现 `ipi_send_mask` 接口，用于向指定 CPU 集合发送特定虚拟 IPI。通过设置 `bits` 字段标记挂起状态，并在必要时触发底层 IPI。\n\n- **`ipi_mux_process()`**  \n  在底层 IPI 中断处理上下文中调用，读取并清除当前 CPU 的挂起虚拟 IPI 位图，并调用对应的中断处理程序。\n\n- **`ipi_mux_create()`**  \n  初始化整个虚拟 IPI 多路复用系统，包括分配 per-CPU 数据、创建 IRQ domain、分配虚拟 IRQ 号，并注册回调函数。\n\n### IRQ 芯片与 Domain 操作\n\n- **`ipi_mux_chip`**：定义了虚拟 IPI 的 `irq_chip` 操作集。\n- **`ipi_mux_domain_ops`**：定义了 IRQ domain 的分配与释放操作。\n\n## 3. 关键实现\n\n### 虚拟 IPI 状态管理\n\n每个 CPU 维护两个位图：\n- `enable`：记录哪些虚拟 IPI 当前被允许触发（即未被 mask）。\n- `bits`：记录哪些虚拟 IPI 已被请求但尚未处理（pending）。\n\n当调用 `ipi_send_mask()` 时，对应位被置入 `bits`；若该位同时在 `enable` 中置位，则立即触发底层 IPI。\n\n### 内存顺序与同步\n\n- 使用 `atomic_fetch_or_release()` 和 `smp_mb__after_atomic()` 确保：\n  - 对 `bits` 的写入在读取 `enable` 之前完成，避免与 `ipi_mux_unmask()` 竞争。\n  - 虚拟 IPI 标志的设置在触发底层 IPI 前对目标 CPU 可见。\n- 在 `ipi_mux_process()` 中使用 `atomic_fetch_andnot()` 原子地清除已使能且挂起的位，确保中断处理的精确性。\n\n### 中断处理流程\n\n1. 软件调用 `ipi_send_mask()` 发送虚拟 IPI。\n2. 目标 CPU 的 `bits` 对应位置位；若已使能，则调用 `ipi_mux_send()` 触发硬件 IPI。\n3. 硬件 IPI 到达后，调用 `ipi_mux_process()`。\n4. `ipi_mux_process()` 读取 `enable` 与 `bits`，计算需处理的虚拟 IPI 集合，并调用 `generic_handle_domain_irq()` 分发至对应处理函数。\n\n### IRQ Domain 管理\n\n- 使用线性 IRQ domain，虚拟 IPI 的 `hwirq` 编号从 0 开始连续分配。\n- 设置 `IRQ_DOMAIN_FLAG_IPI_SINGLE` 和 `DOMAIN_BUS_IPI` 标志，表明该 domain 专用于 IPI。\n- 每个虚拟 IPI 被配置为 per-CPU 中断（`irq_set_percpu_devid`），使用 `handle_percpu_devid_irq` 处理器。\n\n## 4. 依赖关系\n\n- **`<linux/irq.h>` / `<linux/irqdomain.h>`**：IRQ 子系统核心接口，用于注册 IRQ domain 和管理中断。\n- **`<linux/irqchip/chained_irq.h>`**：提供链式中断处理支持（虽未直接使用，但属于 IPI 架构上下文）。\n- **`<linux/percpu.h>`**：用于分配和访问 per-CPU 数据结构。\n- **`<linux/smp.h>` / `<linux/cpu.h>`**：SMP 相关功能，如 CPU 掩码遍历和处理器 ID 获取。\n- **`<linux/jump_label.h>`**：可能用于优化（当前未显式使用，但包含在头文件中）。\n- **底层平台代码**：必须提供 `mux_send` 回调函数，用于实际触发硬件 IPI。\n\n## 5. 使用场景\n\n- **硬件 IPI 资源受限的 SoC**：当物理 IPI 通道数量少于所需逻辑中断类型时（如仅 1 个硬件 IPI 但需支持 timer、reschedule、call-function 等多种 IPI），使用此机制进行软件复用。\n- **RISC-V 或定制架构平台**：如 Asahi Linux（Apple Silicon）或 Ventana Micro 的 RISC-V 实现，这些平台可能缺乏丰富的硬件 IPI 支持。\n- **内核 SMP 初始化阶段**：在 `ipi_mux_create()` 成功后，其他子系统（如调度器、RCU）可通过分配的虚拟 IPI 实现跨 CPU 通信。\n- **替代传统 IPI 向量机制**：在不支持多向量 IPI 的架构上，提供类似 x86 的多类型 IPI 功能。",
      "similarity": 0.5043299794197083,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/ipi-mux.c",
          "start_line": 29,
          "end_line": 176,
          "content": [
            "static void ipi_mux_mask(struct irq_data *d)",
            "{",
            "\tstruct ipi_mux_cpu *icpu = this_cpu_ptr(ipi_mux_pcpu);",
            "",
            "\tatomic_andnot(BIT(irqd_to_hwirq(d)), &icpu->enable);",
            "}",
            "static void ipi_mux_unmask(struct irq_data *d)",
            "{",
            "\tstruct ipi_mux_cpu *icpu = this_cpu_ptr(ipi_mux_pcpu);",
            "\tu32 ibit = BIT(irqd_to_hwirq(d));",
            "",
            "\tatomic_or(ibit, &icpu->enable);",
            "",
            "\t/*",
            "\t * The atomic_or() above must complete before the atomic_read()",
            "\t * below to avoid racing ipi_mux_send_mask().",
            "\t */",
            "\tsmp_mb__after_atomic();",
            "",
            "\t/* If a pending IPI was unmasked, raise a parent IPI immediately. */",
            "\tif (atomic_read(&icpu->bits) & ibit)",
            "\t\tipi_mux_send(smp_processor_id());",
            "}",
            "static void ipi_mux_send_mask(struct irq_data *d, const struct cpumask *mask)",
            "{",
            "\tstruct ipi_mux_cpu *icpu = this_cpu_ptr(ipi_mux_pcpu);",
            "\tu32 ibit = BIT(irqd_to_hwirq(d));",
            "\tunsigned long pending;",
            "\tint cpu;",
            "",
            "\tfor_each_cpu(cpu, mask) {",
            "\t\ticpu = per_cpu_ptr(ipi_mux_pcpu, cpu);",
            "",
            "\t\t/*",
            "\t\t * This sequence is the mirror of the one in ipi_mux_unmask();",
            "\t\t * see the comment there. Additionally, release semantics",
            "\t\t * ensure that the vIPI flag set is ordered after any shared",
            "\t\t * memory accesses that precede it. This therefore also pairs",
            "\t\t * with the atomic_fetch_andnot in ipi_mux_process().",
            "\t\t */",
            "\t\tpending = atomic_fetch_or_release(ibit, &icpu->bits);",
            "",
            "\t\t/*",
            "\t\t * The atomic_fetch_or_release() above must complete",
            "\t\t * before the atomic_read() below to avoid racing with",
            "\t\t * ipi_mux_unmask().",
            "\t\t */",
            "\t\tsmp_mb__after_atomic();",
            "",
            "\t\t/*",
            "\t\t * The flag writes must complete before the physical IPI is",
            "\t\t * issued to another CPU. This is implied by the control",
            "\t\t * dependency on the result of atomic_read() below, which is",
            "\t\t * itself already ordered after the vIPI flag write.",
            "\t\t */",
            "\t\tif (!(pending & ibit) && (atomic_read(&icpu->enable) & ibit))",
            "\t\t\tipi_mux_send(cpu);",
            "\t}",
            "}",
            "static int ipi_mux_domain_alloc(struct irq_domain *d, unsigned int virq,",
            "\t\t\t\tunsigned int nr_irqs, void *arg)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < nr_irqs; i++) {",
            "\t\tirq_set_percpu_devid(virq + i);",
            "\t\tirq_domain_set_info(d, virq + i, i, &ipi_mux_chip, NULL,",
            "\t\t\t\t    handle_percpu_devid_irq, NULL, NULL);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void ipi_mux_process(void)",
            "{",
            "\tstruct ipi_mux_cpu *icpu = this_cpu_ptr(ipi_mux_pcpu);",
            "\tirq_hw_number_t hwirq;",
            "\tunsigned long ipis;",
            "\tunsigned int en;",
            "",
            "\t/*",
            "\t * Reading enable mask does not need to be ordered as long as",
            "\t * this function is called from interrupt handler because only",
            "\t * the CPU itself can change it's own enable mask.",
            "\t */",
            "\ten = atomic_read(&icpu->enable);",
            "",
            "\t/*",
            "\t * Clear the IPIs we are about to handle. This pairs with the",
            "\t * atomic_fetch_or_release() in ipi_mux_send_mask().",
            "\t */",
            "\tipis = atomic_fetch_andnot(en, &icpu->bits) & en;",
            "",
            "\tfor_each_set_bit(hwirq, &ipis, BITS_PER_TYPE(int))",
            "\t\tgeneric_handle_domain_irq(ipi_mux_domain, hwirq);",
            "}",
            "int ipi_mux_create(unsigned int nr_ipi, void (*mux_send)(unsigned int cpu))",
            "{",
            "\tstruct fwnode_handle *fwnode;",
            "\tstruct irq_domain *domain;",
            "\tint rc;",
            "",
            "\tif (ipi_mux_domain)",
            "\t\treturn -EEXIST;",
            "",
            "\tif (BITS_PER_TYPE(int) < nr_ipi || !mux_send)",
            "\t\treturn -EINVAL;",
            "",
            "\tipi_mux_pcpu = alloc_percpu(typeof(*ipi_mux_pcpu));",
            "\tif (!ipi_mux_pcpu)",
            "\t\treturn -ENOMEM;",
            "",
            "\tfwnode = irq_domain_alloc_named_fwnode(\"IPI-Mux\");",
            "\tif (!fwnode) {",
            "\t\tpr_err(\"unable to create IPI Mux fwnode\\n\");",
            "\t\trc = -ENOMEM;",
            "\t\tgoto fail_free_cpu;",
            "\t}",
            "",
            "\tdomain = irq_domain_create_linear(fwnode, nr_ipi,",
            "\t\t\t\t\t  &ipi_mux_domain_ops, NULL);",
            "\tif (!domain) {",
            "\t\tpr_err(\"unable to add IPI Mux domain\\n\");",
            "\t\trc = -ENOMEM;",
            "\t\tgoto fail_free_fwnode;",
            "\t}",
            "",
            "\tdomain->flags |= IRQ_DOMAIN_FLAG_IPI_SINGLE;",
            "\tirq_domain_update_bus_token(domain, DOMAIN_BUS_IPI);",
            "",
            "\trc = irq_domain_alloc_irqs(domain, nr_ipi, NUMA_NO_NODE, NULL);",
            "\tif (rc <= 0) {",
            "\t\tpr_err(\"unable to alloc IRQs from IPI Mux domain\\n\");",
            "\t\tgoto fail_free_domain;",
            "\t}",
            "",
            "\tipi_mux_domain = domain;",
            "\tipi_mux_send = mux_send;",
            "",
            "\treturn rc;",
            "",
            "fail_free_domain:",
            "\tirq_domain_remove(domain);",
            "fail_free_fwnode:",
            "\tirq_domain_free_fwnode(fwnode);",
            "fail_free_cpu:",
            "\tfree_percpu(ipi_mux_pcpu);",
            "\treturn rc;",
            "}"
          ],
          "function_name": "ipi_mux_mask, ipi_mux_unmask, ipi_mux_send_mask, ipi_mux_domain_alloc, ipi_mux_process, ipi_mux_create",
          "description": "实现了IPI多路复用器的核心逻辑，包括中断屏蔽/解除屏蔽操作、批量发送IPI标记、中断域分配、中断处理流程及初始化创建函数，通过原子操作和内存屏障保证跨CPU状态同步与顺序性。",
          "similarity": 0.510356068611145
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/ipi-mux.c",
          "start_line": 1,
          "end_line": 28,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-or-later",
            "/*",
            " * Multiplex several virtual IPIs over a single HW IPI.",
            " *",
            " * Copyright The Asahi Linux Contributors",
            " * Copyright (c) 2022 Ventana Micro Systems Inc.",
            " */",
            "",
            "#define pr_fmt(fmt) \"ipi-mux: \" fmt",
            "#include <linux/cpu.h>",
            "#include <linux/init.h>",
            "#include <linux/irq.h>",
            "#include <linux/irqchip.h>",
            "#include <linux/irqchip/chained_irq.h>",
            "#include <linux/irqdomain.h>",
            "#include <linux/jump_label.h>",
            "#include <linux/percpu.h>",
            "#include <linux/smp.h>",
            "",
            "struct ipi_mux_cpu {",
            "\tatomic_t\t\t\tenable;",
            "\tatomic_t\t\t\tbits;",
            "};",
            "",
            "static struct ipi_mux_cpu __percpu *ipi_mux_pcpu;",
            "static struct irq_domain *ipi_mux_domain;",
            "static void (*ipi_mux_send)(unsigned int cpu);",
            ""
          ],
          "function_name": null,
          "description": "定义了用于多路复用虚拟IPI的CPU状态结构体ipi_mux_cpu，包含启用位掩码和位计数器。声明了全局的per-CPU指针数组ipi_mux_pcpu，中断域ipi_mux_domain，及发送回调函数指针ipi_mux_send。",
          "similarity": 0.4733685851097107
        }
      ]
    },
    {
      "source_file": "mm/swap_slots.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:27:07\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `swap_slots.c`\n\n---\n\n# swap_slots.c 技术文档\n\n## 1. 文件概述\n\n`swap_slots.c` 实现了 Linux 内核中用于管理交换槽（swap slots）的本地 CPU 缓存机制。该机制通过为每个 CPU 维护一个交换槽缓存，避免在每次分配或释放交换槽时频繁获取全局 `swap_info` 锁，从而提升性能。同时，它支持将回收的交换槽批量归还到全局池中，以减少内存碎片。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct swap_slots_cache`：每个 CPU 的交换槽缓存结构，包含两个数组：\n  - `slots`：用于分配的交换槽缓存\n  - `slots_ret`：用于暂存待回收的交换槽\n- 全局 per-CPU 变量 `swp_slots`：存储各 CPU 的交换槽缓存实例\n\n### 主要函数\n- `alloc_swap_slot_cache()`：为指定 CPU 分配交换槽缓存内存\n- `free_slot_cache()`：释放指定 CPU 的交换槽缓存\n- `refill_swap_slots_cache()`：从全局交换池填充本地缓存\n- `free_swap_slot()`：将交换槽返回到本地缓存或直接释放\n- `__drain_swap_slots_cache()`：将所有在线 CPU 的缓存中的交换槽归还到全局池\n- `drain_slots_cache_cpu()`：清空指定 CPU 的交换槽缓存\n- `enable_swap_slots_cache()`：启用交换槽缓存机制\n- `disable_swap_slots_cache_lock()` / `reenable_swap_slots_cache_unlock()`：禁用/重新启用缓存\n- `check_cache_active()`：根据系统交换页数量动态激活/停用缓存\n\n### 全局变量\n- `swap_slot_cache_active`：指示缓存是否当前处于活跃状态\n- `swap_slot_cache_enabled`：指示缓存功能是否已启用\n- `swap_slot_cache_initialized`：指示缓存子系统是否已完成初始化\n- `swap_slots_cache_mutex`：保护缓存操作的互斥锁\n- `swap_slots_cache_enable_mutex`：序列化缓存启用/禁用操作的互斥锁\n\n## 3. 关键实现\n\n### 本地缓存设计\n- 每个 CPU 拥有两个交换槽数组：\n  - `slots`：用于快速分配交换槽（受 `alloc_lock` 互斥锁保护）\n  - `slots_ret`：用于暂存待释放的交换槽（受 `free_lock` 自旋锁保护）\n- 分配时优先从本地 `slots` 数组获取；若为空，则批量从全局池获取 `SWAP_SLOTS_CACHE_SIZE` 个槽位填充\n- 释放时先放入 `slots_ret`，当其满时才批量归还到全局池，有助于减少锁竞争和内存碎片\n\n### 动态启停机制\n- 通过 `check_cache_active()` 根据可用交换页数量动态控制缓存活跃状态：\n  - 当可用交换页 > `num_online_cpus() * THRESHOLD_ACTIVATE_SWAP_SLOTS_CACHE` 时激活缓存\n  - 当可用交换页 < `num_online_cpus() * THRESHOLD_DEACTIVATE_SWAP_SLOTS_CACHE` 时停用缓存\n- 停用时会立即清空所有 CPU 缓存中的交换槽并归还到全局池\n\n### CPU 热插拔支持\n- 使用 `cpuhp_setup_state()` 注册 CPU 热插拔回调：\n  - CPU 上线时调用 `alloc_swap_slot_cache()` 分配缓存\n  - CPU 下线时调用 `free_slot_cache()` 释放缓存\n- 在清空缓存时使用 `for_each_online_cpu()` 遍历，避免与 CPU 热插拔操作死锁\n\n### 锁设计\n- 使用互斥锁（mutex）而非自旋锁，因为分配交换槽可能触发内存回收而睡眠\n- 分离分配锁（`alloc_lock`）和释放锁（`free_lock`），提高并发性\n- 全局操作使用 `swap_slots_cache_mutex` 保护，启用/禁用操作使用独立的 `swap_slots_cache_enable_mutex`\n\n### 安全标记\n- 从全局池分配的交换槽会被标记 `SWAP_HAS_CACHE`，防止被重复分配\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/swap_slots.h>`：定义交换槽缓存接口和数据结构\n  - `<linux/cpu.h>`、`<linux/cpumask.h>`：CPU 热插拔和掩码操作\n  - `<linux/slab.h>`、`<linux/vmalloc.h>`：内存分配\n  - `<linux/mutex.h>`、`<linux/spinlock.h>`：同步原语\n  - `<linux/mm.h>`：内存管理相关函数\n\n- **外部函数依赖**：\n  - `get_swap_pages()`：从全局交换池批量获取交换槽\n  - `swapcache_free_entries()`：将交换槽归还到全局池\n  - `has_usable_swap()`：检查是否存在可用交换设备\n  - `get_nr_swap_pages()`：获取当前可用交换页数量\n  - `zswap_invalidate()`：通知 zswap 无效化交换条目\n\n- **被调用方**：\n  - `folio_alloc_swap()`：在页面分配交换槽时使用此缓存机制\n  - 交换子系统其他组件通过 `free_swap_slot()` 释放交换槽\n\n## 5. 使用场景\n\n1. **页面交换分配**：当内核需要为匿名页分配交换槽时，优先从本地 CPU 缓存获取，避免全局锁竞争\n2. **页面交换释放**：当交换页被换入内存后，其交换槽通过 `free_swap_slot()` 返回到本地缓存\n3. **内存压力场景**：在低内存情况下，系统可能停用交换槽缓存以释放更多交换空间\n4. **交换设备管理**：\n   - `swapon` 时通过 `enable_swap_slots_cache()` 启用缓存\n   - `swapoff` 时通过 `__drain_swap_slots_cache()` 确保所有缓存槽位归还\n5. **CPU 热插拔**：动态为新上线 CPU 分配缓存，为下线 CPU 释放缓存资源\n6. **系统休眠/恢复**：在休眠前确保交换槽缓存被正确清空，避免状态不一致",
      "similarity": 0.4943968653678894,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "mm/swap_slots.c",
          "start_line": 305,
          "end_line": 353,
          "content": [
            "swp_entry_t folio_alloc_swap(struct folio *folio)",
            "{",
            "\tswp_entry_t entry;",
            "\tstruct swap_slots_cache *cache;",
            "",
            "\tentry.val = 0;",
            "",
            "\tif (folio_test_large(folio)) {",
            "\t\tif (IS_ENABLED(CONFIG_THP_SWAP))",
            "\t\t\tget_swap_pages(1, &entry, folio_order(folio));",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/*",
            "\t * Preemption is allowed here, because we may sleep",
            "\t * in refill_swap_slots_cache().  But it is safe, because",
            "\t * accesses to the per-CPU data structure are protected by the",
            "\t * mutex cache->alloc_lock.",
            "\t *",
            "\t * The alloc path here does not touch cache->slots_ret",
            "\t * so cache->free_lock is not taken.",
            "\t */",
            "\tcache = raw_cpu_ptr(&swp_slots);",
            "",
            "\tif (likely(check_cache_active() && cache->slots)) {",
            "\t\tmutex_lock(&cache->alloc_lock);",
            "\t\tif (cache->slots) {",
            "repeat:",
            "\t\t\tif (cache->nr) {",
            "\t\t\t\tentry = cache->slots[cache->cur];",
            "\t\t\t\tcache->slots[cache->cur++].val = 0;",
            "\t\t\t\tcache->nr--;",
            "\t\t\t} else if (refill_swap_slots_cache(cache)) {",
            "\t\t\t\tgoto repeat;",
            "\t\t\t}",
            "\t\t}",
            "\t\tmutex_unlock(&cache->alloc_lock);",
            "\t\tif (entry.val)",
            "\t\t\tgoto out;",
            "\t}",
            "",
            "\tget_swap_pages(1, &entry, 0);",
            "out:",
            "\tif (mem_cgroup_try_charge_swap(folio, entry)) {",
            "\t\tput_swap_folio(folio, entry);",
            "\t\tentry.val = 0;",
            "\t}",
            "\treturn entry;",
            "}"
          ],
          "function_name": "folio_alloc_swap",
          "description": "从swap slots缓存或直接全局池分配交换槽，支持并发场景下的缓存预取与资源回收协作",
          "similarity": 0.4584645926952362
        },
        {
          "chunk_id": 0,
          "file_path": "mm/swap_slots.c",
          "start_line": 1,
          "end_line": 51,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Manage cache of swap slots to be used for and returned from",
            " * swap.",
            " *",
            " * Copyright(c) 2016 Intel Corporation.",
            " *",
            " * Author: Tim Chen <tim.c.chen@linux.intel.com>",
            " *",
            " * We allocate the swap slots from the global pool and put",
            " * it into local per cpu caches.  This has the advantage",
            " * of no needing to acquire the swap_info lock every time",
            " * we need a new slot.",
            " *",
            " * There is also opportunity to simply return the slot",
            " * to local caches without needing to acquire swap_info",
            " * lock.  We do not reuse the returned slots directly but",
            " * move them back to the global pool in a batch.  This",
            " * allows the slots to coalesce and reduce fragmentation.",
            " *",
            " * The swap entry allocated is marked with SWAP_HAS_CACHE",
            " * flag in map_count that prevents it from being allocated",
            " * again from the global pool.",
            " *",
            " * The swap slots cache is protected by a mutex instead of",
            " * a spin lock as when we search for slots with scan_swap_map,",
            " * we can possibly sleep.",
            " */",
            "",
            "#include <linux/swap_slots.h>",
            "#include <linux/cpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/slab.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/mutex.h>",
            "#include <linux/mm.h>",
            "",
            "static DEFINE_PER_CPU(struct swap_slots_cache, swp_slots);",
            "static bool\tswap_slot_cache_active;",
            "bool\tswap_slot_cache_enabled;",
            "static bool\tswap_slot_cache_initialized;",
            "static DEFINE_MUTEX(swap_slots_cache_mutex);",
            "/* Serialize swap slots cache enable/disable operations */",
            "static DEFINE_MUTEX(swap_slots_cache_enable_mutex);",
            "",
            "static void __drain_swap_slots_cache(unsigned int type);",
            "",
            "#define use_swap_slot_cache (swap_slot_cache_active && swap_slot_cache_enabled)",
            "#define SLOTS_CACHE 0x1",
            "#define SLOTS_CACHE_RET 0x2",
            ""
          ],
          "function_name": null,
          "description": "声明swap slots缓存相关的全局变量和宏，用于管理交换槽的本地CPU缓存与全局池切换逻辑",
          "similarity": 0.4463316798210144
        },
        {
          "chunk_id": 1,
          "file_path": "mm/swap_slots.c",
          "start_line": 52,
          "end_line": 159,
          "content": [
            "static void deactivate_swap_slots_cache(void)",
            "{",
            "\tmutex_lock(&swap_slots_cache_mutex);",
            "\tswap_slot_cache_active = false;",
            "\t__drain_swap_slots_cache(SLOTS_CACHE|SLOTS_CACHE_RET);",
            "\tmutex_unlock(&swap_slots_cache_mutex);",
            "}",
            "static void reactivate_swap_slots_cache(void)",
            "{",
            "\tmutex_lock(&swap_slots_cache_mutex);",
            "\tswap_slot_cache_active = true;",
            "\tmutex_unlock(&swap_slots_cache_mutex);",
            "}",
            "void disable_swap_slots_cache_lock(void)",
            "{",
            "\tmutex_lock(&swap_slots_cache_enable_mutex);",
            "\tswap_slot_cache_enabled = false;",
            "\tif (swap_slot_cache_initialized) {",
            "\t\t/* serialize with cpu hotplug operations */",
            "\t\tcpus_read_lock();",
            "\t\t__drain_swap_slots_cache(SLOTS_CACHE|SLOTS_CACHE_RET);",
            "\t\tcpus_read_unlock();",
            "\t}",
            "}",
            "static void __reenable_swap_slots_cache(void)",
            "{",
            "\tswap_slot_cache_enabled = has_usable_swap();",
            "}",
            "void reenable_swap_slots_cache_unlock(void)",
            "{",
            "\t__reenable_swap_slots_cache();",
            "\tmutex_unlock(&swap_slots_cache_enable_mutex);",
            "}",
            "static bool check_cache_active(void)",
            "{",
            "\tlong pages;",
            "",
            "\tif (!swap_slot_cache_enabled)",
            "\t\treturn false;",
            "",
            "\tpages = get_nr_swap_pages();",
            "\tif (!swap_slot_cache_active) {",
            "\t\tif (pages > num_online_cpus() *",
            "\t\t    THRESHOLD_ACTIVATE_SWAP_SLOTS_CACHE)",
            "\t\t\treactivate_swap_slots_cache();",
            "\t\tgoto out;",
            "\t}",
            "",
            "\t/* if global pool of slot caches too low, deactivate cache */",
            "\tif (pages < num_online_cpus() * THRESHOLD_DEACTIVATE_SWAP_SLOTS_CACHE)",
            "\t\tdeactivate_swap_slots_cache();",
            "out:",
            "\treturn swap_slot_cache_active;",
            "}",
            "static int alloc_swap_slot_cache(unsigned int cpu)",
            "{",
            "\tstruct swap_slots_cache *cache;",
            "\tswp_entry_t *slots, *slots_ret;",
            "",
            "\t/*",
            "\t * Do allocation outside swap_slots_cache_mutex",
            "\t * as kvzalloc could trigger reclaim and folio_alloc_swap,",
            "\t * which can lock swap_slots_cache_mutex.",
            "\t */",
            "\tslots = kvcalloc(SWAP_SLOTS_CACHE_SIZE, sizeof(swp_entry_t),",
            "\t\t\t GFP_KERNEL);",
            "\tif (!slots)",
            "\t\treturn -ENOMEM;",
            "",
            "\tslots_ret = kvcalloc(SWAP_SLOTS_CACHE_SIZE, sizeof(swp_entry_t),",
            "\t\t\t     GFP_KERNEL);",
            "\tif (!slots_ret) {",
            "\t\tkvfree(slots);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\tmutex_lock(&swap_slots_cache_mutex);",
            "\tcache = &per_cpu(swp_slots, cpu);",
            "\tif (cache->slots || cache->slots_ret) {",
            "\t\t/* cache already allocated */",
            "\t\tmutex_unlock(&swap_slots_cache_mutex);",
            "",
            "\t\tkvfree(slots);",
            "\t\tkvfree(slots_ret);",
            "",
            "\t\treturn 0;",
            "\t}",
            "",
            "\tif (!cache->lock_initialized) {",
            "\t\tmutex_init(&cache->alloc_lock);",
            "\t\tspin_lock_init(&cache->free_lock);",
            "\t\tcache->lock_initialized = true;",
            "\t}",
            "\tcache->nr = 0;",
            "\tcache->cur = 0;",
            "\tcache->n_ret = 0;",
            "\t/*",
            "\t * We initialized alloc_lock and free_lock earlier.  We use",
            "\t * !cache->slots or !cache->slots_ret to know if it is safe to acquire",
            "\t * the corresponding lock and use the cache.  Memory barrier below",
            "\t * ensures the assumption.",
            "\t */",
            "\tmb();",
            "\tcache->slots = slots;",
            "\tcache->slots_ret = slots_ret;",
            "\tmutex_unlock(&swap_slots_cache_mutex);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "deactivate_swap_slots_cache, reactivate_swap_slots_cache, disable_swap_slots_cache_lock, __reenable_swap_slots_cache, reenable_swap_slots_cache_unlock, check_cache_active, alloc_swap_slot_cache",
          "description": "提供swap slots缓存的激活/停用控制接口，通过互斥锁同步状态变更并协调内存分配与回收流程",
          "similarity": 0.44168561697006226
        },
        {
          "chunk_id": 2,
          "file_path": "mm/swap_slots.c",
          "start_line": 168,
          "end_line": 297,
          "content": [
            "static void drain_slots_cache_cpu(unsigned int cpu, unsigned int type,",
            "\t\t\t\t  bool free_slots)",
            "{",
            "\tstruct swap_slots_cache *cache;",
            "\tswp_entry_t *slots = NULL;",
            "",
            "\tcache = &per_cpu(swp_slots, cpu);",
            "\tif ((type & SLOTS_CACHE) && cache->slots) {",
            "\t\tmutex_lock(&cache->alloc_lock);",
            "\t\tswapcache_free_entries(cache->slots + cache->cur, cache->nr);",
            "\t\tcache->cur = 0;",
            "\t\tcache->nr = 0;",
            "\t\tif (free_slots && cache->slots) {",
            "\t\t\tkvfree(cache->slots);",
            "\t\t\tcache->slots = NULL;",
            "\t\t}",
            "\t\tmutex_unlock(&cache->alloc_lock);",
            "\t}",
            "\tif ((type & SLOTS_CACHE_RET) && cache->slots_ret) {",
            "\t\tspin_lock_irq(&cache->free_lock);",
            "\t\tswapcache_free_entries(cache->slots_ret, cache->n_ret);",
            "\t\tcache->n_ret = 0;",
            "\t\tif (free_slots && cache->slots_ret) {",
            "\t\t\tslots = cache->slots_ret;",
            "\t\t\tcache->slots_ret = NULL;",
            "\t\t}",
            "\t\tspin_unlock_irq(&cache->free_lock);",
            "\t\tkvfree(slots);",
            "\t}",
            "}",
            "static void __drain_swap_slots_cache(unsigned int type)",
            "{",
            "\tunsigned int cpu;",
            "",
            "\t/*",
            "\t * This function is called during",
            "\t *\t1) swapoff, when we have to make sure no",
            "\t *\t   left over slots are in cache when we remove",
            "\t *\t   a swap device;",
            "\t *      2) disabling of swap slot cache, when we run low",
            "\t *\t   on swap slots when allocating memory and need",
            "\t *\t   to return swap slots to global pool.",
            "\t *",
            "\t * We cannot acquire cpu hot plug lock here as",
            "\t * this function can be invoked in the cpu",
            "\t * hot plug path:",
            "\t * cpu_up -> lock cpu_hotplug -> cpu hotplug state callback",
            "\t *   -> memory allocation -> direct reclaim -> folio_alloc_swap",
            "\t *   -> drain_swap_slots_cache",
            "\t *",
            "\t * Hence the loop over current online cpu below could miss cpu that",
            "\t * is being brought online but not yet marked as online.",
            "\t * That is okay as we do not schedule and run anything on a",
            "\t * cpu before it has been marked online. Hence, we will not",
            "\t * fill any swap slots in slots cache of such cpu.",
            "\t * There are no slots on such cpu that need to be drained.",
            "\t */",
            "\tfor_each_online_cpu(cpu)",
            "\t\tdrain_slots_cache_cpu(cpu, type, false);",
            "}",
            "static int free_slot_cache(unsigned int cpu)",
            "{",
            "\tmutex_lock(&swap_slots_cache_mutex);",
            "\tdrain_slots_cache_cpu(cpu, SLOTS_CACHE | SLOTS_CACHE_RET, true);",
            "\tmutex_unlock(&swap_slots_cache_mutex);",
            "\treturn 0;",
            "}",
            "void enable_swap_slots_cache(void)",
            "{",
            "\tmutex_lock(&swap_slots_cache_enable_mutex);",
            "\tif (!swap_slot_cache_initialized) {",
            "\t\tint ret;",
            "",
            "\t\tret = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN, \"swap_slots_cache\",",
            "\t\t\t\t\talloc_swap_slot_cache, free_slot_cache);",
            "\t\tif (WARN_ONCE(ret < 0, \"Cache allocation failed (%s), operating \"",
            "\t\t\t\t       \"without swap slots cache.\\n\", __func__))",
            "\t\t\tgoto out_unlock;",
            "",
            "\t\tswap_slot_cache_initialized = true;",
            "\t}",
            "",
            "\t__reenable_swap_slots_cache();",
            "out_unlock:",
            "\tmutex_unlock(&swap_slots_cache_enable_mutex);",
            "}",
            "static int refill_swap_slots_cache(struct swap_slots_cache *cache)",
            "{",
            "\tif (!use_swap_slot_cache)",
            "\t\treturn 0;",
            "",
            "\tcache->cur = 0;",
            "\tif (swap_slot_cache_active)",
            "\t\tcache->nr = get_swap_pages(SWAP_SLOTS_CACHE_SIZE,",
            "\t\t\t\t\t   cache->slots, 0);",
            "",
            "\treturn cache->nr;",
            "}",
            "void free_swap_slot(swp_entry_t entry)",
            "{",
            "\tstruct swap_slots_cache *cache;",
            "",
            "\t/* Large folio swap slot is not covered. */",
            "\tzswap_invalidate(entry);",
            "",
            "\tcache = raw_cpu_ptr(&swp_slots);",
            "\tif (likely(use_swap_slot_cache && cache->slots_ret)) {",
            "\t\tspin_lock_irq(&cache->free_lock);",
            "\t\t/* Swap slots cache may be deactivated before acquiring lock */",
            "\t\tif (!use_swap_slot_cache || !cache->slots_ret) {",
            "\t\t\tspin_unlock_irq(&cache->free_lock);",
            "\t\t\tgoto direct_free;",
            "\t\t}",
            "\t\tif (cache->n_ret >= SWAP_SLOTS_CACHE_SIZE) {",
            "\t\t\t/*",
            "\t\t\t * Return slots to global pool.",
            "\t\t\t * The current swap_map value is SWAP_HAS_CACHE.",
            "\t\t\t * Set it to 0 to indicate it is available for",
            "\t\t\t * allocation in global pool",
            "\t\t\t */",
            "\t\t\tswapcache_free_entries(cache->slots_ret, cache->n_ret);",
            "\t\t\tcache->n_ret = 0;",
            "\t\t}",
            "\t\tcache->slots_ret[cache->n_ret++] = entry;",
            "\t\tspin_unlock_irq(&cache->free_lock);",
            "\t} else {",
            "direct_free:",
            "\t\tswapcache_free_entries(&entry, 1);",
            "\t}",
            "}"
          ],
          "function_name": "drain_slots_cache_cpu, __drain_swap_slots_cache, free_slot_cache, enable_swap_slots_cache, refill_swap_slots_cache, free_swap_slot",
          "description": "实现swap slots缓存的清理机制，包括CPU本地缓存数据迁移、内存释放及全局池归还操作",
          "similarity": 0.42648884654045105
        }
      ]
    },
    {
      "source_file": "kernel/irq/matrix.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:03:08\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\matrix.c`\n\n---\n\n# `irq/matrix.c` 技术文档\n\n## 1. 文件概述\n\n`irq/matrix.c` 实现了一个通用的中断位图（IRQ matrix）管理机制，用于在多 CPU 系统中高效地分配和管理中断向量（或中断位）。该机制支持两类中断分配：\n\n- **普通分配（allocated）**：由设备驱动等动态申请的中断。\n- **托管分配（managed）**：由内核子系统（如 MSI/MSI-X）预先保留、按需激活的中断。\n\n该文件通过 per-CPU 的位图结构，结合全局状态跟踪，实现了跨 CPU 的中断资源分配、预留、释放和在线/离线管理，特别适用于中断向量数量有限（如 x86 的 256 个向量）的架构。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct cpumap`**：每个 CPU 的本地中断位图状态\n  - `available`：当前 CPU 可用的中断数量\n  - `allocated`：已分配的普通中断数量\n  - `managed` / `managed_allocated`：预留和已激活的托管中断数量\n  - `alloc_map[]`：记录已分配的普通中断位\n  - `managed_map[]`：记录预留的托管中断位\n  - `initialized` / `online`：CPU 初始化和在线状态\n\n- **`struct irq_matrix`**：全局中断矩阵控制结构\n  - `matrix_bits`：总位图大小（≤ `IRQ_MATRIX_BITS`）\n  - `alloc_start` / `alloc_end`：可分配范围\n  - `global_available`：全局可用中断总数\n  - `system_map[]`：系统保留位（如 APIC 自身使用的向量）\n  - `maps`：指向 per-CPU `cpumap` 的指针\n  - `scratch_map[]`：临时位图，用于分配时的合并计算\n\n### 主要函数\n\n| 函数 | 功能 |\n|------|------|\n| `irq_alloc_matrix()` | 分配并初始化一个 `irq_matrix` 结构 |\n| `irq_matrix_online()` / `irq_matrix_offline()` | 将本地 CPU 的中断矩阵置为在线/离线状态 |\n| `irq_matrix_assign_system()` | 在矩阵中保留系统级中断位（如 APIC 向量） |\n| `irq_matrix_reserve_managed()` | 在指定 CPU 掩码上为托管中断预留位 |\n| `irq_matrix_remove_managed()` | 移除托管中断的预留位 |\n| `irq_matrix_alloc_managed()` | 从预留的托管中断中分配一个实际使用的中断 |\n| `matrix_alloc_area()` | 内部辅助函数：在合并位图中查找连续空闲区域 |\n| `matrix_find_best_cpu()` / `matrix_find_best_cpu_managed()` | 选择最优 CPU（基于可用数或托管分配数最少） |\n\n## 3. 关键实现\n\n### 位图合并分配策略\n- 在分配中断时，`matrix_alloc_area()` 会临时合并三个位图：\n  1. 当前 CPU 的 `managed_map`（托管预留）\n  2. 全局 `system_map`（系统保留）\n  3. 当前 CPU 的 `alloc_map`（已分配）\n- 使用 `bitmap_find_next_zero_area()` 在合并后的位图中查找连续空闲区域，确保不会重复分配。\n\n### 托管中断（Managed IRQ）机制\n- **两阶段分配**：\n  1. **预留（reserve）**：调用 `irq_matrix_reserve_managed()` 在多个 CPU 上各预留一个位（不一定对齐）。\n  2. **激活（alloc）**：调用 `irq_matrix_alloc_managed()` 从预留位中选择一个未使用的位进行实际分配。\n- **动态 CPU 选择**：`matrix_find_best_cpu_managed()` 优先选择 `managed_allocated` 最少的 CPU，实现负载均衡。\n\n### 系统中断保留\n- `irq_matrix_assign_system()` 用于保留如 x86 的 `IRQ0_VECTOR`（时钟中断）等关键系统向量。\n- 通过 `BUG_ON()` 强制保证：系统中断只能在单 CPU 初始化阶段分配，防止运行时冲突。\n\n### 在线/离线管理\n- CPU 上线时，将其 `available` 计数加入 `global_available`。\n- CPU 离线时，从全局计数中减去，但保留其位图数据（支持重新上线）。\n\n### 跟踪与调试\n- 集成 `trace/events/irq_matrix.h`，提供分配、预留、系统保留等关键操作的 tracepoint，便于调试中断分配问题。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/bitmap.h>`：位图操作（`bitmap_set`, `bitmap_find_next_zero_area` 等）\n  - `<linux/percpu.h>`：Per-CPU 变量支持\n  - `<linux/cpu.h>`：CPU 在线/离线状态\n  - `<linux/irq.h>`：中断子系统基础定义\n  - `<trace/events/irq_matrix.h>`：自定义 tracepoint\n\n- **内核子系统**：\n  - **中断子系统**：作为底层分配器，被 `irqdomain`、MSI/MSI-X 驱动等使用。\n  - **x86 APIC 驱动**：典型使用者，用于管理 256 个中断向量的分配（如 `kernel/irq/vector.c`）。\n\n## 5. 使用场景\n\n- **x86 中断向量管理**：在 `CONFIG_X86_IO_APIC` 或 `CONFIG_X86_LOCAL_APIC` 下，用于分配 IRQ 向量（0-255），区分系统向量、普通设备中断和 MSI 中断。\n- **MSI/MSI-X 中断分配**：PCIe 设备的 MSI 中断通过托管机制预留和分配，确保每个设备在多个 CPU 上有可用向量。\n- **CPU 热插拔**：支持 CPU 动态上线/下线时的中断资源重新平衡。\n- **中断负载均衡**：通过 `matrix_find_best_cpu*` 函数，在多 CPU 间均匀分配中断，避免单 CPU 向量耗尽。",
      "similarity": 0.4921044111251831,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 78,
          "end_line": 205,
          "content": [
            "void irq_matrix_online(struct irq_matrix *m)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tBUG_ON(cm->online);",
            "",
            "\tif (!cm->initialized) {",
            "\t\tcm->available = m->alloc_size;",
            "\t\tcm->available -= cm->managed + m->systembits_inalloc;",
            "\t\tcm->initialized = true;",
            "\t}",
            "\tm->global_available += cm->available;",
            "\tcm->online = true;",
            "\tm->online_maps++;",
            "\ttrace_irq_matrix_online(m);",
            "}",
            "void irq_matrix_offline(struct irq_matrix *m)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\t/* Update the global available size */",
            "\tm->global_available -= cm->available;",
            "\tcm->online = false;",
            "\tm->online_maps--;",
            "\ttrace_irq_matrix_offline(m);",
            "}",
            "static unsigned int matrix_alloc_area(struct irq_matrix *m, struct cpumap *cm,",
            "\t\t\t\t      unsigned int num, bool managed)",
            "{",
            "\tunsigned int area, start = m->alloc_start;",
            "\tunsigned int end = m->alloc_end;",
            "",
            "\tbitmap_or(m->scratch_map, cm->managed_map, m->system_map, end);",
            "\tbitmap_or(m->scratch_map, m->scratch_map, cm->alloc_map, end);",
            "\tarea = bitmap_find_next_zero_area(m->scratch_map, end, start, num, 0);",
            "\tif (area >= end)",
            "\t\treturn area;",
            "\tif (managed)",
            "\t\tbitmap_set(cm->managed_map, area, num);",
            "\telse",
            "\t\tbitmap_set(cm->alloc_map, area, num);",
            "\treturn area;",
            "}",
            "static unsigned int matrix_find_best_cpu(struct irq_matrix *m,",
            "\t\t\t\t\tconst struct cpumask *msk)",
            "{",
            "\tunsigned int cpu, best_cpu, maxavl = 0;",
            "\tstruct cpumap *cm;",
            "",
            "\tbest_cpu = UINT_MAX;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tcm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\t\tif (!cm->online || cm->available <= maxavl)",
            "\t\t\tcontinue;",
            "",
            "\t\tbest_cpu = cpu;",
            "\t\tmaxavl = cm->available;",
            "\t}",
            "\treturn best_cpu;",
            "}",
            "static unsigned int matrix_find_best_cpu_managed(struct irq_matrix *m,",
            "\t\t\t\t\t\tconst struct cpumask *msk)",
            "{",
            "\tunsigned int cpu, best_cpu, allocated = UINT_MAX;",
            "\tstruct cpumap *cm;",
            "",
            "\tbest_cpu = UINT_MAX;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tcm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\t\tif (!cm->online || cm->managed_allocated > allocated)",
            "\t\t\tcontinue;",
            "",
            "\t\tbest_cpu = cpu;",
            "\t\tallocated = cm->managed_allocated;",
            "\t}",
            "\treturn best_cpu;",
            "}",
            "void irq_matrix_assign_system(struct irq_matrix *m, unsigned int bit,",
            "\t\t\t      bool replace)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tBUG_ON(bit > m->matrix_bits);",
            "\tBUG_ON(m->online_maps > 1 || (m->online_maps && !replace));",
            "",
            "\tset_bit(bit, m->system_map);",
            "\tif (replace) {",
            "\t\tBUG_ON(!test_and_clear_bit(bit, cm->alloc_map));",
            "\t\tcm->allocated--;",
            "\t\tm->total_allocated--;",
            "\t}",
            "\tif (bit >= m->alloc_start && bit < m->alloc_end)",
            "\t\tm->systembits_inalloc++;",
            "",
            "\ttrace_irq_matrix_assign_system(bit, m);",
            "}",
            "int irq_matrix_reserve_managed(struct irq_matrix *m, const struct cpumask *msk)",
            "{",
            "\tunsigned int cpu, failed_cpu;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "\t\tunsigned int bit;",
            "",
            "\t\tbit = matrix_alloc_area(m, cm, 1, true);",
            "\t\tif (bit >= m->alloc_end)",
            "\t\t\tgoto cleanup;",
            "\t\tcm->managed++;",
            "\t\tif (cm->online) {",
            "\t\t\tcm->available--;",
            "\t\t\tm->global_available--;",
            "\t\t}",
            "\t\ttrace_irq_matrix_reserve_managed(bit, cpu, m, cm);",
            "\t}",
            "\treturn 0;",
            "cleanup:",
            "\tfailed_cpu = cpu;",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tif (cpu == failed_cpu)",
            "\t\t\tbreak;",
            "\t\tirq_matrix_remove_managed(m, cpumask_of(cpu));",
            "\t}",
            "\treturn -ENOSPC;",
            "}"
          ],
          "function_name": "irq_matrix_online, irq_matrix_offline, matrix_alloc_area, matrix_find_best_cpu, matrix_find_best_cpu_managed, irq_matrix_assign_system, irq_matrix_reserve_managed",
          "description": "实现CPU矩阵的上线/下线操作，通过bitmap操作实现中断位的分配策略，包含寻找最佳CPU的逻辑，支持系统位管理和保留区域的分配与追踪",
          "similarity": 0.4752890467643738
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 251,
          "end_line": 365,
          "content": [
            "void irq_matrix_remove_managed(struct irq_matrix *m, const struct cpumask *msk)",
            "{",
            "\tunsigned int cpu;",
            "",
            "\tfor_each_cpu(cpu, msk) {",
            "\t\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "\t\tunsigned int bit, end = m->alloc_end;",
            "",
            "\t\tif (WARN_ON_ONCE(!cm->managed))",
            "\t\t\tcontinue;",
            "",
            "\t\t/* Get managed bit which are not allocated */",
            "\t\tbitmap_andnot(m->scratch_map, cm->managed_map, cm->alloc_map, end);",
            "",
            "\t\tbit = find_first_bit(m->scratch_map, end);",
            "\t\tif (WARN_ON_ONCE(bit >= end))",
            "\t\t\tcontinue;",
            "",
            "\t\tclear_bit(bit, cm->managed_map);",
            "",
            "\t\tcm->managed--;",
            "\t\tif (cm->online) {",
            "\t\t\tcm->available++;",
            "\t\t\tm->global_available++;",
            "\t\t}",
            "\t\ttrace_irq_matrix_remove_managed(bit, cpu, m, cm);",
            "\t}",
            "}",
            "int irq_matrix_alloc_managed(struct irq_matrix *m, const struct cpumask *msk,",
            "\t\t\t     unsigned int *mapped_cpu)",
            "{",
            "\tunsigned int bit, cpu, end;",
            "\tstruct cpumap *cm;",
            "",
            "\tif (cpumask_empty(msk))",
            "\t\treturn -EINVAL;",
            "",
            "\tcpu = matrix_find_best_cpu_managed(m, msk);",
            "\tif (cpu == UINT_MAX)",
            "\t\treturn -ENOSPC;",
            "",
            "\tcm = per_cpu_ptr(m->maps, cpu);",
            "\tend = m->alloc_end;",
            "\t/* Get managed bit which are not allocated */",
            "\tbitmap_andnot(m->scratch_map, cm->managed_map, cm->alloc_map, end);",
            "\tbit = find_first_bit(m->scratch_map, end);",
            "\tif (bit >= end)",
            "\t\treturn -ENOSPC;",
            "\tset_bit(bit, cm->alloc_map);",
            "\tcm->allocated++;",
            "\tcm->managed_allocated++;",
            "\tm->total_allocated++;",
            "\t*mapped_cpu = cpu;",
            "\ttrace_irq_matrix_alloc_managed(bit, cpu, m, cm);",
            "\treturn bit;",
            "}",
            "void irq_matrix_assign(struct irq_matrix *m, unsigned int bit)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tif (WARN_ON_ONCE(bit < m->alloc_start || bit >= m->alloc_end))",
            "\t\treturn;",
            "\tif (WARN_ON_ONCE(test_and_set_bit(bit, cm->alloc_map)))",
            "\t\treturn;",
            "\tcm->allocated++;",
            "\tm->total_allocated++;",
            "\tcm->available--;",
            "\tm->global_available--;",
            "\ttrace_irq_matrix_assign(bit, smp_processor_id(), m, cm);",
            "}",
            "void irq_matrix_reserve(struct irq_matrix *m)",
            "{",
            "\tif (m->global_reserved == m->global_available)",
            "\t\tpr_warn(\"Interrupt reservation exceeds available resources\\n\");",
            "",
            "\tm->global_reserved++;",
            "\ttrace_irq_matrix_reserve(m);",
            "}",
            "void irq_matrix_remove_reserved(struct irq_matrix *m)",
            "{",
            "\tm->global_reserved--;",
            "\ttrace_irq_matrix_remove_reserved(m);",
            "}",
            "int irq_matrix_alloc(struct irq_matrix *m, const struct cpumask *msk,",
            "\t\t     bool reserved, unsigned int *mapped_cpu)",
            "{",
            "\tunsigned int cpu, bit;",
            "\tstruct cpumap *cm;",
            "",
            "\t/*",
            "\t * Not required in theory, but matrix_find_best_cpu() uses",
            "\t * for_each_cpu() which ignores the cpumask on UP .",
            "\t */",
            "\tif (cpumask_empty(msk))",
            "\t\treturn -EINVAL;",
            "",
            "\tcpu = matrix_find_best_cpu(m, msk);",
            "\tif (cpu == UINT_MAX)",
            "\t\treturn -ENOSPC;",
            "",
            "\tcm = per_cpu_ptr(m->maps, cpu);",
            "\tbit = matrix_alloc_area(m, cm, 1, false);",
            "\tif (bit >= m->alloc_end)",
            "\t\treturn -ENOSPC;",
            "\tcm->allocated++;",
            "\tcm->available--;",
            "\tm->total_allocated++;",
            "\tm->global_available--;",
            "\tif (reserved)",
            "\t\tm->global_reserved--;",
            "\t*mapped_cpu = cpu;",
            "\ttrace_irq_matrix_alloc(bit, cpu, m, cm);",
            "\treturn bit;",
            "",
            "}"
          ],
          "function_name": "irq_matrix_remove_managed, irq_matrix_alloc_managed, irq_matrix_assign, irq_matrix_reserve, irq_matrix_remove_reserved, irq_matrix_alloc",
          "description": "实现中断位的分配/回收机制，包含保留中断位的管理、跨CPU的中断分配逻辑，以及根据预留状态进行资源分配的控制流程",
          "similarity": 0.471613347530365
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 418,
          "end_line": 483,
          "content": [
            "void irq_matrix_free(struct irq_matrix *m, unsigned int cpu,",
            "\t\t     unsigned int bit, bool managed)",
            "{",
            "\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\tif (WARN_ON_ONCE(bit < m->alloc_start || bit >= m->alloc_end))",
            "\t\treturn;",
            "",
            "\tif (WARN_ON_ONCE(!test_and_clear_bit(bit, cm->alloc_map)))",
            "\t\treturn;",
            "",
            "\tcm->allocated--;",
            "\tif(managed)",
            "\t\tcm->managed_allocated--;",
            "",
            "\tif (cm->online)",
            "\t\tm->total_allocated--;",
            "",
            "\tif (!managed) {",
            "\t\tcm->available++;",
            "\t\tif (cm->online)",
            "\t\t\tm->global_available++;",
            "\t}",
            "\ttrace_irq_matrix_free(bit, cpu, m, cm);",
            "}",
            "unsigned int irq_matrix_available(struct irq_matrix *m, bool cpudown)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\tif (!cpudown)",
            "\t\treturn m->global_available;",
            "\treturn m->global_available - cm->available;",
            "}",
            "unsigned int irq_matrix_reserved(struct irq_matrix *m)",
            "{",
            "\treturn m->global_reserved;",
            "}",
            "unsigned int irq_matrix_allocated(struct irq_matrix *m)",
            "{",
            "\tstruct cpumap *cm = this_cpu_ptr(m->maps);",
            "",
            "\treturn cm->allocated - cm->managed_allocated;",
            "}",
            "void irq_matrix_debug_show(struct seq_file *sf, struct irq_matrix *m, int ind)",
            "{",
            "\tunsigned int nsys = bitmap_weight(m->system_map, m->matrix_bits);",
            "\tint cpu;",
            "",
            "\tseq_printf(sf, \"Online bitmaps:   %6u\\n\", m->online_maps);",
            "\tseq_printf(sf, \"Global available: %6u\\n\", m->global_available);",
            "\tseq_printf(sf, \"Global reserved:  %6u\\n\", m->global_reserved);",
            "\tseq_printf(sf, \"Total allocated:  %6u\\n\", m->total_allocated);",
            "\tseq_printf(sf, \"System: %u: %*pbl\\n\", nsys, m->matrix_bits,",
            "\t\t   m->system_map);",
            "\tseq_printf(sf, \"%*s| CPU | avl | man | mac | act | vectors\\n\", ind, \" \");",
            "\tcpus_read_lock();",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct cpumap *cm = per_cpu_ptr(m->maps, cpu);",
            "",
            "\t\tseq_printf(sf, \"%*s %4d  %4u  %4u  %4u %4u  %*pbl\\n\", ind, \" \",",
            "\t\t\t   cpu, cm->available, cm->managed,",
            "\t\t\t   cm->managed_allocated, cm->allocated,",
            "\t\t\t   m->matrix_bits, cm->alloc_map);",
            "\t}",
            "\tcpus_read_unlock();",
            "}"
          ],
          "function_name": "irq_matrix_free, irq_matrix_available, irq_matrix_reserved, irq_matrix_allocated, irq_matrix_debug_show",
          "description": "提供中断资源的释放接口，实现全局和CPU级的资源使用统计查询，包含调试信息展示功能，通过位图操作维护系统中断位的使用状态",
          "similarity": 0.4662476181983948
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/matrix.c",
          "start_line": 1,
          "end_line": 77,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "// Copyright (C) 2017 Thomas Gleixner <tglx@linutronix.de>",
            "",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpu.h>",
            "#include <linux/irq.h>",
            "",
            "#define IRQ_MATRIX_SIZE\t(BITS_TO_LONGS(IRQ_MATRIX_BITS))",
            "",
            "struct cpumap {",
            "\tunsigned int\t\tavailable;",
            "\tunsigned int\t\tallocated;",
            "\tunsigned int\t\tmanaged;",
            "\tunsigned int\t\tmanaged_allocated;",
            "\tbool\t\t\tinitialized;",
            "\tbool\t\t\tonline;",
            "\tunsigned long\t\talloc_map[IRQ_MATRIX_SIZE];",
            "\tunsigned long\t\tmanaged_map[IRQ_MATRIX_SIZE];",
            "};",
            "",
            "struct irq_matrix {",
            "\tunsigned int\t\tmatrix_bits;",
            "\tunsigned int\t\talloc_start;",
            "\tunsigned int\t\talloc_end;",
            "\tunsigned int\t\talloc_size;",
            "\tunsigned int\t\tglobal_available;",
            "\tunsigned int\t\tglobal_reserved;",
            "\tunsigned int\t\tsystembits_inalloc;",
            "\tunsigned int\t\ttotal_allocated;",
            "\tunsigned int\t\tonline_maps;",
            "\tstruct cpumap __percpu\t*maps;",
            "\tunsigned long\t\tscratch_map[IRQ_MATRIX_SIZE];",
            "\tunsigned long\t\tsystem_map[IRQ_MATRIX_SIZE];",
            "};",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/irq_matrix.h>",
            "",
            "/**",
            " * irq_alloc_matrix - Allocate a irq_matrix structure and initialize it",
            " * @matrix_bits:\tNumber of matrix bits must be <= IRQ_MATRIX_BITS",
            " * @alloc_start:\tFrom which bit the allocation search starts",
            " * @alloc_end:\t\tAt which bit the allocation search ends, i.e first",
            " *\t\t\tinvalid bit",
            " */",
            "__init struct irq_matrix *irq_alloc_matrix(unsigned int matrix_bits,",
            "\t\t\t\t\t   unsigned int alloc_start,",
            "\t\t\t\t\t   unsigned int alloc_end)",
            "{",
            "\tstruct irq_matrix *m;",
            "",
            "\tif (matrix_bits > IRQ_MATRIX_BITS)",
            "\t\treturn NULL;",
            "",
            "\tm = kzalloc(sizeof(*m), GFP_KERNEL);",
            "\tif (!m)",
            "\t\treturn NULL;",
            "",
            "\tm->matrix_bits = matrix_bits;",
            "\tm->alloc_start = alloc_start;",
            "\tm->alloc_end = alloc_end;",
            "\tm->alloc_size = alloc_end - alloc_start;",
            "\tm->maps = alloc_percpu(*m->maps);",
            "\tif (!m->maps) {",
            "\t\tkfree(m);",
            "\t\treturn NULL;",
            "\t}",
            "\treturn m;",
            "}",
            "",
            "/**",
            " * irq_matrix_online - Bring the local CPU matrix online",
            " * @m:\t\tMatrix pointer",
            " */"
          ],
          "function_name": null,
          "description": "定义irq_matrix结构体和相关辅助数据结构，提供irq_alloc_matrix函数用于初始化并分配irq_matrix实例，设置矩阵大小、起始结束位置等参数，并分配per-CPU的cpumap数组",
          "similarity": 0.38836607336997986
        }
      ]
    }
  ]
}