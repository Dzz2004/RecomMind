{
  "query": "virtual machine monitor",
  "timestamp": "2025-12-26 01:48:40",
  "retrieved_files": [
    {
      "source_file": "mm/damon/vaddr.c",
      "md_summary": "> 自动生成时间: 2025-12-07 15:53:40\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `damon\\vaddr.c`\n\n---\n\n# `damon/vaddr.c` 技术文档\n\n## 1. 文件概述\n\n`damon/vaddr.c` 是 Linux 内核中 DAMON（Data Access MONitor）子系统的一部分，专门用于在**虚拟地址空间**（Virtual Address Space）上实现监控原语。该文件提供了针对进程虚拟内存布局的区域初始化、内存映射分析以及与页表和 VMA（Virtual Memory Area）交互的核心逻辑，旨在高效地将复杂的虚拟地址空间抽象为少量可监控的区域，从而降低监控开销并提升适应性。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`damon_get_task_struct()`**  \n  根据 `damon_target` 中保存的 `pid` 获取对应的 `task_struct`，并增加其引用计数。\n\n- **`damon_get_mm()`**  \n  获取目标进程的 `mm_struct`（内存描述符），调用者需在使用后调用 `mmput()` 释放。\n\n- **`damon_va_evenly_split_region()`**  \n  将一个 DAMON 监控区域均匀分割为指定数量的小区域，每个小区域大小对齐到 `DAMON_MIN_REGION`。\n\n- **`__damon_va_three_regions()`**  \n  在给定的 `mm_struct` 中扫描 VMA，找出两个最大的未映射间隙（unmapped gaps），并据此划分出三个覆盖所有已映射区域的地址范围。\n\n- **`damon_va_three_regions()`**  \n  封装 `__damon_va_three_regions()`，负责获取目标进程的内存上下文并加读锁后调用。\n\n- **`__damon_va_init_regions()`**  \n  为指定的监控目标（进程）初始化三个初始监控区域，并根据配置进一步细分为多个子区域。\n\n- **`damon_va_init()`**  \n  （代码截断，但意图明确）遍历 DAMON 上下文中的所有目标，为每个目标调用 `__damon_va_init_regions()` 进行初始化。\n\n### 关键数据结构\n\n- **`struct damon_target`**  \n  表示一个被监控的目标（通常是一个进程），包含 `pid` 指针等信息。\n\n- **`struct damon_region`**  \n  DAMON 监控的基本单位，表示一段连续的虚拟地址区间（`ar.start` 到 `ar.end`）。\n\n- **`struct damon_addr_range`**  \n  简单的地址范围结构，用于临时存储起止地址。\n\n## 3. 关键实现\n\n### 三区域划分算法（Three-Region Heuristic）\n\n该文件的核心思想是：**避免直接监控整个虚拟地址空间**（含大量未映射区域）。为此，采用启发式方法：\n\n1. 遍历进程的 VMA 链表（通过 `VMA_ITERATOR` 和 RCU 读锁安全访问）。\n2. 记录所有相邻 VMA 之间的间隙（`gap = vma->vm_start - prev->vm_end`）。\n3. 找出**两个最大的间隙**（`first_gap` 和 `second_gap`）。\n4. 将整个已映射地址空间划分为三个区域：\n   - 区域0：从第一个 VMA 起始地址到第一个大间隙的开始\n   - 区域1：从第一个大间隙结束到第二个大间隙开始\n   - 区域2：从第二个大间隙结束到最后一个 VMA 结束地址\n5. 所有边界对齐到 `DAMON_MIN_REGION`（通常为页大小或更大）。\n\n此方法有效跳过了堆与 mmap 区之间、mmap 区与栈之间的巨大空洞，显著减少无效监控区域。\n\n### 区域细分策略\n\n初始化的三个大区域会根据 DAMON 上下文配置的 `min_nr_regions` 进一步细分：\n- 计算平均区域大小：`总监控大小 / min_nr_regions`\n- 若计算结果小于 `DAMON_MIN_REGION`，则使用后者作为最小粒度\n- 调用 `damon_va_evenly_split_region()` 将每个大区域均匀切分为若干子区域\n\n这确保了初始监控粒度既不过粗（丢失细节），也不过细（开销过大）。\n\n### 内存安全与同步\n\n- 使用 `mmap_read_lock()`/`mmap_read_unlock()` 保护 VMA 遍历，兼容并发内存映射变更。\n- 通过 `get_task_mm()` 安全获取 `mm_struct`，防止进程退出导致悬空指针。\n- 所有 `mm_struct` 和 `task_struct` 的引用均正确配对（`get`/`put`）。\n\n## 4. 依赖关系\n\n- **内核头文件依赖**：\n  - `<linux/mm.h>` 相关：`hugetlb.h`, `highmem.h`, `page_idle.h`, `pagewalk.h`, `sched/mm.h`\n  - `<linux/mmu_notifier.h>`：用于内存映射变更通知（虽未直接使用，但为 DAMON 整体架构所需）\n  - `<asm-generic/mman-common.h>`：内存管理常量\n- **DAMON 内部依赖**：\n  - `\"ops-common.h\"`：提供 `damon_new_region()`, `damon_add_region()` 等通用操作\n  - 依赖 DAMON 核心框架的 `damon_ctx`, `damon_target`, `damon_region` 等结构定义\n- **KUnit 测试支持**：\n  - `CONFIG_DAMON_VADDR_KUNIT_TEST` 宏用于测试时调整 `DAMON_MIN_REGION` 为 1，便于验证逻辑\n\n## 5. 使用场景\n\n- **DAMON 虚拟地址监控模式初始化**：当用户通过 DAMON 接口（如 debugfs 或 tracepoint）启动对一组进程的内存访问模式监控时，DAMON 核心调用 `damon_va_init()` 为每个目标进程构建初始监控区域。\n- **内存优化工具基础**：为 `damo`（DAMON 用户空间工具）等提供底层支持，用于识别冷热内存、指导内存回收（如 `reclaim`）、透明大页（THP）优化等。\n- **低开销内存行为分析**：适用于需要长期、低性能影响地监控进程内存访问模式的场景，如云环境中的资源调度、性能剖析等。\n- **自适应内存监控起点**：所生成的初始区域将作为 DAMON 自适应区域调整机制（合并/分裂）的起点，在后续监控周期中动态优化区域划分。",
      "similarity": 0.5414831638336182,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "mm/damon/vaddr.c",
          "start_line": 64,
          "end_line": 170,
          "content": [
            "static int damon_va_evenly_split_region(struct damon_target *t,",
            "\t\tstruct damon_region *r, unsigned int nr_pieces)",
            "{",
            "\tunsigned long sz_orig, sz_piece, orig_end;",
            "\tstruct damon_region *n = NULL, *next;",
            "\tunsigned long start;",
            "\tunsigned int i;",
            "",
            "\tif (!r || !nr_pieces)",
            "\t\treturn -EINVAL;",
            "",
            "\torig_end = r->ar.end;",
            "\tsz_orig = damon_sz_region(r);",
            "\tsz_piece = ALIGN_DOWN(sz_orig / nr_pieces, DAMON_MIN_REGION);",
            "",
            "\tif (!sz_piece)",
            "\t\treturn -EINVAL;",
            "",
            "\tr->ar.end = r->ar.start + sz_piece;",
            "\tnext = damon_next_region(r);",
            "\tfor (start = r->ar.end, i = 1; i < nr_pieces; start += sz_piece, i++) {",
            "\t\tn = damon_new_region(start, start + sz_piece);",
            "\t\tif (!n)",
            "\t\t\treturn -ENOMEM;",
            "\t\tdamon_insert_region(n, r, next, t);",
            "\t\tr = n;",
            "\t}",
            "\t/* complement last region for possible rounding error */",
            "\tif (n)",
            "\t\tn->ar.end = orig_end;",
            "",
            "\treturn 0;",
            "}",
            "static unsigned long sz_range(struct damon_addr_range *r)",
            "{",
            "\treturn r->end - r->start;",
            "}",
            "static int __damon_va_three_regions(struct mm_struct *mm,",
            "\t\t\t\t       struct damon_addr_range regions[3])",
            "{",
            "\tstruct damon_addr_range first_gap = {0}, second_gap = {0};",
            "\tVMA_ITERATOR(vmi, mm, 0);",
            "\tstruct vm_area_struct *vma, *prev = NULL;",
            "\tunsigned long start;",
            "",
            "\t/*",
            "\t * Find the two biggest gaps so that first_gap > second_gap > others.",
            "\t * If this is too slow, it can be optimised to examine the maple",
            "\t * tree gaps.",
            "\t */",
            "\trcu_read_lock();",
            "\tfor_each_vma(vmi, vma) {",
            "\t\tunsigned long gap;",
            "",
            "\t\tif (!prev) {",
            "\t\t\tstart = vma->vm_start;",
            "\t\t\tgoto next;",
            "\t\t}",
            "\t\tgap = vma->vm_start - prev->vm_end;",
            "",
            "\t\tif (gap > sz_range(&first_gap)) {",
            "\t\t\tsecond_gap = first_gap;",
            "\t\t\tfirst_gap.start = prev->vm_end;",
            "\t\t\tfirst_gap.end = vma->vm_start;",
            "\t\t} else if (gap > sz_range(&second_gap)) {",
            "\t\t\tsecond_gap.start = prev->vm_end;",
            "\t\t\tsecond_gap.end = vma->vm_start;",
            "\t\t}",
            "next:",
            "\t\tprev = vma;",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\tif (!sz_range(&second_gap) || !sz_range(&first_gap))",
            "\t\treturn -EINVAL;",
            "",
            "\t/* Sort the two biggest gaps by address */",
            "\tif (first_gap.start > second_gap.start)",
            "\t\tswap(first_gap, second_gap);",
            "",
            "\t/* Store the result */",
            "\tregions[0].start = ALIGN(start, DAMON_MIN_REGION);",
            "\tregions[0].end = ALIGN(first_gap.start, DAMON_MIN_REGION);",
            "\tregions[1].start = ALIGN(first_gap.end, DAMON_MIN_REGION);",
            "\tregions[1].end = ALIGN(second_gap.start, DAMON_MIN_REGION);",
            "\tregions[2].start = ALIGN(second_gap.end, DAMON_MIN_REGION);",
            "\tregions[2].end = ALIGN(prev->vm_end, DAMON_MIN_REGION);",
            "",
            "\treturn 0;",
            "}",
            "static int damon_va_three_regions(struct damon_target *t,",
            "\t\t\t\tstruct damon_addr_range regions[3])",
            "{",
            "\tstruct mm_struct *mm;",
            "\tint rc;",
            "",
            "\tmm = damon_get_mm(t);",
            "\tif (!mm)",
            "\t\treturn -EINVAL;",
            "",
            "\tmmap_read_lock(mm);",
            "\trc = __damon_va_three_regions(mm, regions);",
            "\tmmap_read_unlock(mm);",
            "",
            "\tmmput(mm);",
            "\treturn rc;",
            "}"
          ],
          "function_name": "damon_va_evenly_split_region, sz_range, __damon_va_three_regions, damon_va_three_regions",
          "description": "实现将监控区域均分、计算范围大小及寻找最大空闲间隙的函数，核心功能是通过遍历VMA找到两个最大空闲区间用于后续监控区域划分。",
          "similarity": 0.5290101170539856
        },
        {
          "chunk_id": 5,
          "file_path": "mm/damon/vaddr.c",
          "start_line": 632,
          "end_line": 723,
          "content": [
            "static unsigned long damos_madvise(struct damon_target *target,",
            "\t\tstruct damon_region *r, int behavior)",
            "{",
            "\tstruct mm_struct *mm;",
            "\tunsigned long start = PAGE_ALIGN(r->ar.start);",
            "\tunsigned long len = PAGE_ALIGN(damon_sz_region(r));",
            "\tunsigned long applied;",
            "",
            "\tmm = damon_get_mm(target);",
            "\tif (!mm)",
            "\t\treturn 0;",
            "",
            "\tapplied = do_madvise(mm, start, len, behavior) ? 0 : len;",
            "\tmmput(mm);",
            "",
            "\treturn applied;",
            "}",
            "static unsigned long damon_va_apply_scheme(struct damon_ctx *ctx,",
            "\t\tstruct damon_target *t, struct damon_region *r,",
            "\t\tstruct damos *scheme)",
            "{",
            "\tint madv_action;",
            "",
            "\tswitch (scheme->action) {",
            "\tcase DAMOS_WILLNEED:",
            "\t\tmadv_action = MADV_WILLNEED;",
            "\t\tbreak;",
            "\tcase DAMOS_COLD:",
            "\t\tmadv_action = MADV_COLD;",
            "\t\tbreak;",
            "\tcase DAMOS_PAGEOUT:",
            "\t\tmadv_action = MADV_PAGEOUT;",
            "\t\tbreak;",
            "\tcase DAMOS_HUGEPAGE:",
            "\t\tmadv_action = MADV_HUGEPAGE;",
            "\t\tbreak;",
            "\tcase DAMOS_NOHUGEPAGE:",
            "\t\tmadv_action = MADV_NOHUGEPAGE;",
            "\t\tbreak;",
            "\tcase DAMOS_STAT:",
            "\t\treturn 0;",
            "\tdefault:",
            "\t\t/*",
            "\t\t * DAMOS actions that are not yet supported by 'vaddr'.",
            "\t\t */",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn damos_madvise(t, r, madv_action);",
            "}",
            "static int damon_va_scheme_score(struct damon_ctx *context,",
            "\t\tstruct damon_target *t, struct damon_region *r,",
            "\t\tstruct damos *scheme)",
            "{",
            "",
            "\tswitch (scheme->action) {",
            "\tcase DAMOS_PAGEOUT:",
            "\t\treturn damon_cold_score(context, r, scheme);",
            "\tdefault:",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn DAMOS_MAX_SCORE;",
            "}",
            "static int __init damon_va_initcall(void)",
            "{",
            "\tstruct damon_operations ops = {",
            "\t\t.id = DAMON_OPS_VADDR,",
            "\t\t.init = damon_va_init,",
            "\t\t.update = damon_va_update,",
            "\t\t.prepare_access_checks = damon_va_prepare_access_checks,",
            "\t\t.check_accesses = damon_va_check_accesses,",
            "\t\t.reset_aggregated = NULL,",
            "\t\t.target_valid = damon_va_target_valid,",
            "\t\t.cleanup = NULL,",
            "\t\t.apply_scheme = damon_va_apply_scheme,",
            "\t\t.get_scheme_score = damon_va_scheme_score,",
            "\t};",
            "\t/* ops for fixed virtual address ranges */",
            "\tstruct damon_operations ops_fvaddr = ops;",
            "\tint err;",
            "",
            "\t/* Don't set the monitoring target regions for the entire mapping */",
            "\tops_fvaddr.id = DAMON_OPS_FVADDR;",
            "\tops_fvaddr.init = NULL;",
            "\tops_fvaddr.update = NULL;",
            "",
            "\terr = damon_register_ops(&ops);",
            "\tif (err)",
            "\t\treturn err;",
            "\treturn damon_register_ops(&ops_fvaddr);",
            "};"
          ],
          "function_name": "damos_madvise, damon_va_apply_scheme, damon_va_scheme_score, damon_va_initcall",
          "description": "该代码实现基于虚拟地址的内存优化策略管理，主要功能包括：  \n1. `damos_madvise` 和 `damon_va_apply_scheme` 通过 `madvise` 系统调用对内存区域应用特定行为（如预读、冷页迁移等），`damon_va_scheme_score` 根据策略动态计算区域评分；  \n2. `damon_va_initcall` 注册虚拟地址范围监控操作集，支持两种模式（普通/固定范围），关联策略应用与评分逻辑；  \n3. 代码上下文不完整，依赖外部未展示的 `do_madvise`、`damon_cold_score` 等函数及 `damon_operations` 操作接口。",
          "similarity": 0.5139656066894531
        },
        {
          "chunk_id": 0,
          "file_path": "mm/damon/vaddr.c",
          "start_line": 1,
          "end_line": 63,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * DAMON Primitives for Virtual Address Spaces",
            " *",
            " * Author: SeongJae Park <sjpark@amazon.de>",
            " */",
            "",
            "#define pr_fmt(fmt) \"damon-va: \" fmt",
            "",
            "#include <asm-generic/mman-common.h>",
            "#include <linux/highmem.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/page_idle.h>",
            "#include <linux/pagewalk.h>",
            "#include <linux/sched/mm.h>",
            "",
            "#include \"ops-common.h\"",
            "",
            "#ifdef CONFIG_DAMON_VADDR_KUNIT_TEST",
            "#undef DAMON_MIN_REGION",
            "#define DAMON_MIN_REGION 1",
            "#endif",
            "",
            "/*",
            " * 't->pid' should be the pointer to the relevant 'struct pid' having reference",
            " * count.  Caller must put the returned task, unless it is NULL.",
            " */",
            "static inline struct task_struct *damon_get_task_struct(struct damon_target *t)",
            "{",
            "\treturn get_pid_task(t->pid, PIDTYPE_PID);",
            "}",
            "",
            "/*",
            " * Get the mm_struct of the given target",
            " *",
            " * Caller _must_ put the mm_struct after use, unless it is NULL.",
            " *",
            " * Returns the mm_struct of the target on success, NULL on failure",
            " */",
            "static struct mm_struct *damon_get_mm(struct damon_target *t)",
            "{",
            "\tstruct task_struct *task;",
            "\tstruct mm_struct *mm;",
            "",
            "\ttask = damon_get_task_struct(t);",
            "\tif (!task)",
            "\t\treturn NULL;",
            "",
            "\tmm = get_task_mm(task);",
            "\tput_task_struct(task);",
            "\treturn mm;",
            "}",
            "",
            "/*",
            " * Functions for the initial monitoring target regions construction",
            " */",
            "",
            "/*",
            " * Size-evenly split a region into 'nr_pieces' small regions",
            " *",
            " * Returns 0 on success, or negative error code otherwise.",
            " */"
          ],
          "function_name": null,
          "description": "定义获取进程任务结构体和MM结构体的辅助函数，并声明用于初始监控区域构造的相关函数，核心功能是提供虚拟地址空间监控的基本支持。",
          "similarity": 0.49946701526641846
        },
        {
          "chunk_id": 4,
          "file_path": "mm/damon/vaddr.c",
          "start_line": 503,
          "end_line": 605,
          "content": [
            "static int damon_young_hugetlb_entry(pte_t *pte, unsigned long hmask,",
            "\t\t\t\t     unsigned long addr, unsigned long end,",
            "\t\t\t\t     struct mm_walk *walk)",
            "{",
            "\tstruct damon_young_walk_private *priv = walk->private;",
            "\tstruct hstate *h = hstate_vma(walk->vma);",
            "\tstruct folio *folio;",
            "\tspinlock_t *ptl;",
            "\tpte_t entry;",
            "",
            "\tptl = huge_pte_lock(h, walk->mm, pte);",
            "\tentry = huge_ptep_get(pte);",
            "\tif (!pte_present(entry))",
            "\t\tgoto out;",
            "",
            "\tfolio = pfn_folio(pte_pfn(entry));",
            "\tfolio_get(folio);",
            "",
            "\tif (pte_young(entry) || !folio_test_idle(folio) ||",
            "\t    mmu_notifier_test_young(walk->mm, addr))",
            "\t\tpriv->young = true;",
            "\t*priv->folio_sz = huge_page_size(h);",
            "",
            "\tfolio_put(folio);",
            "",
            "out:",
            "\tspin_unlock(ptl);",
            "\treturn 0;",
            "}",
            "static bool damon_va_young(struct mm_struct *mm, unsigned long addr,",
            "\t\tunsigned long *folio_sz)",
            "{",
            "\tstruct damon_young_walk_private arg = {",
            "\t\t.folio_sz = folio_sz,",
            "\t\t.young = false,",
            "\t};",
            "",
            "\tmmap_read_lock(mm);",
            "\twalk_page_range(mm, addr, addr + 1, &damon_young_ops, &arg);",
            "\tmmap_read_unlock(mm);",
            "\treturn arg.young;",
            "}",
            "static void __damon_va_check_access(struct mm_struct *mm,",
            "\t\t\t\tstruct damon_region *r, bool same_target)",
            "{",
            "\tstatic unsigned long last_addr;",
            "\tstatic unsigned long last_folio_sz = PAGE_SIZE;",
            "\tstatic bool last_accessed;",
            "",
            "\t/* If the region is in the last checked page, reuse the result */",
            "\tif (same_target && (ALIGN_DOWN(last_addr, last_folio_sz) ==",
            "\t\t\t\tALIGN_DOWN(r->sampling_addr, last_folio_sz))) {",
            "\t\tif (last_accessed)",
            "\t\t\tr->nr_accesses++;",
            "\t\treturn;",
            "\t}",
            "",
            "\tlast_accessed = damon_va_young(mm, r->sampling_addr, &last_folio_sz);",
            "\tif (last_accessed)",
            "\t\tr->nr_accesses++;",
            "",
            "\tlast_addr = r->sampling_addr;",
            "}",
            "static unsigned int damon_va_check_accesses(struct damon_ctx *ctx)",
            "{",
            "\tstruct damon_target *t;",
            "\tstruct mm_struct *mm;",
            "\tstruct damon_region *r;",
            "\tunsigned int max_nr_accesses = 0;",
            "\tbool same_target;",
            "",
            "\tdamon_for_each_target(t, ctx) {",
            "\t\tmm = damon_get_mm(t);",
            "\t\tif (!mm)",
            "\t\t\tcontinue;",
            "\t\tsame_target = false;",
            "\t\tdamon_for_each_region(r, t) {",
            "\t\t\t__damon_va_check_access(mm, r, same_target);",
            "\t\t\tmax_nr_accesses = max(r->nr_accesses, max_nr_accesses);",
            "\t\t\tsame_target = true;",
            "\t\t}",
            "\t\tmmput(mm);",
            "\t}",
            "",
            "\treturn max_nr_accesses;",
            "}",
            "static bool damon_va_target_valid(struct damon_target *t)",
            "{",
            "\tstruct task_struct *task;",
            "",
            "\ttask = damon_get_task_struct(t);",
            "\tif (task) {",
            "\t\tput_task_struct(task);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static unsigned long damos_madvise(struct damon_target *target,",
            "\t\tstruct damon_region *r, int behavior)",
            "{",
            "\treturn 0;",
            "}"
          ],
          "function_name": "damon_young_hugetlb_entry, damon_va_young, __damon_va_check_access, damon_va_check_accesses, damon_va_target_valid, damos_madvise",
          "description": "检查页面访问状态及统计访问次数的函数，核心功能是通过遍历内存区域判断页面是否被访问并更新监控数据。",
          "similarity": 0.4554569125175476
        },
        {
          "chunk_id": 2,
          "file_path": "mm/damon/vaddr.c",
          "start_line": 235,
          "end_line": 358,
          "content": [
            "static void __damon_va_init_regions(struct damon_ctx *ctx,",
            "\t\t\t\t     struct damon_target *t)",
            "{",
            "\tstruct damon_target *ti;",
            "\tstruct damon_region *r;",
            "\tstruct damon_addr_range regions[3];",
            "\tunsigned long sz = 0, nr_pieces;",
            "\tint i, tidx = 0;",
            "",
            "\tif (damon_va_three_regions(t, regions)) {",
            "\t\tdamon_for_each_target(ti, ctx) {",
            "\t\t\tif (ti == t)",
            "\t\t\t\tbreak;",
            "\t\t\ttidx++;",
            "\t\t}",
            "\t\tpr_debug(\"Failed to get three regions of %dth target\\n\", tidx);",
            "\t\treturn;",
            "\t}",
            "",
            "\tfor (i = 0; i < 3; i++)",
            "\t\tsz += regions[i].end - regions[i].start;",
            "\tif (ctx->attrs.min_nr_regions)",
            "\t\tsz /= ctx->attrs.min_nr_regions;",
            "\tif (sz < DAMON_MIN_REGION)",
            "\t\tsz = DAMON_MIN_REGION;",
            "",
            "\t/* Set the initial three regions of the target */",
            "\tfor (i = 0; i < 3; i++) {",
            "\t\tr = damon_new_region(regions[i].start, regions[i].end);",
            "\t\tif (!r) {",
            "\t\t\tpr_err(\"%d'th init region creation failed\\n\", i);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\tdamon_add_region(r, t);",
            "",
            "\t\tnr_pieces = (regions[i].end - regions[i].start) / sz;",
            "\t\tdamon_va_evenly_split_region(t, r, nr_pieces);",
            "\t}",
            "}",
            "static void damon_va_init(struct damon_ctx *ctx)",
            "{",
            "\tstruct damon_target *t;",
            "",
            "\tdamon_for_each_target(t, ctx) {",
            "\t\t/* the user may set the target regions as they want */",
            "\t\tif (!damon_nr_regions(t))",
            "\t\t\t__damon_va_init_regions(ctx, t);",
            "\t}",
            "}",
            "static void damon_va_update(struct damon_ctx *ctx)",
            "{",
            "\tstruct damon_addr_range three_regions[3];",
            "\tstruct damon_target *t;",
            "",
            "\tdamon_for_each_target(t, ctx) {",
            "\t\tif (damon_va_three_regions(t, three_regions))",
            "\t\t\tcontinue;",
            "\t\tdamon_set_regions(t, three_regions, 3);",
            "\t}",
            "}",
            "static int damon_mkold_pmd_entry(pmd_t *pmd, unsigned long addr,",
            "\t\tunsigned long next, struct mm_walk *walk)",
            "{",
            "\tpte_t *pte;",
            "\tpmd_t pmde;",
            "\tspinlock_t *ptl;",
            "",
            "\tif (pmd_trans_huge(pmdp_get(pmd))) {",
            "\t\tptl = pmd_lock(walk->mm, pmd);",
            "\t\tpmde = pmdp_get(pmd);",
            "",
            "\t\tif (!pmd_present(pmde)) {",
            "\t\t\tspin_unlock(ptl);",
            "\t\t\treturn 0;",
            "\t\t}",
            "",
            "\t\tif (pmd_trans_huge(pmde)) {",
            "\t\t\tdamon_pmdp_mkold(pmd, walk->vma, addr);",
            "\t\t\tspin_unlock(ptl);",
            "\t\t\treturn 0;",
            "\t\t}",
            "\t\tspin_unlock(ptl);",
            "\t}",
            "",
            "\tpte = pte_offset_map_lock(walk->mm, pmd, addr, &ptl);",
            "\tif (!pte) {",
            "\t\twalk->action = ACTION_AGAIN;",
            "\t\treturn 0;",
            "\t}",
            "\tif (!pte_present(ptep_get(pte)))",
            "\t\tgoto out;",
            "\tdamon_ptep_mkold(pte, walk->vma, addr);",
            "out:",
            "\tpte_unmap_unlock(pte, ptl);",
            "\treturn 0;",
            "}",
            "static void damon_hugetlb_mkold(pte_t *pte, struct mm_struct *mm,",
            "\t\t\t\tstruct vm_area_struct *vma, unsigned long addr)",
            "{",
            "\tbool referenced = false;",
            "\tpte_t entry = huge_ptep_get(pte);",
            "\tstruct folio *folio = pfn_folio(pte_pfn(entry));",
            "\tunsigned long psize = huge_page_size(hstate_vma(vma));",
            "",
            "\tfolio_get(folio);",
            "",
            "\tif (pte_young(entry)) {",
            "\t\treferenced = true;",
            "\t\tentry = pte_mkold(entry);",
            "\t\tset_huge_pte_at(mm, addr, pte, entry, psize);",
            "\t}",
            "",
            "#ifdef CONFIG_MMU_NOTIFIER",
            "\tif (mmu_notifier_clear_young(mm, addr,",
            "\t\t\t\t     addr + huge_page_size(hstate_vma(vma))))",
            "\t\treferenced = true;",
            "#endif /* CONFIG_MMU_NOTIFIER */",
            "",
            "\tif (referenced)",
            "\t\tfolio_set_young(folio);",
            "",
            "\tfolio_set_idle(folio);",
            "\tfolio_put(folio);",
            "}"
          ],
          "function_name": "__damon_va_init_regions, damon_va_init, damon_va_update, damon_mkold_pmd_entry, damon_hugetlb_mkold",
          "description": "初始化和更新监控区域的函数，以及处理大页表项的mkold操作，核心功能是构建初始监控区域并维护页面年轻状态标记。",
          "similarity": 0.43441542983055115
        }
      ]
    },
    {
      "source_file": "mm/vmpressure.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:33:01\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `vmpressure.c`\n\n---\n\n# vmpressure.c 技术文档\n\n## 1. 文件概述\n\n`vmpressure.c` 实现了 Linux 内核中的虚拟内存压力（VM pressure）监控机制。该机制通过跟踪页面扫描（scanned）与回收（reclaimed）的比率，评估系统或特定内存控制组（memcg）所面临的内存压力程度，并在达到预设阈值时向用户空间发送通知。此功能主要用于支持 cgroup v2 的 memory.pressure 接口，使用户空间程序（如容器运行时）能够感知内存紧张状况并作出响应（如释放缓存、限制内存使用等），从而避免系统进入 OOM（Out-Of-Memory）状态。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct vmpressure`**  \n  表示一个内存控制组的 VM 压力状态，包含：\n  - `tree_scanned` / `tree_reclaimed`：累积的扫描和回收页数（用于子树模式）\n  - `sr_lock`：保护上述计数器的自旋锁\n  - `events_lock`：保护事件监听列表的互斥锁\n  - `events`：注册的事件监听器链表（`struct vmpressure_event`）\n  - `work`：延迟处理工作项（`struct work_struct`）\n\n- **`struct vmpressure_event`**  \n  表示一个用户空间注册的压力事件监听器，包含：\n  - `efd`：关联的 eventfd 上下文，用于通知\n  - `level`：触发通知的最低压力等级（low/medium/critical）\n  - `mode`：通知模式（default/hierarchy/local）\n  - `node`：链表节点\n\n### 主要函数\n\n- **`vmpressure()`**  \n  核心接口函数，由内存回收路径（vmscan）调用，传入当前扫描和回收的页数，更新压力统计并可能调度异步处理。\n\n- **`vmpressure_work_fn()`**  \n  工作队列回调函数，负责计算压力等级、触发事件通知，并向上遍历内存控制组层级（支持层次化通知）。\n\n- **`vmpressure_calc_level()`**  \n  根据 `scanned` 和 `reclaimed` 计算压力百分比，并映射到离散的压力等级（low/medium/critical）。\n\n- **`vmpressure_event()`**  \n  遍历当前 memcg 注册的所有事件监听器，根据压力等级、通知模式和层级关系决定是否触发 eventfd 信号。\n\n- **辅助函数**  \n  - `vmpressure_parent()`：获取父级 memcg 对应的 `vmpressure` 结构\n  - `vmpressure_level()`：将压力百分比映射为枚举等级\n  - `work_to_vmpressure()`：从 work_struct 转换为 vmpressure 指针\n\n### 关键常量\n\n- **`vmpressure_win`**：压力计算窗口大小（512 页），用于速率限制和平均\n- **`vmpressure_level_med`**（60）和 **`vmpressure_level_critical`**（95）：中等和严重压力的百分比阈值\n- **`vmpressure_level_critical_prio`**：基于扫描优先级判断严重压力的备用机制\n\n## 3. 关键实现\n\n### 压力等级计算\n压力通过公式 `pressure = (scanned - reclaimed) * 100 / scanned` 计算（实际实现考虑了 `reclaimed > scanned` 的边界情况）。该值反映回收效率：值越高表示回收越困难，内存压力越大。\n\n### 异步处理机制\n`vmpressure()` 函数仅累加计数器并调度 `vmpressure_work_fn` 工作项，避免在内存回收关键路径上执行复杂逻辑。工作项在后台执行压力计算和通知。\n\n### 层级化通知（Hierarchy）\n支持三种通知模式：\n- **`local`**：仅当前 memcg 触发\n- **`hierarchy`**：当前及所有祖先 memcg 均可触发\n- **`default`（no passthrough）**：当前 memcg 触发后，阻止向祖先传递（避免重复通知）\n\n### 窗口与速率限制\n使用固定窗口（`vmpressure_win`）累积扫描/回收页数，确保压力评估具有时间局部性，同时防止高频通知。\n\n### 与 vmscan 集成\n直接接收 vmscan 传递的 `scanned` 和 `reclaimed` 参数，紧密耦合内存回收行为，提供实时压力反馈。\n\n## 4. 依赖关系\n\n- **内存控制组（memcg）**：通过 `mem_cgroup` 结构关联 `vmpressure` 实例，依赖 cgroup 子系统（`memory_cgrp_subsys`）\n- **内存管理核心（mm）**：依赖 `vmscan` 回收路径调用 `vmpressure()`，使用 `SWAP_CLUSTER_MAX` 常量\n- **事件通知机制**：使用 `eventfd` 向用户空间发送信号\n- **内核同步原语**：使用 `spinlock`（`sr_lock`）和 `mutex`（`events_lock`）保护数据\n- **通用内核组件**：依赖 `workqueue`（延迟处理）、`slab`（内存分配）、`printk`（调试）\n\n## 5. 使用场景\n\n1. **容器内存管理**  \n   容器运行时（如 Docker、systemd-nspawn）通过监听 cgroup v2 的 `memory.pressure` 文件，在内存压力升高时主动释放缓存或限制应用内存使用，避免被 OOM killer 终止。\n\n2. **系统级内存优化**  \n   用户空间守护进程（如 earlyoom、nohang）利用压力事件提前干预，例如在 `critical` 压力下终止低优先级进程。\n\n3. **内核子系统集成**  \n   其他内核模块可通过注册 `vmpressure` 事件监听器，在内存紧张时调整自身行为（如降低缓存占用）。\n\n4. **传统 cgroup v1 支持**  \n   通过 `tree` 参数兼容旧版 subtree 压力报告模式（尽管主要面向 cgroup v2 设计）。",
      "similarity": 0.532468318939209,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "mm/vmpressure.c",
          "start_line": 1,
          "end_line": 110,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Linux VM pressure",
            " *",
            " * Copyright 2012 Linaro Ltd.",
            " *\t\t  Anton Vorontsov <anton.vorontsov@linaro.org>",
            " *",
            " * Based on ideas from Andrew Morton, David Rientjes, KOSAKI Motohiro,",
            " * Leonid Moiseichuk, Mel Gorman, Minchan Kim and Pekka Enberg.",
            " */",
            "",
            "#include <linux/cgroup.h>",
            "#include <linux/fs.h>",
            "#include <linux/log2.h>",
            "#include <linux/sched.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/eventfd.h>",
            "#include <linux/slab.h>",
            "#include <linux/swap.h>",
            "#include <linux/printk.h>",
            "#include <linux/vmpressure.h>",
            "",
            "/*",
            " * The window size (vmpressure_win) is the number of scanned pages before",
            " * we try to analyze scanned/reclaimed ratio. So the window is used as a",
            " * rate-limit tunable for the \"low\" level notification, and also for",
            " * averaging the ratio for medium/critical levels. Using small window",
            " * sizes can cause lot of false positives, but too big window size will",
            " * delay the notifications.",
            " *",
            " * As the vmscan reclaimer logic works with chunks which are multiple of",
            " * SWAP_CLUSTER_MAX, it makes sense to use it for the window size as well.",
            " *",
            " * TODO: Make the window size depend on machine size, as we do for vmstat",
            " * thresholds. Currently we set it to 512 pages (2MB for 4KB pages).",
            " */",
            "static const unsigned long vmpressure_win = SWAP_CLUSTER_MAX * 16;",
            "",
            "/*",
            " * These thresholds are used when we account memory pressure through",
            " * scanned/reclaimed ratio. The current values were chosen empirically. In",
            " * essence, they are percents: the higher the value, the more number",
            " * unsuccessful reclaims there were.",
            " */",
            "static const unsigned int vmpressure_level_med = 60;",
            "static const unsigned int vmpressure_level_critical = 95;",
            "",
            "/*",
            " * When there are too little pages left to scan, vmpressure() may miss the",
            " * critical pressure as number of pages will be less than \"window size\".",
            " * However, in that case the vmscan priority will raise fast as the",
            " * reclaimer will try to scan LRUs more deeply.",
            " *",
            " * The vmscan logic considers these special priorities:",
            " *",
            " * prio == DEF_PRIORITY (12): reclaimer starts with that value",
            " * prio <= DEF_PRIORITY - 2 : kswapd becomes somewhat overwhelmed",
            " * prio == 0                : close to OOM, kernel scans every page in an lru",
            " *",
            " * Any value in this range is acceptable for this tunable (i.e. from 12 to",
            " * 0). Current value for the vmpressure_level_critical_prio is chosen",
            " * empirically, but the number, in essence, means that we consider",
            " * critical level when scanning depth is ~10% of the lru size (vmscan",
            " * scans 'lru_size >> prio' pages, so it is actually 12.5%, or one",
            " * eights).",
            " */",
            "static const unsigned int vmpressure_level_critical_prio = ilog2(100 / 10);",
            "",
            "static struct vmpressure *work_to_vmpressure(struct work_struct *work)",
            "{",
            "\treturn container_of(work, struct vmpressure, work);",
            "}",
            "",
            "static struct vmpressure *vmpressure_parent(struct vmpressure *vmpr)",
            "{",
            "\tstruct mem_cgroup *memcg = vmpressure_to_memcg(vmpr);",
            "",
            "\tmemcg = parent_mem_cgroup(memcg);",
            "\tif (!memcg)",
            "\t\treturn NULL;",
            "\treturn memcg_to_vmpressure(memcg);",
            "}",
            "",
            "enum vmpressure_levels {",
            "\tVMPRESSURE_LOW = 0,",
            "\tVMPRESSURE_MEDIUM,",
            "\tVMPRESSURE_CRITICAL,",
            "\tVMPRESSURE_NUM_LEVELS,",
            "};",
            "",
            "enum vmpressure_modes {",
            "\tVMPRESSURE_NO_PASSTHROUGH = 0,",
            "\tVMPRESSURE_HIERARCHY,",
            "\tVMPRESSURE_LOCAL,",
            "\tVMPRESSURE_NUM_MODES,",
            "};",
            "",
            "static const char * const vmpressure_str_levels[] = {",
            "\t[VMPRESSURE_LOW] = \"low\",",
            "\t[VMPRESSURE_MEDIUM] = \"medium\",",
            "\t[VMPRESSURE_CRITICAL] = \"critical\",",
            "};",
            "",
            "static const char * const vmpressure_str_modes[] = {",
            "\t[VMPRESSURE_NO_PASSTHROUGH] = \"default\",",
            "\t[VMPRESSURE_HIERARCHY] = \"hierarchy\",",
            "\t[VMPRESSURE_LOCAL] = \"local\",",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义内存压力监控的相关常量和枚举类型，其中vmpressure_win设置扫描窗口大小，vmpressure_level_med和vmpressure_level_critical定义压力阈值，枚举类型表示压力等级和模式，用于后续压力检测逻辑",
          "similarity": 0.4618087708950043
        },
        {
          "chunk_id": 2,
          "file_path": "mm/vmpressure.c",
          "start_line": 335,
          "end_line": 432,
          "content": [
            "void vmpressure_prio(gfp_t gfp, struct mem_cgroup *memcg, int prio)",
            "{",
            "\t/*",
            "\t * We only use prio for accounting critical level. For more info",
            "\t * see comment for vmpressure_level_critical_prio variable above.",
            "\t */",
            "\tif (prio > vmpressure_level_critical_prio)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * OK, the prio is below the threshold, updating vmpressure",
            "\t * information before shrinker dives into long shrinking of long",
            "\t * range vmscan. Passing scanned = vmpressure_win, reclaimed = 0",
            "\t * to the vmpressure() basically means that we signal 'critical'",
            "\t * level.",
            "\t */",
            "\tvmpressure(gfp, memcg, true, vmpressure_win, 0);",
            "}",
            "int vmpressure_register_event(struct mem_cgroup *memcg,",
            "\t\t\t      struct eventfd_ctx *eventfd, const char *args)",
            "{",
            "\tstruct vmpressure *vmpr = memcg_to_vmpressure(memcg);",
            "\tstruct vmpressure_event *ev;",
            "\tenum vmpressure_modes mode = VMPRESSURE_NO_PASSTHROUGH;",
            "\tenum vmpressure_levels level;",
            "\tchar *spec, *spec_orig;",
            "\tchar *token;",
            "\tint ret = 0;",
            "",
            "\tspec_orig = spec = kstrndup(args, MAX_VMPRESSURE_ARGS_LEN, GFP_KERNEL);",
            "\tif (!spec)",
            "\t\treturn -ENOMEM;",
            "",
            "\t/* Find required level */",
            "\ttoken = strsep(&spec, \",\");",
            "\tret = match_string(vmpressure_str_levels, VMPRESSURE_NUM_LEVELS, token);",
            "\tif (ret < 0)",
            "\t\tgoto out;",
            "\tlevel = ret;",
            "",
            "\t/* Find optional mode */",
            "\ttoken = strsep(&spec, \",\");",
            "\tif (token) {",
            "\t\tret = match_string(vmpressure_str_modes, VMPRESSURE_NUM_MODES, token);",
            "\t\tif (ret < 0)",
            "\t\t\tgoto out;",
            "\t\tmode = ret;",
            "\t}",
            "",
            "\tev = kzalloc(sizeof(*ev), GFP_KERNEL);",
            "\tif (!ev) {",
            "\t\tret = -ENOMEM;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tev->efd = eventfd;",
            "\tev->level = level;",
            "\tev->mode = mode;",
            "",
            "\tmutex_lock(&vmpr->events_lock);",
            "\tlist_add(&ev->node, &vmpr->events);",
            "\tmutex_unlock(&vmpr->events_lock);",
            "\tret = 0;",
            "out:",
            "\tkfree(spec_orig);",
            "\treturn ret;",
            "}",
            "void vmpressure_unregister_event(struct mem_cgroup *memcg,",
            "\t\t\t\t struct eventfd_ctx *eventfd)",
            "{",
            "\tstruct vmpressure *vmpr = memcg_to_vmpressure(memcg);",
            "\tstruct vmpressure_event *ev;",
            "",
            "\tmutex_lock(&vmpr->events_lock);",
            "\tlist_for_each_entry(ev, &vmpr->events, node) {",
            "\t\tif (ev->efd != eventfd)",
            "\t\t\tcontinue;",
            "\t\tlist_del(&ev->node);",
            "\t\tkfree(ev);",
            "\t\tbreak;",
            "\t}",
            "\tmutex_unlock(&vmpr->events_lock);",
            "}",
            "void vmpressure_init(struct vmpressure *vmpr)",
            "{",
            "\tspin_lock_init(&vmpr->sr_lock);",
            "\tmutex_init(&vmpr->events_lock);",
            "\tINIT_LIST_HEAD(&vmpr->events);",
            "\tINIT_WORK(&vmpr->work, vmpressure_work_fn);",
            "}",
            "void vmpressure_cleanup(struct vmpressure *vmpr)",
            "{",
            "\t/*",
            "\t * Make sure there is no pending work before eventfd infrastructure",
            "\t * goes away.",
            "\t */",
            "\tflush_work(&vmpr->work);",
            "}"
          ],
          "function_name": "vmpressure_prio, vmpressure_register_event, vmpressure_unregister_event, vmpressure_init, vmpressure_cleanup",
          "description": "提供压力优先级处理、事件注册注销及资源初始化清理功能，vmpressure_prio根据优先级触发压力检测，注册事件接口用于订阅压力状态变化，初始化函数配置锁和工作队列，清理函数确保资源正确释放",
          "similarity": 0.4611063599586487
        },
        {
          "chunk_id": 1,
          "file_path": "mm/vmpressure.c",
          "start_line": 111,
          "end_line": 290,
          "content": [
            "static enum vmpressure_levels vmpressure_level(unsigned long pressure)",
            "{",
            "\tif (pressure >= vmpressure_level_critical)",
            "\t\treturn VMPRESSURE_CRITICAL;",
            "\telse if (pressure >= vmpressure_level_med)",
            "\t\treturn VMPRESSURE_MEDIUM;",
            "\treturn VMPRESSURE_LOW;",
            "}",
            "static enum vmpressure_levels vmpressure_calc_level(unsigned long scanned,",
            "\t\t\t\t\t\t    unsigned long reclaimed)",
            "{",
            "\tunsigned long scale = scanned + reclaimed;",
            "\tunsigned long pressure = 0;",
            "",
            "\t/*",
            "\t * reclaimed can be greater than scanned for things such as reclaimed",
            "\t * slab pages. shrink_node() just adds reclaimed pages without a",
            "\t * related increment to scanned pages.",
            "\t */",
            "\tif (reclaimed >= scanned)",
            "\t\tgoto out;",
            "\t/*",
            "\t * We calculate the ratio (in percents) of how many pages were",
            "\t * scanned vs. reclaimed in a given time frame (window). Note that",
            "\t * time is in VM reclaimer's \"ticks\", i.e. number of pages",
            "\t * scanned. This makes it possible to set desired reaction time",
            "\t * and serves as a ratelimit.",
            "\t */",
            "\tpressure = scale - (reclaimed * scale / scanned);",
            "\tpressure = pressure * 100 / scale;",
            "",
            "out:",
            "\tpr_debug(\"%s: %3lu  (s: %lu  r: %lu)\\n\", __func__, pressure,",
            "\t\t scanned, reclaimed);",
            "",
            "\treturn vmpressure_level(pressure);",
            "}",
            "static bool vmpressure_event(struct vmpressure *vmpr,",
            "\t\t\t     const enum vmpressure_levels level,",
            "\t\t\t     bool ancestor, bool signalled)",
            "{",
            "\tstruct vmpressure_event *ev;",
            "\tbool ret = false;",
            "",
            "\tmutex_lock(&vmpr->events_lock);",
            "\tlist_for_each_entry(ev, &vmpr->events, node) {",
            "\t\tif (ancestor && ev->mode == VMPRESSURE_LOCAL)",
            "\t\t\tcontinue;",
            "\t\tif (signalled && ev->mode == VMPRESSURE_NO_PASSTHROUGH)",
            "\t\t\tcontinue;",
            "\t\tif (level < ev->level)",
            "\t\t\tcontinue;",
            "\t\teventfd_signal(ev->efd);",
            "\t\tret = true;",
            "\t}",
            "\tmutex_unlock(&vmpr->events_lock);",
            "",
            "\treturn ret;",
            "}",
            "static void vmpressure_work_fn(struct work_struct *work)",
            "{",
            "\tstruct vmpressure *vmpr = work_to_vmpressure(work);",
            "\tunsigned long scanned;",
            "\tunsigned long reclaimed;",
            "\tenum vmpressure_levels level;",
            "\tbool ancestor = false;",
            "\tbool signalled = false;",
            "",
            "\tspin_lock(&vmpr->sr_lock);",
            "\t/*",
            "\t * Several contexts might be calling vmpressure(), so it is",
            "\t * possible that the work was rescheduled again before the old",
            "\t * work context cleared the counters. In that case we will run",
            "\t * just after the old work returns, but then scanned might be zero",
            "\t * here. No need for any locks here since we don't care if",
            "\t * vmpr->reclaimed is in sync.",
            "\t */",
            "\tscanned = vmpr->tree_scanned;",
            "\tif (!scanned) {",
            "\t\tspin_unlock(&vmpr->sr_lock);",
            "\t\treturn;",
            "\t}",
            "",
            "\treclaimed = vmpr->tree_reclaimed;",
            "\tvmpr->tree_scanned = 0;",
            "\tvmpr->tree_reclaimed = 0;",
            "\tspin_unlock(&vmpr->sr_lock);",
            "",
            "\tlevel = vmpressure_calc_level(scanned, reclaimed);",
            "",
            "\tdo {",
            "\t\tif (vmpressure_event(vmpr, level, ancestor, signalled))",
            "\t\t\tsignalled = true;",
            "\t\tancestor = true;",
            "\t} while ((vmpr = vmpressure_parent(vmpr)));",
            "}",
            "void vmpressure(gfp_t gfp, struct mem_cgroup *memcg, bool tree,",
            "\t\tunsigned long scanned, unsigned long reclaimed)",
            "{",
            "\tstruct vmpressure *vmpr;",
            "",
            "\tif (mem_cgroup_disabled())",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * The in-kernel users only care about the reclaim efficiency",
            "\t * for this @memcg rather than the whole subtree, and there",
            "\t * isn't and won't be any in-kernel user in a legacy cgroup.",
            "\t */",
            "\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys) && !tree)",
            "\t\treturn;",
            "",
            "\tvmpr = memcg_to_vmpressure(memcg);",
            "",
            "\t/*",
            "\t * Here we only want to account pressure that userland is able to",
            "\t * help us with. For example, suppose that DMA zone is under",
            "\t * pressure; if we notify userland about that kind of pressure,",
            "\t * then it will be mostly a waste as it will trigger unnecessary",
            "\t * freeing of memory by userland (since userland is more likely to",
            "\t * have HIGHMEM/MOVABLE pages instead of the DMA fallback). That",
            "\t * is why we include only movable, highmem and FS/IO pages.",
            "\t * Indirect reclaim (kswapd) sets sc->gfp_mask to GFP_KERNEL, so",
            "\t * we account it too.",
            "\t */",
            "\tif (!(gfp & (__GFP_HIGHMEM | __GFP_MOVABLE | __GFP_IO | __GFP_FS)))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If we got here with no pages scanned, then that is an indicator",
            "\t * that reclaimer was unable to find any shrinkable LRUs at the",
            "\t * current scanning depth. But it does not mean that we should",
            "\t * report the critical pressure, yet. If the scanning priority",
            "\t * (scanning depth) goes too high (deep), we will be notified",
            "\t * through vmpressure_prio(). But so far, keep calm.",
            "\t */",
            "\tif (!scanned)",
            "\t\treturn;",
            "",
            "\tif (tree) {",
            "\t\tspin_lock(&vmpr->sr_lock);",
            "\t\tscanned = vmpr->tree_scanned += scanned;",
            "\t\tvmpr->tree_reclaimed += reclaimed;",
            "\t\tspin_unlock(&vmpr->sr_lock);",
            "",
            "\t\tif (scanned < vmpressure_win)",
            "\t\t\treturn;",
            "\t\tschedule_work(&vmpr->work);",
            "\t} else {",
            "\t\tenum vmpressure_levels level;",
            "",
            "\t\t/* For now, no users for root-level efficiency */",
            "\t\tif (!memcg || mem_cgroup_is_root(memcg))",
            "\t\t\treturn;",
            "",
            "\t\tspin_lock(&vmpr->sr_lock);",
            "\t\tscanned = vmpr->scanned += scanned;",
            "\t\treclaimed = vmpr->reclaimed += reclaimed;",
            "\t\tif (scanned < vmpressure_win) {",
            "\t\t\tspin_unlock(&vmpr->sr_lock);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\tvmpr->scanned = vmpr->reclaimed = 0;",
            "\t\tspin_unlock(&vmpr->sr_lock);",
            "",
            "\t\tlevel = vmpressure_calc_level(scanned, reclaimed);",
            "",
            "\t\tif (level > VMPRESSURE_LOW) {",
            "\t\t\t/*",
            "\t\t\t * Let the socket buffer allocator know that",
            "\t\t\t * we are having trouble reclaiming LRU pages.",
            "\t\t\t *",
            "\t\t\t * For hysteresis keep the pressure state",
            "\t\t\t * asserted for a second in which subsequent",
            "\t\t\t * pressure events can occur.",
            "\t\t\t */",
            "\t\t\tWRITE_ONCE(memcg->socket_pressure, jiffies + HZ);",
            "\t\t}",
            "\t}",
            "}"
          ],
          "function_name": "vmpressure_level, vmpressure_calc_level, vmpressure_event, vmpressure_work_fn, vmpressure",
          "description": "实现内存压力计算和事件触发逻辑，vmpressure_level计算压力等级，vmpressure_calc_level基于扫描与回收比确定压力值，vmpressure_event处理事件通知，vmpressure_work_fn执行压力分析并触发相应操作",
          "similarity": 0.4500429332256317
        }
      ]
    },
    {
      "source_file": "mm/vmstat.c",
      "md_summary": "> 自动生成时间: 2025-12-07 17:34:18\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `vmstat.c`\n\n---\n\n# vmstat.c 技术文档\n\n## 1. 文件概述\n\n`vmstat.c` 是 Linux 内核内存管理子系统（MM）中的核心统计模块，负责维护和管理虚拟内存相关的各类计数器。该文件实现了以下三类主要统计信息：\n\n- **全局/区域级内存统计**（zone/node 级别）\n- **NUMA 架构下的内存访问统计**\n- **虚拟内存事件计数器**（如页面分配、回收、交换等）\n\n这些统计数据通过 `/proc/vmstat`、`/sys/kernel/debug/` 等接口暴露给用户空间，用于性能监控、调优和故障诊断。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `vm_zone_stat[NR_VM_ZONE_STAT_ITEMS]`：全局区域级内存统计计数器（如空闲页、活跃页等）\n- `vm_node_stat[NR_VM_NODE_STAT_ITEMS]`：NUMA 节点级内存统计计数器\n- `vm_numa_event[NR_VM_NUMA_EVENT_ITEMS]`：NUMA 相关事件计数器（如本地/远程页面分配）\n- `vm_event_states`（per-CPU）：每个 CPU 的虚拟内存事件状态\n- `per_cpu_zonestats` / `per_cpu_nodestats`：每个 CPU 对应的区域/节点统计结构\n\n### 主要函数\n- **NUMA 统计控制**：\n  - `sysctl_vm_numa_stat_handler()`：通过 sysctl 接口动态启用/禁用 NUMA 统计\n  - `invalid_numa_statistics()`：清除所有 NUMA 计数器\n  - `fold_vm_numa_events()`：将 per-CPU NUMA 事件聚合到全局计数器\n\n- **VM 事件管理**（需 CONFIG_VM_EVENT_COUNTERS）：\n  - `all_vm_events()`：汇总所有 CPU 的 VM 事件计数\n  - `vm_events_fold_cpu()`：将指定 CPU 的事件折叠到全局计数器\n\n- **阈值计算与刷新**（SMP 系统）：\n  - `calculate_normal_threshold()`：基于 CPU 数量和内存大小计算正常统计更新阈值\n  - `calculate_pressure_threshold()`：计算内存压力下的保守阈值\n  - `refresh_zone_stat_thresholds()`：为所有区域和节点刷新 per-CPU 统计阈值\n\n## 3. 关键实现\n\n### Per-CPU 统计与延迟更新机制\n为避免频繁原子操作带来的性能开销，内核采用 **per-CPU 缓存 + 延迟批量更新** 策略：\n- 每个 CPU 维护自己的统计副本（如 `per_cpu_zonestats`）\n- 当本地计数器超过预设阈值（`stat_threshold`）时，才将增量同步到全局原子变量\n- 阈值通过 `calculate_normal_threshold()` 动态调整，平衡精度与性能\n\n### NUMA 统计动态开关\n通过静态分支（`static_branch_enable/disable`）实现零开销切换：\n- 启用时：记录本地/远程页面分配等 NUMA 行为\n- 禁用时：立即清零所有相关计数器，避免无效统计\n\n### 内存水位线与漂移容忍\n在 `refresh_zone_stat_thresholds()` 中考虑了统计延迟导致的“漂移”问题：\n- 计算最大可能漂移量：`max_drift = num_online_cpus() * threshold`\n- 若漂移可能掩盖 min watermark 违规，则设置 `percpu_drift_mark` 作为更严格的警戒线\n\n### 高效聚合算法\n- 使用 `xchg()` 原子交换清零 per-CPU 计数器，避免读-改-写竞争\n- 全局聚合时加 `cpus_read_lock()` 防止 CPU 热插拔导致的数据不一致\n\n## 4. 依赖关系\n\n### 头文件依赖\n- `<linux/mm.h>`：内存管理核心定义\n- `<linux/vmstat.h>`：VM 统计相关的宏和类型\n- `<linux/percpu.h>`（隐含）：Per-CPU 变量支持\n- `\"internal.h\"`：MM 子系统内部接口\n\n### 配置选项依赖\n- `CONFIG_NUMA`：启用 NUMA 统计相关代码\n- `CONFIG_VM_EVENT_COUNTERS`：启用详细的 VM 事件计数\n- `CONFIG_SMP`：多处理器阈值计算逻辑\n\n### 符号导出\n- `EXPORT_SYMBOL(vm_zone_stat)` / `vm_node_stat`：供其他模块（如 compaction、vmscan）读取统计\n- `EXPORT_SYMBOL_GPL(all_vm_events)`：供 tracing 或 debug 模块使用\n\n## 5. 使用场景\n\n### 内核内部使用\n- **内存回收**（kswapd）：根据 `NR_FREE_PAGES` 等统计决定回收时机\n- **页面分配器**：更新分配路径的统计（如 `alloc_pages` 调用 `count_vm_event`）\n- **内存压缩**（compaction）：监控迁移成功率等指标\n- **OOM Killer**：评估系统内存压力\n\n### 用户空间监控\n- **`/proc/vmstat`**：提供全局 VM 统计（由 `fs/proc/proc_misc.c` 调用 `all_vm_events` 生成）\n- **`/sys/kernel/debug/`**：debugfs 接口暴露详细 per-zone 统计\n- **性能分析工具**：如 `sar -r`, `vmstat`, `perf` 依赖这些计数器\n- **NUMA 调优**：通过 `numastat` 工具分析跨节点访问开销\n\n### 动态调优\n- 管理员可通过 `sysctl vm.numa_stat=0/1` 动态关闭 NUMA 统计以降低开销\n- 内核根据系统规模自动调整统计更新频率，适应从嵌入式设备到大型服务器的不同场景",
      "similarity": 0.5319172143936157,
      "chunks": [
        {
          "chunk_id": 11,
          "file_path": "mm/vmstat.c",
          "start_line": 1773,
          "end_line": 1875,
          "content": [
            "static int zoneinfo_show(struct seq_file *m, void *arg)",
            "{",
            "\tpg_data_t *pgdat = (pg_data_t *)arg;",
            "\twalk_zones_in_node(m, pgdat, false, false, zoneinfo_show_print);",
            "\treturn 0;",
            "}",
            "static int vmstat_show(struct seq_file *m, void *arg)",
            "{",
            "\tunsigned long *l = arg;",
            "\tunsigned long off = l - (unsigned long *)m->private;",
            "",
            "\tseq_puts(m, vmstat_text[off]);",
            "\tseq_put_decimal_ull(m, \" \", *l);",
            "\tseq_putc(m, '\\n');",
            "",
            "\tif (off == NR_VMSTAT_ITEMS - 1) {",
            "\t\t/*",
            "\t\t * We've come to the end - add any deprecated counters to avoid",
            "\t\t * breaking userspace which might depend on them being present.",
            "\t\t */",
            "\t\tseq_puts(m, \"nr_unstable 0\\n\");",
            "\t}",
            "\treturn 0;",
            "}",
            "static void vmstat_stop(struct seq_file *m, void *arg)",
            "{",
            "\tkfree(m->private);",
            "\tm->private = NULL;",
            "}",
            "static void refresh_vm_stats(struct work_struct *work)",
            "{",
            "\trefresh_cpu_vm_stats(true);",
            "}",
            "int vmstat_refresh(struct ctl_table *table, int write,",
            "\t\t   void *buffer, size_t *lenp, loff_t *ppos)",
            "{",
            "\tlong val;",
            "\tint err;",
            "\tint i;",
            "",
            "\t/*",
            "\t * The regular update, every sysctl_stat_interval, may come later",
            "\t * than expected: leaving a significant amount in per_cpu buckets.",
            "\t * This is particularly misleading when checking a quantity of HUGE",
            "\t * pages, immediately after running a test.  /proc/sys/vm/stat_refresh,",
            "\t * which can equally be echo'ed to or cat'ted from (by root),",
            "\t * can be used to update the stats just before reading them.",
            "\t *",
            "\t * Oh, and since global_zone_page_state() etc. are so careful to hide",
            "\t * transiently negative values, report an error here if any of",
            "\t * the stats is negative, so we know to go looking for imbalance.",
            "\t */",
            "\terr = schedule_on_each_cpu(refresh_vm_stats);",
            "\tif (err)",
            "\t\treturn err;",
            "\tfor (i = 0; i < NR_VM_ZONE_STAT_ITEMS; i++) {",
            "\t\t/*",
            "\t\t * Skip checking stats known to go negative occasionally.",
            "\t\t */",
            "\t\tswitch (i) {",
            "\t\tcase NR_ZONE_WRITE_PENDING:",
            "\t\tcase NR_FREE_CMA_PAGES:",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tval = atomic_long_read(&vm_zone_stat[i]);",
            "\t\tif (val < 0) {",
            "\t\t\tpr_warn(\"%s: %s %ld\\n\",",
            "\t\t\t\t__func__, zone_stat_name(i), val);",
            "\t\t}",
            "\t}",
            "\tfor (i = 0; i < NR_VM_NODE_STAT_ITEMS; i++) {",
            "\t\t/*",
            "\t\t * Skip checking stats known to go negative occasionally.",
            "\t\t */",
            "\t\tswitch (i) {",
            "\t\tcase NR_WRITEBACK:",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\tval = atomic_long_read(&vm_node_stat[i]);",
            "\t\tif (val < 0) {",
            "\t\t\tpr_warn(\"%s: %s %ld\\n\",",
            "\t\t\t\t__func__, node_stat_name(i), val);",
            "\t\t}",
            "\t}",
            "\tif (write)",
            "\t\t*ppos += *lenp;",
            "\telse",
            "\t\t*lenp = 0;",
            "\treturn 0;",
            "}",
            "static void vmstat_update(struct work_struct *w)",
            "{",
            "\tif (refresh_cpu_vm_stats(true)) {",
            "\t\t/*",
            "\t\t * Counters were updated so we expect more updates",
            "\t\t * to occur in the future. Keep on running the",
            "\t\t * update worker thread.",
            "\t\t */",
            "\t\tqueue_delayed_work_on(smp_processor_id(), mm_percpu_wq,",
            "\t\t\t\tthis_cpu_ptr(&vmstat_work),",
            "\t\t\t\tround_jiffies_relative(sysctl_stat_interval));",
            "\t}",
            "}"
          ],
          "function_name": "zoneinfo_show, vmstat_show, vmstat_stop, refresh_vm_stats, vmstat_refresh, vmstat_update",
          "description": "提供虚拟内存统计项的显示与刷新功能，支持通过sysctl接口手动刷新统计数据，包含跨CPU的统计更新及异常值检查逻辑",
          "similarity": 0.604145348072052
        },
        {
          "chunk_id": 12,
          "file_path": "mm/vmstat.c",
          "start_line": 1966,
          "end_line": 2071,
          "content": [
            "static bool need_update(int cpu)",
            "{",
            "\tpg_data_t *last_pgdat = NULL;",
            "\tstruct zone *zone;",
            "",
            "\tfor_each_populated_zone(zone) {",
            "\t\tstruct per_cpu_zonestat *pzstats = per_cpu_ptr(zone->per_cpu_zonestats, cpu);",
            "\t\tstruct per_cpu_nodestat *n;",
            "",
            "\t\t/*",
            "\t\t * The fast way of checking if there are any vmstat diffs.",
            "\t\t */",
            "\t\tif (memchr_inv(pzstats->vm_stat_diff, 0, sizeof(pzstats->vm_stat_diff)))",
            "\t\t\treturn true;",
            "",
            "\t\tif (last_pgdat == zone->zone_pgdat)",
            "\t\t\tcontinue;",
            "\t\tlast_pgdat = zone->zone_pgdat;",
            "\t\tn = per_cpu_ptr(zone->zone_pgdat->per_cpu_nodestats, cpu);",
            "\t\tif (memchr_inv(n->vm_node_stat_diff, 0, sizeof(n->vm_node_stat_diff)))",
            "\t\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "void quiet_vmstat(void)",
            "{",
            "\tif (system_state != SYSTEM_RUNNING)",
            "\t\treturn;",
            "",
            "\tif (!delayed_work_pending(this_cpu_ptr(&vmstat_work)))",
            "\t\treturn;",
            "",
            "\tif (!need_update(smp_processor_id()))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Just refresh counters and do not care about the pending delayed",
            "\t * vmstat_update. It doesn't fire that often to matter and canceling",
            "\t * it would be too expensive from this path.",
            "\t * vmstat_shepherd will take care about that for us.",
            "\t */",
            "\trefresh_cpu_vm_stats(false);",
            "}",
            "static void vmstat_shepherd(struct work_struct *w)",
            "{",
            "\tint cpu;",
            "",
            "\tcpus_read_lock();",
            "\t/* Check processors whose vmstat worker threads have been disabled */",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct delayed_work *dw = &per_cpu(vmstat_work, cpu);",
            "",
            "\t\t/*",
            "\t\t * In kernel users of vmstat counters either require the precise value and",
            "\t\t * they are using zone_page_state_snapshot interface or they can live with",
            "\t\t * an imprecision as the regular flushing can happen at arbitrary time and",
            "\t\t * cumulative error can grow (see calculate_normal_threshold).",
            "\t\t *",
            "\t\t * From that POV the regular flushing can be postponed for CPUs that have",
            "\t\t * been isolated from the kernel interference without critical",
            "\t\t * infrastructure ever noticing. Skip regular flushing from vmstat_shepherd",
            "\t\t * for all isolated CPUs to avoid interference with the isolated workload.",
            "\t\t */",
            "\t\tif (cpu_is_isolated(cpu))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (!delayed_work_pending(dw) && need_update(cpu))",
            "\t\t\tqueue_delayed_work_on(cpu, mm_percpu_wq, dw, 0);",
            "",
            "\t\tcond_resched();",
            "\t}",
            "\tcpus_read_unlock();",
            "",
            "\tschedule_delayed_work(&shepherd,",
            "\t\tround_jiffies_relative(sysctl_stat_interval));",
            "}",
            "static void __init start_shepherd_timer(void)",
            "{",
            "\tint cpu;",
            "",
            "\tfor_each_possible_cpu(cpu)",
            "\t\tINIT_DEFERRABLE_WORK(per_cpu_ptr(&vmstat_work, cpu),",
            "\t\t\tvmstat_update);",
            "",
            "\tschedule_delayed_work(&shepherd,",
            "\t\tround_jiffies_relative(sysctl_stat_interval));",
            "}",
            "static void __init init_cpu_node_state(void)",
            "{",
            "\tint node;",
            "",
            "\tfor_each_online_node(node) {",
            "\t\tif (!cpumask_empty(cpumask_of_node(node)))",
            "\t\t\tnode_set_state(node, N_CPU);",
            "\t}",
            "}",
            "static int vmstat_cpu_online(unsigned int cpu)",
            "{",
            "\trefresh_zone_stat_thresholds();",
            "",
            "\tif (!node_state(cpu_to_node(cpu), N_CPU)) {",
            "\t\tnode_set_state(cpu_to_node(cpu), N_CPU);",
            "\t}",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "need_update, quiet_vmstat, vmstat_shepherd, start_shepherd_timer, init_cpu_node_state, vmstat_cpu_online",
          "description": "管理vmstat统计更新的延迟工作队列，处理CPU热插拔事件的统计维护，包含CPU在线/离线状态下的统计阈值调整与工作队列调度",
          "similarity": 0.5575265884399414
        },
        {
          "chunk_id": 1,
          "file_path": "mm/vmstat.c",
          "start_line": 38,
          "end_line": 142,
          "content": [
            "static void zero_zone_numa_counters(struct zone *zone)",
            "{",
            "\tint item, cpu;",
            "",
            "\tfor (item = 0; item < NR_VM_NUMA_EVENT_ITEMS; item++) {",
            "\t\tatomic_long_set(&zone->vm_numa_event[item], 0);",
            "\t\tfor_each_online_cpu(cpu) {",
            "\t\t\tper_cpu_ptr(zone->per_cpu_zonestats, cpu)->vm_numa_event[item]",
            "\t\t\t\t\t\t= 0;",
            "\t\t}",
            "\t}",
            "}",
            "static void zero_zones_numa_counters(void)",
            "{",
            "\tstruct zone *zone;",
            "",
            "\tfor_each_populated_zone(zone)",
            "\t\tzero_zone_numa_counters(zone);",
            "}",
            "static void zero_global_numa_counters(void)",
            "{",
            "\tint item;",
            "",
            "\tfor (item = 0; item < NR_VM_NUMA_EVENT_ITEMS; item++)",
            "\t\tatomic_long_set(&vm_numa_event[item], 0);",
            "}",
            "static void invalid_numa_statistics(void)",
            "{",
            "\tzero_zones_numa_counters();",
            "\tzero_global_numa_counters();",
            "}",
            "int sysctl_vm_numa_stat_handler(struct ctl_table *table, int write,",
            "\t\tvoid *buffer, size_t *length, loff_t *ppos)",
            "{",
            "\tint ret, oldval;",
            "",
            "\tmutex_lock(&vm_numa_stat_lock);",
            "\tif (write)",
            "\t\toldval = sysctl_vm_numa_stat;",
            "\tret = proc_dointvec_minmax(table, write, buffer, length, ppos);",
            "\tif (ret || !write)",
            "\t\tgoto out;",
            "",
            "\tif (oldval == sysctl_vm_numa_stat)",
            "\t\tgoto out;",
            "\telse if (sysctl_vm_numa_stat == ENABLE_NUMA_STAT) {",
            "\t\tstatic_branch_enable(&vm_numa_stat_key);",
            "\t\tpr_info(\"enable numa statistics\\n\");",
            "\t} else {",
            "\t\tstatic_branch_disable(&vm_numa_stat_key);",
            "\t\tinvalid_numa_statistics();",
            "\t\tpr_info(\"disable numa statistics, and clear numa counters\\n\");",
            "\t}",
            "",
            "out:",
            "\tmutex_unlock(&vm_numa_stat_lock);",
            "\treturn ret;",
            "}",
            "static void sum_vm_events(unsigned long *ret)",
            "{",
            "\tint cpu;",
            "\tint i;",
            "",
            "\tmemset(ret, 0, NR_VM_EVENT_ITEMS * sizeof(unsigned long));",
            "",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct vm_event_state *this = &per_cpu(vm_event_states, cpu);",
            "",
            "\t\tfor (i = 0; i < NR_VM_EVENT_ITEMS; i++)",
            "\t\t\tret[i] += this->event[i];",
            "\t}",
            "}",
            "void all_vm_events(unsigned long *ret)",
            "{",
            "\tcpus_read_lock();",
            "\tsum_vm_events(ret);",
            "\tcpus_read_unlock();",
            "}",
            "void vm_events_fold_cpu(int cpu)",
            "{",
            "\tstruct vm_event_state *fold_state = &per_cpu(vm_event_states, cpu);",
            "\tint i;",
            "",
            "\tfor (i = 0; i < NR_VM_EVENT_ITEMS; i++) {",
            "\t\tcount_vm_events(i, fold_state->event[i]);",
            "\t\tfold_state->event[i] = 0;",
            "\t}",
            "}",
            "static void fold_vm_zone_numa_events(struct zone *zone)",
            "{",
            "\tunsigned long zone_numa_events[NR_VM_NUMA_EVENT_ITEMS] = { 0, };",
            "\tint cpu;",
            "\tenum numa_stat_item item;",
            "",
            "\tfor_each_online_cpu(cpu) {",
            "\t\tstruct per_cpu_zonestat *pzstats;",
            "",
            "\t\tpzstats = per_cpu_ptr(zone->per_cpu_zonestats, cpu);",
            "\t\tfor (item = 0; item < NR_VM_NUMA_EVENT_ITEMS; item++)",
            "\t\t\tzone_numa_events[item] += xchg(&pzstats->vm_numa_event[item], 0);",
            "\t}",
            "",
            "\tfor (item = 0; item < NR_VM_NUMA_EVENT_ITEMS; item++)",
            "\t\tzone_numa_event_add(zone_numa_events[item], zone, item);",
            "}"
          ],
          "function_name": "zero_zone_numa_counters, zero_zones_numa_counters, zero_global_numa_counters, invalid_numa_statistics, sysctl_vm_numa_stat_handler, sum_vm_events, all_vm_events, vm_events_fold_cpu, fold_vm_zone_numa_events",
          "description": "实现NUMA统计计数器的重置逻辑，包含zero_zone_numa_counters用于清空单个zone的统计计数器，sysctl_vm_numa_stat_handler用于动态开关NUMA统计功能，以及fold_vm_zone_numa_events用于汇总多CPU的NUMA事件统计",
          "similarity": 0.4888882637023926
        },
        {
          "chunk_id": 8,
          "file_path": "mm/vmstat.c",
          "start_line": 1014,
          "end_line": 1124,
          "content": [
            "unsigned long node_page_state_pages(struct pglist_data *pgdat,",
            "\t\t\t\t    enum node_stat_item item)",
            "{",
            "\tlong x = atomic_long_read(&pgdat->vm_stat[item]);",
            "#ifdef CONFIG_SMP",
            "\tif (x < 0)",
            "\t\tx = 0;",
            "#endif",
            "\treturn x;",
            "}",
            "unsigned long node_page_state(struct pglist_data *pgdat,",
            "\t\t\t      enum node_stat_item item)",
            "{",
            "\tVM_WARN_ON_ONCE(vmstat_item_in_bytes(item));",
            "",
            "\treturn node_page_state_pages(pgdat, item);",
            "}",
            "static void fill_contig_page_info(struct zone *zone,",
            "\t\t\t\tunsigned int suitable_order,",
            "\t\t\t\tstruct contig_page_info *info)",
            "{",
            "\tunsigned int order;",
            "",
            "\tinfo->free_pages = 0;",
            "\tinfo->free_blocks_total = 0;",
            "\tinfo->free_blocks_suitable = 0;",
            "",
            "\tfor (order = 0; order < NR_PAGE_ORDERS; order++) {",
            "\t\tunsigned long blocks;",
            "",
            "\t\t/*",
            "\t\t * Count number of free blocks.",
            "\t\t *",
            "\t\t * Access to nr_free is lockless as nr_free is used only for",
            "\t\t * diagnostic purposes. Use data_race to avoid KCSAN warning.",
            "\t\t */",
            "\t\tblocks = data_race(zone->free_area[order].nr_free);",
            "\t\tinfo->free_blocks_total += blocks;",
            "",
            "\t\t/* Count free base pages */",
            "\t\tinfo->free_pages += blocks << order;",
            "",
            "\t\t/* Count the suitable free blocks */",
            "\t\tif (order >= suitable_order)",
            "\t\t\tinfo->free_blocks_suitable += blocks <<",
            "\t\t\t\t\t\t(order - suitable_order);",
            "\t}",
            "}",
            "static int __fragmentation_index(unsigned int order, struct contig_page_info *info)",
            "{",
            "\tunsigned long requested = 1UL << order;",
            "",
            "\tif (WARN_ON_ONCE(order > MAX_PAGE_ORDER))",
            "\t\treturn 0;",
            "",
            "\tif (!info->free_blocks_total)",
            "\t\treturn 0;",
            "",
            "\t/* Fragmentation index only makes sense when a request would fail */",
            "\tif (info->free_blocks_suitable)",
            "\t\treturn -1000;",
            "",
            "\t/*",
            "\t * Index is between 0 and 1 so return within 3 decimal places",
            "\t *",
            "\t * 0 => allocation would fail due to lack of memory",
            "\t * 1 => allocation would fail due to fragmentation",
            "\t */",
            "\treturn 1000 - div_u64( (1000+(div_u64(info->free_pages * 1000ULL, requested))), info->free_blocks_total);",
            "}",
            "unsigned int extfrag_for_order(struct zone *zone, unsigned int order)",
            "{",
            "\tstruct contig_page_info info;",
            "",
            "\tfill_contig_page_info(zone, order, &info);",
            "\tif (info.free_pages == 0)",
            "\t\treturn 0;",
            "",
            "\treturn div_u64((info.free_pages -",
            "\t\t\t(info.free_blocks_suitable << order)) * 100,",
            "\t\t\tinfo.free_pages);",
            "}",
            "int fragmentation_index(struct zone *zone, unsigned int order)",
            "{",
            "\tstruct contig_page_info info;",
            "",
            "\tfill_contig_page_info(zone, order, &info);",
            "\treturn __fragmentation_index(order, &info);",
            "}",
            "static void frag_stop(struct seq_file *m, void *arg)",
            "{",
            "}",
            "static void walk_zones_in_node(struct seq_file *m, pg_data_t *pgdat,",
            "\t\tbool assert_populated, bool nolock,",
            "\t\tvoid (*print)(struct seq_file *m, pg_data_t *, struct zone *))",
            "{",
            "\tstruct zone *zone;",
            "\tstruct zone *node_zones = pgdat->node_zones;",
            "\tunsigned long flags;",
            "",
            "\tfor (zone = node_zones; zone - node_zones < MAX_NR_ZONES; ++zone) {",
            "\t\tif (assert_populated && !populated_zone(zone))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (!nolock)",
            "\t\t\tspin_lock_irqsave(&zone->lock, flags);",
            "\t\tprint(m, pgdat, zone);",
            "\t\tif (!nolock)",
            "\t\t\tspin_unlock_irqrestore(&zone->lock, flags);",
            "\t}",
            "}"
          ],
          "function_name": "node_page_state_pages, node_page_state, fill_contig_page_info, __fragmentation_index, extfrag_for_order, fragmentation_index, frag_stop, walk_zones_in_node",
          "description": "提供内存碎片化评估工具，通过分析空闲块分布计算碎片指数，包含遍历节点区域的通用框架用于调试输出。",
          "similarity": 0.465663343667984
        },
        {
          "chunk_id": 0,
          "file_path": "mm/vmstat.c",
          "start_line": 1,
          "end_line": 37,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " *  linux/mm/vmstat.c",
            " *",
            " *  Manages VM statistics",
            " *  Copyright (C) 1991, 1992, 1993, 1994  Linus Torvalds",
            " *",
            " *  zoned VM statistics",
            " *  Copyright (C) 2006 Silicon Graphics, Inc.,",
            " *\t\tChristoph Lameter <christoph@lameter.com>",
            " *  Copyright (C) 2008-2014 Christoph Lameter",
            " */",
            "#include <linux/fs.h>",
            "#include <linux/mm.h>",
            "#include <linux/err.h>",
            "#include <linux/module.h>",
            "#include <linux/slab.h>",
            "#include <linux/cpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/sched.h>",
            "#include <linux/math64.h>",
            "#include <linux/writeback.h>",
            "#include <linux/compaction.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/page_owner.h>",
            "#include <linux/sched/isolation.h>",
            "",
            "#include \"internal.h\"",
            "",
            "#ifdef CONFIG_NUMA",
            "int sysctl_vm_numa_stat = ENABLE_NUMA_STAT;",
            "",
            "/* zero numa counters within a zone */"
          ],
          "function_name": null,
          "description": "此代码块为vmstat模块的头文件引入和配置定义，声明了NUMA统计相关配置项sysctl_vm_numa_stat，用于控制是否启用NUMA统计功能，上下文不完整",
          "similarity": 0.44899582862854004
        }
      ]
    }
  ]
}