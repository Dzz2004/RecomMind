{
  "query": "磁盘调度算法",
  "timestamp": "2025-12-25 23:41:12",
  "retrieved_files": [
    {
      "source_file": "kernel/sched/fair.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:09:04\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\fair.c`\n\n---\n\n# `sched/fair.c` 技术文档\n\n## 1. 文件概述\n\n`sched/fair.c` 是 Linux 内核中 **完全公平调度器**（Completely Fair Scheduler, CFS）的核心实现文件，负责实现 `SCHED_NORMAL` 和 `SCHED_BATCH` 调度策略。CFS 旨在通过红黑树（RB-tree）维护可运行任务的虚拟运行时间（vruntime），以实现 CPU 时间的公平分配。该文件实现了任务调度、负载跟踪、时间片计算、组调度（group scheduling）、NUMA 负载均衡、带宽控制等关键机制，是 Linux 通用调度子系统的核心组成部分。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct sched_entity`：调度实体，代表一个可调度单元（任务或任务组）\n- `struct cfs_rq`：CFS 运行队列，管理一组调度实体\n- `struct load_weight`：负载权重结构，用于计算任务对系统负载的贡献\n\n### 关键函数与宏\n- `__calc_delta()` / `calc_delta_fair()`：计算基于权重的调度时间增量\n- `update_load_add()` / `update_load_sub()` / `update_load_set()`：更新负载权重\n- `__update_inv_weight()`：预计算权重的倒数以优化除法运算\n- `get_update_sysctl_factor()`：根据在线 CPU 数量动态调整调度参数\n- `update_sysctl()` / `sched_init_granularity()`：初始化和更新调度粒度参数\n- `for_each_sched_entity()`：遍历调度实体层级结构（用于组调度）\n\n### 可调参数（sysctl）\n- `sysctl_sched_base_slice`：基础时间片（默认 700,000 纳秒）\n- `sysctl_sched_tunable_scaling`：调度参数缩放策略（NONE/LOG/LINEAR）\n- `sysctl_sched_migration_cost`：任务迁移成本阈值（500 微秒）\n- `sysctl_sched_cfs_bandwidth_slice_us`（CFS 带宽控制切片，默认 5 毫秒）\n- `sysctl_numa_balancing_promote_rate_limit_MBps`（NUMA 页迁移速率限制）\n\n## 3. 关键实现\n\n### 虚拟时间与公平性\nCFS 使用 **虚拟运行时间**（vruntime）衡量任务已使用的 CPU 时间，并通过 `calc_delta_fair()` 将实际执行时间按任务权重归一化。权重由任务的 nice 值决定（`NICE_0_LOAD = 1024` 为基准）。调度器总是选择 vruntime 最小的任务运行，确保高优先级（高权重）任务获得更多 CPU 时间。\n\n### 高效除法优化\n为避免频繁除法运算，CFS 预计算 `inv_weight = WMULT_CONST / weight`（`WMULT_CONST = ~0U`），将除法转换为乘法和右移操作（`mul_u64_u32_shr`）。`__calc_delta()` 通过动态调整移位位数（`shift`）保证计算精度，适用于 32/64 位架构。\n\n### 动态粒度调整\n基础时间片 `sched_base_slice` 根据在线 CPU 数量动态缩放：\n- `SCHED_TUNABLESCALING_NONE`：固定值\n- `SCHED_TUNABLESCALING_LINEAR`：线性缩放（×ncpus）\n- `SCHED_TUNABLESCALING_LOG`（默认）：对数缩放（×(1 + ilog2(ncpus))）  \n此设计确保在多核系统中保持合理的调度延迟和交互性。\n\n### 组调度支持\n通过 `for_each_sched_entity()` 宏遍历任务所属的调度实体层级（任务 → 任务组 → 父任务组），实现 CPU 带宽在任务组间的公平分配。每个 `cfs_rq` 独立维护其子实体的红黑树。\n\n### SMP 相关优化\n- **非对称 CPU 优先级**：`arch_asym_cpu_priority()` 允许架构定义 CPU 能力差异（如大小核）\n- **容量比较宏**：`fits_capacity()`（20% 容差）和 `capacity_greater()`（5% 容差）用于负载均衡决策\n\n## 4. 依赖关系\n\n### 内核头文件依赖\n- 调度核心：`\"sched.h\"`、`\"stats.h\"`、`\"autogroup.h\"`\n- 系统服务：`<linux/sched/clock.h>`、`<linux/sched/nohz.h>`、`<linux/psi.h>`\n- 内存管理：`<linux/mem_policy.h>`、`<linux/energy_model.h>`\n- SMP 支持：`<linux/topology.h>`、`<linux/cpumask_api.h>`\n- 数据结构：`<linux/rbtree_augmented.h>`\n\n### 条件编译特性\n- `CONFIG_SMP`：多处理器调度优化\n- `CONFIG_CFS_BANDWIDTH`：CPU 带宽限制（cgroup v1/v2）\n- `CONFIG_NUMA_BALANCING`：NUMA 自动迁移\n- `CONFIG_FAIR_GROUP_SCHED`：CFS 组调度（cgroup 支持）\n\n## 5. 使用场景\n\n- **通用任务调度**：所有使用 `SCHED_NORMAL` 或 `SCHED_BATCH` 策略的用户态进程\n- **cgroup CPU 资源控制**：通过 `cpu.cfs_quota_us` 和 `cpu.cfs_period_us` 限制任务组带宽\n- **NUMA 优化**：自动迁移内存页以减少远程访问（`numa_balancing`）\n- **节能调度**：结合 `energy_model` 在满足性能前提下选择低功耗 CPU\n- **实时性保障**：通过 `cond_resched()` 在长循环中主动让出 CPU，避免内核抢占延迟过高\n- **系统调优**：管理员通过 `/proc/sys/kernel/` 下的 sysctl 参数动态调整调度行为",
      "similarity": 0.6250284910202026,
      "chunks": [
        {
          "chunk_id": 52,
          "file_path": "kernel/sched/fair.c",
          "start_line": 8581,
          "end_line": 8709,
          "content": [
            "static void set_task_max_allowed_capacity(struct task_struct *p)",
            "{",
            "\tstruct asym_cap_data *entry;",
            "",
            "\tif (!sched_asym_cpucap_active())",
            "\t\treturn;",
            "",
            "\trcu_read_lock();",
            "\tlist_for_each_entry_rcu(entry, &asym_cap_list, link) {",
            "\t\tcpumask_t *cpumask;",
            "",
            "\t\tcpumask = cpu_capacity_span(entry);",
            "\t\tif (!cpumask_intersects(p->cpus_ptr, cpumask))",
            "\t\t\tcontinue;",
            "",
            "\t\tp->max_allowed_capacity = entry->capacity;",
            "\t\tbreak;",
            "\t}",
            "\trcu_read_unlock();",
            "}",
            "static void set_cpus_allowed_fair(struct task_struct *p, struct affinity_context *ctx)",
            "{",
            "\tset_cpus_allowed_common(p, ctx);",
            "\tset_task_max_allowed_capacity(p);",
            "}",
            "static int",
            "balance_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)",
            "{",
            "\tif (sched_fair_runnable(rq))",
            "\t\treturn 1;",
            "",
            "\treturn sched_balance_newidle(rq, rf) != 0;",
            "}",
            "static inline void set_task_max_allowed_capacity(struct task_struct *p) {}",
            "static void set_next_buddy(struct sched_entity *se)",
            "{",
            "\tfor_each_sched_entity(se) {",
            "\t\tif (SCHED_WARN_ON(!se->on_rq))",
            "\t\t\treturn;",
            "\t\tif (se_is_idle(se))",
            "\t\t\treturn;",
            "\t\tcfs_rq_of(se)->next = se;",
            "\t}",
            "}",
            "static void check_preempt_wakeup_fair(struct rq *rq, struct task_struct *p, int wake_flags)",
            "{",
            "\tstruct task_struct *curr = rq->curr;",
            "\tstruct sched_entity *se = &curr->se, *pse = &p->se;",
            "\tstruct cfs_rq *cfs_rq = task_cfs_rq(curr);",
            "\tint next_buddy_marked = 0;",
            "\tint cse_is_idle, pse_is_idle;",
            "",
            "\tif (unlikely(se == pse))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * This is possible from callers such as attach_tasks(), in which we",
            "\t * unconditionally wakeup_preempt() after an enqueue (which may have",
            "\t * lead to a throttle).  This both saves work and prevents false",
            "\t * next-buddy nomination below.",
            "\t */",
            "\tif (unlikely(throttled_hierarchy(cfs_rq_of(pse))))",
            "\t\treturn;",
            "",
            "\tif (sched_feat(NEXT_BUDDY) && !(wake_flags & WF_FORK) && !pse->sched_delayed) {",
            "\t\tset_next_buddy(pse);",
            "\t\tnext_buddy_marked = 1;",
            "\t}",
            "",
            "\t/*",
            "\t * We can come here with TIF_NEED_RESCHED already set from new task",
            "\t * wake up path.",
            "\t *",
            "\t * Note: this also catches the edge-case of curr being in a throttled",
            "\t * group (e.g. via set_curr_task), since update_curr() (in the",
            "\t * enqueue of curr) will have resulted in resched being set.  This",
            "\t * prevents us from potentially nominating it as a false LAST_BUDDY",
            "\t * below.",
            "\t */",
            "\tif (test_tsk_need_resched(curr))",
            "\t\treturn;",
            "",
            "\tif (!sched_feat(WAKEUP_PREEMPTION))",
            "\t\treturn;",
            "",
            "\tfind_matching_se(&se, &pse);",
            "\tWARN_ON_ONCE(!pse);",
            "",
            "\tcse_is_idle = se_is_idle(se);",
            "\tpse_is_idle = se_is_idle(pse);",
            "",
            "\t/*",
            "\t * Preempt an idle entity in favor of a non-idle entity (and don't preempt",
            "\t * in the inverse case).",
            "\t */",
            "\tif (cse_is_idle && !pse_is_idle)",
            "\t\tgoto preempt;",
            "\tif (cse_is_idle != pse_is_idle)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * BATCH and IDLE tasks do not preempt others.",
            "\t */",
            "\tif (unlikely(!normal_policy(p->policy)))",
            "\t\treturn;",
            "",
            "\tcfs_rq = cfs_rq_of(se);",
            "\tupdate_curr(cfs_rq);",
            "\t/*",
            "\t * If @p has a shorter slice than current and @p is eligible, override",
            "\t * current's slice protection in order to allow preemption.",
            "\t *",
            "\t * Note that even if @p does not turn out to be the most eligible",
            "\t * task at this moment, current's slice protection will be lost.",
            "\t */",
            "\tif (do_preempt_short(cfs_rq, pse, se) && se->vlag == se->deadline)",
            "\t\tse->vlag = se->deadline + 1;",
            "",
            "\t/*",
            "\t * If @p has become the most eligible task, force preemption.",
            "\t */",
            "\tif (pick_eevdf(cfs_rq) == pse)",
            "\t\tgoto preempt;",
            "",
            "\treturn;",
            "",
            "preempt:",
            "\tresched_curr(rq);",
            "}"
          ],
          "function_name": "set_task_max_allowed_capacity, set_cpus_allowed_fair, balance_fair, set_task_max_allowed_capacity, set_next_buddy, check_preempt_wakeup_fair",
          "description": "设置任务最大允许容量，实现负载均衡判断逻辑，管理调度实体间的抢占关系和运行队列状态更新。",
          "similarity": 0.6112658977508545
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/fair.c",
          "start_line": 83,
          "end_line": 186,
          "content": [
            "static int __init setup_sched_thermal_decay_shift(char *str)",
            "{",
            "\tpr_warn(\"Ignoring the deprecated sched_thermal_decay_shift= option\\n\");",
            "\treturn 1;",
            "}",
            "int __weak arch_asym_cpu_priority(int cpu)",
            "{",
            "\treturn -cpu;",
            "}",
            "static int __init sched_fair_sysctl_init(void)",
            "{",
            "\tregister_sysctl_init(\"kernel\", sched_fair_sysctls);",
            "\treturn 0;",
            "}",
            "static inline void update_load_add(struct load_weight *lw, unsigned long inc)",
            "{",
            "\tlw->weight += inc;",
            "\tlw->inv_weight = 0;",
            "}",
            "static inline void update_load_sub(struct load_weight *lw, unsigned long dec)",
            "{",
            "\tlw->weight -= dec;",
            "\tlw->inv_weight = 0;",
            "}",
            "static inline void update_load_set(struct load_weight *lw, unsigned long w)",
            "{",
            "\tlw->weight = w;",
            "\tlw->inv_weight = 0;",
            "}",
            "static unsigned int get_update_sysctl_factor(void)",
            "{",
            "\tunsigned int cpus = min_t(unsigned int, num_online_cpus(), 8);",
            "\tunsigned int factor;",
            "",
            "\tswitch (sysctl_sched_tunable_scaling) {",
            "\tcase SCHED_TUNABLESCALING_NONE:",
            "\t\tfactor = 1;",
            "\t\tbreak;",
            "\tcase SCHED_TUNABLESCALING_LINEAR:",
            "\t\tfactor = cpus;",
            "\t\tbreak;",
            "\tcase SCHED_TUNABLESCALING_LOG:",
            "\tdefault:",
            "\t\tfactor = 1 + ilog2(cpus);",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn factor;",
            "}",
            "static void update_sysctl(void)",
            "{",
            "\tunsigned int factor = get_update_sysctl_factor();",
            "",
            "#define SET_SYSCTL(name) \\",
            "\t(sysctl_##name = (factor) * normalized_sysctl_##name)",
            "\tSET_SYSCTL(sched_base_slice);",
            "#undef SET_SYSCTL",
            "}",
            "void __init sched_init_granularity(void)",
            "{",
            "\tupdate_sysctl();",
            "}",
            "static void __update_inv_weight(struct load_weight *lw)",
            "{",
            "\tunsigned long w;",
            "",
            "\tif (likely(lw->inv_weight))",
            "\t\treturn;",
            "",
            "\tw = scale_load_down(lw->weight);",
            "",
            "\tif (BITS_PER_LONG > 32 && unlikely(w >= WMULT_CONST))",
            "\t\tlw->inv_weight = 1;",
            "\telse if (unlikely(!w))",
            "\t\tlw->inv_weight = WMULT_CONST;",
            "\telse",
            "\t\tlw->inv_weight = WMULT_CONST / w;",
            "}",
            "static u64 __calc_delta(u64 delta_exec, unsigned long weight, struct load_weight *lw)",
            "{",
            "\tu64 fact = scale_load_down(weight);",
            "\tu32 fact_hi = (u32)(fact >> 32);",
            "\tint shift = WMULT_SHIFT;",
            "\tint fs;",
            "",
            "\t__update_inv_weight(lw);",
            "",
            "\tif (unlikely(fact_hi)) {",
            "\t\tfs = fls(fact_hi);",
            "\t\tshift -= fs;",
            "\t\tfact >>= fs;",
            "\t}",
            "",
            "\tfact = mul_u32_u32(fact, lw->inv_weight);",
            "",
            "\tfact_hi = (u32)(fact >> 32);",
            "\tif (fact_hi) {",
            "\t\tfs = fls(fact_hi);",
            "\t\tshift -= fs;",
            "\t\tfact >>= fs;",
            "\t}",
            "",
            "\treturn mul_u64_u32_shr(delta_exec, fact, shift);",
            "}"
          ],
          "function_name": "setup_sched_thermal_decay_shift, arch_asym_cpu_priority, sched_fair_sysctl_init, update_load_add, update_load_sub, update_load_set, get_update_sysctl_factor, update_sysctl, sched_init_granularity, __update_inv_weight, __calc_delta",
          "description": "实现负载权重更新逻辑和调度参数缩放因子计算，包含负载调整函数、系统控制参数初始化及虚拟时间计算辅助函数。",
          "similarity": 0.5804227590560913
        },
        {
          "chunk_id": 66,
          "file_path": "kernel/sched/fair.c",
          "start_line": 11839,
          "end_line": 11950,
          "content": [
            "static inline unsigned long",
            "get_sd_balance_interval(struct sched_domain *sd, int cpu_busy)",
            "{",
            "\tunsigned long interval = sd->balance_interval;",
            "",
            "\tif (cpu_busy)",
            "\t\tinterval *= sd->busy_factor;",
            "",
            "\t/* scale ms to jiffies */",
            "\tinterval = msecs_to_jiffies(interval);",
            "",
            "\t/*",
            "\t * Reduce likelihood of busy balancing at higher domains racing with",
            "\t * balancing at lower domains by preventing their balancing periods",
            "\t * from being multiples of each other.",
            "\t */",
            "\tif (cpu_busy)",
            "\t\tinterval -= 1;",
            "",
            "\tinterval = clamp(interval, 1UL, max_load_balance_interval);",
            "",
            "\treturn interval;",
            "}",
            "static inline void",
            "update_next_balance(struct sched_domain *sd, unsigned long *next_balance)",
            "{",
            "\tunsigned long interval, next;",
            "",
            "\t/* used by idle balance, so cpu_busy = 0 */",
            "\tinterval = get_sd_balance_interval(sd, 0);",
            "\tnext = sd->last_balance + interval;",
            "",
            "\tif (time_after(*next_balance, next))",
            "\t\t*next_balance = next;",
            "}",
            "static int active_load_balance_cpu_stop(void *data)",
            "{",
            "\tstruct rq *busiest_rq = data;",
            "\tint busiest_cpu = cpu_of(busiest_rq);",
            "\tint target_cpu = busiest_rq->push_cpu;",
            "\tstruct rq *target_rq = cpu_rq(target_cpu);",
            "\tstruct sched_domain *sd;",
            "\tstruct task_struct *p = NULL;",
            "\tstruct rq_flags rf;",
            "",
            "\trq_lock_irq(busiest_rq, &rf);",
            "\t/*",
            "\t * Between queueing the stop-work and running it is a hole in which",
            "\t * CPUs can become inactive. We should not move tasks from or to",
            "\t * inactive CPUs.",
            "\t */",
            "\tif (!cpu_active(busiest_cpu) || !cpu_active(target_cpu))",
            "\t\tgoto out_unlock;",
            "",
            "\t/* Make sure the requested CPU hasn't gone down in the meantime: */",
            "\tif (unlikely(busiest_cpu != smp_processor_id() ||",
            "\t\t     !busiest_rq->active_balance))",
            "\t\tgoto out_unlock;",
            "",
            "\t/* Is there any task to move? */",
            "\tif (busiest_rq->nr_running <= 1)",
            "\t\tgoto out_unlock;",
            "",
            "\t/*",
            "\t * This condition is \"impossible\", if it occurs",
            "\t * we need to fix it. Originally reported by",
            "\t * Bjorn Helgaas on a 128-CPU setup.",
            "\t */",
            "\tWARN_ON_ONCE(busiest_rq == target_rq);",
            "",
            "\t/* Search for an sd spanning us and the target CPU. */",
            "\trcu_read_lock();",
            "\tfor_each_domain(target_cpu, sd) {",
            "\t\tif (cpumask_test_cpu(busiest_cpu, sched_domain_span(sd)))",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\tif (likely(sd)) {",
            "\t\tstruct lb_env env = {",
            "\t\t\t.sd\t\t= sd,",
            "\t\t\t.dst_cpu\t= target_cpu,",
            "\t\t\t.dst_rq\t\t= target_rq,",
            "\t\t\t.src_cpu\t= busiest_rq->cpu,",
            "\t\t\t.src_rq\t\t= busiest_rq,",
            "\t\t\t.idle\t\t= CPU_IDLE,",
            "\t\t\t.flags\t\t= LBF_ACTIVE_LB,",
            "\t\t};",
            "",
            "\t\tschedstat_inc(sd->alb_count);",
            "\t\tupdate_rq_clock(busiest_rq);",
            "",
            "\t\tp = detach_one_task(&env);",
            "\t\tif (p) {",
            "\t\t\tschedstat_inc(sd->alb_pushed);",
            "\t\t\t/* Active balancing done, reset the failure counter. */",
            "\t\t\tsd->nr_balance_failed = 0;",
            "\t\t} else {",
            "\t\t\tschedstat_inc(sd->alb_failed);",
            "\t\t}",
            "\t}",
            "\trcu_read_unlock();",
            "out_unlock:",
            "\tbusiest_rq->active_balance = 0;",
            "\trq_unlock(busiest_rq, &rf);",
            "",
            "\tif (p)",
            "\t\tattach_one_task(target_rq, p);",
            "",
            "\tlocal_irq_enable();",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "get_sd_balance_interval, update_next_balance, active_load_balance_cpu_stop",
          "description": "计算调度域平衡间隔，更新下次平衡时间戳，处理主动负载平衡的迁移任务终止逻辑",
          "similarity": 0.5801922678947449
        },
        {
          "chunk_id": 14,
          "file_path": "kernel/sched/fair.c",
          "start_line": 2430,
          "end_line": 2620,
          "content": [
            "static void task_numa_find_cpu(struct task_numa_env *env,",
            "\t\t\t\tlong taskimp, long groupimp)",
            "{",
            "\tbool maymove = false;",
            "\tint cpu;",
            "",
            "\t/*",
            "\t * If dst node has spare capacity, then check if there is an",
            "\t * imbalance that would be overruled by the load balancer.",
            "\t */",
            "\tif (env->dst_stats.node_type == node_has_spare) {",
            "\t\tunsigned int imbalance;",
            "\t\tint src_running, dst_running;",
            "",
            "\t\t/*",
            "\t\t * Would movement cause an imbalance? Note that if src has",
            "\t\t * more running tasks that the imbalance is ignored as the",
            "\t\t * move improves the imbalance from the perspective of the",
            "\t\t * CPU load balancer.",
            "\t\t * */",
            "\t\tsrc_running = env->src_stats.nr_running - 1;",
            "\t\tdst_running = env->dst_stats.nr_running + 1;",
            "\t\timbalance = max(0, dst_running - src_running);",
            "\t\timbalance = adjust_numa_imbalance(imbalance, dst_running,",
            "\t\t\t\t\t\t  env->imb_numa_nr);",
            "",
            "\t\t/* Use idle CPU if there is no imbalance */",
            "\t\tif (!imbalance) {",
            "\t\t\tmaymove = true;",
            "\t\t\tif (env->dst_stats.idle_cpu >= 0) {",
            "\t\t\t\tenv->dst_cpu = env->dst_stats.idle_cpu;",
            "\t\t\t\ttask_numa_assign(env, NULL, 0);",
            "\t\t\t\treturn;",
            "\t\t\t}",
            "\t\t}",
            "\t} else {",
            "\t\tlong src_load, dst_load, load;",
            "\t\t/*",
            "\t\t * If the improvement from just moving env->p direction is better",
            "\t\t * than swapping tasks around, check if a move is possible.",
            "\t\t */",
            "\t\tload = task_h_load(env->p);",
            "\t\tdst_load = env->dst_stats.load + load;",
            "\t\tsrc_load = env->src_stats.load - load;",
            "\t\tmaymove = !load_too_imbalanced(src_load, dst_load, env);",
            "\t}",
            "",
            "\tfor_each_cpu(cpu, cpumask_of_node(env->dst_nid)) {",
            "\t\t/* Skip this CPU if the source task cannot migrate */",
            "\t\tif (!cpumask_test_cpu(cpu, env->p->cpus_ptr))",
            "\t\t\tcontinue;",
            "",
            "\t\tenv->dst_cpu = cpu;",
            "\t\tif (task_numa_compare(env, taskimp, groupimp, maymove))",
            "\t\t\tbreak;",
            "\t}",
            "}",
            "static int task_numa_migrate(struct task_struct *p)",
            "{",
            "\tstruct task_numa_env env = {",
            "\t\t.p = p,",
            "",
            "\t\t.src_cpu = task_cpu(p),",
            "\t\t.src_nid = task_node(p),",
            "",
            "\t\t.imbalance_pct = 112,",
            "",
            "\t\t.best_task = NULL,",
            "\t\t.best_imp = 0,",
            "\t\t.best_cpu = -1,",
            "\t};",
            "\tunsigned long taskweight, groupweight;",
            "\tstruct sched_domain *sd;",
            "\tlong taskimp, groupimp;",
            "\tstruct numa_group *ng;",
            "\tstruct rq *best_rq;",
            "\tint nid, ret, dist;",
            "",
            "\t/*",
            "\t * Pick the lowest SD_NUMA domain, as that would have the smallest",
            "\t * imbalance and would be the first to start moving tasks about.",
            "\t *",
            "\t * And we want to avoid any moving of tasks about, as that would create",
            "\t * random movement of tasks -- counter the numa conditions we're trying",
            "\t * to satisfy here.",
            "\t */",
            "\trcu_read_lock();",
            "\tsd = rcu_dereference(per_cpu(sd_numa, env.src_cpu));",
            "\tif (sd) {",
            "\t\tenv.imbalance_pct = 100 + (sd->imbalance_pct - 100) / 2;",
            "\t\tenv.imb_numa_nr = sd->imb_numa_nr;",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\t/*",
            "\t * Cpusets can break the scheduler domain tree into smaller",
            "\t * balance domains, some of which do not cross NUMA boundaries.",
            "\t * Tasks that are \"trapped\" in such domains cannot be migrated",
            "\t * elsewhere, so there is no point in (re)trying.",
            "\t */",
            "\tif (unlikely(!sd)) {",
            "\t\tsched_setnuma(p, task_node(p));",
            "\t\treturn -EINVAL;",
            "\t}",
            "",
            "\tenv.dst_nid = p->numa_preferred_nid;",
            "\tdist = env.dist = node_distance(env.src_nid, env.dst_nid);",
            "\ttaskweight = task_weight(p, env.src_nid, dist);",
            "\tgroupweight = group_weight(p, env.src_nid, dist);",
            "\tupdate_numa_stats(&env, &env.src_stats, env.src_nid, false);",
            "\ttaskimp = task_weight(p, env.dst_nid, dist) - taskweight;",
            "\tgroupimp = group_weight(p, env.dst_nid, dist) - groupweight;",
            "\tupdate_numa_stats(&env, &env.dst_stats, env.dst_nid, true);",
            "",
            "\t/* Try to find a spot on the preferred nid. */",
            "\ttask_numa_find_cpu(&env, taskimp, groupimp);",
            "",
            "\t/*",
            "\t * Look at other nodes in these cases:",
            "\t * - there is no space available on the preferred_nid",
            "\t * - the task is part of a numa_group that is interleaved across",
            "\t *   multiple NUMA nodes; in order to better consolidate the group,",
            "\t *   we need to check other locations.",
            "\t */",
            "\tng = deref_curr_numa_group(p);",
            "\tif (env.best_cpu == -1 || (ng && ng->active_nodes > 1)) {",
            "\t\tfor_each_node_state(nid, N_CPU) {",
            "\t\t\tif (nid == env.src_nid || nid == p->numa_preferred_nid)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tdist = node_distance(env.src_nid, env.dst_nid);",
            "\t\t\tif (sched_numa_topology_type == NUMA_BACKPLANE &&",
            "\t\t\t\t\t\tdist != env.dist) {",
            "\t\t\t\ttaskweight = task_weight(p, env.src_nid, dist);",
            "\t\t\t\tgroupweight = group_weight(p, env.src_nid, dist);",
            "\t\t\t}",
            "",
            "\t\t\t/* Only consider nodes where both task and groups benefit */",
            "\t\t\ttaskimp = task_weight(p, nid, dist) - taskweight;",
            "\t\t\tgroupimp = group_weight(p, nid, dist) - groupweight;",
            "\t\t\tif (taskimp < 0 && groupimp < 0)",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tenv.dist = dist;",
            "\t\t\tenv.dst_nid = nid;",
            "\t\t\tupdate_numa_stats(&env, &env.dst_stats, env.dst_nid, true);",
            "\t\t\ttask_numa_find_cpu(&env, taskimp, groupimp);",
            "\t\t}",
            "\t}",
            "",
            "\t/*",
            "\t * If the task is part of a workload that spans multiple NUMA nodes,",
            "\t * and is migrating into one of the workload's active nodes, remember",
            "\t * this node as the task's preferred numa node, so the workload can",
            "\t * settle down.",
            "\t * A task that migrated to a second choice node will be better off",
            "\t * trying for a better one later. Do not set the preferred node here.",
            "\t */",
            "\tif (ng) {",
            "\t\tif (env.best_cpu == -1)",
            "\t\t\tnid = env.src_nid;",
            "\t\telse",
            "\t\t\tnid = cpu_to_node(env.best_cpu);",
            "",
            "\t\tif (nid != p->numa_preferred_nid)",
            "\t\t\tsched_setnuma(p, nid);",
            "\t}",
            "",
            "\t/* No better CPU than the current one was found. */",
            "\tif (env.best_cpu == -1) {",
            "\t\ttrace_sched_stick_numa(p, env.src_cpu, NULL, -1);",
            "\t\treturn -EAGAIN;",
            "\t}",
            "",
            "\tbest_rq = cpu_rq(env.best_cpu);",
            "\tif (env.best_task == NULL) {",
            "\t\tret = migrate_task_to(p, env.best_cpu);",
            "\t\tWRITE_ONCE(best_rq->numa_migrate_on, 0);",
            "\t\tif (ret != 0)",
            "\t\t\ttrace_sched_stick_numa(p, env.src_cpu, NULL, env.best_cpu);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tret = migrate_swap(p, env.best_task, env.best_cpu, env.src_cpu);",
            "\tWRITE_ONCE(best_rq->numa_migrate_on, 0);",
            "",
            "\tif (ret != 0)",
            "\t\ttrace_sched_stick_numa(p, env.src_cpu, env.best_task, env.best_cpu);",
            "\tput_task_struct(env.best_task);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "task_numa_find_cpu, task_numa_migrate",
          "description": "基于NUMA拓扑和调度域选择最佳目标节点；计算任务权重差异并触发迁移；若未找到合适节点则标记为无法迁移并返回错误码",
          "similarity": 0.5798819065093994
        },
        {
          "chunk_id": 53,
          "file_path": "kernel/sched/fair.c",
          "start_line": 8842,
          "end_line": 8948,
          "content": [
            "static bool fair_server_has_tasks(struct sched_dl_entity *dl_se)",
            "{",
            "\treturn !!dl_se->rq->cfs.nr_running;",
            "}",
            "void fair_server_init(struct rq *rq)",
            "{",
            "\tstruct sched_dl_entity *dl_se = &rq->fair_server;",
            "",
            "\tinit_dl_entity(dl_se);",
            "",
            "\tdl_server_init(dl_se, rq, fair_server_has_tasks, fair_server_pick_next,",
            "\t\t       fair_server_pick_task);",
            "",
            "}",
            "static void put_prev_task_fair(struct rq *rq, struct task_struct *prev, struct task_struct *next)",
            "{",
            "\tstruct sched_entity *se = &prev->se;",
            "\tstruct cfs_rq *cfs_rq;",
            "",
            "\tfor_each_sched_entity(se) {",
            "\t\tcfs_rq = cfs_rq_of(se);",
            "\t\tput_prev_entity(cfs_rq, se);",
            "\t}",
            "}",
            "static void yield_task_fair(struct rq *rq)",
            "{",
            "\tstruct task_struct *curr = rq->curr;",
            "\tstruct cfs_rq *cfs_rq = task_cfs_rq(curr);",
            "\tstruct sched_entity *se = &curr->se;",
            "",
            "\t/*",
            "\t * Are we the only task in the tree?",
            "\t */",
            "\tif (unlikely(rq->nr_running == 1))",
            "\t\treturn;",
            "",
            "\tclear_buddies(cfs_rq, se);",
            "",
            "\tupdate_rq_clock(rq);",
            "\t/*",
            "\t * Update run-time statistics of the 'current'.",
            "\t */",
            "\tupdate_curr(cfs_rq);",
            "\t/*",
            "\t * Tell update_rq_clock() that we've just updated,",
            "\t * so we don't do microscopic update in schedule()",
            "\t * and double the fastpath cost.",
            "\t */",
            "\trq_clock_skip_update(rq);",
            "",
            "\tse->deadline = se->vruntime + calc_delta_fair(se->slice, se);",
            "}",
            "static bool yield_to_task_fair(struct rq *rq, struct task_struct *p)",
            "{",
            "\tstruct sched_entity *se = &p->se;",
            "",
            "\t/* throttled hierarchies are not runnable */",
            "\tif (!se->on_rq || throttled_hierarchy(cfs_rq_of(se)))",
            "\t\treturn false;",
            "",
            "\t/* Tell the scheduler that we'd really like se to run next. */",
            "\tset_next_buddy(se);",
            "",
            "\tyield_task_fair(rq);",
            "",
            "\treturn true;",
            "}",
            "static int task_hot(struct task_struct *p, struct lb_env *env)",
            "{",
            "\ts64 delta;",
            "",
            "\tlockdep_assert_rq_held(env->src_rq);",
            "",
            "\tif (p->sched_class != &fair_sched_class)",
            "\t\treturn 0;",
            "",
            "\tif (unlikely(task_has_idle_policy(p)))",
            "\t\treturn 0;",
            "",
            "\t/* SMT siblings share cache */",
            "\tif (env->sd->flags & SD_SHARE_CPUCAPACITY)",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * Buddy candidates are cache hot:",
            "\t */",
            "\tif (sched_feat(CACHE_HOT_BUDDY) && env->dst_rq->nr_running &&",
            "\t    (&p->se == cfs_rq_of(&p->se)->next))",
            "\t\treturn 1;",
            "",
            "\tif (sysctl_sched_migration_cost == -1)",
            "\t\treturn 1;",
            "",
            "\t/*",
            "\t * Don't migrate task if the task's cookie does not match",
            "\t * with the destination CPU's core cookie.",
            "\t */",
            "\tif (!sched_core_cookie_match(cpu_rq(env->dst_cpu), p))",
            "\t\treturn 1;",
            "",
            "\tif (sysctl_sched_migration_cost == 0)",
            "\t\treturn 0;",
            "",
            "\tdelta = rq_clock_task(env->src_rq) - p->se.exec_start;",
            "",
            "\treturn delta < (s64)sysctl_sched_migration_cost;",
            "}"
          ],
          "function_name": "fair_server_has_tasks, fair_server_init, put_prev_task_fair, yield_task_fair, yield_to_task_fair, task_hot",
          "description": "维护公平调度器的服务器实体状态，实现任务切换时的统计更新、主动让出CPU以及基于缓存热度的任务迁移判定。",
          "similarity": 0.5785181522369385
        }
      ]
    },
    {
      "source_file": "kernel/sched/core_sched.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:00:47\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\core_sched.c`\n\n---\n\n# `sched/core_sched.c` 技术文档\n\n## 1. 文件概述\n\n`sched/core_sched.c` 是 Linux 内核调度器中用于实现 **核心调度（Core Scheduling）** 功能的核心文件之一。核心调度是一种安全机制，旨在防止来自不同安全上下文的任务在同一个物理 CPU 核心（特别是超线程/SMT 共享核心）上并发执行，从而缓解侧信道攻击（如 Spectre、MDS 等）。\n\n该文件主要负责管理任务的 **调度 cookie**（`core_cookie`），通过引用计数的 cookie 对象将具有相同安全上下文的任务分组，确保只有拥有相同 cookie 的任务才能在同一个 CPU 核心上并发运行。\n\n## 2. 核心功能\n\n### 数据结构\n\n- **`struct sched_core_cookie`**  \n  表示一个调度 cookie，仅包含一个引用计数器 `refcnt`。其内存地址本身即作为 cookie 值使用。\n\n### 主要函数\n\n| 函数 | 功能描述 |\n|------|--------|\n| `sched_core_alloc_cookie()` | 分配一个新的 `sched_core_cookie` 对象，初始化引用计数为 1，并启用核心调度全局状态。返回 cookie 地址（转换为 `unsigned long`）。 |\n| `sched_core_put_cookie(unsigned long cookie)` | 释放 cookie 引用；若引用计数归零，则释放内存并关闭核心调度全局状态。 |\n| `sched_core_get_cookie(unsigned long cookie)` | 增加 cookie 引用计数，返回原 cookie 值。 |\n| `sched_core_update_cookie(struct task_struct *p, unsigned long cookie)` | 原子地更新任务 `p` 的 `core_cookie`，处理任务在运行队列中的入队/出队，并在必要时触发重调度。 |\n| `sched_core_clone_cookie(struct task_struct *p)` | 安全地复制任务 `p` 的当前 cookie（带锁保护），用于 fork 或共享操作。 |\n| `sched_core_fork(struct task_struct *p)` | 在 `fork()` 时初始化子任务的核心调度状态，继承父进程的 cookie。 |\n| `sched_core_free(struct task_struct *p)` | 在任务退出时释放其持有的 cookie 引用。 |\n| `__sched_core_set(struct task_struct *p, unsigned long cookie)` | 设置任务 `p` 的 cookie，自动处理引用计数的获取与释放。 |\n| `sched_core_share_pid(...)` | 用户空间通过 `prctl(PR_SCHED_CORE, ...)` 调用的核心接口，支持创建、查询、共享 cookie。 |\n| `__sched_core_account_forceidle(struct rq *rq)` | （仅当 `CONFIG_SCHEDSTATS` 启用）统计核心强制空闲（force-idle）时间，并分摊到相关任务。 |\n| `__sched_core_tick(struct rq *rq)` | 在调度 tick 中调用，用于更新强制空闲时间统计。 |\n\n## 3. 关键实现\n\n### Cookie 生命周期管理\n- Cookie 通过 `kmalloc` 动态分配，其地址作为唯一标识。\n- 使用 `refcount_t` 实现线程安全的引用计数。\n- `sched_core_get()` / `sched_core_put()` 控制全局核心调度使能状态。\n\n### 任务 Cookie 更新\n- 在 `task_rq_lock()` 保护下更新 `p->core_cookie`，确保调度器一致性。\n- 若任务已在运行队列中，先出队再根据新 cookie 决定是否重新入队。\n- 若任务正在 CPU 上运行，调用 `resched_curr()` 触发重调度，以确保新 cookie 策略立即生效。\n\n### 安全访问控制\n- 通过 `ptrace_may_access()` 检查调用者是否有权限操作目标进程的 cookie。\n- 仅当系统存在 SMT（超线程）时（`sched_smt_present` 为真），才允许使用核心调度功能。\n\n### prctl 接口支持\n- 支持四种命令：\n  - `PR_SCHED_CORE_CREATE`：创建新 cookie。\n  - `PR_SCHED_CORE_SHARE_TO`：将当前进程的 cookie 应用于目标进程（或进程组）。\n  - `PR_SCHED_CORE_SHARE_FROM`：将目标进程的 cookie 应用于当前进程。\n  - `PR_SCHED_CORE_GET`：获取目标进程的 cookie 哈希值（用于用户空间识别）。\n- 支持作用域：线程（`PIDTYPE_PID`）、线程组（`PIDTYPE_TGID`）、进程组（`PIDTYPE_PGID`）。\n\n### 强制空闲时间统计（`CONFIG_SCHEDSTATS`）\n- 当核心因 cookie 不兼容而进入强制空闲状态时，记录空闲时间。\n- 时间按 `core_forceidle_count / core_forceidle_occupation` 比例分摊到所有相关 CPU 上的非 idle 任务。\n- 通过 `__account_forceidle_time()` 更新任务的调度统计信息。\n\n## 4. 依赖关系\n\n- **调度器核心**：依赖 `kernel/sched/` 下的通用调度器基础设施，如 `task_rq_lock()`、`resched_curr()`、`rq` 结构等。\n- **SMT 检测**：依赖 `sched_smt_present` 静态分支判断系统是否支持超线程。\n- **内存管理**：使用 `kmalloc`/`kfree` 进行动态内存分配。\n- **进程管理**：依赖 `find_task_by_vpid()`、`tasklist_lock`、`do_each_pid_thread` 等进程遍历机制。\n- **安全机制**：依赖 `ptrace_may_access()` 进行权限检查。\n- **调度统计**：`__sched_core_account_forceidle` 依赖 `CONFIG_SCHEDSTATS` 和 `__account_forceidle_time`。\n\n## 5. 使用场景\n\n- **安全敏感应用**：如浏览器、虚拟机监控器（VMM）、加密服务等，需防止跨任务的侧信道攻击。\n- **用户空间控制**：通过 `prctl(PR_SCHED_CORE, ...)` 接口，应用程序可显式创建和共享调度 cookie，将信任的任务分组。\n- **进程 fork 行为**：子进程自动继承父进程的 cookie，确保同源任务保持调度兼容性。\n- **系统资源隔离**：在多租户或容器环境中，确保不同租户的任务不会在同一个物理核心上并发执行。\n- **性能调优与监控**：通过 `CONFIG_SCHEDSTATS` 收集核心强制空闲开销，评估安全策略对性能的影响。",
      "similarity": 0.6121341586112976,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/core_sched.c",
          "start_line": 11,
          "end_line": 216,
          "content": [
            "static unsigned long sched_core_alloc_cookie(void)",
            "{",
            "\tstruct sched_core_cookie *ck = kmalloc(sizeof(*ck), GFP_KERNEL);",
            "\tif (!ck)",
            "\t\treturn 0;",
            "",
            "\trefcount_set(&ck->refcnt, 1);",
            "\tsched_core_get();",
            "",
            "\treturn (unsigned long)ck;",
            "}",
            "static void sched_core_put_cookie(unsigned long cookie)",
            "{",
            "\tstruct sched_core_cookie *ptr = (void *)cookie;",
            "",
            "\tif (ptr && refcount_dec_and_test(&ptr->refcnt)) {",
            "\t\tkfree(ptr);",
            "\t\tsched_core_put();",
            "\t}",
            "}",
            "static unsigned long sched_core_get_cookie(unsigned long cookie)",
            "{",
            "\tstruct sched_core_cookie *ptr = (void *)cookie;",
            "",
            "\tif (ptr)",
            "\t\trefcount_inc(&ptr->refcnt);",
            "",
            "\treturn cookie;",
            "}",
            "static unsigned long sched_core_update_cookie(struct task_struct *p,",
            "\t\t\t\t\t      unsigned long cookie)",
            "{",
            "\tunsigned long old_cookie;",
            "\tstruct rq_flags rf;",
            "\tstruct rq *rq;",
            "",
            "\trq = task_rq_lock(p, &rf);",
            "",
            "\t/*",
            "\t * Since creating a cookie implies sched_core_get(), and we cannot set",
            "\t * a cookie until after we've created it, similarly, we cannot destroy",
            "\t * a cookie until after we've removed it, we must have core scheduling",
            "\t * enabled here.",
            "\t */",
            "\tSCHED_WARN_ON((p->core_cookie || cookie) && !sched_core_enabled(rq));",
            "",
            "\tif (sched_core_enqueued(p))",
            "\t\tsched_core_dequeue(rq, p, DEQUEUE_SAVE);",
            "",
            "\told_cookie = p->core_cookie;",
            "\tp->core_cookie = cookie;",
            "",
            "\t/*",
            "\t * Consider the cases: !prev_cookie and !cookie.",
            "\t */",
            "\tif (cookie && task_on_rq_queued(p))",
            "\t\tsched_core_enqueue(rq, p);",
            "",
            "\t/*",
            "\t * If task is currently running, it may not be compatible anymore after",
            "\t * the cookie change, so enter the scheduler on its CPU to schedule it",
            "\t * away.",
            "\t *",
            "\t * Note that it is possible that as a result of this cookie change, the",
            "\t * core has now entered/left forced idle state. Defer accounting to the",
            "\t * next scheduling edge, rather than always forcing a reschedule here.",
            "\t */",
            "\tif (task_on_cpu(rq, p))",
            "\t\tresched_curr(rq);",
            "",
            "\ttask_rq_unlock(rq, p, &rf);",
            "",
            "\treturn old_cookie;",
            "}",
            "static unsigned long sched_core_clone_cookie(struct task_struct *p)",
            "{",
            "\tunsigned long cookie, flags;",
            "",
            "\traw_spin_lock_irqsave(&p->pi_lock, flags);",
            "\tcookie = sched_core_get_cookie(p->core_cookie);",
            "\traw_spin_unlock_irqrestore(&p->pi_lock, flags);",
            "",
            "\treturn cookie;",
            "}",
            "void sched_core_fork(struct task_struct *p)",
            "{",
            "\tRB_CLEAR_NODE(&p->core_node);",
            "\tp->core_cookie = sched_core_clone_cookie(current);",
            "}",
            "void sched_core_free(struct task_struct *p)",
            "{",
            "\tsched_core_put_cookie(p->core_cookie);",
            "}",
            "static void __sched_core_set(struct task_struct *p, unsigned long cookie)",
            "{",
            "\tcookie = sched_core_get_cookie(cookie);",
            "\tcookie = sched_core_update_cookie(p, cookie);",
            "\tsched_core_put_cookie(cookie);",
            "}",
            "int sched_core_share_pid(unsigned int cmd, pid_t pid, enum pid_type type,",
            "\t\t\t unsigned long uaddr)",
            "{",
            "\tunsigned long cookie = 0, id = 0;",
            "\tstruct task_struct *task, *p;",
            "\tstruct pid *grp;",
            "\tint err = 0;",
            "",
            "\tif (!static_branch_likely(&sched_smt_present))",
            "\t\treturn -ENODEV;",
            "",
            "\tBUILD_BUG_ON(PR_SCHED_CORE_SCOPE_THREAD != PIDTYPE_PID);",
            "\tBUILD_BUG_ON(PR_SCHED_CORE_SCOPE_THREAD_GROUP != PIDTYPE_TGID);",
            "\tBUILD_BUG_ON(PR_SCHED_CORE_SCOPE_PROCESS_GROUP != PIDTYPE_PGID);",
            "",
            "\tif (type > PIDTYPE_PGID || cmd >= PR_SCHED_CORE_MAX || pid < 0 ||",
            "\t    (cmd != PR_SCHED_CORE_GET && uaddr))",
            "\t\treturn -EINVAL;",
            "",
            "\trcu_read_lock();",
            "\tif (pid == 0) {",
            "\t\ttask = current;",
            "\t} else {",
            "\t\ttask = find_task_by_vpid(pid);",
            "\t\tif (!task) {",
            "\t\t\trcu_read_unlock();",
            "\t\t\treturn -ESRCH;",
            "\t\t}",
            "\t}",
            "\tget_task_struct(task);",
            "\trcu_read_unlock();",
            "",
            "\t/*",
            "\t * Check if this process has the right to modify the specified",
            "\t * process. Use the regular \"ptrace_may_access()\" checks.",
            "\t */",
            "\tif (!ptrace_may_access(task, PTRACE_MODE_READ_REALCREDS)) {",
            "\t\terr = -EPERM;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tswitch (cmd) {",
            "\tcase PR_SCHED_CORE_GET:",
            "\t\tif (type != PIDTYPE_PID || uaddr & 7) {",
            "\t\t\terr = -EINVAL;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t\tcookie = sched_core_clone_cookie(task);",
            "\t\tif (cookie) {",
            "\t\t\t/* XXX improve ? */",
            "\t\t\tptr_to_hashval((void *)cookie, &id);",
            "\t\t}",
            "\t\terr = put_user(id, (u64 __user *)uaddr);",
            "\t\tgoto out;",
            "",
            "\tcase PR_SCHED_CORE_CREATE:",
            "\t\tcookie = sched_core_alloc_cookie();",
            "\t\tif (!cookie) {",
            "\t\t\terr = -ENOMEM;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t\tbreak;",
            "",
            "\tcase PR_SCHED_CORE_SHARE_TO:",
            "\t\tcookie = sched_core_clone_cookie(current);",
            "\t\tbreak;",
            "",
            "\tcase PR_SCHED_CORE_SHARE_FROM:",
            "\t\tif (type != PIDTYPE_PID) {",
            "\t\t\terr = -EINVAL;",
            "\t\t\tgoto out;",
            "\t\t}",
            "\t\tcookie = sched_core_clone_cookie(task);",
            "\t\t__sched_core_set(current, cookie);",
            "\t\tgoto out;",
            "",
            "\tdefault:",
            "\t\terr = -EINVAL;",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (type == PIDTYPE_PID) {",
            "\t\t__sched_core_set(task, cookie);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tread_lock(&tasklist_lock);",
            "\tgrp = task_pid_type(task, type);",
            "",
            "\tdo_each_pid_thread(grp, type, p) {",
            "\t\tif (!ptrace_may_access(p, PTRACE_MODE_READ_REALCREDS)) {",
            "\t\t\terr = -EPERM;",
            "\t\t\tgoto out_tasklist;",
            "\t\t}",
            "\t} while_each_pid_thread(grp, type, p);",
            "",
            "\tdo_each_pid_thread(grp, type, p) {",
            "\t\t__sched_core_set(p, cookie);",
            "\t} while_each_pid_thread(grp, type, p);",
            "out_tasklist:",
            "\tread_unlock(&tasklist_lock);",
            "",
            "out:",
            "\tsched_core_put_cookie(cookie);",
            "\tput_task_struct(task);",
            "\treturn err;",
            "}"
          ],
          "function_name": "sched_core_alloc_cookie, sched_core_put_cookie, sched_core_get_cookie, sched_core_update_cookie, sched_core_clone_cookie, sched_core_fork, sched_core_free, __sched_core_set, sched_core_share_pid",
          "description": "实现了核心调度 cookie 的分配、释放、获取和更新机制，包含 cookie 分配/回收、任务核心绑定变更、进程克隆共享及核心调度策略控制等功能",
          "similarity": 0.5923396348953247
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/core_sched.c",
          "start_line": 1,
          "end_line": 10,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "",
            "/*",
            " * A simple wrapper around refcount. An allocated sched_core_cookie's",
            " * address is used to compute the cookie of the task.",
            " */",
            "struct sched_core_cookie {",
            "\trefcount_t refcnt;",
            "};",
            ""
          ],
          "function_name": null,
          "description": "定义了 sched_core_cookie 结构体，用于核心调度系统中管理任务的 cookie 引用计数，通过结构体地址计算 cookie 值",
          "similarity": 0.5056924223899841
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/core_sched.c",
          "start_line": 240,
          "end_line": 297,
          "content": [
            "void __sched_core_account_forceidle(struct rq *rq)",
            "{",
            "\tconst struct cpumask *smt_mask = cpu_smt_mask(cpu_of(rq));",
            "\tu64 delta, now = rq_clock(rq->core);",
            "\tstruct rq *rq_i;",
            "\tstruct task_struct *p;",
            "\tint i;",
            "",
            "\tlockdep_assert_rq_held(rq);",
            "",
            "\tWARN_ON_ONCE(!rq->core->core_forceidle_count);",
            "",
            "\tif (rq->core->core_forceidle_start == 0)",
            "\t\treturn;",
            "",
            "\tdelta = now - rq->core->core_forceidle_start;",
            "\tif (unlikely((s64)delta <= 0))",
            "\t\treturn;",
            "",
            "\trq->core->core_forceidle_start = now;",
            "",
            "\tif (WARN_ON_ONCE(!rq->core->core_forceidle_occupation)) {",
            "\t\t/* can't be forced idle without a running task */",
            "\t} else if (rq->core->core_forceidle_count > 1 ||",
            "\t\t   rq->core->core_forceidle_occupation > 1) {",
            "\t\t/*",
            "\t\t * For larger SMT configurations, we need to scale the charged",
            "\t\t * forced idle amount since there can be more than one forced",
            "\t\t * idle sibling and more than one running cookied task.",
            "\t\t */",
            "\t\tdelta *= rq->core->core_forceidle_count;",
            "\t\tdelta = div_u64(delta, rq->core->core_forceidle_occupation);",
            "\t}",
            "",
            "\tfor_each_cpu(i, smt_mask) {",
            "\t\trq_i = cpu_rq(i);",
            "\t\tp = rq_i->core_pick ?: rq_i->curr;",
            "",
            "\t\tif (p == rq_i->idle)",
            "\t\t\tcontinue;",
            "",
            "\t\t/*",
            "\t\t * Note: this will account forceidle to the current cpu, even",
            "\t\t * if it comes from our SMT sibling.",
            "\t\t */",
            "\t\t__account_forceidle_time(p, delta);",
            "\t}",
            "}",
            "void __sched_core_tick(struct rq *rq)",
            "{",
            "\tif (!rq->core->core_forceidle_count)",
            "\t\treturn;",
            "",
            "\tif (rq != rq->core)",
            "\t\tupdate_rq_clock(rq->core);",
            "",
            "\t__sched_core_account_forceidle(rq);",
            "}"
          ],
          "function_name": "__sched_core_account_forceidle, __sched_core_tick",
          "description": "提供强制空闲时间统计功能，通过遍历 SMT 核心计算并分摊强制空闲时间消耗，tick 中断触发强制空闲会计入逻辑",
          "similarity": 0.5019029378890991
        }
      ]
    },
    {
      "source_file": "kernel/sched/sched.h",
      "md_summary": "> 自动生成时间: 2025-10-25 16:16:13\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\sched.h`\n\n---\n\n# `sched/sched.h` 技术文档\n\n## 1. 文件概述\n\n`sched/sched.h` 是 Linux 内核调度器（Scheduler）的核心内部头文件，定义了调度子系统内部使用的类型、宏、辅助函数和全局变量。该文件不对外暴露给其他子系统直接使用，而是作为调度器各组件（如 CFS、RT、Deadline 调度类）之间的内部接口和共享基础设施。它整合了任务状态管理、负载计算、策略判断、CPU 能力建模、cgroup 权重转换等关键调度逻辑，并为调试、性能追踪和平台适配提供支持。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct asym_cap_data`：用于描述非对称 CPU 架构中不同 CPU 集合的计算能力（capacity），支持异构多核系统（如 big.LITTLE）的调度优化。\n- `struct rq`（前向声明）：运行队列（runqueue）结构体，每个 CPU 对应一个，是调度器管理可运行任务的核心数据结构。\n- `struct cpuidle_state`（前向声明）：CPU 空闲状态信息，用于与调度器协同进行能效管理。\n\n### 关键全局变量\n- `scheduler_running`：标志调度器是否已启动。\n- `calc_load_update` / `calc_load_tasks`：用于全局负载（load average）计算的时间戳和任务计数。\n- `sysctl_sched_rt_period` / `sysctl_sched_rt_runtime`：实时任务带宽控制参数。\n- `sched_rr_timeslice`：SCHED_RR 策略的时间片长度。\n- `asym_cap_list`：非对称 CPU 能力数据的全局链表。\n\n### 核心辅助函数与宏\n- **任务策略判断函数**：\n  - `idle_policy()` / `task_has_idle_policy()`\n  - `normal_policy()` / `fair_policy()`\n  - `rt_policy()` / `task_has_rt_policy()`\n  - `dl_policy()` / `task_has_dl_policy()`\n  - `valid_policy()`\n- **负载与权重转换**：\n  - `scale_load()` / `scale_load_down()`：在内部高精度负载值与用户可见权重间转换。\n  - `sched_weight_from_cgroup()` / `sched_weight_to_cgroup()`：cgroup 权重与调度器内部权重的映射。\n- **时间与精度处理**：\n  - `NS_TO_JIFFIES()`：纳秒转 jiffies。\n  - `update_avg()`：指数移动平均（EMA）更新。\n  - `shr_bound()`：安全右移，避免未定义行为。\n- **特殊调度标志**：\n  - `SCHED_FLAG_SUGOV`：用于 schedutil 频率调节器的特殊标志，使相关 kworker 临时获得高于 SCHED_DEADLINE 的优先级。\n  - `dl_entity_is_special()`：判断 Deadline 实体是否为 SUGOV 特殊任务。\n\n### 重要宏定义\n- `TASK_ON_RQ_QUEUED` / `TASK_ON_RQ_MIGRATING`：`task_struct::on_rq` 字段的状态值。\n- `NICE_0_LOAD`：nice 值为 0 的任务对应的内部负载基准值。\n- `DL_SCALE`：SCHED_DEADLINE 内部计算的精度因子。\n- `RUNTIME_INF`：表示无限运行时间的常量。\n- `SCHED_WARN_ON()`：调度器专用的条件警告宏（仅在 `CONFIG_SCHED_DEBUG` 时生效）。\n\n## 3. 关键实现\n\n### 高精度负载计算（64 位优化）\n在 64 位架构上，通过 `NICE_0_LOAD_SHIFT = 2 * SCHED_FIXEDPOINT_SHIFT` 提升内部负载计算的精度，改善低权重任务组（如 nice +19）和深层 cgroup 层级的负载均衡效果。`scale_load()` 和 `scale_load_down()` 实现了用户权重与内部高精度负载值之间的无损转换。\n\n### 非对称 CPU 能力建模\n`asym_cap_data` 结构体结合 `cpu_capacity_span()` 宏，将具有相同计算能力的 CPU 归为一组，并通过全局链表 `asym_cap_list` 管理。这为调度器在异构系统中进行负载均衡和任务迁移提供关键拓扑信息。\n\n### cgroup 权重标准化\n通过 `sched_weight_from_cgroup()` 和 `sched_weight_to_cgroup()`，将 cgroup 接口的权重范围（1–10000，默认 100）映射到调度器内部使用的权重值（基于 1024 基准），确保用户配置与调度行为的一致性。\n\n### SCHED_DEADLINE 与频率调节协同\n引入 `SCHED_FLAG_SUGOV` 标志，允许 `schedutil` 频率调节器的工作线程在需要时临时突破 SCHED_DEADLINE 的优先级限制，以解决某些平台无法原子切换 CPU 频率的问题。这是一种临时性 workaround，依赖于 `dl_entity_is_special()` 进行识别。\n\n### 安全位运算\n`shr_bound()` 宏确保右移操作不会因移位数过大而触发未定义行为（UB），通过 `min_t()` 将移位数限制在 `BITS_PER_TYPE(val) - 1` 以内。\n\n## 4. 依赖关系\n\n### 内核头文件依赖\n- **调度子系统内部**：包含多个调度相关子模块头文件（如 `affinity.h`, `deadline.h`, `topology.h`, `cpupri.h` 等）。\n- **核心内核设施**：依赖 `atomic.h`, `rcupdate.h`, `cpumask_api.h`, `ktime_api.h`, `trace/events/sched.h` 等。\n- **平台与虚拟化**：条件包含 `asm/paravirt.h`（半虚拟化支持）和 `asm/barrier.h`（内存屏障）。\n- **工作队列**：包含 `../workqueue_internal.h`，用于与工作队列子系统交互。\n\n### 配置选项依赖\n- `CONFIG_64BIT`：启用高精度负载计算。\n- `CONFIG_SCHED_DEBUG`：启用 `SCHED_WARN_ON()` 调试检查。\n- `CONFIG_CPU_FREQ_GOV_SCHEDUTIL`：启用 `SCHED_FLAG_SUGOV` 相关逻辑。\n- `CONFIG_SCHED_CLASS_EXT`：扩展调度类支持（影响 `normal_policy()` 判断）。\n- `CONFIG_PARAVIRT`：半虚拟化支持。\n\n## 5. 使用场景\n\n- **调度器初始化与运行**：`scheduler_running` 和负载计算变量在调度器启动和周期性负载更新中使用。\n- **任务调度策略处理**：所有调度类（CFS、RT、Deadline、Idle）在入队、出队、选择下一个任务时，通过策略判断函数确定任务类型。\n- **负载均衡与迁移**：`asym_cap_data` 和 CPU 拓扑信息用于跨 CPU 的任务迁移决策，尤其在异构系统中。\n- **cgroup 资源控制**：在设置或读取 cgroup 的 CPU 权重时，通过权重转换函数确保调度器内部表示与用户接口一致。\n- **实时带宽管理**：`sysctl_sched_rt_*` 参数用于限制 SCHED_FIFO/SCHED_RR 任务的 CPU 使用率。\n- **能效调度协同**：`SCHED_FLAG_SUGOV` 机制使频率调节器能及时响应 Deadline 任务的性能需求。\n- **内核调试与追踪**：`SCHED_WARN_ON()` 用于捕获调度器内部异常状态；tracepoint 定义支持调度事件追踪。",
      "similarity": 0.6120638847351074,
      "chunks": []
    }
  ]
}