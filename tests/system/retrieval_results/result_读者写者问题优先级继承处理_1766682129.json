{
  "query": "读者写者问题优先级继承处理",
  "timestamp": "2025-12-26 01:02:09",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/rwbase_rt.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:50:50\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\rwbase_rt.c`\n\n---\n\n# `locking/rwbase_rt.c` 技术文档\n\n## 1. 文件概述\n\n`rwbase_rt.c` 是 Linux 内核实时（RT）补丁中用于实现 **实时读者-写者同步原语**（包括 `rw_semaphore` 和 `rwlock`）的通用底层代码。该文件为实时调度环境（如 `PREEMPT_RT`）提供了一套基于 `rtmutex` 的读写锁实现，以解决传统读写锁在实时系统中可能导致的优先级反转和不可预测延迟问题。\n\n该实现通过将写者操作与 `rtmutex` 绑定，利用 `rtmutex` 的优先级继承（PI）或截止时间（DL）调度机制，确保写者不会被低优先级读者无限阻塞，同时在多数情况下允许读者通过无锁快速路径（fast path）高效执行。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct rwbase_rt`：读写同步原语的通用底层结构，包含：\n  - `atomic_t readers`：读者计数器，使用偏置（bias）机制区分读/写状态\n  - `struct rt_mutex_base rtmutex`：底层实时互斥锁，用于串行化写者和阻塞读者\n\n### 关键常量\n- `READER_BIAS`：正偏置值（通常为 `0x7fffffff`），表示允许读者使用快速路径\n- `WRITER_BIAS`：负偏置值（通常为 `-0x80000000`），表示写者已持有锁\n\n### 主要函数\n\n| 函数 | 功能 |\n|------|------|\n| `rwbase_read_trylock()` | 尝试快速获取读锁（仅当 `READER_BIAS` 存在时） |\n| `__rwbase_read_lock()` / `rwbase_read_lock()` | 获取读锁（慢路径 + 快路径组合） |\n| `__rwbase_read_unlock()` / `rwbase_read_unlock()` | 释放读锁，必要时唤醒等待的写者 |\n| `__rwbase_write_unlock()` / `rwbase_write_unlock()` | 释放写锁，恢复 `READER_BIAS` 并释放 `rtmutex` |\n| `rwbase_write_downgrade()` | 将写锁降级为读锁 |\n| `__rwbase_write_trylock()` | 在持有 `wait_lock` 下尝试获取写锁 |\n| `rwbase_write_lock()` | 获取写锁（完整慢路径，含阻塞等待） |\n| `rwbase_write_trylock()` | 尝试非阻塞获取写锁（代码片段未完整） |\n\n## 3. 关键实现\n\n### 3.1 读者-写者状态管理\n- 使用 `atomic_t readers` 字段统一管理状态：\n  - **初始状态**：`readers = READER_BIAS`（正值），允许读者走快速路径\n  - **写者加锁时**：先获取 `rtmutex`，然后 `atomic_sub(READER_BIAS, &readers)`，使值变为负或零，强制后续读者进入慢路径\n  - **写者持有锁**：`readers = WRITER_BIAS`（最小负值）\n  - **读者持有锁**：`readers = READER_BIAS + N`（N 为活跃读者数）\n\n### 3.2 快速路径（Fast Path）\n- **读锁获取**：通过 `atomic_try_cmpxchg_acquire()` 原子递增 `readers`（仅当 `< 0` 不成立，即偏置存在）\n- **读锁释放**：`atomic_dec_and_test()`，仅当计数归零（即最后一个读者）时才需唤醒写者\n- 所有原子操作均使用 `_acquire` / `_release` 语义，确保内存顺序正确\n\n### 3.3 写者加锁流程\n1. 获取底层 `rtmutex`（可能阻塞）\n2. 清除 `READER_BIAS`，阻止新读者进入快速路径\n3. 在 `rtmutex.wait_lock` 保护下检查是否所有读者已退出（`readers == 0`）\n4. 若仍有读者，循环等待并调度，直到可安全设置 `WRITER_BIAS`\n\n### 3.4 非写者公平性\n- **明确不保证写者公平**：新到达的读者即使在写者等待时仍可获取读锁（若写者尚未清除 `READER_BIAS`）\n- 原因：实现完全公平需为每个读者代理锁定 `rtmutex` 并逐个继承优先级，这在 `SCHED_DEADLINE` 下不可行\n- 权衡：接受潜在写者饥饿风险，换取实现简洁性和典型 RT 场景下的低延迟\n\n### 3.5 与 `rtmutex` 的集成\n- 所有慢路径操作均在 `rtmutex.wait_lock`（raw spinlock）保护下进行\n- 写者通过 `rtmutex` 阻塞，天然获得 PI/DL 调度支持\n- 读者在慢路径中临时获取 `rtmutex` 以确保与写者互斥，成功后立即释放\n\n## 4. 依赖关系\n\n- **`rtmutex` 子系统**：依赖 `rt_mutex_base`、`rt_mutex_lock/unlock`、`rt_mutex_wake_q` 等接口实现阻塞/唤醒和优先级继承\n- **原子操作**：使用 `atomic_read`、`atomic_try_cmpxchg_acquire`、`atomic_add_return_release` 等提供内存序保证\n- **调度器**：调用 `rwbase_pre_schedule()` / `rwbase_post_schedule()`、`rwbase_schedule()` 与 RT 调度器交互\n- **跟踪机制**：使用 `trace_contention_begin/end` 提供锁竞争跟踪\n- **中断管理**：使用 `raw_spin_lock_irq{save/restore}` 保护关键区\n- **信号处理**：通过 `rwbase_signal_pending_state()` 支持可中断等待\n\n## 5. 使用场景\n\n- **实时任务中的读写同步**：适用于需要低延迟响应的 RT 任务访问共享数据结构\n- **`mmap_sem` 等内核锁的 RT 实现**：作为 `rw_semaphore` 的底层支持，用于内存管理等子系统\n- **避免优先级反转**：当高优先级写者需等待低优先级读者时，通过 `rtmutex` 的 PI 机制临时提升读者优先级\n- **高并发读场景**：允许多个读者无锁并发执行，仅在写者存在时才串行化\n- **不适用于强写者公平需求场景**：如需严格 FIFO 写者调度，应避免在 RT 任务中使用此类锁",
      "similarity": 0.5639933347702026,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/rwbase_rt.c",
          "start_line": 168,
          "end_line": 273,
          "content": [
            "static __always_inline void rwbase_read_unlock(struct rwbase_rt *rwb,",
            "\t\t\t\t\t       unsigned int state)",
            "{",
            "\t/*",
            "\t * rwb->readers can only hit 0 when a writer is waiting for the",
            "\t * active readers to leave the critical section.",
            "\t *",
            "\t * dec_and_test() is fully ordered, provides RELEASE.",
            "\t */",
            "\tif (unlikely(atomic_dec_and_test(&rwb->readers)))",
            "\t\t__rwbase_read_unlock(rwb, state);",
            "}",
            "static inline void __rwbase_write_unlock(struct rwbase_rt *rwb, int bias,",
            "\t\t\t\t\t unsigned long flags)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "",
            "\t/*",
            "\t * _release() is needed in case that reader is in fast path, pairing",
            "\t * with atomic_try_cmpxchg_acquire() in rwbase_read_trylock().",
            "\t */",
            "\t(void)atomic_add_return_release(READER_BIAS - bias, &rwb->readers);",
            "\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);",
            "\trwbase_rtmutex_unlock(rtm);",
            "}",
            "static inline void rwbase_write_unlock(struct rwbase_rt *rwb)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "\t__rwbase_write_unlock(rwb, WRITER_BIAS, flags);",
            "}",
            "static inline void rwbase_write_downgrade(struct rwbase_rt *rwb)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "\t/* Release it and account current as reader */",
            "\t__rwbase_write_unlock(rwb, WRITER_BIAS - 1, flags);",
            "}",
            "static inline bool __rwbase_write_trylock(struct rwbase_rt *rwb)",
            "{",
            "\t/* Can do without CAS because we're serialized by wait_lock. */",
            "\tlockdep_assert_held(&rwb->rtmutex.wait_lock);",
            "",
            "\t/*",
            "\t * _acquire is needed in case the reader is in the fast path, pairing",
            "\t * with rwbase_read_unlock(), provides ACQUIRE.",
            "\t */",
            "\tif (!atomic_read_acquire(&rwb->readers)) {",
            "\t\tatomic_set(&rwb->readers, WRITER_BIAS);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,",
            "\t\t\t\t     unsigned int state)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tunsigned long flags;",
            "",
            "\t/* Take the rtmutex as a first step */",
            "\tif (rwbase_rtmutex_lock_state(rtm, state))",
            "\t\treturn -EINTR;",
            "",
            "\t/* Force readers into slow path */",
            "\tatomic_sub(READER_BIAS, &rwb->readers);",
            "",
            "\trwbase_pre_schedule();",
            "",
            "\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "\tif (__rwbase_write_trylock(rwb))",
            "\t\tgoto out_unlock;",
            "",
            "\trwbase_set_and_save_current_state(state);",
            "\ttrace_contention_begin(rwb, LCB_F_RT | LCB_F_WRITE);",
            "\tfor (;;) {",
            "\t\t/* Optimized out for rwlocks */",
            "\t\tif (rwbase_signal_pending_state(state, current)) {",
            "\t\t\trwbase_restore_current_state();",
            "\t\t\t__rwbase_write_unlock(rwb, 0, flags);",
            "\t\t\trwbase_post_schedule();",
            "\t\t\ttrace_contention_end(rwb, -EINTR);",
            "\t\t\treturn -EINTR;",
            "\t\t}",
            "",
            "\t\tif (__rwbase_write_trylock(rwb))",
            "\t\t\tbreak;",
            "",
            "\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);",
            "\t\trwbase_schedule();",
            "\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "",
            "\t\tset_current_state(state);",
            "\t}",
            "\trwbase_restore_current_state();",
            "\ttrace_contention_end(rwb, 0);",
            "",
            "out_unlock:",
            "\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);",
            "\trwbase_post_schedule();",
            "\treturn 0;",
            "}"
          ],
          "function_name": "rwbase_read_unlock, __rwbase_write_unlock, rwbase_write_unlock, rwbase_write_downgrade, __rwbase_write_trylock, rwbase_write_lock",
          "description": "处理写锁的释放、降级与尝试获取逻辑，包含读者偏置调整、内存序保障、写锁竞争解决及状态转换的完整流程",
          "similarity": 0.595707893371582
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/rwbase_rt.c",
          "start_line": 280,
          "end_line": 297,
          "content": [
            "static inline int rwbase_write_trylock(struct rwbase_rt *rwb)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tunsigned long flags;",
            "",
            "\tif (!rwbase_rtmutex_trylock(rtm))",
            "\t\treturn 0;",
            "",
            "\tatomic_sub(READER_BIAS, &rwb->readers);",
            "",
            "\traw_spin_lock_irqsave(&rtm->wait_lock, flags);",
            "\tif (__rwbase_write_trylock(rwb)) {",
            "\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);",
            "\t\treturn 1;",
            "\t}",
            "\t__rwbase_write_unlock(rwb, 0, flags);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "rwbase_write_trylock",
          "description": "实现非阻塞式写锁尝试获取，通过先获取rtmutex再调整读者偏置，最终判断能否直接获得写锁的原子化操作流程",
          "similarity": 0.5821097493171692
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/rwbase_rt.c",
          "start_line": 1,
          "end_line": 52,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "",
            "/*",
            " * RT-specific reader/writer semaphores and reader/writer locks",
            " *",
            " * down_write/write_lock()",
            " *  1) Lock rtmutex",
            " *  2) Remove the reader BIAS to force readers into the slow path",
            " *  3) Wait until all readers have left the critical section",
            " *  4) Mark it write locked",
            " *",
            " * up_write/write_unlock()",
            " *  1) Remove the write locked marker",
            " *  2) Set the reader BIAS, so readers can use the fast path again",
            " *  3) Unlock rtmutex, to release blocked readers",
            " *",
            " * down_read/read_lock()",
            " *  1) Try fast path acquisition (reader BIAS is set)",
            " *  2) Take tmutex::wait_lock, which protects the writelocked flag",
            " *  3) If !writelocked, acquire it for read",
            " *  4) If writelocked, block on tmutex",
            " *  5) unlock rtmutex, goto 1)",
            " *",
            " * up_read/read_unlock()",
            " *  1) Try fast path release (reader count != 1)",
            " *  2) Wake the writer waiting in down_write()/write_lock() #3",
            " *",
            " * down_read/read_lock()#3 has the consequence, that rw semaphores and rw",
            " * locks on RT are not writer fair, but writers, which should be avoided in",
            " * RT tasks (think mmap_sem), are subject to the rtmutex priority/DL",
            " * inheritance mechanism.",
            " *",
            " * It's possible to make the rw primitives writer fair by keeping a list of",
            " * active readers. A blocked writer would force all newly incoming readers",
            " * to block on the rtmutex, but the rtmutex would have to be proxy locked",
            " * for one reader after the other. We can't use multi-reader inheritance",
            " * because there is no way to support that with SCHED_DEADLINE.",
            " * Implementing the one by one reader boosting/handover mechanism is a",
            " * major surgery for a very dubious value.",
            " *",
            " * The risk of writer starvation is there, but the pathological use cases",
            " * which trigger it are not necessarily the typical RT workloads.",
            " *",
            " * Fast-path orderings:",
            " * The lock/unlock of readers can run in fast paths: lock and unlock are only",
            " * atomic ops, and there is no inner lock to provide ACQUIRE and RELEASE",
            " * semantics of rwbase_rt. Atomic ops should thus provide _acquire()",
            " * and _release() (or stronger).",
            " *",
            " * Common code shared between RT rw_semaphore and rwlock",
            " */",
            ""
          ],
          "function_name": null,
          "description": "描述RT读写锁的实现机制，包括写锁强制读者进入慢路径、读锁快慢路径切换及优先级继承特性，说明其不支持公平写入但通过RT mutex机制控制并发",
          "similarity": 0.574019193649292
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/rwbase_rt.c",
          "start_line": 53,
          "end_line": 163,
          "content": [
            "static __always_inline int rwbase_read_trylock(struct rwbase_rt *rwb)",
            "{",
            "\tint r;",
            "",
            "\t/*",
            "\t * Increment reader count, if sem->readers < 0, i.e. READER_BIAS is",
            "\t * set.",
            "\t */",
            "\tfor (r = atomic_read(&rwb->readers); r < 0;) {",
            "\t\tif (likely(atomic_try_cmpxchg_acquire(&rwb->readers, &r, r + 1)))",
            "\t\t\treturn 1;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int __sched __rwbase_read_lock(struct rwbase_rt *rwb,",
            "\t\t\t\t      unsigned int state)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tint ret;",
            "",
            "\trwbase_pre_schedule();",
            "\traw_spin_lock_irq(&rtm->wait_lock);",
            "",
            "\t/*",
            "\t * Call into the slow lock path with the rtmutex->wait_lock",
            "\t * held, so this can't result in the following race:",
            "\t *",
            "\t * Reader1\t\tReader2\t\tWriter",
            "\t *\t\t\tdown_read()",
            "\t *\t\t\t\t\tdown_write()",
            "\t *\t\t\t\t\trtmutex_lock(m)",
            "\t *\t\t\t\t\twait()",
            "\t * down_read()",
            "\t * unlock(m->wait_lock)",
            "\t *\t\t\tup_read()",
            "\t *\t\t\twake(Writer)",
            "\t *\t\t\t\t\tlock(m->wait_lock)",
            "\t *\t\t\t\t\tsem->writelocked=true",
            "\t *\t\t\t\t\tunlock(m->wait_lock)",
            "\t *",
            "\t *\t\t\t\t\tup_write()",
            "\t *\t\t\t\t\tsem->writelocked=false",
            "\t *\t\t\t\t\trtmutex_unlock(m)",
            "\t *\t\t\tdown_read()",
            "\t *\t\t\t\t\tdown_write()",
            "\t *\t\t\t\t\trtmutex_lock(m)",
            "\t *\t\t\t\t\twait()",
            "\t * rtmutex_lock(m)",
            "\t *",
            "\t * That would put Reader1 behind the writer waiting on",
            "\t * Reader2 to call up_read(), which might be unbound.",
            "\t */",
            "",
            "\ttrace_contention_begin(rwb, LCB_F_RT | LCB_F_READ);",
            "",
            "\t/*",
            "\t * For rwlocks this returns 0 unconditionally, so the below",
            "\t * !ret conditionals are optimized out.",
            "\t */",
            "\tret = rwbase_rtmutex_slowlock_locked(rtm, state);",
            "",
            "\t/*",
            "\t * On success the rtmutex is held, so there can't be a writer",
            "\t * active. Increment the reader count and immediately drop the",
            "\t * rtmutex again.",
            "\t *",
            "\t * rtmutex->wait_lock has to be unlocked in any case of course.",
            "\t */",
            "\tif (!ret)",
            "\t\tatomic_inc(&rwb->readers);",
            "\traw_spin_unlock_irq(&rtm->wait_lock);",
            "\tif (!ret)",
            "\t\trwbase_rtmutex_unlock(rtm);",
            "",
            "\ttrace_contention_end(rwb, ret);",
            "\trwbase_post_schedule();",
            "\treturn ret;",
            "}",
            "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,",
            "\t\t\t\t\t    unsigned int state)",
            "{",
            "\tlockdep_assert(!current->pi_blocked_on);",
            "",
            "\tif (rwbase_read_trylock(rwb))",
            "\t\treturn 0;",
            "",
            "\treturn __rwbase_read_lock(rwb, state);",
            "}",
            "static void __sched __rwbase_read_unlock(struct rwbase_rt *rwb,",
            "\t\t\t\t\t unsigned int state)",
            "{",
            "\tstruct rt_mutex_base *rtm = &rwb->rtmutex;",
            "\tstruct task_struct *owner;",
            "\tDEFINE_RT_WAKE_Q(wqh);",
            "",
            "\traw_spin_lock_irq(&rtm->wait_lock);",
            "\t/*",
            "\t * Wake the writer, i.e. the rtmutex owner. It might release the",
            "\t * rtmutex concurrently in the fast path (due to a signal), but to",
            "\t * clean up rwb->readers it needs to acquire rtm->wait_lock. The",
            "\t * worst case which can happen is a spurious wakeup.",
            "\t */",
            "\towner = rt_mutex_owner(rtm);",
            "\tif (owner)",
            "\t\trt_mutex_wake_q_add_task(&wqh, owner, state);",
            "",
            "\t/* Pairs with the preempt_enable in rt_mutex_wake_up_q() */",
            "\tpreempt_disable();",
            "\traw_spin_unlock_irq(&rtm->wait_lock);",
            "\trt_mutex_wake_up_q(&wqh);",
            "}"
          ],
          "function_name": "rwbase_read_trylock, __rwbase_read_lock, rwbase_read_lock, __rwbase_read_unlock",
          "description": "实现读锁的尝试获取与锁定逻辑，包含原子操作更新读者计数、持有rtmutex_wait_lock保护临界区、唤醒等待写者的解锁逻辑",
          "similarity": 0.544908881187439
        }
      ]
    },
    {
      "source_file": "kernel/locking/rwsem.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:51:36\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\rwsem.c`\n\n---\n\n# `locking/rwsem.c` 技术文档\n\n## 1. 文件概述\n\n`locking/rwsem.c` 是 Linux 内核中读写信号量（Read-Write Semaphore, rwsem）的核心实现文件，提供了对共享资源进行并发访问控制的机制。该机制允许多个读者并发访问资源，但写者必须独占访问。文件实现了 rwsem 的底层原子操作、锁获取/释放逻辑、乐观自旋（optimistic spinning）、写者锁抢占（lock-stealing）以及调试支持等功能，适用于高并发场景下的同步需求。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct rw_semaphore`：读写信号量的核心结构体，包含：\n  - `count`：原子长整型，编码了写者锁状态、等待者标志、移交标志、读者计数等信息。\n  - `owner`：记录当前锁持有者（写者任务指针或带标志的读者信息）。\n  - `wait_list`：等待队列，用于管理阻塞的读者和写者。\n  - `wait_lock`：保护等待队列的自旋锁。\n\n### 关键宏定义\n- **Owner 字段标志位**：\n  - `RWSEM_READER_OWNED`（bit 0）：表示当前由读者持有。\n  - `RWSEM_NONSPINNABLE`（bit 1）：禁止乐观自旋。\n- **Count 字段位布局**（64 位架构）：\n  - bit 0：`RWSEM_WRITER_LOCKED`（写者已加锁）\n  - bit 1：`RWSEM_FLAG_WAITERS`（存在等待者）\n  - bit 2：`RWSEM_FLAG_HANDOFF`（锁移交标志）\n  - bits 8–62：55 位读者计数\n  - bit 63：`RWSEM_FLAG_READFAIL`（读取失败标志，用于未来扩展）\n\n### 核心内联函数\n- `rwsem_set_owner()` / `rwsem_clear_owner()`：设置/清除写者所有者。\n- `rwsem_set_reader_owned()` / `rwsem_clear_reader_owned()`：标记/清除读者所有者（带调试支持）。\n- `is_rwsem_reader_owned()`：判断是否由读者持有。\n- `rwsem_set_nonspinnable()`：在读者持有时设置不可自旋标志。\n- `rwsem_test_oflags()`：测试 owner 字段中的标志位。\n\n## 3. 关键实现\n\n### 位域编码设计\n`count` 字段采用紧凑的位域编码，将写者锁状态、等待者存在标志、锁移交标志和读者计数集成在一个 `atomic_long_t` 中。这种设计使得 fast-path（快速路径）操作（如读者加锁）可通过单一原子加法完成，极大提升性能。\n\n### 乐观自旋（Optimistic Spinning）\n当写者尝试获取锁失败时，若满足条件（如锁由写者刚释放、无移交请求），会进入乐观自旋状态，避免立即进入睡眠。若自旋超时且锁仍为读者持有，则设置 `RWSEM_NONSPINNABLE` 标志，禁止后续写者自旋，防止 CPU 资源浪费。\n\n### 写者锁抢占（Writer Lock-Stealing）\n在特定条件下（如锁刚由写者释放、无等待者、无移交标志），新来的写者可直接抢占锁，无需排队，减少延迟。\n\n### 所有者追踪机制\n- **写者**：`owner` 字段直接存储 `task_struct*` 指针。\n- **读者**：`owner` 字段存储当前读者任务指针并置 `RWSEM_READER_OWNED` 位。由于性能考虑，仅记录**最后一个获取锁的读者**，而非所有读者。\n- 调试模式（`CONFIG_DEBUG_RWSEMS`）下，`rwsem_clear_reader_owned()` 确保只有真正的持有者才能清除其所有者记录。\n\n### 原子操作策略\n- **读者加锁**：使用 `atomic_long_fetch_add()` 原子增加读者计数。\n- **写者加锁**：使用 `atomic_long_cmpxchg()` 进行条件交换，确保互斥。\n\n### 锁移交（Handoff）机制\n当写者被唤醒时，若其位于等待队列头部，可设置 `RWSEM_FLAG_HANDOFF` 标志，确保该写者优先获得锁，避免“写者饥饿”。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/rwsem.h>`：定义 `rw_semaphore` 结构和公共 API。\n  - `<linux/atomic.h>`：提供原子操作原语。\n  - `<linux/sched/*.h>`：任务调度、唤醒队列、实时调度支持。\n  - `<trace/events/lock.h>`：锁事件追踪。\n- **配置依赖**：\n  - `CONFIG_PREEMPT_RT`：若启用，部分实现（如乐观自旋）被禁用。\n  - `CONFIG_DEBUG_RWSEMS`：启用所有者一致性检查和警告。\n- **内部依赖**：\n  - `lock_events.h`：统计锁事件（仅在非 `PREEMPT_RT` 下）。\n  - 内核调度器：用于任务阻塞/唤醒。\n\n## 5. 使用场景\n\n- **文件系统**：如 ext4、XFS 使用 rwsem 保护 inode 或目录结构，允许多读者并发访问元数据。\n- **内存管理**：`mm_struct` 的 `mmap_lock` 采用 rwsem，支持并发读（如页表遍历）与独占写（如内存映射修改）。\n- **模块加载**：内核模块的引用计数和符号表访问通过 rwsem 同步。\n- **RCU 替代场景**：在需要严格写者优先或不能使用 RCU 的上下文中，rwsem 提供强一致性保证。\n- **调试与死锁检测**：结合 `lockdep` 和 `DEBUG_RWSEMS`，用于检测读者/写者死锁或非法嵌套。",
      "similarity": 0.5304346084594727,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/rwsem.c",
          "start_line": 369,
          "end_line": 544,
          "content": [
            "static inline void",
            "rwsem_add_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)",
            "{",
            "\tlockdep_assert_held(&sem->wait_lock);",
            "\tlist_add_tail(&waiter->list, &sem->wait_list);",
            "\t/* caller will set RWSEM_FLAG_WAITERS */",
            "}",
            "static inline bool",
            "rwsem_del_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)",
            "{",
            "\tlockdep_assert_held(&sem->wait_lock);",
            "\tlist_del(&waiter->list);",
            "\tif (likely(!list_empty(&sem->wait_list)))",
            "\t\treturn true;",
            "",
            "\tatomic_long_andnot(RWSEM_FLAG_HANDOFF | RWSEM_FLAG_WAITERS, &sem->count);",
            "\treturn false;",
            "}",
            "static void rwsem_mark_wake(struct rw_semaphore *sem,",
            "\t\t\t    enum rwsem_wake_type wake_type,",
            "\t\t\t    struct wake_q_head *wake_q)",
            "{",
            "\tstruct rwsem_waiter *waiter, *tmp;",
            "\tlong oldcount, woken = 0, adjustment = 0;",
            "\tstruct list_head wlist;",
            "",
            "\tlockdep_assert_held(&sem->wait_lock);",
            "",
            "\t/*",
            "\t * Take a peek at the queue head waiter such that we can determine",
            "\t * the wakeup(s) to perform.",
            "\t */",
            "\twaiter = rwsem_first_waiter(sem);",
            "",
            "\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {",
            "\t\tif (wake_type == RWSEM_WAKE_ANY) {",
            "\t\t\t/*",
            "\t\t\t * Mark writer at the front of the queue for wakeup.",
            "\t\t\t * Until the task is actually later awoken later by",
            "\t\t\t * the caller, other writers are able to steal it.",
            "\t\t\t * Readers, on the other hand, will block as they",
            "\t\t\t * will notice the queued writer.",
            "\t\t\t */",
            "\t\t\twake_q_add(wake_q, waiter->task);",
            "\t\t\tlockevent_inc(rwsem_wake_writer);",
            "\t\t}",
            "",
            "\t\treturn;",
            "\t}",
            "",
            "\t/*",
            "\t * No reader wakeup if there are too many of them already.",
            "\t */",
            "\tif (unlikely(atomic_long_read(&sem->count) < 0))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Writers might steal the lock before we grant it to the next reader.",
            "\t * We prefer to do the first reader grant before counting readers",
            "\t * so we can bail out early if a writer stole the lock.",
            "\t */",
            "\tif (wake_type != RWSEM_WAKE_READ_OWNED) {",
            "\t\tstruct task_struct *owner;",
            "",
            "\t\tadjustment = RWSEM_READER_BIAS;",
            "\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);",
            "\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {",
            "\t\t\t/*",
            "\t\t\t * When we've been waiting \"too\" long (for writers",
            "\t\t\t * to give up the lock), request a HANDOFF to",
            "\t\t\t * force the issue.",
            "\t\t\t */",
            "\t\t\tif (time_after(jiffies, waiter->timeout)) {",
            "\t\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF)) {",
            "\t\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;",
            "\t\t\t\t\tlockevent_inc(rwsem_rlock_handoff);",
            "\t\t\t\t}",
            "\t\t\t\twaiter->handoff_set = true;",
            "\t\t\t}",
            "",
            "\t\t\tatomic_long_add(-adjustment, &sem->count);",
            "\t\t\treturn;",
            "\t\t}",
            "\t\t/*",
            "\t\t * Set it to reader-owned to give spinners an early",
            "\t\t * indication that readers now have the lock.",
            "\t\t * The reader nonspinnable bit seen at slowpath entry of",
            "\t\t * the reader is copied over.",
            "\t\t */",
            "\t\towner = waiter->task;",
            "\t\t__rwsem_set_reader_owned(sem, owner);",
            "\t}",
            "",
            "\t/*",
            "\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the",
            "\t * queue. We know that the woken will be at least 1 as we accounted",
            "\t * for above. Note we increment the 'active part' of the count by the",
            "\t * number of readers before waking any processes up.",
            "\t *",
            "\t * This is an adaptation of the phase-fair R/W locks where at the",
            "\t * reader phase (first waiter is a reader), all readers are eligible",
            "\t * to acquire the lock at the same time irrespective of their order",
            "\t * in the queue. The writers acquire the lock according to their",
            "\t * order in the queue.",
            "\t *",
            "\t * We have to do wakeup in 2 passes to prevent the possibility that",
            "\t * the reader count may be decremented before it is incremented. It",
            "\t * is because the to-be-woken waiter may not have slept yet. So it",
            "\t * may see waiter->task got cleared, finish its critical section and",
            "\t * do an unlock before the reader count increment.",
            "\t *",
            "\t * 1) Collect the read-waiters in a separate list, count them and",
            "\t *    fully increment the reader count in rwsem.",
            "\t * 2) For each waiters in the new list, clear waiter->task and",
            "\t *    put them into wake_q to be woken up later.",
            "\t */",
            "\tINIT_LIST_HEAD(&wlist);",
            "\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {",
            "\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)",
            "\t\t\tcontinue;",
            "",
            "\t\twoken++;",
            "\t\tlist_move_tail(&waiter->list, &wlist);",
            "",
            "\t\t/*",
            "\t\t * Limit # of readers that can be woken up per wakeup call.",
            "\t\t */",
            "\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))",
            "\t\t\tbreak;",
            "\t}",
            "",
            "\tadjustment = woken * RWSEM_READER_BIAS - adjustment;",
            "\tlockevent_cond_inc(rwsem_wake_reader, woken);",
            "",
            "\toldcount = atomic_long_read(&sem->count);",
            "\tif (list_empty(&sem->wait_list)) {",
            "\t\t/*",
            "\t\t * Combined with list_move_tail() above, this implies",
            "\t\t * rwsem_del_waiter().",
            "\t\t */",
            "\t\tadjustment -= RWSEM_FLAG_WAITERS;",
            "\t\tif (oldcount & RWSEM_FLAG_HANDOFF)",
            "\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;",
            "\t} else if (woken) {",
            "\t\t/*",
            "\t\t * When we've woken a reader, we no longer need to force",
            "\t\t * writers to give up the lock and we can clear HANDOFF.",
            "\t\t */",
            "\t\tif (oldcount & RWSEM_FLAG_HANDOFF)",
            "\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;",
            "\t}",
            "",
            "\tif (adjustment)",
            "\t\tatomic_long_add(adjustment, &sem->count);",
            "",
            "\t/* 2nd pass */",
            "\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {",
            "\t\tstruct task_struct *tsk;",
            "",
            "\t\ttsk = waiter->task;",
            "\t\tget_task_struct(tsk);",
            "",
            "\t\t/*",
            "\t\t * Ensure calling get_task_struct() before setting the reader",
            "\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot",
            "\t\t * race with do_exit() by always holding a reference count",
            "\t\t * to the task to wakeup.",
            "\t\t */",
            "\t\tsmp_store_release(&waiter->task, NULL);",
            "\t\t/*",
            "\t\t * Ensure issuing the wakeup (either by us or someone else)",
            "\t\t * after setting the reader waiter to nil.",
            "\t\t */",
            "\t\twake_q_add_safe(wake_q, tsk);",
            "\t}",
            "}"
          ],
          "function_name": "rwsem_add_waiter, rwsem_del_waiter, rwsem_mark_wake",
          "description": "实现等待队列的维护逻辑，支持唤醒等待线程并处理读写锁的优先级唤醒策略",
          "similarity": 0.5832369923591614
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/rwsem.c",
          "start_line": 576,
          "end_line": 698,
          "content": [
            "static inline void",
            "rwsem_del_wake_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter,",
            "\t\t      struct wake_q_head *wake_q)",
            "\t\t      __releases(&sem->wait_lock)",
            "{",
            "\tbool first = rwsem_first_waiter(sem) == waiter;",
            "",
            "\twake_q_init(wake_q);",
            "",
            "\t/*",
            "\t * If the wait_list isn't empty and the waiter to be deleted is",
            "\t * the first waiter, we wake up the remaining waiters as they may",
            "\t * be eligible to acquire or spin on the lock.",
            "\t */",
            "\tif (rwsem_del_waiter(sem, waiter) && first)",
            "\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, wake_q);",
            "\traw_spin_unlock_irq(&sem->wait_lock);",
            "\tif (!wake_q_empty(wake_q))",
            "\t\twake_up_q(wake_q);",
            "}",
            "static inline bool rwsem_try_write_lock(struct rw_semaphore *sem,",
            "\t\t\t\t\tstruct rwsem_waiter *waiter)",
            "{",
            "\tstruct rwsem_waiter *first = rwsem_first_waiter(sem);",
            "\tlong count, new;",
            "",
            "\tlockdep_assert_held(&sem->wait_lock);",
            "",
            "\tcount = atomic_long_read(&sem->count);",
            "\tdo {",
            "\t\tbool has_handoff = !!(count & RWSEM_FLAG_HANDOFF);",
            "",
            "\t\tif (has_handoff) {",
            "\t\t\t/*",
            "\t\t\t * Honor handoff bit and yield only when the first",
            "\t\t\t * waiter is the one that set it. Otherwisee, we",
            "\t\t\t * still try to acquire the rwsem.",
            "\t\t\t */",
            "\t\t\tif (first->handoff_set && (waiter != first))",
            "\t\t\t\treturn false;",
            "\t\t}",
            "",
            "\t\tnew = count;",
            "",
            "\t\tif (count & RWSEM_LOCK_MASK) {",
            "\t\t\t/*",
            "\t\t\t * A waiter (first or not) can set the handoff bit",
            "\t\t\t * if it is an RT task or wait in the wait queue",
            "\t\t\t * for too long.",
            "\t\t\t */",
            "\t\t\tif (has_handoff || (!rt_or_dl_task(waiter->task) &&",
            "\t\t\t\t\t    !time_after(jiffies, waiter->timeout)))",
            "\t\t\t\treturn false;",
            "",
            "\t\t\tnew |= RWSEM_FLAG_HANDOFF;",
            "\t\t} else {",
            "\t\t\tnew |= RWSEM_WRITER_LOCKED;",
            "\t\t\tnew &= ~RWSEM_FLAG_HANDOFF;",
            "",
            "\t\t\tif (list_is_singular(&sem->wait_list))",
            "\t\t\t\tnew &= ~RWSEM_FLAG_WAITERS;",
            "\t\t}",
            "\t} while (!atomic_long_try_cmpxchg_acquire(&sem->count, &count, new));",
            "",
            "\t/*",
            "\t * We have either acquired the lock with handoff bit cleared or set",
            "\t * the handoff bit. Only the first waiter can have its handoff_set",
            "\t * set here to enable optimistic spinning in slowpath loop.",
            "\t */",
            "\tif (new & RWSEM_FLAG_HANDOFF) {",
            "\t\tfirst->handoff_set = true;",
            "\t\tlockevent_inc(rwsem_wlock_handoff);",
            "\t\treturn false;",
            "\t}",
            "",
            "\t/*",
            "\t * Have rwsem_try_write_lock() fully imply rwsem_del_waiter() on",
            "\t * success.",
            "\t */",
            "\tlist_del(&waiter->list);",
            "\trwsem_set_owner(sem);",
            "\treturn true;",
            "}",
            "static inline bool rwsem_try_write_lock_unqueued(struct rw_semaphore *sem)",
            "{",
            "\tlong count = atomic_long_read(&sem->count);",
            "",
            "\twhile (!(count & (RWSEM_LOCK_MASK|RWSEM_FLAG_HANDOFF))) {",
            "\t\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &count,",
            "\t\t\t\t\tcount | RWSEM_WRITER_LOCKED)) {",
            "\t\t\trwsem_set_owner(sem);",
            "\t\t\tlockevent_inc(rwsem_opt_lock);",
            "\t\t\treturn true;",
            "\t\t}",
            "\t}",
            "\treturn false;",
            "}",
            "static inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)",
            "{",
            "\tstruct task_struct *owner;",
            "\tunsigned long flags;",
            "\tbool ret = true;",
            "",
            "\tif (need_resched()) {",
            "\t\tlockevent_inc(rwsem_opt_fail);",
            "\t\treturn false;",
            "\t}",
            "",
            "\t/*",
            "\t * Disable preemption is equal to the RCU read-side crital section,",
            "\t * thus the task_strcut structure won't go away.",
            "\t */",
            "\towner = rwsem_owner_flags(sem, &flags);",
            "\t/*",
            "\t * Don't check the read-owner as the entry may be stale.",
            "\t */",
            "\tif ((flags & RWSEM_NONSPINNABLE) ||",
            "\t    (owner && !(flags & RWSEM_READER_OWNED) && !owner_on_cpu(owner)))",
            "\t\tret = false;",
            "",
            "\tlockevent_cond_inc(rwsem_opt_fail, !ret);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "rwsem_del_wake_waiter, rwsem_try_write_lock, rwsem_try_write_lock_unqueued, rwsem_can_spin_on_owner",
          "description": "处理写锁的尝试获取逻辑，包含手柄标志判定、等待队列操作及自旋兼容性检查",
          "similarity": 0.5411543846130371
        },
        {
          "chunk_id": 8,
          "file_path": "kernel/locking/rwsem.c",
          "start_line": 1639,
          "end_line": 1703,
          "content": [
            "void downgrade_write(struct rw_semaphore *sem)",
            "{",
            "\tlock_downgrade(&sem->dep_map, _RET_IP_);",
            "\t__downgrade_write(sem);",
            "}",
            "void down_read_nested(struct rw_semaphore *sem, int subclass)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire_read(&sem->dep_map, subclass, 0, _RET_IP_);",
            "\tLOCK_CONTENDED(sem, __down_read_trylock, __down_read);",
            "}",
            "int down_read_killable_nested(struct rw_semaphore *sem, int subclass)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire_read(&sem->dep_map, subclass, 0, _RET_IP_);",
            "",
            "\tif (LOCK_CONTENDED_RETURN(sem, __down_read_trylock, __down_read_killable)) {",
            "\t\trwsem_release(&sem->dep_map, _RET_IP_);",
            "\t\treturn -EINTR;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void _down_write_nest_lock(struct rw_semaphore *sem, struct lockdep_map *nest)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire_nest(&sem->dep_map, 0, 0, nest, _RET_IP_);",
            "\tLOCK_CONTENDED(sem, __down_write_trylock, __down_write);",
            "}",
            "void down_read_non_owner(struct rw_semaphore *sem)",
            "{",
            "\tmight_sleep();",
            "\t__down_read(sem);",
            "\t/*",
            "\t * The owner value for a reader-owned lock is mostly for debugging",
            "\t * purpose only and is not critical to the correct functioning of",
            "\t * rwsem. So it is perfectly fine to set it in a preempt-enabled",
            "\t * context here.",
            "\t */",
            "\t__rwsem_set_reader_owned(sem, NULL);",
            "}",
            "void down_write_nested(struct rw_semaphore *sem, int subclass)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire(&sem->dep_map, subclass, 0, _RET_IP_);",
            "\tLOCK_CONTENDED(sem, __down_write_trylock, __down_write);",
            "}",
            "int __sched down_write_killable_nested(struct rw_semaphore *sem, int subclass)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire(&sem->dep_map, subclass, 0, _RET_IP_);",
            "",
            "\tif (LOCK_CONTENDED_RETURN(sem, __down_write_trylock,",
            "\t\t\t\t  __down_write_killable)) {",
            "\t\trwsem_release(&sem->dep_map, _RET_IP_);",
            "\t\treturn -EINTR;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "void up_read_non_owner(struct rw_semaphore *sem)",
            "{",
            "\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);",
            "\t__up_read(sem);",
            "}"
          ],
          "function_name": "downgrade_write, down_read_nested, down_read_killable_nested, _down_write_nest_lock, down_read_non_owner, down_write_nested, down_write_killable_nested, up_read_non_owner",
          "description": "实现锁的降级操作与嵌套锁管理功能，downgrade_write将写锁转换为读锁并调整计数器，nested版本接口支持锁子类嵌套，down_read_non_owner/up_read_non_owner处理非所有者场景的读操作，通过__rwsem_set_reader_owned设置调试用的所有者标识。",
          "similarity": 0.5059186220169067
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/rwsem.c",
          "start_line": 140,
          "end_line": 249,
          "content": [
            "static inline void rwsem_set_owner(struct rw_semaphore *sem)",
            "{",
            "\tlockdep_assert_preemption_disabled();",
            "\tatomic_long_set(&sem->owner, (long)current);",
            "}",
            "static inline void rwsem_clear_owner(struct rw_semaphore *sem)",
            "{",
            "\tlockdep_assert_preemption_disabled();",
            "\tatomic_long_set(&sem->owner, 0);",
            "}",
            "static inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)",
            "{",
            "\treturn atomic_long_read(&sem->owner) & flags;",
            "}",
            "static inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,",
            "\t\t\t\t\t    struct task_struct *owner)",
            "{",
            "\tunsigned long val = (unsigned long)owner | RWSEM_READER_OWNED |",
            "\t\t(atomic_long_read(&sem->owner) & RWSEM_NONSPINNABLE);",
            "",
            "\tatomic_long_set(&sem->owner, val);",
            "}",
            "static inline void rwsem_set_reader_owned(struct rw_semaphore *sem)",
            "{",
            "\t__rwsem_set_reader_owned(sem, current);",
            "}",
            "static inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)",
            "{",
            "#ifdef CONFIG_DEBUG_RWSEMS",
            "\t/*",
            "\t * Check the count to see if it is write-locked.",
            "\t */",
            "\tlong count = atomic_long_read(&sem->count);",
            "",
            "\tif (count & RWSEM_WRITER_MASK)",
            "\t\treturn false;",
            "#endif",
            "\treturn rwsem_test_oflags(sem, RWSEM_READER_OWNED);",
            "}",
            "static inline void rwsem_clear_reader_owned(struct rw_semaphore *sem)",
            "{",
            "\tunsigned long val = atomic_long_read(&sem->owner);",
            "",
            "\twhile ((val & ~RWSEM_OWNER_FLAGS_MASK) == (unsigned long)current) {",
            "\t\tif (atomic_long_try_cmpxchg(&sem->owner, &val,",
            "\t\t\t\t\t    val & RWSEM_OWNER_FLAGS_MASK))",
            "\t\t\treturn;",
            "\t}",
            "}",
            "static inline void rwsem_clear_reader_owned(struct rw_semaphore *sem)",
            "{",
            "}",
            "static inline void rwsem_set_nonspinnable(struct rw_semaphore *sem)",
            "{",
            "\tunsigned long owner = atomic_long_read(&sem->owner);",
            "",
            "\tdo {",
            "\t\tif (!(owner & RWSEM_READER_OWNED))",
            "\t\t\tbreak;",
            "\t\tif (owner & RWSEM_NONSPINNABLE)",
            "\t\t\tbreak;",
            "\t} while (!atomic_long_try_cmpxchg(&sem->owner, &owner,",
            "\t\t\t\t\t  owner | RWSEM_NONSPINNABLE));",
            "}",
            "static inline bool rwsem_read_trylock(struct rw_semaphore *sem, long *cntp)",
            "{",
            "\t*cntp = atomic_long_add_return_acquire(RWSEM_READER_BIAS, &sem->count);",
            "",
            "\tif (WARN_ON_ONCE(*cntp < 0))",
            "\t\trwsem_set_nonspinnable(sem);",
            "",
            "\tif (!(*cntp & RWSEM_READ_FAILED_MASK)) {",
            "\t\trwsem_set_reader_owned(sem);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static inline bool rwsem_write_trylock(struct rw_semaphore *sem)",
            "{",
            "\tlong tmp = RWSEM_UNLOCKED_VALUE;",
            "",
            "\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &tmp, RWSEM_WRITER_LOCKED)) {",
            "\t\trwsem_set_owner(sem);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "void __init_rwsem(struct rw_semaphore *sem, const char *name,",
            "\t\t  struct lock_class_key *key)",
            "{",
            "#ifdef CONFIG_DEBUG_LOCK_ALLOC",
            "\t/*",
            "\t * Make sure we are not reinitializing a held semaphore:",
            "\t */",
            "\tdebug_check_no_locks_freed((void *)sem, sizeof(*sem));",
            "\tlockdep_init_map_wait(&sem->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "#endif",
            "#ifdef CONFIG_DEBUG_RWSEMS",
            "\tsem->magic = sem;",
            "#endif",
            "\tatomic_long_set(&sem->count, RWSEM_UNLOCKED_VALUE);",
            "\traw_spin_lock_init(&sem->wait_lock);",
            "\tINIT_LIST_HEAD(&sem->wait_list);",
            "\tatomic_long_set(&sem->owner, 0L);",
            "#ifdef CONFIG_RWSEM_SPIN_ON_OWNER",
            "\tosq_lock_init(&sem->osq);",
            "#endif",
            "}"
          ],
          "function_name": "rwsem_set_owner, rwsem_clear_owner, rwsem_test_oflags, __rwsem_set_reader_owned, rwsem_set_reader_owned, is_rwsem_reader_owned, rwsem_clear_reader_owned, rwsem_clear_reader_owned, rwsem_set_nonspinnable, rwsem_read_trylock, rwsem_write_trylock, __init_rwsem",
          "description": "提供读写信号量的核心操作函数，包括设置/清除所有者、尝试加锁、初始化信号量结构体及其状态管理",
          "similarity": 0.4936327040195465
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/locking/rwsem.c",
          "start_line": 1483,
          "end_line": 1585,
          "content": [
            "static inline int __sched __down_write_killable(struct rw_semaphore *sem)",
            "{",
            "\treturn rwbase_write_lock(&sem->rwbase, TASK_KILLABLE);",
            "}",
            "static inline int __down_write_trylock(struct rw_semaphore *sem)",
            "{",
            "\treturn rwbase_write_trylock(&sem->rwbase);",
            "}",
            "static inline void __up_write(struct rw_semaphore *sem)",
            "{",
            "\trwbase_write_unlock(&sem->rwbase);",
            "}",
            "static inline void __downgrade_write(struct rw_semaphore *sem)",
            "{",
            "\trwbase_write_downgrade(&sem->rwbase);",
            "}",
            "static inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,",
            "\t\t\t\t\t    struct task_struct *owner)",
            "{",
            "}",
            "static inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)",
            "{",
            "\tint count = atomic_read(&sem->rwbase.readers);",
            "",
            "\treturn count < 0 && count != READER_BIAS;",
            "}",
            "void __sched down_read(struct rw_semaphore *sem)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);",
            "",
            "\tLOCK_CONTENDED(sem, __down_read_trylock, __down_read);",
            "}",
            "int __sched down_read_interruptible(struct rw_semaphore *sem)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);",
            "",
            "\tif (LOCK_CONTENDED_RETURN(sem, __down_read_trylock, __down_read_interruptible)) {",
            "\t\trwsem_release(&sem->dep_map, _RET_IP_);",
            "\t\treturn -EINTR;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int __sched down_read_killable(struct rw_semaphore *sem)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);",
            "",
            "\tif (LOCK_CONTENDED_RETURN(sem, __down_read_trylock, __down_read_killable)) {",
            "\t\trwsem_release(&sem->dep_map, _RET_IP_);",
            "\t\treturn -EINTR;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int down_read_trylock(struct rw_semaphore *sem)",
            "{",
            "\tint ret = __down_read_trylock(sem);",
            "",
            "\tif (ret == 1)",
            "\t\trwsem_acquire_read(&sem->dep_map, 0, 1, _RET_IP_);",
            "\treturn ret;",
            "}",
            "void __sched down_write(struct rw_semaphore *sem)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);",
            "\tLOCK_CONTENDED(sem, __down_write_trylock, __down_write);",
            "}",
            "int __sched down_write_killable(struct rw_semaphore *sem)",
            "{",
            "\tmight_sleep();",
            "\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);",
            "",
            "\tif (LOCK_CONTENDED_RETURN(sem, __down_write_trylock,",
            "\t\t\t\t  __down_write_killable)) {",
            "\t\trwsem_release(&sem->dep_map, _RET_IP_);",
            "\t\treturn -EINTR;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "int down_write_trylock(struct rw_semaphore *sem)",
            "{",
            "\tint ret = __down_write_trylock(sem);",
            "",
            "\tif (ret == 1)",
            "\t\trwsem_acquire(&sem->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn ret;",
            "}",
            "void up_read(struct rw_semaphore *sem)",
            "{",
            "\trwsem_release(&sem->dep_map, _RET_IP_);",
            "\t__up_read(sem);",
            "}",
            "void up_write(struct rw_semaphore *sem)",
            "{",
            "\trwsem_release(&sem->dep_map, _RET_IP_);",
            "\t__up_write(sem);",
            "}"
          ],
          "function_name": "__down_write_killable, __down_write_trylock, __up_write, __downgrade_write, __rwsem_set_reader_owned, is_rwsem_reader_owned, down_read, down_read_interruptible, down_read_killable, down_read_trylock, down_write, down_write_killable, down_write_trylock, up_read, up_write",
          "description": "提供标准的读写信号量API接口，包含down_read/down_write等公共函数，通过LOCK_CONTENDED宏协调自旋尝试与阻塞等待，整合锁的获取/释放追踪机制（如rwsem_acquire/read_unlock），并处理中断可睡眠的锁获取场景。",
          "similarity": 0.49294281005859375
        }
      ]
    },
    {
      "source_file": "kernel/futex/pi.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:33:45\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `futex\\pi.c`\n\n---\n\n# futex/pi.c 技术文档\n\n## 1. 文件概述\n\n`futex/pi.c` 是 Linux 内核中实现 **Priority Inheritance (PI) futex**（优先级继承 futex）机制的核心文件。该文件负责管理与 PI futex 相关的 `pi_state` 对象的生命周期、引用计数、所有者更新以及与用户空间状态的一致性校验。PI futex 允许在使用互斥锁（mutex）时，通过优先级继承避免优先级反转问题，确保高优先级任务不会因低优先级任务持有锁而被无限期阻塞。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct futex_pi_state`：表示一个 PI futex 的状态对象，包含：\n  - `pi_mutex`：关联的实时互斥锁（`rt_mutex`）\n  - `owner`：当前锁的所有者任务（`task_struct *`）\n  - `list`：挂载到任务 `pi_state_list` 的链表节点\n  - `refcount`：引用计数\n  - `key`：futex 键，用于标识用户空间地址\n\n### 主要函数\n- `refill_pi_state_cache(void)`：为当前任务预分配一个 `pi_state` 缓存对象\n- `alloc_pi_state(void)`：从当前任务的缓存中取出一个 `pi_state` 对象\n- `pi_state_update_owner(struct futex_pi_state *, struct task_struct *)`：更新 `pi_state` 的所有者，并维护任务的 `pi_state_list`\n- `get_pi_state(struct futex_pi_state *)`：增加 `pi_state` 的引用计数\n- `put_pi_state(struct futex_pi_state *)`：减少引用计数，若为 0 则释放或缓存对象\n- `attach_to_pi_state(u32 __user *, u32, struct futex_pi_state *, struct futex_pi_state **)`：验证并附加到现有的 `pi_state`，确保用户空间值与内核状态一致\n\n## 3. 关键实现\n\n### pi_state 缓存机制\n- 每个任务（`task_struct`）维护一个 `pi_state_cache`，用于缓存一个预分配的 `pi_state` 对象。\n- `refill_pi_state_cache()` 在首次需要时分配对象，避免在关键路径上进行内存分配。\n- `put_pi_state()` 在引用计数归零时优先将对象放回当前任务的缓存，而非直接释放，以提高性能。\n\n### 所有者管理与一致性校验\n- `pi_state_update_owner()` 在更新所有者时，需持有 `pi_mutex.wait_lock` 和对应任务的 `pi_lock`，确保链表操作的原子性。\n- `attach_to_pi_state()` 实现了复杂的用户空间与内核状态一致性校验逻辑，涵盖 10 种状态组合（见代码注释），防止用户空间篡改 futex 值导致内核状态不一致。\n- 特别处理 `FUTEX_OWNER_DIED` 位：当所有者进程退出时，内核需接管 `pi_state` 并允许新任务获取锁。\n\n### 引用计数与生命周期\n- `pi_state` 的生命周期由引用计数管理，引用来源包括：\n  - 等待队列中的 `futex_q`\n  - 正在执行 `futex_lock_pi`/`futex_unlock_pi` 的任务\n- `put_pi_state()` 在释放前会调用 `rt_mutex_proxy_unlock()` 清理 `rt_mutex` 状态，并从原所有者任务的 `pi_state_list` 中移除。\n\n### 锁顺序与并发控制\n- 严格遵守锁顺序：`hb->lock` → `pi_mutex.wait_lock` → `task->pi_lock`\n- 使用 `raw_spin_lock` 保证在中断上下文中的安全性\n- 通过 `lockdep_assert_held()` 验证锁持有状态，防止死锁\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `linux/slab.h`：内存分配（`kzalloc`/`kfree`）\n  - `linux/sched/rt.h`：实时调度相关功能\n  - `linux/sched/task.h`：任务结构体操作\n  - `\"futex.h\"`：futex 核心定义\n  - `\"../locking/rtmutex_common.h\"`：实时互斥锁实现\n\n- **模块依赖**：\n  - **futex 核心模块**（`kernel/futex.c`）：调用本文件函数处理 PI futex 操作\n  - **rtmutex 子系统**：提供 `rt_mutex_proxy_unlock()` 等底层锁操作\n  - **调度器**：依赖任务结构体中的 `pi_lock` 和 `pi_state_list`\n\n## 5. 使用场景\n\n- **PI futex 加锁**（`FUTEX_LOCK_PI`）：\n  - 当用户空间尝试获取 PI futex 时，内核通过 `attach_to_pi_state()` 验证状态并附加到现有 `pi_state`\n  - 若无可用 `pi_state`，则通过 `alloc_pi_state()` 分配新对象\n\n- **PI futex 解锁**（`FUTEX_UNLOCK_PI`）：\n  - 调用 `put_pi_state()` 释放 `pi_state` 引用，可能触发缓存或清理\n\n- **进程退出处理**：\n  - 当持有 PI futex 的进程退出时，内核通过 `exit_pi_state_list()` 清理其拥有的 `pi_state`，设置 `owner = NULL` 并唤醒等待者\n\n- **robust futex 支持**：\n  - 与 `FUTEX_OWNER_DIED` 位协同工作，确保进程异常退出后 futex 状态可被恢复\n\n- **优先级继承**：\n  - 当高优先级任务等待低优先级任务持有的 PI futex 时，内核通过 `rt_mutex` 机制临时提升低优先级任务的优先级，避免优先级反转",
      "similarity": 0.5116969347000122,
      "chunks": [
        {
          "chunk_id": 5,
          "file_path": "kernel/futex/pi.c",
          "start_line": 843,
          "end_line": 1079,
          "content": [
            "static int fixup_pi_state_owner(u32 __user *uaddr, struct futex_q *q,",
            "\t\t\t\tstruct task_struct *argowner)",
            "{",
            "\tstruct futex_pi_state *pi_state = q->pi_state;",
            "\tint ret;",
            "",
            "\tlockdep_assert_held(q->lock_ptr);",
            "",
            "\traw_spin_lock_irq(&pi_state->pi_mutex.wait_lock);",
            "\tret = __fixup_pi_state_owner(uaddr, q, argowner);",
            "\traw_spin_unlock_irq(&pi_state->pi_mutex.wait_lock);",
            "\treturn ret;",
            "}",
            "int fixup_pi_owner(u32 __user *uaddr, struct futex_q *q, int locked)",
            "{",
            "\tif (locked) {",
            "\t\t/*",
            "\t\t * Got the lock. We might not be the anticipated owner if we",
            "\t\t * did a lock-steal - fix up the PI-state in that case:",
            "\t\t *",
            "\t\t * Speculative pi_state->owner read (we don't hold wait_lock);",
            "\t\t * since we own the lock pi_state->owner == current is the",
            "\t\t * stable state, anything else needs more attention.",
            "\t\t */",
            "\t\tif (q->pi_state->owner != current)",
            "\t\t\treturn fixup_pi_state_owner(uaddr, q, current);",
            "\t\treturn 1;",
            "\t}",
            "",
            "\t/*",
            "\t * If we didn't get the lock; check if anybody stole it from us. In",
            "\t * that case, we need to fix up the uval to point to them instead of",
            "\t * us, otherwise bad things happen. [10]",
            "\t *",
            "\t * Another speculative read; pi_state->owner == current is unstable",
            "\t * but needs our attention.",
            "\t */",
            "\tif (q->pi_state->owner == current)",
            "\t\treturn fixup_pi_state_owner(uaddr, q, NULL);",
            "",
            "\t/*",
            "\t * Paranoia check. If we did not take the lock, then we should not be",
            "\t * the owner of the rt_mutex. Warn and establish consistent state.",
            "\t */",
            "\tif (WARN_ON_ONCE(rt_mutex_owner(&q->pi_state->pi_mutex) == current))",
            "\t\treturn fixup_pi_state_owner(uaddr, q, current);",
            "",
            "\treturn 0;",
            "}",
            "int futex_lock_pi(u32 __user *uaddr, unsigned int flags, ktime_t *time, int trylock)",
            "{",
            "\tstruct hrtimer_sleeper timeout, *to;",
            "\tstruct task_struct *exiting = NULL;",
            "\tstruct rt_mutex_waiter rt_waiter;",
            "\tstruct futex_hash_bucket *hb;",
            "\tstruct futex_q q = futex_q_init;",
            "\tint res, ret;",
            "",
            "\tif (!IS_ENABLED(CONFIG_FUTEX_PI))",
            "\t\treturn -ENOSYS;",
            "",
            "\tif (refill_pi_state_cache())",
            "\t\treturn -ENOMEM;",
            "",
            "\tto = futex_setup_timer(time, &timeout, flags, 0);",
            "",
            "retry:",
            "\tret = get_futex_key(uaddr, flags, &q.key, FUTEX_WRITE);",
            "\tif (unlikely(ret != 0))",
            "\t\tgoto out;",
            "",
            "retry_private:",
            "\thb = futex_q_lock(&q);",
            "",
            "\tret = futex_lock_pi_atomic(uaddr, hb, &q.key, &q.pi_state, current,",
            "\t\t\t\t   &exiting, 0);",
            "\tif (unlikely(ret)) {",
            "\t\t/*",
            "\t\t * Atomic work succeeded and we got the lock,",
            "\t\t * or failed. Either way, we do _not_ block.",
            "\t\t */",
            "\t\tswitch (ret) {",
            "\t\tcase 1:",
            "\t\t\t/* We got the lock. */",
            "\t\t\tret = 0;",
            "\t\t\tgoto out_unlock_put_key;",
            "\t\tcase -EFAULT:",
            "\t\t\tgoto uaddr_faulted;",
            "\t\tcase -EBUSY:",
            "\t\tcase -EAGAIN:",
            "\t\t\t/*",
            "\t\t\t * Two reasons for this:",
            "\t\t\t * - EBUSY: Task is exiting and we just wait for the",
            "\t\t\t *   exit to complete.",
            "\t\t\t * - EAGAIN: The user space value changed.",
            "\t\t\t */",
            "\t\t\tfutex_q_unlock(hb);",
            "\t\t\t/*",
            "\t\t\t * Handle the case where the owner is in the middle of",
            "\t\t\t * exiting. Wait for the exit to complete otherwise",
            "\t\t\t * this task might loop forever, aka. live lock.",
            "\t\t\t */",
            "\t\t\twait_for_owner_exiting(ret, exiting);",
            "\t\t\tcond_resched();",
            "\t\t\tgoto retry;",
            "\t\tdefault:",
            "\t\t\tgoto out_unlock_put_key;",
            "\t\t}",
            "\t}",
            "",
            "\tWARN_ON(!q.pi_state);",
            "",
            "\t/*",
            "\t * Only actually queue now that the atomic ops are done:",
            "\t */",
            "\t__futex_queue(&q, hb);",
            "",
            "\tif (trylock) {",
            "\t\tret = rt_mutex_futex_trylock(&q.pi_state->pi_mutex);",
            "\t\t/* Fixup the trylock return value: */",
            "\t\tret = ret ? 0 : -EWOULDBLOCK;",
            "\t\tgoto no_block;",
            "\t}",
            "",
            "\t/*",
            "\t * Must be done before we enqueue the waiter, here is unfortunately",
            "\t * under the hb lock, but that *should* work because it does nothing.",
            "\t */",
            "\trt_mutex_pre_schedule();",
            "",
            "\trt_mutex_init_waiter(&rt_waiter);",
            "",
            "\t/*",
            "\t * On PREEMPT_RT, when hb->lock becomes an rt_mutex, we must not",
            "\t * hold it while doing rt_mutex_start_proxy(), because then it will",
            "\t * include hb->lock in the blocking chain, even through we'll not in",
            "\t * fact hold it while blocking. This will lead it to report -EDEADLK",
            "\t * and BUG when futex_unlock_pi() interleaves with this.",
            "\t *",
            "\t * Therefore acquire wait_lock while holding hb->lock, but drop the",
            "\t * latter before calling __rt_mutex_start_proxy_lock(). This",
            "\t * interleaves with futex_unlock_pi() -- which does a similar lock",
            "\t * handoff -- such that the latter can observe the futex_q::pi_state",
            "\t * before __rt_mutex_start_proxy_lock() is done.",
            "\t */",
            "\traw_spin_lock_irq(&q.pi_state->pi_mutex.wait_lock);",
            "\tspin_unlock(q.lock_ptr);",
            "\t/*",
            "\t * __rt_mutex_start_proxy_lock() unconditionally enqueues the @rt_waiter",
            "\t * such that futex_unlock_pi() is guaranteed to observe the waiter when",
            "\t * it sees the futex_q::pi_state.",
            "\t */",
            "\tret = __rt_mutex_start_proxy_lock(&q.pi_state->pi_mutex, &rt_waiter, current);",
            "\traw_spin_unlock_irq(&q.pi_state->pi_mutex.wait_lock);",
            "",
            "\tif (ret) {",
            "\t\tif (ret == 1)",
            "\t\t\tret = 0;",
            "\t\tgoto cleanup;",
            "\t}",
            "",
            "\tif (unlikely(to))",
            "\t\thrtimer_sleeper_start_expires(to, HRTIMER_MODE_ABS);",
            "",
            "\tret = rt_mutex_wait_proxy_lock(&q.pi_state->pi_mutex, to, &rt_waiter);",
            "",
            "cleanup:",
            "\t/*",
            "\t * If we failed to acquire the lock (deadlock/signal/timeout), we must",
            "\t * must unwind the above, however we canont lock hb->lock because",
            "\t * rt_mutex already has a waiter enqueued and hb->lock can itself try",
            "\t * and enqueue an rt_waiter through rtlock.",
            "\t *",
            "\t * Doing the cleanup without holding hb->lock can cause inconsistent",
            "\t * state between hb and pi_state, but only in the direction of not",
            "\t * seeing a waiter that is leaving.",
            "\t *",
            "\t * See futex_unlock_pi(), it deals with this inconsistency.",
            "\t *",
            "\t * There be dragons here, since we must deal with the inconsistency on",
            "\t * the way out (here), it is impossible to detect/warn about the race",
            "\t * the other way around (missing an incoming waiter).",
            "\t *",
            "\t * What could possibly go wrong...",
            "\t */",
            "\tif (ret && !rt_mutex_cleanup_proxy_lock(&q.pi_state->pi_mutex, &rt_waiter))",
            "\t\tret = 0;",
            "",
            "\t/*",
            "\t * Now that the rt_waiter has been dequeued, it is safe to use",
            "\t * spinlock/rtlock (which might enqueue its own rt_waiter) and fix up",
            "\t * the",
            "\t */",
            "\tspin_lock(q.lock_ptr);",
            "\t/*",
            "\t * Waiter is unqueued.",
            "\t */",
            "\trt_mutex_post_schedule();",
            "no_block:",
            "\t/*",
            "\t * Fixup the pi_state owner and possibly acquire the lock if we",
            "\t * haven't already.",
            "\t */",
            "\tres = fixup_pi_owner(uaddr, &q, !ret);",
            "\t/*",
            "\t * If fixup_pi_owner() returned an error, propagate that.  If it acquired",
            "\t * the lock, clear our -ETIMEDOUT or -EINTR.",
            "\t */",
            "\tif (res)",
            "\t\tret = (res < 0) ? res : 0;",
            "",
            "\tfutex_unqueue_pi(&q);",
            "\tspin_unlock(q.lock_ptr);",
            "\tgoto out;",
            "",
            "out_unlock_put_key:",
            "\tfutex_q_unlock(hb);",
            "",
            "out:",
            "\tif (to) {",
            "\t\thrtimer_cancel(&to->timer);",
            "\t\tdestroy_hrtimer_on_stack(&to->timer);",
            "\t}",
            "\treturn ret != -EINTR ? ret : -ERESTARTNOINTR;",
            "",
            "uaddr_faulted:",
            "\tfutex_q_unlock(hb);",
            "",
            "\tret = fault_in_user_writeable(uaddr);",
            "\tif (ret)",
            "\t\tgoto out;",
            "",
            "\tif (!(flags & FLAGS_SHARED))",
            "\t\tgoto retry_private;",
            "",
            "\tgoto retry;",
            "}"
          ],
          "function_name": "fixup_pi_state_owner, fixup_pi_owner, futex_lock_pi",
          "description": "fixup_pi_state_owner 函数用于修复 PI 状态的所有者字段，通过持有互斥锁保证原子性更新。fixup_pi_owner 根据是否成功获取锁判断是否需要修复所有者，处理锁偷窃场景下的状态一致性。futex_lock_pi 实现带优先级继承的 FUTEX_LOCK 原子加锁逻辑，包含锁竞争处理、等待队列管理及与 rt_mutex 的交互。",
          "similarity": 0.5041464567184448
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/futex/pi.c",
          "start_line": 13,
          "end_line": 211,
          "content": [
            "int refill_pi_state_cache(void)",
            "{",
            "\tstruct futex_pi_state *pi_state;",
            "",
            "\tif (likely(current->pi_state_cache))",
            "\t\treturn 0;",
            "",
            "\tpi_state = kzalloc(sizeof(*pi_state), GFP_KERNEL);",
            "",
            "\tif (!pi_state)",
            "\t\treturn -ENOMEM;",
            "",
            "\tINIT_LIST_HEAD(&pi_state->list);",
            "\t/* pi_mutex gets initialized later */",
            "\tpi_state->owner = NULL;",
            "\trefcount_set(&pi_state->refcount, 1);",
            "\tpi_state->key = FUTEX_KEY_INIT;",
            "",
            "\tcurrent->pi_state_cache = pi_state;",
            "",
            "\treturn 0;",
            "}",
            "static void pi_state_update_owner(struct futex_pi_state *pi_state,",
            "\t\t\t\t  struct task_struct *new_owner)",
            "{",
            "\tstruct task_struct *old_owner = pi_state->owner;",
            "",
            "\tlockdep_assert_held(&pi_state->pi_mutex.wait_lock);",
            "",
            "\tif (old_owner) {",
            "\t\traw_spin_lock(&old_owner->pi_lock);",
            "\t\tWARN_ON(list_empty(&pi_state->list));",
            "\t\tlist_del_init(&pi_state->list);",
            "\t\traw_spin_unlock(&old_owner->pi_lock);",
            "\t}",
            "",
            "\tif (new_owner) {",
            "\t\traw_spin_lock(&new_owner->pi_lock);",
            "\t\tWARN_ON(!list_empty(&pi_state->list));",
            "\t\tlist_add(&pi_state->list, &new_owner->pi_state_list);",
            "\t\tpi_state->owner = new_owner;",
            "\t\traw_spin_unlock(&new_owner->pi_lock);",
            "\t}",
            "}",
            "void get_pi_state(struct futex_pi_state *pi_state)",
            "{",
            "\tWARN_ON_ONCE(!refcount_inc_not_zero(&pi_state->refcount));",
            "}",
            "void put_pi_state(struct futex_pi_state *pi_state)",
            "{",
            "\tif (!pi_state)",
            "\t\treturn;",
            "",
            "\tif (!refcount_dec_and_test(&pi_state->refcount))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If pi_state->owner is NULL, the owner is most probably dying",
            "\t * and has cleaned up the pi_state already",
            "\t */",
            "\tif (pi_state->owner) {",
            "\t\tunsigned long flags;",
            "",
            "\t\traw_spin_lock_irqsave(&pi_state->pi_mutex.wait_lock, flags);",
            "\t\tpi_state_update_owner(pi_state, NULL);",
            "\t\trt_mutex_proxy_unlock(&pi_state->pi_mutex);",
            "\t\traw_spin_unlock_irqrestore(&pi_state->pi_mutex.wait_lock, flags);",
            "\t}",
            "",
            "\tif (current->pi_state_cache) {",
            "\t\tkfree(pi_state);",
            "\t} else {",
            "\t\t/*",
            "\t\t * pi_state->list is already empty.",
            "\t\t * clear pi_state->owner.",
            "\t\t * refcount is at 0 - put it back to 1.",
            "\t\t */",
            "\t\tpi_state->owner = NULL;",
            "\t\trefcount_set(&pi_state->refcount, 1);",
            "\t\tcurrent->pi_state_cache = pi_state;",
            "\t}",
            "}",
            "static int attach_to_pi_state(u32 __user *uaddr, u32 uval,",
            "\t\t\t      struct futex_pi_state *pi_state,",
            "\t\t\t      struct futex_pi_state **ps)",
            "{",
            "\tpid_t pid = uval & FUTEX_TID_MASK;",
            "\tu32 uval2;",
            "\tint ret;",
            "",
            "\t/*",
            "\t * Userspace might have messed up non-PI and PI futexes [3]",
            "\t */",
            "\tif (unlikely(!pi_state))",
            "\t\treturn -EINVAL;",
            "",
            "\t/*",
            "\t * We get here with hb->lock held, and having found a",
            "\t * futex_top_waiter(). This means that futex_lock_pi() of said futex_q",
            "\t * has dropped the hb->lock in between futex_queue() and futex_unqueue_pi(),",
            "\t * which in turn means that futex_lock_pi() still has a reference on",
            "\t * our pi_state.",
            "\t *",
            "\t * The waiter holding a reference on @pi_state also protects against",
            "\t * the unlocked put_pi_state() in futex_unlock_pi(), futex_lock_pi()",
            "\t * and futex_wait_requeue_pi() as it cannot go to 0 and consequently",
            "\t * free pi_state before we can take a reference ourselves.",
            "\t */",
            "\tWARN_ON(!refcount_read(&pi_state->refcount));",
            "",
            "\t/*",
            "\t * Now that we have a pi_state, we can acquire wait_lock",
            "\t * and do the state validation.",
            "\t */",
            "\traw_spin_lock_irq(&pi_state->pi_mutex.wait_lock);",
            "",
            "\t/*",
            "\t * Since {uval, pi_state} is serialized by wait_lock, and our current",
            "\t * uval was read without holding it, it can have changed. Verify it",
            "\t * still is what we expect it to be, otherwise retry the entire",
            "\t * operation.",
            "\t */",
            "\tif (futex_get_value_locked(&uval2, uaddr))",
            "\t\tgoto out_efault;",
            "",
            "\tif (uval != uval2)",
            "\t\tgoto out_eagain;",
            "",
            "\t/*",
            "\t * Handle the owner died case:",
            "\t */",
            "\tif (uval & FUTEX_OWNER_DIED) {",
            "\t\t/*",
            "\t\t * exit_pi_state_list sets owner to NULL and wakes the",
            "\t\t * topmost waiter. The task which acquires the",
            "\t\t * pi_state->rt_mutex will fixup owner.",
            "\t\t */",
            "\t\tif (!pi_state->owner) {",
            "\t\t\t/*",
            "\t\t\t * No pi state owner, but the user space TID",
            "\t\t\t * is not 0. Inconsistent state. [5]",
            "\t\t\t */",
            "\t\t\tif (pid)",
            "\t\t\t\tgoto out_einval;",
            "\t\t\t/*",
            "\t\t\t * Take a ref on the state and return success. [4]",
            "\t\t\t */",
            "\t\t\tgoto out_attach;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * If TID is 0, then either the dying owner has not",
            "\t\t * yet executed exit_pi_state_list() or some waiter",
            "\t\t * acquired the rtmutex in the pi state, but did not",
            "\t\t * yet fixup the TID in user space.",
            "\t\t *",
            "\t\t * Take a ref on the state and return success. [6]",
            "\t\t */",
            "\t\tif (!pid)",
            "\t\t\tgoto out_attach;",
            "\t} else {",
            "\t\t/*",
            "\t\t * If the owner died bit is not set, then the pi_state",
            "\t\t * must have an owner. [7]",
            "\t\t */",
            "\t\tif (!pi_state->owner)",
            "\t\t\tgoto out_einval;",
            "\t}",
            "",
            "\t/*",
            "\t * Bail out if user space manipulated the futex value. If pi",
            "\t * state exists then the owner TID must be the same as the",
            "\t * user space TID. [9/10]",
            "\t */",
            "\tif (pid != task_pid_vnr(pi_state->owner))",
            "\t\tgoto out_einval;",
            "",
            "out_attach:",
            "\tget_pi_state(pi_state);",
            "\traw_spin_unlock_irq(&pi_state->pi_mutex.wait_lock);",
            "\t*ps = pi_state;",
            "\treturn 0;",
            "",
            "out_einval:",
            "\tret = -EINVAL;",
            "\tgoto out_error;",
            "",
            "out_eagain:",
            "\tret = -EAGAIN;",
            "\tgoto out_error;",
            "",
            "out_efault:",
            "\tret = -EFAULT;",
            "\tgoto out_error;",
            "",
            "out_error:",
            "\traw_spin_unlock_irq(&pi_state->pi_mutex.wait_lock);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "refill_pi_state_cache, pi_state_update_owner, get_pi_state, put_pi_state, attach_to_pi_state",
          "description": "实现PI状态缓存管理与所有权转换逻辑，包含pi_state分配、引用计数、列表操作及所有者变更控制。",
          "similarity": 0.5039119720458984
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/futex/pi.c",
          "start_line": 1,
          "end_line": 12,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-or-later",
            "",
            "#include <linux/slab.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/task.h>",
            "",
            "#include \"futex.h\"",
            "#include \"../locking/rtmutex_common.h\"",
            "",
            "/*",
            " * PI code:",
            " */"
          ],
          "function_name": null,
          "description": "定义PI（Priority Inheritance）相关代码的头部文件和基础结构，包含内核模块依赖项和注释说明。",
          "similarity": 0.5028720498085022
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/futex/pi.c",
          "start_line": 614,
          "end_line": 840,
          "content": [
            "static int wake_futex_pi(u32 __user *uaddr, u32 uval,",
            "\t\t\t struct futex_pi_state *pi_state,",
            "\t\t\t struct rt_mutex_waiter *top_waiter)",
            "{",
            "\tstruct task_struct *new_owner;",
            "\tbool postunlock = false;",
            "\tDEFINE_RT_WAKE_Q(wqh);",
            "\tu32 curval, newval;",
            "\tint ret = 0;",
            "",
            "\tnew_owner = top_waiter->task;",
            "",
            "\t/*",
            "\t * We pass it to the next owner. The WAITERS bit is always kept",
            "\t * enabled while there is PI state around. We cleanup the owner",
            "\t * died bit, because we are the owner.",
            "\t */",
            "\tnewval = FUTEX_WAITERS | task_pid_vnr(new_owner);",
            "",
            "\tif (unlikely(should_fail_futex(true))) {",
            "\t\tret = -EFAULT;",
            "\t\tgoto out_unlock;",
            "\t}",
            "",
            "\tret = futex_cmpxchg_value_locked(&curval, uaddr, uval, newval);",
            "\tif (!ret && (curval != uval)) {",
            "\t\t/*",
            "\t\t * If a unconditional UNLOCK_PI operation (user space did not",
            "\t\t * try the TID->0 transition) raced with a waiter setting the",
            "\t\t * FUTEX_WAITERS flag between get_user() and locking the hash",
            "\t\t * bucket lock, retry the operation.",
            "\t\t */",
            "\t\tif ((FUTEX_TID_MASK & curval) == uval)",
            "\t\t\tret = -EAGAIN;",
            "\t\telse",
            "\t\t\tret = -EINVAL;",
            "\t}",
            "",
            "\tif (!ret) {",
            "\t\t/*",
            "\t\t * This is a point of no return; once we modified the uval",
            "\t\t * there is no going back and subsequent operations must",
            "\t\t * not fail.",
            "\t\t */",
            "\t\tpi_state_update_owner(pi_state, new_owner);",
            "\t\tpostunlock = __rt_mutex_futex_unlock(&pi_state->pi_mutex, &wqh);",
            "\t}",
            "",
            "out_unlock:",
            "\traw_spin_unlock_irq(&pi_state->pi_mutex.wait_lock);",
            "",
            "\tif (postunlock)",
            "\t\trt_mutex_postunlock(&wqh);",
            "",
            "\treturn ret;",
            "}",
            "static int __fixup_pi_state_owner(u32 __user *uaddr, struct futex_q *q,",
            "\t\t\t\t  struct task_struct *argowner)",
            "{",
            "\tstruct futex_pi_state *pi_state = q->pi_state;",
            "\tstruct task_struct *oldowner, *newowner;",
            "\tu32 uval, curval, newval, newtid;",
            "\tint err = 0;",
            "",
            "\toldowner = pi_state->owner;",
            "",
            "\t/*",
            "\t * We are here because either:",
            "\t *",
            "\t *  - we stole the lock and pi_state->owner needs updating to reflect",
            "\t *    that (@argowner == current),",
            "\t *",
            "\t * or:",
            "\t *",
            "\t *  - someone stole our lock and we need to fix things to point to the",
            "\t *    new owner (@argowner == NULL).",
            "\t *",
            "\t * Either way, we have to replace the TID in the user space variable.",
            "\t * This must be atomic as we have to preserve the owner died bit here.",
            "\t *",
            "\t * Note: We write the user space value _before_ changing the pi_state",
            "\t * because we can fault here. Imagine swapped out pages or a fork",
            "\t * that marked all the anonymous memory readonly for cow.",
            "\t *",
            "\t * Modifying pi_state _before_ the user space value would leave the",
            "\t * pi_state in an inconsistent state when we fault here, because we",
            "\t * need to drop the locks to handle the fault. This might be observed",
            "\t * in the PID checks when attaching to PI state .",
            "\t */",
            "retry:",
            "\tif (!argowner) {",
            "\t\tif (oldowner != current) {",
            "\t\t\t/*",
            "\t\t\t * We raced against a concurrent self; things are",
            "\t\t\t * already fixed up. Nothing to do.",
            "\t\t\t */",
            "\t\t\treturn 0;",
            "\t\t}",
            "",
            "\t\tif (__rt_mutex_futex_trylock(&pi_state->pi_mutex)) {",
            "\t\t\t/* We got the lock. pi_state is correct. Tell caller. */",
            "\t\t\treturn 1;",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * The trylock just failed, so either there is an owner or",
            "\t\t * there is a higher priority waiter than this one.",
            "\t\t */",
            "\t\tnewowner = rt_mutex_owner(&pi_state->pi_mutex);",
            "\t\t/*",
            "\t\t * If the higher priority waiter has not yet taken over the",
            "\t\t * rtmutex then newowner is NULL. We can't return here with",
            "\t\t * that state because it's inconsistent vs. the user space",
            "\t\t * state. So drop the locks and try again. It's a valid",
            "\t\t * situation and not any different from the other retry",
            "\t\t * conditions.",
            "\t\t */",
            "\t\tif (unlikely(!newowner)) {",
            "\t\t\terr = -EAGAIN;",
            "\t\t\tgoto handle_err;",
            "\t\t}",
            "\t} else {",
            "\t\tWARN_ON_ONCE(argowner != current);",
            "\t\tif (oldowner == current) {",
            "\t\t\t/*",
            "\t\t\t * We raced against a concurrent self; things are",
            "\t\t\t * already fixed up. Nothing to do.",
            "\t\t\t */",
            "\t\t\treturn 1;",
            "\t\t}",
            "\t\tnewowner = argowner;",
            "\t}",
            "",
            "\tnewtid = task_pid_vnr(newowner) | FUTEX_WAITERS;",
            "\t/* Owner died? */",
            "\tif (!pi_state->owner)",
            "\t\tnewtid |= FUTEX_OWNER_DIED;",
            "",
            "\terr = futex_get_value_locked(&uval, uaddr);",
            "\tif (err)",
            "\t\tgoto handle_err;",
            "",
            "\tfor (;;) {",
            "\t\tnewval = (uval & FUTEX_OWNER_DIED) | newtid;",
            "",
            "\t\terr = futex_cmpxchg_value_locked(&curval, uaddr, uval, newval);",
            "\t\tif (err)",
            "\t\t\tgoto handle_err;",
            "",
            "\t\tif (curval == uval)",
            "\t\t\tbreak;",
            "\t\tuval = curval;",
            "\t}",
            "",
            "\t/*",
            "\t * We fixed up user space. Now we need to fix the pi_state",
            "\t * itself.",
            "\t */",
            "\tpi_state_update_owner(pi_state, newowner);",
            "",
            "\treturn argowner == current;",
            "",
            "\t/*",
            "\t * In order to reschedule or handle a page fault, we need to drop the",
            "\t * locks here. In the case of a fault, this gives the other task",
            "\t * (either the highest priority waiter itself or the task which stole",
            "\t * the rtmutex) the chance to try the fixup of the pi_state. So once we",
            "\t * are back from handling the fault we need to check the pi_state after",
            "\t * reacquiring the locks and before trying to do another fixup. When",
            "\t * the fixup has been done already we simply return.",
            "\t *",
            "\t * Note: we hold both hb->lock and pi_mutex->wait_lock. We can safely",
            "\t * drop hb->lock since the caller owns the hb -> futex_q relation.",
            "\t * Dropping the pi_mutex->wait_lock requires the state revalidate.",
            "\t */",
            "handle_err:",
            "\traw_spin_unlock_irq(&pi_state->pi_mutex.wait_lock);",
            "\tspin_unlock(q->lock_ptr);",
            "",
            "\tswitch (err) {",
            "\tcase -EFAULT:",
            "\t\terr = fault_in_user_writeable(uaddr);",
            "\t\tbreak;",
            "",
            "\tcase -EAGAIN:",
            "\t\tcond_resched();",
            "\t\terr = 0;",
            "\t\tbreak;",
            "",
            "\tdefault:",
            "\t\tWARN_ON_ONCE(1);",
            "\t\tbreak;",
            "\t}",
            "",
            "\tspin_lock(q->lock_ptr);",
            "\traw_spin_lock_irq(&pi_state->pi_mutex.wait_lock);",
            "",
            "\t/*",
            "\t * Check if someone else fixed it for us:",
            "\t */",
            "\tif (pi_state->owner != oldowner)",
            "\t\treturn argowner == current;",
            "",
            "\t/* Retry if err was -EAGAIN or the fault in succeeded */",
            "\tif (!err)",
            "\t\tgoto retry;",
            "",
            "\t/*",
            "\t * fault_in_user_writeable() failed so user state is immutable. At",
            "\t * best we can make the kernel state consistent but user state will",
            "\t * be most likely hosed and any subsequent unlock operation will be",
            "\t * rejected due to PI futex rule [10].",
            "\t *",
            "\t * Ensure that the rtmutex owner is also the pi_state owner despite",
            "\t * the user space value claiming something different. There is no",
            "\t * point in unlocking the rtmutex if current is the owner as it",
            "\t * would need to wait until the next waiter has taken the rtmutex",
            "\t * to guarantee consistent state. Keep it simple. Userspace asked",
            "\t * for this wreckaged state.",
            "\t *",
            "\t * The rtmutex has an owner - either current or some other",
            "\t * task. See the EAGAIN loop above.",
            "\t */",
            "\tpi_state_update_owner(pi_state, rt_mutex_owner(&pi_state->pi_mutex));",
            "",
            "\treturn err;",
            "}"
          ],
          "function_name": "wake_futex_pi, __fixup_pi_state_owner",
          "description": "提供PI状态唤醒与修复机制，包含所有者切换、用户空间值修正及互斥锁状态同步的完整性保障。",
          "similarity": 0.48359665274620056
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/futex/pi.c",
          "start_line": 475,
          "end_line": 584,
          "content": [
            "static int lock_pi_update_atomic(u32 __user *uaddr, u32 uval, u32 newval)",
            "{",
            "\tint err;",
            "\tu32 curval;",
            "",
            "\tif (unlikely(should_fail_futex(true)))",
            "\t\treturn -EFAULT;",
            "",
            "\terr = futex_cmpxchg_value_locked(&curval, uaddr, uval, newval);",
            "\tif (unlikely(err))",
            "\t\treturn err;",
            "",
            "\t/* If user space value changed, let the caller retry */",
            "\treturn curval != uval ? -EAGAIN : 0;",
            "}",
            "int futex_lock_pi_atomic(u32 __user *uaddr, struct futex_hash_bucket *hb,",
            "\t\t\t union futex_key *key,",
            "\t\t\t struct futex_pi_state **ps,",
            "\t\t\t struct task_struct *task,",
            "\t\t\t struct task_struct **exiting,",
            "\t\t\t int set_waiters)",
            "{",
            "\tu32 uval, newval, vpid = task_pid_vnr(task);",
            "\tstruct futex_q *top_waiter;",
            "\tint ret;",
            "",
            "\t/*",
            "\t * Read the user space value first so we can validate a few",
            "\t * things before proceeding further.",
            "\t */",
            "\tif (futex_get_value_locked(&uval, uaddr))",
            "\t\treturn -EFAULT;",
            "",
            "\tif (unlikely(should_fail_futex(true)))",
            "\t\treturn -EFAULT;",
            "",
            "\t/*",
            "\t * Detect deadlocks.",
            "\t */",
            "\tif ((unlikely((uval & FUTEX_TID_MASK) == vpid)))",
            "\t\treturn -EDEADLK;",
            "",
            "\tif ((unlikely(should_fail_futex(true))))",
            "\t\treturn -EDEADLK;",
            "",
            "\t/*",
            "\t * Lookup existing state first. If it exists, try to attach to",
            "\t * its pi_state.",
            "\t */",
            "\ttop_waiter = futex_top_waiter(hb, key);",
            "\tif (top_waiter)",
            "\t\treturn attach_to_pi_state(uaddr, uval, top_waiter->pi_state, ps);",
            "",
            "\t/*",
            "\t * No waiter and user TID is 0. We are here because the",
            "\t * waiters or the owner died bit is set or called from",
            "\t * requeue_cmp_pi or for whatever reason something took the",
            "\t * syscall.",
            "\t */",
            "\tif (!(uval & FUTEX_TID_MASK)) {",
            "\t\t/*",
            "\t\t * We take over the futex. No other waiters and the user space",
            "\t\t * TID is 0. We preserve the owner died bit.",
            "\t\t */",
            "\t\tnewval = uval & FUTEX_OWNER_DIED;",
            "\t\tnewval |= vpid;",
            "",
            "\t\t/* The futex requeue_pi code can enforce the waiters bit */",
            "\t\tif (set_waiters)",
            "\t\t\tnewval |= FUTEX_WAITERS;",
            "",
            "\t\tret = lock_pi_update_atomic(uaddr, uval, newval);",
            "\t\tif (ret)",
            "\t\t\treturn ret;",
            "",
            "\t\t/*",
            "\t\t * If the waiter bit was requested the caller also needs PI",
            "\t\t * state attached to the new owner of the user space futex.",
            "\t\t *",
            "\t\t * @task is guaranteed to be alive and it cannot be exiting",
            "\t\t * because it is either sleeping or waiting in",
            "\t\t * futex_requeue_pi_wakeup_sync().",
            "\t\t *",
            "\t\t * No need to do the full attach_to_pi_owner() exercise",
            "\t\t * because @task is known and valid.",
            "\t\t */",
            "\t\tif (set_waiters) {",
            "\t\t\traw_spin_lock_irq(&task->pi_lock);",
            "\t\t\t__attach_to_pi_owner(task, key, ps);",
            "\t\t\traw_spin_unlock_irq(&task->pi_lock);",
            "\t\t}",
            "\t\treturn 1;",
            "\t}",
            "",
            "\t/*",
            "\t * First waiter. Set the waiters bit before attaching ourself to",
            "\t * the owner. If owner tries to unlock, it will be forced into",
            "\t * the kernel and blocked on hb->lock.",
            "\t */",
            "\tnewval = uval | FUTEX_WAITERS;",
            "\tret = lock_pi_update_atomic(uaddr, uval, newval);",
            "\tif (ret)",
            "\t\treturn ret;",
            "\t/*",
            "\t * If the update of the user space value succeeded, we try to",
            "\t * attach to the owner. If that fails, no harm done, we only",
            "\t * set the FUTEX_WAITERS bit in the user space variable.",
            "\t */",
            "\treturn attach_to_pi_owner(uaddr, newval, key, ps, exiting);",
            "}"
          ],
          "function_name": "lock_pi_update_atomic, futex_lock_pi_atomic",
          "description": "实现原子值更新与锁获取流程，包含死锁检测、等待位设置及PI状态附加的核心控制流。",
          "similarity": 0.46005117893218994
        }
      ]
    }
  ]
}