{
  "query": "cgroup PID缓存限制机制",
  "timestamp": "2025-12-26 01:41:53",
  "retrieved_files": [
    {
      "source_file": "kernel/cgroup/pids.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:50:03\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `cgroup\\pids.c`\n\n---\n\n# cgroup/pids.c 技术文档\n\n## 1. 文件概述\n\n`cgroup/pids.c` 实现了 Linux 内核中 cgroup 的 **PID 控制器（pids controller）**，用于限制指定 cgroup 及其子层级中可创建的最大进程（任务）数量。该控制器通过监控 `fork()` 系统调用，在进程数量即将超过设定阈值时拒绝创建新进程（返回 `-EAGAIN`），从而防止 PID 资源耗尽。该控制器支持层级继承语义，即子 cgroup 的有效限制为其自身与所有祖先中**最严格**的限制。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct pids_cgroup`**  \n  表示一个 cgroup 的 PID 控制状态，包含：\n  - `counter`：当前 cgroup 中的进程数量（64 位原子计数器）\n  - `limit`：允许的最大进程数（64 位原子值，`PIDS_MAX` 表示无限制）\n  - `watermark`：历史最高进程数（用于监控）\n  - `events` / `events_local`：事件计数器（如 `PIDCG_MAX`、`PIDCG_FORKFAIL`）\n  - `events_file` / `events_local_file`：用于通知用户空间事件发生的 cgroup 文件句柄\n\n- **`enum pidcg_event`**  \n  定义两类事件：\n  - `PIDCG_MAX`：因本 cgroup 或祖先限制被触发而导致 fork 失败\n  - `PIDCG_FORKFAIL`：在本 cgroup 中 fork 失败（用于本地事件通知）\n\n### 主要函数\n\n- **资源分配与释放**\n  - `pids_css_alloc()`：为新 cgroup 分配 `pids_cgroup` 结构，初始限制设为 `PIDS_MAX`（无限制）\n  - `pids_css_free()`：释放 `pids_cgroup` 结构\n\n- **计数操作**\n  - `pids_charge()`：**无条件**增加指定 cgroup 及其所有祖先的进程计数（用于回滚）\n  - `pids_uncharge()`：减少指定 cgroup 及其所有祖先的进程计数\n  - `pids_cancel()`：内部辅助函数，执行实际的原子减操作，并检查负值（视为 bug）\n  - `pids_try_charge()`：**有条件**增加计数，若任一祖先层级超过限制则回滚并返回 `-EAGAIN`\n\n- **cgroup 钩子函数**\n  - `pids_can_attach()`：在任务迁移到新 cgroup 时，更新源/目标 cgroup 的计数\n  - `pids_cancel_attach()`：回滚 `pids_can_attach()` 的操作\n  - `pids_can_fork()`：在 `fork()` 前检查是否允许创建新进程（未在提供的代码片段中完整显示）\n  - `pids_cancel_fork()`：回滚 fork 失败时的计数（未在提供的代码片段中完整显示）\n\n- **事件通知**\n  - `pids_event()`：当 fork 因 PID 限制失败时，记录事件并通知用户空间（通过 `cgroup_file_notify`）\n\n- **辅助函数**\n  - `css_pids()`：从 `cgroup_subsys_state` 转换为 `pids_cgroup`\n  - `parent_pids()`：获取父 cgroup 的 `pids_cgroup`\n  - `pids_update_watermark()`：更新历史最高进程数（非原子，容忍竞态）\n\n## 3. 关键实现\n\n### 层级限制语义\nPID 限制遵循 cgroup 的层级继承规则：一个进程的实际限制由其所在 cgroup 路径上**所有祖先中最小的 `limit` 值**决定。`pids_try_charge()` 在从当前 cgroup 向根方向遍历时，一旦发现任一祖先的 `counter + num > limit`，即判定为违反策略。\n\n### 原子计数与回滚机制\n- 所有计数操作均使用 `atomic64_t` 保证并发安全。\n- `pids_try_charge()` 采用“先增加后检查+回滚”策略：先原子增加所有祖先计数，再逐级检查是否超限。若超限，则从当前节点回滚到起始节点的所有增量。\n- `pids_charge()` 用于必须成功的场景（如 attach 回滚），**不检查限制**，允许临时超限。\n\n### 事件通知机制\n- 当 fork 因限制失败时，调用 `pids_event()`：\n  - 在 fork 发生的 cgroup 中记录 `PIDCG_FORKFAIL` 事件（仅首次触发时打印内核日志）\n  - 若启用了本地事件（通过 `cgroup v2` 的 `pids.local_events` 选项），则仅通知本地事件文件\n  - 否则，在**触发限制的祖先 cgroup** 中记录 `PIDCG_MAX` 事件，并向上传播通知\n\n### 无限制表示\n使用 `PIDS_MAX = PID_MAX_LIMIT + 1` 表示“无限制”，因为实际 PID 数量不可能超过 `PID_MAX_LIMIT`，因此该值可安全用于比较（`new > limit` 永远为假）。\n\n## 4. 依赖关系\n\n- **`<linux/cgroup.h>`**：cgroup 核心框架，提供 `cgroup_subsys_state`、`cgroup_taskset` 等基础结构和钩子函数接口\n- **`<linux/atomic.h>`**：提供 64 位原子操作（`atomic64_t`）\n- **`<linux/sched/task.h>`**：提供 `task_css()` 等任务与 cgroup 关联的接口\n- **`<linux/slab.h>`**：内存分配（`kzalloc`/`kfree`）\n- **`pids_cgrp_id`**：全局子系统 ID，用于从 `css_set` 或 `task_struct` 中获取 PID 控制器状态\n- **`cgroup_threadgroup_change_begin()`**：确保在 `fork` 过程中 cgroup 关联稳定（`pids_can_fork` 依赖此锁）\n\n## 5. 使用场景\n\n1. **容器资源隔离**  \n   在容器运行时（如 Docker、Podman）中限制单个容器或 Pod 可创建的最大进程数，防止 fork bomb 耗尽系统 PID 资源。\n\n2. **多租户系统防护**  \n   在共享主机环境中，为不同用户或服务分配独立的 cgroup，并设置 PID 限制，避免某一用户进程泛滥影响其他用户。\n\n3. **系统稳定性保障**  \n   通过全局或关键服务 cgroup 设置 PID 上限，确保即使某个子系统异常，也不会导致整个系统因 PID 耗尽而无法创建新进程。\n\n4. **监控与告警**  \n   通过读取 `pids.current`、`pids.max` 和 `pids.events` 文件，监控进程使用情况并在接近或达到限制时触发告警。",
      "similarity": 0.6503173112869263,
      "chunks": [
        {
          "chunk_id": 0,
          "file_path": "kernel/cgroup/pids.c",
          "start_line": 1,
          "end_line": 90,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Process number limiting controller for cgroups.",
            " *",
            " * Used to allow a cgroup hierarchy to stop any new processes from fork()ing",
            " * after a certain limit is reached.",
            " *",
            " * Since it is trivial to hit the task limit without hitting any kmemcg limits",
            " * in place, PIDs are a fundamental resource. As such, PID exhaustion must be",
            " * preventable in the scope of a cgroup hierarchy by allowing resource limiting",
            " * of the number of tasks in a cgroup.",
            " *",
            " * In order to use the `pids` controller, set the maximum number of tasks in",
            " * pids.max (this is not available in the root cgroup for obvious reasons). The",
            " * number of processes currently in the cgroup is given by pids.current.",
            " * Organisational operations are not blocked by cgroup policies, so it is",
            " * possible to have pids.current > pids.max. However, it is not possible to",
            " * violate a cgroup policy through fork(). fork() will return -EAGAIN if forking",
            " * would cause a cgroup policy to be violated.",
            " *",
            " * To set a cgroup to have no limit, set pids.max to \"max\". This is the default",
            " * for all new cgroups (N.B. that PID limits are hierarchical, so the most",
            " * stringent limit in the hierarchy is followed).",
            " *",
            " * pids.current tracks all child cgroup hierarchies, so parent/pids.current is",
            " * a superset of parent/child/pids.current.",
            " *",
            " * Copyright (C) 2015 Aleksa Sarai <cyphar@cyphar.com>",
            " */",
            "",
            "#include <linux/kernel.h>",
            "#include <linux/threads.h>",
            "#include <linux/atomic.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "",
            "#define PIDS_MAX (PID_MAX_LIMIT + 1ULL)",
            "#define PIDS_MAX_STR \"max\"",
            "",
            "enum pidcg_event {",
            "\t/* Fork failed in subtree because this pids_cgroup limit was hit. */",
            "\tPIDCG_MAX,",
            "\t/* Fork failed in this pids_cgroup because ancestor limit was hit. */",
            "\tPIDCG_FORKFAIL,",
            "\tNR_PIDCG_EVENTS,",
            "};",
            "",
            "struct pids_cgroup {",
            "\tstruct cgroup_subsys_state\tcss;",
            "",
            "\t/*",
            "\t * Use 64-bit types so that we can safely represent \"max\" as",
            "\t * %PIDS_MAX = (%PID_MAX_LIMIT + 1).",
            "\t */",
            "\tatomic64_t\t\t\tcounter;",
            "\tatomic64_t\t\t\tlimit;",
            "\tint64_t\t\t\t\twatermark;",
            "",
            "\t/* Handles for pids.events[.local] */",
            "\tstruct cgroup_file\t\tevents_file;",
            "\tstruct cgroup_file\t\tevents_local_file;",
            "",
            "\tatomic64_t\t\t\tevents[NR_PIDCG_EVENTS];",
            "\tatomic64_t\t\t\tevents_local[NR_PIDCG_EVENTS];",
            "};",
            "",
            "static struct pids_cgroup *css_pids(struct cgroup_subsys_state *css)",
            "{",
            "\treturn container_of(css, struct pids_cgroup, css);",
            "}",
            "",
            "static struct pids_cgroup *parent_pids(struct pids_cgroup *pids)",
            "{",
            "\treturn css_pids(pids->css.parent);",
            "}",
            "",
            "static struct cgroup_subsys_state *",
            "pids_css_alloc(struct cgroup_subsys_state *parent)",
            "{",
            "\tstruct pids_cgroup *pids;",
            "",
            "\tpids = kzalloc(sizeof(struct pids_cgroup), GFP_KERNEL);",
            "\tif (!pids)",
            "\t\treturn ERR_PTR(-ENOMEM);",
            "",
            "\tatomic64_set(&pids->limit, PIDS_MAX);",
            "\treturn &pids->css;",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义了cgroup的pids控制器核心结构体pids_cgroup，包含原子计数器、限制值和事件统计字段，用于跟踪任务数量以防止进程爆炸。通过CSS子系统状态关联到cgroup层级，支持基于层级的资源限制。",
          "similarity": 0.6077526807785034
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/cgroup/pids.c",
          "start_line": 91,
          "end_line": 202,
          "content": [
            "static void pids_css_free(struct cgroup_subsys_state *css)",
            "{",
            "\tkfree(css_pids(css));",
            "}",
            "static void pids_update_watermark(struct pids_cgroup *p, int64_t nr_pids)",
            "{",
            "\t/*",
            "\t * This is racy, but we don't need perfectly accurate tallying of",
            "\t * the watermark, and this lets us avoid extra atomic overhead.",
            "\t */",
            "\tif (nr_pids > READ_ONCE(p->watermark))",
            "\t\tWRITE_ONCE(p->watermark, nr_pids);",
            "}",
            "static void pids_cancel(struct pids_cgroup *pids, int num)",
            "{",
            "\t/*",
            "\t * A negative count (or overflow for that matter) is invalid,",
            "\t * and indicates a bug in the `pids` controller proper.",
            "\t */",
            "\tWARN_ON_ONCE(atomic64_add_negative(-num, &pids->counter));",
            "}",
            "static void pids_uncharge(struct pids_cgroup *pids, int num)",
            "{",
            "\tstruct pids_cgroup *p;",
            "",
            "\tfor (p = pids; parent_pids(p); p = parent_pids(p))",
            "\t\tpids_cancel(p, num);",
            "}",
            "static void pids_charge(struct pids_cgroup *pids, int num)",
            "{",
            "\tstruct pids_cgroup *p;",
            "",
            "\tfor (p = pids; parent_pids(p); p = parent_pids(p)) {",
            "\t\tint64_t new = atomic64_add_return(num, &p->counter);",
            "",
            "\t\tpids_update_watermark(p, new);",
            "\t}",
            "}",
            "static int pids_try_charge(struct pids_cgroup *pids, int num, struct pids_cgroup **fail)",
            "{",
            "\tstruct pids_cgroup *p, *q;",
            "",
            "\tfor (p = pids; parent_pids(p); p = parent_pids(p)) {",
            "\t\tint64_t new = atomic64_add_return(num, &p->counter);",
            "\t\tint64_t limit = atomic64_read(&p->limit);",
            "",
            "\t\t/*",
            "\t\t * Since new is capped to the maximum number of pid_t, if",
            "\t\t * p->limit is %PIDS_MAX then we know that this test will never",
            "\t\t * fail.",
            "\t\t */",
            "\t\tif (new > limit) {",
            "\t\t\t*fail = p;",
            "\t\t\tgoto revert;",
            "\t\t}",
            "\t\t/*",
            "\t\t * Not technically accurate if we go over limit somewhere up",
            "\t\t * the hierarchy, but that's tolerable for the watermark.",
            "\t\t */",
            "\t\tpids_update_watermark(p, new);",
            "\t}",
            "",
            "\treturn 0;",
            "",
            "revert:",
            "\tfor (q = pids; q != p; q = parent_pids(q))",
            "\t\tpids_cancel(q, num);",
            "\tpids_cancel(p, num);",
            "",
            "\treturn -EAGAIN;",
            "}",
            "static int pids_can_attach(struct cgroup_taskset *tset)",
            "{",
            "\tstruct task_struct *task;",
            "\tstruct cgroup_subsys_state *dst_css;",
            "",
            "\tcgroup_taskset_for_each(task, dst_css, tset) {",
            "\t\tstruct pids_cgroup *pids = css_pids(dst_css);",
            "\t\tstruct cgroup_subsys_state *old_css;",
            "\t\tstruct pids_cgroup *old_pids;",
            "",
            "\t\t/*",
            "\t\t * No need to pin @old_css between here and cancel_attach()",
            "\t\t * because cgroup core protects it from being freed before",
            "\t\t * the migration completes or fails.",
            "\t\t */",
            "\t\told_css = task_css(task, pids_cgrp_id);",
            "\t\told_pids = css_pids(old_css);",
            "",
            "\t\tpids_charge(pids, 1);",
            "\t\tpids_uncharge(old_pids, 1);",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static void pids_cancel_attach(struct cgroup_taskset *tset)",
            "{",
            "\tstruct task_struct *task;",
            "\tstruct cgroup_subsys_state *dst_css;",
            "",
            "\tcgroup_taskset_for_each(task, dst_css, tset) {",
            "\t\tstruct pids_cgroup *pids = css_pids(dst_css);",
            "\t\tstruct cgroup_subsys_state *old_css;",
            "\t\tstruct pids_cgroup *old_pids;",
            "",
            "\t\told_css = task_css(task, pids_cgrp_id);",
            "\t\told_pids = css_pids(old_css);",
            "",
            "\t\tpids_charge(old_pids, 1);",
            "\t\tpids_uncharge(pids, 1);",
            "\t}",
            "}"
          ],
          "function_name": "pids_css_free, pids_update_watermark, pids_cancel, pids_uncharge, pids_charge, pids_try_charge, pids_can_attach, pids_cancel_attach",
          "description": "实现了pids控制器的资源充放电逻辑，包含分配/释放CSS结构、更新水位线、充放电操作及附件检查等功能。通过遍历祖先cgroup进行全局资源追踪，确保层级间限制一致性。",
          "similarity": 0.5791415572166443
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/cgroup/pids.c",
          "start_line": 243,
          "end_line": 344,
          "content": [
            "static void pids_event(struct pids_cgroup *pids_forking,",
            "\t\t       struct pids_cgroup *pids_over_limit)",
            "{",
            "\tstruct pids_cgroup *p = pids_forking;",
            "",
            "\t/* Only log the first time limit is hit. */",
            "\tif (atomic64_inc_return(&p->events_local[PIDCG_FORKFAIL]) == 1) {",
            "\t\tpr_info(\"cgroup: fork rejected by pids controller in \");",
            "\t\tpr_cont_cgroup_path(p->css.cgroup);",
            "\t\tpr_cont(\"\\n\");",
            "\t}",
            "\tif (!cgroup_subsys_on_dfl(pids_cgrp_subsys) ||",
            "\t    cgrp_dfl_root.flags & CGRP_ROOT_PIDS_LOCAL_EVENTS) {",
            "\t\tcgroup_file_notify(&p->events_local_file);",
            "\t\treturn;",
            "\t}",
            "",
            "\tatomic64_inc(&pids_over_limit->events_local[PIDCG_MAX]);",
            "\tcgroup_file_notify(&pids_over_limit->events_local_file);",
            "",
            "\tfor (p = pids_over_limit; parent_pids(p); p = parent_pids(p)) {",
            "\t\tatomic64_inc(&p->events[PIDCG_MAX]);",
            "\t\tcgroup_file_notify(&p->events_file);",
            "\t}",
            "}",
            "static int pids_can_fork(struct task_struct *task, struct css_set *cset)",
            "{",
            "\tstruct cgroup_subsys_state *css;",
            "\tstruct pids_cgroup *pids, *pids_over_limit;",
            "\tint err;",
            "",
            "\tif (cset)",
            "\t\tcss = cset->subsys[pids_cgrp_id];",
            "\telse",
            "\t\tcss = task_css_check(current, pids_cgrp_id, true);",
            "\tpids = css_pids(css);",
            "\terr = pids_try_charge(pids, 1, &pids_over_limit);",
            "\tif (err)",
            "\t\tpids_event(pids, pids_over_limit);",
            "",
            "\treturn err;",
            "}",
            "static void pids_cancel_fork(struct task_struct *task, struct css_set *cset)",
            "{",
            "\tstruct cgroup_subsys_state *css;",
            "\tstruct pids_cgroup *pids;",
            "",
            "\tif (cset)",
            "\t\tcss = cset->subsys[pids_cgrp_id];",
            "\telse",
            "\t\tcss = task_css_check(current, pids_cgrp_id, true);",
            "\tpids = css_pids(css);",
            "\tpids_uncharge(pids, 1);",
            "}",
            "static void pids_release(struct task_struct *task)",
            "{",
            "\tstruct pids_cgroup *pids = css_pids(task_css(task, pids_cgrp_id));",
            "",
            "\tpids_uncharge(pids, 1);",
            "}",
            "static ssize_t pids_max_write(struct kernfs_open_file *of, char *buf,",
            "\t\t\t      size_t nbytes, loff_t off)",
            "{",
            "\tstruct cgroup_subsys_state *css = of_css(of);",
            "\tstruct pids_cgroup *pids = css_pids(css);",
            "\tint64_t limit;",
            "\tint err;",
            "",
            "\tbuf = strstrip(buf);",
            "\tif (!strcmp(buf, PIDS_MAX_STR)) {",
            "\t\tlimit = PIDS_MAX;",
            "\t\tgoto set_limit;",
            "\t}",
            "",
            "\terr = kstrtoll(buf, 0, &limit);",
            "\tif (err)",
            "\t\treturn err;",
            "",
            "\tif (limit < 0 || limit >= PIDS_MAX)",
            "\t\treturn -EINVAL;",
            "",
            "set_limit:",
            "\t/*",
            "\t * Limit updates don't need to be mutex'd, since it isn't",
            "\t * critical that any racing fork()s follow the new limit.",
            "\t */",
            "\tatomic64_set(&pids->limit, limit);",
            "\treturn nbytes;",
            "}",
            "static int pids_max_show(struct seq_file *sf, void *v)",
            "{",
            "\tstruct cgroup_subsys_state *css = seq_css(sf);",
            "\tstruct pids_cgroup *pids = css_pids(css);",
            "\tint64_t limit = atomic64_read(&pids->limit);",
            "",
            "\tif (limit >= PIDS_MAX)",
            "\t\tseq_printf(sf, \"%s\\n\", PIDS_MAX_STR);",
            "\telse",
            "\t\tseq_printf(sf, \"%lld\\n\", limit);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "pids_event, pids_can_fork, pids_cancel_fork, pids_release, pids_max_write, pids_max_show",
          "description": "处理进程创建时的配额检查与事件记录，包含can_fork检查、取消fork操作、任务释放及最大进程数配置接口。当达到硬限制时触发事件通知并拒绝fork请求。",
          "similarity": 0.4651044011116028
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/cgroup/pids.c",
          "start_line": 355,
          "end_line": 394,
          "content": [
            "static s64 pids_current_read(struct cgroup_subsys_state *css,",
            "\t\t\t     struct cftype *cft)",
            "{",
            "\tstruct pids_cgroup *pids = css_pids(css);",
            "",
            "\treturn atomic64_read(&pids->counter);",
            "}",
            "static s64 pids_peak_read(struct cgroup_subsys_state *css,",
            "\t\t\t  struct cftype *cft)",
            "{",
            "\tstruct pids_cgroup *pids = css_pids(css);",
            "",
            "\treturn READ_ONCE(pids->watermark);",
            "}",
            "static int __pids_events_show(struct seq_file *sf, bool local)",
            "{",
            "\tstruct pids_cgroup *pids = css_pids(seq_css(sf));",
            "\tenum pidcg_event pe = PIDCG_MAX;",
            "\tatomic64_t *events;",
            "",
            "\tif (!cgroup_subsys_on_dfl(pids_cgrp_subsys) ||",
            "\t    cgrp_dfl_root.flags & CGRP_ROOT_PIDS_LOCAL_EVENTS) {",
            "\t\tpe = PIDCG_FORKFAIL;",
            "\t\tlocal = true;",
            "\t}",
            "\tevents = local ? pids->events_local : pids->events;",
            "",
            "\tseq_printf(sf, \"max %lld\\n\", (s64)atomic64_read(&events[pe]));",
            "\treturn 0;",
            "}",
            "static int pids_events_show(struct seq_file *sf, void *v)",
            "{",
            "\t__pids_events_show(sf, false);",
            "\treturn 0;",
            "}",
            "static int pids_events_local_show(struct seq_file *sf, void *v)",
            "{",
            "\t__pids_events_show(sf, true);",
            "\treturn 0;",
            "}"
          ],
          "function_name": "pids_current_read, pids_peak_read, __pids_events_show, pids_events_show, pids_events_local_show",
          "description": "暴露pids控制器的监控接口，包括当前任务数读取、历史峰值查询及事件统计展示。通过seq_file接口向用户空间导出运行时统计数据。",
          "similarity": 0.4157078266143799
        }
      ]
    },
    {
      "source_file": "kernel/cgroup/cgroup-v1.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:41:31\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `cgroup\\cgroup-v1.c`\n\n---\n\n# cgroup/cgroup-v1.c 技术文档\n\n## 1. 文件概述\n\n`cgroup-v1.c` 是 Linux 内核中控制组（cgroup）v1 版本的核心实现文件之一，负责提供 cgroup v1 特有的功能接口和机制。该文件主要实现了任务迁移、进程/线程 PID 列表管理、cgroup v1 控制器屏蔽逻辑以及与用户空间交互所需的文件操作支持（如 `tasks` 和 `cgroup.procs` 文件的读取）。它构建在通用 cgroup 基础设施之上，专用于维护 cgroup v1 的兼容性和行为一致性。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`cgroup1_ssid_disabled(int ssid)`**  \n  检查指定子系统 ID（ssid）是否被命令行参数禁用（通过 `cgroup_no_v1_mask`）。\n\n- **`cgroup_attach_task_all(struct task_struct *from, struct task_struct *tsk)`**  \n  将任务 `tsk` 附加到 `from` 任务所属的所有 cgroup v1 层级中，实现跨层级的一致性迁移。\n\n- **`cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from)`**  \n  将 `from` cgroup 中的所有任务原子地迁移到 `to` cgroup，确保迁移过程中 fork 的子进程不会“逃逸”。\n\n- **`cgroup1_pidlist_destroy_all(struct cgroup *cgrp)`**  \n  销毁指定 cgroup 中所有延迟释放的 PID 列表，用于 cgroup 销毁前的清理。\n\n- **`cgroup_pidlist_destroy_work_fn(struct work_struct *work)`**  \n  延迟工作队列回调函数，异步释放不再使用的 `cgroup_pidlist` 结构。\n\n- **`pidlist_uniq(pid_t *list, int length)`**  \n  对已排序的 PID 数组去重，返回唯一 PID 的数量。\n\n- **`cgroup_pidlist_find(struct cgroup *cgrp, enum cgroup_filetype type)`**  \n  在指定 cgroup 中查找匹配当前 PID 命名空间和文件类型的 PID 列表。\n\n### 主要数据结构\n\n- **`enum cgroup_filetype`**  \n  枚举类型，标识 PID 列表对应的是 `CGROUP_FILE_PROCS`（进程）还是 `CGROUP_FILE_TASKS`（线程）。\n\n- **`struct cgroup_pidlist`**  \n  表示一个 PID 列表的缓存结构，包含：\n  - `key`：标识类型（procs/tasks）和所属 PID 命名空间\n  - `list`：存储 PID 的动态数组（使用 `kvfree` 分配）\n  - `length`：有效 PID 数量\n  - `links`：挂载到 cgroup 的 `pidlists` 链表\n  - `owner`：所属 cgroup\n  - `destroy_dwork`：延迟销毁的工作项\n\n### 全局变量\n\n- **`cgroup_no_v1_mask`**  \n  位掩码，记录被命令行（如 `cgroup_no_v1=`）禁用的 v1 控制器。\n\n- **`cgroup_no_v1_named`**  \n  布尔值，控制是否禁止命名的 v1 cgroup 挂载。\n\n- **`cgroup_pidlist_destroy_wq`**  \n  专用工作队列，用于异步销毁 PID 列表，避免阻塞关键路径。\n\n- **`release_agent_path_lock`**  \n  自旋锁，保护 `cgroup_subsys->release_agent_path` 的并发访问。\n\n## 3. 关键实现\n\n### PID 列表缓存机制\n\n为高效读取 `tasks` 和 `cgroup.procs` 文件，内核采用按 **cgroup + PID 命名空间 + 文件类型** 三元组缓存 PID 列表的策略。由于不同 PID 命名空间中 PID 映射不同，且文件要求输出**排序且去重**的 PID，无法使用全局数据结构（如红黑树），故引入 `cgroup_pidlist` 共享池。\n\n- 列表生成后缓存一段时间（`CGROUP_PIDLIST_DESTROY_DELAY = 1秒`），避免连续读操作重复构建。\n- 使用 `delayed_work` 延迟释放，若在延迟期间再次被访问，则取消销毁。\n- 通过专用工作队列 `cgroup_pidlist_destroy_wq` 确保销毁操作可被 flush，保证 cgroup 销毁时无残留。\n\n### 任务迁移原子性保障\n\n`cgroup_transfer_tasks` 实现了安全的任务批量迁移：\n\n1. 使用 `cgroup_migrate` 框架，先收集所有源 css_set（`cgroup_migrate_add_src`），再准备目标（`cgroup_migrate_prepare_dst`）。\n2. 逐个迁移任务，跳过 `PF_EXITING` 的退出中任务。\n3. 依赖 `cgroup_attach_lock` 和 fork 路径的同步机制，确保迁移过程中 fork 的子进程要么留在源 cgroup（迁移完成后可见），要么直接进入目标 cgroup，**杜绝任务“丢失”**。\n\n### 排序与去重\n\n- PID 列表通过 `sort()` + `cmppid()` 进行升序排序。\n- `pidlist_uniq()` 对已排序数组原地去重，利用相邻元素比较实现 O(n) 时间复杂度。\n\n## 4. 依赖关系\n\n- **内部依赖**：\n  - `cgroup-internal.h`：cgroup 内部通用接口和数据结构\n  - `css_set_lock`、`cgroup_lock()` 等同步原语\n  - `cgroup_migrate_*` 系列迁移框架函数\n  - `task_cgroup_from_root()` 等任务-cgroup 映射函数\n\n- **外部依赖**：\n  - `<linux/pid_namespace.h>`：PID 命名空间支持\n  - `<linux/sched/task.h>`、`<linux/sched/signal.h>`：任务结构和状态访问\n  - `<linux/vmalloc.h>`：大内存分配（`kvfree`）\n  - `<trace/events/cgroup.h>`：cgroup 追踪事件\n  - 各 cgroup v1 子系统（如 cpu、memory）通过 `cgroup_subsys` 与本文件交互\n\n## 5. 使用场景\n\n- **用户空间读取 `tasks`/`cgroup.procs` 文件**：触发 PID 列表生成、缓存和输出。\n- **容器运行时迁移进程**：调用 `cgroup_attach_task_all` 或 `cgroup_transfer_tasks` 实现跨 cgroup 的进程移动。\n- **系统启动时控制器屏蔽**：通过内核参数 `cgroup_no_v1=...` 设置 `cgroup_no_v1_mask`，禁用特定 v1 控制器。\n- **cgroup v1 层级销毁**：调用 `cgroup1_pidlist_destroy_all` 清理所有缓存的 PID 列表。\n- **release agent 路径更新**：通过 `release_agent_path_lock` 保护并发写入。",
      "similarity": 0.6308044791221619,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/cgroup/cgroup-v1.c",
          "start_line": 44,
          "end_line": 162,
          "content": [
            "bool cgroup1_ssid_disabled(int ssid)",
            "{",
            "\treturn cgroup_no_v1_mask & (1 << ssid);",
            "}",
            "int cgroup_attach_task_all(struct task_struct *from, struct task_struct *tsk)",
            "{",
            "\tstruct cgroup_root *root;",
            "\tint retval = 0;",
            "",
            "\tcgroup_lock();",
            "\tcgroup_attach_lock(true);",
            "\tfor_each_root(root) {",
            "\t\tstruct cgroup *from_cgrp;",
            "",
            "\t\tspin_lock_irq(&css_set_lock);",
            "\t\tfrom_cgrp = task_cgroup_from_root(from, root);",
            "\t\tspin_unlock_irq(&css_set_lock);",
            "",
            "\t\tretval = cgroup_attach_task(from_cgrp, tsk, false);",
            "\t\tif (retval)",
            "\t\t\tbreak;",
            "\t}",
            "\tcgroup_attach_unlock(true);",
            "\tcgroup_unlock();",
            "",
            "\treturn retval;",
            "}",
            "int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from)",
            "{",
            "\tDEFINE_CGROUP_MGCTX(mgctx);",
            "\tstruct cgrp_cset_link *link;",
            "\tstruct css_task_iter it;",
            "\tstruct task_struct *task;",
            "\tint ret;",
            "",
            "\tif (cgroup_on_dfl(to))",
            "\t\treturn -EINVAL;",
            "",
            "\tret = cgroup_migrate_vet_dst(to);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tcgroup_lock();",
            "",
            "\tcgroup_attach_lock(true);",
            "",
            "\t/* all tasks in @from are being moved, all csets are source */",
            "\tspin_lock_irq(&css_set_lock);",
            "\tlist_for_each_entry(link, &from->cset_links, cset_link)",
            "\t\tcgroup_migrate_add_src(link->cset, to, &mgctx);",
            "\tspin_unlock_irq(&css_set_lock);",
            "",
            "\tret = cgroup_migrate_prepare_dst(&mgctx);",
            "\tif (ret)",
            "\t\tgoto out_err;",
            "",
            "\t/*",
            "\t * Migrate tasks one-by-one until @from is empty.  This fails iff",
            "\t * ->can_attach() fails.",
            "\t */",
            "\tdo {",
            "\t\tcss_task_iter_start(&from->self, 0, &it);",
            "",
            "\t\tdo {",
            "\t\t\ttask = css_task_iter_next(&it);",
            "\t\t} while (task && (task->flags & PF_EXITING));",
            "",
            "\t\tif (task)",
            "\t\t\tget_task_struct(task);",
            "\t\tcss_task_iter_end(&it);",
            "",
            "\t\tif (task) {",
            "\t\t\tret = cgroup_migrate(task, false, &mgctx);",
            "\t\t\tif (!ret)",
            "\t\t\t\tTRACE_CGROUP_PATH(transfer_tasks, to, task, false);",
            "\t\t\tput_task_struct(task);",
            "\t\t}",
            "\t} while (task && !ret);",
            "out_err:",
            "\tcgroup_migrate_finish(&mgctx);",
            "\tcgroup_attach_unlock(true);",
            "\tcgroup_unlock();",
            "\treturn ret;",
            "}",
            "void cgroup1_pidlist_destroy_all(struct cgroup *cgrp)",
            "{",
            "\tstruct cgroup_pidlist *l, *tmp_l;",
            "",
            "\tmutex_lock(&cgrp->pidlist_mutex);",
            "\tlist_for_each_entry_safe(l, tmp_l, &cgrp->pidlists, links)",
            "\t\tmod_delayed_work(cgroup_pidlist_destroy_wq, &l->destroy_dwork, 0);",
            "\tmutex_unlock(&cgrp->pidlist_mutex);",
            "",
            "\tflush_workqueue(cgroup_pidlist_destroy_wq);",
            "\tBUG_ON(!list_empty(&cgrp->pidlists));",
            "}",
            "static void cgroup_pidlist_destroy_work_fn(struct work_struct *work)",
            "{",
            "\tstruct delayed_work *dwork = to_delayed_work(work);",
            "\tstruct cgroup_pidlist *l = container_of(dwork, struct cgroup_pidlist,",
            "\t\t\t\t\t\tdestroy_dwork);",
            "\tstruct cgroup_pidlist *tofree = NULL;",
            "",
            "\tmutex_lock(&l->owner->pidlist_mutex);",
            "",
            "\t/*",
            "\t * Destroy iff we didn't get queued again.  The state won't change",
            "\t * as destroy_dwork can only be queued while locked.",
            "\t */",
            "\tif (!delayed_work_pending(dwork)) {",
            "\t\tlist_del(&l->links);",
            "\t\tkvfree(l->list);",
            "\t\tput_pid_ns(l->key.ns);",
            "\t\ttofree = l;",
            "\t}",
            "",
            "\tmutex_unlock(&l->owner->pidlist_mutex);",
            "\tkfree(tofree);",
            "}"
          ],
          "function_name": "cgroup1_ssid_disabled, cgroup_attach_task_all, cgroup_transfer_tasks, cgroup1_pidlist_destroy_all, cgroup_pidlist_destroy_work_fn",
          "description": "提供cgroup任务附加、迁移及进程列表销毁功能，实现跨cgroup的任务转移和延迟资源回收机制。",
          "similarity": 0.6029837131500244
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/cgroup/cgroup-v1.c",
          "start_line": 237,
          "end_line": 379,
          "content": [
            "static int pidlist_uniq(pid_t *list, int length)",
            "{",
            "\tint src, dest = 1;",
            "",
            "\t/*",
            "\t * we presume the 0th element is unique, so i starts at 1. trivial",
            "\t * edge cases first; no work needs to be done for either",
            "\t */",
            "\tif (length == 0 || length == 1)",
            "\t\treturn length;",
            "\t/* src and dest walk down the list; dest counts unique elements */",
            "\tfor (src = 1; src < length; src++) {",
            "\t\t/* find next unique element */",
            "\t\twhile (list[src] == list[src-1]) {",
            "\t\t\tsrc++;",
            "\t\t\tif (src == length)",
            "\t\t\t\tgoto after;",
            "\t\t}",
            "\t\t/* dest always points to where the next unique element goes */",
            "\t\tlist[dest] = list[src];",
            "\t\tdest++;",
            "\t}",
            "after:",
            "\treturn dest;",
            "}",
            "static int cmppid(const void *a, const void *b)",
            "{",
            "\treturn *(pid_t *)a - *(pid_t *)b;",
            "}",
            "static int pidlist_array_load(struct cgroup *cgrp, enum cgroup_filetype type,",
            "\t\t\t      struct cgroup_pidlist **lp)",
            "{",
            "\tpid_t *array;",
            "\tint length;",
            "\tint pid, n = 0; /* used for populating the array */",
            "\tstruct css_task_iter it;",
            "\tstruct task_struct *tsk;",
            "\tstruct cgroup_pidlist *l;",
            "",
            "\tlockdep_assert_held(&cgrp->pidlist_mutex);",
            "",
            "\t/*",
            "\t * If cgroup gets more users after we read count, we won't have",
            "\t * enough space - tough.  This race is indistinguishable to the",
            "\t * caller from the case that the additional cgroup users didn't",
            "\t * show up until sometime later on.",
            "\t */",
            "\tlength = cgroup_task_count(cgrp);",
            "\tarray = kvmalloc_array(length, sizeof(pid_t), GFP_KERNEL);",
            "\tif (!array)",
            "\t\treturn -ENOMEM;",
            "\t/* now, populate the array */",
            "\tcss_task_iter_start(&cgrp->self, 0, &it);",
            "\twhile ((tsk = css_task_iter_next(&it))) {",
            "\t\tif (unlikely(n == length))",
            "\t\t\tbreak;",
            "\t\t/* get tgid or pid for procs or tasks file respectively */",
            "\t\tif (type == CGROUP_FILE_PROCS)",
            "\t\t\tpid = task_tgid_vnr(tsk);",
            "\t\telse",
            "\t\t\tpid = task_pid_vnr(tsk);",
            "\t\tif (pid > 0) /* make sure to only use valid results */",
            "\t\t\tarray[n++] = pid;",
            "\t}",
            "\tcss_task_iter_end(&it);",
            "\tlength = n;",
            "\t/* now sort & strip out duplicates (tgids or recycled thread PIDs) */",
            "\tsort(array, length, sizeof(pid_t), cmppid, NULL);",
            "\tlength = pidlist_uniq(array, length);",
            "",
            "\tl = cgroup_pidlist_find_create(cgrp, type);",
            "\tif (!l) {",
            "\t\tkvfree(array);",
            "\t\treturn -ENOMEM;",
            "\t}",
            "",
            "\t/* store array, freeing old if necessary */",
            "\tkvfree(l->list);",
            "\tl->list = array;",
            "\tl->length = length;",
            "\t*lp = l;",
            "\treturn 0;",
            "}",
            "static void cgroup_pidlist_stop(struct seq_file *s, void *v)",
            "{",
            "\tstruct kernfs_open_file *of = s->private;",
            "\tstruct cgroup_file_ctx *ctx = of->priv;",
            "\tstruct cgroup_pidlist *l = ctx->procs1.pidlist;",
            "",
            "\tif (l)",
            "\t\tmod_delayed_work(cgroup_pidlist_destroy_wq, &l->destroy_dwork,",
            "\t\t\t\t CGROUP_PIDLIST_DESTROY_DELAY);",
            "\tmutex_unlock(&seq_css(s)->cgroup->pidlist_mutex);",
            "}",
            "static int cgroup_pidlist_show(struct seq_file *s, void *v)",
            "{",
            "\tseq_printf(s, \"%d\\n\", *(int *)v);",
            "",
            "\treturn 0;",
            "}",
            "static ssize_t __cgroup1_procs_write(struct kernfs_open_file *of,",
            "\t\t\t\t     char *buf, size_t nbytes, loff_t off,",
            "\t\t\t\t     bool threadgroup)",
            "{",
            "\tstruct cgroup *cgrp;",
            "\tstruct task_struct *task;",
            "\tconst struct cred *cred, *tcred;",
            "\tssize_t ret;",
            "\tbool locked;",
            "",
            "\tcgrp = cgroup_kn_lock_live(of->kn, false);",
            "\tif (!cgrp)",
            "\t\treturn -ENODEV;",
            "",
            "\ttask = cgroup_procs_write_start(buf, threadgroup, &locked);",
            "\tret = PTR_ERR_OR_ZERO(task);",
            "\tif (ret)",
            "\t\tgoto out_unlock;",
            "",
            "\t/*",
            "\t * Even if we're attaching all tasks in the thread group, we only need",
            "\t * to check permissions on one of them. Check permissions using the",
            "\t * credentials from file open to protect against inherited fd attacks.",
            "\t */",
            "\tcred = of->file->f_cred;",
            "\ttcred = get_task_cred(task);",
            "\tif (!uid_eq(cred->euid, GLOBAL_ROOT_UID) &&",
            "\t    !uid_eq(cred->euid, tcred->uid) &&",
            "\t    !uid_eq(cred->euid, tcred->suid))",
            "\t\tret = -EACCES;",
            "\tput_cred(tcred);",
            "\tif (ret)",
            "\t\tgoto out_finish;",
            "",
            "\tret = cgroup_attach_task(cgrp, task, threadgroup);",
            "",
            "out_finish:",
            "\tcgroup_procs_write_finish(task, locked);",
            "out_unlock:",
            "\tcgroup_kn_unlock(of->kn);",
            "",
            "\treturn ret ?: nbytes;",
            "}"
          ],
          "function_name": "pidlist_uniq, cmppid, pidlist_array_load, cgroup_pidlist_stop, cgroup_pidlist_show, __cgroup1_procs_write",
          "description": "实现进程ID列表的唯一化、排序及加载逻辑，支持通过proc文件接口暴露cgroup进程视图。",
          "similarity": 0.5841033458709717
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/cgroup/cgroup-v1.c",
          "start_line": 1,
          "end_line": 43,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "#include \"cgroup-internal.h\"",
            "",
            "#include <linux/ctype.h>",
            "#include <linux/kmod.h>",
            "#include <linux/sort.h>",
            "#include <linux/delay.h>",
            "#include <linux/mm.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/magic.h>",
            "#include <linux/slab.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/fs_parser.h>",
            "",
            "#include <trace/events/cgroup.h>",
            "",
            "/*",
            " * pidlists linger the following amount before being destroyed.  The goal",
            " * is avoiding frequent destruction in the middle of consecutive read calls",
            " * Expiring in the middle is a performance problem not a correctness one.",
            " * 1 sec should be enough.",
            " */",
            "#define CGROUP_PIDLIST_DESTROY_DELAY\tHZ",
            "",
            "/* Controllers blocked by the commandline in v1 */",
            "static u16 cgroup_no_v1_mask;",
            "",
            "/* disable named v1 mounts */",
            "static bool cgroup_no_v1_named;",
            "",
            "/*",
            " * pidlist destructions need to be flushed on cgroup destruction.  Use a",
            " * separate workqueue as flush domain.",
            " */",
            "static struct workqueue_struct *cgroup_pidlist_destroy_wq;",
            "",
            "/* protects cgroup_subsys->release_agent_path */",
            "static DEFINE_SPINLOCK(release_agent_path_lock);",
            ""
          ],
          "function_name": null,
          "description": "声明cgroup v1子系统相关的全局变量和头文件，包含进程列表销毁延迟、控制器掩码、工作队列及释放代理路径锁等核心资源。",
          "similarity": 0.5640472173690796
        },
        {
          "chunk_id": 7,
          "file_path": "kernel/cgroup/cgroup-v1.c",
          "start_line": 1233,
          "end_line": 1305,
          "content": [
            "int cgroup1_get_tree(struct fs_context *fc)",
            "{",
            "\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);",
            "\tint ret;",
            "",
            "\t/* Check if the caller has permission to mount. */",
            "\tif (!ns_capable(ctx->ns->user_ns, CAP_SYS_ADMIN))",
            "\t\treturn -EPERM;",
            "",
            "\tcgroup_lock_and_drain_offline(&cgrp_dfl_root.cgrp);",
            "",
            "\tret = cgroup1_root_to_use(fc);",
            "\tif (!ret && !percpu_ref_tryget_live(&ctx->root->cgrp.self.refcnt))",
            "\t\tret = 1;\t/* restart */",
            "",
            "\tcgroup_unlock();",
            "",
            "\tif (!ret)",
            "\t\tret = cgroup_do_get_tree(fc);",
            "",
            "\tif (!ret && percpu_ref_is_dying(&ctx->root->cgrp.self.refcnt)) {",
            "\t\tfc_drop_locked(fc);",
            "\t\tret = 1;",
            "\t}",
            "",
            "\tif (unlikely(ret > 0)) {",
            "\t\tmsleep(10);",
            "\t\treturn restart_syscall();",
            "\t}",
            "\treturn ret;",
            "}",
            "static int __init cgroup1_wq_init(void)",
            "{",
            "\t/*",
            "\t * Used to destroy pidlists and separate to serve as flush domain.",
            "\t * Cap @max_active to 1 too.",
            "\t */",
            "\tcgroup_pidlist_destroy_wq = alloc_workqueue(\"cgroup_pidlist_destroy\",",
            "\t\t\t\t\t\t    0, 1);",
            "\tBUG_ON(!cgroup_pidlist_destroy_wq);",
            "\treturn 0;",
            "}",
            "static int __init cgroup_no_v1(char *str)",
            "{",
            "\tstruct cgroup_subsys *ss;",
            "\tchar *token;",
            "\tint i;",
            "",
            "\twhile ((token = strsep(&str, \",\")) != NULL) {",
            "\t\tif (!*token)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (!strcmp(token, \"all\")) {",
            "\t\t\tcgroup_no_v1_mask = U16_MAX;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tif (!strcmp(token, \"named\")) {",
            "\t\t\tcgroup_no_v1_named = true;",
            "\t\t\tcontinue;",
            "\t\t}",
            "",
            "\t\tfor_each_subsys(ss, i) {",
            "\t\t\tif (strcmp(token, ss->name) &&",
            "\t\t\t    strcmp(token, ss->legacy_name))",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\tcgroup_no_v1_mask |= 1 << i;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "\treturn 1;",
            "}"
          ],
          "function_name": "cgroup1_get_tree, cgroup1_wq_init, cgroup_no_v1",
          "description": "构建cgroup v1层级树结构，初始化销毁工作队列，提供内核启动参数接口以控制禁用特定子系统及其命名功能",
          "similarity": 0.5637478828430176
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/cgroup/cgroup-v1.c",
          "start_line": 920,
          "end_line": 1066,
          "content": [
            "int cgroup1_parse_param(struct fs_context *fc, struct fs_parameter *param)",
            "{",
            "\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);",
            "\tstruct cgroup_subsys *ss;",
            "\tstruct fs_parse_result result;",
            "\tint opt, i;",
            "",
            "\topt = fs_parse(fc, cgroup1_fs_parameters, param, &result);",
            "\tif (opt == -ENOPARAM) {",
            "\t\tint ret;",
            "",
            "\t\tret = vfs_parse_fs_param_source(fc, param);",
            "\t\tif (ret != -ENOPARAM)",
            "\t\t\treturn ret;",
            "\t\tfor_each_subsys(ss, i) {",
            "\t\t\tif (strcmp(param->key, ss->legacy_name))",
            "\t\t\t\tcontinue;",
            "\t\t\tif (!cgroup_ssid_enabled(i) || cgroup1_ssid_disabled(i))",
            "\t\t\t\treturn invalfc(fc, \"Disabled controller '%s'\",",
            "\t\t\t\t\t       param->key);",
            "\t\t\tctx->subsys_mask |= (1 << i);",
            "\t\t\treturn 0;",
            "\t\t}",
            "\t\treturn invalfc(fc, \"Unknown subsys name '%s'\", param->key);",
            "\t}",
            "\tif (opt < 0)",
            "\t\treturn opt;",
            "",
            "\tswitch (opt) {",
            "\tcase Opt_none:",
            "\t\t/* Explicitly have no subsystems */",
            "\t\tctx->none = true;",
            "\t\tbreak;",
            "\tcase Opt_all:",
            "\t\tctx->all_ss = true;",
            "\t\tbreak;",
            "\tcase Opt_noprefix:",
            "\t\tctx->flags |= CGRP_ROOT_NOPREFIX;",
            "\t\tbreak;",
            "\tcase Opt_clone_children:",
            "\t\tctx->cpuset_clone_children = true;",
            "\t\tbreak;",
            "\tcase Opt_cpuset_v2_mode:",
            "\t\tctx->flags |= CGRP_ROOT_CPUSET_V2_MODE;",
            "\t\tbreak;",
            "\tcase Opt_xattr:",
            "\t\tctx->flags |= CGRP_ROOT_XATTR;",
            "\t\tbreak;",
            "\tcase Opt_favordynmods:",
            "\t\tctx->flags |= CGRP_ROOT_FAVOR_DYNMODS;",
            "\t\tbreak;",
            "\tcase Opt_nofavordynmods:",
            "\t\tctx->flags &= ~CGRP_ROOT_FAVOR_DYNMODS;",
            "\t\tbreak;",
            "\tcase Opt_release_agent:",
            "\t\t/* Specifying two release agents is forbidden */",
            "\t\tif (ctx->release_agent)",
            "\t\t\treturn invalfc(fc, \"release_agent respecified\");",
            "\t\t/*",
            "\t\t * Release agent gets called with all capabilities,",
            "\t\t * require capabilities to set release agent.",
            "\t\t */",
            "\t\tif ((fc->user_ns != &init_user_ns) || !capable(CAP_SYS_ADMIN))",
            "\t\t\treturn invalfc(fc, \"Setting release_agent not allowed\");",
            "\t\tctx->release_agent = param->string;",
            "\t\tparam->string = NULL;",
            "\t\tbreak;",
            "\tcase Opt_name:",
            "\t\t/* blocked by boot param? */",
            "\t\tif (cgroup_no_v1_named)",
            "\t\t\treturn -ENOENT;",
            "\t\t/* Can't specify an empty name */",
            "\t\tif (!param->size)",
            "\t\t\treturn invalfc(fc, \"Empty name\");",
            "\t\tif (param->size > MAX_CGROUP_ROOT_NAMELEN - 1)",
            "\t\t\treturn invalfc(fc, \"Name too long\");",
            "\t\t/* Must match [\\w.-]+ */",
            "\t\tfor (i = 0; i < param->size; i++) {",
            "\t\t\tchar c = param->string[i];",
            "\t\t\tif (isalnum(c))",
            "\t\t\t\tcontinue;",
            "\t\t\tif ((c == '.') || (c == '-') || (c == '_'))",
            "\t\t\t\tcontinue;",
            "\t\t\treturn invalfc(fc, \"Invalid name\");",
            "\t\t}",
            "\t\t/* Specifying two names is forbidden */",
            "\t\tif (ctx->name)",
            "\t\t\treturn invalfc(fc, \"name respecified\");",
            "\t\tctx->name = param->string;",
            "\t\tparam->string = NULL;",
            "\t\tbreak;",
            "\t}",
            "\treturn 0;",
            "}",
            "static int check_cgroupfs_options(struct fs_context *fc)",
            "{",
            "\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);",
            "\tu16 mask = U16_MAX;",
            "\tu16 enabled = 0;",
            "\tstruct cgroup_subsys *ss;",
            "\tint i;",
            "",
            "#ifdef CONFIG_CPUSETS",
            "\tmask = ~((u16)1 << cpuset_cgrp_id);",
            "#endif",
            "\tfor_each_subsys(ss, i)",
            "\t\tif (cgroup_ssid_enabled(i) && !cgroup1_ssid_disabled(i))",
            "\t\t\tenabled |= 1 << i;",
            "",
            "\tctx->subsys_mask &= enabled;",
            "",
            "\t/*",
            "\t * In absence of 'none', 'name=' and subsystem name options,",
            "\t * let's default to 'all'.",
            "\t */",
            "\tif (!ctx->subsys_mask && !ctx->none && !ctx->name)",
            "\t\tctx->all_ss = true;",
            "",
            "\tif (ctx->all_ss) {",
            "\t\t/* Mutually exclusive option 'all' + subsystem name */",
            "\t\tif (ctx->subsys_mask)",
            "\t\t\treturn invalfc(fc, \"subsys name conflicts with all\");",
            "\t\t/* 'all' => select all the subsystems */",
            "\t\tctx->subsys_mask = enabled;",
            "\t}",
            "",
            "\t/*",
            "\t * We either have to specify by name or by subsystems. (So all",
            "\t * empty hierarchies must have a name).",
            "\t */",
            "\tif (!ctx->subsys_mask && !ctx->name)",
            "\t\treturn invalfc(fc, \"Need name or subsystem set\");",
            "",
            "\t/*",
            "\t * Option noprefix was introduced just for backward compatibility",
            "\t * with the old cpuset, so we allow noprefix only if mounting just",
            "\t * the cpuset subsystem.",
            "\t */",
            "\tif ((ctx->flags & CGRP_ROOT_NOPREFIX) && (ctx->subsys_mask & mask))",
            "\t\treturn invalfc(fc, \"noprefix used incorrectly\");",
            "",
            "\t/* Can't specify \"none\" and some subsystems */",
            "\tif (ctx->subsys_mask && ctx->none)",
            "\t\treturn invalfc(fc, \"none used incorrectly\");",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "cgroup1_parse_param, check_cgroupfs_options",
          "description": "解析并验证cgroup v1挂载参数，处理子系统选择、命名空间限制、释放代理等选项，确保参数有效性及互斥性",
          "similarity": 0.5539917349815369
        }
      ]
    },
    {
      "source_file": "kernel/cgroup/dmem.c",
      "md_summary": "> 自动生成时间: 2025-10-25 12:45:21\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `cgroup\\dmem.c`\n\n---\n\n# cgroup/dmem.c 技术文档\n\n## 文件概述\n\n`cgroup/dmem.c` 实现了一个名为 **dmem（device memory）** 的 cgroup 子系统，用于对设备内存（如 GPU、NPU 或其他专用硬件内存）的使用进行资源控制和配额管理。该子系统通过 `page_counter` 机制跟踪每个 cgroup 在特定设备内存区域（region）上的用量，并支持设置 `min`、`low` 和 `max` 三种资源限制级别，以实现分级内存保护和回收策略。文件还提供了内存回收时的“是否可驱逐”判断逻辑，用于指导设备驱动在内存压力下选择合适的 cgroup 进行释放。\n\n## 核心功能\n\n### 主要数据结构\n\n- **`struct dmem_cgroup_region`**  \n  表示一个设备内存区域（如某块 GPU 显存），包含：\n  - `ref`：引用计数，配合 RCU 管理生命周期\n  - `region_node`：全局区域链表节点（`dmem_cgroup_regions`）\n  - `pools`：关联到该区域的所有 cgroup 内存池列表\n  - `size`：区域总大小（字节）\n  - `name`：区域名称\n  - `unregistered`：标记区域是否已注销，防止新池加入\n\n- **`struct dmemcg_state`**  \n  cgroup 子系统状态（CSS），每个 cgroup 实例对应一个，包含：\n  - `css`：标准 cgroup_subsys_state 基类\n  - `pools`：该 cgroup 下所有设备内存池的链表\n\n- **`struct dmem_cgroup_pool_state`**  \n  表示某个 cgroup 在特定设备内存区域上的使用状态，包含：\n  - `region`：指向所属的 `dmem_cgroup_region`\n  - `cs`：指向所属的 `dmemcg_state`\n  - `css_node`：挂载到 cgroup 的 `pools` 链表（RCU 保护）\n  - `region_node`：挂载到 region 的 `pools` 链表（自旋锁保护）\n  - `cnt`：`page_counter` 实例，记录当前用量及限制\n  - `inited`：初始化标志\n\n### 主要函数\n\n- **资源限制操作函数**  \n  - `set_resource_min/low/max()`：设置 min/low/max 限制\n  - `get_resource_current/min/low/max()`：获取当前用量或限制值\n  - `reset_all_resource_limits()`：重置所有限制为默认值\n\n- **cgroup 生命周期回调**  \n  - `dmemcs_alloc()`：分配 cgroup 状态\n  - `dmemcs_offline()`：cgroup 下线时重置所有池的限制\n  - `dmemcs_free()`：释放 cgroup 状态及关联的池\n\n- **内存回收辅助函数**  \n  - `dmem_cgroup_state_evict_valuable()`：判断某内存池是否可被驱逐（核心回收逻辑）\n  - `dmem_cgroup_calculate_protection()`：计算子树中各池的有效保护值（emin/elow）\n\n- **辅助函数**  \n  - `find_cg_pool_locked()`：在指定 cgroup 中查找特定 region 的池（需持锁）\n  - `pool_parent()`：获取池的父池（基于 page_counter 层级）\n\n## 关键实现\n\n### 并发控制策略\n\n- **全局自旋锁 `dmemcg_lock`**：保护以下操作：\n  - 全局区域列表 `dmem_cgroup_regions` 的增删\n  - cgroup 的 `pools` 链表与 region 的 `pools` 链表的修改\n- **RCU 机制**：用于无锁读取 cgroup 的 `pools` 链表（如 `dmemcs_offline()` 和 `find_cg_pool_locked()`）\n- **`page_counter`**：本身是无锁的原子计数器，用于高效跟踪内存用量\n\n### 内存保护与回收逻辑\n\n- **三级保护机制**：\n  - `min`：硬性保证，用量 ≤ min 时不可驱逐\n  - `low`：软性保护，用量 > low 时可驱逐；用量 ≤ low 时需特殊处理（如设置 `ret_hit_low`）\n  - `max`：硬性上限，用量不可超过\n- **`dmem_cgroup_state_evict_valuable()` 工作流程**：\n  1. 若 `limit_pool == test_pool`，直接允许驱逐（自身超限）\n  2. 若 `limit_pool` 无父 cgroup（即根 cgroup），允许驱逐\n  3. 检查 `test_pool` 是否在 `limit_pool` 的子树中（通过 `pool_parent` 遍历）\n  4. 调用 `dmem_cgroup_calculate_protection()` 计算子树中各池的有效保护值\n  5. 比较 `test_pool` 的当前用量与 `emin`/`elow`：\n     - 用量 ≤ `emin` → 不可驱逐\n     - 用量 > `elow` → 可驱逐\n     - 用量 ≤ `elow` 且 `ignore_low=false` → 不可驱逐，但设置 `ret_hit_low=true` 建议重试\n\n### 层级关系维护\n\n- **池的父子关系**：通过 `page_counter` 的 `parent` 字段隐式建立，`pool_parent()` 用于向上遍历\n- **保护值传播**：`dmem_cgroup_calculate_protection()` 遍历 `limit_pool` 的整个子树，调用 `page_counter_calculate_protection()` 更新各子池的 `emin`/`elow`\n\n## 依赖关系\n\n- **核心依赖**：\n  - `<linux/cgroup.h>`：cgroup 子系统框架\n  - `<linux/page_counter.h>`：内存用量计数与保护机制\n  - `<linux/rcupdate.h>`（隐式）：RCU 读写锁\n  - `<linux/spinlock.h>`：自旋锁实现\n- **头文件依赖**：\n  - `<linux/cgroup_dmem.h>`：dmem cgroup 的公共接口定义（如 `dmem_cgrp_id`）\n- **与其他子系统关系**：\n  - 类似 `rdma` 和 `misc` cgroup 控制器的设计模式\n  - 为设备驱动（如 GPU/NPU 驱动）提供内存配额管理接口\n\n## 使用场景\n\n- **设备内存资源隔离**：在多租户或容器化环境中，限制不同 cgroup 对专用设备内存（如 GPU 显存）的使用量。\n- **分级内存回收**：当设备内存不足时，驱动调用 `dmem_cgroup_state_evict_valuable()` 判断哪些 cgroup 的内存可安全释放，优先驱逐超出 `low` 限制的 cgroup，保护 `min` 限制内的关键任务。\n- **动态配额调整**：管理员可通过 cgroup 接口（如 `memory.dmem.*` 文件）动态调整各 cgroup 的 `min`/`low`/`max` 限制，实现灵活的资源调度。\n- **根 cgroup 默认行为**：未显式设置限制的 cgroup 继承根 cgroup 的默认策略（`max=PAGE_COUNTER_MAX`，无硬限制）。",
      "similarity": 0.5919989943504333,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/cgroup/dmem.c",
          "start_line": 106,
          "end_line": 209,
          "content": [
            "static void free_cg_pool(struct dmem_cgroup_pool_state *pool)",
            "{",
            "\tlist_del(&pool->region_node);",
            "\tkfree(pool);",
            "}",
            "static void",
            "set_resource_min(struct dmem_cgroup_pool_state *pool, u64 val)",
            "{",
            "\tpage_counter_set_min(&pool->cnt, val);",
            "}",
            "static void",
            "set_resource_low(struct dmem_cgroup_pool_state *pool, u64 val)",
            "{",
            "\tpage_counter_set_low(&pool->cnt, val);",
            "}",
            "static void",
            "set_resource_max(struct dmem_cgroup_pool_state *pool, u64 val)",
            "{",
            "\tpage_counter_set_max(&pool->cnt, val);",
            "}",
            "static u64 get_resource_low(struct dmem_cgroup_pool_state *pool)",
            "{",
            "\treturn pool ? READ_ONCE(pool->cnt.low) : 0;",
            "}",
            "static u64 get_resource_min(struct dmem_cgroup_pool_state *pool)",
            "{",
            "\treturn pool ? READ_ONCE(pool->cnt.min) : 0;",
            "}",
            "static u64 get_resource_max(struct dmem_cgroup_pool_state *pool)",
            "{",
            "\treturn pool ? READ_ONCE(pool->cnt.max) : PAGE_COUNTER_MAX;",
            "}",
            "static u64 get_resource_current(struct dmem_cgroup_pool_state *pool)",
            "{",
            "\treturn pool ? page_counter_read(&pool->cnt) : 0;",
            "}",
            "static void reset_all_resource_limits(struct dmem_cgroup_pool_state *rpool)",
            "{",
            "\tset_resource_min(rpool, 0);",
            "\tset_resource_low(rpool, 0);",
            "\tset_resource_max(rpool, PAGE_COUNTER_MAX);",
            "}",
            "static void dmemcs_offline(struct cgroup_subsys_state *css)",
            "{",
            "\tstruct dmemcg_state *dmemcs = css_to_dmemcs(css);",
            "\tstruct dmem_cgroup_pool_state *pool;",
            "",
            "\trcu_read_lock();",
            "\tlist_for_each_entry_rcu(pool, &dmemcs->pools, css_node)",
            "\t\treset_all_resource_limits(pool);",
            "\trcu_read_unlock();",
            "}",
            "static void dmemcs_free(struct cgroup_subsys_state *css)",
            "{",
            "\tstruct dmemcg_state *dmemcs = css_to_dmemcs(css);",
            "\tstruct dmem_cgroup_pool_state *pool, *next;",
            "",
            "\tspin_lock(&dmemcg_lock);",
            "\tlist_for_each_entry_safe(pool, next, &dmemcs->pools, css_node) {",
            "\t\t/*",
            "\t\t *The pool is dead and all references are 0,",
            "\t\t * no need for RCU protection with list_del_rcu or freeing.",
            "\t\t */",
            "\t\tlist_del(&pool->css_node);",
            "\t\tfree_cg_pool(pool);",
            "\t}",
            "\tspin_unlock(&dmemcg_lock);",
            "",
            "\tkfree(dmemcs);",
            "}",
            "static void",
            "dmem_cgroup_calculate_protection(struct dmem_cgroup_pool_state *limit_pool,",
            "\t\t\t\t struct dmem_cgroup_pool_state *test_pool)",
            "{",
            "\tstruct page_counter *climit;",
            "\tstruct cgroup_subsys_state *css;",
            "\tstruct dmemcg_state *dmemcg_iter;",
            "\tstruct dmem_cgroup_pool_state *pool, *found_pool;",
            "",
            "\tclimit = &limit_pool->cnt;",
            "",
            "\trcu_read_lock();",
            "",
            "\tcss_for_each_descendant_pre(css, &limit_pool->cs->css) {",
            "\t\tdmemcg_iter = container_of(css, struct dmemcg_state, css);",
            "\t\tfound_pool = NULL;",
            "",
            "\t\tlist_for_each_entry_rcu(pool, &dmemcg_iter->pools, css_node) {",
            "\t\t\tif (pool->region == limit_pool->region) {",
            "\t\t\t\tfound_pool = pool;",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t}",
            "\t\tif (!found_pool)",
            "\t\t\tcontinue;",
            "",
            "\t\tpage_counter_calculate_protection(",
            "\t\t\tclimit, &found_pool->cnt, true);",
            "",
            "\t\tif (found_pool == test_pool)",
            "\t\t\tbreak;",
            "\t}",
            "\trcu_read_unlock();",
            "}"
          ],
          "function_name": "free_cg_pool, set_resource_min, set_resource_low, set_resource_max, get_resource_low, get_resource_min, get_resource_max, get_resource_current, reset_all_resource_limits, dmemcs_offline, dmemcs_free, dmem_cgroup_calculate_protection",
          "description": "实现内存池释放逻辑（free_cg_pool）及资源限制设置/获取接口（set_resource_* / get_resource_*）；通过RCU和自旋锁保护池生命周期管理；处理cgroup卸载时的资源重置（dmemcs_offline）和彻底销毁（dmemcs_free）；计算层级保护策略（dmem_cgroup_calculate_protection）",
          "similarity": 0.5516078472137451
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/cgroup/dmem.c",
          "start_line": 731,
          "end_line": 784,
          "content": [
            "static int dmemcg_limit_show(struct seq_file *sf, void *v,",
            "\t\t\t    u64 (*fn)(struct dmem_cgroup_pool_state *))",
            "{",
            "\tstruct dmemcg_state *dmemcs = css_to_dmemcs(seq_css(sf));",
            "\tstruct dmem_cgroup_region *region;",
            "",
            "\trcu_read_lock();",
            "\tlist_for_each_entry_rcu(region, &dmem_cgroup_regions, region_node) {",
            "\t\tstruct dmem_cgroup_pool_state *pool = find_cg_pool_locked(dmemcs, region);",
            "\t\tu64 val;",
            "",
            "\t\tseq_puts(sf, region->name);",
            "",
            "\t\tval = fn(pool);",
            "\t\tif (val < PAGE_COUNTER_MAX)",
            "\t\t\tseq_printf(sf, \" %lld\\n\", val);",
            "\t\telse",
            "\t\t\tseq_puts(sf, \" max\\n\");",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\treturn 0;",
            "}",
            "static int dmem_cgroup_region_current_show(struct seq_file *sf, void *v)",
            "{",
            "\treturn dmemcg_limit_show(sf, v, get_resource_current);",
            "}",
            "static int dmem_cgroup_region_min_show(struct seq_file *sf, void *v)",
            "{",
            "\treturn dmemcg_limit_show(sf, v, get_resource_min);",
            "}",
            "static ssize_t dmem_cgroup_region_min_write(struct kernfs_open_file *of,",
            "\t\t\t\t      char *buf, size_t nbytes, loff_t off)",
            "{",
            "\treturn dmemcg_limit_write(of, buf, nbytes, off, set_resource_min);",
            "}",
            "static int dmem_cgroup_region_low_show(struct seq_file *sf, void *v)",
            "{",
            "\treturn dmemcg_limit_show(sf, v, get_resource_low);",
            "}",
            "static ssize_t dmem_cgroup_region_low_write(struct kernfs_open_file *of,",
            "\t\t\t\t      char *buf, size_t nbytes, loff_t off)",
            "{",
            "\treturn dmemcg_limit_write(of, buf, nbytes, off, set_resource_low);",
            "}",
            "static int dmem_cgroup_region_max_show(struct seq_file *sf, void *v)",
            "{",
            "\treturn dmemcg_limit_show(sf, v, get_resource_max);",
            "}",
            "static ssize_t dmem_cgroup_region_max_write(struct kernfs_open_file *of,",
            "\t\t\t\t      char *buf, size_t nbytes, loff_t off)",
            "{",
            "\treturn dmemcg_limit_write(of, buf, nbytes, off, set_resource_max);",
            "}"
          ],
          "function_name": "dmemcg_limit_show, dmem_cgroup_region_current_show, dmem_cgroup_region_min_show, dmem_cgroup_region_min_write, dmem_cgroup_region_low_show, dmem_cgroup_region_low_write, dmem_cgroup_region_max_show, dmem_cgroup_region_max_write",
          "description": "实现内存限制属性展示接口（dmemcg_limit_show系列）用于序列化输出；通过统一接口暴露当前值（get_resource_current）、最小值（get_resource_min）、低水位（get_resource_low）和最大值（get_resource_max）；提供限制参数写入接口（dmem_cgroup_region_min_write等）支持动态调整",
          "similarity": 0.5133496522903442
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/cgroup/dmem.c",
          "start_line": 572,
          "end_line": 704,
          "content": [
            "void dmem_cgroup_uncharge(struct dmem_cgroup_pool_state *pool, u64 size)",
            "{",
            "\tif (!pool)",
            "\t\treturn;",
            "",
            "\tpage_counter_uncharge(&pool->cnt, size);",
            "\tcss_put(&pool->cs->css);",
            "}",
            "int dmem_cgroup_try_charge(struct dmem_cgroup_region *region, u64 size,",
            "\t\t\t  struct dmem_cgroup_pool_state **ret_pool,",
            "\t\t\t  struct dmem_cgroup_pool_state **ret_limit_pool)",
            "{",
            "\tstruct dmemcg_state *cg;",
            "\tstruct dmem_cgroup_pool_state *pool;",
            "\tstruct page_counter *fail;",
            "\tint ret;",
            "",
            "\t*ret_pool = NULL;",
            "\tif (ret_limit_pool)",
            "\t\t*ret_limit_pool = NULL;",
            "",
            "\t/*",
            "\t * hold on to css, as cgroup can be removed but resource",
            "\t * accounting happens on css.",
            "\t */",
            "\tcg = get_current_dmemcs();",
            "",
            "\tpool = get_cg_pool_unlocked(cg, region);",
            "\tif (IS_ERR(pool)) {",
            "\t\tret = PTR_ERR(pool);",
            "\t\tgoto err;",
            "\t}",
            "",
            "\tif (!page_counter_try_charge(&pool->cnt, size, &fail)) {",
            "\t\tif (ret_limit_pool) {",
            "\t\t\t*ret_limit_pool = container_of(fail, struct dmem_cgroup_pool_state, cnt);",
            "\t\t\tcss_get(&(*ret_limit_pool)->cs->css);",
            "\t\t}",
            "\t\tret = -EAGAIN;",
            "\t\tgoto err;",
            "\t}",
            "",
            "\t/* On success, reference from get_current_dmemcs is transferred to *ret_pool */",
            "\t*ret_pool = pool;",
            "\treturn 0;",
            "",
            "err:",
            "\tcss_put(&cg->css);",
            "\treturn ret;",
            "}",
            "static int dmem_cgroup_region_capacity_show(struct seq_file *sf, void *v)",
            "{",
            "\tstruct dmem_cgroup_region *region;",
            "",
            "\trcu_read_lock();",
            "\tlist_for_each_entry_rcu(region, &dmem_cgroup_regions, region_node) {",
            "\t\tseq_puts(sf, region->name);",
            "\t\tseq_printf(sf, \" %llu\\n\", region->size);",
            "\t}",
            "\trcu_read_unlock();",
            "\treturn 0;",
            "}",
            "static int dmemcg_parse_limit(char *options, struct dmem_cgroup_region *region,",
            "\t\t\t      u64 *new_limit)",
            "{",
            "\tchar *end;",
            "",
            "\tif (!strcmp(options, \"max\")) {",
            "\t\t*new_limit = PAGE_COUNTER_MAX;",
            "\t\treturn 0;",
            "\t}",
            "",
            "\t*new_limit = memparse(options, &end);",
            "\tif (*end != '\\0')",
            "\t\treturn -EINVAL;",
            "",
            "\treturn 0;",
            "}",
            "static ssize_t dmemcg_limit_write(struct kernfs_open_file *of,",
            "\t\t\t\t char *buf, size_t nbytes, loff_t off,",
            "\t\t\t\t void (*apply)(struct dmem_cgroup_pool_state *, u64))",
            "{",
            "\tstruct dmemcg_state *dmemcs = css_to_dmemcs(of_css(of));",
            "\tint err = 0;",
            "",
            "\twhile (buf && !err) {",
            "\t\tstruct dmem_cgroup_pool_state *pool = NULL;",
            "\t\tchar *options, *region_name;",
            "\t\tstruct dmem_cgroup_region *region;",
            "\t\tu64 new_limit;",
            "",
            "\t\toptions = buf;",
            "\t\tbuf = strchr(buf, '\\n');",
            "\t\tif (buf)",
            "\t\t\t*buf++ = '\\0';",
            "",
            "\t\toptions = strstrip(options);",
            "",
            "\t\t/* eat empty lines */",
            "\t\tif (!options[0])",
            "\t\t\tcontinue;",
            "",
            "\t\tregion_name = strsep(&options, \" \\t\");",
            "\t\tif (!region_name[0])",
            "\t\t\tcontinue;",
            "",
            "\t\trcu_read_lock();",
            "\t\tregion = dmemcg_get_region_by_name(region_name);",
            "\t\trcu_read_unlock();",
            "",
            "\t\tif (!region)",
            "\t\t\treturn -EINVAL;",
            "",
            "\t\terr = dmemcg_parse_limit(options, region, &new_limit);",
            "\t\tif (err < 0)",
            "\t\t\tgoto out_put;",
            "",
            "\t\tpool = get_cg_pool_unlocked(dmemcs, region);",
            "\t\tif (IS_ERR(pool)) {",
            "\t\t\terr = PTR_ERR(pool);",
            "\t\t\tgoto out_put;",
            "\t\t}",
            "",
            "\t\t/* And commit */",
            "\t\tapply(pool, new_limit);",
            "",
            "out_put:",
            "\t\tkref_put(&region->ref, dmemcg_free_region);",
            "\t}",
            "",
            "",
            "\treturn err ?: nbytes;",
            "}"
          ],
          "function_name": "dmem_cgroup_uncharge, dmem_cgroup_try_charge, dmem_cgroup_region_capacity_show, dmemcg_parse_limit, dmemcg_limit_write",
          "description": "实现内存扣费操作（dmem_cgroup_uncharge）及带检查的扣费尝试（dmem_cgroup_try_charge）；提供区域容量展示接口（dmem_cgroup_region_capacity_show）；解析限制参数（dmemcg_parse_limit）并应用到指定区域池（dmemcg_limit_write）",
          "similarity": 0.49542468786239624
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/cgroup/dmem.c",
          "start_line": 267,
          "end_line": 367,
          "content": [
            "bool dmem_cgroup_state_evict_valuable(struct dmem_cgroup_pool_state *limit_pool,",
            "\t\t\t\t      struct dmem_cgroup_pool_state *test_pool,",
            "\t\t\t\t      bool ignore_low, bool *ret_hit_low)",
            "{",
            "\tstruct dmem_cgroup_pool_state *pool = test_pool;",
            "\tstruct page_counter *climit, *ctest;",
            "\tu64 used, min, low;",
            "",
            "\t/* Can always evict from current pool, despite limits */",
            "\tif (limit_pool == test_pool)",
            "\t\treturn true;",
            "",
            "\tif (limit_pool) {",
            "\t\tif (!parent_dmemcs(limit_pool->cs))",
            "\t\t\treturn true;",
            "",
            "\t\tfor (pool = test_pool; pool && limit_pool != pool; pool = pool_parent(pool))",
            "\t\t\t{}",
            "",
            "\t\tif (!pool)",
            "\t\t\treturn false;",
            "\t} else {",
            "\t\t/*",
            "\t\t * If there is no cgroup limiting memory usage, use the root",
            "\t\t * cgroup instead for limit calculations.",
            "\t\t */",
            "\t\tfor (limit_pool = test_pool; pool_parent(limit_pool); limit_pool = pool_parent(limit_pool))",
            "\t\t\t{}",
            "\t}",
            "",
            "\tclimit = &limit_pool->cnt;",
            "\tctest = &test_pool->cnt;",
            "",
            "\tdmem_cgroup_calculate_protection(limit_pool, test_pool);",
            "",
            "\tused = page_counter_read(ctest);",
            "\tmin = READ_ONCE(ctest->emin);",
            "",
            "\tif (used <= min)",
            "\t\treturn false;",
            "",
            "\tif (!ignore_low) {",
            "\t\tlow = READ_ONCE(ctest->elow);",
            "\t\tif (used > low)",
            "\t\t\treturn true;",
            "",
            "\t\t*ret_hit_low = true;",
            "\t\treturn false;",
            "\t}",
            "\treturn true;",
            "}",
            "static void dmemcg_free_rcu(struct rcu_head *rcu)",
            "{",
            "\tstruct dmem_cgroup_region *region = container_of(rcu, typeof(*region), rcu);",
            "\tstruct dmem_cgroup_pool_state *pool, *next;",
            "",
            "\tlist_for_each_entry_safe(pool, next, &region->pools, region_node)",
            "\t\tfree_cg_pool(pool);",
            "\tkfree(region->name);",
            "\tkfree(region);",
            "}",
            "static void dmemcg_free_region(struct kref *ref)",
            "{",
            "\tstruct dmem_cgroup_region *cgregion = container_of(ref, typeof(*cgregion), ref);",
            "",
            "\tcall_rcu(&cgregion->rcu, dmemcg_free_rcu);",
            "}",
            "void dmem_cgroup_unregister_region(struct dmem_cgroup_region *region)",
            "{",
            "\tstruct list_head *entry;",
            "",
            "\tif (!region)",
            "\t\treturn;",
            "",
            "\tspin_lock(&dmemcg_lock);",
            "",
            "\t/* Remove from global region list */",
            "\tlist_del_rcu(&region->region_node);",
            "",
            "\tlist_for_each_rcu(entry, &region->pools) {",
            "\t\tstruct dmem_cgroup_pool_state *pool =",
            "\t\t\tcontainer_of(entry, typeof(*pool), region_node);",
            "",
            "\t\tlist_del_rcu(&pool->css_node);",
            "\t}",
            "",
            "\t/*",
            "\t * Ensure any RCU based lookups fail. Additionally,",
            "\t * no new pools should be added to the dead region",
            "\t * by get_cg_pool_unlocked.",
            "\t */",
            "\tregion->unregistered = true;",
            "\tspin_unlock(&dmemcg_lock);",
            "",
            "\tkref_put(&region->ref, dmemcg_free_region);",
            "}",
            "void dmem_cgroup_pool_state_put(struct dmem_cgroup_pool_state *pool)",
            "{",
            "\tif (pool)",
            "\t\tcss_put(&pool->cs->css);",
            "}"
          ],
          "function_name": "dmem_cgroup_state_evict_valuable, dmemcg_free_rcu, dmemcg_free_region, dmem_cgroup_unregister_region, dmem_cgroup_pool_state_put",
          "description": "实现内存可驱逐性判定（dmem_cgroup_state_evict_valuable）；通过RCU异步释放内存区域相关资源（dmemcg_free_rcu/dmemcg_free_region）；提供区域注销接口（dmem_cgroup_unregister_region）标记区域无效并触发动态清理；实现池状态引用计数管理（dmem_cgroup_pool_state_put）",
          "similarity": 0.4942406713962555
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/cgroup/dmem.c",
          "start_line": 1,
          "end_line": 105,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright 2023-2024 Intel Corporation (Maarten Lankhorst <dev@lankhorst.se>)",
            " * Copyright 2024 Red Hat (Maxime Ripard <mripard@kernel.org>)",
            " * Partially based on the rdma and misc controllers, which bear the following copyrights:",
            " *",
            " * Copyright 2020 Google LLC",
            " * Copyright (C) 2016 Parav Pandit <pandit.parav@gmail.com>",
            " */",
            "",
            "#include <linux/cgroup.h>",
            "#include <linux/cgroup_dmem.h>",
            "#include <linux/list.h>",
            "#include <linux/mutex.h>",
            "#include <linux/page_counter.h>",
            "#include <linux/parser.h>",
            "#include <linux/slab.h>",
            "",
            "struct dmem_cgroup_region {",
            "\t/**",
            "\t * @ref: References keeping the region alive.",
            "\t * Keeps the region reference alive after a succesful RCU lookup.",
            "\t */",
            "\tstruct kref ref;",
            "",
            "\t/** @rcu: RCU head for freeing */",
            "\tstruct rcu_head rcu;",
            "",
            "\t/**",
            "\t * @region_node: Linked into &dmem_cgroup_regions list.",
            "\t * Protected by RCU and global spinlock.",
            "\t */",
            "\tstruct list_head region_node;",
            "",
            "\t/**",
            "\t * @pools: List of pools linked to this region.",
            "\t * Protected by global spinlock only",
            "\t */",
            "\tstruct list_head pools;",
            "",
            "\t/** @size: Size of region, in bytes */",
            "\tu64 size;",
            "",
            "\t/** @name: Name describing the node, set by dmem_cgroup_register_region */",
            "\tchar *name;",
            "",
            "\t/**",
            "\t * @unregistered: Whether the region is unregistered by its caller.",
            "\t * No new pools should be added to the region afterwards.",
            "\t */",
            "\tbool unregistered;",
            "};",
            "",
            "struct dmemcg_state {",
            "\tstruct cgroup_subsys_state css;",
            "",
            "\tstruct list_head pools;",
            "};",
            "",
            "struct dmem_cgroup_pool_state {",
            "\tstruct dmem_cgroup_region *region;",
            "\tstruct dmemcg_state *cs;",
            "",
            "\t/* css node, RCU protected against region teardown */",
            "\tstruct list_head\tcss_node;",
            "",
            "\t/* dev node, no RCU protection required */",
            "\tstruct list_head\tregion_node;",
            "",
            "\tstruct rcu_head rcu;",
            "",
            "\tstruct page_counter cnt;",
            "",
            "\tbool inited;",
            "};",
            "",
            "/*",
            " * 3 operations require locking protection:",
            " * - Registering and unregistering region to/from list, requires global lock.",
            " * - Adding a dmem_cgroup_pool_state to a CSS, removing when CSS is freed.",
            " * - Adding a dmem_cgroup_pool_state to a region list.",
            " *",
            " * Since for the most common operations RCU provides enough protection, I",
            " * do not think more granular locking makes sense. Most protection is offered",
            " * by RCU and the lockless operating page_counter.",
            " */",
            "static DEFINE_SPINLOCK(dmemcg_lock);",
            "static LIST_HEAD(dmem_cgroup_regions);",
            "",
            "static inline struct dmemcg_state *",
            "css_to_dmemcs(struct cgroup_subsys_state *css)",
            "{",
            "\treturn container_of(css, struct dmemcg_state, css);",
            "}",
            "",
            "static inline struct dmemcg_state *get_current_dmemcs(void)",
            "{",
            "\treturn css_to_dmemcs(task_get_css(current, dmem_cgrp_id));",
            "}",
            "",
            "static struct dmemcg_state *parent_dmemcs(struct dmemcg_state *cg)",
            "{",
            "\treturn cg->css.parent ? css_to_dmemcs(cg->css.parent) : NULL;",
            "}",
            ""
          ],
          "function_name": null,
          "description": "定义dmem_cgroup_region结构体，用于管理内存区域及其关联的池列表、大小、名称和注册状态；定义dmemcg_state结构体，作为cgroup子系统状态扩展；定义dmem_cgroup_pool_state结构体，保存池状态、计数器及链接节点；声明全局锁和链表头以协调多线程访问；提供css到dmemcg_state的转换函数",
          "similarity": 0.45351192355155945
        }
      ]
    }
  ]
}