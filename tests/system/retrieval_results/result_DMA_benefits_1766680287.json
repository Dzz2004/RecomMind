{
  "query": "DMA benefits",
  "timestamp": "2025-12-26 00:31:27",
  "retrieved_files": [
    {
      "source_file": "kernel/dma/pool.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:15:49\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `dma\\pool.c`\n\n---\n\n# `dma/pool.c` 技术文档\n\n## 1. 文件概述\n\n`dma/pool.c` 实现了 Linux 内核中的 **DMA 原子内存池（atomic DMA pools）** 机制，用于在无法睡眠的上下文（如中断处理、原子上下文）中分配一致性（coherent）DMA 内存。该机制通过预分配多个按内存区域（ZONE_DMA、ZONE_DMA32、普通内核内存）划分的通用内存池（`gen_pool`），并在池空间不足时通过工作队列异步扩展，从而支持在 GFP_ATOMIC 等限制性分配标志下安全地分配 DMA 内存。\n\n该文件主要用于支持 `dma-direct` 子系统中的原子 DMA 分配路径，确保即使在内存压力大或无法睡眠的场景下，设备驱动仍能获得满足地址限制（如 32 位或 24 位寻址）的一致性 DMA 缓冲区。\n\n## 2. 核心功能\n\n### 全局变量\n- `atomic_pool_dma` / `pool_size_dma`：用于 `GFP_DMA` 区域的原子 DMA 池及其已分配大小。\n- `atomic_pool_dma32` / `pool_size_dma32`：用于 `GFP_DMA32` 区域的原子 DMA 池及其已分配大小。\n- `atomic_pool_kernel` / `pool_size_kernel`：用于普通内核区域（无特殊 DMA 限制）的原子 DMA 池及其已分配大小。\n- `atomic_pool_size`：每个池的初始目标大小，可通过内核命令行参数 `coherent_pool=` 设置。\n- `atomic_pool_work`：用于后台动态扩展内存池的工作项。\n\n### 主要函数\n- `early_coherent_pool()`：解析内核命令行参数 `coherent_pool`，设置 `atomic_pool_size`。\n- `dma_atomic_pool_init()`：初始化所有原子 DMA 池（postcore 阶段调用）。\n- `__dma_atomic_pool_init()`：创建并填充指定 GFP 标志的原子池。\n- `atomic_pool_expand()`：向指定池中添加一块连续物理内存。\n- `atomic_pool_resize()` / `atomic_pool_work_fn()`：检查池剩余空间，若不足则触发扩展。\n- `dma_alloc_from_pool()`：从合适的原子池中分配指定大小的 DMA 内存。\n- `dma_free_from_pool()`：将内存归还到对应的原子池。\n- `dma_guess_pool()`：根据 GFP 标志和尝试顺序选择合适的内存池。\n- `cma_in_zone()`：判断 CMA 区域是否位于指定 DMA 区域内，以决定是否优先从 CMA 分配。\n- `dma_atomic_pool_debugfs_init()`：在 debugfs 中导出各池的当前大小。\n\n## 3. 关键实现\n\n### 内存池初始化策略\n- 若未通过 `coherent_pool=` 指定大小，则默认按 **每 1GB 物理内存分配 128KB** 原子池，最小 128KB，最大不超过 `MAX_ORDER_NR_PAGES` 对应的内存。\n- 每个池使用 `gen_pool` 管理，分配算法为 `gen_pool_first_fit_order_align`，保证分配地址按页对齐。\n- 初始化时调用 `atomic_pool_expand()` 预分配内存。\n\n### 内存分配来源\n- 优先尝试从 **CMA（Contiguous Memory Allocator）** 区域分配（若 CMA 区域位于目标 DMA zone 内）。\n- 若 CMA 不可用或不在目标 zone，则回退到 `alloc_pages()`。\n- 分配的内存块大小不超过 `MAX_PAGE_ORDER`，通过降序尝试（从大到小）提高分配成功率。\n\n### 内存属性处理\n- 调用 `arch_dma_prep_coherent()` 通知架构层准备一致性内存。\n- 在支持内存加密（如 AMD SEV、Intel TDX）的系统上，显式调用 `set_memory_decrypted()` 确保 DMA 内存为 **未加密状态**，因为设备无法访问加密内存。\n- 若启用了 `CONFIG_DMA_DIRECT_REMAP`，则通过 `dma_common_contiguous_remap()` 建立非缓存或设备专用的页表映射。\n\n### 动态扩展机制\n- 每次从池中分配内存后，检查剩余空间是否小于 `atomic_pool_size`。\n- 若不足，则调度 `atomic_pool_work` 工作项，在进程上下文中异步扩展对应池。\n- 扩展时尝试分配与当前池总大小相当的新内存块，避免频繁小量扩展。\n\n### 多池选择逻辑\n- `dma_guess_pool()` 实现池选择策略：\n  1. 首选与 GFP 标志匹配的池（DMA32 > DMA > 普通内核）。\n  2. 若首次分配失败，按 `kernel → dma32 → dma` 顺序尝试其他池（fallback 机制）。\n- 释放时遍历所有池，通过 `gen_pool_has_addr()` 确定内存归属。\n\n## 4. 依赖关系\n\n- **内存管理子系统**：\n  - 依赖 `genalloc`（`gen_pool`）实现内存池管理。\n  - 使用 `alloc_pages()`、`__free_pages()` 进行底层页分配。\n  - 依赖 CMA 接口（`dma_alloc_from_contiguous()`）获取大块连续内存。\n- **DMA 子系统**：\n  - 与 `dma-direct.c` 紧密集成，为其提供 `___dma_direct_alloc_pages()` 中的原子分配路径。\n  - 使用 `dma-map-ops.h` 和 `dma-direct.h` 中的辅助函数。\n- **架构相关支持**：\n  - 调用 `arch_dma_prep_coherent()`（架构可选实现）。\n  - 使用 `set_memory_decrypted()`/`set_memory_encrypted()`（x86/ARM64 等支持内存加密的架构）。\n  - 依赖 `DMA_BIT_MASK()` 和 `zone_dma_bits` 判断 DMA 地址范围。\n- **其他**：\n  - 使用 `debugfs` 导出调试信息。\n  - 依赖 `workqueue` 实现异步扩展。\n  - 使用 `slab.h` 中的内存分配器（间接）。\n\n## 5. 使用场景\n\n- **原子上下文 DMA 分配**：当设备驱动在中断处理程序、自旋锁保护区域或使用 `GFP_ATOMIC` 标志调用 `dma_alloc_coherent()` 时，若常规页分配器无法满足（如内存碎片），内核会回退到从原子池分配。\n- **满足地址限制的 DMA 缓冲区**：对于需要 24 位（ISA 设备）或 32 位（旧 PCIe 设备）寻址能力的设备，驱动使用 `DMA_BIT_MASK(24)` 或 `DMA_BIT_MASK(32)` 限制 DMA 地址范围，原子池确保分配的内存物理地址符合要求。\n- **一致性内存需求**：适用于需要 CPU 与设备之间缓存一致性的场景（如网络数据包缓冲区、音频流缓冲区），原子池分配的内存经过 `arch_dma_prep_coherent()` 处理，保证一致性。\n- **内存加密环境**：在启用内存加密的系统中，确保分配给设备的 DMA 内存处于解密状态，使设备能正常访问。",
      "similarity": 0.5082463026046753,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/dma/pool.c",
          "start_line": 29,
          "end_line": 138,
          "content": [
            "static int __init early_coherent_pool(char *p)",
            "{",
            "\tatomic_pool_size = memparse(p, &p);",
            "\treturn 0;",
            "}",
            "static void __init dma_atomic_pool_debugfs_init(void)",
            "{",
            "\tstruct dentry *root;",
            "",
            "\troot = debugfs_create_dir(\"dma_pools\", NULL);",
            "\tdebugfs_create_ulong(\"pool_size_dma\", 0400, root, &pool_size_dma);",
            "\tdebugfs_create_ulong(\"pool_size_dma32\", 0400, root, &pool_size_dma32);",
            "\tdebugfs_create_ulong(\"pool_size_kernel\", 0400, root, &pool_size_kernel);",
            "}",
            "static void dma_atomic_pool_size_add(gfp_t gfp, size_t size)",
            "{",
            "\tif (gfp & __GFP_DMA)",
            "\t\tpool_size_dma += size;",
            "\telse if (gfp & __GFP_DMA32)",
            "\t\tpool_size_dma32 += size;",
            "\telse",
            "\t\tpool_size_kernel += size;",
            "}",
            "static bool cma_in_zone(gfp_t gfp)",
            "{",
            "\tunsigned long size;",
            "\tphys_addr_t end;",
            "\tstruct cma *cma;",
            "",
            "\tcma = dev_get_cma_area(NULL);",
            "\tif (!cma)",
            "\t\treturn false;",
            "",
            "\tsize = cma_get_size(cma);",
            "\tif (!size)",
            "\t\treturn false;",
            "",
            "\t/* CMA can't cross zone boundaries, see cma_activate_area() */",
            "\tend = cma_get_base(cma) + size - 1;",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA) && (gfp & GFP_DMA))",
            "\t\treturn end <= DMA_BIT_MASK(zone_dma_bits);",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA32) && (gfp & GFP_DMA32))",
            "\t\treturn end <= DMA_BIT_MASK(32);",
            "\treturn true;",
            "}",
            "static int atomic_pool_expand(struct gen_pool *pool, size_t pool_size,",
            "\t\t\t      gfp_t gfp)",
            "{",
            "\tunsigned int order;",
            "\tstruct page *page = NULL;",
            "\tvoid *addr;",
            "\tint ret = -ENOMEM;",
            "",
            "\t/* Cannot allocate larger than MAX_PAGE_ORDER */",
            "\torder = min(get_order(pool_size), MAX_PAGE_ORDER);",
            "",
            "\tdo {",
            "\t\tpool_size = 1 << (PAGE_SHIFT + order);",
            "\t\tif (cma_in_zone(gfp))",
            "\t\t\tpage = dma_alloc_from_contiguous(NULL, 1 << order,",
            "\t\t\t\t\t\t\t order, false);",
            "\t\tif (!page)",
            "\t\t\tpage = alloc_pages(gfp, order);",
            "\t} while (!page && order-- > 0);",
            "\tif (!page)",
            "\t\tgoto out;",
            "",
            "\tarch_dma_prep_coherent(page, pool_size);",
            "",
            "#ifdef CONFIG_DMA_DIRECT_REMAP",
            "\taddr = dma_common_contiguous_remap(page, pool_size,",
            "\t\t\tpgprot_decrypted(pgprot_dmacoherent(PAGE_KERNEL)),",
            "\t\t\t__builtin_return_address(0));",
            "\tif (!addr)",
            "\t\tgoto free_page;",
            "#else",
            "\taddr = page_to_virt(page);",
            "#endif",
            "\t/*",
            "\t * Memory in the atomic DMA pools must be unencrypted, the pools do not",
            "\t * shrink so no re-encryption occurs in dma_direct_free().",
            "\t */",
            "\tret = set_memory_decrypted((unsigned long)page_to_virt(page),",
            "\t\t\t\t   1 << order);",
            "\tif (ret)",
            "\t\tgoto remove_mapping;",
            "\tret = gen_pool_add_virt(pool, (unsigned long)addr, page_to_phys(page),",
            "\t\t\t\tpool_size, NUMA_NO_NODE);",
            "\tif (ret)",
            "\t\tgoto encrypt_mapping;",
            "",
            "\tdma_atomic_pool_size_add(gfp, pool_size);",
            "\treturn 0;",
            "",
            "encrypt_mapping:",
            "\tret = set_memory_encrypted((unsigned long)page_to_virt(page),",
            "\t\t\t\t   1 << order);",
            "\tif (WARN_ON_ONCE(ret)) {",
            "\t\t/* Decrypt succeeded but encrypt failed, purposely leak */",
            "\t\tgoto out;",
            "\t}",
            "remove_mapping:",
            "#ifdef CONFIG_DMA_DIRECT_REMAP",
            "\tdma_common_free_remap(addr, pool_size);",
            "free_page:",
            "\t__free_pages(page, order);",
            "#endif",
            "out:",
            "\treturn ret;",
            "}"
          ],
          "function_name": "early_coherent_pool, dma_atomic_pool_debugfs_init, dma_atomic_pool_size_add, cma_in_zone, atomic_pool_expand",
          "description": "实现DMA内存池的动态扩展逻辑，包含解析命令行参数、调试接口注册、内存分配策略选择、CMA区域有效性检测及池扩容操作，支持加密/解密内存映射管理。",
          "similarity": 0.5005519986152649
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/dma/pool.c",
          "start_line": 1,
          "end_line": 28,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 2012 ARM Ltd.",
            " * Copyright (C) 2020 Google LLC",
            " */",
            "#include <linux/cma.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/dma-map-ops.h>",
            "#include <linux/dma-direct.h>",
            "#include <linux/init.h>",
            "#include <linux/genalloc.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "",
            "static struct gen_pool *atomic_pool_dma __ro_after_init;",
            "static unsigned long pool_size_dma;",
            "static struct gen_pool *atomic_pool_dma32 __ro_after_init;",
            "static unsigned long pool_size_dma32;",
            "static struct gen_pool *atomic_pool_kernel __ro_after_init;",
            "static unsigned long pool_size_kernel;",
            "",
            "/* Size can be defined by the coherent_pool command line */",
            "static size_t atomic_pool_size;",
            "",
            "/* Dynamic background expansion when the atomic pool is near capacity */",
            "static struct work_struct atomic_pool_work;",
            ""
          ],
          "function_name": null,
          "description": "定义并初始化用于管理DMA内存池的全局变量，包括针对不同架构（DMA/DMA32/内核）的通用池指针、尺寸参数及动态扩展的工作队列。",
          "similarity": 0.42841076850891113
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/dma/pool.c",
          "start_line": 145,
          "end_line": 207,
          "content": [
            "static void atomic_pool_resize(struct gen_pool *pool, gfp_t gfp)",
            "{",
            "\tif (pool && gen_pool_avail(pool) < atomic_pool_size)",
            "\t\tatomic_pool_expand(pool, gen_pool_size(pool), gfp);",
            "}",
            "static void atomic_pool_work_fn(struct work_struct *work)",
            "{",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA))",
            "\t\tatomic_pool_resize(atomic_pool_dma,",
            "\t\t\t\t   GFP_KERNEL | GFP_DMA);",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA32))",
            "\t\tatomic_pool_resize(atomic_pool_dma32,",
            "\t\t\t\t   GFP_KERNEL | GFP_DMA32);",
            "\tatomic_pool_resize(atomic_pool_kernel, GFP_KERNEL);",
            "}",
            "static int __init dma_atomic_pool_init(void)",
            "{",
            "\tint ret = 0;",
            "",
            "\t/*",
            "\t * If coherent_pool was not used on the command line, default the pool",
            "\t * sizes to 128KB per 1GB of memory, min 128KB, max MAX_PAGE_ORDER.",
            "\t */",
            "\tif (!atomic_pool_size) {",
            "\t\tunsigned long pages = totalram_pages() / (SZ_1G / SZ_128K);",
            "\t\tpages = min_t(unsigned long, pages, MAX_ORDER_NR_PAGES);",
            "\t\tatomic_pool_size = max_t(size_t, pages << PAGE_SHIFT, SZ_128K);",
            "\t}",
            "\tINIT_WORK(&atomic_pool_work, atomic_pool_work_fn);",
            "",
            "\tatomic_pool_kernel = __dma_atomic_pool_init(atomic_pool_size,",
            "\t\t\t\t\t\t    GFP_KERNEL);",
            "\tif (!atomic_pool_kernel)",
            "\t\tret = -ENOMEM;",
            "\tif (has_managed_dma()) {",
            "\t\tatomic_pool_dma = __dma_atomic_pool_init(atomic_pool_size,",
            "\t\t\t\t\t\tGFP_KERNEL | GFP_DMA);",
            "\t\tif (!atomic_pool_dma)",
            "\t\t\tret = -ENOMEM;",
            "\t}",
            "\tif (IS_ENABLED(CONFIG_ZONE_DMA32)) {",
            "\t\tatomic_pool_dma32 = __dma_atomic_pool_init(atomic_pool_size,",
            "\t\t\t\t\t\tGFP_KERNEL | GFP_DMA32);",
            "\t\tif (!atomic_pool_dma32)",
            "\t\t\tret = -ENOMEM;",
            "\t}",
            "",
            "\tdma_atomic_pool_debugfs_init();",
            "\treturn ret;",
            "}",
            "bool dma_free_from_pool(struct device *dev, void *start, size_t size)",
            "{",
            "\tstruct gen_pool *pool = NULL;",
            "",
            "\twhile ((pool = dma_guess_pool(pool, 0))) {",
            "\t\tif (!gen_pool_has_addr(pool, (unsigned long)start, size))",
            "\t\t\tcontinue;",
            "\t\tgen_pool_free(pool, (unsigned long)start, size);",
            "\t\treturn true;",
            "\t}",
            "",
            "\treturn false;",
            "}"
          ],
          "function_name": "atomic_pool_resize, atomic_pool_work_fn, dma_atomic_pool_init, dma_free_from_pool",
          "description": "实现内存池的初始化与维护机制，包含池大小自动调节逻辑、后台扩展任务调度、默认尺寸计算及内存释放查找功能，提供设备内存池的统一管理接口。",
          "similarity": 0.3382790982723236
        }
      ]
    },
    {
      "source_file": "kernel/dma/mapping.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:14:22\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `dma\\mapping.c`\n\n---\n\n# `dma/mapping.c` 技术文档\n\n## 1. 文件概述\n\n`dma/mapping.c` 是 Linux 内核中与架构无关的 DMA（Direct Memory Access）映射核心实现文件。该文件提供了统一的、可管理的 DMA 内存分配与映射接口，屏蔽了底层硬件（如 IOMMU、直接映射等）的差异，为驱动开发者提供一致的 DMA 操作抽象。同时，它支持“资源管理”（Managed DMA）机制，确保在设备卸载时自动释放 DMA 资源，防止内存泄漏。\n\n## 2. 核心功能\n\n### 主要数据结构\n- **`struct dma_devres`**  \n  用于实现“Managed DMA”资源管理的私有结构体，包含：\n  - `size`：分配的内存大小\n  - `vaddr`：内核虚拟地址\n  - `dma_handle`：设备可见的 DMA 地址\n  - `attrs`：DMA 属性标志（如 `DMA_ATTR_*`）\n\n### 主要函数\n- **Managed DMA 接口**\n  - `dmam_alloc_attrs()`：分配受管理的 DMA 内存（自动释放）\n  - `dmam_free_coherent()`：显式释放受管理的 coherent DMA 内存（通常由 devres 自动调用）\n\n- **DMA 映射/解映射接口**\n  - `dma_map_page_attrs()`：将单个页面映射为 DMA 地址\n  - `dma_unmap_page_attrs()`：解映射单个页面的 DMA 地址\n  - `dma_map_sg_attrs()`：映射 scatterlist 缓冲区（返回成功映射的条目数）\n  - `dma_map_sgtable()`：映射 `sg_table` 结构描述的缓冲区（返回错误码）\n\n- **内部辅助函数**\n  - `dma_go_direct()` / `dma_alloc_direct()` / `dma_map_direct()`：判断是否可绕过 IOMMU 使用直接映射\n  - `__dma_map_sg_attrs()`：`dma_map_sg_attrs()` 和 `dma_map_sgtable()` 的公共实现\n\n## 3. 关键实现\n\n### Managed DMA 资源管理机制\n- 使用 `devres`（Device Resource Management）框架实现自动资源回收。\n- `dmam_alloc_attrs()` 在分配 DMA 内存后，将 `dma_devres` 结构注册到设备的资源链表中。\n- 设备卸载时，`devres` 框架自动调用 `dmam_release()`，进而调用 `dma_free_attrs()` 释放内存。\n- `dmam_match()` 用于在显式释放时匹配资源条目，确保一致性。\n\n### 直接映射（Direct Mapping）优化\n- 通过 `dma_go_direct()` 判断是否可跳过 IOMMU 操作：\n  - 若设备无自定义 `dma_map_ops`，默认使用直接映射。\n  - 若启用 `CONFIG_DMA_OPS_BYPASS` 且设备设置 `dma_ops_bypass`，且 DMA 掩码足够大（覆盖物理地址空间），则使用直接映射。\n- 直接映射路径调用 `dma_direct_*` 系列函数（定义在 `direct.h` 中），避免 IOMMU 开销。\n\n### 错误处理与调试支持\n- 所有映射函数均校验 DMA 方向（`valid_dma_direction`）和设备 DMA 掩码。\n- 集成 `KMSAN`（Kernel Memory Sanitizer）支持，通过 `kmsan_handle_dma*` 标记 DMA 访问区域。\n- 启用 `DMA_API_DEBUG` 时，调用 `debug_dma_*` 函数记录映射操作，用于检测错误使用（如未映射即访问）。\n\n### Scatterlist 映射语义\n- `dma_map_sg_attrs()` 返回实际映射成功的条目数（可能 ≤ `nents`），但**解映射必须使用原始 `nents`**。\n- `dma_map_sgtable()` 返回标准错误码（如 `-ENOMEM`, `-EINVAL`），便于错误分类和重试逻辑。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/dma-map-ops.h>`：DMA 操作集抽象（`dma_map_ops`）\n  - `<linux/devres.h>`（隐式）：设备资源管理框架\n  - `\"direct.h\"`：直接映射实现（`dma_direct_map_page` 等）\n  - `\"debug.h\"`：DMA 调试接口\n- **配置依赖**：\n  - `CONFIG_ARCH_HAS_SYNC_DMA_*`：决定是否定义 `dma_default_coherent`\n  - `CONFIG_DMA_OPS_BYPASS`：启用 DMA 操作绕过优化\n  - `CONFIG_ARCH_DMA_DEFAULT_COHERENT`：设置默认一致性属性\n- **底层依赖**：\n  - 架构特定的 `arch_dma_*_direct()` 函数（用于判断直接映射可行性）\n  - IOMMU 驱动提供的 `dma_map_ops` 实现（当不使用直接映射时）\n\n## 5. 使用场景\n\n- **驱动开发**：\n  - 使用 `dmam_alloc_attrs()` 分配 DMA 缓冲区，避免手动释放。\n  - 使用 `dma_map_page_attrs()` 或 `dma_map_sg_attrs()` 映射数据缓冲区供设备访问。\n- **IOMMU 子系统**：\n  - IOMMU 驱动通过注册 `dma_map_ops` 拦截映射请求，实现地址转换和权限控制。\n  - 当设备 DMA 能力足够时（如 64 位 DMA 掩码），自动切换至直接映射以提升性能。\n- **内存调试**：\n  - 与 KMSAN 集成，在 DMA 操作前后标记内存状态，检测 CPU/DMA 访问冲突。\n  - 通过 `DMA_API_DEBUG` 捕获驱动错误（如重复映射、方向错误等）。",
      "similarity": 0.5044281482696533,
      "chunks": [
        {
          "chunk_id": 3,
          "file_path": "kernel/dma/mapping.c",
          "start_line": 399,
          "end_line": 503,
          "content": [
            "int dma_get_sgtable_attrs(struct device *dev, struct sg_table *sgt,",
            "\t\tvoid *cpu_addr, dma_addr_t dma_addr, size_t size,",
            "\t\tunsigned long attrs)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (dma_alloc_direct(dev, ops))",
            "\t\treturn dma_direct_get_sgtable(dev, sgt, cpu_addr, dma_addr,",
            "\t\t\t\tsize, attrs);",
            "\tif (!ops->get_sgtable)",
            "\t\treturn -ENXIO;",
            "\treturn ops->get_sgtable(dev, sgt, cpu_addr, dma_addr, size, attrs);",
            "}",
            "pgprot_t dma_pgprot(struct device *dev, pgprot_t prot, unsigned long attrs)",
            "{",
            "\tif (dev_is_dma_coherent(dev))",
            "\t\treturn prot;",
            "#ifdef CONFIG_ARCH_HAS_DMA_WRITE_COMBINE",
            "\tif (attrs & DMA_ATTR_WRITE_COMBINE)",
            "\t\treturn pgprot_writecombine(prot);",
            "#endif",
            "\treturn pgprot_dmacoherent(prot);",
            "}",
            "bool dma_can_mmap(struct device *dev)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (dma_alloc_direct(dev, ops))",
            "\t\treturn dma_direct_can_mmap(dev);",
            "\treturn ops->mmap != NULL;",
            "}",
            "int dma_mmap_attrs(struct device *dev, struct vm_area_struct *vma,",
            "\t\tvoid *cpu_addr, dma_addr_t dma_addr, size_t size,",
            "\t\tunsigned long attrs)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (dma_alloc_direct(dev, ops))",
            "\t\treturn dma_direct_mmap(dev, vma, cpu_addr, dma_addr, size,",
            "\t\t\t\tattrs);",
            "\tif (!ops->mmap)",
            "\t\treturn -ENXIO;",
            "\treturn ops->mmap(dev, vma, cpu_addr, dma_addr, size, attrs);",
            "}",
            "u64 dma_get_required_mask(struct device *dev)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (dma_alloc_direct(dev, ops))",
            "\t\treturn dma_direct_get_required_mask(dev);",
            "\tif (ops->get_required_mask)",
            "\t\treturn ops->get_required_mask(dev);",
            "",
            "\t/*",
            "\t * We require every DMA ops implementation to at least support a 32-bit",
            "\t * DMA mask (and use bounce buffering if that isn't supported in",
            "\t * hardware).  As the direct mapping code has its own routine to",
            "\t * actually report an optimal mask we default to 32-bit here as that",
            "\t * is the right thing for most IOMMUs, and at least not actively",
            "\t * harmful in general.",
            "\t */",
            "\treturn DMA_BIT_MASK(32);",
            "}",
            "void dma_free_attrs(struct device *dev, size_t size, void *cpu_addr,",
            "\t\tdma_addr_t dma_handle, unsigned long attrs)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (dma_release_from_dev_coherent(dev, get_order(size), cpu_addr))",
            "\t\treturn;",
            "\t/*",
            "\t * On non-coherent platforms which implement DMA-coherent buffers via",
            "\t * non-cacheable remaps, ops->free() may call vunmap(). Thus getting",
            "\t * this far in IRQ context is a) at risk of a BUG_ON() or trying to",
            "\t * sleep on some machines, and b) an indication that the driver is",
            "\t * probably misusing the coherent API anyway.",
            "\t */",
            "\tWARN_ON(irqs_disabled());",
            "",
            "\tif (!cpu_addr)",
            "\t\treturn;",
            "",
            "\tdebug_dma_free_coherent(dev, size, cpu_addr, dma_handle);",
            "\tif (dma_alloc_direct(dev, ops))",
            "\t\tdma_direct_free(dev, size, cpu_addr, dma_handle, attrs);",
            "\telse if (ops->free)",
            "\t\tops->free(dev, size, cpu_addr, dma_handle, attrs);",
            "}",
            "static void __dma_free_pages(struct device *dev, size_t size, struct page *page,",
            "\t\tdma_addr_t dma_handle, enum dma_data_direction dir)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tsize = PAGE_ALIGN(size);",
            "\tif (dma_alloc_direct(dev, ops))",
            "\t\tdma_direct_free_pages(dev, size, page, dma_handle, dir);",
            "\telse if (ops->free_pages)",
            "\t\tops->free_pages(dev, size, page, dma_handle, dir);",
            "}",
            "void dma_free_pages(struct device *dev, size_t size, struct page *page,",
            "\t\tdma_addr_t dma_handle, enum dma_data_direction dir)",
            "{",
            "\tdebug_dma_unmap_page(dev, dma_handle, size, dir);",
            "\t__dma_free_pages(dev, size, page, dma_handle, dir);",
            "}"
          ],
          "function_name": "dma_get_sgtable_attrs, dma_pgprot, dma_can_mmap, dma_mmap_attrs, dma_get_required_mask, dma_free_attrs, __dma_free_pages, dma_free_pages",
          "description": "实现DMA地址转换相关功能，dma_get_sgtable_attrs生成SG表并设置页面保护属性；dma_get_required_mask确定设备所需DMA掩码；dma_free_attrs释放带属性的DMA缓冲区，区分直接映射与通用操作路径。",
          "similarity": 0.5155227780342102
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/dma/mapping.c",
          "start_line": 609,
          "end_line": 719,
          "content": [
            "int dma_mmap_pages(struct device *dev, struct vm_area_struct *vma,",
            "\t\tsize_t size, struct page *page)",
            "{",
            "\tunsigned long count = PAGE_ALIGN(size) >> PAGE_SHIFT;",
            "",
            "\tif (vma->vm_pgoff >= count || vma_pages(vma) > count - vma->vm_pgoff)",
            "\t\treturn -ENXIO;",
            "\treturn remap_pfn_range(vma, vma->vm_start,",
            "\t\t\t       page_to_pfn(page) + vma->vm_pgoff,",
            "\t\t\t       vma_pages(vma) << PAGE_SHIFT, vma->vm_page_prot);",
            "}",
            "static void free_single_sgt(struct device *dev, size_t size,",
            "\t\tstruct sg_table *sgt, enum dma_data_direction dir)",
            "{",
            "\t__dma_free_pages(dev, size, sg_page(sgt->sgl), sgt->sgl->dma_address,",
            "\t\t\t dir);",
            "\tsg_free_table(sgt);",
            "\tkfree(sgt);",
            "}",
            "void dma_free_noncontiguous(struct device *dev, size_t size,",
            "\t\tstruct sg_table *sgt, enum dma_data_direction dir)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tdebug_dma_unmap_sg(dev, sgt->sgl, sgt->orig_nents, dir);",
            "\tif (ops && ops->free_noncontiguous)",
            "\t\tops->free_noncontiguous(dev, size, sgt, dir);",
            "\telse",
            "\t\tfree_single_sgt(dev, size, sgt, dir);",
            "}",
            "void dma_vunmap_noncontiguous(struct device *dev, void *vaddr)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (ops && ops->alloc_noncontiguous)",
            "\t\tvunmap(vaddr);",
            "}",
            "int dma_mmap_noncontiguous(struct device *dev, struct vm_area_struct *vma,",
            "\t\tsize_t size, struct sg_table *sgt)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (ops && ops->alloc_noncontiguous) {",
            "\t\tunsigned long count = PAGE_ALIGN(size) >> PAGE_SHIFT;",
            "",
            "\t\tif (vma->vm_pgoff >= count ||",
            "\t\t    vma_pages(vma) > count - vma->vm_pgoff)",
            "\t\t\treturn -ENXIO;",
            "\t\treturn vm_map_pages(vma, sgt_handle(sgt)->pages, count);",
            "\t}",
            "\treturn dma_mmap_pages(dev, vma, size, sg_page(sgt->sgl));",
            "}",
            "static int dma_supported(struct device *dev, u64 mask)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\t/*",
            "\t * ->dma_supported sets the bypass flag, so we must always call",
            "\t * into the method here unless the device is truly direct mapped.",
            "\t */",
            "\tif (!ops)",
            "\t\treturn dma_direct_supported(dev, mask);",
            "\tif (!ops->dma_supported)",
            "\t\treturn 1;",
            "\treturn ops->dma_supported(dev, mask);",
            "}",
            "bool dma_pci_p2pdma_supported(struct device *dev)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\t/* if ops is not set, dma direct will be used which supports P2PDMA */",
            "\tif (!ops)",
            "\t\treturn true;",
            "",
            "\t/*",
            "\t * Note: dma_ops_bypass is not checked here because P2PDMA should",
            "\t * not be used with dma mapping ops that do not have support even",
            "\t * if the specific device is bypassing them.",
            "\t */",
            "",
            "\treturn ops->flags & DMA_F_PCI_P2PDMA_SUPPORTED;",
            "}",
            "int dma_set_mask(struct device *dev, u64 mask)",
            "{",
            "\t/*",
            "\t * Truncate the mask to the actually supported dma_addr_t width to",
            "\t * avoid generating unsupportable addresses.",
            "\t */",
            "\tmask = (dma_addr_t)mask;",
            "",
            "\tif (!dev->dma_mask || !dma_supported(dev, mask))",
            "\t\treturn -EIO;",
            "",
            "\tarch_dma_set_mask(dev, mask);",
            "\t*dev->dma_mask = mask;",
            "\treturn 0;",
            "}",
            "int dma_set_coherent_mask(struct device *dev, u64 mask)",
            "{",
            "\t/*",
            "\t * Truncate the mask to the actually supported dma_addr_t width to",
            "\t * avoid generating unsupportable addresses.",
            "\t */",
            "\tmask = (dma_addr_t)mask;",
            "",
            "\tif (!dma_supported(dev, mask))",
            "\t\treturn -EIO;",
            "",
            "\tdev->coherent_dma_mask = mask;",
            "\treturn 0;",
            "}"
          ],
          "function_name": "dma_mmap_pages, free_single_sgt, dma_free_noncontiguous, dma_vunmap_noncontiguous, dma_mmap_noncontiguous, dma_supported, dma_pci_p2pdma_supported, dma_set_mask, dma_set_coherent_mask",
          "description": "处理非连续物理内存的映射与释放，dma_mmap_noncontiguous通过SG表实现页框映射；dma_set_mask/coherent_mask配置DMA地址掩码；dma_pci_p2pdma_supported检测设备对P2PDMA的支持状态。",
          "similarity": 0.4900428354740143
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/dma/mapping.c",
          "start_line": 36,
          "end_line": 145,
          "content": [
            "static void dmam_release(struct device *dev, void *res)",
            "{",
            "\tstruct dma_devres *this = res;",
            "",
            "\tdma_free_attrs(dev, this->size, this->vaddr, this->dma_handle,",
            "\t\t\tthis->attrs);",
            "}",
            "static int dmam_match(struct device *dev, void *res, void *match_data)",
            "{",
            "\tstruct dma_devres *this = res, *match = match_data;",
            "",
            "\tif (this->vaddr == match->vaddr) {",
            "\t\tWARN_ON(this->size != match->size ||",
            "\t\t\tthis->dma_handle != match->dma_handle);",
            "\t\treturn 1;",
            "\t}",
            "\treturn 0;",
            "}",
            "void dmam_free_coherent(struct device *dev, size_t size, void *vaddr,",
            "\t\t\tdma_addr_t dma_handle)",
            "{",
            "\tstruct dma_devres match_data = { size, vaddr, dma_handle };",
            "",
            "\tWARN_ON(devres_destroy(dev, dmam_release, dmam_match, &match_data));",
            "\tdma_free_coherent(dev, size, vaddr, dma_handle);",
            "}",
            "static bool dma_go_direct(struct device *dev, dma_addr_t mask,",
            "\t\tconst struct dma_map_ops *ops)",
            "{",
            "\tif (likely(!ops))",
            "\t\treturn true;",
            "#ifdef CONFIG_DMA_OPS_BYPASS",
            "\tif (dev->dma_ops_bypass)",
            "\t\treturn min_not_zero(mask, dev->bus_dma_limit) >=",
            "\t\t\t    dma_direct_get_required_mask(dev);",
            "#endif",
            "\treturn false;",
            "}",
            "static inline bool dma_alloc_direct(struct device *dev,",
            "\t\tconst struct dma_map_ops *ops)",
            "{",
            "\treturn dma_go_direct(dev, dev->coherent_dma_mask, ops);",
            "}",
            "static inline bool dma_map_direct(struct device *dev,",
            "\t\tconst struct dma_map_ops *ops)",
            "{",
            "\treturn dma_go_direct(dev, *dev->dma_mask, ops);",
            "}",
            "dma_addr_t dma_map_page_attrs(struct device *dev, struct page *page,",
            "\t\tsize_t offset, size_t size, enum dma_data_direction dir,",
            "\t\tunsigned long attrs)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "\tdma_addr_t addr;",
            "",
            "\tBUG_ON(!valid_dma_direction(dir));",
            "",
            "\tif (WARN_ON_ONCE(!dev->dma_mask))",
            "\t\treturn DMA_MAPPING_ERROR;",
            "",
            "\tif (dma_map_direct(dev, ops) ||",
            "\t    arch_dma_map_page_direct(dev, page_to_phys(page) + offset + size))",
            "\t\taddr = dma_direct_map_page(dev, page, offset, size, dir, attrs);",
            "\telse",
            "\t\taddr = ops->map_page(dev, page, offset, size, dir, attrs);",
            "\tkmsan_handle_dma(page, offset, size, dir);",
            "\tdebug_dma_map_page(dev, page, offset, size, dir, addr, attrs);",
            "",
            "\treturn addr;",
            "}",
            "void dma_unmap_page_attrs(struct device *dev, dma_addr_t addr, size_t size,",
            "\t\tenum dma_data_direction dir, unsigned long attrs)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tBUG_ON(!valid_dma_direction(dir));",
            "\tif (dma_map_direct(dev, ops) ||",
            "\t    arch_dma_unmap_page_direct(dev, addr + size))",
            "\t\tdma_direct_unmap_page(dev, addr, size, dir, attrs);",
            "\telse if (ops->unmap_page)",
            "\t\tops->unmap_page(dev, addr, size, dir, attrs);",
            "\tdebug_dma_unmap_page(dev, addr, size, dir);",
            "}",
            "static int __dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,",
            "\t int nents, enum dma_data_direction dir, unsigned long attrs)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "\tint ents;",
            "",
            "\tBUG_ON(!valid_dma_direction(dir));",
            "",
            "\tif (WARN_ON_ONCE(!dev->dma_mask))",
            "\t\treturn 0;",
            "",
            "\tif (dma_map_direct(dev, ops) ||",
            "\t    arch_dma_map_sg_direct(dev, sg, nents))",
            "\t\tents = dma_direct_map_sg(dev, sg, nents, dir, attrs);",
            "\telse",
            "\t\tents = ops->map_sg(dev, sg, nents, dir, attrs);",
            "",
            "\tif (ents > 0) {",
            "\t\tkmsan_handle_dma_sg(sg, nents, dir);",
            "\t\tdebug_dma_map_sg(dev, sg, nents, ents, dir, attrs);",
            "\t} else if (WARN_ON_ONCE(ents != -EINVAL && ents != -ENOMEM &&",
            "\t\t\t\tents != -EIO && ents != -EREMOTEIO)) {",
            "\t\treturn -EIO;",
            "\t}",
            "",
            "\treturn ents;",
            "}"
          ],
          "function_name": "dmam_release, dmam_match, dmam_free_coherent, dma_go_direct, dma_alloc_direct, dma_map_direct, dma_map_page_attrs, dma_unmap_page_attrs, __dma_map_sg_attrs",
          "description": "实现DMA资源释放与匹配逻辑，通过dmam_release/Match管理设备资源生命周期；定义dma_go_direct/dma_alloc_direct等辅助函数判断是否启用直接映射路径；实现dma_map_page_attrs等核心接口，根据设备能力选择直接映射或通用DMA操作路径。",
          "similarity": 0.4875386953353882
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/dma/mapping.c",
          "start_line": 1,
          "end_line": 35,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * arch-independent dma-mapping routines",
            " *",
            " * Copyright (c) 2006  SUSE Linux Products GmbH",
            " * Copyright (c) 2006  Tejun Heo <teheo@suse.de>",
            " */",
            "#include <linux/memblock.h> /* for max_pfn */",
            "#include <linux/acpi.h>",
            "#include <linux/dma-map-ops.h>",
            "#include <linux/export.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kmsan.h>",
            "#include <linux/of_device.h>",
            "#include <linux/slab.h>",
            "#include <linux/vmalloc.h>",
            "#include \"debug.h\"",
            "#include \"direct.h\"",
            "",
            "#if defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE) || \\",
            "\tdefined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \\",
            "\tdefined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL)",
            "bool dma_default_coherent = IS_ENABLED(CONFIG_ARCH_DMA_DEFAULT_COHERENT);",
            "#endif",
            "",
            "/*",
            " * Managed DMA API",
            " */",
            "struct dma_devres {",
            "\tsize_t\t\tsize;",
            "\tvoid\t\t*vaddr;",
            "\tdma_addr_t\tdma_handle;",
            "\tunsigned long\tattrs;",
            "};",
            ""
          ],
          "function_name": null,
          "description": "声明DMA设备资源结构体dma_devres，用于跟踪分配的DMA缓冲区大小、虚拟地址、DMA句柄及属性，并定义ARCH_HAS_SYNC_DMA系列配置选项，为后续DMA操作提供基础支持。",
          "similarity": 0.4787968397140503
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/dma/mapping.c",
          "start_line": 796,
          "end_line": 834,
          "content": [
            "size_t dma_max_mapping_size(struct device *dev)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "\tsize_t size = SIZE_MAX;",
            "",
            "\tif (dma_map_direct(dev, ops))",
            "\t\tsize = dma_direct_max_mapping_size(dev);",
            "\telse if (ops && ops->max_mapping_size)",
            "\t\tsize = ops->max_mapping_size(dev);",
            "",
            "\treturn size;",
            "}",
            "size_t dma_opt_mapping_size(struct device *dev)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "\tsize_t size = SIZE_MAX;",
            "",
            "\tif (ops && ops->opt_mapping_size)",
            "\t\tsize = ops->opt_mapping_size();",
            "",
            "\treturn min(dma_max_mapping_size(dev), size);",
            "}",
            "bool dma_need_sync(struct device *dev, dma_addr_t dma_addr)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (dma_map_direct(dev, ops))",
            "\t\treturn dma_direct_need_sync(dev, dma_addr);",
            "\treturn ops->sync_single_for_cpu || ops->sync_single_for_device;",
            "}",
            "unsigned long dma_get_merge_boundary(struct device *dev)",
            "{",
            "\tconst struct dma_map_ops *ops = get_dma_ops(dev);",
            "",
            "\tif (!ops || !ops->get_merge_boundary)",
            "\t\treturn 0;\t/* can't merge */",
            "",
            "\treturn ops->get_merge_boundary(dev);",
            "}"
          ],
          "function_name": "dma_max_mapping_size, dma_opt_mapping_size, dma_need_sync, dma_get_merge_boundary",
          "description": "这段代码实现了DMA映射相关的参数查询功能，包含四个关键函数：  \n1. `dma_max_mapping_size` 获取设备最大映射尺寸，优先采用直接映射逻辑或DMA操作符的定制实现；  \n2. `dma_opt_mapping_size` 返回最优映射尺寸与最大尺寸的最小值，依赖于DMA操作符的回调接口；  \n3. `dma_need_sync` 判断DMA地址是否需同步，通过直接映射逻辑或操作符的同步标志位决定；  \n4. `dma_get_merge_boundary` 查询DMA合并边界，若操作符未实现则返回0。  \n\n注：代码片段未包含`dma_map_direct`等辅助函数定义，部分条件分支依赖上下文完整的DMA操作符结构体实现。",
          "similarity": 0.4675827622413635
        }
      ]
    },
    {
      "source_file": "kernel/dma/debug.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:11:41\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `dma\\debug.c`\n\n---\n\n# `dma/debug.c` 技术文档\n\n## 1. 文件概述\n\n`dma/debug.c` 是 Linux 内核中用于调试 DMA（Direct Memory Access）API 使用错误的核心模块。该文件实现了对 `dma_map_*`、`dma_unmap_*`、`dma_alloc_coherent` 等 DMA 操作的运行时跟踪与验证机制，旨在检测常见的 DMA 编程错误，例如：\n\n- 重复映射或重复释放\n- 未配对的映射/解除映射操作\n- 越界访问\n- 未检查 `dma_mapping_error()` 返回值\n\n当检测到违规行为时，该模块会输出详细的错误信息（包括设备信息、DMA 地址、操作类型、调用栈等），帮助开发者定位问题。该功能通过 `CONFIG_DMA_API_DEBUG` 配置选项启用，主要用于开发和调试阶段。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct dma_debug_entry`**  \n  表示一个 DMA 映射记录，包含设备指针、DMA 地址、大小、方向、类型（single/sg/coherent/resource）、页帧号、偏移量、错误检查状态及调用栈信息。\n\n- **`struct hash_bucket`**  \n  哈希桶结构，包含一个链表头和自旋锁，用于并发安全地管理哈希表中的 DMA 条目。\n\n- **全局变量**\n  - `dma_entry_hash[HASH_SIZE]`：哈希表，用于快速查找 DMA 映射条目。\n  - `free_entries`：预分配的空闲 `dma_debug_entry` 链表。\n  - `global_disable`：全局禁用标志，一旦发生严重错误即关闭调试功能。\n  - `error_count`：累计错误计数。\n  - `show_num_errors` / `show_all_errors`：控制错误输出数量。\n  - `current_driver_name` / `current_driver`：支持按驱动名称过滤错误输出。\n\n### 主要函数与宏\n\n- **`hash_fn()`**：基于 DMA 地址的哈希函数（使用 bits 20–27）。\n- **`get_hash_bucket()` / `put_hash_bucket()`**：获取/释放哈希桶的自旋锁，支持中断上下文安全。\n- **`exact_match()` / `containing_match()`**：用于在哈希链表中匹配条目（精确匹配或包含匹配）。\n- **`driver_filter()`**：根据当前设置的驱动名过滤错误报告。\n- **`err_printk()`**：错误打印宏，自动递增错误计数、应用过滤规则、打印警告及调用栈。\n- **`dump_entry_trace()`**：在支持 `CONFIG_STACKTRACE` 时打印 DMA 映射时的调用栈。\n\n### 枚举类型\n\n- **DMA 类型枚举**：\n  - `dma_debug_single`\n  - `dma_debug_sg`\n  - `dma_debug_coherent`\n  - `dma_debug_resource`\n\n- **映射错误检查状态**：\n  - `MAP_ERR_CHECK_NOT_APPLICABLE`\n  - `MAP_ERR_NOT_CHECKED`\n  - `MAP_ERR_CHECKED`\n\n## 3. 关键实现\n\n### 哈希表设计\n\n- 使用大小为 16384（`HASH_SIZE`）的静态哈希表。\n- 哈希函数 `hash_fn()` 通过右移 13 位（`HASH_FN_SHIFT`）并掩码 `0x3FFF` 提取地址中间位，以减少冲突。\n- 每个桶（`hash_bucket`）配备独立自旋锁，支持高并发访问。\n\n### 内存管理\n\n- 启动时预分配 `PREALLOC_DMA_DEBUG_ENTRIES`（65536）个 `dma_debug_entry`。\n- 若池耗尽，动态按页分配（每页可容纳 `DMA_DEBUG_DYNAMIC_ENTRIES` 个条目）。\n- 使用 `free_entries` 链表和 `free_entries_lock` 管理空闲条目。\n\n### 错误抑制与过滤\n\n- 通过 `show_num_errors` 限制初始错误输出数量（默认 1），避免日志爆炸。\n- 支持通过 debugfs 动态设置 `show_all_errors` 以显示所有错误。\n- `driver_filter()` 允许用户指定只监控特定驱动的 DMA 操作，提升调试效率。\n\n### 调用栈追踪\n\n- 在 `CONFIG_STACKTRACE` 启用时，每个 `dma_debug_entry` 记录最多 5 层调用栈（`DMA_DEBUG_STACKTRACE_ENTRIES`）。\n- 出错时通过 `dump_entry_trace()` 打印映射发生的位置，极大提升问题定位能力。\n\n### 线程安全\n\n- 哈希桶使用 `spin_lock_irqsave`/`spin_unlock_irqrestore` 保证中断上下文安全。\n- 全局状态变量（如 `error_count`）虽存在竞态，但设计上容忍轻微不一致（如少计错误），以避免性能开销。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/dma-map-ops.h>`：DMA 映射操作接口。\n  - `<linux/stacktrace.h>`：调用栈记录支持。\n  - `<linux/debugfs.h>`：用于暴露调试参数（如错误数量、驱动过滤器）。\n  - `<linux/scatterlist.h>`：SG 列表相关定义。\n  - `<asm/sections.h>`：内核段信息（可能用于地址合法性检查）。\n\n- **配置依赖**：\n  - 由 `CONFIG_DMA_API_DEBUG` 控制编译。\n  - `CONFIG_STACKTRACE` 决定是否启用调用栈记录。\n\n- **与其他模块交互**：\n  - 与 `dma-mapping.c` 紧密集成，在 `dma_map_*` / `dma_unmap_*` 等函数中调用本模块的钩子函数（如 `dma_debug_add()`、`dma_debug_remove()` 等，虽未在本片段中展示）。\n  - 通过 `device` 和 `device_driver` 结构与设备模型交互，实现驱动级过滤。\n\n## 5. 使用场景\n\n- **内核开发与调试**：在开发新驱动或修改 DMA 代码时启用，检测潜在的 DMA 使用错误。\n- **系统稳定性分析**：在出现内存损坏、设备异常时，开启 DMA 调试以排查是否由 DMA 操作不当引起。\n- **CI/测试环境**：在自动化测试中启用 `CONFIG_DMA_API_DEBUG`，作为静态检查的补充，捕获运行时错误。\n- **生产环境（谨慎）**：通常不在生产内核中启用，因其带来显著内存与性能开销；但在特定高可靠性场景下可临时开启用于问题复现。\n\n该模块是 Linux 内核 DMA 子系统的重要调试基础设施，显著提升了 DMA 相关 bug 的可发现性和可诊断性。",
      "similarity": 0.4964698553085327,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/dma/debug.c",
          "start_line": 105,
          "end_line": 209,
          "content": [
            "static inline bool dma_debug_disabled(void)",
            "{",
            "\treturn global_disable || !dma_debug_initialized;",
            "}",
            "static inline void dump_entry_trace(struct dma_debug_entry *entry)",
            "{",
            "#ifdef CONFIG_STACKTRACE",
            "\tif (entry) {",
            "\t\tpr_warn(\"Mapped at:\\n\");",
            "\t\tstack_trace_print(entry->stack_entries, entry->stack_len, 0);",
            "\t}",
            "#endif",
            "}",
            "static bool driver_filter(struct device *dev)",
            "{",
            "\tstruct device_driver *drv;",
            "\tunsigned long flags;",
            "\tbool ret;",
            "",
            "\t/* driver filter off */",
            "\tif (likely(!current_driver_name[0]))",
            "\t\treturn true;",
            "",
            "\t/* driver filter on and initialized */",
            "\tif (current_driver && dev && dev->driver == current_driver)",
            "\t\treturn true;",
            "",
            "\t/* driver filter on, but we can't filter on a NULL device... */",
            "\tif (!dev)",
            "\t\treturn false;",
            "",
            "\tif (current_driver || !current_driver_name[0])",
            "\t\treturn false;",
            "",
            "\t/* driver filter on but not yet initialized */",
            "\tdrv = dev->driver;",
            "\tif (!drv)",
            "\t\treturn false;",
            "",
            "\t/* lock to protect against change of current_driver_name */",
            "\tread_lock_irqsave(&driver_name_lock, flags);",
            "",
            "\tret = false;",
            "\tif (drv->name &&",
            "\t    strncmp(current_driver_name, drv->name, NAME_MAX_LEN - 1) == 0) {",
            "\t\tcurrent_driver = drv;",
            "\t\tret = true;",
            "\t}",
            "",
            "\tread_unlock_irqrestore(&driver_name_lock, flags);",
            "",
            "\treturn ret;",
            "}",
            "static int hash_fn(struct dma_debug_entry *entry)",
            "{",
            "\t/*",
            "\t * Hash function is based on the dma address.",
            "\t * We use bits 20-27 here as the index into the hash",
            "\t */",
            "\treturn (entry->dev_addr >> HASH_FN_SHIFT) & HASH_FN_MASK;",
            "}",
            "static void put_hash_bucket(struct hash_bucket *bucket,",
            "\t\t\t    unsigned long flags)",
            "\t__releases(&bucket->lock)",
            "{",
            "\tspin_unlock_irqrestore(&bucket->lock, flags);",
            "}",
            "static bool exact_match(struct dma_debug_entry *a, struct dma_debug_entry *b)",
            "{",
            "\treturn ((a->dev_addr == b->dev_addr) &&",
            "\t\t(a->dev == b->dev)) ? true : false;",
            "}",
            "static bool containing_match(struct dma_debug_entry *a,",
            "\t\t\t     struct dma_debug_entry *b)",
            "{",
            "\tif (a->dev != b->dev)",
            "\t\treturn false;",
            "",
            "\tif ((b->dev_addr <= a->dev_addr) &&",
            "\t    ((b->dev_addr + b->size) >= (a->dev_addr + a->size)))",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "static void hash_bucket_add(struct hash_bucket *bucket,",
            "\t\t\t    struct dma_debug_entry *entry)",
            "{",
            "\tlist_add_tail(&entry->list, &bucket->list);",
            "}",
            "static void hash_bucket_del(struct dma_debug_entry *entry)",
            "{",
            "\tlist_del(&entry->list);",
            "}",
            "static unsigned long long phys_addr(struct dma_debug_entry *entry)",
            "{",
            "\tif (entry->type == dma_debug_resource)",
            "\t\treturn __pfn_to_phys(entry->pfn) + entry->offset;",
            "",
            "\treturn page_to_phys(pfn_to_page(entry->pfn)) + entry->offset;",
            "}",
            "static phys_addr_t to_cacheline_number(struct dma_debug_entry *entry)",
            "{",
            "\treturn (entry->pfn << CACHELINE_PER_PAGE_SHIFT) +",
            "\t\t(entry->offset >> L1_CACHE_SHIFT);",
            "}"
          ],
          "function_name": "dma_debug_disabled, dump_entry_trace, driver_filter, hash_fn, put_hash_bucket, exact_match, containing_match, hash_bucket_add, hash_bucket_del, phys_addr, to_cacheline_number",
          "description": "实现DMA调试的核心控制逻辑，包括驱动过滤判断、哈希函数计算、缓存行重叠检测及映射条目增删操作，支持对DMA地址的快速查找与冲突检测。",
          "similarity": 0.49107348918914795
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/dma/debug.c",
          "start_line": 882,
          "end_line": 1053,
          "content": [
            "void dma_debug_add_bus(const struct bus_type *bus)",
            "{",
            "\tstruct notifier_block *nb;",
            "",
            "\tif (dma_debug_disabled())",
            "\t\treturn;",
            "",
            "\tnb = kzalloc(sizeof(struct notifier_block), GFP_KERNEL);",
            "\tif (nb == NULL) {",
            "\t\tpr_err(\"dma_debug_add_bus: out of memory\\n\");",
            "\t\treturn;",
            "\t}",
            "",
            "\tnb->notifier_call = dma_debug_device_change;",
            "",
            "\tbus_register_notifier(bus, nb);",
            "}",
            "static int dma_debug_init(void)",
            "{",
            "\tint i, nr_pages;",
            "",
            "\t/* Do not use dma_debug_initialized here, since we really want to be",
            "\t * called to set dma_debug_initialized",
            "\t */",
            "\tif (global_disable)",
            "\t\treturn 0;",
            "",
            "\tfor (i = 0; i < HASH_SIZE; ++i) {",
            "\t\tINIT_LIST_HEAD(&dma_entry_hash[i].list);",
            "\t\tspin_lock_init(&dma_entry_hash[i].lock);",
            "\t}",
            "",
            "\tnr_pages = DIV_ROUND_UP(nr_prealloc_entries, DMA_DEBUG_DYNAMIC_ENTRIES);",
            "\tfor (i = 0; i < nr_pages; ++i)",
            "\t\tdma_debug_create_entries(GFP_KERNEL);",
            "\tif (num_free_entries >= nr_prealloc_entries) {",
            "\t\tpr_info(\"preallocated %d debug entries\\n\", nr_total_entries);",
            "\t} else if (num_free_entries > 0) {",
            "\t\tpr_warn(\"%d debug entries requested but only %d allocated\\n\",",
            "\t\t\tnr_prealloc_entries, nr_total_entries);",
            "\t} else {",
            "\t\tpr_err(\"debugging out of memory error - disabled\\n\");",
            "\t\tglobal_disable = true;",
            "",
            "\t\treturn 0;",
            "\t}",
            "\tmin_free_entries = num_free_entries;",
            "",
            "\tdma_debug_initialized = true;",
            "",
            "\tpr_info(\"debugging enabled by kernel config\\n\");",
            "\treturn 0;",
            "}",
            "static __init int dma_debug_cmdline(char *str)",
            "{",
            "\tif (!str)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (strncmp(str, \"off\", 3) == 0) {",
            "\t\tpr_info(\"debugging disabled on kernel command line\\n\");",
            "\t\tglobal_disable = true;",
            "\t}",
            "",
            "\treturn 1;",
            "}",
            "static __init int dma_debug_entries_cmdline(char *str)",
            "{",
            "\tif (!str)",
            "\t\treturn -EINVAL;",
            "\tif (!get_option(&str, &nr_prealloc_entries))",
            "\t\tnr_prealloc_entries = PREALLOC_DMA_DEBUG_ENTRIES;",
            "\treturn 1;",
            "}",
            "static void check_unmap(struct dma_debug_entry *ref)",
            "{",
            "\tstruct dma_debug_entry *entry;",
            "\tstruct hash_bucket *bucket;",
            "\tunsigned long flags;",
            "",
            "\tbucket = get_hash_bucket(ref, &flags);",
            "\tentry = bucket_find_exact(bucket, ref);",
            "",
            "\tif (!entry) {",
            "\t\t/* must drop lock before calling dma_mapping_error */",
            "\t\tput_hash_bucket(bucket, flags);",
            "",
            "\t\tif (dma_mapping_error(ref->dev, ref->dev_addr)) {",
            "\t\t\terr_printk(ref->dev, NULL,",
            "\t\t\t\t   \"device driver tries to free an \"",
            "\t\t\t\t   \"invalid DMA memory address\\n\");",
            "\t\t} else {",
            "\t\t\terr_printk(ref->dev, NULL,",
            "\t\t\t\t   \"device driver tries to free DMA \"",
            "\t\t\t\t   \"memory it has not allocated [device \"",
            "\t\t\t\t   \"address=0x%016llx] [size=%llu bytes]\\n\",",
            "\t\t\t\t   ref->dev_addr, ref->size);",
            "\t\t}",
            "\t\treturn;",
            "\t}",
            "",
            "\tif (ref->size != entry->size) {",
            "\t\terr_printk(ref->dev, entry, \"device driver frees \"",
            "\t\t\t   \"DMA memory with different size \"",
            "\t\t\t   \"[device address=0x%016llx] [map size=%llu bytes] \"",
            "\t\t\t   \"[unmap size=%llu bytes]\\n\",",
            "\t\t\t   ref->dev_addr, entry->size, ref->size);",
            "\t}",
            "",
            "\tif (ref->type != entry->type) {",
            "\t\terr_printk(ref->dev, entry, \"device driver frees \"",
            "\t\t\t   \"DMA memory with wrong function \"",
            "\t\t\t   \"[device address=0x%016llx] [size=%llu bytes] \"",
            "\t\t\t   \"[mapped as %s] [unmapped as %s]\\n\",",
            "\t\t\t   ref->dev_addr, ref->size,",
            "\t\t\t   type2name[entry->type], type2name[ref->type]);",
            "\t} else if ((entry->type == dma_debug_coherent) &&",
            "\t\t   (phys_addr(ref) != phys_addr(entry))) {",
            "\t\terr_printk(ref->dev, entry, \"device driver frees \"",
            "\t\t\t   \"DMA memory with different CPU address \"",
            "\t\t\t   \"[device address=0x%016llx] [size=%llu bytes] \"",
            "\t\t\t   \"[cpu alloc address=0x%016llx] \"",
            "\t\t\t   \"[cpu free address=0x%016llx]\",",
            "\t\t\t   ref->dev_addr, ref->size,",
            "\t\t\t   phys_addr(entry),",
            "\t\t\t   phys_addr(ref));",
            "\t}",
            "",
            "\tif (ref->sg_call_ents && ref->type == dma_debug_sg &&",
            "\t    ref->sg_call_ents != entry->sg_call_ents) {",
            "\t\terr_printk(ref->dev, entry, \"device driver frees \"",
            "\t\t\t   \"DMA sg list with different entry count \"",
            "\t\t\t   \"[map count=%d] [unmap count=%d]\\n\",",
            "\t\t\t   entry->sg_call_ents, ref->sg_call_ents);",
            "\t}",
            "",
            "\t/*",
            "\t * This may be no bug in reality - but most implementations of the",
            "\t * DMA API don't handle this properly, so check for it here",
            "\t */",
            "\tif (ref->direction != entry->direction) {",
            "\t\terr_printk(ref->dev, entry, \"device driver frees \"",
            "\t\t\t   \"DMA memory with different direction \"",
            "\t\t\t   \"[device address=0x%016llx] [size=%llu bytes] \"",
            "\t\t\t   \"[mapped with %s] [unmapped with %s]\\n\",",
            "\t\t\t   ref->dev_addr, ref->size,",
            "\t\t\t   dir2name[entry->direction],",
            "\t\t\t   dir2name[ref->direction]);",
            "\t}",
            "",
            "\t/*",
            "\t * Drivers should use dma_mapping_error() to check the returned",
            "\t * addresses of dma_map_single() and dma_map_page().",
            "\t * If not, print this warning message. See Documentation/core-api/dma-api.rst.",
            "\t */",
            "\tif (entry->map_err_type == MAP_ERR_NOT_CHECKED) {",
            "\t\terr_printk(ref->dev, entry,",
            "\t\t\t   \"device driver failed to check map error\"",
            "\t\t\t   \"[device address=0x%016llx] [size=%llu bytes] \"",
            "\t\t\t   \"[mapped as %s]\",",
            "\t\t\t   ref->dev_addr, ref->size,",
            "\t\t\t   type2name[entry->type]);",
            "\t}",
            "",
            "\thash_bucket_del(entry);",
            "\tput_hash_bucket(bucket, flags);",
            "",
            "\t/*",
            "\t * Free the entry outside of bucket_lock to avoid ABBA deadlocks",
            "\t * between that and radix_lock.",
            "\t */",
            "\tdma_entry_free(entry);",
            "}"
          ],
          "function_name": "dma_debug_add_bus, dma_debug_init, dma_debug_cmdline, dma_debug_entries_cmdline, check_unmap",
          "description": "注册DMA调试总线通知块，初始化调试条目缓存并处理命令行参数，通过check_unmap验证DMA解除映射操作的合法性，检测地址有效性及方向/大小不匹配等问题",
          "similarity": 0.4888995885848999
        },
        {
          "chunk_id": 6,
          "file_path": "kernel/dma/debug.c",
          "start_line": 1063,
          "end_line": 1169,
          "content": [
            "static void check_for_stack(struct device *dev,",
            "\t\t\t    struct page *page, size_t offset)",
            "{",
            "\tvoid *addr;",
            "\tstruct vm_struct *stack_vm_area = task_stack_vm_area(current);",
            "",
            "\tif (!stack_vm_area) {",
            "\t\t/* Stack is direct-mapped. */",
            "\t\tif (PageHighMem(page))",
            "\t\t\treturn;",
            "\t\taddr = page_address(page) + offset;",
            "\t\tif (object_is_on_stack(addr))",
            "\t\t\terr_printk(dev, NULL, \"device driver maps memory from stack [addr=%p]\\n\", addr);",
            "\t} else {",
            "\t\t/* Stack is vmalloced. */",
            "\t\tint i;",
            "",
            "\t\tfor (i = 0; i < stack_vm_area->nr_pages; i++) {",
            "\t\t\tif (page != stack_vm_area->pages[i])",
            "\t\t\t\tcontinue;",
            "",
            "\t\t\taddr = (u8 *)current->stack + i * PAGE_SIZE + offset;",
            "\t\t\terr_printk(dev, NULL, \"device driver maps memory from stack [probable addr=%p]\\n\", addr);",
            "\t\t\tbreak;",
            "\t\t}",
            "\t}",
            "}",
            "static void check_for_illegal_area(struct device *dev, void *addr, unsigned long len)",
            "{",
            "\tif (memory_intersects(_stext, _etext, addr, len) ||",
            "\t    memory_intersects(__start_rodata, __end_rodata, addr, len))",
            "\t\terr_printk(dev, NULL, \"device driver maps memory from kernel text or rodata [addr=%p] [len=%lu]\\n\", addr, len);",
            "}",
            "static void check_sync(struct device *dev,",
            "\t\t       struct dma_debug_entry *ref,",
            "\t\t       bool to_cpu)",
            "{",
            "\tstruct dma_debug_entry *entry;",
            "\tstruct hash_bucket *bucket;",
            "\tunsigned long flags;",
            "",
            "\tbucket = get_hash_bucket(ref, &flags);",
            "",
            "\tentry = bucket_find_contain(&bucket, ref, &flags);",
            "",
            "\tif (!entry) {",
            "\t\terr_printk(dev, NULL, \"device driver tries \"",
            "\t\t\t\t\"to sync DMA memory it has not allocated \"",
            "\t\t\t\t\"[device address=0x%016llx] [size=%llu bytes]\\n\",",
            "\t\t\t\t(unsigned long long)ref->dev_addr, ref->size);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\tif (ref->size > entry->size) {",
            "\t\terr_printk(dev, entry, \"device driver syncs\"",
            "\t\t\t\t\" DMA memory outside allocated range \"",
            "\t\t\t\t\"[device address=0x%016llx] \"",
            "\t\t\t\t\"[allocation size=%llu bytes] \"",
            "\t\t\t\t\"[sync offset+size=%llu]\\n\",",
            "\t\t\t\tentry->dev_addr, entry->size,",
            "\t\t\t\tref->size);",
            "\t}",
            "",
            "\tif (entry->direction == DMA_BIDIRECTIONAL)",
            "\t\tgoto out;",
            "",
            "\tif (ref->direction != entry->direction) {",
            "\t\terr_printk(dev, entry, \"device driver syncs \"",
            "\t\t\t\t\"DMA memory with different direction \"",
            "\t\t\t\t\"[device address=0x%016llx] [size=%llu bytes] \"",
            "\t\t\t\t\"[mapped with %s] [synced with %s]\\n\",",
            "\t\t\t\t(unsigned long long)ref->dev_addr, entry->size,",
            "\t\t\t\tdir2name[entry->direction],",
            "\t\t\t\tdir2name[ref->direction]);",
            "\t}",
            "",
            "\tif (to_cpu && !(entry->direction == DMA_FROM_DEVICE) &&",
            "\t\t      !(ref->direction == DMA_TO_DEVICE))",
            "\t\terr_printk(dev, entry, \"device driver syncs \"",
            "\t\t\t\t\"device read-only DMA memory for cpu \"",
            "\t\t\t\t\"[device address=0x%016llx] [size=%llu bytes] \"",
            "\t\t\t\t\"[mapped with %s] [synced with %s]\\n\",",
            "\t\t\t\t(unsigned long long)ref->dev_addr, entry->size,",
            "\t\t\t\tdir2name[entry->direction],",
            "\t\t\t\tdir2name[ref->direction]);",
            "",
            "\tif (!to_cpu && !(entry->direction == DMA_TO_DEVICE) &&",
            "\t\t       !(ref->direction == DMA_FROM_DEVICE))",
            "\t\terr_printk(dev, entry, \"device driver syncs \"",
            "\t\t\t\t\"device write-only DMA memory to device \"",
            "\t\t\t\t\"[device address=0x%016llx] [size=%llu bytes] \"",
            "\t\t\t\t\"[mapped with %s] [synced with %s]\\n\",",
            "\t\t\t\t(unsigned long long)ref->dev_addr, entry->size,",
            "\t\t\t\tdir2name[entry->direction],",
            "\t\t\t\tdir2name[ref->direction]);",
            "",
            "\tif (ref->sg_call_ents && ref->type == dma_debug_sg &&",
            "\t    ref->sg_call_ents != entry->sg_call_ents) {",
            "\t\terr_printk(ref->dev, entry, \"device driver syncs \"",
            "\t\t\t   \"DMA sg list with different entry count \"",
            "\t\t\t   \"[map count=%d] [sync count=%d]\\n\",",
            "\t\t\t   entry->sg_call_ents, ref->sg_call_ents);",
            "\t}",
            "",
            "out:",
            "\tput_hash_bucket(bucket, flags);",
            "}"
          ],
          "function_name": "check_for_stack, check_for_illegal_area, check_sync",
          "description": "检查DMA映射是否来自栈内存或内核只读区，验证同步操作的方向一致性，防止非法内存访问和错误的DMA同步行为",
          "similarity": 0.4809585213661194
        },
        {
          "chunk_id": 9,
          "file_path": "kernel/dma/debug.c",
          "start_line": 1394,
          "end_line": 1510,
          "content": [
            "void debug_dma_alloc_coherent(struct device *dev, size_t size,",
            "\t\t\t      dma_addr_t dma_addr, void *virt,",
            "\t\t\t      unsigned long attrs)",
            "{",
            "\tstruct dma_debug_entry *entry;",
            "",
            "\tif (unlikely(dma_debug_disabled()))",
            "\t\treturn;",
            "",
            "\tif (unlikely(virt == NULL))",
            "\t\treturn;",
            "",
            "\t/* handle vmalloc and linear addresses */",
            "\tif (!is_vmalloc_addr(virt) && !virt_addr_valid(virt))",
            "\t\treturn;",
            "",
            "\tentry = dma_entry_alloc();",
            "\tif (!entry)",
            "\t\treturn;",
            "",
            "\tentry->type      = dma_debug_coherent;",
            "\tentry->dev       = dev;",
            "\tentry->offset\t = offset_in_page(virt);",
            "\tentry->size      = size;",
            "\tentry->dev_addr  = dma_addr;",
            "\tentry->direction = DMA_BIDIRECTIONAL;",
            "",
            "\tif (is_vmalloc_addr(virt))",
            "\t\tentry->pfn = vmalloc_to_pfn(virt);",
            "\telse",
            "\t\tentry->pfn = page_to_pfn(virt_to_page(virt));",
            "",
            "\tadd_dma_entry(entry, attrs);",
            "}",
            "void debug_dma_free_coherent(struct device *dev, size_t size,",
            "\t\t\t void *virt, dma_addr_t dma_addr)",
            "{",
            "\tstruct dma_debug_entry ref = {",
            "\t\t.type           = dma_debug_coherent,",
            "\t\t.dev            = dev,",
            "\t\t.offset\t\t= offset_in_page(virt),",
            "\t\t.dev_addr       = dma_addr,",
            "\t\t.size           = size,",
            "\t\t.direction      = DMA_BIDIRECTIONAL,",
            "\t};",
            "",
            "\t/* handle vmalloc and linear addresses */",
            "\tif (!is_vmalloc_addr(virt) && !virt_addr_valid(virt))",
            "\t\treturn;",
            "",
            "\tif (is_vmalloc_addr(virt))",
            "\t\tref.pfn = vmalloc_to_pfn(virt);",
            "\telse",
            "\t\tref.pfn = page_to_pfn(virt_to_page(virt));",
            "",
            "\tif (unlikely(dma_debug_disabled()))",
            "\t\treturn;",
            "",
            "\tcheck_unmap(&ref);",
            "}",
            "void debug_dma_map_resource(struct device *dev, phys_addr_t addr, size_t size,",
            "\t\t\t    int direction, dma_addr_t dma_addr,",
            "\t\t\t    unsigned long attrs)",
            "{",
            "\tstruct dma_debug_entry *entry;",
            "",
            "\tif (unlikely(dma_debug_disabled()))",
            "\t\treturn;",
            "",
            "\tentry = dma_entry_alloc();",
            "\tif (!entry)",
            "\t\treturn;",
            "",
            "\tentry->type\t\t= dma_debug_resource;",
            "\tentry->dev\t\t= dev;",
            "\tentry->pfn\t\t= PHYS_PFN(addr);",
            "\tentry->offset\t\t= offset_in_page(addr);",
            "\tentry->size\t\t= size;",
            "\tentry->dev_addr\t\t= dma_addr;",
            "\tentry->direction\t= direction;",
            "\tentry->map_err_type\t= MAP_ERR_NOT_CHECKED;",
            "",
            "\tadd_dma_entry(entry, attrs);",
            "}",
            "void debug_dma_unmap_resource(struct device *dev, dma_addr_t dma_addr,",
            "\t\t\t      size_t size, int direction)",
            "{",
            "\tstruct dma_debug_entry ref = {",
            "\t\t.type           = dma_debug_resource,",
            "\t\t.dev            = dev,",
            "\t\t.dev_addr       = dma_addr,",
            "\t\t.size           = size,",
            "\t\t.direction      = direction,",
            "\t};",
            "",
            "\tif (unlikely(dma_debug_disabled()))",
            "\t\treturn;",
            "",
            "\tcheck_unmap(&ref);",
            "}",
            "void debug_dma_sync_single_for_cpu(struct device *dev, dma_addr_t dma_handle,",
            "\t\t\t\t   size_t size, int direction)",
            "{",
            "\tstruct dma_debug_entry ref;",
            "",
            "\tif (unlikely(dma_debug_disabled()))",
            "\t\treturn;",
            "",
            "\tref.type         = dma_debug_single;",
            "\tref.dev          = dev;",
            "\tref.dev_addr     = dma_handle;",
            "\tref.size         = size;",
            "\tref.direction    = direction;",
            "\tref.sg_call_ents = 0;",
            "",
            "\tcheck_sync(dev, &ref, true);",
            "}"
          ],
          "function_name": "debug_dma_alloc_coherent, debug_dma_free_coherent, debug_dma_map_resource, debug_dma_unmap_resource, debug_dma_sync_single_for_cpu",
          "description": "追踪一致性内存和资源映射操作，验证CPU-设备数据同步方向，确保DMA资源分配/释放与映射记录的一致性",
          "similarity": 0.4762938320636749
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/dma/debug.c",
          "start_line": 557,
          "end_line": 666,
          "content": [
            "static int dump_show(struct seq_file *seq, void *v)",
            "{",
            "\tint idx;",
            "\tphys_addr_t cln;",
            "",
            "\tfor (idx = 0; idx < HASH_SIZE; idx++) {",
            "\t\tstruct hash_bucket *bucket = &dma_entry_hash[idx];",
            "\t\tstruct dma_debug_entry *entry;",
            "\t\tunsigned long flags;",
            "",
            "\t\tspin_lock_irqsave(&bucket->lock, flags);",
            "\t\tlist_for_each_entry(entry, &bucket->list, list) {",
            "\t\t\tcln = to_cacheline_number(entry);",
            "\t\t\tseq_printf(seq,",
            "\t\t\t\t   \"%s %s %s idx %d P=%llx N=%lx D=%llx L=%llx cln=%pa %s %s\\n\",",
            "\t\t\t\t   dev_driver_string(entry->dev),",
            "\t\t\t\t   dev_name(entry->dev),",
            "\t\t\t\t   type2name[entry->type], idx,",
            "\t\t\t\t   phys_addr(entry), entry->pfn,",
            "\t\t\t\t   entry->dev_addr, entry->size,",
            "\t\t\t\t   &cln, dir2name[entry->direction],",
            "\t\t\t\t   maperr2str[entry->map_err_type]);",
            "\t\t}",
            "\t\tspin_unlock_irqrestore(&bucket->lock, flags);",
            "\t}",
            "\treturn 0;",
            "}",
            "static void add_dma_entry(struct dma_debug_entry *entry, unsigned long attrs)",
            "{",
            "\tstruct hash_bucket *bucket;",
            "\tunsigned long flags;",
            "\tint rc;",
            "",
            "\tbucket = get_hash_bucket(entry, &flags);",
            "\thash_bucket_add(bucket, entry);",
            "\tput_hash_bucket(bucket, flags);",
            "",
            "\trc = active_cacheline_insert(entry);",
            "\tif (rc == -ENOMEM) {",
            "\t\tpr_err_once(\"cacheline tracking ENOMEM, dma-debug disabled\\n\");",
            "\t\tglobal_disable = true;",
            "\t} else if (rc == -EEXIST && !(attrs & DMA_ATTR_SKIP_CPU_SYNC)) {",
            "\t\terr_printk(entry->dev, entry,",
            "\t\t\t\"cacheline tracking EEXIST, overlapping mappings aren't supported\\n\");",
            "\t}",
            "}",
            "static int dma_debug_create_entries(gfp_t gfp)",
            "{",
            "\tstruct dma_debug_entry *entry;",
            "\tint i;",
            "",
            "\tentry = (void *)get_zeroed_page(gfp);",
            "\tif (!entry)",
            "\t\treturn -ENOMEM;",
            "",
            "\tfor (i = 0; i < DMA_DEBUG_DYNAMIC_ENTRIES; i++)",
            "\t\tlist_add_tail(&entry[i].list, &free_entries);",
            "",
            "\tnum_free_entries += DMA_DEBUG_DYNAMIC_ENTRIES;",
            "\tnr_total_entries += DMA_DEBUG_DYNAMIC_ENTRIES;",
            "",
            "\treturn 0;",
            "}",
            "static void __dma_entry_alloc_check_leak(u32 nr_entries)",
            "{",
            "\tu32 tmp = nr_entries % nr_prealloc_entries;",
            "",
            "\t/* Shout each time we tick over some multiple of the initial pool */",
            "\tif (tmp < DMA_DEBUG_DYNAMIC_ENTRIES) {",
            "\t\tpr_info(\"dma_debug_entry pool grown to %u (%u00%%)\\n\",",
            "\t\t\tnr_entries,",
            "\t\t\t(nr_entries / nr_prealloc_entries));",
            "\t}",
            "}",
            "static void dma_entry_free(struct dma_debug_entry *entry)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tactive_cacheline_remove(entry);",
            "",
            "\t/*",
            "\t * add to beginning of the list - this way the entries are",
            "\t * more likely cache hot when they are reallocated.",
            "\t */",
            "\tspin_lock_irqsave(&free_entries_lock, flags);",
            "\tlist_add(&entry->list, &free_entries);",
            "\tnum_free_entries += 1;",
            "\tspin_unlock_irqrestore(&free_entries_lock, flags);",
            "}",
            "static ssize_t filter_read(struct file *file, char __user *user_buf,",
            "\t\t\t   size_t count, loff_t *ppos)",
            "{",
            "\tchar buf[NAME_MAX_LEN + 1];",
            "\tunsigned long flags;",
            "\tint len;",
            "",
            "\tif (!current_driver_name[0])",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * We can't copy to userspace directly because current_driver_name can",
            "\t * only be read under the driver_name_lock with irqs disabled. So",
            "\t * create a temporary copy first.",
            "\t */",
            "\tread_lock_irqsave(&driver_name_lock, flags);",
            "\tlen = scnprintf(buf, NAME_MAX_LEN + 1, \"%s\\n\", current_driver_name);",
            "\tread_unlock_irqrestore(&driver_name_lock, flags);",
            "",
            "\treturn simple_read_from_buffer(user_buf, count, ppos, buf, len);",
            "}"
          ],
          "function_name": "dump_show, add_dma_entry, dma_debug_create_entries, __dma_entry_alloc_check_leak, dma_entry_free, filter_read",
          "description": "管理DMA调试条目的生命周期，包含动态扩容逻辑、内存泄漏检测统计及调试信息导出功能，支持通过seq_file接口展示调试数据并实现过滤器配置。",
          "similarity": 0.466426819562912
        }
      ]
    }
  ]
}