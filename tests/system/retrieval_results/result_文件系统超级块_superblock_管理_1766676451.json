{
  "query": "文件系统超级块（superblock）管理",
  "timestamp": "2025-12-25 23:27:31",
  "retrieved_files": [
    {
      "source_file": "mm/memblock.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:38:16\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memblock.c`\n\n---\n\n# memblock.c 技术文档\n\n## 1. 文件概述\n\n`memblock.c` 实现了 Linux 内核早期启动阶段的内存管理机制——**memblock**。该机制用于在常规内存分配器（如 buddy allocator）尚未初始化之前，对物理内存进行粗粒度的区域管理。它将系统内存抽象为若干连续的内存区域（regions），支持“可用内存”（memory）、“保留内存”（reserved）和“物理内存”（physmem，部分架构支持）三种类型，为内核早期初始化提供内存添加、查询和分配能力。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct memblock_region`：表示一个连续的物理内存区域，包含基地址（base）、大小（size）、NUMA 节点 ID 和属性标志。\n- `struct memblock_type`：管理一类内存区域的集合，包含区域数组、当前数量（cnt）、最大容量（max）和名称。\n- `struct memblock`：全局 memblock 管理结构，包含 `memory` 和 `reserved` 两种类型的 `memblock_type`，以及分配方向（bottom_up）和当前分配上限（current_limit）。\n- `physmem`（条件编译）：描述不受 `mem=` 参数限制的实际物理内存布局。\n\n### 主要函数与变量\n- `memblock_add()` / `memblock_add_node()`：向 memblock 添加可用内存区域。\n- `memblock_reserve()`：标记内存区域为保留（不可用于动态分配）。\n- `memblock_phys_alloc*()` / `memblock_alloc*()`：分配物理或虚拟地址的内存。\n- `memblock_overlaps_region()`：判断指定区域是否与某类 memblock 区域重叠。\n- `__memblock_find_range_bottom_up()`：从低地址向高地址查找满足条件的空闲内存范围。\n- 全局变量 `memblock`：静态初始化的主 memblock 结构体。\n- `max_low_pfn`, `min_low_pfn`, `max_pfn`, `max_possible_pfn`：记录 PFN（页帧号）边界信息。\n\n### 配置宏\n- `INIT_MEMBLOCK_REGIONS`：初始内存/保留区域数组大小（默认 128）。\n- `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 类型支持。\n- `CONFIG_MEMBLOCK_KHO_SCRATCH`：支持仅从特定标记（KHO_SCRATCH）区域分配内存。\n- `CONFIG_ARCH_KEEP_MEMBLOCK`：决定是否在初始化完成后保留 memblock 数据结构。\n\n## 3. 关键实现\n\n### 初始化与存储\n- `memblock` 结构体在编译时静态初始化，其 `memory` 和 `reserved` 的区域数组分别使用 `memblock_memory_init_regions` 和 `memblock_reserved_init_regions`，初始容量由 `INIT_MEMBLOCK_*_REGIONS` 定义。\n- 每个 `memblock_type` 的 `cnt` 初始设为 1，但实际第一个条目为空的占位符，有效区域从索引 1 开始（后续代码处理）。\n- 支持通过 `memblock_allow_resize()` 动态扩容区域数组，但需谨慎避免与 initrd 等关键区域冲突。\n\n### 内存区域管理\n- 使用 `for_each_memblock_type` 宏遍历指定类型的区域。\n- `memblock_addrs_overlap()` 通过比较区间端点判断两个物理内存区域是否重叠。\n- `memblock_overlaps_region()` 封装了对某类所有区域的重叠检测。\n\n### 分配策略\n- 默认采用 **top-down**（从高地址向低地址）分配策略，可通过 `memblock_set_bottom_up(true)` 切换为 **bottom-up**。\n- 分配时受 `current_limit` 限制（默认 `MEMBLOCK_ALLOC_ANYWHERE` 表示无限制）。\n- 支持基于 NUMA 节点、对齐要求、内存属性（如 `MEMBLOCK_MIRROR`、`MEMBLOCK_KHO_SCRATCH`）的精细控制。\n- `choose_memblock_flags()` 根据 `kho_scratch_only` 和镜像内存存在性动态选择分配标志。\n\n### 安全与调试\n- `memblock_cap_size()` 防止地址计算溢出（确保 `base + size <= PHYS_ADDR_MAX`）。\n- 条件编译的 `memblock_dbg()` 宏用于调试输出（需开启 `memblock_debug`）。\n- 使用 `__initdata_memblock` 属性标记仅在初始化阶段使用的数据，便于后续释放。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memblock.h>`：定义 memblock API 和数据结构。\n  - `<linux/kernel.h>`, `<linux/init.h>`：提供基础内核功能和初始化宏。\n  - `<linux/pfn.h>`：PFN 相关操作。\n  - `<asm/sections.h>`：访问内核链接段信息。\n  - 架构相关头文件（如 `internal.h`）。\n- **配置依赖**：\n  - `CONFIG_NUMA`：影响 `contig_page_data` 的定义。\n  - `CONFIG_KEXEC_HANDOVER`：引入 kexec 相关头文件。\n  - `CONFIG_HAVE_MEMBLOCK_PHYS_MAP`：启用 `physmem` 支持。\n- **后续移交**：在 `mem_init()` 中，memblock 管理的内存会被释放给 buddy allocator，完成内存管理权移交。\n\n## 5. 使用场景\n\n- **内核早期初始化**：在 `start_kernel()` 初期，架构代码（如 `setup_arch()`）调用 `memblock_add()` 注册可用物理内存，调用 `memblock_reserve()` 保留内核镜像、设备树、initrd 等关键区域。\n- **早期内存分配**：在 slab/buddy 分配器就绪前，使用 `memblock_alloc()` 分配大块连续内存（如页表、中断向量表、ACPI 表解析缓冲区）。\n- **内存布局查询**：通过 `for_each_memblock()` 等宏遍历内存区域，用于构建 e820 表、EFI 内存映射或 NUMA 拓扑。\n- **特殊分配需求**：支持从镜像内存（`MEMBLOCK_MIRROR`）或 KHO scratch 区域分配，满足安全启动或崩溃转储等场景。\n- **调试与分析**：通过 debugfs 接口（未在片段中体现）导出 memblock 布局，辅助内存问题诊断。",
      "similarity": 0.6175848841667175,
      "chunks": [
        {
          "chunk_id": 10,
          "file_path": "mm/memblock.c",
          "start_line": 1954,
          "end_line": 2057,
          "content": [
            "void __init memblock_mem_limit_remove_map(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr;",
            "",
            "\tif (!limit)",
            "\t\treturn;",
            "",
            "\tmax_addr = __find_max_addr(limit);",
            "",
            "\t/* @limit exceeds the total size of the memory, do nothing */",
            "\tif (max_addr == PHYS_ADDR_MAX)",
            "\t\treturn;",
            "",
            "\tmemblock_cap_memory_range(0, max_addr);",
            "}",
            "static int __init_memblock memblock_search(struct memblock_type *type, phys_addr_t addr)",
            "{",
            "\tunsigned int left = 0, right = type->cnt;",
            "",
            "\tdo {",
            "\t\tunsigned int mid = (right + left) / 2;",
            "",
            "\t\tif (addr < type->regions[mid].base)",
            "\t\t\tright = mid;",
            "\t\telse if (addr >= (type->regions[mid].base +",
            "\t\t\t\t  type->regions[mid].size))",
            "\t\t\tleft = mid + 1;",
            "\t\telse",
            "\t\t\treturn mid;",
            "\t} while (left < right);",
            "\treturn -1;",
            "}",
            "bool __init_memblock memblock_is_reserved(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.reserved, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_memory(phys_addr_t addr)",
            "{",
            "\treturn memblock_search(&memblock.memory, addr) != -1;",
            "}",
            "bool __init_memblock memblock_is_map_memory(phys_addr_t addr)",
            "{",
            "\tint i = memblock_search(&memblock.memory, addr);",
            "",
            "\tif (i == -1)",
            "\t\treturn false;",
            "\treturn !memblock_is_nomap(&memblock.memory.regions[i]);",
            "}",
            "int __init_memblock memblock_search_pfn_nid(unsigned long pfn,",
            "\t\t\t unsigned long *start_pfn, unsigned long *end_pfn)",
            "{",
            "\tstruct memblock_type *type = &memblock.memory;",
            "\tint mid = memblock_search(type, PFN_PHYS(pfn));",
            "",
            "\tif (mid == -1)",
            "\t\treturn -1;",
            "",
            "\t*start_pfn = PFN_DOWN(type->regions[mid].base);",
            "\t*end_pfn = PFN_DOWN(type->regions[mid].base + type->regions[mid].size);",
            "",
            "\treturn memblock_get_region_node(&type->regions[mid]);",
            "}",
            "bool __init_memblock memblock_is_region_memory(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tint idx = memblock_search(&memblock.memory, base);",
            "\tphys_addr_t end = base + memblock_cap_size(base, &size);",
            "",
            "\tif (idx == -1)",
            "\t\treturn false;",
            "\treturn (memblock.memory.regions[idx].base +",
            "\t\t memblock.memory.regions[idx].size) >= end;",
            "}",
            "bool __init_memblock memblock_is_region_reserved(phys_addr_t base, phys_addr_t size)",
            "{",
            "\treturn memblock_overlaps_region(&memblock.reserved, base, size);",
            "}",
            "void __init_memblock memblock_trim_memory(phys_addr_t align)",
            "{",
            "\tphys_addr_t start, end, orig_start, orig_end;",
            "\tstruct memblock_region *r;",
            "",
            "\tfor_each_mem_region(r) {",
            "\t\torig_start = r->base;",
            "\t\torig_end = r->base + r->size;",
            "\t\tstart = round_up(orig_start, align);",
            "\t\tend = round_down(orig_end, align);",
            "",
            "\t\tif (start == orig_start && end == orig_end)",
            "\t\t\tcontinue;",
            "",
            "\t\tif (start < end) {",
            "\t\t\tr->base = start;",
            "\t\t\tr->size = end - start;",
            "\t\t} else {",
            "\t\t\tmemblock_remove_region(&memblock.memory,",
            "\t\t\t\t\t       r - memblock.memory.regions);",
            "\t\t\tr--;",
            "\t\t}",
            "\t}",
            "}",
            "void __init_memblock memblock_set_current_limit(phys_addr_t limit)",
            "{",
            "\tmemblock.current_limit = limit;",
            "}"
          ],
          "function_name": "memblock_mem_limit_remove_map, memblock_search, memblock_is_reserved, memblock_is_memory, memblock_is_map_memory, memblock_search_pfn_nid, memblock_is_region_memory, memblock_is_region_reserved, memblock_trim_memory, memblock_set_current_limit",
          "description": "实现内存块限制移除、搜索和区域判断逻辑，用于管理内存和保留区域的地址范围查询及修剪操作",
          "similarity": 0.6335036158561707
        },
        {
          "chunk_id": 5,
          "file_path": "mm/memblock.c",
          "start_line": 887,
          "end_line": 987,
          "content": [
            "int __init_memblock memblock_remove(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\", __func__,",
            "\t\t     &base, &end, (void *)_RET_IP_);",
            "",
            "\treturn memblock_remove_range(&memblock.memory, base, size);",
            "}",
            "void __init_memblock memblock_free(void *ptr, size_t size)",
            "{",
            "\tif (ptr)",
            "\t\tmemblock_phys_free(__pa(ptr), size);",
            "}",
            "int __init_memblock memblock_phys_free(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\", __func__,",
            "\t\t     &base, &end, (void *)_RET_IP_);",
            "",
            "\tkmemleak_free_part_phys(base, size);",
            "\treturn memblock_remove_range(&memblock.reserved, base, size);",
            "}",
            "int __init_memblock __memblock_reserve(phys_addr_t base, phys_addr_t size,",
            "\t\t\t\t       int nid, enum memblock_flags flags)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] nid=%d flags=%x %pS\\n\", __func__,",
            "\t\t     &base, &end, nid, flags, (void *)_RET_IP_);",
            "",
            "\treturn memblock_add_range(&memblock.reserved, base, size, nid, flags);",
            "}",
            "int __init_memblock memblock_physmem_add(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t end = base + size - 1;",
            "",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\", __func__,",
            "\t\t     &base, &end, (void *)_RET_IP_);",
            "",
            "\treturn memblock_add_range(&physmem, base, size, MAX_NUMNODES, 0);",
            "}",
            "__init void memblock_set_kho_scratch_only(void)",
            "{",
            "\tkho_scratch_only = true;",
            "}",
            "__init void memblock_clear_kho_scratch_only(void)",
            "{",
            "\tkho_scratch_only = false;",
            "}",
            "__init void memmap_init_kho_scratch_pages(void)",
            "{",
            "\tphys_addr_t start, end;",
            "\tunsigned long pfn;",
            "\tint nid;",
            "\tu64 i;",
            "",
            "\tif (!IS_ENABLED(CONFIG_DEFERRED_STRUCT_PAGE_INIT))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Initialize struct pages for free scratch memory.",
            "\t * The struct pages for reserved scratch memory will be set up in",
            "\t * reserve_bootmem_region()",
            "\t */",
            "\t__for_each_mem_range(i, &memblock.memory, NULL, NUMA_NO_NODE,",
            "\t\t\t     MEMBLOCK_KHO_SCRATCH, &start, &end, &nid) {",
            "\t\tfor (pfn = PFN_UP(start); pfn < PFN_DOWN(end); pfn++)",
            "\t\t\tinit_deferred_page(pfn, nid);",
            "\t}",
            "}",
            "static int __init_memblock memblock_setclr_flag(struct memblock_type *type,",
            "\t\t\t\tphys_addr_t base, phys_addr_t size, int set, int flag)",
            "{",
            "\tint i, ret, start_rgn, end_rgn;",
            "",
            "\tret = memblock_isolate_range(type, base, size, &start_rgn, &end_rgn);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tfor (i = start_rgn; i < end_rgn; i++) {",
            "\t\tstruct memblock_region *r = &type->regions[i];",
            "",
            "\t\tif (set)",
            "\t\t\tr->flags |= flag;",
            "\t\telse",
            "\t\t\tr->flags &= ~flag;",
            "\t}",
            "",
            "\tmemblock_merge_regions(type, start_rgn, end_rgn);",
            "\treturn 0;",
            "}",
            "int __init_memblock memblock_mark_hotplug(phys_addr_t base, phys_addr_t size)",
            "{",
            "\treturn memblock_setclr_flag(&memblock.memory, base, size, 1, MEMBLOCK_HOTPLUG);",
            "}",
            "int __init_memblock memblock_clear_hotplug(phys_addr_t base, phys_addr_t size)",
            "{",
            "\treturn memblock_setclr_flag(&memblock.memory, base, size, 0, MEMBLOCK_HOTPLUG);",
            "}"
          ],
          "function_name": "memblock_remove, memblock_free, memblock_phys_free, __memblock_reserve, memblock_physmem_add, memblock_set_kho_scratch_only, memblock_clear_kho_scratch_only, memmap_init_kho_scratch_pages, memblock_setclr_flag, memblock_mark_hotplug, memblock_clear_hotplug",
          "description": "定义并实现内存块操作函数，用于移除/释放内存区域，标记预留内存属性，初始化KHO_SCRATCH页结构，并通过memblock_setclr_flag修改内存区域标志位，支持热插拔、镜像等特性",
          "similarity": 0.5936689972877502
        },
        {
          "chunk_id": 9,
          "file_path": "mm/memblock.c",
          "start_line": 1607,
          "end_line": 1734,
          "content": [
            "phys_addr_t __init memblock_phys_alloc_range(phys_addr_t size,",
            "\t\t\t\t\t     phys_addr_t align,",
            "\t\t\t\t\t     phys_addr_t start,",
            "\t\t\t\t\t     phys_addr_t end)",
            "{",
            "\tmemblock_dbg(\"%s: %llu bytes align=0x%llx from=%pa max_addr=%pa %pS\\n\",",
            "\t\t     __func__, (u64)size, (u64)align, &start, &end,",
            "\t\t     (void *)_RET_IP_);",
            "\treturn memblock_alloc_range_nid(size, align, start, end, NUMA_NO_NODE,",
            "\t\t\t\t\tfalse);",
            "}",
            "phys_addr_t __init memblock_phys_alloc_try_nid(phys_addr_t size, phys_addr_t align, int nid)",
            "{",
            "\treturn memblock_alloc_range_nid(size, align, 0,",
            "\t\t\t\t\tMEMBLOCK_ALLOC_ACCESSIBLE, nid, false);",
            "}",
            "void __init memblock_free_late(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tphys_addr_t cursor, end;",
            "",
            "\tend = base + size - 1;",
            "\tmemblock_dbg(\"%s: [%pa-%pa] %pS\\n\",",
            "\t\t     __func__, &base, &end, (void *)_RET_IP_);",
            "\tkmemleak_free_part_phys(base, size);",
            "\tcursor = PFN_UP(base);",
            "\tend = PFN_DOWN(base + size);",
            "",
            "\tfor (; cursor < end; cursor++) {",
            "\t\tmemblock_free_pages(pfn_to_page(cursor), cursor, 0);",
            "\t\ttotalram_pages_inc();",
            "\t}",
            "}",
            "phys_addr_t __init_memblock memblock_reserved_kern_size(phys_addr_t limit, int nid)",
            "{",
            "\tstruct memblock_region *r;",
            "\tphys_addr_t total = 0;",
            "",
            "\tfor_each_reserved_mem_region(r) {",
            "\t\tphys_addr_t size = r->size;",
            "",
            "\t\tif (r->base > limit)",
            "\t\t\tbreak;",
            "",
            "\t\tif (r->base + r->size > limit)",
            "\t\t\tsize = limit - r->base;",
            "",
            "\t\tif (nid == memblock_get_region_node(r) || !numa_valid_node(nid))",
            "\t\t\tif (r->flags & MEMBLOCK_RSRV_KERN)",
            "\t\t\t\ttotal += size;",
            "\t}",
            "",
            "\treturn total;",
            "}",
            "unsigned long __init memblock_estimated_nr_free_pages(void)",
            "{",
            "\treturn PHYS_PFN(memblock_phys_mem_size() - memblock_reserved_size());",
            "}",
            "static phys_addr_t __init_memblock __find_max_addr(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr = PHYS_ADDR_MAX;",
            "\tstruct memblock_region *r;",
            "",
            "\t/*",
            "\t * translate the memory @limit size into the max address within one of",
            "\t * the memory memblock regions, if the @limit exceeds the total size",
            "\t * of those regions, max_addr will keep original value PHYS_ADDR_MAX",
            "\t */",
            "\tfor_each_mem_region(r) {",
            "\t\tif (limit <= r->size) {",
            "\t\t\tmax_addr = r->base + limit;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tlimit -= r->size;",
            "\t}",
            "",
            "\treturn max_addr;",
            "}",
            "void __init memblock_enforce_memory_limit(phys_addr_t limit)",
            "{",
            "\tphys_addr_t max_addr;",
            "",
            "\tif (!limit)",
            "\t\treturn;",
            "",
            "\tmax_addr = __find_max_addr(limit);",
            "",
            "\t/* @limit exceeds the total size of the memory, do nothing */",
            "\tif (max_addr == PHYS_ADDR_MAX)",
            "\t\treturn;",
            "",
            "\t/* truncate both memory and reserved regions */",
            "\tmemblock_remove_range(&memblock.memory, max_addr,",
            "\t\t\t      PHYS_ADDR_MAX);",
            "\tmemblock_remove_range(&memblock.reserved, max_addr,",
            "\t\t\t      PHYS_ADDR_MAX);",
            "}",
            "void __init memblock_cap_memory_range(phys_addr_t base, phys_addr_t size)",
            "{",
            "\tint start_rgn, end_rgn;",
            "\tint i, ret;",
            "",
            "\tif (!size)",
            "\t\treturn;",
            "",
            "\tif (!memblock_memory->total_size) {",
            "\t\tpr_warn(\"%s: No memory registered yet\\n\", __func__);",
            "\t\treturn;",
            "\t}",
            "",
            "\tret = memblock_isolate_range(&memblock.memory, base, size,",
            "\t\t\t\t\t\t&start_rgn, &end_rgn);",
            "\tif (ret)",
            "\t\treturn;",
            "",
            "\t/* remove all the MAP regions */",
            "\tfor (i = memblock.memory.cnt - 1; i >= end_rgn; i--)",
            "\t\tif (!memblock_is_nomap(&memblock.memory.regions[i]))",
            "\t\t\tmemblock_remove_region(&memblock.memory, i);",
            "",
            "\tfor (i = start_rgn - 1; i >= 0; i--)",
            "\t\tif (!memblock_is_nomap(&memblock.memory.regions[i]))",
            "\t\t\tmemblock_remove_region(&memblock.memory, i);",
            "",
            "\t/* truncate the reserved regions */",
            "\tmemblock_remove_range(&memblock.reserved, 0, base);",
            "\tmemblock_remove_range(&memblock.reserved,",
            "\t\t\tbase + size, PHYS_ADDR_MAX);",
            "}"
          ],
          "function_name": "memblock_phys_alloc_range, memblock_phys_alloc_try_nid, memblock_free_late, memblock_reserved_kern_size, memblock_estimated_nr_free_pages, __find_max_addr, memblock_enforce_memory_limit, memblock_cap_memory_range",
          "description": "实现物理内存分配/释放控制，包含内存上限强制限制、空闲页面估算、内存区域截断等管理功能，支持对保留内存的容量统计",
          "similarity": 0.5879735350608826
        },
        {
          "chunk_id": 0,
          "file_path": "mm/memblock.c",
          "start_line": 1,
          "end_line": 191,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-or-later",
            "/*",
            " * Procedures for maintaining information about logical memory blocks.",
            " *",
            " * Peter Bergner, IBM Corp.\tJune 2001.",
            " * Copyright (C) 2001 Peter Bergner.",
            " */",
            "",
            "#include <linux/kernel.h>",
            "#include <linux/slab.h>",
            "#include <linux/init.h>",
            "#include <linux/bitops.h>",
            "#include <linux/poison.h>",
            "#include <linux/pfn.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/memblock.h>",
            "#include <linux/mutex.h>",
            "",
            "#ifdef CONFIG_KEXEC_HANDOVER",
            "#include <linux/libfdt.h>",
            "#include <linux/kexec_handover.h>",
            "#endif /* CONFIG_KEXEC_HANDOVER */",
            "",
            "#include <asm/sections.h>",
            "#include <linux/io.h>",
            "",
            "#include \"internal.h\"",
            "",
            "#define INIT_MEMBLOCK_REGIONS\t\t\t128",
            "#define INIT_PHYSMEM_REGIONS\t\t\t4",
            "",
            "#ifndef INIT_MEMBLOCK_RESERVED_REGIONS",
            "# define INIT_MEMBLOCK_RESERVED_REGIONS\t\tINIT_MEMBLOCK_REGIONS",
            "#endif",
            "",
            "#ifndef INIT_MEMBLOCK_MEMORY_REGIONS",
            "#define INIT_MEMBLOCK_MEMORY_REGIONS\t\tINIT_MEMBLOCK_REGIONS",
            "#endif",
            "",
            "/**",
            " * DOC: memblock overview",
            " *",
            " * Memblock is a method of managing memory regions during the early",
            " * boot period when the usual kernel memory allocators are not up and",
            " * running.",
            " *",
            " * Memblock views the system memory as collections of contiguous",
            " * regions. There are several types of these collections:",
            " *",
            " * * ``memory`` - describes the physical memory available to the",
            " *   kernel; this may differ from the actual physical memory installed",
            " *   in the system, for instance when the memory is restricted with",
            " *   ``mem=`` command line parameter",
            " * * ``reserved`` - describes the regions that were allocated",
            " * * ``physmem`` - describes the actual physical memory available during",
            " *   boot regardless of the possible restrictions and memory hot(un)plug;",
            " *   the ``physmem`` type is only available on some architectures.",
            " *",
            " * Each region is represented by struct memblock_region that",
            " * defines the region extents, its attributes and NUMA node id on NUMA",
            " * systems. Every memory type is described by the struct memblock_type",
            " * which contains an array of memory regions along with",
            " * the allocator metadata. The \"memory\" and \"reserved\" types are nicely",
            " * wrapped with struct memblock. This structure is statically",
            " * initialized at build time. The region arrays are initially sized to",
            " * %INIT_MEMBLOCK_MEMORY_REGIONS for \"memory\" and",
            " * %INIT_MEMBLOCK_RESERVED_REGIONS for \"reserved\". The region array",
            " * for \"physmem\" is initially sized to %INIT_PHYSMEM_REGIONS.",
            " * The memblock_allow_resize() enables automatic resizing of the region",
            " * arrays during addition of new regions. This feature should be used",
            " * with care so that memory allocated for the region array will not",
            " * overlap with areas that should be reserved, for example initrd.",
            " *",
            " * The early architecture setup should tell memblock what the physical",
            " * memory layout is by using memblock_add() or memblock_add_node()",
            " * functions. The first function does not assign the region to a NUMA",
            " * node and it is appropriate for UMA systems. Yet, it is possible to",
            " * use it on NUMA systems as well and assign the region to a NUMA node",
            " * later in the setup process using memblock_set_node(). The",
            " * memblock_add_node() performs such an assignment directly.",
            " *",
            " * Once memblock is setup the memory can be allocated using one of the",
            " * API variants:",
            " *",
            " * * memblock_phys_alloc*() - these functions return the **physical**",
            " *   address of the allocated memory",
            " * * memblock_alloc*() - these functions return the **virtual** address",
            " *   of the allocated memory.",
            " *",
            " * Note, that both API variants use implicit assumptions about allowed",
            " * memory ranges and the fallback methods. Consult the documentation",
            " * of memblock_alloc_internal() and memblock_alloc_range_nid()",
            " * functions for more elaborate description.",
            " *",
            " * As the system boot progresses, the architecture specific mem_init()",
            " * function frees all the memory to the buddy page allocator.",
            " *",
            " * Unless an architecture enables %CONFIG_ARCH_KEEP_MEMBLOCK, the",
            " * memblock data structures (except \"physmem\") will be discarded after the",
            " * system initialization completes.",
            " */",
            "",
            "#ifndef CONFIG_NUMA",
            "struct pglist_data __refdata contig_page_data;",
            "EXPORT_SYMBOL(contig_page_data);",
            "#endif",
            "",
            "unsigned long max_low_pfn;",
            "unsigned long min_low_pfn;",
            "unsigned long max_pfn;",
            "unsigned long long max_possible_pfn;",
            "",
            "#ifdef CONFIG_MEMBLOCK_KHO_SCRATCH",
            "/* When set to true, only allocate from MEMBLOCK_KHO_SCRATCH ranges */",
            "static bool kho_scratch_only;",
            "#else",
            "#define kho_scratch_only false",
            "#endif",
            "",
            "static struct memblock_region memblock_memory_init_regions[INIT_MEMBLOCK_MEMORY_REGIONS] __initdata_memblock;",
            "static struct memblock_region memblock_reserved_init_regions[INIT_MEMBLOCK_RESERVED_REGIONS] __initdata_memblock;",
            "#ifdef CONFIG_HAVE_MEMBLOCK_PHYS_MAP",
            "static struct memblock_region memblock_physmem_init_regions[INIT_PHYSMEM_REGIONS];",
            "#endif",
            "",
            "struct memblock memblock __initdata_memblock = {",
            "\t.memory.regions\t\t= memblock_memory_init_regions,",
            "\t.memory.cnt\t\t= 1,\t/* empty dummy entry */",
            "\t.memory.max\t\t= INIT_MEMBLOCK_MEMORY_REGIONS,",
            "\t.memory.name\t\t= \"memory\",",
            "",
            "\t.reserved.regions\t= memblock_reserved_init_regions,",
            "\t.reserved.cnt\t\t= 1,\t/* empty dummy entry */",
            "\t.reserved.max\t\t= INIT_MEMBLOCK_RESERVED_REGIONS,",
            "\t.reserved.name\t\t= \"reserved\",",
            "",
            "\t.bottom_up\t\t= false,",
            "\t.current_limit\t\t= MEMBLOCK_ALLOC_ANYWHERE,",
            "};",
            "",
            "#ifdef CONFIG_HAVE_MEMBLOCK_PHYS_MAP",
            "struct memblock_type physmem = {",
            "\t.regions\t\t= memblock_physmem_init_regions,",
            "\t.cnt\t\t\t= 1,\t/* empty dummy entry */",
            "\t.max\t\t\t= INIT_PHYSMEM_REGIONS,",
            "\t.name\t\t\t= \"physmem\",",
            "};",
            "#endif",
            "",
            "/*",
            " * keep a pointer to &memblock.memory in the text section to use it in",
            " * __next_mem_range() and its helpers.",
            " *  For architectures that do not keep memblock data after init, this",
            " * pointer will be reset to NULL at memblock_discard()",
            " */",
            "static __refdata struct memblock_type *memblock_memory = &memblock.memory;",
            "",
            "#define for_each_memblock_type(i, memblock_type, rgn)\t\t\t\\",
            "\tfor (i = 0, rgn = &memblock_type->regions[0];\t\t\t\\",
            "\t     i < memblock_type->cnt;\t\t\t\t\t\\",
            "\t     i++, rgn = &memblock_type->regions[i])",
            "",
            "#define memblock_dbg(fmt, ...)\t\t\t\t\t\t\\",
            "\tdo {\t\t\t\t\t\t\t\t\\",
            "\t\tif (memblock_debug)\t\t\t\t\t\\",
            "\t\t\tpr_info(fmt, ##__VA_ARGS__);\t\t\t\\",
            "\t} while (0)",
            "",
            "static int memblock_debug __initdata_memblock;",
            "static bool system_has_some_mirror __initdata_memblock;",
            "static int memblock_can_resize __initdata_memblock;",
            "static int memblock_memory_in_slab __initdata_memblock;",
            "static int memblock_reserved_in_slab __initdata_memblock;",
            "",
            "bool __init_memblock memblock_has_mirror(void)",
            "{",
            "\treturn system_has_some_mirror;",
            "}",
            "",
            "static enum memblock_flags __init_memblock choose_memblock_flags(void)",
            "{",
            "\t/* skip non-scratch memory for kho early boot allocations */",
            "\tif (kho_scratch_only)",
            "\t\treturn MEMBLOCK_KHO_SCRATCH;",
            "",
            "\treturn system_has_some_mirror ? MEMBLOCK_MIRROR : MEMBLOCK_NONE;",
            "}",
            "",
            "/* adjust *@size so that (@base + *@size) doesn't overflow, return new size */"
          ],
          "function_name": null,
          "description": "定义memblock数据结构及初始化内存区域类型（memory/reserved），用于早期系统启动期间管理物理内存分区，支持动态扩容和NUMA节点绑定。",
          "similarity": 0.5675615072250366
        },
        {
          "chunk_id": 2,
          "file_path": "mm/memblock.c",
          "start_line": 366,
          "end_line": 506,
          "content": [
            "static void __init_memblock memblock_remove_region(struct memblock_type *type, unsigned long r)",
            "{",
            "\ttype->total_size -= type->regions[r].size;",
            "\tmemmove(&type->regions[r], &type->regions[r + 1],",
            "\t\t(type->cnt - (r + 1)) * sizeof(type->regions[r]));",
            "\ttype->cnt--;",
            "",
            "\t/* Special case for empty arrays */",
            "\tif (type->cnt == 0) {",
            "\t\tWARN_ON(type->total_size != 0);",
            "\t\ttype->cnt = 1;",
            "\t\ttype->regions[0].base = 0;",
            "\t\ttype->regions[0].size = 0;",
            "\t\ttype->regions[0].flags = 0;",
            "\t\tmemblock_set_region_node(&type->regions[0], MAX_NUMNODES);",
            "\t}",
            "}",
            "void __init memblock_discard(void)",
            "{",
            "\tphys_addr_t addr, size;",
            "",
            "\tif (memblock.reserved.regions != memblock_reserved_init_regions) {",
            "\t\taddr = __pa(memblock.reserved.regions);",
            "\t\tsize = PAGE_ALIGN(sizeof(struct memblock_region) *",
            "\t\t\t\t  memblock.reserved.max);",
            "\t\tif (memblock_reserved_in_slab)",
            "\t\t\tkfree(memblock.reserved.regions);",
            "\t\telse",
            "\t\t\tmemblock_free_late(addr, size);",
            "\t}",
            "",
            "\tif (memblock.memory.regions != memblock_memory_init_regions) {",
            "\t\taddr = __pa(memblock.memory.regions);",
            "\t\tsize = PAGE_ALIGN(sizeof(struct memblock_region) *",
            "\t\t\t\t  memblock.memory.max);",
            "\t\tif (memblock_memory_in_slab)",
            "\t\t\tkfree(memblock.memory.regions);",
            "\t\telse",
            "\t\t\tmemblock_free_late(addr, size);",
            "\t}",
            "",
            "\tmemblock_memory = NULL;",
            "}",
            "static int __init_memblock memblock_double_array(struct memblock_type *type,",
            "\t\t\t\t\t\tphys_addr_t new_area_start,",
            "\t\t\t\t\t\tphys_addr_t new_area_size)",
            "{",
            "\tstruct memblock_region *new_array, *old_array;",
            "\tphys_addr_t old_alloc_size, new_alloc_size;",
            "\tphys_addr_t old_size, new_size, addr, new_end;",
            "\tint use_slab = slab_is_available();",
            "\tint *in_slab;",
            "",
            "\t/* We don't allow resizing until we know about the reserved regions",
            "\t * of memory that aren't suitable for allocation",
            "\t */",
            "\tif (!memblock_can_resize)",
            "\t\treturn -1;",
            "",
            "\t/* Calculate new doubled size */",
            "\told_size = type->max * sizeof(struct memblock_region);",
            "\tnew_size = old_size << 1;",
            "\t/*",
            "\t * We need to allocated new one align to PAGE_SIZE,",
            "\t *   so we can free them completely later.",
            "\t */",
            "\told_alloc_size = PAGE_ALIGN(old_size);",
            "\tnew_alloc_size = PAGE_ALIGN(new_size);",
            "",
            "\t/* Retrieve the slab flag */",
            "\tif (type == &memblock.memory)",
            "\t\tin_slab = &memblock_memory_in_slab;",
            "\telse",
            "\t\tin_slab = &memblock_reserved_in_slab;",
            "",
            "\t/* Try to find some space for it */",
            "\tif (use_slab) {",
            "\t\tnew_array = kmalloc(new_size, GFP_KERNEL);",
            "\t\taddr = new_array ? __pa(new_array) : 0;",
            "\t} else {",
            "\t\t/* only exclude range when trying to double reserved.regions */",
            "\t\tif (type != &memblock.reserved)",
            "\t\t\tnew_area_start = new_area_size = 0;",
            "",
            "\t\taddr = memblock_find_in_range(new_area_start + new_area_size,",
            "\t\t\t\t\t\tmemblock.current_limit,",
            "\t\t\t\t\t\tnew_alloc_size, PAGE_SIZE);",
            "\t\tif (!addr && new_area_size)",
            "\t\t\taddr = memblock_find_in_range(0,",
            "\t\t\t\tmin(new_area_start, memblock.current_limit),",
            "\t\t\t\tnew_alloc_size, PAGE_SIZE);",
            "",
            "\t\tif (addr) {",
            "\t\t\t/* The memory may not have been accepted, yet. */",
            "\t\t\taccept_memory(addr, new_alloc_size);",
            "",
            "\t\t\tnew_array = __va(addr);",
            "\t\t} else {",
            "\t\t\tnew_array = NULL;",
            "\t\t}",
            "\t}",
            "\tif (!addr) {",
            "\t\tpr_err(\"memblock: Failed to double %s array from %ld to %ld entries !\\n\",",
            "\t\t       type->name, type->max, type->max * 2);",
            "\t\treturn -1;",
            "\t}",
            "",
            "\tnew_end = addr + new_size - 1;",
            "\tmemblock_dbg(\"memblock: %s is doubled to %ld at [%pa-%pa]\",",
            "\t\t\ttype->name, type->max * 2, &addr, &new_end);",
            "",
            "\t/*",
            "\t * Found space, we now need to move the array over before we add the",
            "\t * reserved region since it may be our reserved array itself that is",
            "\t * full.",
            "\t */",
            "\tmemcpy(new_array, type->regions, old_size);",
            "\tmemset(new_array + type->max, 0, old_size);",
            "\told_array = type->regions;",
            "\ttype->regions = new_array;",
            "\ttype->max <<= 1;",
            "",
            "\t/* Free old array. We needn't free it if the array is the static one */",
            "\tif (*in_slab)",
            "\t\tkfree(old_array);",
            "\telse if (old_array != memblock_memory_init_regions &&",
            "\t\t old_array != memblock_reserved_init_regions)",
            "\t\tmemblock_free(old_array, old_alloc_size);",
            "",
            "\t/*",
            "\t * Reserve the new array if that comes from the memblock.  Otherwise, we",
            "\t * needn't do it",
            "\t */",
            "\tif (!use_slab)",
            "\t\tBUG_ON(memblock_reserve_kern(addr, new_alloc_size));",
            "",
            "\t/* Update slab flag */",
            "\t*in_slab = use_slab;",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "memblock_remove_region, memblock_discard, memblock_double_array",
          "description": "实现内存区域数组的动态扩容（double_array）、旧区域释放（discard）及区域移除操作，维护内存类型总大小统计。",
          "similarity": 0.5541504621505737
        }
      ]
    },
    {
      "source_file": "mm/hugetlb_cgroup.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:06:55\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `hugetlb_cgroup.c`\n\n---\n\n# hugetlb_cgroup.c 技术文档\n\n## 1. 文件概述\n\n`hugetlb_cgroup.c` 是 Linux 内核中用于实现 **HugeTLB（大页）内存资源控制组（cgroup）** 功能的核心文件。该文件通过 cgroup v1/v2 接口，对不同 HugeTLB 页面大小（如 2MB、1GB 等）的内存使用进行配额限制和统计追踪。它支持两种计费模式：普通分配（fault-based）和预留（reservation-based），并确保在 cgroup 被销毁时将资源正确迁移至父 cgroup，防止资源泄漏。\n\n## 2. 核心功能\n\n### 主要数据结构\n- `struct hugetlb_cgroup`：每个 cgroup 实例对应的 HugeTLB 控制结构。\n  - 包含两个 `page_counter` 数组：`hugepage[]`（普通使用）和 `rsvd_hugepage[]`（预留使用），分别对应每种 HugeTLB 页面类型。\n  - 包含 per-node 信息 `nodeinfo[]`，用于 NUMA 感知。\n  - 包含事件计数器 `events[][]` 和 `events_local[][]`，用于触发 cgroup 通知。\n- `struct hugetlb_cgroup_per_node`：每个 NUMA 节点上的 HugeTLB cgroup 附加信息（当前未在代码片段中完整定义）。\n\n### 主要函数\n- `hugetlb_cgroup_css_alloc()` / `hugetlb_cgroup_css_free()`：cgroup 子系统实例的创建与销毁。\n- `hugetlb_cgroup_init()`：初始化新 cgroup 的 page_counter，设置最大限制为 `PAGE_COUNTER_MAX` 向下对齐到 HugeTLB 页面大小。\n- `__hugetlb_cgroup_charge_cgroup()` / `hugetlb_cgroup_charge_cgroup()`：对当前任务所属 cgroup 尝试 charge（计费）指定数量的 HugeTLB 页面。\n- `hugetlb_cgroup_move_parent()`：将属于某 cgroup 的 HugeTLB 页面迁移至其父 cgroup。\n- `hugetlb_cgroup_css_offline()`：在 cgroup 离线时，强制将其所有 HugeTLB 资源迁移至父级。\n- `hugetlb_event()`：向上冒泡记录 HugeTLB 事件（如达到限制 `HUGETLB_MAX`）并触发 cgroup 文件通知。\n- 辅助内联函数：\n  - `hugetlb_cgroup_from_css()` / `from_task()`：从 cgroup_subsys_state 或 task 获取 hugetlb_cgroup。\n  - `hugetlb_cgroup_counter_from_cgroup()` / `_rsvd()`：获取对应计费类型的 page_counter。\n  - `hugetlb_cgroup_is_root()` / `parent_hugetlb_cgroup()`：判断是否为根 cgroup 或获取父 cgroup。\n\n## 3. 关键实现\n\n### 资源计费机制\n- 使用 `page_counter` 子系统管理每种 HugeTLB 页面类型的用量和上限。\n- 支持两种独立的计费路径：\n  - **普通分配（fault）**：实际分配物理页面时计费。\n  - **预留（reservation）**：仅预留虚拟地址空间时计费（用于 mmap 等场景）。\n- 计费时通过 RCU 安全地获取当前任务的 cgroup，并使用 `css_tryget()` 确保引用有效性。\n- 若计费失败（超出限制），触发 `HUGETLB_MAX` 事件并通过 `cgroup_file_notify()` 通知用户空间。\n\n### cgroup 生命周期管理\n- **创建**：为每个在线 NUMA 节点分配 `hugetlb_cgroup_per_node` 结构；初始化所有 HugeTLB 类型的 page_counter，父子层级通过 `page_counter` 的 parent 字段建立级联关系。\n- **离线（offline）**：遍历所有 HugeTLB 页面的 active list，调用 `hugetlb_cgroup_move_parent()` 将页面所有权转移给父 cgroup。此过程循环执行直至当前 cgroup 无任何 HugeTLB 使用量，确保资源完全迁移。\n- **销毁**：释放 per-node 数据及主结构体。\n\n### 资源迁移（Reparenting）\n- `hugetlb_cgroup_move_parent()` 在持有 `hugetlb_lock` 时执行，确保页面不会被并发释放或迁移。\n- 仅处理属于目标 cgroup 的页面；若父 cgroup 为空（即目标为根），则 charge 到全局 root cgroup（无硬限制）。\n- 通过 `set_hugetlb_cgroup()` 更新页面所属的 cgroup。\n\n### 限制与优化\n- 对于 order 小于 `HUGETLB_CGROUP_MIN_ORDER`（通常为 3，即 8 个普通页 = 32KB）的 HugeTLB 页面，**不进行 cgroup 计费**，以减少小 HugeTLB 页面的开销。\n- 最大限制设为 `PAGE_COUNTER_MAX` 向下对齐到 HugeTLB 页面大小，避免跨页边界问题。\n- 当前 per-node 分配策略对 offline 节点也分配内存（使用 `NUMA_NO_NODE`），存在内存浪费，注释中指出未来可通过内存热插拔回调优化。\n\n## 4. 依赖关系\n\n- **核心依赖**：\n  - `<linux/cgroup.h>`：cgroup 基础框架。\n  - `<linux/page_counter.h>`：提供层次化内存计数和限制功能。\n  - `<linux/hugetlb.h>`：HugeTLB 核心数据结构（如 `hstate`, `hugepage_activelist`）和锁（`hugetlb_lock`）。\n  - `<linux/hugetlb_cgroup.h>`：HugeTLB cgroup 的公共接口和数据结构定义。\n- **交互模块**：\n  - **HugeTLB 子系统**：在页面分配/释放、预留/取消预留等路径中调用本文件的 charge/uncharge 函数。\n  - **Memory cgroup (memcg)**：共享部分设计思想（如 page_counter），但 HugeTLB cgroup 是独立子系统。\n  - **Scheduler**：通过 `current` 获取当前任务的 cgroup 上下文。\n\n## 5. 使用场景\n\n- **容器资源隔离**：在 Kubernetes/Docker 等容器运行时中，通过 cgroup v1 的 `hugetlb` 子系统或 cgroup v2 的 `hugetlb.` 控制器，限制容器可使用的 HugeTLB 内存总量，防止单个容器耗尽系统大页资源。\n- **高性能计算（HPC）**：为不同 HPC 作业分配专用的 HugeTLB 内存配额，确保关键应用获得确定性内存性能。\n- **数据库优化**：Oracle、MySQL 等数据库使用 HugeTLB 提升 TLB 效率，通过 cgroup 限制其大页使用量，避免影响其他服务。\n- **资源监控与告警**：用户空间可通过读取 cgroup 的 `hugetlb.events` 文件监控 `max` 事件，实现基于 HugeTLB 使用量的自动扩缩容或告警。",
      "similarity": 0.5953454971313477,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 785,
          "end_line": 901,
          "content": [
            "static void __init __hugetlb_cgroup_file_legacy_init(int idx)",
            "{",
            "\tchar buf[32];",
            "\tstruct cftype *cft;",
            "\tstruct hstate *h = &hstates[idx];",
            "",
            "\t/* format the size */",
            "\tmem_fmt(buf, sizeof(buf), huge_page_size(h));",
            "",
            "\t/* Add the limit file */",
            "\tcft = &h->cgroup_files_legacy[0];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.limit_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_LIMIT);",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "\tcft->write = hugetlb_cgroup_write_legacy;",
            "",
            "\t/* Add the reservation limit file */",
            "\tcft = &h->cgroup_files_legacy[1];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.limit_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_LIMIT);",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "\tcft->write = hugetlb_cgroup_write_legacy;",
            "",
            "\t/* Add the usage file */",
            "\tcft = &h->cgroup_files_legacy[2];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.usage_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_USAGE);",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the reservation usage file */",
            "\tcft = &h->cgroup_files_legacy[3];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.usage_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_USAGE);",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the MAX usage file */",
            "\tcft = &h->cgroup_files_legacy[4];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.max_usage_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_MAX_USAGE);",
            "\tcft->write = hugetlb_cgroup_reset;",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the MAX reservation usage file */",
            "\tcft = &h->cgroup_files_legacy[5];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.max_usage_in_bytes\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_MAX_USAGE);",
            "\tcft->write = hugetlb_cgroup_reset;",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the failcntfile */",
            "\tcft = &h->cgroup_files_legacy[6];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.failcnt\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_FAILCNT);",
            "\tcft->write = hugetlb_cgroup_reset;",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the reservation failcntfile */",
            "\tcft = &h->cgroup_files_legacy[7];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.rsvd.failcnt\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, RES_RSVD_FAILCNT);",
            "\tcft->write = hugetlb_cgroup_reset;",
            "\tcft->read_u64 = hugetlb_cgroup_read_u64;",
            "",
            "\t/* Add the numa stat file */",
            "\tcft = &h->cgroup_files_legacy[8];",
            "\tsnprintf(cft->name, MAX_CFTYPE_NAME, \"%s.numa_stat\", buf);",
            "\tcft->private = MEMFILE_PRIVATE(idx, 1);",
            "\tcft->seq_show = hugetlb_cgroup_read_numa_stat;",
            "",
            "\t/* NULL terminate the last cft */",
            "\tcft = &h->cgroup_files_legacy[9];",
            "\tmemset(cft, 0, sizeof(*cft));",
            "",
            "\tWARN_ON(cgroup_add_legacy_cftypes(&hugetlb_cgrp_subsys,",
            "\t\t\t\t\t  h->cgroup_files_legacy));",
            "}",
            "static void __init __hugetlb_cgroup_file_init(int idx)",
            "{",
            "\t__hugetlb_cgroup_file_dfl_init(idx);",
            "\t__hugetlb_cgroup_file_legacy_init(idx);",
            "}",
            "void __init hugetlb_cgroup_file_init(void)",
            "{",
            "\tstruct hstate *h;",
            "",
            "\tfor_each_hstate(h) {",
            "\t\t/*",
            "\t\t * Add cgroup control files only if the huge page consists",
            "\t\t * of more than two normal pages. This is because we use",
            "\t\t * page[2].private for storing cgroup details.",
            "\t\t */",
            "\t\tif (huge_page_order(h) >= HUGETLB_CGROUP_MIN_ORDER)",
            "\t\t\t__hugetlb_cgroup_file_init(hstate_index(h));",
            "\t}",
            "}",
            "void hugetlb_cgroup_migrate(struct folio *old_folio, struct folio *new_folio)",
            "{",
            "\tstruct hugetlb_cgroup *h_cg;",
            "\tstruct hugetlb_cgroup *h_cg_rsvd;",
            "\tstruct hstate *h = folio_hstate(old_folio);",
            "",
            "\tif (hugetlb_cgroup_disabled())",
            "\t\treturn;",
            "",
            "\tspin_lock_irq(&hugetlb_lock);",
            "\th_cg = hugetlb_cgroup_from_folio(old_folio);",
            "\th_cg_rsvd = hugetlb_cgroup_from_folio_rsvd(old_folio);",
            "\tset_hugetlb_cgroup(old_folio, NULL);",
            "\tset_hugetlb_cgroup_rsvd(old_folio, NULL);",
            "",
            "\t/* move the h_cg details to new cgroup */",
            "\tset_hugetlb_cgroup(new_folio, h_cg);",
            "\tset_hugetlb_cgroup_rsvd(new_folio, h_cg_rsvd);",
            "\tlist_move(&new_folio->lru, &h->hugepage_activelist);",
            "\tspin_unlock_irq(&hugetlb_lock);",
            "\treturn;",
            "}"
          ],
          "function_name": "__hugetlb_cgroup_file_legacy_init, __hugetlb_cgroup_file_init, hugetlb_cgroup_file_init, hugetlb_cgroup_migrate",
          "description": "初始化传统模式下的hugetlb cgroup文件系统接口，包含限额、使用量、最大使用量等监控文件，并实现页面迁移时的cgroup上下文切换逻辑，通过hugetlb_cgroup_migrate维护huge页面与cgroup的关联关系",
          "similarity": 0.5227125883102417
        },
        {
          "chunk_id": 1,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 65,
          "end_line": 177,
          "content": [
            "static inline bool hugetlb_cgroup_is_root(struct hugetlb_cgroup *h_cg)",
            "{",
            "\treturn (h_cg == root_h_cgroup);",
            "}",
            "static inline bool hugetlb_cgroup_have_usage(struct hugetlb_cgroup *h_cg)",
            "{",
            "\tstruct hstate *h;",
            "",
            "\tfor_each_hstate(h) {",
            "\t\tif (page_counter_read(",
            "\t\t    hugetlb_cgroup_counter_from_cgroup(h_cg, hstate_index(h))))",
            "\t\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "static void hugetlb_cgroup_init(struct hugetlb_cgroup *h_cgroup,",
            "\t\t\t\tstruct hugetlb_cgroup *parent_h_cgroup)",
            "{",
            "\tint idx;",
            "",
            "\tfor (idx = 0; idx < HUGE_MAX_HSTATE; idx++) {",
            "\t\tstruct page_counter *fault_parent = NULL;",
            "\t\tstruct page_counter *rsvd_parent = NULL;",
            "\t\tunsigned long limit;",
            "\t\tint ret;",
            "",
            "\t\tif (parent_h_cgroup) {",
            "\t\t\tfault_parent = hugetlb_cgroup_counter_from_cgroup(",
            "\t\t\t\tparent_h_cgroup, idx);",
            "\t\t\trsvd_parent = hugetlb_cgroup_counter_from_cgroup_rsvd(",
            "\t\t\t\tparent_h_cgroup, idx);",
            "\t\t}",
            "\t\tpage_counter_init(hugetlb_cgroup_counter_from_cgroup(h_cgroup,",
            "\t\t\t\t\t\t\t\t     idx),",
            "\t\t\t\t  fault_parent, false);",
            "\t\tpage_counter_init(",
            "\t\t\thugetlb_cgroup_counter_from_cgroup_rsvd(h_cgroup, idx),",
            "\t\t\trsvd_parent, false);",
            "",
            "\t\tlimit = round_down(PAGE_COUNTER_MAX,",
            "\t\t\t\t   pages_per_huge_page(&hstates[idx]));",
            "",
            "\t\tret = page_counter_set_max(",
            "\t\t\thugetlb_cgroup_counter_from_cgroup(h_cgroup, idx),",
            "\t\t\tlimit);",
            "\t\tVM_BUG_ON(ret);",
            "\t\tret = page_counter_set_max(",
            "\t\t\thugetlb_cgroup_counter_from_cgroup_rsvd(h_cgroup, idx),",
            "\t\t\tlimit);",
            "\t\tVM_BUG_ON(ret);",
            "\t}",
            "}",
            "static void hugetlb_cgroup_free(struct hugetlb_cgroup *h_cgroup)",
            "{",
            "\tint node;",
            "",
            "\tfor_each_node(node)",
            "\t\tkfree(h_cgroup->nodeinfo[node]);",
            "\tkfree(h_cgroup);",
            "}",
            "static void hugetlb_cgroup_css_free(struct cgroup_subsys_state *css)",
            "{",
            "\thugetlb_cgroup_free(hugetlb_cgroup_from_css(css));",
            "}",
            "static void hugetlb_cgroup_move_parent(int idx, struct hugetlb_cgroup *h_cg,",
            "\t\t\t\t       struct page *page)",
            "{",
            "\tunsigned int nr_pages;",
            "\tstruct page_counter *counter;",
            "\tstruct hugetlb_cgroup *page_hcg;",
            "\tstruct hugetlb_cgroup *parent = parent_hugetlb_cgroup(h_cg);",
            "\tstruct folio *folio = page_folio(page);",
            "",
            "\tpage_hcg = hugetlb_cgroup_from_folio(folio);",
            "\t/*",
            "\t * We can have pages in active list without any cgroup",
            "\t * ie, hugepage with less than 3 pages. We can safely",
            "\t * ignore those pages.",
            "\t */",
            "\tif (!page_hcg || page_hcg != h_cg)",
            "\t\tgoto out;",
            "",
            "\tnr_pages = compound_nr(page);",
            "\tif (!parent) {",
            "\t\tparent = root_h_cgroup;",
            "\t\t/* root has no limit */",
            "\t\tpage_counter_charge(&parent->hugepage[idx], nr_pages);",
            "\t}",
            "\tcounter = &h_cg->hugepage[idx];",
            "\t/* Take the pages off the local counter */",
            "\tpage_counter_cancel(counter, nr_pages);",
            "",
            "\tset_hugetlb_cgroup(folio, parent);",
            "out:",
            "\treturn;",
            "}",
            "static void hugetlb_cgroup_css_offline(struct cgroup_subsys_state *css)",
            "{",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(css);",
            "\tstruct hstate *h;",
            "\tstruct page *page;",
            "",
            "\tdo {",
            "\t\tfor_each_hstate(h) {",
            "\t\t\tspin_lock_irq(&hugetlb_lock);",
            "\t\t\tlist_for_each_entry(page, &h->hugepage_activelist, lru)",
            "\t\t\t\thugetlb_cgroup_move_parent(hstate_index(h), h_cg, page);",
            "",
            "\t\t\tspin_unlock_irq(&hugetlb_lock);",
            "\t\t}",
            "\t\tcond_resched();",
            "\t} while (hugetlb_cgroup_have_usage(h_cg));",
            "}"
          ],
          "function_name": "hugetlb_cgroup_is_root, hugetlb_cgroup_have_usage, hugetlb_cgroup_init, hugetlb_cgroup_free, hugetlb_cgroup_css_free, hugetlb_cgroup_move_parent, hugetlb_cgroup_css_offline",
          "description": "实现HugeTLB cgroup的核心管理逻辑，包含判断是否为根节点、检测使用量、初始化/释放cgroup结构、迁移父节点、处理cgroup离线状态等功能。",
          "similarity": 0.5157283544540405
        },
        {
          "chunk_id": 2,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 242,
          "end_line": 368,
          "content": [
            "static inline void hugetlb_event(struct hugetlb_cgroup *hugetlb, int idx,",
            "\t\t\t\t enum hugetlb_memory_event event)",
            "{",
            "\tatomic_long_inc(&hugetlb->events_local[idx][event]);",
            "\tcgroup_file_notify(&hugetlb->events_local_file[idx]);",
            "",
            "\tdo {",
            "\t\tatomic_long_inc(&hugetlb->events[idx][event]);",
            "\t\tcgroup_file_notify(&hugetlb->events_file[idx]);",
            "\t} while ((hugetlb = parent_hugetlb_cgroup(hugetlb)) &&",
            "\t\t !hugetlb_cgroup_is_root(hugetlb));",
            "}",
            "static int __hugetlb_cgroup_charge_cgroup(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t  struct hugetlb_cgroup **ptr,",
            "\t\t\t\t\t  bool rsvd)",
            "{",
            "\tint ret = 0;",
            "\tstruct page_counter *counter;",
            "\tstruct hugetlb_cgroup *h_cg = NULL;",
            "",
            "\tif (hugetlb_cgroup_disabled())",
            "\t\tgoto done;",
            "\t/*",
            "\t * We don't charge any cgroup if the compound page have less",
            "\t * than 3 pages.",
            "\t */",
            "\tif (huge_page_order(&hstates[idx]) < HUGETLB_CGROUP_MIN_ORDER)",
            "\t\tgoto done;",
            "again:",
            "\trcu_read_lock();",
            "\th_cg = hugetlb_cgroup_from_task(current);",
            "\tif (!css_tryget(&h_cg->css)) {",
            "\t\trcu_read_unlock();",
            "\t\tgoto again;",
            "\t}",
            "\trcu_read_unlock();",
            "",
            "\tif (!page_counter_try_charge(",
            "\t\t    __hugetlb_cgroup_counter_from_cgroup(h_cg, idx, rsvd),",
            "\t\t    nr_pages, &counter)) {",
            "\t\tret = -ENOMEM;",
            "\t\thugetlb_event(h_cg, idx, HUGETLB_MAX);",
            "\t\tcss_put(&h_cg->css);",
            "\t\tgoto done;",
            "\t}",
            "\t/* Reservations take a reference to the css because they do not get",
            "\t * reparented.",
            "\t */",
            "\tif (!rsvd)",
            "\t\tcss_put(&h_cg->css);",
            "done:",
            "\t*ptr = h_cg;",
            "\treturn ret;",
            "}",
            "int hugetlb_cgroup_charge_cgroup(int idx, unsigned long nr_pages,",
            "\t\t\t\t struct hugetlb_cgroup **ptr)",
            "{",
            "\treturn __hugetlb_cgroup_charge_cgroup(idx, nr_pages, ptr, false);",
            "}",
            "int hugetlb_cgroup_charge_cgroup_rsvd(int idx, unsigned long nr_pages,",
            "\t\t\t\t      struct hugetlb_cgroup **ptr)",
            "{",
            "\treturn __hugetlb_cgroup_charge_cgroup(idx, nr_pages, ptr, true);",
            "}",
            "static void __hugetlb_cgroup_commit_charge(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t   struct hugetlb_cgroup *h_cg,",
            "\t\t\t\t\t   struct folio *folio, bool rsvd)",
            "{",
            "\tif (hugetlb_cgroup_disabled() || !h_cg)",
            "\t\treturn;",
            "",
            "\t__set_hugetlb_cgroup(folio, h_cg, rsvd);",
            "\tif (!rsvd) {",
            "\t\tunsigned long usage =",
            "\t\t\th_cg->nodeinfo[folio_nid(folio)]->usage[idx];",
            "\t\t/*",
            "\t\t * This write is not atomic due to fetching usage and writing",
            "\t\t * to it, but that's fine because we call this with",
            "\t\t * hugetlb_lock held anyway.",
            "\t\t */",
            "\t\tWRITE_ONCE(h_cg->nodeinfo[folio_nid(folio)]->usage[idx],",
            "\t\t\t   usage + nr_pages);",
            "\t}",
            "}",
            "void hugetlb_cgroup_commit_charge(int idx, unsigned long nr_pages,",
            "\t\t\t\t  struct hugetlb_cgroup *h_cg,",
            "\t\t\t\t  struct folio *folio)",
            "{",
            "\t__hugetlb_cgroup_commit_charge(idx, nr_pages, h_cg, folio, false);",
            "}",
            "void hugetlb_cgroup_commit_charge_rsvd(int idx, unsigned long nr_pages,",
            "\t\t\t\t       struct hugetlb_cgroup *h_cg,",
            "\t\t\t\t       struct folio *folio)",
            "{",
            "\t__hugetlb_cgroup_commit_charge(idx, nr_pages, h_cg, folio, true);",
            "}",
            "static void __hugetlb_cgroup_uncharge_folio(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t   struct folio *folio, bool rsvd)",
            "{",
            "\tstruct hugetlb_cgroup *h_cg;",
            "",
            "\tif (hugetlb_cgroup_disabled())",
            "\t\treturn;",
            "\tlockdep_assert_held(&hugetlb_lock);",
            "\th_cg = __hugetlb_cgroup_from_folio(folio, rsvd);",
            "\tif (unlikely(!h_cg))",
            "\t\treturn;",
            "\t__set_hugetlb_cgroup(folio, NULL, rsvd);",
            "",
            "\tpage_counter_uncharge(__hugetlb_cgroup_counter_from_cgroup(h_cg, idx,",
            "\t\t\t\t\t\t\t\t   rsvd),",
            "\t\t\t      nr_pages);",
            "",
            "\tif (rsvd)",
            "\t\tcss_put(&h_cg->css);",
            "\telse {",
            "\t\tunsigned long usage =",
            "\t\t\th_cg->nodeinfo[folio_nid(folio)]->usage[idx];",
            "\t\t/*",
            "\t\t * This write is not atomic due to fetching usage and writing",
            "\t\t * to it, but that's fine because we call this with",
            "\t\t * hugetlb_lock held anyway.",
            "\t\t */",
            "\t\tWRITE_ONCE(h_cg->nodeinfo[folio_nid(folio)]->usage[idx],",
            "\t\t\t   usage - nr_pages);",
            "\t}",
            "}"
          ],
          "function_name": "hugetlb_event, __hugetlb_cgroup_charge_cgroup, hugetlb_cgroup_charge_cgroup, hugetlb_cgroup_charge_cgroup_rsvd, __hugetlb_cgroup_commit_charge, hugetlb_cgroup_commit_charge, hugetlb_cgroup_commit_charge_rsvd, __hugetlb_cgroup_uncharge_folio",
          "description": "处理HugeTLB页面分配时的计费操作，包含事件记录、尝试充电、提交充电等流程，区分普通页与保留页的计数逻辑，并维护各层级cgroup的使用统计。",
          "similarity": 0.5150347948074341
        },
        {
          "chunk_id": 4,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 520,
          "end_line": 626,
          "content": [
            "static u64 hugetlb_cgroup_read_u64(struct cgroup_subsys_state *css,",
            "\t\t\t\t   struct cftype *cft)",
            "{",
            "\tstruct page_counter *counter;",
            "\tstruct page_counter *rsvd_counter;",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(css);",
            "",
            "\tcounter = &h_cg->hugepage[MEMFILE_IDX(cft->private)];",
            "\trsvd_counter = &h_cg->rsvd_hugepage[MEMFILE_IDX(cft->private)];",
            "",
            "\tswitch (MEMFILE_ATTR(cft->private)) {",
            "\tcase RES_USAGE:",
            "\t\treturn (u64)page_counter_read(counter) * PAGE_SIZE;",
            "\tcase RES_RSVD_USAGE:",
            "\t\treturn (u64)page_counter_read(rsvd_counter) * PAGE_SIZE;",
            "\tcase RES_LIMIT:",
            "\t\treturn (u64)counter->max * PAGE_SIZE;",
            "\tcase RES_RSVD_LIMIT:",
            "\t\treturn (u64)rsvd_counter->max * PAGE_SIZE;",
            "\tcase RES_MAX_USAGE:",
            "\t\treturn (u64)counter->watermark * PAGE_SIZE;",
            "\tcase RES_RSVD_MAX_USAGE:",
            "\t\treturn (u64)rsvd_counter->watermark * PAGE_SIZE;",
            "\tcase RES_FAILCNT:",
            "\t\treturn counter->failcnt;",
            "\tcase RES_RSVD_FAILCNT:",
            "\t\treturn rsvd_counter->failcnt;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "}",
            "static int hugetlb_cgroup_read_u64_max(struct seq_file *seq, void *v)",
            "{",
            "\tint idx;",
            "\tu64 val;",
            "\tstruct cftype *cft = seq_cft(seq);",
            "\tunsigned long limit;",
            "\tstruct page_counter *counter;",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(seq_css(seq));",
            "",
            "\tidx = MEMFILE_IDX(cft->private);",
            "\tcounter = &h_cg->hugepage[idx];",
            "",
            "\tlimit = round_down(PAGE_COUNTER_MAX,",
            "\t\t\t   pages_per_huge_page(&hstates[idx]));",
            "",
            "\tswitch (MEMFILE_ATTR(cft->private)) {",
            "\tcase RES_RSVD_USAGE:",
            "\t\tcounter = &h_cg->rsvd_hugepage[idx];",
            "\t\tfallthrough;",
            "\tcase RES_USAGE:",
            "\t\tval = (u64)page_counter_read(counter);",
            "\t\tseq_printf(seq, \"%llu\\n\", val * PAGE_SIZE);",
            "\t\tbreak;",
            "\tcase RES_RSVD_LIMIT:",
            "\t\tcounter = &h_cg->rsvd_hugepage[idx];",
            "\t\tfallthrough;",
            "\tcase RES_LIMIT:",
            "\t\tval = (u64)counter->max;",
            "\t\tif (val == limit)",
            "\t\t\tseq_puts(seq, \"max\\n\");",
            "\t\telse",
            "\t\t\tseq_printf(seq, \"%llu\\n\", val * PAGE_SIZE);",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static ssize_t hugetlb_cgroup_write(struct kernfs_open_file *of,",
            "\t\t\t\t    char *buf, size_t nbytes, loff_t off,",
            "\t\t\t\t    const char *max)",
            "{",
            "\tint ret, idx;",
            "\tunsigned long nr_pages;",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(of_css(of));",
            "\tbool rsvd = false;",
            "",
            "\tif (hugetlb_cgroup_is_root(h_cg)) /* Can't set limit on root */",
            "\t\treturn -EINVAL;",
            "",
            "\tbuf = strstrip(buf);",
            "\tret = page_counter_memparse(buf, max, &nr_pages);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tidx = MEMFILE_IDX(of_cft(of)->private);",
            "\tnr_pages = round_down(nr_pages, pages_per_huge_page(&hstates[idx]));",
            "",
            "\tswitch (MEMFILE_ATTR(of_cft(of)->private)) {",
            "\tcase RES_RSVD_LIMIT:",
            "\t\trsvd = true;",
            "\t\tfallthrough;",
            "\tcase RES_LIMIT:",
            "\t\tmutex_lock(&hugetlb_limit_mutex);",
            "\t\tret = page_counter_set_max(",
            "\t\t\t__hugetlb_cgroup_counter_from_cgroup(h_cg, idx, rsvd),",
            "\t\t\tnr_pages);",
            "\t\tmutex_unlock(&hugetlb_limit_mutex);",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tret = -EINVAL;",
            "\t\tbreak;",
            "\t}",
            "\treturn ret ?: nbytes;",
            "}"
          ],
          "function_name": "hugetlb_cgroup_read_u64, hugetlb_cgroup_read_u64_max, hugetlb_cgroup_write",
          "description": "提供HugeTLB cgroup的监控接口，实现读取当前使用量、限制等参数的功能，并支持通过接口设置内存限制参数。",
          "similarity": 0.5089244842529297
        },
        {
          "chunk_id": 3,
          "file_path": "mm/hugetlb_cgroup.c",
          "start_line": 381,
          "end_line": 500,
          "content": [
            "void hugetlb_cgroup_uncharge_folio(int idx, unsigned long nr_pages,",
            "\t\t\t\t  struct folio *folio)",
            "{",
            "\t__hugetlb_cgroup_uncharge_folio(idx, nr_pages, folio, false);",
            "}",
            "void hugetlb_cgroup_uncharge_folio_rsvd(int idx, unsigned long nr_pages,",
            "\t\t\t\t       struct folio *folio)",
            "{",
            "\t__hugetlb_cgroup_uncharge_folio(idx, nr_pages, folio, true);",
            "}",
            "static void __hugetlb_cgroup_uncharge_cgroup(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t     struct hugetlb_cgroup *h_cg,",
            "\t\t\t\t\t     bool rsvd)",
            "{",
            "\tif (hugetlb_cgroup_disabled() || !h_cg)",
            "\t\treturn;",
            "",
            "\tif (huge_page_order(&hstates[idx]) < HUGETLB_CGROUP_MIN_ORDER)",
            "\t\treturn;",
            "",
            "\tpage_counter_uncharge(__hugetlb_cgroup_counter_from_cgroup(h_cg, idx,",
            "\t\t\t\t\t\t\t\t   rsvd),",
            "\t\t\t      nr_pages);",
            "",
            "\tif (rsvd)",
            "\t\tcss_put(&h_cg->css);",
            "}",
            "void hugetlb_cgroup_uncharge_cgroup(int idx, unsigned long nr_pages,",
            "\t\t\t\t    struct hugetlb_cgroup *h_cg)",
            "{",
            "\t__hugetlb_cgroup_uncharge_cgroup(idx, nr_pages, h_cg, false);",
            "}",
            "void hugetlb_cgroup_uncharge_cgroup_rsvd(int idx, unsigned long nr_pages,",
            "\t\t\t\t\t struct hugetlb_cgroup *h_cg)",
            "{",
            "\t__hugetlb_cgroup_uncharge_cgroup(idx, nr_pages, h_cg, true);",
            "}",
            "void hugetlb_cgroup_uncharge_counter(struct resv_map *resv, unsigned long start,",
            "\t\t\t\t     unsigned long end)",
            "{",
            "\tif (hugetlb_cgroup_disabled() || !resv || !resv->reservation_counter ||",
            "\t    !resv->css)",
            "\t\treturn;",
            "",
            "\tpage_counter_uncharge(resv->reservation_counter,",
            "\t\t\t      (end - start) * resv->pages_per_hpage);",
            "\tcss_put(resv->css);",
            "}",
            "void hugetlb_cgroup_uncharge_file_region(struct resv_map *resv,",
            "\t\t\t\t\t struct file_region *rg,",
            "\t\t\t\t\t unsigned long nr_pages,",
            "\t\t\t\t\t bool region_del)",
            "{",
            "\tif (hugetlb_cgroup_disabled() || !resv || !rg || !nr_pages)",
            "\t\treturn;",
            "",
            "\tif (rg->reservation_counter && resv->pages_per_hpage &&",
            "\t    !resv->reservation_counter) {",
            "\t\tpage_counter_uncharge(rg->reservation_counter,",
            "\t\t\t\t      nr_pages * resv->pages_per_hpage);",
            "\t\t/*",
            "\t\t * Only do css_put(rg->css) when we delete the entire region",
            "\t\t * because one file_region must hold exactly one css reference.",
            "\t\t */",
            "\t\tif (region_del)",
            "\t\t\tcss_put(rg->css);",
            "\t}",
            "}",
            "static int hugetlb_cgroup_read_numa_stat(struct seq_file *seq, void *dummy)",
            "{",
            "\tint nid;",
            "\tstruct cftype *cft = seq_cft(seq);",
            "\tint idx = MEMFILE_IDX(cft->private);",
            "\tbool legacy = MEMFILE_ATTR(cft->private);",
            "\tstruct hugetlb_cgroup *h_cg = hugetlb_cgroup_from_css(seq_css(seq));",
            "\tstruct cgroup_subsys_state *css;",
            "\tunsigned long usage;",
            "",
            "\tif (legacy) {",
            "\t\t/* Add up usage across all nodes for the non-hierarchical total. */",
            "\t\tusage = 0;",
            "\t\tfor_each_node_state(nid, N_MEMORY)",
            "\t\t\tusage += READ_ONCE(h_cg->nodeinfo[nid]->usage[idx]);",
            "\t\tseq_printf(seq, \"total=%lu\", usage * PAGE_SIZE);",
            "",
            "\t\t/* Simply print the per-node usage for the non-hierarchical total. */",
            "\t\tfor_each_node_state(nid, N_MEMORY)",
            "\t\t\tseq_printf(seq, \" N%d=%lu\", nid,",
            "\t\t\t\t   READ_ONCE(h_cg->nodeinfo[nid]->usage[idx]) *",
            "\t\t\t\t\t   PAGE_SIZE);",
            "\t\tseq_putc(seq, '\\n');",
            "\t}",
            "",
            "\t/*",
            "\t * The hierarchical total is pretty much the value recorded by the",
            "\t * counter, so use that.",
            "\t */",
            "\tseq_printf(seq, \"%stotal=%lu\", legacy ? \"hierarchical_\" : \"\",",
            "\t\t   page_counter_read(&h_cg->hugepage[idx]) * PAGE_SIZE);",
            "",
            "\t/*",
            "\t * For each node, transverse the css tree to obtain the hierarchical",
            "\t * node usage.",
            "\t */",
            "\tfor_each_node_state(nid, N_MEMORY) {",
            "\t\tusage = 0;",
            "\t\trcu_read_lock();",
            "\t\tcss_for_each_descendant_pre(css, &h_cg->css) {",
            "\t\t\tusage += READ_ONCE(hugetlb_cgroup_from_css(css)",
            "\t\t\t\t\t\t   ->nodeinfo[nid]",
            "\t\t\t\t\t\t   ->usage[idx]);",
            "\t\t}",
            "\t\trcu_read_unlock();",
            "\t\tseq_printf(seq, \" N%d=%lu\", nid, usage * PAGE_SIZE);",
            "\t}",
            "",
            "\tseq_putc(seq, '\\n');",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "hugetlb_cgroup_uncharge_folio, hugetlb_cgroup_uncharge_folio_rsvd, __hugetlb_cgroup_uncharge_cgroup, hugetlb_cgroup_uncharge_cgroup, hugetlb_cgroup_uncharge_cgroup_rsvd, hugetlb_cgroup_uncharge_counter, hugetlb_cgroup_uncharge_file_region, hugetlb_cgroup_read_numa_stat",
          "description": "实现HugeTLB页面释放时的反向计费操作，包含对单个folio和整体cgroup的解除分配逻辑，以及读取NUMA节点统计信息的实现。",
          "similarity": 0.5064830780029297
        }
      ]
    },
    {
      "source_file": "mm/memcontrol-v1.c",
      "md_summary": "> 自动生成时间: 2025-12-07 16:38:55\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `memcontrol-v1.c`\n\n---\n\n# memcontrol-v1.c 技术文档\n\n## 1. 文件概述\n\n`memcontrol-v1.c` 是 Linux 内核内存控制组（Memory Cgroup）v1 接口的核心实现文件之一，主要负责基于软限制（soft limit）的内存回收机制、OOM 事件通知以及与 cgroup v1 兼容的资源统计和管理功能。该文件维护了一个独立于 cgroup 层级结构的红黑树（RB-Tree），用于高效地追踪和选择超出软限制最多的内存控制组进行内存回收。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct mem_cgroup_tree_per_node`**  \n  每个 NUMA 节点对应的红黑树结构，用于存储超出软限制的 `mem_cgroup_per_node` 实例。\n  - `rb_root`: 红黑树根节点\n  - `rb_rightmost`: 指向使用量超出软限制最多的节点（树中最右侧节点）\n  - `lock`: 保护该树的自旋锁\n\n- **`struct mem_cgroup_tree`**  \n  全局软限制树结构，包含每个 NUMA 节点对应的 `mem_cgroup_tree_per_node`。\n\n- **`struct mem_cgroup_eventfd_list`**  \n  用于 OOM 事件通知的 eventfd 列表项。\n\n- **`struct mem_cgroup_event`**  \n  表示用户空间注册的内存事件（如 OOM、阈值触发等），支持通过 eventfd 通知用户空间。\n\n- **枚举常量 `RES_*`**  \n  定义了 cgroup v1 接口中可读写的资源属性类型（如使用量、限制、最大使用量、失败计数、软限制等）。\n\n### 主要函数\n\n- **`__mem_cgroup_insert_exceeded()` / `__mem_cgroup_remove_exceeded()`**  \n  在指定节点的软限制红黑树中插入或移除一个 `mem_cgroup_per_node` 节点。\n\n- **`memcg1_update_tree()`**  \n  根据当前内存使用量与软限制的差值，更新指定 memcg 及其所有祖先在软限制树中的位置。\n\n- **`memcg1_remove_from_trees()`**  \n  在 memcg 销毁时，将其从所有 NUMA 节点的软限制树中移除。\n\n- **`mem_cgroup_largest_soft_limit_node()`**  \n  从指定节点的软限制树中找出超出软限制最多的 memcg 节点，用于优先回收。\n\n- **`mem_cgroup_soft_reclaim()`**  \n  对指定 memcg 层级结构执行软限制驱动的内存回收。\n\n- **`memcg1_soft_limit_reclaim()`**（未完整显示）  \n  全局软限制回收入口函数，由内存短缺路径调用，尝试从超出软限制的 memcg 中回收内存。\n\n## 3. 关键实现\n\n### 软限制红黑树机制\n\n- 所有超出软限制（`memory.usage > soft_limit`）的 `mem_cgroup_per_node` 实例被组织到 per-NUMA-node 的红黑树中。\n- 树按 `usage_in_excess = usage - soft_limit` 升序排列，最右侧节点即为超出最多的 memcg。\n- 当 memcg 的内存使用量变化或软限制被修改时，调用 `memcg1_update_tree()` 更新其在树中的位置（先删除再重新插入）。\n- 回收时优先选择 `rb_rightmost` 节点，确保优先回收“最违规”的 memcg。\n\n### 层级遍历与祖先更新\n\n- 在启用 cgroup 层级模式时，子 memcg 的内存使用会影响父 memcg 的统计。\n- 因此，当子 memcg 的使用量变化时，需向上遍历所有祖先，更新它们在软限制树中的状态。\n\n### 防止无限循环的回收控制\n\n- `MEM_CGROUP_MAX_RECLAIM_LOOPS`（100）和 `MEM_CGROUP_MAX_SOFT_LIMIT_RECLAIM_LOOPS`（2）用于限制回收循环次数。\n- 若一轮遍历未回收足够内存（`total < excess >> 2`），最多再尝试一次。\n\n### 与 LRU_GEN 的集成\n\n- 若启用了多代 LRU（`lru_gen_enabled()`），则绕过红黑树机制，直接调用 `lru_gen_soft_reclaim()` 进行软限制回收。\n\n### 事件通知机制\n\n- 支持通过 `eventfd` 向用户空间发送 OOM 或其他内存事件通知。\n- 使用 `poll_table` 和 `wait_queue` 实现 eventfd 的自动注销（当 fd 关闭时）。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/memcontrol.h>`：内存控制组核心接口\n  - `<linux/swap.h>`, `\"swap.h\"`：交换子系统支持\n  - `<linux/eventfd.h>`, `<linux/poll.h>`：事件通知机制\n  - `\"internal.h\"`：内核内存管理内部接口\n\n- **功能依赖**：\n  - 依赖 `page_counter` 子系统进行内存使用量统计\n  - 依赖 `mem_cgroup_iter()` 实现层级遍历\n  - 依赖 `mem_cgroup_shrink_node()` 执行实际页面回收\n  - 可选依赖 `lru_gen` 多代 LRU 回收器\n\n- **配置依赖**：\n  - `CONFIG_MEMCG`：必须启用内存 cgroup\n  - `CONFIG_LOCKDEP`：仅在调试时定义锁依赖映射\n\n## 5. 使用场景\n\n- **内存压力下的软限制回收**：当系统内存紧张时，`kswapd` 或直接回收路径会调用 `memcg1_soft_limit_reclaim()`，优先从超出软限制的 memcg 中回收内存，以维持服务质量（QoS）。\n- **cgroup v1 接口兼容**：为 `/sys/fs/cgroup/memory/` 下的 `memory.soft_limit_in_bytes` 等文件提供后端支持。\n- **OOM 事件通知**：当 memcg 触发 OOM 时，通过预先注册的 eventfd 向用户空间守护进程（如容器运行时）发送通知。\n- **动态资源调整**：当用户通过写入 `memory.soft_limit_in_bytes` 修改软限制时，触发 `memcg1_update_tree()` 更新红黑树结构。\n- **memcg 销毁清理**：在 cgroup 被删除时，确保其从所有软限制树中正确移除，防止悬挂指针。",
      "similarity": 0.5767921209335327,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 222,
          "end_line": 364,
          "content": [
            "void memcg1_remove_from_trees(struct mem_cgroup *memcg)",
            "{",
            "\tstruct mem_cgroup_tree_per_node *mctz;",
            "\tstruct mem_cgroup_per_node *mz;",
            "\tint nid;",
            "",
            "\tfor_each_node(nid) {",
            "\t\tmz = memcg->nodeinfo[nid];",
            "\t\tmctz = soft_limit_tree.rb_tree_per_node[nid];",
            "\t\tif (mctz)",
            "\t\t\tmem_cgroup_remove_exceeded(mz, mctz);",
            "\t}",
            "}",
            "static int mem_cgroup_soft_reclaim(struct mem_cgroup *root_memcg,",
            "\t\t\t\t   pg_data_t *pgdat,",
            "\t\t\t\t   gfp_t gfp_mask,",
            "\t\t\t\t   unsigned long *total_scanned)",
            "{",
            "\tstruct mem_cgroup *victim = NULL;",
            "\tint total = 0;",
            "\tint loop = 0;",
            "\tunsigned long excess;",
            "\tunsigned long nr_scanned;",
            "\tstruct mem_cgroup_reclaim_cookie reclaim = {",
            "\t\t.pgdat = pgdat,",
            "\t};",
            "",
            "\texcess = soft_limit_excess(root_memcg);",
            "",
            "\twhile (1) {",
            "\t\tvictim = mem_cgroup_iter(root_memcg, victim, &reclaim);",
            "\t\tif (!victim) {",
            "\t\t\tloop++;",
            "\t\t\tif (loop >= 2) {",
            "\t\t\t\t/*",
            "\t\t\t\t * If we have not been able to reclaim",
            "\t\t\t\t * anything, it might because there are",
            "\t\t\t\t * no reclaimable pages under this hierarchy",
            "\t\t\t\t */",
            "\t\t\t\tif (!total)",
            "\t\t\t\t\tbreak;",
            "\t\t\t\t/*",
            "\t\t\t\t * We want to do more targeted reclaim.",
            "\t\t\t\t * excess >> 2 is not to excessive so as to",
            "\t\t\t\t * reclaim too much, nor too less that we keep",
            "\t\t\t\t * coming back to reclaim from this cgroup",
            "\t\t\t\t */",
            "\t\t\t\tif (total >= (excess >> 2) ||",
            "\t\t\t\t\t(loop > MEM_CGROUP_MAX_RECLAIM_LOOPS))",
            "\t\t\t\t\tbreak;",
            "\t\t\t}",
            "\t\t\tcontinue;",
            "\t\t}",
            "\t\ttotal += mem_cgroup_shrink_node(victim, gfp_mask, false,",
            "\t\t\t\t\tpgdat, &nr_scanned);",
            "\t\t*total_scanned += nr_scanned;",
            "\t\tif (!soft_limit_excess(root_memcg))",
            "\t\t\tbreak;",
            "\t}",
            "\tmem_cgroup_iter_break(root_memcg, victim);",
            "\treturn total;",
            "}",
            "unsigned long memcg1_soft_limit_reclaim(pg_data_t *pgdat, int order,",
            "\t\t\t\t\t    gfp_t gfp_mask,",
            "\t\t\t\t\t    unsigned long *total_scanned)",
            "{",
            "\tunsigned long nr_reclaimed = 0;",
            "\tstruct mem_cgroup_per_node *mz, *next_mz = NULL;",
            "\tunsigned long reclaimed;",
            "\tint loop = 0;",
            "\tstruct mem_cgroup_tree_per_node *mctz;",
            "\tunsigned long excess;",
            "",
            "\tif (lru_gen_enabled())",
            "\t\treturn 0;",
            "",
            "\tif (order > 0)",
            "\t\treturn 0;",
            "",
            "\tmctz = soft_limit_tree.rb_tree_per_node[pgdat->node_id];",
            "",
            "\t/*",
            "\t * Do not even bother to check the largest node if the root",
            "\t * is empty. Do it lockless to prevent lock bouncing. Races",
            "\t * are acceptable as soft limit is best effort anyway.",
            "\t */",
            "\tif (!mctz || RB_EMPTY_ROOT(&mctz->rb_root))",
            "\t\treturn 0;",
            "",
            "\t/*",
            "\t * This loop can run a while, specially if mem_cgroup's continuously",
            "\t * keep exceeding their soft limit and putting the system under",
            "\t * pressure",
            "\t */",
            "\tdo {",
            "\t\tif (next_mz)",
            "\t\t\tmz = next_mz;",
            "\t\telse",
            "\t\t\tmz = mem_cgroup_largest_soft_limit_node(mctz);",
            "\t\tif (!mz)",
            "\t\t\tbreak;",
            "",
            "\t\treclaimed = mem_cgroup_soft_reclaim(mz->memcg, pgdat,",
            "\t\t\t\t\t\t    gfp_mask, total_scanned);",
            "\t\tnr_reclaimed += reclaimed;",
            "\t\tspin_lock_irq(&mctz->lock);",
            "",
            "\t\t/*",
            "\t\t * If we failed to reclaim anything from this memory cgroup",
            "\t\t * it is time to move on to the next cgroup",
            "\t\t */",
            "\t\tnext_mz = NULL;",
            "\t\tif (!reclaimed)",
            "\t\t\tnext_mz = __mem_cgroup_largest_soft_limit_node(mctz);",
            "",
            "\t\texcess = soft_limit_excess(mz->memcg);",
            "\t\t/*",
            "\t\t * One school of thought says that we should not add",
            "\t\t * back the node to the tree if reclaim returns 0.",
            "\t\t * But our reclaim could return 0, simply because due",
            "\t\t * to priority we are exposing a smaller subset of",
            "\t\t * memory to reclaim from. Consider this as a longer",
            "\t\t * term TODO.",
            "\t\t */",
            "\t\t/* If excess == 0, no tree ops */",
            "\t\t__mem_cgroup_insert_exceeded(mz, mctz, excess);",
            "\t\tspin_unlock_irq(&mctz->lock);",
            "\t\tcss_put(&mz->memcg->css);",
            "\t\tloop++;",
            "\t\t/*",
            "\t\t * Could not reclaim anything and there are no more",
            "\t\t * mem cgroups to try or we seem to be looping without",
            "\t\t * reclaiming anything.",
            "\t\t */",
            "\t\tif (!nr_reclaimed &&",
            "\t\t\t(next_mz == NULL ||",
            "\t\t\tloop > MEM_CGROUP_MAX_SOFT_LIMIT_RECLAIM_LOOPS))",
            "\t\t\tbreak;",
            "\t} while (!nr_reclaimed);",
            "\tif (next_mz)",
            "\t\tcss_put(&next_mz->memcg->css);",
            "\treturn nr_reclaimed;",
            "}"
          ],
          "function_name": "memcg1_remove_from_trees, mem_cgroup_soft_reclaim, memcg1_soft_limit_reclaim",
          "description": "提供内存回收逻辑，当内存控制组超过软限制时，通过迭代寻找目标cgroup执行内存回收操作，并通过循环控制防止无限回收，最终返回回收的页面数量。",
          "similarity": 0.564929187297821
        },
        {
          "chunk_id": 9,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 1400,
          "end_line": 1528,
          "content": [
            "static int mem_cgroup_force_empty(struct mem_cgroup *memcg)",
            "{",
            "\tint nr_retries = MAX_RECLAIM_RETRIES;",
            "",
            "\t/* we call try-to-free pages for make this cgroup empty */",
            "\tlru_add_drain_all();",
            "",
            "\tdrain_all_stock(memcg);",
            "",
            "\t/* try to free all pages in this cgroup */",
            "\twhile (nr_retries && page_counter_read(&memcg->memory)) {",
            "\t\tif (signal_pending(current))",
            "\t\t\treturn -EINTR;",
            "",
            "\t\tif (!try_to_free_mem_cgroup_pages(memcg, 1, GFP_KERNEL,",
            "\t\t\t\t\t\t  MEMCG_RECLAIM_MAY_SWAP))",
            "\t\t\tnr_retries--;",
            "\t}",
            "",
            "\treturn 0;",
            "}",
            "static ssize_t mem_cgroup_force_empty_write(struct kernfs_open_file *of,",
            "\t\t\t\t\t    char *buf, size_t nbytes,",
            "\t\t\t\t\t    loff_t off)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));",
            "",
            "\tif (mem_cgroup_is_root(memcg))",
            "\t\treturn -EINVAL;",
            "\treturn mem_cgroup_force_empty(memcg) ?: nbytes;",
            "}",
            "static u64 mem_cgroup_hierarchy_read(struct cgroup_subsys_state *css,",
            "\t\t\t\t     struct cftype *cft)",
            "{",
            "\treturn 1;",
            "}",
            "static int mem_cgroup_hierarchy_write(struct cgroup_subsys_state *css,",
            "\t\t\t\t      struct cftype *cft, u64 val)",
            "{",
            "\tif (val == 1)",
            "\t\treturn 0;",
            "",
            "\tpr_warn_once(\"Non-hierarchical mode is deprecated. \"",
            "\t\t     \"Please report your usecase to linux-mm@kvack.org if you \"",
            "\t\t     \"depend on this functionality.\\n\");",
            "",
            "\treturn -EINVAL;",
            "}",
            "static u64 mem_cgroup_read_u64(struct cgroup_subsys_state *css,",
            "\t\t\t       struct cftype *cft)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);",
            "\tstruct page_counter *counter;",
            "",
            "\tswitch (MEMFILE_TYPE(cft->private)) {",
            "\tcase _MEM:",
            "\t\tcounter = &memcg->memory;",
            "\t\tbreak;",
            "\tcase _MEMSWAP:",
            "\t\tcounter = &memcg->memsw;",
            "\t\tbreak;",
            "\tcase _KMEM:",
            "\t\tcounter = &memcg->kmem;",
            "\t\tbreak;",
            "\tcase _TCP:",
            "\t\tcounter = &memcg->tcpmem;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "",
            "\tswitch (MEMFILE_ATTR(cft->private)) {",
            "\tcase RES_USAGE:",
            "\t\tif (counter == &memcg->memory)",
            "\t\t\treturn (u64)mem_cgroup_usage(memcg, false) * PAGE_SIZE;",
            "\t\tif (counter == &memcg->memsw)",
            "\t\t\treturn (u64)mem_cgroup_usage(memcg, true) * PAGE_SIZE;",
            "\t\treturn (u64)page_counter_read(counter) * PAGE_SIZE;",
            "\tcase RES_LIMIT:",
            "\t\treturn (u64)counter->max * PAGE_SIZE;",
            "\tcase RES_MAX_USAGE:",
            "\t\treturn (u64)counter->watermark * PAGE_SIZE;",
            "\tcase RES_FAILCNT:",
            "\t\treturn counter->failcnt;",
            "\tcase RES_SOFT_LIMIT:",
            "\t\treturn (u64)READ_ONCE(memcg->soft_limit) * PAGE_SIZE;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "}",
            "static int mem_cgroup_dummy_seq_show(__always_unused struct seq_file *m,",
            "\t\t\t\t     __always_unused void *v)",
            "{",
            "\treturn -EINVAL;",
            "}",
            "static int memcg_update_tcp_max(struct mem_cgroup *memcg, unsigned long max)",
            "{",
            "\tint ret;",
            "",
            "\tmutex_lock(&memcg_max_mutex);",
            "",
            "\tret = page_counter_set_max(&memcg->tcpmem, max);",
            "\tif (ret)",
            "\t\tgoto out;",
            "",
            "\tif (!memcg->tcpmem_active) {",
            "\t\t/*",
            "\t\t * The active flag needs to be written after the static_key",
            "\t\t * update. This is what guarantees that the socket activation",
            "\t\t * function is the last one to run. See mem_cgroup_sk_alloc()",
            "\t\t * for details, and note that we don't mark any socket as",
            "\t\t * belonging to this memcg until that flag is up.",
            "\t\t *",
            "\t\t * We need to do this, because static_keys will span multiple",
            "\t\t * sites, but we can't control their order. If we mark a socket",
            "\t\t * as accounted, but the accounting functions are not patched in",
            "\t\t * yet, we'll lose accounting.",
            "\t\t *",
            "\t\t * We never race with the readers in mem_cgroup_sk_alloc(),",
            "\t\t * because when this value change, the code to process it is not",
            "\t\t * patched in yet.",
            "\t\t */",
            "\t\tstatic_branch_inc(&memcg_sockets_enabled_key);",
            "\t\tmemcg->tcpmem_active = true;",
            "\t}",
            "out:",
            "\tmutex_unlock(&memcg_max_mutex);",
            "\treturn ret;",
            "}"
          ],
          "function_name": "mem_cgroup_force_empty, mem_cgroup_force_empty_write, mem_cgroup_hierarchy_read, mem_cgroup_hierarchy_write, mem_cgroup_read_u64, mem_cgroup_dummy_seq_show, memcg_update_tcp_max",
          "description": "提供内存控制组的强制清空、层级参数读写及统计信息查询功能。包含内存使用量读取接口、虚拟内存软限制更新及TCP内存上限调整逻辑，支持不同资源类型的计数器访问。",
          "similarity": 0.5474708676338196
        },
        {
          "chunk_id": 10,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 1544,
          "end_line": 1646,
          "content": [
            "static ssize_t mem_cgroup_write(struct kernfs_open_file *of,",
            "\t\t\t\tchar *buf, size_t nbytes, loff_t off)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));",
            "\tunsigned long nr_pages;",
            "\tint ret;",
            "",
            "\tbuf = strstrip(buf);",
            "\tret = page_counter_memparse(buf, \"-1\", &nr_pages);",
            "\tif (ret)",
            "\t\treturn ret;",
            "",
            "\tswitch (MEMFILE_ATTR(of_cft(of)->private)) {",
            "\tcase RES_LIMIT:",
            "\t\tif (mem_cgroup_is_root(memcg)) { /* Can't set limit on root */",
            "\t\t\tret = -EINVAL;",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tswitch (MEMFILE_TYPE(of_cft(of)->private)) {",
            "\t\tcase _MEM:",
            "\t\t\tret = mem_cgroup_resize_max(memcg, nr_pages, false);",
            "\t\t\tbreak;",
            "\t\tcase _MEMSWAP:",
            "\t\t\tret = mem_cgroup_resize_max(memcg, nr_pages, true);",
            "\t\t\tbreak;",
            "\t\tcase _KMEM:",
            "\t\t\tpr_warn_once(\"kmem.limit_in_bytes is deprecated and will be removed. \"",
            "\t\t\t\t     \"Writing any value to this file has no effect. \"",
            "\t\t\t\t     \"Please report your usecase to linux-mm@kvack.org if you \"",
            "\t\t\t\t     \"depend on this functionality.\\n\");",
            "\t\t\tret = 0;",
            "\t\t\tbreak;",
            "\t\tcase _TCP:",
            "\t\t\tret = memcg_update_tcp_max(memcg, nr_pages);",
            "\t\t\tbreak;",
            "\t\t}",
            "\t\tbreak;",
            "\tcase RES_SOFT_LIMIT:",
            "\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT)) {",
            "\t\t\tret = -EOPNOTSUPP;",
            "\t\t} else {",
            "\t\t\tWRITE_ONCE(memcg->soft_limit, nr_pages);",
            "\t\t\tret = 0;",
            "\t\t}",
            "\t\tbreak;",
            "\t}",
            "\treturn ret ?: nbytes;",
            "}",
            "static ssize_t mem_cgroup_reset(struct kernfs_open_file *of, char *buf,",
            "\t\t\t\tsize_t nbytes, loff_t off)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(of_css(of));",
            "\tstruct page_counter *counter;",
            "",
            "\tswitch (MEMFILE_TYPE(of_cft(of)->private)) {",
            "\tcase _MEM:",
            "\t\tcounter = &memcg->memory;",
            "\t\tbreak;",
            "\tcase _MEMSWAP:",
            "\t\tcounter = &memcg->memsw;",
            "\t\tbreak;",
            "\tcase _KMEM:",
            "\t\tcounter = &memcg->kmem;",
            "\t\tbreak;",
            "\tcase _TCP:",
            "\t\tcounter = &memcg->tcpmem;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "",
            "\tswitch (MEMFILE_ATTR(of_cft(of)->private)) {",
            "\tcase RES_MAX_USAGE:",
            "\t\tpage_counter_reset_watermark(counter);",
            "\t\tbreak;",
            "\tcase RES_FAILCNT:",
            "\t\tcounter->failcnt = 0;",
            "\t\tbreak;",
            "\tdefault:",
            "\t\tBUG();",
            "\t}",
            "",
            "\treturn nbytes;",
            "}",
            "static unsigned long mem_cgroup_node_nr_lru_pages(struct mem_cgroup *memcg,",
            "\t\t\t\tint nid, unsigned int lru_mask, bool tree)",
            "{",
            "\tstruct lruvec *lruvec = mem_cgroup_lruvec(memcg, NODE_DATA(nid));",
            "\tunsigned long nr = 0;",
            "\tenum lru_list lru;",
            "",
            "\tVM_BUG_ON((unsigned)nid >= nr_node_ids);",
            "",
            "\tfor_each_lru(lru) {",
            "\t\tif (!(BIT(lru) & lru_mask))",
            "\t\t\tcontinue;",
            "\t\tif (tree)",
            "\t\t\tnr += lruvec_page_state(lruvec, NR_LRU_BASE + lru);",
            "\t\telse",
            "\t\t\tnr += lruvec_page_state_local(lruvec, NR_LRU_BASE + lru);",
            "\t}",
            "\treturn nr;",
            "}"
          ],
          "function_name": "mem_cgroup_write, mem_cgroup_reset, mem_cgroup_node_nr_lru_pages",
          "description": "实现内存控制组的写操作接口，根据不同的属性类型设置内存限制（如RES_LIMIT、RES_SOFT_LIMIT），对根控制组禁止设置限制并处理相应错误码。",
          "similarity": 0.5462139844894409
        },
        {
          "chunk_id": 1,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 109,
          "end_line": 216,
          "content": [
            "static void __mem_cgroup_insert_exceeded(struct mem_cgroup_per_node *mz,",
            "\t\t\t\t\t struct mem_cgroup_tree_per_node *mctz,",
            "\t\t\t\t\t unsigned long new_usage_in_excess)",
            "{",
            "\tstruct rb_node **p = &mctz->rb_root.rb_node;",
            "\tstruct rb_node *parent = NULL;",
            "\tstruct mem_cgroup_per_node *mz_node;",
            "\tbool rightmost = true;",
            "",
            "\tif (mz->on_tree)",
            "\t\treturn;",
            "",
            "\tmz->usage_in_excess = new_usage_in_excess;",
            "\tif (!mz->usage_in_excess)",
            "\t\treturn;",
            "\twhile (*p) {",
            "\t\tparent = *p;",
            "\t\tmz_node = rb_entry(parent, struct mem_cgroup_per_node,",
            "\t\t\t\t\ttree_node);",
            "\t\tif (mz->usage_in_excess < mz_node->usage_in_excess) {",
            "\t\t\tp = &(*p)->rb_left;",
            "\t\t\trightmost = false;",
            "\t\t} else {",
            "\t\t\tp = &(*p)->rb_right;",
            "\t\t}",
            "\t}",
            "",
            "\tif (rightmost)",
            "\t\tmctz->rb_rightmost = &mz->tree_node;",
            "",
            "\trb_link_node(&mz->tree_node, parent, p);",
            "\trb_insert_color(&mz->tree_node, &mctz->rb_root);",
            "\tmz->on_tree = true;",
            "}",
            "static void __mem_cgroup_remove_exceeded(struct mem_cgroup_per_node *mz,",
            "\t\t\t\t\t struct mem_cgroup_tree_per_node *mctz)",
            "{",
            "\tif (!mz->on_tree)",
            "\t\treturn;",
            "",
            "\tif (&mz->tree_node == mctz->rb_rightmost)",
            "\t\tmctz->rb_rightmost = rb_prev(&mz->tree_node);",
            "",
            "\trb_erase(&mz->tree_node, &mctz->rb_root);",
            "\tmz->on_tree = false;",
            "}",
            "static void mem_cgroup_remove_exceeded(struct mem_cgroup_per_node *mz,",
            "\t\t\t\t       struct mem_cgroup_tree_per_node *mctz)",
            "{",
            "\tunsigned long flags;",
            "",
            "\tspin_lock_irqsave(&mctz->lock, flags);",
            "\t__mem_cgroup_remove_exceeded(mz, mctz);",
            "\tspin_unlock_irqrestore(&mctz->lock, flags);",
            "}",
            "static unsigned long soft_limit_excess(struct mem_cgroup *memcg)",
            "{",
            "\tunsigned long nr_pages = page_counter_read(&memcg->memory);",
            "\tunsigned long soft_limit = READ_ONCE(memcg->soft_limit);",
            "\tunsigned long excess = 0;",
            "",
            "\tif (nr_pages > soft_limit)",
            "\t\texcess = nr_pages - soft_limit;",
            "",
            "\treturn excess;",
            "}",
            "static void memcg1_update_tree(struct mem_cgroup *memcg, int nid)",
            "{",
            "\tunsigned long excess;",
            "\tstruct mem_cgroup_per_node *mz;",
            "\tstruct mem_cgroup_tree_per_node *mctz;",
            "",
            "\tif (lru_gen_enabled()) {",
            "\t\tif (soft_limit_excess(memcg))",
            "\t\t\tlru_gen_soft_reclaim(memcg, nid);",
            "\t\treturn;",
            "\t}",
            "",
            "\tmctz = soft_limit_tree.rb_tree_per_node[nid];",
            "\tif (!mctz)",
            "\t\treturn;",
            "\t/*",
            "\t * Necessary to update all ancestors when hierarchy is used.",
            "\t * because their event counter is not touched.",
            "\t */",
            "\tfor (; memcg; memcg = parent_mem_cgroup(memcg)) {",
            "\t\tmz = memcg->nodeinfo[nid];",
            "\t\texcess = soft_limit_excess(memcg);",
            "\t\t/*",
            "\t\t * We have to update the tree if mz is on RB-tree or",
            "\t\t * mem is over its softlimit.",
            "\t\t */",
            "\t\tif (excess || mz->on_tree) {",
            "\t\t\tunsigned long flags;",
            "",
            "\t\t\tspin_lock_irqsave(&mctz->lock, flags);",
            "\t\t\t/* if on-tree, remove it */",
            "\t\t\tif (mz->on_tree)",
            "\t\t\t\t__mem_cgroup_remove_exceeded(mz, mctz);",
            "\t\t\t/*",
            "\t\t\t * Insert again. mz->usage_in_excess will be updated.",
            "\t\t\t * If excess is 0, no tree ops.",
            "\t\t\t */",
            "\t\t\t__mem_cgroup_insert_exceeded(mz, mctz, excess);",
            "\t\t\tspin_unlock_irqrestore(&mctz->lock, flags);",
            "\t\t}",
            "\t}",
            "}"
          ],
          "function_name": "__mem_cgroup_insert_exceeded, __mem_cgroup_remove_exceeded, mem_cgroup_remove_exceeded, soft_limit_excess, memcg1_update_tree",
          "description": "实现RB树操作函数，用于将超出软限制的内存控制组节点插入或删除到RB树中，同时维护树的右极值指针，并通过遍历层级更新树结构以反映当前软限制状态。",
          "similarity": 0.5142663717269897
        },
        {
          "chunk_id": 12,
          "file_path": "mm/memcontrol-v1.c",
          "start_line": 1838,
          "end_line": 1934,
          "content": [
            "static u64 mem_cgroup_swappiness_read(struct cgroup_subsys_state *css,",
            "\t\t\t\t      struct cftype *cft)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);",
            "",
            "\treturn mem_cgroup_swappiness(memcg);",
            "}",
            "static int mem_cgroup_swappiness_write(struct cgroup_subsys_state *css,",
            "\t\t\t\t       struct cftype *cft, u64 val)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);",
            "",
            "\tif (val > 200)",
            "\t\treturn -EINVAL;",
            "",
            "\tif (!mem_cgroup_is_root(memcg))",
            "\t\tWRITE_ONCE(memcg->swappiness, val);",
            "\telse",
            "\t\tWRITE_ONCE(vm_swappiness, val);",
            "",
            "\treturn 0;",
            "}",
            "static int mem_cgroup_oom_control_read(struct seq_file *sf, void *v)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_seq(sf);",
            "",
            "\tseq_printf(sf, \"oom_kill_disable %d\\n\", READ_ONCE(memcg->oom_kill_disable));",
            "\tseq_printf(sf, \"under_oom %d\\n\", (bool)memcg->under_oom);",
            "\tseq_printf(sf, \"oom_kill %lu\\n\",",
            "\t\t   atomic_long_read(&memcg->memory_events[MEMCG_OOM_KILL]));",
            "\treturn 0;",
            "}",
            "static int mem_cgroup_oom_control_write(struct cgroup_subsys_state *css,",
            "\tstruct cftype *cft, u64 val)",
            "{",
            "\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);",
            "",
            "\t/* cannot set to root cgroup and only 0 and 1 are allowed */",
            "\tif (mem_cgroup_is_root(memcg) || !((val == 0) || (val == 1)))",
            "\t\treturn -EINVAL;",
            "",
            "\tWRITE_ONCE(memcg->oom_kill_disable, val);",
            "\tif (!val)",
            "\t\tmemcg1_oom_recover(memcg);",
            "",
            "\treturn 0;",
            "}",
            "static int mem_cgroup_slab_show(struct seq_file *m, void *p)",
            "{",
            "\t/*",
            "\t * Deprecated.",
            "\t * Please, take a look at tools/cgroup/memcg_slabinfo.py .",
            "\t */",
            "\treturn 0;",
            "}",
            "void memcg1_account_kmem(struct mem_cgroup *memcg, int nr_pages)",
            "{",
            "\tif (!cgroup_subsys_on_dfl(memory_cgrp_subsys)) {",
            "\t\tif (nr_pages > 0)",
            "\t\t\tpage_counter_charge(&memcg->kmem, nr_pages);",
            "\t\telse",
            "\t\t\tpage_counter_uncharge(&memcg->kmem, -nr_pages);",
            "\t}",
            "}",
            "bool memcg1_charge_skmem(struct mem_cgroup *memcg, unsigned int nr_pages,",
            "\t\t\t gfp_t gfp_mask)",
            "{",
            "\tstruct page_counter *fail;",
            "",
            "\tif (page_counter_try_charge(&memcg->tcpmem, nr_pages, &fail)) {",
            "\t\tmemcg->tcpmem_pressure = 0;",
            "\t\treturn true;",
            "\t}",
            "\tmemcg->tcpmem_pressure = 1;",
            "\tif (gfp_mask & __GFP_NOFAIL) {",
            "\t\tpage_counter_charge(&memcg->tcpmem, nr_pages);",
            "\t\treturn true;",
            "\t}",
            "\treturn false;",
            "}",
            "static int __init memcg1_init(void)",
            "{",
            "\tint node;",
            "",
            "\tfor_each_node(node) {",
            "\t\tstruct mem_cgroup_tree_per_node *rtpn;",
            "",
            "\t\trtpn = kzalloc_node(sizeof(*rtpn), GFP_KERNEL, node);",
            "",
            "\t\trtpn->rb_root = RB_ROOT;",
            "\t\trtpn->rb_rightmost = NULL;",
            "\t\tspin_lock_init(&rtpn->lock);",
            "\t\tsoft_limit_tree.rb_tree_per_node[node] = rtpn;",
            "\t}",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "mem_cgroup_swappiness_read, mem_cgroup_swappiness_write, mem_cgroup_oom_control_read, mem_cgroup_oom_control_write, mem_cgroup_slab_show, memcg1_account_kmem, memcg1_charge_skmem, memcg1_init",
          "description": "实现swappiness参数读写、OOM控制策略配置、Slab信息展示及内核内存计费逻辑，初始化节点级红黑树结构以支持层级内存控制。",
          "similarity": 0.5087526440620422
        }
      ]
    }
  ]
}