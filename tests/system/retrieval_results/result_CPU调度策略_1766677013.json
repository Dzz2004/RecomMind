{
  "query": "CPU调度策略",
  "timestamp": "2025-12-25 23:36:53",
  "retrieved_files": [
    {
      "source_file": "kernel/sched/cpufreq.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:02:58\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\cpufreq.c`\n\n---\n\n# `sched/cpufreq.c` 技术文档\n\n## 1. 文件概述\n\n`sched/cpufreq.c` 是 Linux 内核调度器子系统中与 CPU 频率调节（cpufreq）紧密集成的核心文件。该文件提供了调度器与 cpufreq 子系统之间的桥梁，允许调度器在运行时动态通知频率调节器当前 CPU 的负载或利用率变化，从而驱动 CPU 频率的动态调整（DVFS, Dynamic Voltage and Frequency Scaling）。其核心机制是通过 per-CPU 的回调函数指针，实现低延迟、无锁的利用率更新通知。\n\n## 2. 核心功能\n\n### 数据结构\n- `cpufreq_update_util_data`：一个 per-CPU 的 RCU 指针，指向 `struct update_util_data` 实例。该结构体封装了用于更新 CPU 利用率的回调函数及上下文数据。\n\n### 主要函数\n- `cpufreq_add_update_util_hook(int cpu, struct update_util_data *data, void (*func)(...))`  \n  为指定 CPU 注册一个利用率更新回调钩子。\n- `cpufreq_remove_update_util_hook(int cpu)`  \n  移除指定 CPU 的利用率更新回调钩子。\n- `cpufreq_this_cpu_can_update(struct cpufreq_policy *policy)`  \n  判断当前 CPU 是否有权限更新给定的 cpufreq 策略。\n\n## 3. 关键实现\n\n- **RCU 安全的回调机制**：  \n  所有对 `cpufreq_update_util_data` 的读写操作均通过 RCU（Read-Copy-Update）机制保护。写操作使用 `rcu_assign_pointer()` 发布新指针，读操作（如在 `cpufreq_update_util()` 中）位于 RCU-sched 读端临界区内，确保无锁且安全地访问回调函数。\n\n- **回调函数约束**：  \n  注册的回调函数 `func` 必须是非阻塞的（不能睡眠），因为它会在调度器关键路径中被调用（例如在 `update_load_avg()` 或 `enqueue/dequeue_task()` 路径中）。函数接收 `update_util_data` 指针、时间戳和标志位，允许驱动程序访问其私有数据结构。\n\n- **钩子注册/注销的安全性**：  \n  `cpufreq_add_update_util_hook()` 要求目标 CPU 的钩子必须为 `NULL`，否则触发 `WARN_ON`，防止重复注册。`cpufreq_remove_update_util_hook()` 仅将指针置空，调用者需自行通过 `synchronize_rcu()` 或 RCU 回调确保旧数据结构在无读者后再释放，避免 use-after-free。\n\n- **策略更新权限判断**：  \n  `cpufreq_this_cpu_can_update()` 通过两个条件判断当前 CPU 是否可更新策略：\n  1. 当前 CPU 属于该策略管理的 CPU 集合（`policy->cpus`）；\n  2. 或策略支持从任意 CPU 更新（`dvfs_possible_from_any_cpu` 为真）且当前 CPU 仍注册了有效的更新钩子（即未离线）。\n\n## 4. 依赖关系\n\n- **调度器核心**：依赖 `kernel/sched/` 中的负载跟踪和利用率计算逻辑（如 `update_load_avg()`），这些逻辑会调用 `cpufreq_update_util()` 触发频率更新。\n- **cpufreq 子系统**：与 `drivers/cpufreq/` 中的具体调频驱动（如 `schedutil`）紧密协作。`schedutil` 驱动会调用 `cpufreq_add_update_util_hook()` 注册其回调函数。\n- **RCU 子系统**：依赖 `kernel/rcu/` 提供的 RCU-sched 机制，确保多核环境下回调指针的安全读写。\n- **CPU 热插拔**：在 CPU 离线时需调用 `cpufreq_remove_update_util_hook()`，防止离线 CPU 继续参与频率决策。\n\n## 5. 使用场景\n\n- **调度器驱动的频率调节（如 schedutil）**：  \n  当启用 `schedutil` 调频策略时，该策略会为每个 CPU 注册一个回调函数。调度器在任务入队、出队或周期性负载更新时，通过 `cpufreq_update_util()` 调用此回调，将当前 CPU 的利用率信息传递给 cpufreq 驱动，驱动据此计算并设置最优频率。\n\n- **异构多核系统（如 big.LITTLE）**：  \n  在共享频率域（如多个小核共享一个调频策略）的场景中，即使当前 CPU 不属于策略的主控 CPU，只要 `dvfs_possible_from_any_cpu` 被设置，任何 CPU 都可触发该策略的频率更新，提升响应速度。\n\n- **CPU 热插拔处理**：  \n  在 CPU 离线流程中，系统会调用 `cpufreq_remove_update_util_hook()` 清除钩子，确保离线 CPU 不再影响频率决策；上线时重新注册钩子。",
      "similarity": 0.6326349377632141,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/cpufreq.c",
          "start_line": 29,
          "end_line": 51,
          "content": [
            "void cpufreq_add_update_util_hook(int cpu, struct update_util_data *data,",
            "\t\t\tvoid (*func)(struct update_util_data *data, u64 time,",
            "\t\t\t\t     unsigned int flags))",
            "{",
            "\tif (WARN_ON(!data || !func))",
            "\t\treturn;",
            "",
            "\tif (WARN_ON(per_cpu(cpufreq_update_util_data, cpu)))",
            "\t\treturn;",
            "",
            "\tdata->func = func;",
            "\trcu_assign_pointer(per_cpu(cpufreq_update_util_data, cpu), data);",
            "}",
            "void cpufreq_remove_update_util_hook(int cpu)",
            "{",
            "\trcu_assign_pointer(per_cpu(cpufreq_update_util_data, cpu), NULL);",
            "}",
            "bool cpufreq_this_cpu_can_update(struct cpufreq_policy *policy)",
            "{",
            "\treturn cpumask_test_cpu(smp_processor_id(), policy->cpus) ||",
            "\t\t(policy->dvfs_possible_from_any_cpu &&",
            "\t\t rcu_dereference_sched(*this_cpu_ptr(&cpufreq_update_util_data)));",
            "}"
          ],
          "function_name": "cpufreq_add_update_util_hook, cpufreq_remove_update_util_hook, cpufreq_this_cpu_can_update",
          "description": "实现 CPU 频率调节钩子管理功能，包含添加/移除 CPU 更新回调函数、检查当前 CPU 是否具备频率调整能力的逻辑，通过 RCU 安全地更新 per-CPU 数据结构",
          "similarity": 0.6399585008621216
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/cpufreq.c",
          "start_line": 1,
          "end_line": 28,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Scheduler code and data structures related to cpufreq.",
            " *",
            " * Copyright (C) 2016, Intel Corporation",
            " * Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>",
            " */",
            "",
            "DEFINE_PER_CPU(struct update_util_data __rcu *, cpufreq_update_util_data);",
            "",
            "/**",
            " * cpufreq_add_update_util_hook - Populate the CPU's update_util_data pointer.",
            " * @cpu: The CPU to set the pointer for.",
            " * @data: New pointer value.",
            " * @func: Callback function to set for the CPU.",
            " *",
            " * Set and publish the update_util_data pointer for the given CPU.",
            " *",
            " * The update_util_data pointer of @cpu is set to @data and the callback",
            " * function pointer in the target struct update_util_data is set to @func.",
            " * That function will be called by cpufreq_update_util() from RCU-sched",
            " * read-side critical sections, so it must not sleep.  @data will always be",
            " * passed to it as the first argument which allows the function to get to the",
            " * target update_util_data structure and its container.",
            " *",
            " * The update_util_data pointer of @cpu must be NULL when this function is",
            " * called or it will WARN() and return with no effect.",
            " */"
          ],
          "function_name": null,
          "description": "定义 per-CPU 变量 cpufreq_update_util_data，用于存储每个 CPU 的 update_util_data 结构指针，支持 CPU 频率调节时的利用率更新操作",
          "similarity": 0.520902156829834
        }
      ]
    },
    {
      "source_file": "kernel/sched/cpufreq_schedutil.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:03:51\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\cpufreq_schedutil.c`\n\n---\n\n# `sched/cpufreq_schedutil.c` 技术文档\n\n## 1. 文件概述\n\n`sched/cpufreq_schedutil.c` 实现了 Linux 内核中基于调度器提供的 CPU 利用率数据的 **schedutil CPUFreq 调速器（governor）**。该调速器通过实时获取调度器计算的 CPU 利用率（包括 CFS、RT、DL 任务以及 I/O 等待状态），动态调整 CPU 频率，以在性能与能效之间取得平衡。其核心优势在于直接利用调度器的 `util` 信息，避免传统调速器依赖采样机制带来的延迟和不准确性。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- **`struct sugov_tunables`**  \n  调速器可调参数，包含：\n  - `rate_limit_us`：频率更新的最小时间间隔（微秒），防止过于频繁的频率切换。\n\n- **`struct sugov_policy`**  \n  每个 `cpufreq_policy` 对应的 schedutil 策略实例，包含：\n  - `policy`：关联的 CPUFreq 策略。\n  - `update_lock`：保护频率更新的自旋锁。\n  - `last_freq_update_time` / `freq_update_delay_ns`：控制频率更新速率。\n  - `next_freq` / `cached_raw_freq`：目标频率与原始计算频率缓存。\n  - `irq_work` / `worker` / `thread`：用于慢速切换平台（非 fast-switch）的异步工作队列机制。\n  - `limits_changed` / `need_freq_update`：标志策略限制（如 min/max freq）是否变更。\n\n- **`struct sugov_cpu`**  \n  每个 CPU 的 schedutil 状态，包含：\n  - `update_util`：注册到调度器的回调接口（`update_util_data`）。\n  - `util` / `bw_min`：当前有效利用率及带宽最小值。\n  - `iowait_boost` / `iowait_boost_pending`：I/O 等待唤醒时的频率提升机制。\n  - `last_update`：上次更新时间戳。\n\n### 主要函数\n\n- **`sugov_should_update_freq()`**  \n  判断是否应执行频率更新，考虑硬件是否支持本 CPU 更新、策略限制变更、以及频率更新间隔限制。\n\n- **`sugov_update_next_freq()`**  \n  更新目标频率，处理策略限制变更场景，避免不必要的驱动回调。\n\n- **`get_next_freq()`**  \n  核心频率计算函数，根据 CPU 利用率、最大容量和参考频率，计算目标频率，并通过 `cpufreq_driver_resolve_freq()` 映射到驱动支持的频率。\n\n- **`sugov_get_util()`**  \n  获取当前 CPU 的综合利用率，整合 CFS/RT/DL 任务利用率、boost 值，并调用 `sugov_effective_cpu_perf()` 计算有效性能目标。\n\n- **`sugov_effective_cpu_perf()`**  \n  计算最终的有效性能目标，确保不低于最小性能要求，并限制不超过实际需求。\n\n- **`sugov_iowait_reset()` / `sugov_iowait_boost()`**  \n  实现 I/O 等待唤醒时的动态频率提升机制：短时间内连续 I/O 唤醒会逐步提升 boost 值（从 `IOWAIT_BOOST_MIN` 到最大 OPP），超过一个 tick 无 I/O 唤醒则重置。\n\n- **`get_capacity_ref_freq()`**  \n  获取用于计算 CPU 容量的参考频率，优先使用架构特定的 `arch_scale_freq_ref()`，其次为最大频率或当前频率。\n\n- **`sugov_deferred_update()`**  \n  在不支持 fast-switch 的平台上，通过 `irq_work` 触发异步频率更新。\n\n## 3. 关键实现\n\n### 频率计算算法\n- **频率不变性支持**：若系统支持频率不变调度（`arch_scale_freq_invariant()`），则直接使用调度器提供的频率不变利用率 `util`，按比例计算目标频率：  \n  `next_freq = C * max_freq * util / max`  \n  其中常数 `C = 1.25`，使在 `util/max = 0.8` 时达到 `max_freq`，提供性能余量。\n- **非频率不变性**：使用原始利用率 `util_raw` 乘以 `(curr_freq / max_freq)` 近似频率不变利用率，再计算目标频率。\n\n### I/O 等待 Boost 机制\n- 当任务因 I/O 完成而唤醒时，标记 `SCHED_CPUFREQ_IOWAIT`。\n- 若在 **一个 tick 内** 多次发生 I/O 唤醒，则 `iowait_boost` 值倍增（上限为最大 OPP 对应的利用率）。\n- 若超过一个 tick 无 I/O 唤醒，则重置 boost 值为 `IOWAIT_BOOST_MIN`（`SCHED_CAPACITY_SCALE / 8`），避免对偶发 I/O 过度响应，提升能效。\n\n### 快速切换（Fast-Switch）与异步更新\n- **Fast-Switch 平台**：支持在调度上下文中直接调用 `cpufreq_driver_fast_switch()` 更新频率，延迟最低。\n- **非 Fast-Switch 平台**：通过 `irq_work` 触发内核线程（`kthread_worker`）异步执行频率更新，避免在中断上下文或持有 rq 锁时调用可能阻塞的驱动接口。\n\n### 策略限制变更处理\n- 当用户空间修改 policy 的 min/max 频率时，`sugov_limits()` 设置 `limits_changed` 标志。\n- 下次更新时，强制重新计算频率，并通过内存屏障（`smp_mb()`）确保读取到最新的策略限制。\n\n## 4. 依赖关系\n\n- **调度器子系统**：\n  - 依赖 `update_util_data` 回调机制（通过 `cpufreq_add_update_util_hook()` 注册）。\n  - 调用 `cpu_util_cfs_boost()`、`effective_cpu_util()` 等函数获取综合利用率。\n  - 使用 `scx_cpuperf_target()`（若启用了 SCHED_CLASS_EXT）。\n- **CPUFreq 核心**：\n  - 依赖 `cpufreq_policy`、`cpufreq_driver_resolve_freq()`、`cpufreq_driver_fast_switch()` 等接口。\n  - 使用 `cpufreq_this_cpu_can_update()` 判断硬件更新能力。\n- **架构相关支持**：\n  - 依赖 `arch_scale_freq_ref()` 和 `arch_scale_freq_invariant()` 提供频率不变性信息。\n- **内核基础设施**：\n  - 使用 `irq_work`、`kthread_worker` 实现异步更新。\n  - 依赖 `TICK_NSEC` 定义 tick 时间。\n\n## 5. 使用场景\n\n- **默认高性能能效平衡场景**：现代 Linux 发行版通常将 `schedutil` 作为默认 CPUFreq 调速器，适用于大多数桌面、服务器和移动设备。\n- **实时性要求较高的系统**：由于其低延迟特性（尤其在 fast-switch 平台上），适合对响应时间敏感的应用。\n- **能效敏感设备**：通过 I/O boost 机制和精确的利用率跟踪，在保证交互性能的同时降低空闲功耗。\n- **异构多核系统（如 big.LITTLE）**：结合调度器的 CPU capacity 信息，为不同性能核提供差异化频率调整。",
      "similarity": 0.6314491033554077,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 827,
          "end_line": 916,
          "content": [
            "static int sugov_start(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy = policy->governor_data;",
            "\tvoid (*uu)(struct update_util_data *data, u64 time, unsigned int flags);",
            "\tunsigned int cpu;",
            "",
            "\tsg_policy->freq_update_delay_ns\t= sg_policy->tunables->rate_limit_us * NSEC_PER_USEC;",
            "\tsg_policy->last_freq_update_time\t= 0;",
            "\tsg_policy->next_freq\t\t\t= 0;",
            "\tsg_policy->work_in_progress\t\t= false;",
            "\tsg_policy->limits_changed\t\t= false;",
            "\tsg_policy->cached_raw_freq\t\t= 0;",
            "",
            "\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);",
            "",
            "\tfor_each_cpu(cpu, policy->cpus) {",
            "\t\tstruct sugov_cpu *sg_cpu = &per_cpu(sugov_cpu, cpu);",
            "",
            "\t\tmemset(sg_cpu, 0, sizeof(*sg_cpu));",
            "\t\tsg_cpu->cpu\t\t\t= cpu;",
            "\t\tsg_cpu->sg_policy\t\t= sg_policy;",
            "\t}",
            "",
            "\tif (policy_is_shared(policy))",
            "\t\tuu = sugov_update_shared;",
            "\telse if (policy->fast_switch_enabled && cpufreq_driver_has_adjust_perf())",
            "\t\tuu = sugov_update_single_perf;",
            "\telse",
            "\t\tuu = sugov_update_single_freq;",
            "",
            "\tfor_each_cpu(cpu, policy->cpus) {",
            "\t\tstruct sugov_cpu *sg_cpu = &per_cpu(sugov_cpu, cpu);",
            "",
            "\t\tcpufreq_add_update_util_hook(cpu, &sg_cpu->update_util, uu);",
            "\t}",
            "\treturn 0;",
            "}",
            "static void sugov_stop(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy = policy->governor_data;",
            "\tunsigned int cpu;",
            "",
            "\tfor_each_cpu(cpu, policy->cpus)",
            "\t\tcpufreq_remove_update_util_hook(cpu);",
            "",
            "\tsynchronize_rcu();",
            "",
            "\tif (!policy->fast_switch_enabled) {",
            "\t\tirq_work_sync(&sg_policy->irq_work);",
            "\t\tkthread_cancel_work_sync(&sg_policy->work);",
            "\t}",
            "}",
            "static void sugov_limits(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy = policy->governor_data;",
            "",
            "\tif (!policy->fast_switch_enabled) {",
            "\t\tmutex_lock(&sg_policy->work_lock);",
            "\t\tcpufreq_policy_apply_limits(policy);",
            "\t\tmutex_unlock(&sg_policy->work_lock);",
            "\t}",
            "",
            "\t/*",
            "\t * The limits_changed update below must take place before the updates",
            "\t * of policy limits in cpufreq_set_policy() or a policy limits update",
            "\t * might be missed, so use a memory barrier to ensure it.",
            "\t *",
            "\t * This pairs with the memory barrier in sugov_should_update_freq().",
            "\t */",
            "\tsmp_wmb();",
            "",
            "\tWRITE_ONCE(sg_policy->limits_changed, true);",
            "}",
            "static void rebuild_sd_workfn(struct work_struct *work)",
            "{",
            "\trebuild_sched_domains_energy();",
            "}",
            "void sched_cpufreq_governor_change(struct cpufreq_policy *policy,",
            "\t\t\t\t  struct cpufreq_governor *old_gov)",
            "{",
            "\tif (old_gov == &schedutil_gov || policy->governor == &schedutil_gov) {",
            "\t\t/*",
            "\t\t * When called from the cpufreq_register_driver() path, the",
            "\t\t * cpu_hotplug_lock is already held, so use a work item to",
            "\t\t * avoid nested locking in rebuild_sched_domains().",
            "\t\t */",
            "\t\tschedule_work(&rebuild_sd_work);",
            "\t}",
            "",
            "}"
          ],
          "function_name": "sugov_start, sugov_stop, sugov_limits, rebuild_sd_workfn, sched_cpufreq_governor_change",
          "description": "sugov_start 注册CPU利用率更新钩子函数并初始化频率更新参数；sugov_stop 移除所有CPU的更新钩子并同步RCU状态；sugov_limits 应用频率限制并标记策略变更；rebuild_sd_workfn 触发调度域能量重新构建；sched_cpufreq_governor_change 在策略切换时安排调度域重建工作",
          "similarity": 0.636554479598999
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 1,
          "end_line": 61,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * CPUFreq governor based on scheduler-provided CPU utilization data.",
            " *",
            " * Copyright (C) 2016, Intel Corporation",
            " * Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>",
            " */",
            "",
            "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)",
            "",
            "struct sugov_tunables {",
            "\tstruct gov_attr_set\tattr_set;",
            "\tunsigned int\t\trate_limit_us;",
            "};",
            "",
            "struct sugov_policy {",
            "\tstruct cpufreq_policy\t*policy;",
            "",
            "\tstruct sugov_tunables\t*tunables;",
            "\tstruct list_head\ttunables_hook;",
            "",
            "\traw_spinlock_t\t\tupdate_lock;",
            "\tu64\t\t\tlast_freq_update_time;",
            "\ts64\t\t\tfreq_update_delay_ns;",
            "\tunsigned int\t\tnext_freq;",
            "\tunsigned int\t\tcached_raw_freq;",
            "",
            "\t/* The next fields are only needed if fast switch cannot be used: */",
            "\tstruct\t\t\tirq_work irq_work;",
            "\tstruct\t\t\tkthread_work work;",
            "\tstruct\t\t\tmutex work_lock;",
            "\tstruct\t\t\tkthread_worker worker;",
            "\tstruct task_struct\t*thread;",
            "\tbool\t\t\twork_in_progress;",
            "",
            "\tbool\t\t\tlimits_changed;",
            "\tbool\t\t\tneed_freq_update;",
            "};",
            "",
            "struct sugov_cpu {",
            "\tstruct update_util_data\tupdate_util;",
            "\tstruct sugov_policy\t*sg_policy;",
            "\tunsigned int\t\tcpu;",
            "",
            "\tbool\t\t\tiowait_boost_pending;",
            "\tunsigned int\t\tiowait_boost;",
            "\tu64\t\t\tlast_update;",
            "",
            "\tunsigned long\t\tutil;",
            "\tunsigned long\t\tbw_min;",
            "",
            "\t/* The field below is for single-CPU policies only: */",
            "#ifdef CONFIG_NO_HZ_COMMON",
            "\tunsigned long\t\tsaved_idle_calls;",
            "#endif",
            "};",
            "",
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);",
            "",
            "/************************ Governor internals ***********************/",
            ""
          ],
          "function_name": null,
          "description": "定义了CPU频率调节器所需的结构体和宏，包括sugov_tunables保存策略参数，sugov_policy管理策略状态，sugov_cpu保存每个CPU的运行数据，以及相关锁和标志位，用于协调多核间的频率调整操作。",
          "similarity": 0.6003249883651733
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 381,
          "end_line": 496,
          "content": [
            "static inline bool sugov_hold_freq(struct sugov_cpu *sg_cpu) { return false; }",
            "static inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu)",
            "{",
            "\tif (cpu_bw_dl(cpu_rq(sg_cpu->cpu)) > sg_cpu->bw_min)",
            "\t\tWRITE_ONCE(sg_cpu->sg_policy->limits_changed, true);",
            "}",
            "static inline bool sugov_update_single_common(struct sugov_cpu *sg_cpu,",
            "\t\t\t\t\t      u64 time, unsigned long max_cap,",
            "\t\t\t\t\t      unsigned int flags)",
            "{",
            "\tunsigned long boost;",
            "",
            "\tsugov_iowait_boost(sg_cpu, time, flags);",
            "\tsg_cpu->last_update = time;",
            "",
            "\tignore_dl_rate_limit(sg_cpu);",
            "",
            "\tif (!sugov_should_update_freq(sg_cpu->sg_policy, time))",
            "\t\treturn false;",
            "",
            "\tboost = sugov_iowait_apply(sg_cpu, time, max_cap);",
            "\tsugov_get_util(sg_cpu, boost);",
            "",
            "\treturn true;",
            "}",
            "static void sugov_update_single_freq(struct update_util_data *hook, u64 time,",
            "\t\t\t\t     unsigned int flags)",
            "{",
            "\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);",
            "\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;",
            "\tunsigned int cached_freq = sg_policy->cached_raw_freq;",
            "\tunsigned long max_cap;",
            "\tunsigned int next_f;",
            "",
            "\tmax_cap = arch_scale_cpu_capacity(sg_cpu->cpu);",
            "",
            "\tif (!sugov_update_single_common(sg_cpu, time, max_cap, flags))",
            "\t\treturn;",
            "",
            "\tnext_f = get_next_freq(sg_policy, sg_cpu->util, max_cap);",
            "",
            "\tif (sugov_hold_freq(sg_cpu) && next_f < sg_policy->next_freq &&",
            "\t    !sg_policy->need_freq_update) {",
            "\t\tnext_f = sg_policy->next_freq;",
            "",
            "\t\t/* Restore cached freq as next_freq has changed */",
            "\t\tsg_policy->cached_raw_freq = cached_freq;",
            "\t}",
            "",
            "\tif (!sugov_update_next_freq(sg_policy, time, next_f))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * This code runs under rq->lock for the target CPU, so it won't run",
            "\t * concurrently on two different CPUs for the same target and it is not",
            "\t * necessary to acquire the lock in the fast switch case.",
            "\t */",
            "\tif (sg_policy->policy->fast_switch_enabled) {",
            "\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);",
            "\t} else {",
            "\t\traw_spin_lock(&sg_policy->update_lock);",
            "\t\tsugov_deferred_update(sg_policy);",
            "\t\traw_spin_unlock(&sg_policy->update_lock);",
            "\t}",
            "}",
            "static void sugov_update_single_perf(struct update_util_data *hook, u64 time,",
            "\t\t\t\t     unsigned int flags)",
            "{",
            "\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);",
            "\tunsigned long prev_util = sg_cpu->util;",
            "\tunsigned long max_cap;",
            "",
            "\t/*",
            "\t * Fall back to the \"frequency\" path if frequency invariance is not",
            "\t * supported, because the direct mapping between the utilization and",
            "\t * the performance levels depends on the frequency invariance.",
            "\t */",
            "\tif (!arch_scale_freq_invariant()) {",
            "\t\tsugov_update_single_freq(hook, time, flags);",
            "\t\treturn;",
            "\t}",
            "",
            "\tmax_cap = arch_scale_cpu_capacity(sg_cpu->cpu);",
            "",
            "\tif (!sugov_update_single_common(sg_cpu, time, max_cap, flags))",
            "\t\treturn;",
            "",
            "\tif (sugov_hold_freq(sg_cpu) && sg_cpu->util < prev_util)",
            "\t\tsg_cpu->util = prev_util;",
            "",
            "\tcpufreq_driver_adjust_perf(sg_cpu->cpu, sg_cpu->bw_min,",
            "\t\t\t\t   sg_cpu->util, max_cap);",
            "",
            "\tsg_cpu->sg_policy->last_freq_update_time = time;",
            "}",
            "static unsigned int sugov_next_freq_shared(struct sugov_cpu *sg_cpu, u64 time)",
            "{",
            "\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;",
            "\tstruct cpufreq_policy *policy = sg_policy->policy;",
            "\tunsigned long util = 0, max_cap;",
            "\tunsigned int j;",
            "",
            "\tmax_cap = arch_scale_cpu_capacity(sg_cpu->cpu);",
            "",
            "\tfor_each_cpu(j, policy->cpus) {",
            "\t\tstruct sugov_cpu *j_sg_cpu = &per_cpu(sugov_cpu, j);",
            "\t\tunsigned long boost;",
            "",
            "\t\tboost = sugov_iowait_apply(j_sg_cpu, time, max_cap);",
            "\t\tsugov_get_util(j_sg_cpu, boost);",
            "",
            "\t\tutil = max(j_sg_cpu->util, util);",
            "\t}",
            "",
            "\treturn get_next_freq(sg_policy, util, max_cap);",
            "}"
          ],
          "function_name": "sugov_hold_freq, ignore_dl_rate_limit, sugov_update_single_common, sugov_update_single_freq, sugov_update_single_perf, sugov_next_freq_shared",
          "description": "实现单核/多核频率调整逻辑，sugov_update_single_freq处理单核频率更新，sugov_update_single_perf处理性能调优路径，sugov_next_freq_shared计算多核共享场景下的全局目标频率。",
          "similarity": 0.5963209867477417
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 701,
          "end_line": 809,
          "content": [
            "static void sugov_kthread_stop(struct sugov_policy *sg_policy)",
            "{",
            "\t/* kthread only required for slow path */",
            "\tif (sg_policy->policy->fast_switch_enabled)",
            "\t\treturn;",
            "",
            "\tkthread_flush_worker(&sg_policy->worker);",
            "\tkthread_stop(sg_policy->thread);",
            "\tmutex_destroy(&sg_policy->work_lock);",
            "}",
            "static void sugov_clear_global_tunables(void)",
            "{",
            "\tif (!have_governor_per_policy())",
            "\t\tglobal_tunables = NULL;",
            "}",
            "static int sugov_init(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy;",
            "\tstruct sugov_tunables *tunables;",
            "\tint ret = 0;",
            "",
            "\t/* State should be equivalent to EXIT */",
            "\tif (policy->governor_data)",
            "\t\treturn -EBUSY;",
            "",
            "\tcpufreq_enable_fast_switch(policy);",
            "",
            "\tsg_policy = sugov_policy_alloc(policy);",
            "\tif (!sg_policy) {",
            "\t\tret = -ENOMEM;",
            "\t\tgoto disable_fast_switch;",
            "\t}",
            "",
            "\tret = sugov_kthread_create(sg_policy);",
            "\tif (ret)",
            "\t\tgoto free_sg_policy;",
            "",
            "\tmutex_lock(&global_tunables_lock);",
            "",
            "\tif (global_tunables) {",
            "\t\tif (WARN_ON(have_governor_per_policy())) {",
            "\t\t\tret = -EINVAL;",
            "\t\t\tgoto stop_kthread;",
            "\t\t}",
            "\t\tpolicy->governor_data = sg_policy;",
            "\t\tsg_policy->tunables = global_tunables;",
            "",
            "\t\tgov_attr_set_get(&global_tunables->attr_set, &sg_policy->tunables_hook);",
            "\t\tgoto out;",
            "\t}",
            "",
            "\ttunables = sugov_tunables_alloc(sg_policy);",
            "\tif (!tunables) {",
            "\t\tret = -ENOMEM;",
            "\t\tgoto stop_kthread;",
            "\t}",
            "",
            "\ttunables->rate_limit_us = cpufreq_policy_transition_delay_us(policy);",
            "",
            "\tpolicy->governor_data = sg_policy;",
            "\tsg_policy->tunables = tunables;",
            "",
            "\tret = kobject_init_and_add(&tunables->attr_set.kobj, &sugov_tunables_ktype,",
            "\t\t\t\t   get_governor_parent_kobj(policy), \"%s\",",
            "\t\t\t\t   schedutil_gov.name);",
            "\tif (ret)",
            "\t\tgoto fail;",
            "",
            "out:",
            "\tmutex_unlock(&global_tunables_lock);",
            "\treturn 0;",
            "",
            "fail:",
            "\tkobject_put(&tunables->attr_set.kobj);",
            "\tpolicy->governor_data = NULL;",
            "\tsugov_clear_global_tunables();",
            "",
            "stop_kthread:",
            "\tsugov_kthread_stop(sg_policy);",
            "\tmutex_unlock(&global_tunables_lock);",
            "",
            "free_sg_policy:",
            "\tsugov_policy_free(sg_policy);",
            "",
            "disable_fast_switch:",
            "\tcpufreq_disable_fast_switch(policy);",
            "",
            "\tpr_err(\"initialization failed (error %d)\\n\", ret);",
            "\treturn ret;",
            "}",
            "static void sugov_exit(struct cpufreq_policy *policy)",
            "{",
            "\tstruct sugov_policy *sg_policy = policy->governor_data;",
            "\tstruct sugov_tunables *tunables = sg_policy->tunables;",
            "\tunsigned int count;",
            "",
            "\tmutex_lock(&global_tunables_lock);",
            "",
            "\tcount = gov_attr_set_put(&tunables->attr_set, &sg_policy->tunables_hook);",
            "\tpolicy->governor_data = NULL;",
            "\tif (!count)",
            "\t\tsugov_clear_global_tunables();",
            "",
            "\tmutex_unlock(&global_tunables_lock);",
            "",
            "\tsugov_kthread_stop(sg_policy);",
            "\tsugov_policy_free(sg_policy);",
            "\tcpufreq_disable_fast_switch(policy);",
            "}"
          ],
          "function_name": "sugov_kthread_stop, sugov_clear_global_tunables, sugov_init, sugov_exit",
          "description": "sugov_kthread_stop 停止慢速路径相关内核线程并释放锁资源；sugov_clear_global_tunables 清除全局调谐参数指针；sugov_init 初始化CPU频率策略模块，分配策略结构体并创建内核线程；sugov_exit 释放策略资源，停止线程并禁用快速切换功能",
          "similarity": 0.5949333906173706
        },
        {
          "chunk_id": 4,
          "file_path": "kernel/sched/cpufreq_schedutil.c",
          "start_line": 508,
          "end_line": 651,
          "content": [
            "static void",
            "sugov_update_shared(struct update_util_data *hook, u64 time, unsigned int flags)",
            "{",
            "\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);",
            "\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;",
            "\tunsigned int next_f;",
            "",
            "\traw_spin_lock(&sg_policy->update_lock);",
            "",
            "\tsugov_iowait_boost(sg_cpu, time, flags);",
            "\tsg_cpu->last_update = time;",
            "",
            "\tignore_dl_rate_limit(sg_cpu);",
            "",
            "\tif (sugov_should_update_freq(sg_policy, time)) {",
            "\t\tnext_f = sugov_next_freq_shared(sg_cpu, time);",
            "",
            "\t\tif (!sugov_update_next_freq(sg_policy, time, next_f))",
            "\t\t\tgoto unlock;",
            "",
            "\t\tif (sg_policy->policy->fast_switch_enabled)",
            "\t\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);",
            "\t\telse",
            "\t\t\tsugov_deferred_update(sg_policy);",
            "\t}",
            "unlock:",
            "\traw_spin_unlock(&sg_policy->update_lock);",
            "}",
            "static void sugov_work(struct kthread_work *work)",
            "{",
            "\tstruct sugov_policy *sg_policy = container_of(work, struct sugov_policy, work);",
            "\tunsigned int freq;",
            "\tunsigned long flags;",
            "",
            "\t/*",
            "\t * Hold sg_policy->update_lock shortly to handle the case where:",
            "\t * in case sg_policy->next_freq is read here, and then updated by",
            "\t * sugov_deferred_update() just before work_in_progress is set to false",
            "\t * here, we may miss queueing the new update.",
            "\t *",
            "\t * Note: If a work was queued after the update_lock is released,",
            "\t * sugov_work() will just be called again by kthread_work code; and the",
            "\t * request will be proceed before the sugov thread sleeps.",
            "\t */",
            "\traw_spin_lock_irqsave(&sg_policy->update_lock, flags);",
            "\tfreq = sg_policy->next_freq;",
            "\tsg_policy->work_in_progress = false;",
            "\traw_spin_unlock_irqrestore(&sg_policy->update_lock, flags);",
            "",
            "\tmutex_lock(&sg_policy->work_lock);",
            "\t__cpufreq_driver_target(sg_policy->policy, freq, CPUFREQ_RELATION_L);",
            "\tmutex_unlock(&sg_policy->work_lock);",
            "}",
            "static void sugov_irq_work(struct irq_work *irq_work)",
            "{",
            "\tstruct sugov_policy *sg_policy;",
            "",
            "\tsg_policy = container_of(irq_work, struct sugov_policy, irq_work);",
            "",
            "\tkthread_queue_work(&sg_policy->worker, &sg_policy->work);",
            "}",
            "static ssize_t rate_limit_us_show(struct gov_attr_set *attr_set, char *buf)",
            "{",
            "\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);",
            "",
            "\treturn sprintf(buf, \"%u\\n\", tunables->rate_limit_us);",
            "}",
            "static ssize_t",
            "rate_limit_us_store(struct gov_attr_set *attr_set, const char *buf, size_t count)",
            "{",
            "\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);",
            "\tstruct sugov_policy *sg_policy;",
            "\tunsigned int rate_limit_us;",
            "",
            "\tif (kstrtouint(buf, 10, &rate_limit_us))",
            "\t\treturn -EINVAL;",
            "",
            "\ttunables->rate_limit_us = rate_limit_us;",
            "",
            "\tlist_for_each_entry(sg_policy, &attr_set->policy_list, tunables_hook)",
            "\t\tsg_policy->freq_update_delay_ns = rate_limit_us * NSEC_PER_USEC;",
            "",
            "\treturn count;",
            "}",
            "static void sugov_tunables_free(struct kobject *kobj)",
            "{",
            "\tstruct gov_attr_set *attr_set = to_gov_attr_set(kobj);",
            "",
            "\tkfree(to_sugov_tunables(attr_set));",
            "}",
            "static void sugov_policy_free(struct sugov_policy *sg_policy)",
            "{",
            "\tkfree(sg_policy);",
            "}",
            "static int sugov_kthread_create(struct sugov_policy *sg_policy)",
            "{",
            "\tstruct task_struct *thread;",
            "\tstruct sched_attr attr = {",
            "\t\t.size\t\t= sizeof(struct sched_attr),",
            "\t\t.sched_policy\t= SCHED_DEADLINE,",
            "\t\t.sched_flags\t= SCHED_FLAG_SUGOV,",
            "\t\t.sched_nice\t= 0,",
            "\t\t.sched_priority\t= 0,",
            "\t\t/*",
            "\t\t * Fake (unused) bandwidth; workaround to \"fix\"",
            "\t\t * priority inheritance.",
            "\t\t */",
            "\t\t.sched_runtime\t=  1000000,",
            "\t\t.sched_deadline = 10000000,",
            "\t\t.sched_period\t= 10000000,",
            "\t};",
            "\tstruct cpufreq_policy *policy = sg_policy->policy;",
            "\tint ret;",
            "",
            "\t/* kthread only required for slow path */",
            "\tif (policy->fast_switch_enabled)",
            "\t\treturn 0;",
            "",
            "\tkthread_init_work(&sg_policy->work, sugov_work);",
            "\tkthread_init_worker(&sg_policy->worker);",
            "\tthread = kthread_create(kthread_worker_fn, &sg_policy->worker,",
            "\t\t\t\t\"sugov:%d\",",
            "\t\t\t\tcpumask_first(policy->related_cpus));",
            "\tif (IS_ERR(thread)) {",
            "\t\tpr_err(\"failed to create sugov thread: %ld\\n\", PTR_ERR(thread));",
            "\t\treturn PTR_ERR(thread);",
            "\t}",
            "",
            "\tret = sched_setattr_nocheck(thread, &attr);",
            "\tif (ret) {",
            "\t\tkthread_stop(thread);",
            "\t\tpr_warn(\"%s: failed to set SCHED_DEADLINE\\n\", __func__);",
            "\t\treturn ret;",
            "\t}",
            "",
            "\tsg_policy->thread = thread;",
            "\tkthread_bind_mask(thread, policy->related_cpus);",
            "\tinit_irq_work(&sg_policy->irq_work, sugov_irq_work);",
            "\tmutex_init(&sg_policy->work_lock);",
            "",
            "\twake_up_process(thread);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "sugov_update_shared, sugov_work, sugov_irq_work, rate_limit_us_show, rate_limit_us_store, sugov_tunables_free, sugov_policy_free, sugov_kthread_create",
          "description": "管理频率调节的工作线程和参数配置，sugov_kthread_create创建慢速切换场景的后台线程，rate_limit_us_*/提供速率限制配置接口，sugov_work/sugov_irq_work处理异步频率更新任务。",
          "similarity": 0.5729176998138428
        }
      ]
    },
    {
      "source_file": "kernel/sched/cpupri.c",
      "md_summary": "> 自动生成时间: 2025-10-25 16:04:45\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `sched\\cpupri.c`\n\n---\n\n# `sched/cpupri.c` 技术文档\n\n## 1. 文件概述\n\n`sched/cpupri.c` 实现了 **CPU 优先级管理（CPU Priority Management）** 机制，用于实时任务（RT tasks）的全局负载均衡和迁移决策。该机制通过维护一个二维位图结构，快速追踪每个 CPU 当前运行任务的最高优先级，从而在 O(1) 时间复杂度内为新唤醒或迁移的实时任务找到合适的 CPU 目标。该机制特别优化了无 CPU 亲和性限制的任务调度路径，同时支持带亲和性约束的场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n| 函数 | 功能描述 |\n|------|--------|\n| `convert_prio(int prio)` | 将任务的调度优先级（`p->prio`）转换为内部 `cpupri` 优先级值（范围：-1 到 100） |\n| `__cpupri_find(struct cpupri *cp, struct task_struct *p, struct cpumask *lowest_mask, int idx)` | 在指定优先级层级 `idx` 中查找满足任务 `p` 的 CPU（考虑亲和性） |\n| `cpupri_find(struct cpupri *cp, struct task_struct *p, struct cpumask *lowest_mask)` | 查找系统中优先级 **低于或等于** 任务 `p` 的 CPU（即任务可运行的 CPU） |\n| `cpupri_find_fitness(...)` | 增强版查找函数，支持通过 `fitness_fn` 自定义 CPU 适配条件（如容量感知） |\n| `cpupri_set(struct cpupri *cp, int cpu, int newpri)` | 更新指定 CPU 的当前最高优先级状态 |\n| `cpupri_init(struct cpupri *cp)` | 初始化 `cpupri` 数据结构（声明但未在片段中实现） |\n\n### 关键数据结构（隐含）\n\n- `struct cpupri`：全局 CPU 优先级管理上下文\n  - `cpu_to_pri[]`：每个 CPU 当前的 `cpupri` 优先级\n  - `pri_to_cpu[]`：每个优先级对应的 `struct cpupri_vec`\n- `struct cpupri_vec`：\n  - `mask`：该优先级下所有 CPU 的位图\n  - `count`：该优先级下活跃 CPU 的数量（原子计数）\n\n### 优先级映射关系\n\n| 任务 `p->prio` | `cpupri` 值 | 含义 |\n|---------------|------------|------|\n| -1 | -1 (`CPUPRI_INVALID`) | 无效状态（CPU 不可调度） |\n| 0–98 | 99–1 | 实时优先级（数值越大，任务优先级越高，`cpupri` 值越小） |\n| 99 (`MAX_RT_PRIO-1`) | 0 (`CPUPRI_NORMAL`) | 普通（非实时）任务 |\n| 100 (`MAX_RT_PRIO`) | 100 (`CPUPRI_HIGHER`) | 高于所有 RT 任务的特殊优先级 |\n\n> **注意**：`cpupri` 值越小，表示 CPU 当前负载的优先级 **越高**。\n\n## 3. 关键实现\n\n### 优先级转换逻辑\n- `convert_prio()` 实现了任务调度优先级到 `cpupri` 内部表示的映射，确保实时任务（`p->prio` ∈ [0, 98]）被正确映射到 `cpupri` ∈ [1, 99]，且高优先级任务对应更小的 `cpupri` 值。\n\n### 快速查找算法\n- 使用 **二维位图**：第一维为优先级（0–100），第二维为 CPU 位图。\n- `cpupri_find_fitness()` 从最低优先级（`idx = 0`）开始遍历，找到第一个存在可用 CPU 的优先级层级。\n- 对于每个层级，通过 `cpumask_any_and()` 快速判断任务亲和性掩码与该优先级 CPU 掩码是否有交集。\n- 若提供 `fitness_fn`（如容量检查），会过滤掉不满足条件的 CPU；若过滤后无 CPU 可用，则继续搜索更高优先级层级。\n\n### 容错与回退策略\n- 如果启用了 `fitness_fn` 但未找到满足条件的 CPU，函数会 **忽略 fitness 条件重新搜索**，确保高优先级任务总能找到运行 CPU（优先保证实时性，而非最优资源匹配）。\n\n### 并发安全更新\n- `cpupri_set()` 使用 **内存屏障（`smp_mb__before/after_atomic()`）** 确保 CPU 位图和计数器的更新顺序：\n  1. **添加 CPU**：先设置位图 → 内存屏障 → 增加计数器\n  2. **移除 CPU**：先减少计数器 → 内存屏障 → 清除位图\n- 此顺序防止 `cpupri_find` 在并发读取时看到不一致状态（如计数器为 0 但位图仍置位）。\n\n### 亲和性处理\n- 所有查找操作均与任务的 `p->cpus_mask`（CPU 亲和性）和 `cpu_active_mask`（活跃 CPU）进行交集运算，确保只返回合法 CPU。\n\n## 4. 依赖关系\n\n- **调度器核心**：依赖 `task_struct`、`p->prio`、`p->cpus_mask` 等调度器基本结构。\n- **实时调度类（`rt.c`）**：`cpupri` 主要服务于 `SCHED_FIFO`/`SCHED_RR` 任务的负载均衡。\n- **CPU 掩码操作**：使用 `cpumask_*` 系列函数（如 `cpumask_and`, `cpumask_clear_cpu`）。\n- **内存屏障原语**：依赖 `smp_rmb()`、`smp_mb__before_atomic()` 等 SMP 同步机制。\n- **原子操作**：使用 `atomic_read/inc/dec` 管理优先级层级的 CPU 计数。\n\n## 5. 使用场景\n\n- **实时任务唤醒/迁移**：当高优先级 RT 任务被唤醒或需要迁移时，调用 `cpupri_find()` 快速定位可运行的最低优先级 CPU（减少抢占开销）。\n- **全局负载均衡**：RT 调度器的 `push_rt_task()` 和 `pull_rt_task()` 机制利用 `cpupri` 决定任务推送/拉取的目标 CPU。\n- **容量感知调度（Capacity Awareness）**：通过 `cpupri_find_fitness()` 的 `fitness_fn` 参数，集成 CPU 性能/能效信息（如 ARM big.LITTLE 架构），在满足优先级前提下选择合适 CPU。\n- **CPU 热插拔**：CPU 上下线时通过 `cpupri_set()` 更新其优先级状态（设为 `CPUPRI_INVALID` 或恢复）。",
      "similarity": 0.6110197901725769,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/sched/cpupri.c",
          "start_line": 42,
          "end_line": 178,
          "content": [
            "static int convert_prio(int prio)",
            "{",
            "\tint cpupri;",
            "",
            "\tswitch (prio) {",
            "\tcase CPUPRI_INVALID:",
            "\t\tcpupri = CPUPRI_INVALID;\t/* -1 */",
            "\t\tbreak;",
            "",
            "\tcase 0 ... 98:",
            "\t\tcpupri = MAX_RT_PRIO-1 - prio;\t/* 1 ... 99 */",
            "\t\tbreak;",
            "",
            "\tcase MAX_RT_PRIO-1:",
            "\t\tcpupri = CPUPRI_NORMAL;\t\t/*  0 */",
            "\t\tbreak;",
            "",
            "\tcase MAX_RT_PRIO:",
            "\t\tcpupri = CPUPRI_HIGHER;\t\t/* 100 */",
            "\t\tbreak;",
            "\t}",
            "",
            "\treturn cpupri;",
            "}",
            "static inline int __cpupri_find(struct cpupri *cp, struct task_struct *p,",
            "\t\t\t\tstruct cpumask *lowest_mask, int idx)",
            "{",
            "\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[idx];",
            "\tint skip = 0;",
            "",
            "\tif (!atomic_read(&(vec)->count))",
            "\t\tskip = 1;",
            "\t/*",
            "\t * When looking at the vector, we need to read the counter,",
            "\t * do a memory barrier, then read the mask.",
            "\t *",
            "\t * Note: This is still all racy, but we can deal with it.",
            "\t *  Ideally, we only want to look at masks that are set.",
            "\t *",
            "\t *  If a mask is not set, then the only thing wrong is that we",
            "\t *  did a little more work than necessary.",
            "\t *",
            "\t *  If we read a zero count but the mask is set, because of the",
            "\t *  memory barriers, that can only happen when the highest prio",
            "\t *  task for a run queue has left the run queue, in which case,",
            "\t *  it will be followed by a pull. If the task we are processing",
            "\t *  fails to find a proper place to go, that pull request will",
            "\t *  pull this task if the run queue is running at a lower",
            "\t *  priority.",
            "\t */",
            "\tsmp_rmb();",
            "",
            "\t/* Need to do the rmb for every iteration */",
            "\tif (skip)",
            "\t\treturn 0;",
            "",
            "\tif (cpumask_any_and(&p->cpus_mask, vec->mask) >= nr_cpu_ids)",
            "\t\treturn 0;",
            "",
            "\tif (lowest_mask) {",
            "\t\tcpumask_and(lowest_mask, &p->cpus_mask, vec->mask);",
            "\t\tcpumask_and(lowest_mask, lowest_mask, cpu_active_mask);",
            "",
            "\t\t/*",
            "\t\t * We have to ensure that we have at least one bit",
            "\t\t * still set in the array, since the map could have",
            "\t\t * been concurrently emptied between the first and",
            "\t\t * second reads of vec->mask.  If we hit this",
            "\t\t * condition, simply act as though we never hit this",
            "\t\t * priority level and continue on.",
            "\t\t */",
            "\t\tif (cpumask_empty(lowest_mask))",
            "\t\t\treturn 0;",
            "\t}",
            "",
            "\treturn 1;",
            "}",
            "int cpupri_find(struct cpupri *cp, struct task_struct *p,",
            "\t\tstruct cpumask *lowest_mask)",
            "{",
            "\treturn cpupri_find_fitness(cp, p, lowest_mask, NULL);",
            "}",
            "int cpupri_find_fitness(struct cpupri *cp, struct task_struct *p,",
            "\t\tstruct cpumask *lowest_mask,",
            "\t\tbool (*fitness_fn)(struct task_struct *p, int cpu))",
            "{",
            "\tint task_pri = convert_prio(p->prio);",
            "\tint idx, cpu;",
            "",
            "\tWARN_ON_ONCE(task_pri >= CPUPRI_NR_PRIORITIES);",
            "",
            "\tfor (idx = 0; idx < task_pri; idx++) {",
            "",
            "\t\tif (!__cpupri_find(cp, p, lowest_mask, idx))",
            "\t\t\tcontinue;",
            "",
            "\t\tif (!lowest_mask || !fitness_fn)",
            "\t\t\treturn 1;",
            "",
            "\t\t/* Ensure the capacity of the CPUs fit the task */",
            "\t\tfor_each_cpu(cpu, lowest_mask) {",
            "\t\t\tif (!fitness_fn(p, cpu))",
            "\t\t\t\tcpumask_clear_cpu(cpu, lowest_mask);",
            "\t\t}",
            "",
            "\t\t/*",
            "\t\t * If no CPU at the current priority can fit the task",
            "\t\t * continue looking",
            "\t\t */",
            "\t\tif (cpumask_empty(lowest_mask))",
            "\t\t\tcontinue;",
            "",
            "\t\treturn 1;",
            "\t}",
            "",
            "\t/*",
            "\t * If we failed to find a fitting lowest_mask, kick off a new search",
            "\t * but without taking into account any fitness criteria this time.",
            "\t *",
            "\t * This rule favours honouring priority over fitting the task in the",
            "\t * correct CPU (Capacity Awareness being the only user now).",
            "\t * The idea is that if a higher priority task can run, then it should",
            "\t * run even if this ends up being on unfitting CPU.",
            "\t *",
            "\t * The cost of this trade-off is not entirely clear and will probably",
            "\t * be good for some workloads and bad for others.",
            "\t *",
            "\t * The main idea here is that if some CPUs were over-committed, we try",
            "\t * to spread which is what the scheduler traditionally did. Sys admins",
            "\t * must do proper RT planning to avoid overloading the system if they",
            "\t * really care.",
            "\t */",
            "\tif (fitness_fn)",
            "\t\treturn cpupri_find(cp, p, lowest_mask);",
            "",
            "\treturn 0;",
            "}"
          ],
          "function_name": "convert_prio, __cpupri_find, cpupri_find, cpupri_find_fitness",
          "description": "convert_prio将任务优先级映射为CPU优先级数值；__cpupri_find检查特定优先级下是否存在可用CPU；cpupri_find_fitness遍历优先级层级寻找适配CPU，结合适应性判断与优先级策略决定最终选择",
          "similarity": 0.5829004049301147
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/sched/cpupri.c",
          "start_line": 210,
          "end_line": 304,
          "content": [
            "void cpupri_set(struct cpupri *cp, int cpu, int newpri)",
            "{",
            "\tint *currpri = &cp->cpu_to_pri[cpu];",
            "\tint oldpri = *currpri;",
            "\tint do_mb = 0;",
            "",
            "\tnewpri = convert_prio(newpri);",
            "",
            "\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);",
            "",
            "\tif (newpri == oldpri)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * If the CPU was currently mapped to a different value, we",
            "\t * need to map it to the new value then remove the old value.",
            "\t * Note, we must add the new value first, otherwise we risk the",
            "\t * cpu being missed by the priority loop in cpupri_find.",
            "\t */",
            "\tif (likely(newpri != CPUPRI_INVALID)) {",
            "\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];",
            "",
            "\t\tcpumask_set_cpu(cpu, vec->mask);",
            "\t\t/*",
            "\t\t * When adding a new vector, we update the mask first,",
            "\t\t * do a write memory barrier, and then update the count, to",
            "\t\t * make sure the vector is visible when count is set.",
            "\t\t */",
            "\t\tsmp_mb__before_atomic();",
            "\t\tatomic_inc(&(vec)->count);",
            "\t\tdo_mb = 1;",
            "\t}",
            "\tif (likely(oldpri != CPUPRI_INVALID)) {",
            "\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];",
            "",
            "\t\t/*",
            "\t\t * Because the order of modification of the vec->count",
            "\t\t * is important, we must make sure that the update",
            "\t\t * of the new prio is seen before we decrement the",
            "\t\t * old prio. This makes sure that the loop sees",
            "\t\t * one or the other when we raise the priority of",
            "\t\t * the run queue. We don't care about when we lower the",
            "\t\t * priority, as that will trigger an rt pull anyway.",
            "\t\t *",
            "\t\t * We only need to do a memory barrier if we updated",
            "\t\t * the new priority vec.",
            "\t\t */",
            "\t\tif (do_mb)",
            "\t\t\tsmp_mb__after_atomic();",
            "",
            "\t\t/*",
            "\t\t * When removing from the vector, we decrement the counter first",
            "\t\t * do a memory barrier and then clear the mask.",
            "\t\t */",
            "\t\tatomic_dec(&(vec)->count);",
            "\t\tsmp_mb__after_atomic();",
            "\t\tcpumask_clear_cpu(cpu, vec->mask);",
            "\t}",
            "",
            "\t*currpri = newpri;",
            "}",
            "int cpupri_init(struct cpupri *cp)",
            "{",
            "\tint i;",
            "",
            "\tfor (i = 0; i < CPUPRI_NR_PRIORITIES; i++) {",
            "\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[i];",
            "",
            "\t\tatomic_set(&vec->count, 0);",
            "\t\tif (!zalloc_cpumask_var(&vec->mask, GFP_KERNEL))",
            "\t\t\tgoto cleanup;",
            "\t}",
            "",
            "\tcp->cpu_to_pri = kcalloc(nr_cpu_ids, sizeof(int), GFP_KERNEL);",
            "\tif (!cp->cpu_to_pri)",
            "\t\tgoto cleanup;",
            "",
            "\tfor_each_possible_cpu(i)",
            "\t\tcp->cpu_to_pri[i] = CPUPRI_INVALID;",
            "",
            "\treturn 0;",
            "",
            "cleanup:",
            "\tfor (i--; i >= 0; i--)",
            "\t\tfree_cpumask_var(cp->pri_to_cpu[i].mask);",
            "\treturn -ENOMEM;",
            "}",
            "void cpupri_cleanup(struct cpupri *cp)",
            "{",
            "\tint i;",
            "",
            "\tkfree(cp->cpu_to_pri);",
            "\tfor (i = 0; i < CPUPRI_NR_PRIORITIES; i++)",
            "\t\tfree_cpumask_var(cp->pri_to_cpu[i].mask);",
            "}"
          ],
          "function_name": "cpupri_set, cpupri_init, cpupri_cleanup",
          "description": "cpupri_set更新CPU优先级状态，通过原子操作同步位图与计数器；cpupri_init初始化优先级到CPU的映射表与CPU到优先级的数组；cpupri_cleanup释放所有动态分配的位图资源与优先级数组",
          "similarity": 0.5677308440208435
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/sched/cpupri.c",
          "start_line": 1,
          "end_line": 41,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " *  kernel/sched/cpupri.c",
            " *",
            " *  CPU priority management",
            " *",
            " *  Copyright (C) 2007-2008 Novell",
            " *",
            " *  Author: Gregory Haskins <ghaskins@novell.com>",
            " *",
            " *  This code tracks the priority of each CPU so that global migration",
            " *  decisions are easy to calculate.  Each CPU can be in a state as follows:",
            " *",
            " *                 (INVALID), NORMAL, RT1, ... RT99, HIGHER",
            " *",
            " *  going from the lowest priority to the highest.  CPUs in the INVALID state",
            " *  are not eligible for routing.  The system maintains this state with",
            " *  a 2 dimensional bitmap (the first for priority class, the second for CPUs",
            " *  in that class).  Therefore a typical application without affinity",
            " *  restrictions can find a suitable CPU with O(1) complexity (e.g. two bit",
            " *  searches).  For tasks with affinity restrictions, the algorithm has a",
            " *  worst case complexity of O(min(101, nr_domcpus)), though the scenario that",
            " *  yields the worst case search is fairly contrived.",
            " */",
            "",
            "/*",
            " * p->rt_priority   p->prio   newpri   cpupri",
            " *",
            " *\t\t\t\t  -1       -1 (CPUPRI_INVALID)",
            " *",
            " *\t\t\t\t  99        0 (CPUPRI_NORMAL)",
            " *",
            " *\t\t1        98       98        1",
            " *\t      ...",
            " *\t       49        50       50       49",
            " *\t       50        49       49       50",
            " *\t      ...",
            " *\t       99         0        0       99",
            " *",
            " *\t\t\t\t 100\t  100 (CPUPRI_HIGHER)",
            " */"
          ],
          "function_name": null,
          "description": "定义CPU优先级管理模块，通过二维位图跟踪各CPU优先级状态，支持NORMAL、RT1至RT99及HIGHER五种优先级分类，INVALID状态表示CPU不可用，用于全局任务调度时快速计算迁移决策",
          "similarity": 0.544630765914917
        }
      ]
    }
  ]
}