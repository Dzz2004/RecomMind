{
  "query": "读写锁与互斥锁的并发性能对比",
  "timestamp": "2025-12-26 00:57:03",
  "retrieved_files": [
    {
      "source_file": "kernel/locking/mutex.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:42:50\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\mutex.c`\n\n---\n\n# Linux 内核互斥锁（mutex）实现文档\n\n## 1. 文件概述\n\n`locking/mutex.c` 是 Linux 内核中互斥锁（mutex）的核心实现文件，提供了基于阻塞的互斥同步原语。该文件实现了高效、可睡眠的互斥锁机制，支持自旋优化、锁移交（handoff）、调试功能以及与调度器、死锁检测等子系统的深度集成。互斥锁用于保护临界区，确保同一时间只有一个任务可以持有锁，适用于需要长时间持有锁或可能睡眠的场景。\n\n## 2. 核心功能\n\n### 主要函数\n\n- `__mutex_init()`：初始化互斥锁对象\n- `mutex_is_locked()`：检查互斥锁是否已被持有\n- `mutex_get_owner()`：获取当前锁持有者的任务指针（仅用于调试）\n- `__mutex_trylock()`：尝试获取互斥锁（非阻塞）\n- `__mutex_trylock_fast()`：快速路径尝试获取未竞争的锁\n- `__mutex_unlock_fast()`：快速路径释放锁\n- `__mutex_lock_slowpath()`：慢速路径获取锁（包含睡眠和等待逻辑）\n- `__mutex_handoff()`：将锁所有权移交给指定任务\n- `__mutex_add_waiter()` / `__mutex_remove_waiter()`：管理等待队列\n\n### 关键数据结构\n\n- `struct mutex`：互斥锁核心结构体\n  - `atomic_long_t owner`：原子存储锁持有者指针和状态标志\n  - `raw_spinlock_t wait_lock`：保护等待队列的自旋锁\n  - `struct list_head wait_list`：等待获取锁的任务队列\n  - `struct optimistic_spin_queue osq`：用于自旋优化的队列（CONFIG_MUTEX_SPIN_ON_OWNER）\n\n### 状态标志位\n\n- `MUTEX_FLAG_WAITERS (0x01)`：表示存在等待者，解锁时需唤醒\n- `MUTEX_FLAG_HANDOFF (0x02)`：表示需要将锁移交给队首等待者\n- `MUTEX_FLAG_PICKUP (0x04)`：表示锁已被移交给特定任务，等待其获取\n\n## 3. 关键实现\n\n### 锁状态编码\n互斥锁的 `owner` 字段采用指针-标志位混合编码：利用 `task_struct` 指针的低 3 位（因内存对齐保证为 0）存储状态标志。这种设计避免了额外的内存访问，提高了原子操作效率。\n\n### 快慢路径分离\n- **快速路径**：针对无竞争场景，直接通过原子比较交换（cmpxchg）获取/释放锁，避免函数调用开销\n- **慢速路径**：处理竞争情况，包含自旋等待、任务阻塞、唤醒等复杂逻辑\n\n### 自适应自旋（Adaptive Spinning）\n在 `CONFIG_MUTEX_SPIN_ON_OWNER` 配置下，当检测到锁持有者正在运行时，当前任务会先自旋等待而非立即睡眠，减少上下文切换开销。使用 OSQ（Optimistic Spin Queue）机制协调多个自旋任务。\n\n### 锁移交机制（Handoff）\n通过 `MUTEX_FLAG_HANDOFF` 和 `MUTEX_FLAG_PICKUP` 标志实现高效的锁移交：\n1. 解锁者设置 `HANDOFF` 标志并唤醒队首等待者\n2. 被唤醒任务在获取锁时检测到 `HANDOFF`，设置 `PICKUP` 标志\n3. 解锁者通过 `__mutex_handoff()` 直接将所有权转移给指定任务\n避免了唤醒后再次竞争的问题，提高实时性。\n\n### 调试支持\n- `CONFIG_DEBUG_MUTEXES`：提供锁状态验证、死锁检测\n- `CONFIG_DETECT_HUNG_TASK_BLOCKER`：集成 hung task 检测，记录阻塞源\n- `lockdep`：通过 `debug_mutex_*` 函数集成锁依赖验证\n\n## 4. 依赖关系\n\n### 头文件依赖\n- `<linux/mutex.h>` / `<linux/ww_mutex.h>`：互斥锁接口定义\n- `<linux/sched/*.h>`：调度器相关功能（睡眠、唤醒、实时任务）\n- `<linux/spinlock.h>`：底层自旋锁实现\n- `<linux/osq_lock.h>`：乐观自旋队列支持\n- `<linux/hung_task.h>`：hung task 检测集成\n- `<trace/events/lock.h>`：锁事件跟踪点\n\n### 子系统交互\n- **调度器**：通过 `schedule()` 实现任务阻塞，`wake_q` 机制批量唤醒\n- **内存管理**：依赖 `task_struct` 的内存对齐特性\n- **实时补丁（PREEMPT_RT）**：非 RT 配置下编译此文件（`#ifndef CONFIG_PREEMPT_RT`）\n- **调试子系统**：与 lockdep、hung task detector 深度集成\n\n## 5. 使用场景\n\n### 典型应用场景\n- **长临界区保护**：当临界区执行时间较长或包含可能睡眠的操作（如内存分配、I/O）\n- **驱动程序同步**：设备驱动中保护硬件寄存器访问或共享数据结构\n- **文件系统操作**：保护 inode、dentry 等元数据结构\n- **内核子系统互斥**：如网络协议栈、块设备层等需要互斥访问的场景\n\n### 使用约束\n- **不可递归**：同一任务重复获取会导致死锁\n- **必须配对使用**：获取锁的任务必须负责释放\n- **禁止中断上下文使用**：因可能睡眠，只能在进程上下文使用\n- **内存生命周期**：锁对象内存不能在持有锁时释放\n\n### 性能考量\n- 无竞争场景：纳秒级延迟（快速路径原子操作）\n- 有竞争场景：微秒级延迟（自旋优化）或毫秒级（任务切换）\n- 适用于中低频竞争场景，高频竞争建议使用读写锁或 RCU",
      "similarity": 0.588396430015564,
      "chunks": [
        {
          "chunk_id": 6,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 1059,
          "end_line": 1129,
          "content": [
            "static noinline int __sched",
            "__mutex_lock_interruptible_slowpath(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "static noinline int __sched",
            "__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0,",
            "\t\t\t       _RET_IP_, ctx);",
            "}",
            "static noinline int __sched",
            "__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,",
            "\t\t\t\t\t    struct ww_acquire_ctx *ctx)",
            "{",
            "\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0,",
            "\t\t\t       _RET_IP_, ctx);",
            "}",
            "int __sched mutex_trylock(struct mutex *lock)",
            "{",
            "\tbool locked;",
            "",
            "\tMUTEX_WARN_ON(lock->magic != lock);",
            "",
            "\tlocked = __mutex_trylock(lock);",
            "\tif (locked)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn locked;",
            "}",
            "int __sched",
            "ww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(&lock->base)) {",
            "\t\tif (ctx)",
            "\t\t\tww_mutex_set_context_fastpath(lock, ctx);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn __ww_mutex_lock_slowpath(lock, ctx);",
            "}",
            "int __sched",
            "ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(&lock->base)) {",
            "\t\tif (ctx)",
            "\t\t\tww_mutex_set_context_fastpath(lock, ctx);",
            "\t\treturn 0;",
            "\t}",
            "",
            "\treturn __ww_mutex_lock_interruptible_slowpath(lock, ctx);",
            "}",
            "int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock)",
            "{",
            "\t/* dec if we can't possibly hit 0 */",
            "\tif (atomic_add_unless(cnt, -1, 1))",
            "\t\treturn 0;",
            "\t/* we might hit 0, so take the lock */",
            "\tmutex_lock(lock);",
            "\tif (!atomic_dec_and_test(cnt)) {",
            "\t\t/* when we actually did the dec, we didn't hit 0 */",
            "\t\tmutex_unlock(lock);",
            "\t\treturn 0;",
            "\t}",
            "\t/* we hit 0, and we hold the lock */",
            "\treturn 1;",
            "}"
          ],
          "function_name": "__mutex_lock_interruptible_slowpath, __ww_mutex_lock_slowpath, __ww_mutex_lock_interruptible_slowpath, mutex_trylock, ww_mutex_lock, ww_mutex_lock_interruptible, atomic_dec_and_mutex_lock",
          "description": "提供互斥锁快速路径与慢速路径切换支持，包含原子计数器递减与锁获取协同机制",
          "similarity": 0.6996603012084961
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 46,
          "end_line": 151,
          "content": [
            "void",
            "__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)",
            "{",
            "\tatomic_long_set(&lock->owner, 0);",
            "\traw_spin_lock_init(&lock->wait_lock);",
            "\tINIT_LIST_HEAD(&lock->wait_list);",
            "#ifdef CONFIG_MUTEX_SPIN_ON_OWNER",
            "\tosq_lock_init(&lock->osq);",
            "#endif",
            "",
            "\tdebug_mutex_init(lock, name, key);",
            "}",
            "bool mutex_is_locked(struct mutex *lock)",
            "{",
            "\treturn __mutex_owner(lock) != NULL;",
            "}",
            "static inline unsigned long __owner_flags(unsigned long owner)",
            "{",
            "\treturn owner & MUTEX_FLAGS;",
            "}",
            "unsigned long mutex_get_owner(struct mutex *lock)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\treturn (unsigned long)__owner_task(owner);",
            "}",
            "static inline bool __mutex_trylock_or_handoff(struct mutex *lock, bool handoff)",
            "{",
            "\treturn !__mutex_trylock_common(lock, handoff);",
            "}",
            "static inline bool __mutex_trylock(struct mutex *lock)",
            "{",
            "\treturn !__mutex_trylock_common(lock, false);",
            "}",
            "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "\tunsigned long zero = 0UL;",
            "",
            "\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))",
            "\t\treturn true;",
            "",
            "\treturn false;",
            "}",
            "static __always_inline bool __mutex_unlock_fast(struct mutex *lock)",
            "{",
            "\tunsigned long curr = (unsigned long)current;",
            "",
            "\treturn atomic_long_try_cmpxchg_release(&lock->owner, &curr, 0UL);",
            "}",
            "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_or(flag, &lock->owner);",
            "}",
            "static inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)",
            "{",
            "\tatomic_long_andnot(flag, &lock->owner);",
            "}",
            "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;",
            "}",
            "static void",
            "__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,",
            "\t\t   struct list_head *list)",
            "{",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_set_blocker(lock, BLOCKER_TYPE_MUTEX);",
            "#endif",
            "\tdebug_mutex_add_waiter(lock, waiter, current);",
            "",
            "\tlist_add_tail(&waiter->list, list);",
            "\tif (__mutex_waiter_is_first(lock, waiter))",
            "\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);",
            "}",
            "static void",
            "__mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter)",
            "{",
            "\tlist_del(&waiter->list);",
            "\tif (likely(list_empty(&lock->wait_list)))",
            "\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);",
            "",
            "\tdebug_mutex_remove_waiter(lock, waiter, current);",
            "#ifdef CONFIG_DETECT_HUNG_TASK_BLOCKER",
            "\thung_task_clear_blocker();",
            "#endif",
            "}",
            "static void __mutex_handoff(struct mutex *lock, struct task_struct *task)",
            "{",
            "\tunsigned long owner = atomic_long_read(&lock->owner);",
            "",
            "\tfor (;;) {",
            "\t\tunsigned long new;",
            "",
            "\t\tMUTEX_WARN_ON(__owner_task(owner) != current);",
            "\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);",
            "",
            "\t\tnew = (owner & MUTEX_FLAG_WAITERS);",
            "\t\tnew |= (unsigned long)task;",
            "\t\tif (task)",
            "\t\t\tnew |= MUTEX_FLAG_PICKUP;",
            "",
            "\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, new))",
            "\t\t\tbreak;",
            "\t}",
            "}"
          ],
          "function_name": "__mutex_init, mutex_is_locked, __owner_flags, mutex_get_owner, __mutex_trylock_or_handoff, __mutex_trylock, __mutex_trylock_fast, __mutex_unlock_fast, __mutex_set_flag, __mutex_clear_flag, __mutex_waiter_is_first, __mutex_add_waiter, __mutex_remove_waiter, __mutex_handoff",
          "description": "实现互斥锁核心操作，包括初始化、状态检查、快速尝试加锁、标志位操作及等待者链表管理。",
          "similarity": 0.6747139692306519
        },
        {
          "chunk_id": 5,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 895,
          "end_line": 996,
          "content": [
            "int __sched",
            "ww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tret = __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE,",
            "\t\t\t      0, _RET_IP_, ctx);",
            "",
            "\tif (!ret && ctx && ctx->acquired > 1)",
            "\t\treturn ww_mutex_deadlock_injection(lock, ctx);",
            "",
            "\treturn ret;",
            "}",
            "static noinline void __sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)",
            "{",
            "\tstruct task_struct *next = NULL;",
            "\tDEFINE_WAKE_Q(wake_q);",
            "\tunsigned long owner;",
            "",
            "\tmutex_release(&lock->dep_map, ip);",
            "",
            "\t/*",
            "\t * Release the lock before (potentially) taking the spinlock such that",
            "\t * other contenders can get on with things ASAP.",
            "\t *",
            "\t * Except when HANDOFF, in that case we must not clear the owner field,",
            "\t * but instead set it to the top waiter.",
            "\t */",
            "\towner = atomic_long_read(&lock->owner);",
            "\tfor (;;) {",
            "\t\tMUTEX_WARN_ON(__owner_task(owner) != current);",
            "\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);",
            "",
            "\t\tif (owner & MUTEX_FLAG_HANDOFF)",
            "\t\t\tbreak;",
            "",
            "\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, __owner_flags(owner))) {",
            "\t\t\tif (owner & MUTEX_FLAG_WAITERS)",
            "\t\t\t\tbreak;",
            "",
            "\t\t\treturn;",
            "\t\t}",
            "\t}",
            "",
            "\traw_spin_lock(&lock->wait_lock);",
            "\tdebug_mutex_unlock(lock);",
            "\tif (!list_empty(&lock->wait_list)) {",
            "\t\t/* get the first entry from the wait-list: */",
            "\t\tstruct mutex_waiter *waiter =",
            "\t\t\tlist_first_entry(&lock->wait_list,",
            "\t\t\t\t\t struct mutex_waiter, list);",
            "",
            "\t\tnext = waiter->task;",
            "",
            "\t\tdebug_mutex_wake_waiter(lock, waiter);",
            "\t\twake_q_add(&wake_q, next);",
            "\t}",
            "",
            "\tif (owner & MUTEX_FLAG_HANDOFF)",
            "\t\t__mutex_handoff(lock, next);",
            "",
            "\traw_spin_unlock(&lock->wait_lock);",
            "",
            "\twake_up_q(&wake_q);",
            "}",
            "int __sched mutex_lock_interruptible(struct mutex *lock)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(lock))",
            "\t\treturn 0;",
            "",
            "\treturn __mutex_lock_interruptible_slowpath(lock);",
            "}",
            "int __sched mutex_lock_killable(struct mutex *lock)",
            "{",
            "\tmight_sleep();",
            "",
            "\tif (__mutex_trylock_fast(lock))",
            "\t\treturn 0;",
            "",
            "\treturn __mutex_lock_killable_slowpath(lock);",
            "}",
            "void __sched mutex_lock_io(struct mutex *lock)",
            "{",
            "\tint token;",
            "",
            "\ttoken = io_schedule_prepare();",
            "\tmutex_lock(lock);",
            "\tio_schedule_finish(token);",
            "}",
            "static noinline void __sched",
            "__mutex_lock_slowpath(struct mutex *lock)",
            "{",
            "\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "static noinline int __sched",
            "__mutex_lock_killable_slowpath(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);",
            "}"
          ],
          "function_name": "ww_mutex_lock_interruptible, __mutex_unlock_slowpath, mutex_lock_interruptible, mutex_lock_killable, mutex_lock_io, __mutex_lock_slowpath, __mutex_lock_killable_slowpath",
          "description": "实现带死锁检测的递归互斥锁中断获取逻辑，处理锁状态转换、唤醒等待线程及异常注入场景",
          "similarity": 0.6257262825965881
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 1,
          "end_line": 45,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * kernel/locking/mutex.c",
            " *",
            " * Mutexes: blocking mutual exclusion locks",
            " *",
            " * Started by Ingo Molnar:",
            " *",
            " *  Copyright (C) 2004, 2005, 2006 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>",
            " *",
            " * Many thanks to Arjan van de Ven, Thomas Gleixner, Steven Rostedt and",
            " * David Howells for suggestions and improvements.",
            " *",
            " *  - Adaptive spinning for mutexes by Peter Zijlstra. (Ported to mainline",
            " *    from the -rt tree, where it was originally implemented for rtmutexes",
            " *    by Steven Rostedt, based on work by Gregory Haskins, Peter Morreale",
            " *    and Sven Dietrich.",
            " *",
            " * Also see Documentation/locking/mutex-design.rst.",
            " */",
            "#include <linux/mutex.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/osq_lock.h>",
            "#include <linux/hung_task.h>",
            "",
            "#define CREATE_TRACE_POINTS",
            "#include <trace/events/lock.h>",
            "",
            "#ifndef CONFIG_PREEMPT_RT",
            "#include \"mutex.h\"",
            "",
            "#ifdef CONFIG_DEBUG_MUTEXES",
            "# define MUTEX_WARN_ON(cond) DEBUG_LOCKS_WARN_ON(cond)",
            "#else",
            "# define MUTEX_WARN_ON(cond)",
            "#endif",
            ""
          ],
          "function_name": null,
          "description": "声明互斥锁模块的头文件和基本配置，初始化互斥锁结构体并设置等待队列及调试信息。",
          "similarity": 0.607864260673523
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/mutex.c",
          "start_line": 455,
          "end_line": 722,
          "content": [
            "static __always_inline bool",
            "mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t      struct mutex_waiter *waiter)",
            "{",
            "\tif (!waiter) {",
            "\t\t/*",
            "\t\t * The purpose of the mutex_can_spin_on_owner() function is",
            "\t\t * to eliminate the overhead of osq_lock() and osq_unlock()",
            "\t\t * in case spinning isn't possible. As a waiter-spinner",
            "\t\t * is not going to take OSQ lock anyway, there is no need",
            "\t\t * to call mutex_can_spin_on_owner().",
            "\t\t */",
            "\t\tif (!mutex_can_spin_on_owner(lock))",
            "\t\t\tgoto fail;",
            "",
            "\t\t/*",
            "\t\t * In order to avoid a stampede of mutex spinners trying to",
            "\t\t * acquire the mutex all at once, the spinners need to take a",
            "\t\t * MCS (queued) lock first before spinning on the owner field.",
            "\t\t */",
            "\t\tif (!osq_lock(&lock->osq))",
            "\t\t\tgoto fail;",
            "\t}",
            "",
            "\tfor (;;) {",
            "\t\tstruct task_struct *owner;",
            "",
            "\t\t/* Try to acquire the mutex... */",
            "\t\towner = __mutex_trylock_or_owner(lock);",
            "\t\tif (!owner)",
            "\t\t\tbreak;",
            "",
            "\t\t/*",
            "\t\t * There's an owner, wait for it to either",
            "\t\t * release the lock or go to sleep.",
            "\t\t */",
            "\t\tif (!mutex_spin_on_owner(lock, owner, ww_ctx, waiter))",
            "\t\t\tgoto fail_unlock;",
            "",
            "\t\t/*",
            "\t\t * The cpu_relax() call is a compiler barrier which forces",
            "\t\t * everything in this loop to be re-loaded. We don't need",
            "\t\t * memory barriers as we'll eventually observe the right",
            "\t\t * values at the cost of a few extra spins.",
            "\t\t */",
            "\t\tcpu_relax();",
            "\t}",
            "",
            "\tif (!waiter)",
            "\t\tosq_unlock(&lock->osq);",
            "",
            "\treturn true;",
            "",
            "",
            "fail_unlock:",
            "\tif (!waiter)",
            "\t\tosq_unlock(&lock->osq);",
            "",
            "fail:",
            "\t/*",
            "\t * If we fell out of the spin path because of need_resched(),",
            "\t * reschedule now, before we try-lock the mutex. This avoids getting",
            "\t * scheduled out right after we obtained the mutex.",
            "\t */",
            "\tif (need_resched()) {",
            "\t\t/*",
            "\t\t * We _should_ have TASK_RUNNING here, but just in case",
            "\t\t * we do not, make it so, otherwise we might get stuck.",
            "\t\t */",
            "\t\t__set_current_state(TASK_RUNNING);",
            "\t\tschedule_preempt_disabled();",
            "\t}",
            "",
            "\treturn false;",
            "}",
            "static __always_inline bool",
            "mutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,",
            "\t\t      struct mutex_waiter *waiter)",
            "{",
            "\treturn false;",
            "}",
            "void __sched mutex_unlock(struct mutex *lock)",
            "{",
            "#ifndef CONFIG_DEBUG_LOCK_ALLOC",
            "\tif (__mutex_unlock_fast(lock))",
            "\t\treturn;",
            "#endif",
            "\t__mutex_unlock_slowpath(lock, _RET_IP_);",
            "}",
            "void __sched ww_mutex_unlock(struct ww_mutex *lock)",
            "{",
            "\t__ww_mutex_unlock(lock);",
            "\tmutex_unlock(&lock->base);",
            "}",
            "static __always_inline int __sched",
            "__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,",
            "\t\t    struct lockdep_map *nest_lock, unsigned long ip,",
            "\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)",
            "{",
            "\tstruct mutex_waiter waiter;",
            "\tstruct ww_mutex *ww;",
            "\tint ret;",
            "",
            "\tif (!use_ww_ctx)",
            "\t\tww_ctx = NULL;",
            "",
            "\tmight_sleep();",
            "",
            "\tMUTEX_WARN_ON(lock->magic != lock);",
            "",
            "\tww = container_of(lock, struct ww_mutex, base);",
            "\tif (ww_ctx) {",
            "\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))",
            "\t\t\treturn -EALREADY;",
            "",
            "\t\t/*",
            "\t\t * Reset the wounded flag after a kill. No other process can",
            "\t\t * race and wound us here since they can't have a valid owner",
            "\t\t * pointer if we don't have any locks held.",
            "\t\t */",
            "\t\tif (ww_ctx->acquired == 0)",
            "\t\t\tww_ctx->wounded = 0;",
            "",
            "#ifdef CONFIG_DEBUG_LOCK_ALLOC",
            "\t\tnest_lock = &ww_ctx->dep_map;",
            "#endif",
            "\t}",
            "",
            "\tpreempt_disable();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);",
            "",
            "\ttrace_contention_begin(lock, LCB_F_MUTEX | LCB_F_SPIN);",
            "\tif (__mutex_trylock(lock) ||",
            "\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {",
            "\t\t/* got the lock, yay! */",
            "\t\tlock_acquired(&lock->dep_map, ip);",
            "\t\tif (ww_ctx)",
            "\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);",
            "\t\ttrace_contention_end(lock, 0);",
            "\t\tpreempt_enable();",
            "\t\treturn 0;",
            "\t}",
            "",
            "\traw_spin_lock(&lock->wait_lock);",
            "\t/*",
            "\t * After waiting to acquire the wait_lock, try again.",
            "\t */",
            "\tif (__mutex_trylock(lock)) {",
            "\t\tif (ww_ctx)",
            "\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);",
            "",
            "\t\tgoto skip_wait;",
            "\t}",
            "",
            "\tdebug_mutex_lock_common(lock, &waiter);",
            "\twaiter.task = current;",
            "\tif (use_ww_ctx)",
            "\t\twaiter.ww_ctx = ww_ctx;",
            "",
            "\tlock_contended(&lock->dep_map, ip);",
            "",
            "\tif (!use_ww_ctx) {",
            "\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */",
            "\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);",
            "\t} else {",
            "\t\t/*",
            "\t\t * Add in stamp order, waking up waiters that must kill",
            "\t\t * themselves.",
            "\t\t */",
            "\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);",
            "\t\tif (ret)",
            "\t\t\tgoto err_early_kill;",
            "\t}",
            "",
            "\tset_current_state(state);",
            "\ttrace_contention_begin(lock, LCB_F_MUTEX);",
            "\tfor (;;) {",
            "\t\tbool first;",
            "",
            "\t\t/*",
            "\t\t * Once we hold wait_lock, we're serialized against",
            "\t\t * mutex_unlock() handing the lock off to us, do a trylock",
            "\t\t * before testing the error conditions to make sure we pick up",
            "\t\t * the handoff.",
            "\t\t */",
            "\t\tif (__mutex_trylock(lock))",
            "\t\t\tgoto acquired;",
            "",
            "\t\t/*",
            "\t\t * Check for signals and kill conditions while holding",
            "\t\t * wait_lock. This ensures the lock cancellation is ordered",
            "\t\t * against mutex_unlock() and wake-ups do not go missing.",
            "\t\t */",
            "\t\tif (signal_pending_state(state, current)) {",
            "\t\t\tret = -EINTR;",
            "\t\t\tgoto err;",
            "\t\t}",
            "",
            "\t\tif (ww_ctx) {",
            "\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);",
            "\t\t\tif (ret)",
            "\t\t\t\tgoto err;",
            "\t\t}",
            "",
            "\t\traw_spin_unlock(&lock->wait_lock);",
            "\t\tschedule_preempt_disabled();",
            "",
            "\t\tfirst = __mutex_waiter_is_first(lock, &waiter);",
            "",
            "\t\tset_current_state(state);",
            "\t\t/*",
            "\t\t * Here we order against unlock; we must either see it change",
            "\t\t * state back to RUNNING and fall through the next schedule(),",
            "\t\t * or we must see its unlock and acquire.",
            "\t\t */",
            "\t\tif (__mutex_trylock_or_handoff(lock, first))",
            "\t\t\tbreak;",
            "",
            "\t\tif (first) {",
            "\t\t\ttrace_contention_begin(lock, LCB_F_MUTEX | LCB_F_SPIN);",
            "\t\t\tif (mutex_optimistic_spin(lock, ww_ctx, &waiter))",
            "\t\t\t\tbreak;",
            "\t\t\ttrace_contention_begin(lock, LCB_F_MUTEX);",
            "\t\t}",
            "",
            "\t\traw_spin_lock(&lock->wait_lock);",
            "\t}",
            "\traw_spin_lock(&lock->wait_lock);",
            "acquired:",
            "\t__set_current_state(TASK_RUNNING);",
            "",
            "\tif (ww_ctx) {",
            "\t\t/*",
            "\t\t * Wound-Wait; we stole the lock (!first_waiter), check the",
            "\t\t * waiters as anyone might want to wound us.",
            "\t\t */",
            "\t\tif (!ww_ctx->is_wait_die &&",
            "\t\t    !__mutex_waiter_is_first(lock, &waiter))",
            "\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);",
            "\t}",
            "",
            "\t__mutex_remove_waiter(lock, &waiter);",
            "",
            "\tdebug_mutex_free_waiter(&waiter);",
            "",
            "skip_wait:",
            "\t/* got the lock - cleanup and rejoice! */",
            "\tlock_acquired(&lock->dep_map, ip);",
            "\ttrace_contention_end(lock, 0);",
            "",
            "\tif (ww_ctx)",
            "\t\tww_mutex_lock_acquired(ww, ww_ctx);",
            "",
            "\traw_spin_unlock(&lock->wait_lock);",
            "\tpreempt_enable();",
            "\treturn 0;",
            "",
            "err:",
            "\t__set_current_state(TASK_RUNNING);",
            "\t__mutex_remove_waiter(lock, &waiter);",
            "err_early_kill:",
            "\ttrace_contention_end(lock, ret);",
            "\traw_spin_unlock(&lock->wait_lock);",
            "\tdebug_mutex_free_waiter(&waiter);",
            "\tmutex_release(&lock->dep_map, ip);",
            "\tpreempt_enable();",
            "\treturn ret;",
            "}"
          ],
          "function_name": "mutex_optimistic_spin, mutex_optimistic_spin, mutex_unlock, ww_mutex_unlock, __mutex_lock_common",
          "description": "实现乐观自旋逻辑和锁解除操作，通过原子操作和同步机制管理锁竞争，支持带资源检查的锁操作。",
          "similarity": 0.5757826566696167
        }
      ]
    },
    {
      "source_file": "kernel/locking/ww_mutex.h",
      "md_summary": "> 自动生成时间: 2025-10-25 14:56:40\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\ww_mutex.h`\n\n---\n\n# `locking/ww_mutex.h` 技术文档\n\n## 1. 文件概述\n\n`ww_mutex.h` 是 Linux 内核中用于实现 **Wound-Wait (WW) 互斥锁**（`ww_mutex`）的头文件。该机制主要用于解决 **死锁问题**，特别是在图形子系统（如 DRM/KMS）和资源管理场景中，多个事务（transactions）需要以特定顺序获取多个锁时。  \nWW 互斥锁通过为每个锁请求关联一个 **获取上下文**（`ww_acquire_ctx`），并基于事务的优先级或时间戳实现 **Wait-Die** 或 **Wound-Wait** 死锁避免策略。\n\n该文件通过条件编译（`WW_RT` 宏）支持两种底层锁实现：\n- **普通互斥锁**（`mutex`）：用于非实时（non-RT）内核配置。\n- **实时互斥锁**（`rt_mutex`）：用于实时（RT）内核补丁配置，支持优先级继承。\n\n## 2. 核心功能\n\n### 2.1 主要宏定义\n- `MUTEX` / `MUTEX_WAITER`：根据 `WW_RT` 宏分别映射到 `mutex`/`rt_mutex` 及其等待者结构。\n\n### 2.2 等待者链表/红黑树操作函数（抽象接口）\n- `__ww_waiter_first()`：获取等待队列中的第一个等待者。\n- `__ww_waiter_next()` / `__ww_waiter_prev()`：获取下一个/上一个等待者。\n- `__ww_waiter_last()`：获取等待队列中的最后一个等待者。\n- `__ww_waiter_add()`：将等待者插入到指定位置（普通 mutex 使用链表，RT 使用红黑树）。\n\n### 2.3 锁状态查询函数\n- `__ww_mutex_owner()`：获取当前锁的持有者任务。\n- `__ww_mutex_has_waiters()`：检查锁是否有等待者。\n- `lock_wait_lock()` / `unlock_wait_lock()`：获取/释放锁的等待队列自旋锁（`wait_lock`）。\n- `lockdep_assert_wait_lock_held()`：调试时断言 `wait_lock` 已被持有。\n\n### 2.4 WW 互斥锁核心逻辑函数\n- `ww_mutex_lock_acquired()`：在成功获取 `ww_mutex` 后，将其与获取上下文（`ww_ctx`）关联，并执行调试检查。\n- `__ww_ctx_less()`：比较两个获取上下文的优先级（用于决定谁应“等待”或“死亡/被抢占”）。\n- `__ww_mutex_die()`：**Wait-Die 策略**实现：若当前请求者（新事务）发现等待队列中有更老的事务持有其他锁，则唤醒该老事务使其“死亡”（回滚）。\n- `__ww_mutex_wound()`：**Wound-Wait 策略**实现：若当前请求者（老事务）发现锁持有者是更年轻的事务，则“刺伤”（标记 `wounded=1`）该年轻事务，迫使其回滚。\n\n## 3. 关键实现\n\n### 3.1 死锁避免策略\n- **Wait-Die**（`is_wait_die=1`）：\n  - **新事务**请求**老事务**持有的锁 → **新事务等待**。\n  - **新事务**请求**老事务**等待的锁 → **新事务死亡**（回滚）。\n- **Wound-Wait**（`is_wait_die=0`）：\n  - **老事务**请求**新事务**持有的锁 → **新事务被刺伤**（回滚）。\n  - **老事务**请求**新事务**等待的锁 → **老事务等待**。\n\n### 3.2 上下文比较 (`__ww_ctx_less`)\n- **非 RT 模式**：仅基于时间戳（`stamp`），值越大表示事务越新。\n- **RT 模式**：\n  1. 优先比较 **实时优先级**（`prio`），数值越小优先级越高。\n  2. 若均为 **Deadline 调度类**，比较 **截止时间**（`deadline`），越早截止优先级越高。\n  3. 若优先级相同，回退到时间戳比较。\n\n### 3.3 RT 与非 RT 差异\n- **数据结构**：\n  - 非 RT：等待者使用 **双向链表**（`list_head`）。\n  - RT：等待者使用 **红黑树**（`rb_root`），按优先级排序。\n- **插入逻辑**：\n  - 非 RT：`__ww_waiter_add` 显式插入到指定位置。\n  - RT：`__ww_waiter_add` 为空（RT 互斥锁内部自动处理插入）。\n\n### 3.4 调试支持 (`DEBUG_WW_MUTEXES`)\n- 检查 `ww_mutex` 是否被错误地用普通 `mutex_unlock` 释放。\n- 验证上下文一致性（如 `ww_class` 匹配、`contending_lock` 状态等）。\n\n## 4. 依赖关系\n\n- **基础锁机制**：\n  - 非 RT 模式依赖 `<linux/mutex.h>`。\n  - RT 模式依赖 `<linux/rtmutex.h>`。\n- **调度器**：依赖任务结构（`task_struct`）、优先级（`prio`）、调度类（如 `dl_prio`）。\n- **调试框架**：依赖 `lockdep`（`lockdep_assert_held`）和 `DEBUG_LOCKS_WARN_ON`。\n- **原子操作**：使用 `atomic_long_read` 检查锁状态标志（`MUTEX_FLAG_WAITERS`）。\n\n## 5. 使用场景\n\n- **图形子系统**（DRM/KMS）：  \n  多个 GPU 作业（如渲染、合成）需按顺序获取多个缓冲区（buffer）或 CRTC 锁，避免死锁。\n- **资源分配器**：  \n  当多个客户端竞争一组有限资源（如内存区域、I/O 端口）时，通过 WW 互斥锁确保无死锁的分配顺序。\n- **实时系统**（RT 补丁）：  \n  在需要确定性延迟的场景中，结合优先级继承（PI）避免优先级反转，同时通过 WW 策略解决多锁死锁。\n- **文件系统**：  \n  某些文件系统（如 Btrfs）在元数据操作中使用 WW 互斥锁管理多个 extent 锁。",
      "similarity": 0.5664708018302917,
      "chunks": []
    },
    {
      "source_file": "kernel/locking/rtmutex_api.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:49:05\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `locking\\rtmutex_api.c`\n\n---\n\n# `locking/rtmutex_api.c` 技术文档\n\n## 1. 文件概述\n\n`rtmutex_api.c` 是 Linux 内核中实时互斥锁（Real-Time Mutex, rtmutex）的公共 API 实现文件。该文件封装了底层 rtmutex 核心逻辑（定义在 `rtmutex.c` 中），为内核其他子系统提供统一、安全、可调试的互斥锁操作接口。它支持多种锁获取模式（不可中断、可中断、可终止）、调试锁依赖（lockdep）、PI（Priority Inheritance，优先级继承）机制，并为 futex（快速用户空间互斥）提供专用变体接口。该文件通过条件编译适配是否启用锁调试功能（`CONFIG_DEBUG_LOCK_ALLOC`）。\n\n## 2. 核心功能\n\n### 全局变量\n- `max_lock_depth`: 定义优先级继承链（boosting chain）的最大遍历深度，防止死锁检测时无限循环，默认值为 1024。\n\n### 主要函数\n\n#### 初始化与销毁\n- `rt_mutex_base_init()`: 初始化 `rt_mutex_base` 结构体的基础字段。\n- `__rt_mutex_init()`: 完整初始化一个 `rt_mutex`，包括底层 rtmutex 和 lockdep 调试信息。\n- `rt_mutex_init_proxy_locked()`: 为 PI-futex 场景初始化并立即锁定 rtmutex，指定代理持有者（proxy owner）。\n- `rt_mutex_proxy_unlock()`: 为 PI-futex 场景释放由代理持有的 rtmutex。\n\n#### 锁获取（Locking）\n- `rt_mutex_lock[_nested]()`: 以不可中断方式获取 rtmutex（支持 lockdep 嵌套子类）。\n- `_rt_mutex_lock_nest_lock()`: 获取 rtmutex 并关联一个嵌套锁（nest lock）用于 lockdep。\n- `rt_mutex_lock_interruptible()`: 以可被信号中断的方式获取 rtmutex。\n- `rt_mutex_lock_killable()`: 以可被致命信号中断的方式获取 rtmutex。\n- `rt_mutex_trylock()`: 尝试非阻塞获取 rtmutex，成功返回 1，失败返回 0。\n\n#### 锁释放（Unlocking）\n- `rt_mutex_unlock()`: 释放 rtmutex。\n- `rt_mutex_futex_unlock()`: 专用于 futex 的 rtmutex 释放接口。\n- `__rt_mutex_futex_unlock()`: futex 释放的内部实现，需配合 `rt_mutex_postunlock()` 使用。\n\n#### Futex 专用接口\n- `rt_mutex_futex_trylock()`: futex 使用的非阻塞尝试锁接口。\n- `__rt_mutex_futex_trylock()`: futex 尝试锁的底层实现。\n\n#### 代理锁操作（Proxy Locking，用于 PI-futex）\n- `__rt_mutex_start_proxy_lock()`: 为另一个任务启动代理锁获取流程（仅入队，不阻塞等待）。\n\n## 3. 关键实现\n\n### 锁操作通用封装\n- `__rt_mutex_lock_common()` 是所有阻塞式锁获取函数的统一入口。它负责：\n  - 调用 `might_sleep()` 提示可能睡眠。\n  - 通过 `mutex_acquire_nest()` 向 lockdep 子系统注册锁获取事件。\n  - 调用底层 `__rt_mutex_lock()` 执行实际的锁逻辑。\n  - 若获取失败（如被信号中断），则调用 `mutex_release()` 通知 lockdep 释放。\n\n### 调试支持\n- 在 `CONFIG_DEBUG_LOCK_ALLOC` 启用时，提供带 lockdep 子类和嵌套锁参数的锁接口（如 `rt_mutex_lock_nested`），增强死锁检测能力。\n- `rt_mutex_trylock()` 在调试模式下会检查调用上下文是否为任务上下文（`in_task()`），防止在中断上下文中误用。\n- 初始化函数 `__rt_mutex_init()` 调用 `debug_check_no_locks_freed()` 防止对已释放内存初始化锁。\n\n### Futex 特殊处理\n- Futex 相关接口（如 `rt_mutex_futex_unlock`）绕过 rtmutex 的 fast-path，直接使用 slow-path 实现。\n- `rt_mutex_init_proxy_locked()` 为 PI-futex 场景中的 `wait_lock` 分配独立的 lockdep 类键（`pi_futex_key`），避免与 futex 哈希桶自旋锁产生虚假的锁递归警告。\n- `__rt_mutex_futex_unlock()` 在释放锁时，若存在等待者，则调用 `mark_wakeup_next_waiter()` 准备唤醒，并返回 `true` 指示需后续调用 `rt_mutex_postunlock()` 完成唤醒。\n\n### 代理锁机制\n- 代理锁函数（如 `rt_mutex_init_proxy_locked` 和 `__rt_mutex_start_proxy_lock`）用于 PI-futex 实现，允许内核代表用户空间任务持有或竞争锁，是优先级继承在 futex 上的关键支撑。\n\n## 4. 依赖关系\n\n- **底层实现**: 通过 `#include \"rtmutex.c\"`（配合 `RT_MUTEX_BUILD_MUTEX` 宏）内联包含 `rtmutex.c` 中的核心逻辑（如 `__rt_mutex_lock`, `__rt_mutex_unlock` 等）。\n- **同步原语**: 依赖 `<linux/spinlock.h>` 提供自旋锁操作（如 `raw_spin_lock_irqsave`）。\n- **调试子系统**: \n  - 依赖 Lockdep（`<linux/lockdep.h>` 隐式包含）进行锁依赖和死锁检测。\n  - 依赖 RT Mutex 调试（`CONFIG_DEBUG_RT_MUTEXES`）进行运行时检查。\n- **调度器**: 使用 `TASK_*` 状态常量（如 `TASK_INTERRUPTIBLE`）与调度器交互，支持可中断睡眠。\n- **导出符号**: 通过 `EXPORT_SYMBOL` 和 `EXPORT_SYMBOL_GPL` 向内核其他模块（如 futex、PI 子系统）提供 API。\n\n## 5. 使用场景\n\n- **实时互斥锁**: 作为内核中支持优先级继承的互斥锁实现，用于需要避免优先级反转的实时任务同步。\n- **PI-futex 支持**: 为用户空间的 PI-aware futex（`FUTEX_LOCK_PI` 等操作）提供内核态代理锁管理，实现跨进程的优先级继承。\n- **内核子系统同步**: 被需要强优先级继承语义的内核子系统（如某些设备驱动、实时调度相关代码）直接使用。\n- **调试与验证**: 在启用锁调试的内核配置下，为 lockdep 提供详细的锁获取/释放轨迹，辅助死锁分析。",
      "similarity": 0.5641339421272278,
      "chunks": [
        {
          "chunk_id": 4,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 590,
          "end_line": 607,
          "content": [
            "int __sched mutex_trylock(struct mutex *lock)",
            "{",
            "\tint ret;",
            "",
            "\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))",
            "\t\treturn 0;",
            "",
            "\tret = __rt_mutex_trylock(&lock->rtmutex);",
            "\tif (ret)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn ret;",
            "}",
            "void __sched mutex_unlock(struct mutex *lock)",
            "{",
            "\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\t__rt_mutex_unlock(&lock->rtmutex);",
            "}"
          ],
          "function_name": "mutex_trylock, mutex_unlock",
          "description": "实现互斥锁的尝试获取和释放操作，通过底层rtmutex_trylock进行非阻塞获取，成功时记录锁占用状态，释放时触发锁依赖跟踪和底层解锁流程。",
          "similarity": 0.6317816376686096
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 453,
          "end_line": 554,
          "content": [
            "void __sched rt_mutex_adjust_pi(struct task_struct *task)",
            "{",
            "\tstruct rt_mutex_waiter *waiter;",
            "\tstruct rt_mutex_base *next_lock;",
            "\tunsigned long flags;",
            "",
            "\traw_spin_lock_irqsave(&task->pi_lock, flags);",
            "",
            "\twaiter = task->pi_blocked_on;",
            "\tif (!waiter || rt_waiter_node_equal(&waiter->tree, task_to_waiter_node(task))) {",
            "\t\traw_spin_unlock_irqrestore(&task->pi_lock, flags);",
            "\t\treturn;",
            "\t}",
            "\tnext_lock = waiter->lock;",
            "\traw_spin_unlock_irqrestore(&task->pi_lock, flags);",
            "",
            "\t/* gets dropped in rt_mutex_adjust_prio_chain()! */",
            "\tget_task_struct(task);",
            "",
            "\trt_mutex_adjust_prio_chain(task, RT_MUTEX_MIN_CHAINWALK, NULL,",
            "\t\t\t\t   next_lock, NULL, task);",
            "}",
            "void __sched rt_mutex_postunlock(struct rt_wake_q_head *wqh)",
            "{",
            "\trt_mutex_wake_up_q(wqh);",
            "}",
            "void rt_mutex_debug_task_free(struct task_struct *task)",
            "{",
            "\tDEBUG_LOCKS_WARN_ON(!RB_EMPTY_ROOT(&task->pi_waiters.rb_root));",
            "\tDEBUG_LOCKS_WARN_ON(task->pi_blocked_on);",
            "}",
            "void __mutex_rt_init(struct mutex *mutex, const char *name,",
            "\t\t     struct lock_class_key *key)",
            "{",
            "\tdebug_check_no_locks_freed((void *)mutex, sizeof(*mutex));",
            "\tlockdep_init_map_wait(&mutex->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "}",
            "static __always_inline int __mutex_lock_common(struct mutex *lock,",
            "\t\t\t\t\t       unsigned int state,",
            "\t\t\t\t\t       unsigned int subclass,",
            "\t\t\t\t\t       struct lockdep_map *nest_lock,",
            "\t\t\t\t\t       unsigned long ip)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);",
            "\tret = __rt_mutex_lock(&lock->rtmutex, state);",
            "\tif (ret)",
            "\t\tmutex_release(&lock->dep_map, ip);",
            "\telse",
            "\t\tlock_acquired(&lock->dep_map, ip);",
            "\treturn ret;",
            "}",
            "void __sched mutex_lock_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched _mutex_lock_nest_lock(struct mutex *lock,",
            "\t\t\t\t   struct lockdep_map *nest_lock)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, nest_lock, _RET_IP_);",
            "}",
            "int __sched mutex_lock_interruptible_nested(struct mutex *lock,",
            "\t\t\t\t\t    unsigned int subclass)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_killable_nested(struct mutex *lock,",
            "\t\t\t\t\t    unsigned int subclass)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);",
            "}",
            "void __sched mutex_lock_io_nested(struct mutex *lock, unsigned int subclass)",
            "{",
            "\tint token;",
            "",
            "\tmight_sleep();",
            "",
            "\ttoken = io_schedule_prepare();",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);",
            "\tio_schedule_finish(token);",
            "}",
            "void __sched mutex_lock(struct mutex *lock)",
            "{",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_interruptible(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "}",
            "int __sched mutex_lock_killable(struct mutex *lock)",
            "{",
            "\treturn __mutex_lock_common(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);",
            "}",
            "void __sched mutex_lock_io(struct mutex *lock)",
            "{",
            "\tint token = io_schedule_prepare();",
            "",
            "\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);",
            "\tio_schedule_finish(token);",
            "}"
          ],
          "function_name": "rt_mutex_adjust_pi, rt_mutex_postunlock, rt_mutex_debug_task_free, __mutex_rt_init, __mutex_lock_common, mutex_lock_nested, _mutex_lock_nest_lock, mutex_lock_interruptible_nested, mutex_lock_killable_nested, mutex_lock_io_nested, mutex_lock, mutex_lock_interruptible, mutex_lock_killable, mutex_lock_io",
          "description": "提供标准互斥锁（mutex）的封装接口，将rtmutex操作映射到传统mutex接口，包含嵌套加锁、I/O路径加锁、优先级调整等特殊场景的支持实现。",
          "similarity": 0.6161662340164185
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 1,
          "end_line": 21,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * rtmutex API",
            " */",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "",
            "#define RT_MUTEX_BUILD_MUTEX",
            "#include \"rtmutex.c\"",
            "",
            "/*",
            " * Max number of times we'll walk the boosting chain:",
            " */",
            "int max_lock_depth = 1024;",
            "",
            "/*",
            " * Debug aware fast / slowpath lock,trylock,unlock",
            " *",
            " * The atomic acquire/release ops are compiled away, when either the",
            " * architecture does not support cmpxchg or when debugging is enabled.",
            " */"
          ],
          "function_name": null,
          "description": "定义实时互斥锁（rtmutex）的核心参数和调试相关配置，通过宏引入rtmutex实现文件，并设置最大锁深度限制，启用原子操作优化和调试支持。",
          "similarity": 0.6133504509925842
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 22,
          "end_line": 127,
          "content": [
            "static __always_inline int __rt_mutex_lock_common(struct rt_mutex *lock,",
            "\t\t\t\t\t\t  unsigned int state,",
            "\t\t\t\t\t\t  struct lockdep_map *nest_lock,",
            "\t\t\t\t\t\t  unsigned int subclass)",
            "{",
            "\tint ret;",
            "",
            "\tmight_sleep();",
            "\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, _RET_IP_);",
            "\tret = __rt_mutex_lock(&lock->rtmutex, state);",
            "\tif (ret)",
            "\t\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\treturn ret;",
            "}",
            "void rt_mutex_base_init(struct rt_mutex_base *rtb)",
            "{",
            "\t__rt_mutex_base_init(rtb);",
            "}",
            "void __sched rt_mutex_lock_nested(struct rt_mutex *lock, unsigned int subclass)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, subclass);",
            "}",
            "void __sched _rt_mutex_lock_nest_lock(struct rt_mutex *lock, struct lockdep_map *nest_lock)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, nest_lock, 0);",
            "}",
            "void __sched rt_mutex_lock(struct rt_mutex *lock)",
            "{",
            "\t__rt_mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_lock_interruptible(struct rt_mutex *lock)",
            "{",
            "\treturn __rt_mutex_lock_common(lock, TASK_INTERRUPTIBLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_lock_killable(struct rt_mutex *lock)",
            "{",
            "\treturn __rt_mutex_lock_common(lock, TASK_KILLABLE, NULL, 0);",
            "}",
            "int __sched rt_mutex_trylock(struct rt_mutex *lock)",
            "{",
            "\tint ret;",
            "",
            "\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES) && WARN_ON_ONCE(!in_task()))",
            "\t\treturn 0;",
            "",
            "\tret = __rt_mutex_trylock(&lock->rtmutex);",
            "\tif (ret)",
            "\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);",
            "",
            "\treturn ret;",
            "}",
            "void __sched rt_mutex_unlock(struct rt_mutex *lock)",
            "{",
            "\tmutex_release(&lock->dep_map, _RET_IP_);",
            "\t__rt_mutex_unlock(&lock->rtmutex);",
            "}",
            "int __sched rt_mutex_futex_trylock(struct rt_mutex_base *lock)",
            "{",
            "\treturn rt_mutex_slowtrylock(lock);",
            "}",
            "int __sched __rt_mutex_futex_trylock(struct rt_mutex_base *lock)",
            "{",
            "\treturn __rt_mutex_slowtrylock(lock);",
            "}",
            "bool __sched __rt_mutex_futex_unlock(struct rt_mutex_base *lock,",
            "\t\t\t\t     struct rt_wake_q_head *wqh)",
            "{",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tdebug_rt_mutex_unlock(lock);",
            "",
            "\tif (!rt_mutex_has_waiters(lock)) {",
            "\t\tlock->owner = NULL;",
            "\t\treturn false; /* done */",
            "\t}",
            "",
            "\t/*",
            "\t * We've already deboosted, mark_wakeup_next_waiter() will",
            "\t * retain preempt_disabled when we drop the wait_lock, to",
            "\t * avoid inversion prior to the wakeup.  preempt_disable()",
            "\t * therein pairs with rt_mutex_postunlock().",
            "\t */",
            "\tmark_wakeup_next_waiter(wqh, lock);",
            "",
            "\treturn true; /* call postunlock() */",
            "}",
            "void __sched rt_mutex_futex_unlock(struct rt_mutex_base *lock)",
            "{",
            "\tDEFINE_RT_WAKE_Q(wqh);",
            "\tunsigned long flags;",
            "\tbool postunlock;",
            "",
            "\traw_spin_lock_irqsave(&lock->wait_lock, flags);",
            "\tpostunlock = __rt_mutex_futex_unlock(lock, &wqh);",
            "\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);",
            "",
            "\tif (postunlock)",
            "\t\trt_mutex_postunlock(&wqh);",
            "}",
            "void __sched __rt_mutex_init(struct rt_mutex *lock, const char *name,",
            "\t\t\t     struct lock_class_key *key)",
            "{",
            "\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));",
            "\t__rt_mutex_base_init(&lock->rtmutex);",
            "\tlockdep_init_map_wait(&lock->dep_map, name, key, 0, LD_WAIT_SLEEP);",
            "}"
          ],
          "function_name": "__rt_mutex_lock_common, rt_mutex_base_init, rt_mutex_lock_nested, _rt_mutex_lock_nest_lock, rt_mutex_lock, rt_mutex_lock_interruptible, rt_mutex_lock_killable, rt_mutex_trylock, rt_mutex_unlock, rt_mutex_futex_trylock, __rt_mutex_futex_trylock, __rt_mutex_futex_unlock, rt_mutex_futex_unlock, __rt_mutex_init",
          "description": "实现多种rtmutex操作接口，包括常规加锁、尝试加锁、解锁及嵌套锁管理，通过统一入口函数处理不同睡眠状态和锁依赖追踪，维护锁状态转换和抢占控制。",
          "similarity": 0.5350204706192017
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/locking/rtmutex_api.c",
          "start_line": 236,
          "end_line": 354,
          "content": [
            "void __sched rt_mutex_init_proxy_locked(struct rt_mutex_base *lock,",
            "\t\t\t\t\tstruct task_struct *proxy_owner)",
            "{",
            "\tstatic struct lock_class_key pi_futex_key;",
            "",
            "\t__rt_mutex_base_init(lock);",
            "\t/*",
            "\t * On PREEMPT_RT the futex hashbucket spinlock becomes 'sleeping'",
            "\t * and rtmutex based. That causes a lockdep false positive, because",
            "\t * some of the futex functions invoke spin_unlock(&hb->lock) with",
            "\t * the wait_lock of the rtmutex associated to the pi_futex held.",
            "\t * spin_unlock() in turn takes wait_lock of the rtmutex on which",
            "\t * the spinlock is based, which makes lockdep notice a lock",
            "\t * recursion. Give the futex/rtmutex wait_lock a separate key.",
            "\t */",
            "\tlockdep_set_class(&lock->wait_lock, &pi_futex_key);",
            "\trt_mutex_set_owner(lock, proxy_owner);",
            "}",
            "void __sched rt_mutex_proxy_unlock(struct rt_mutex_base *lock)",
            "{",
            "\tdebug_rt_mutex_proxy_unlock(lock);",
            "\trt_mutex_clear_owner(lock);",
            "}",
            "int __sched __rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t\tstruct rt_mutex_waiter *waiter,",
            "\t\t\t\t\tstruct task_struct *task)",
            "{",
            "\tint ret;",
            "",
            "\tlockdep_assert_held(&lock->wait_lock);",
            "",
            "\tif (try_to_take_rt_mutex(lock, task, NULL))",
            "\t\treturn 1;",
            "",
            "\t/* We enforce deadlock detection for futexes */",
            "\tret = task_blocks_on_rt_mutex(lock, waiter, task, NULL,",
            "\t\t\t\t      RT_MUTEX_FULL_CHAINWALK);",
            "",
            "\tif (ret && !rt_mutex_owner(lock)) {",
            "\t\t/*",
            "\t\t * Reset the return value. We might have",
            "\t\t * returned with -EDEADLK and the owner",
            "\t\t * released the lock while we were walking the",
            "\t\t * pi chain.  Let the waiter sort it out.",
            "\t\t */",
            "\t\tret = 0;",
            "\t}",
            "",
            "\treturn ret;",
            "}",
            "int __sched rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t      struct rt_mutex_waiter *waiter,",
            "\t\t\t\t      struct task_struct *task)",
            "{",
            "\tint ret;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\tret = __rt_mutex_start_proxy_lock(lock, waiter, task);",
            "\tif (unlikely(ret))",
            "\t\tremove_waiter(lock, waiter);",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn ret;",
            "}",
            "int __sched rt_mutex_wait_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t     struct hrtimer_sleeper *to,",
            "\t\t\t\t     struct rt_mutex_waiter *waiter)",
            "{",
            "\tint ret;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\t/* sleep on the mutex */",
            "\tset_current_state(TASK_INTERRUPTIBLE);",
            "\tret = rt_mutex_slowlock_block(lock, NULL, TASK_INTERRUPTIBLE, to, waiter);",
            "\t/*",
            "\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might",
            "\t * have to fix that up.",
            "\t */",
            "\tfixup_rt_mutex_waiters(lock, true);",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn ret;",
            "}",
            "bool __sched rt_mutex_cleanup_proxy_lock(struct rt_mutex_base *lock,",
            "\t\t\t\t\t struct rt_mutex_waiter *waiter)",
            "{",
            "\tbool cleanup = false;",
            "",
            "\traw_spin_lock_irq(&lock->wait_lock);",
            "\t/*",
            "\t * Do an unconditional try-lock, this deals with the lock stealing",
            "\t * state where __rt_mutex_futex_unlock() -> mark_wakeup_next_waiter()",
            "\t * sets a NULL owner.",
            "\t *",
            "\t * We're not interested in the return value, because the subsequent",
            "\t * test on rt_mutex_owner() will infer that. If the trylock succeeded,",
            "\t * we will own the lock and it will have removed the waiter. If we",
            "\t * failed the trylock, we're still not owner and we need to remove",
            "\t * ourselves.",
            "\t */",
            "\ttry_to_take_rt_mutex(lock, current, waiter);",
            "\t/*",
            "\t * Unless we're the owner; we're still enqueued on the wait_list.",
            "\t * So check if we became owner, if not, take us off the wait_list.",
            "\t */",
            "\tif (rt_mutex_owner(lock) != current) {",
            "\t\tremove_waiter(lock, waiter);",
            "\t\tcleanup = true;",
            "\t}",
            "\t/*",
            "\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might",
            "\t * have to fix that up.",
            "\t */",
            "\tfixup_rt_mutex_waiters(lock, false);",
            "",
            "\traw_spin_unlock_irq(&lock->wait_lock);",
            "",
            "\treturn cleanup;",
            "}"
          ],
          "function_name": "rt_mutex_init_proxy_locked, rt_mutex_proxy_unlock, __rt_mutex_start_proxy_lock, rt_mutex_start_proxy_lock, rt_mutex_wait_proxy_lock, rt_mutex_cleanup_proxy_lock",
          "description": "处理锁代理机制，包含代理锁初始化、释放逻辑及死锁检测流程，通过遍历锁链进行优先级继承调整，确保多线程环境下的锁所有权安全转移。",
          "similarity": 0.49613043665885925
        }
      ]
    }
  ]
}