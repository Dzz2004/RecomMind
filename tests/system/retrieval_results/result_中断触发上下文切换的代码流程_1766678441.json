{
  "query": "中断触发上下文切换的代码流程",
  "timestamp": "2025-12-26 00:00:41",
  "retrieved_files": [
    {
      "source_file": "kernel/irq_work.c",
      "md_summary": "> 自动生成时间: 2025-10-25 14:11:23\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq_work.c`\n\n---\n\n# `irq_work.c` 技术文档\n\n## 1. 文件概述\n\n`irq_work.c` 实现了一个轻量级的中断上下文工作队列机制，允许在硬中断（hardirq）或 NMI（不可屏蔽中断）上下文中安全地调度回调函数，并在稍后的硬中断上下文或专用内核线程中执行。该机制的核心目标是提供一种 **NMI 安全** 的方式来延迟执行某些不能在 NMI 或硬中断中直接完成的操作。\n\n该框架特别适用于需要从 NMI 或硬中断中触发后续处理（如 perf 事件、ftrace、RCU 等子系统）但又不能阻塞或执行复杂逻辑的场景。\n\n## 2. 核心功能\n\n### 主要数据结构\n\n- `struct irq_work`：表示一个中断工作项，包含回调函数 `func` 和状态标志（如 `IRQ_WORK_PENDING`、`IRQ_WORK_CLAIMED`、`IRQ_WORK_BUSY`、`IRQ_WORK_LAZY`、`IRQ_WORK_HARD_IRQ`）。\n- 每 CPU 变量：\n  - `raised_list`：存放需在硬中断上下文中立即处理的工作项。\n  - `lazy_list`：存放“惰性”工作项，在非硬中断上下文（如 tick 或专用线程）中处理。\n  - `irq_workd`：指向每 CPU 的 `irq_work` 内核线程（仅在 `CONFIG_PREEMPT_RT` 下使用）。\n\n### 主要函数\n\n| 函数 | 功能 |\n|------|------|\n| `irq_work_queue(struct irq_work *work)` | 在当前 CPU 上排队一个 `irq_work`，若未被声明则声明并入队。 |\n| `irq_work_queue_on(struct irq_work *work, int cpu)` | 将 `irq_work` 排队到指定 CPU（支持跨 CPU 调度）。 |\n| `irq_work_run(void)` | 在当前 CPU 上执行所有 `raised_list` 和（非 RT 下的）`lazy_list` 中的工作项。 |\n| `irq_work_tick(void)` | 由时钟 tick 调用，处理未被硬中断处理的 `raised_list` 和 `lazy_list`。 |\n| `irq_work_sync(struct irq_work *work)` | 同步等待指定 `irq_work` 执行完毕。 |\n| `irq_work_single(void *arg)` | 执行单个工作项的回调函数，并清理状态。 |\n| `arch_irq_work_raise(void)` | 架构相关函数，用于触发 IPI 或中断以唤醒处理逻辑（弱符号，默认为空）。 |\n\n## 3. 关键实现\n\n### 状态管理与原子操作\n\n- 每个 `irq_work` 通过 `atomic_t node.a_flags` 管理状态：\n  - `IRQ_WORK_PENDING`：表示工作项已入队但尚未执行。\n  - `IRQ_WORK_CLAIMED`：表示已被声明，防止重复入队。\n  - `IRQ_WORK_BUSY`：表示正在执行中。\n- `irq_work_claim()` 使用 `atomic_fetch_or()` 原子地设置 `CLAIMED` 和 `PENDING` 标志，并检查是否已存在，避免重复入队。\n\n### 双队列设计\n\n- **`raised_list`**：用于需要尽快在硬中断上下文执行的工作（如标记为 `IRQ_WORK_HARD_IRQ` 的项）。\n- **`lazy_list`**：\n  - 在非 RT 内核中，由 `irq_work_tick()` 或 `irq_work_run()` 在软中断或进程上下文中处理。\n  - 在 `CONFIG_PREEMPT_RT` 下，由每 CPU 的 `irq_work/%u` 内核线程处理（以避免在硬中断中执行非硬实时代码）。\n\n### NMI 安全性\n\n- 入队操作（如 `irq_work_queue`）仅使用原子操作和每 CPU 链表（`llist`），不涉及锁或内存分配，因此可在 NMI 上下文中安全调用。\n- 跨 CPU 入队时（`irq_work_queue_on`）会检查 `in_nmi()`，防止在 NMI 中调用非 NMI 安全的 IPI 发送函数。\n\n### PREEMPT_RT 支持\n\n- 在 RT 内核中，非 `IRQ_WORK_HARD_IRQ` 的工作项被放入 `lazy_list`，并通过专用内核线程执行，以避免在硬中断中运行可能阻塞或延迟高的代码。\n- 使用 `rcuwait` 机制实现 `irq_work_sync()` 的睡眠等待。\n\n### IPI 触发机制\n\n- 若架构支持（通过 `arch_irq_work_has_interrupt()`），调用 `arch_irq_work_raise()` 触发本地中断处理。\n- 否则依赖时钟 tick（`irq_work_tick`）或显式调用 `irq_work_run` 来处理队列。\n\n## 4. 依赖关系\n\n- **架构依赖**：\n  - `arch_irq_work_raise()` 和 `arch_irq_work_has_interrupt()` 需由具体架构实现（如 x86 提供）。\n- **内核子系统**：\n  - `llist`（无锁链表）：用于高效、无锁的每 CPU 队列管理。\n  - `smpboot`：用于注册每 CPU 内核线程（RT 模式）。\n  - `rcu`：`rcuwait` 用于同步等待（RT 模式）。\n  - `tick`：`tick_nohz_tick_stopped()` 用于判断是否需要立即触发处理。\n  - `trace_events`：IPI 跟踪点 `trace_ipi_send_cpu`。\n- **配置选项**：\n  - `CONFIG_SMP`：启用跨 CPU 调度和 IPI 支持。\n  - `CONFIG_PREEMPT_RT`：启用 RT 模式下的线程化处理。\n\n## 5. 使用场景\n\n- **性能监控（perf）**：从 NMI 中记录采样后，通过 `irq_work` 安全地将数据传递到常规上下文处理。\n- **ftrace / tracing**：在中断上下文中触发延迟的跟踪事件处理。\n- **RCU**：某些 RCU 实现使用 `irq_work` 来触发宽限期处理。\n- **热插拔 CPU**：在 CPU 离线前通过 `flush_smp_call_function_queue()` 调用 `irq_work_run()` 确保工作项被清空。\n- **中断负载均衡或延迟处理**：将非关键中断处理逻辑延迟到更安全的上下文执行。\n\n该机制为内核提供了一种高效、安全且可扩展的中断后处理框架，尤其适用于实时性和可靠性要求高的子系统。",
      "similarity": 0.652034342288971,
      "chunks": [
        {
          "chunk_id": 2,
          "file_path": "kernel/irq_work.c",
          "start_line": 184,
          "end_line": 286,
          "content": [
            "bool irq_work_needs_cpu(void)",
            "{",
            "\tstruct llist_head *raised, *lazy;",
            "",
            "\traised = this_cpu_ptr(&raised_list);",
            "\tlazy = this_cpu_ptr(&lazy_list);",
            "",
            "\tif (llist_empty(raised) || arch_irq_work_has_interrupt())",
            "\t\tif (llist_empty(lazy))",
            "\t\t\treturn false;",
            "",
            "\t/* All work should have been flushed before going offline */",
            "\tWARN_ON_ONCE(cpu_is_offline(smp_processor_id()));",
            "",
            "\treturn true;",
            "}",
            "void irq_work_single(void *arg)",
            "{",
            "\tstruct irq_work *work = arg;",
            "\tint flags;",
            "",
            "\t/*",
            "\t * Clear the PENDING bit, after this point the @work can be re-used.",
            "\t * The PENDING bit acts as a lock, and we own it, so we can clear it",
            "\t * without atomic ops.",
            "\t */",
            "\tflags = atomic_read(&work->node.a_flags);",
            "\tflags &= ~IRQ_WORK_PENDING;",
            "\tatomic_set(&work->node.a_flags, flags);",
            "",
            "\t/*",
            "\t * See irq_work_claim().",
            "\t */",
            "\tsmp_mb();",
            "",
            "\tlockdep_irq_work_enter(flags);",
            "\twork->func(work);",
            "\tlockdep_irq_work_exit(flags);",
            "",
            "\t/*",
            "\t * Clear the BUSY bit, if set, and return to the free state if no-one",
            "\t * else claimed it meanwhile.",
            "\t */",
            "\t(void)atomic_cmpxchg(&work->node.a_flags, flags, flags & ~IRQ_WORK_BUSY);",
            "",
            "\tif ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||",
            "\t    !arch_irq_work_has_interrupt())",
            "\t\trcuwait_wake_up(&work->irqwait);",
            "}",
            "static void irq_work_run_list(struct llist_head *list)",
            "{",
            "\tstruct irq_work *work, *tmp;",
            "\tstruct llist_node *llnode;",
            "",
            "\t/*",
            "\t * On PREEMPT_RT IRQ-work which is not marked as HARD will be processed",
            "\t * in a per-CPU thread in preemptible context. Only the items which are",
            "\t * marked as IRQ_WORK_HARD_IRQ will be processed in hardirq context.",
            "\t */",
            "\tBUG_ON(!irqs_disabled() && !IS_ENABLED(CONFIG_PREEMPT_RT));",
            "",
            "\tif (llist_empty(list))",
            "\t\treturn;",
            "",
            "\tllnode = llist_del_all(list);",
            "\tllist_for_each_entry_safe(work, tmp, llnode, node.llist)",
            "\t\tirq_work_single(work);",
            "}",
            "void irq_work_run(void)",
            "{",
            "\tirq_work_run_list(this_cpu_ptr(&raised_list));",
            "\tif (!IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\tirq_work_run_list(this_cpu_ptr(&lazy_list));",
            "\telse",
            "\t\twake_irq_workd();",
            "}",
            "void irq_work_tick(void)",
            "{",
            "\tstruct llist_head *raised = this_cpu_ptr(&raised_list);",
            "",
            "\tif (!llist_empty(raised) && !arch_irq_work_has_interrupt())",
            "\t\tirq_work_run_list(raised);",
            "",
            "\tif (!IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\tirq_work_run_list(this_cpu_ptr(&lazy_list));",
            "\telse",
            "\t\twake_irq_workd();",
            "}",
            "void irq_work_sync(struct irq_work *work)",
            "{",
            "\tlockdep_assert_irqs_enabled();",
            "\tmight_sleep();",
            "",
            "\tif ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||",
            "\t    !arch_irq_work_has_interrupt()) {",
            "\t\trcuwait_wait_event(&work->irqwait, !irq_work_is_busy(work),",
            "\t\t\t\t   TASK_UNINTERRUPTIBLE);",
            "\t\treturn;",
            "\t}",
            "",
            "\twhile (irq_work_is_busy(work))",
            "\t\tcpu_relax();",
            "}"
          ],
          "function_name": "irq_work_needs_cpu, irq_work_single, irq_work_run_list, irq_work_run, irq_work_tick, irq_work_sync",
          "description": "处理工作项的实际执行流程，包含单次执行逻辑、链表遍历运行及同步等待机制，区分硬中断上下文与RCU等待状态的处理",
          "similarity": 0.6114106774330139
        },
        {
          "chunk_id": 1,
          "file_path": "kernel/irq_work.c",
          "start_line": 31,
          "end_line": 157,
          "content": [
            "static void wake_irq_workd(void)",
            "{",
            "\tstruct task_struct *tsk = __this_cpu_read(irq_workd);",
            "",
            "\tif (!llist_empty(this_cpu_ptr(&lazy_list)) && tsk)",
            "\t\twake_up_process(tsk);",
            "}",
            "static void irq_work_wake(struct irq_work *entry)",
            "{",
            "\twake_irq_workd();",
            "}",
            "static int irq_workd_should_run(unsigned int cpu)",
            "{",
            "\treturn !llist_empty(this_cpu_ptr(&lazy_list));",
            "}",
            "static bool irq_work_claim(struct irq_work *work)",
            "{",
            "\tint oflags;",
            "",
            "\toflags = atomic_fetch_or(IRQ_WORK_CLAIMED | CSD_TYPE_IRQ_WORK, &work->node.a_flags);",
            "\t/*",
            "\t * If the work is already pending, no need to raise the IPI.",
            "\t * The pairing smp_mb() in irq_work_single() makes sure",
            "\t * everything we did before is visible.",
            "\t */",
            "\tif (oflags & IRQ_WORK_PENDING)",
            "\t\treturn false;",
            "\treturn true;",
            "}",
            "void __weak arch_irq_work_raise(void)",
            "{",
            "\t/*",
            "\t * Lame architectures will get the timer tick callback",
            "\t */",
            "}",
            "static __always_inline void irq_work_raise(struct irq_work *work)",
            "{",
            "\tif (trace_ipi_send_cpu_enabled() && arch_irq_work_has_interrupt())",
            "\t\ttrace_ipi_send_cpu(smp_processor_id(), _RET_IP_, work->func);",
            "",
            "\tarch_irq_work_raise();",
            "}",
            "static void __irq_work_queue_local(struct irq_work *work)",
            "{",
            "\tstruct llist_head *list;",
            "\tbool rt_lazy_work = false;",
            "\tbool lazy_work = false;",
            "\tint work_flags;",
            "",
            "\twork_flags = atomic_read(&work->node.a_flags);",
            "\tif (work_flags & IRQ_WORK_LAZY)",
            "\t\tlazy_work = true;",
            "\telse if (IS_ENABLED(CONFIG_PREEMPT_RT) &&",
            "\t\t !(work_flags & IRQ_WORK_HARD_IRQ))",
            "\t\trt_lazy_work = true;",
            "",
            "\tif (lazy_work || rt_lazy_work)",
            "\t\tlist = this_cpu_ptr(&lazy_list);",
            "\telse",
            "\t\tlist = this_cpu_ptr(&raised_list);",
            "",
            "\tif (!llist_add(&work->node.llist, list))",
            "\t\treturn;",
            "",
            "\t/* If the work is \"lazy\", handle it from next tick if any */",
            "\tif (!lazy_work || tick_nohz_tick_stopped())",
            "\t\tirq_work_raise(work);",
            "}",
            "bool irq_work_queue(struct irq_work *work)",
            "{",
            "\t/* Only queue if not already pending */",
            "\tif (!irq_work_claim(work))",
            "\t\treturn false;",
            "",
            "\t/* Queue the entry and raise the IPI if needed. */",
            "\tpreempt_disable();",
            "\t__irq_work_queue_local(work);",
            "\tpreempt_enable();",
            "",
            "\treturn true;",
            "}",
            "bool irq_work_queue_on(struct irq_work *work, int cpu)",
            "{",
            "#ifndef CONFIG_SMP",
            "\treturn irq_work_queue(work);",
            "",
            "#else /* CONFIG_SMP: */",
            "\t/* All work should have been flushed before going offline */",
            "\tWARN_ON_ONCE(cpu_is_offline(cpu));",
            "",
            "\t/* Only queue if not already pending */",
            "\tif (!irq_work_claim(work))",
            "\t\treturn false;",
            "",
            "\tkasan_record_aux_stack_noalloc(work);",
            "",
            "\tpreempt_disable();",
            "\tif (cpu != smp_processor_id()) {",
            "\t\t/* Arch remote IPI send/receive backend aren't NMI safe */",
            "\t\tWARN_ON_ONCE(in_nmi());",
            "",
            "\t\t/*",
            "\t\t * On PREEMPT_RT the items which are not marked as",
            "\t\t * IRQ_WORK_HARD_IRQ are added to the lazy list and a HARD work",
            "\t\t * item is used on the remote CPU to wake the thread.",
            "\t\t */",
            "\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) &&",
            "\t\t    !(atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ)) {",
            "",
            "\t\t\tif (!llist_add(&work->node.llist, &per_cpu(lazy_list, cpu)))",
            "\t\t\t\tgoto out;",
            "",
            "\t\t\twork = &per_cpu(irq_work_wakeup, cpu);",
            "\t\t\tif (!irq_work_claim(work))",
            "\t\t\t\tgoto out;",
            "\t\t}",
            "",
            "\t\t__smp_call_single_queue(cpu, &work->node.llist);",
            "\t} else {",
            "\t\t__irq_work_queue_local(work);",
            "\t}",
            "out:",
            "\tpreempt_enable();",
            "",
            "\treturn true;",
            "#endif /* CONFIG_SMP */",
            "}"
          ],
          "function_name": "wake_irq_workd, irq_work_wake, irq_workd_should_run, irq_work_claim, arch_irq_work_raise, irq_work_raise, __irq_work_queue_local, irq_work_queue, irq_work_queue_on",
          "description": "实现了中断工作项的排队逻辑，区分硬中断与延迟工作项，通过IPI或线程唤醒机制确保跨CPU执行，支持PREEMPT_RT配置下的延迟处理",
          "similarity": 0.5639921426773071
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq_work.c",
          "start_line": 1,
          "end_line": 30,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0-only",
            "/*",
            " * Copyright (C) 2010 Red Hat, Inc., Peter Zijlstra",
            " *",
            " * Provides a framework for enqueueing and running callbacks from hardirq",
            " * context. The enqueueing is NMI-safe.",
            " */",
            "",
            "#include <linux/bug.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/percpu.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/sched.h>",
            "#include <linux/tick.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/smp.h>",
            "#include <linux/smpboot.h>",
            "#include <asm/processor.h>",
            "#include <linux/kasan.h>",
            "",
            "#include <trace/events/ipi.h>",
            "",
            "static DEFINE_PER_CPU(struct llist_head, raised_list);",
            "static DEFINE_PER_CPU(struct llist_head, lazy_list);",
            "static DEFINE_PER_CPU(struct task_struct *, irq_workd);",
            ""
          ],
          "function_name": null,
          "description": "定义了用于管理中断工作队列的per-CPU链表（raised_list/lazy_list）和irq_workd线程指针，提供NMI安全的enqueue框架",
          "similarity": 0.5331760048866272
        },
        {
          "chunk_id": 3,
          "file_path": "kernel/irq_work.c",
          "start_line": 303,
          "end_line": 316,
          "content": [
            "static void run_irq_workd(unsigned int cpu)",
            "{",
            "\tirq_work_run_list(this_cpu_ptr(&lazy_list));",
            "}",
            "static void irq_workd_setup(unsigned int cpu)",
            "{",
            "\tsched_set_fifo_low(current);",
            "}",
            "static __init int irq_work_init_threads(void)",
            "{",
            "\tif (IS_ENABLED(CONFIG_PREEMPT_RT))",
            "\t\tBUG_ON(smpboot_register_percpu_thread(&irqwork_threads));",
            "\treturn 0;",
            "}"
          ],
          "function_name": "run_irq_workd, irq_workd_setup, irq_work_init_threads",
          "description": "初始化PREEMPT_RT环境下的per-CPU工作线程，注册并启动处理延迟工作项的专用线程，通过smpboot接口创建线程实体",
          "similarity": 0.525126039981842
        }
      ]
    },
    {
      "source_file": "kernel/irq/handle.c",
      "md_summary": "> 自动生成时间: 2025-10-25 13:55:29\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `irq\\handle.c`\n\n---\n\n# `irq/handle.c` 技术文档\n\n## 1. 文件概述\n\n`irq/handle.c` 是 Linux 内核通用中断子系统（Generic IRQ）的核心实现文件之一，负责中断事件的高层处理逻辑。该文件实现了中断处理流程中的关键函数，包括中断动作（`irqaction`）的调用、线程化中断的唤醒机制、未处理或异常中断的处理，以及架构无关的中断入口封装。其目标是为不同硬件架构提供统一、可扩展的中断处理框架。\n\n## 2. 核心功能\n\n### 主要函数\n\n- **`handle_bad_irq(struct irq_desc *desc)`**  \n  处理伪中断（spurious IRQ）或未注册处理函数的中断，记录统计信息并调用架构相关的 `ack_bad_irq()`。\n\n- **`no_action(int cpl, void *dev_id)`**  \n  空中断处理函数，返回 `IRQ_NONE`，常用于占位或测试。\n\n- **`__irq_wake_thread(struct irq_desc *desc, struct irqaction *action)`**  \n  唤醒与中断动作关联的内核线程（用于线程化中断），管理 `threads_oneshot` 和 `threads_active` 状态。\n\n- **`__handle_irq_event_percpu(struct irq_desc *desc)`**  \n  在当前 CPU 上遍历并执行该中断描述符关联的所有 `irqaction` 处理函数，支持 `IRQ_WAKE_THREAD` 返回值以触发线程化处理。\n\n- **`handle_irq_event_percpu(struct irq_desc *desc)`**  \n  对 `__handle_irq_event_percpu` 的封装，附加中断随机数注入（`add_interrupt_randomness`）和调试记录（`note_interrupt`）。\n\n- **`handle_irq_event(struct irq_desc *desc)`**  \n  中断事件处理的顶层入口，负责清除 `IRQS_PENDING` 状态、设置 `IRQD_IRQ_INPROGRESS` 标志，并在释放 `desc->lock` 后调用 per-CPU 处理函数，最后恢复锁和状态。\n\n- **`generic_handle_arch_irq(struct pt_regs *regs)`**（仅当 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 启用）  \n  架构无关的通用中断入口点，封装 `irq_enter()`/`irq_exit()` 和寄存器上下文切换。\n\n- **`set_handle_irq(void (*handle_irq)(struct pt_regs *))`**（仅当 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 启用）  \n  初始化架构特定的底层中断处理函数指针 `handle_arch_irq`。\n\n### 关键数据结构（引用）\n\n- `struct irq_desc`：中断描述符，包含中断状态、动作链表、锁等。\n- `struct irqaction`：中断动作，包含处理函数 `handler`、线程函数 `thread_fn`、设备 ID、标志等。\n- `handle_arch_irq`：函数指针，指向架构特定的底层中断分发函数（仅在 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 下定义）。\n\n## 3. 关键实现\n\n### 线程化中断唤醒机制\n\n当硬中断处理函数返回 `IRQ_WAKE_THREAD` 时，内核需唤醒对应的线程处理下半部。`__irq_wake_thread` 实现了以下关键逻辑：\n\n- 检查线程是否已退出（`PF_EXITING`），若是则忽略。\n- 使用原子位操作 `test_and_set_bit(IRQTF_RUNTHREAD, ...)` 避免重复唤醒。\n- 通过 `desc->threads_oneshot |= action->thread_mask` 标记需运行的线程。\n- 原子递增 `desc->threads_active`，供 `synchronize_irq()` 等同步原语使用。\n- 调用 `wake_up_process()` 唤醒内核线程。\n\n该机制通过 `IRQS_INPROGRESS` 状态和 `desc->lock` 实现硬中断上下文与中断线程之间的同步，确保 `threads_oneshot` 的读写安全。\n\n### 中断处理流程控制\n\n`handle_irq_event` 是中断流控的关键：\n\n1. 清除 `IRQS_PENDING`（表示中断已开始处理）。\n2. 设置 `IRQD_IRQ_INPROGRESS`（防止嵌套处理）。\n3. 释放 `desc->lock`，允许中断线程或其他 CPU 并发访问。\n4. 调用 `handle_irq_event_percpu` 执行实际处理。\n5. 重新获取锁，清除 `IRQD_IRQ_INPROGRESS`。\n\n此设计解耦了中断流控（如电平触发中断的 EOI）与具体处理逻辑，提高并发性。\n\n### 架构无关中断入口（`CONFIG_GENERIC_IRQ_MULTI_HANDLER`）\n\n该配置允许架构代码注册一个统一的中断入口函数 `handle_arch_irq`。`generic_handle_arch_irq` 作为通用包装器：\n\n- 调用 `irq_enter()` 进入中断上下文。\n- 使用 `set_irq_regs()` 切换当前 CPU 的中断寄存器上下文。\n- 调用注册的 `handle_arch_irq` 进行实际分发。\n- 恢复寄存器上下文并调用 `irq_exit()`。\n\n适用于不自行管理中断入口计数和上下文的架构（如 ARM64）。\n\n### 安全与调试\n\n- **中断使能检查**：在调用 `action->handler` 后，检查中断是否被意外使能（`WARN_ONCE(!irqs_disabled(), ...)`），若发现则强制禁用。\n- **伪中断处理**：`handle_bad_irq` 提供统一的异常中断处理路径，便于调试和统计。\n- **随机数注入**：通过 `add_interrupt_randomness()` 利用中断时间戳增强内核熵池。\n\n## 4. 依赖关系\n\n- **头文件依赖**：\n  - `<linux/irq.h>`、`<linux/interrupt.h>`：中断核心 API 和数据结构。\n  - `<linux/kernel_stat.h>`：中断统计（`kstat_incr_irqs_this_cpu`）。\n  - `<linux/random.h>`：中断随机数注入。\n  - `<asm/irq_regs.h>`：架构相关的中断寄存器上下文管理。\n  - `\"internals.h\"`：中断子系统内部实现细节。\n  - `<trace/events/irq.h>`：中断事件跟踪点。\n\n- **模块依赖**：\n  - **Generic IRQ 子系统**：依赖 `irqdesc.c`、`irqchip.c` 等提供的 `irq_desc` 管理。\n  - **调度器**：`wake_up_process()` 依赖进程调度。\n  - **RCU 与同步原语**：`synchronize_irq()` 依赖 `threads_active` 计数。\n  - **架构代码**：`ack_bad_irq()`、`handle_arch_irq` 由具体架构实现。\n\n## 5. 使用场景\n\n- **设备驱动注册中断处理函数**：驱动通过 `request_irq()` 注册 `irqaction`，中断触发时由 `handle_irq_event_percpu` 调用其 `handler`。\n- **线程化中断处理**：驱动设置 `IRQF_ONESHOT` 并提供 `thread_fn`，硬中断返回 `IRQ_WAKE_THREAD` 后由 `__irq_wake_thread` 唤醒线程。\n- **伪中断或未处理中断**：硬件误触发或未注册处理函数的中断由 `handle_bad_irq` 统一处理。\n- **架构中断入口**：在 `CONFIG_GENERIC_IRQ_MULTI_HANDLER` 架构（如 ARM64）中，异常向量表直接跳转至 `generic_handle_arch_irq`。\n- **中断同步**：`synchronize_irq()` 等函数依赖 `threads_active` 计数等待线程化中断完成。\n- **内核调试与监控**：通过 `note_interrupt()` 记录异常中断，通过 ftrace 的 `irq_handler_entry/exit` 跟踪点监控中断处理性能。",
      "similarity": 0.6338480114936829,
      "chunks": [
        {
          "chunk_id": 1,
          "file_path": "kernel/irq/handle.c",
          "start_line": 33,
          "end_line": 178,
          "content": [
            "void handle_bad_irq(struct irq_desc *desc)",
            "{",
            "\tunsigned int irq = irq_desc_get_irq(desc);",
            "",
            "\tprint_irq_desc(irq, desc);",
            "\tkstat_incr_irqs_this_cpu(desc);",
            "\tack_bad_irq(irq);",
            "}",
            "irqreturn_t no_action(int cpl, void *dev_id)",
            "{",
            "\treturn IRQ_NONE;",
            "}",
            "static void warn_no_thread(unsigned int irq, struct irqaction *action)",
            "{",
            "\tif (test_and_set_bit(IRQTF_WARNED, &action->thread_flags))",
            "\t\treturn;",
            "",
            "\tprintk(KERN_WARNING \"IRQ %d device %s returned IRQ_WAKE_THREAD \"",
            "\t       \"but no thread function available.\", irq, action->name);",
            "}",
            "void __irq_wake_thread(struct irq_desc *desc, struct irqaction *action)",
            "{",
            "\t/*",
            "\t * In case the thread crashed and was killed we just pretend that",
            "\t * we handled the interrupt. The hardirq handler has disabled the",
            "\t * device interrupt, so no irq storm is lurking.",
            "\t */",
            "\tif (action->thread->flags & PF_EXITING)",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * Wake up the handler thread for this action. If the",
            "\t * RUNTHREAD bit is already set, nothing to do.",
            "\t */",
            "\tif (test_and_set_bit(IRQTF_RUNTHREAD, &action->thread_flags))",
            "\t\treturn;",
            "",
            "\t/*",
            "\t * It's safe to OR the mask lockless here. We have only two",
            "\t * places which write to threads_oneshot: This code and the",
            "\t * irq thread.",
            "\t *",
            "\t * This code is the hard irq context and can never run on two",
            "\t * cpus in parallel. If it ever does we have more serious",
            "\t * problems than this bitmask.",
            "\t *",
            "\t * The irq threads of this irq which clear their \"running\" bit",
            "\t * in threads_oneshot are serialized via desc->lock against",
            "\t * each other and they are serialized against this code by",
            "\t * IRQS_INPROGRESS.",
            "\t *",
            "\t * Hard irq handler:",
            "\t *",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tdesc->state |= IRQS_INPROGRESS;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *\tset_bit(IRQTF_RUNTHREAD, &action->thread_flags);",
            "\t *\tdesc->threads_oneshot |= mask;",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tdesc->state &= ~IRQS_INPROGRESS;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *",
            "\t * irq thread:",
            "\t *",
            "\t * again:",
            "\t *\tspin_lock(desc->lock);",
            "\t *\tif (desc->state & IRQS_INPROGRESS) {",
            "\t *\t\tspin_unlock(desc->lock);",
            "\t *\t\twhile(desc->state & IRQS_INPROGRESS)",
            "\t *\t\t\tcpu_relax();",
            "\t *\t\tgoto again;",
            "\t *\t}",
            "\t *\tif (!test_bit(IRQTF_RUNTHREAD, &action->thread_flags))",
            "\t *\t\tdesc->threads_oneshot &= ~mask;",
            "\t *\tspin_unlock(desc->lock);",
            "\t *",
            "\t * So either the thread waits for us to clear IRQS_INPROGRESS",
            "\t * or we are waiting in the flow handler for desc->lock to be",
            "\t * released before we reach this point. The thread also checks",
            "\t * IRQTF_RUNTHREAD under desc->lock. If set it leaves",
            "\t * threads_oneshot untouched and runs the thread another time.",
            "\t */",
            "\tdesc->threads_oneshot |= action->thread_mask;",
            "",
            "\t/*",
            "\t * We increment the threads_active counter in case we wake up",
            "\t * the irq thread. The irq thread decrements the counter when",
            "\t * it returns from the handler or in the exit path and wakes",
            "\t * up waiters which are stuck in synchronize_irq() when the",
            "\t * active count becomes zero. synchronize_irq() is serialized",
            "\t * against this code (hard irq handler) via IRQS_INPROGRESS",
            "\t * like the finalize_oneshot() code. See comment above.",
            "\t */",
            "\tatomic_inc(&desc->threads_active);",
            "",
            "\twake_up_process(action->thread);",
            "}",
            "irqreturn_t __handle_irq_event_percpu(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t retval = IRQ_NONE;",
            "\tunsigned int irq = desc->irq_data.irq;",
            "\tstruct irqaction *action;",
            "",
            "\trecord_irq_time(desc);",
            "",
            "\tfor_each_action_of_desc(desc, action) {",
            "\t\tirqreturn_t res;",
            "",
            "\t\t/*",
            "\t\t * If this IRQ would be threaded under force_irqthreads, mark it so.",
            "\t\t */",
            "\t\tif (irq_settings_can_thread(desc) &&",
            "\t\t    !(action->flags & (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT)))",
            "\t\t\tlockdep_hardirq_threaded();",
            "",
            "\t\ttrace_irq_handler_entry(irq, action);",
            "\t\tres = action->handler(irq, action->dev_id);",
            "\t\ttrace_irq_handler_exit(irq, action, res);",
            "",
            "\t\tif (WARN_ONCE(!irqs_disabled(),\"irq %u handler %pS enabled interrupts\\n\",",
            "\t\t\t      irq, action->handler))",
            "\t\t\tlocal_irq_disable();",
            "",
            "\t\tswitch (res) {",
            "\t\tcase IRQ_WAKE_THREAD:",
            "\t\t\t/*",
            "\t\t\t * Catch drivers which return WAKE_THREAD but",
            "\t\t\t * did not set up a thread function",
            "\t\t\t */",
            "\t\t\tif (unlikely(!action->thread_fn)) {",
            "\t\t\t\twarn_no_thread(irq, action);",
            "\t\t\t\tbreak;",
            "\t\t\t}",
            "",
            "\t\t\t__irq_wake_thread(desc, action);",
            "\t\t\tbreak;",
            "",
            "\t\tdefault:",
            "\t\t\tbreak;",
            "\t\t}",
            "",
            "\t\tretval |= res;",
            "\t}",
            "",
            "\treturn retval;",
            "}"
          ],
          "function_name": "handle_bad_irq, no_action, warn_no_thread, __irq_wake_thread, __handle_irq_event_percpu",
          "description": "实现中断处理核心逻辑，包括错误中断处理、唤醒线程函数、事件分发及中断处理结果收集，包含中断线程唤醒与状态同步机制",
          "similarity": 0.5896095633506775
        },
        {
          "chunk_id": 2,
          "file_path": "kernel/irq/handle.c",
          "start_line": 189,
          "end_line": 232,
          "content": [
            "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t retval;",
            "",
            "\tretval = __handle_irq_event_percpu(desc);",
            "",
            "\tadd_interrupt_randomness(desc->irq_data.irq);",
            "",
            "\tif (!irq_settings_no_debug(desc))",
            "\t\tnote_interrupt(desc, retval);",
            "\treturn retval;",
            "}",
            "irqreturn_t handle_irq_event(struct irq_desc *desc)",
            "{",
            "\tirqreturn_t ret;",
            "",
            "\tdesc->istate &= ~IRQS_PENDING;",
            "\tirqd_set(&desc->irq_data, IRQD_IRQ_INPROGRESS);",
            "\traw_spin_unlock(&desc->lock);",
            "",
            "\tret = handle_irq_event_percpu(desc);",
            "",
            "\traw_spin_lock(&desc->lock);",
            "\tirqd_clear(&desc->irq_data, IRQD_IRQ_INPROGRESS);",
            "\treturn ret;",
            "}",
            "int __init set_handle_irq(void (*handle_irq)(struct pt_regs *))",
            "{",
            "\tif (handle_arch_irq)",
            "\t\treturn -EBUSY;",
            "",
            "\thandle_arch_irq = handle_irq;",
            "\treturn 0;",
            "}",
            "asmlinkage void noinstr generic_handle_arch_irq(struct pt_regs *regs)",
            "{",
            "\tstruct pt_regs *old_regs;",
            "",
            "\tirq_enter();",
            "\told_regs = set_irq_regs(regs);",
            "\thandle_arch_irq(regs);",
            "\tset_irq_regs(old_regs);",
            "\tirq_exit();",
            "}"
          ],
          "function_name": "handle_irq_event_percpu, handle_irq_event, set_handle_irq, generic_handle_arch_irq",
          "description": "提供中断事件处理接口，包含通用架构中断入口点generic_handle_arch_irq，管理中断处理流程并集成随机化干扰注入功能",
          "similarity": 0.5504204034805298
        },
        {
          "chunk_id": 0,
          "file_path": "kernel/irq/handle.c",
          "start_line": 1,
          "end_line": 32,
          "content": [
            "// SPDX-License-Identifier: GPL-2.0",
            "/*",
            " * Copyright (C) 1992, 1998-2006 Linus Torvalds, Ingo Molnar",
            " * Copyright (C) 2005-2006, Thomas Gleixner, Russell King",
            " *",
            " * This file contains the core interrupt handling code. Detailed",
            " * information is available in Documentation/core-api/genericirq.rst",
            " *",
            " */",
            "",
            "#include <linux/irq.h>",
            "#include <linux/random.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "",
            "#include <asm/irq_regs.h>",
            "",
            "#include <trace/events/irq.h>",
            "",
            "#include \"internals.h\"",
            "",
            "#ifdef CONFIG_GENERIC_IRQ_MULTI_HANDLER",
            "void (*handle_arch_irq)(struct pt_regs *) __ro_after_init;",
            "#endif",
            "",
            "/**",
            " * handle_bad_irq - handle spurious and unhandled irqs",
            " * @desc:      description of the interrupt",
            " *",
            " * Handles spurious and unhandled IRQ's. It also prints a debugmessage.",
            " */"
          ],
          "function_name": null,
          "description": "定义了处理异常中断的函数handle_bad_irq，用于处理未处理或误触发的中断，打印调试信息并更新中断统计",
          "similarity": 0.5413079261779785
        }
      ]
    },
    {
      "source_file": "kernel/bpf/mmap_unlock_work.h",
      "md_summary": "> 自动生成时间: 2025-10-25 12:20:10\n> \n> 生成工具: 通义千问 API (qwen3-max)\n> \n> 原始文件: `bpf\\mmap_unlock_work.h`\n\n---\n\n# `bpf/mmap_unlock_work.h` 技术文档\n\n## 文件概述\n\n`bpf/mmap_unlock_work.h` 是 Linux 内核中用于在中断上下文（特别是中断关闭状态下）安全释放 `mmap_read_lock` 的辅助机制。该文件定义了一个基于 `irq_work` 的延迟解锁机制，以避免在中断禁用时直接调用 `mmap_read_unlock()` 可能导致的死锁问题（尤其是与调度器 `rq_lock` 的竞争）。此机制主要用于 BPF 子系统在遍历 VMA（虚拟内存区域）时的安全内存映射读锁管理。\n\n## 核心功能\n\n### 数据结构\n\n- **`struct mmap_unlock_irq_work`**  \n  封装了 `irq_work` 和目标 `mm_struct`，用于在中断工作队列中异步执行 `mmap_read_unlock()`。\n  - `struct irq_work irq_work`：内核通用的中断工作结构。\n  - `struct mm_struct *mm`：需要释放读锁的内存描述符。\n\n- **`DECLARE_PER_CPU(struct mmap_unlock_irq_work, mmap_unlock_work)`**  \n  声明一个 per-CPU 变量 `mmap_unlock_work`，每个 CPU 核心拥有一个独立实例，避免并发冲突。\n\n### 主要函数\n\n- **`bpf_mmap_unlock_get_irq_work()`**  \n  检查当前是否处于中断禁用上下文，并尝试获取可用的 per-CPU `mmap_unlock_irq_work` 实例。  \n  - 若中断已禁用且非 `PREEMPT_RT` 内核，则尝试使用本 CPU 的 `irq_work`。\n  - 若 `irq_work` 正在被使用（`irq_work_is_busy()` 返回 true），则返回 `true` 表示无法使用延迟解锁，需回退到其他处理路径。\n  - 在 `PREEMPT_RT` 内核中，由于实时性要求禁止在中断禁用上下文中尝试获取 mmap 信号量，直接强制回退。\n  - 返回值：`true` 表示 `irq_work` 不可用（需回退），`false` 表示可用；通过 `work_ptr` 输出获取到的 `work` 指针（可能为 `NULL`）。\n\n- **`bpf_mmap_unlock_mm()`**  \n  根据传入的 `work` 指针决定解锁方式：\n  - 若 `work == NULL`，直接调用 `mmap_read_unlock(mm)`。\n  - 否则，将 `mm` 保存到 `work` 中，通过 `rwsem_release()` 通知 Lockdep 锁已逻辑释放（避免误报锁泄漏），然后将 `irq_work` 加入中断工作队列，由中断上下文稍后执行实际解锁。\n\n## 关键实现\n\n1. **中断上下文安全解锁**  \n   在中断关闭（`irqs_disabled()`）时，直接调用 `mmap_read_unlock()` 可能因内部调度或锁竞争导致死锁（如与 runqueue 锁冲突）。因此，采用 `irq_work` 机制将解锁操作延迟到中断使能的上下文执行。\n\n2. **Per-CPU 单实例设计**  \n   每个 CPU 仅有一个 `mmap_unlock_work` 实例。若该实例已被占用（`irq_work_is_busy()`），则无法排队新的解锁请求，调用方必须采用回退策略（如放弃 VMA 查找或使用其他路径）。这种设计简化了同步，但限制了并发能力。\n\n3. **Lockdep 兼容性处理**  \n   在排队 `irq_work` 前，显式调用 `rwsem_release(&mm->mmap_lock.dep_map, _RET_IP_)`，告知 Lockdep 子系统“逻辑上”已释放锁，防止 Lockdep 误判为锁泄漏。\n\n4. **PREEMPT_RT 特殊处理**  \n   在实时内核（`CONFIG_PREEMPT_RT`）中，即使在中断禁用上下文也不允许尝试获取 mmap 信号量，因此直接跳过 `irq_work` 机制，强制使用回退路径，确保实时性约束。\n\n## 依赖关系\n\n- **`<linux/irq_work.h>`**：提供 `irq_work` 基础设施，包括 `irq_work_queue()`、`irq_work_is_busy()` 等接口。\n- **内存管理子系统**：依赖 `mm_struct` 和 `mmap_lock`（读写信号量）的定义及 `mmap_read_unlock()` 实现。\n- **Lockdep 子系统**：通过 `rwsem_release()` 与 Lockdep 交互，确保锁状态跟踪正确。\n- **BPF 子系统**：该头文件主要服务于 BPF 程序在内核态访问用户内存时的安全 VMA 查找逻辑。\n\n## 使用场景\n\n该文件主要用于 **BPF 程序在内核态执行期间需要安全访问用户空间内存映射** 的场景，典型流程如下：\n\n1. BPF 程序（如 kprobe、tracepoint 等）在中断或软中断上下文中执行。\n2. 需要通过 `mm->mmap_lock` 读锁保护来查找目标 VMA（例如 `bpf_probe_read_user()`）。\n3. 若当前处于 `irqs_disabled()` 状态：\n   - 调用 `bpf_mmap_unlock_get_irq_work()` 获取延迟解锁工作项。\n   - 若获取成功，则在完成 VMA 操作后调用 `bpf_mmap_unlock_mm()`，将解锁操作排队到 `irq_work`。\n   - 若获取失败（`irq_work` 忙或 `PREEMPT_RT`），则必须放弃操作或采用不依赖 mmap 锁的替代方案。\n4. 当中断上下文退出、中断重新使能后，`irq_work` 回调自动执行 `mmap_read_unlock()`，完成实际解锁。\n\n此机制确保了在高优先级上下文（如中断处理）中对内存映射的只读访问既安全又不会破坏内核锁的正确性。",
      "similarity": 0.6262250542640686,
      "chunks": []
    }
  ]
}